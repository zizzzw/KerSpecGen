[
  {
    "instruction": "Store Connected Direct: The store-connected relationship is defined for specific capability configurations, where the set of store-connected pairs is {(0,0), (1,1), (1,2)}. This ensures that the store operations are restricted to these specific target and source pairs, maintaining the integrity and security of the system.",
    "input": "",
    "output": "lemma store_connected_direct_s_helper1:\n  \"{c'.(c' = \\<lparr>target = 0, rights = UNIV\\<rparr> \\<or> c' \\<in> range create_cap) \\<and>\n        c' \\<noteq> \\<lparr>target = 1, rights = {Create}\\<rparr> \\<and> c' \\<noteq> \\<lparr>target = 2, rights = {Create}\\<rparr> \\<and>\n        Store \\<in> rights c'} = {full_cap 0}\"\n by (auto simp: create_cap_def full_cap_def all_rights_def e0_caps_def)\n\nlemma store_connected_direct_s_helper2:\n  \"{c'. (c' = \\<lparr>target = 2, rights = {Create}\\<rparr> \\<or> c' = \\<lparr>target = 1, rights = {Write, Store}\\<rparr> \\<or>\n         c' = \\<lparr>target = 2, rights = UNIV\\<rparr>)    \\<and>  Store \\<in> rights c'}\n   = {\\<lparr>target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (auto simp: create_cap_def full_cap_def all_rights_def e0_caps_def)\n\n\nlemma store_connected_direct_s:\n  \"store_connected_direct s = {(0,0), (1,1), (1,2)}\"\n  by (fastforce simp: store_connected_direct_def s_def e0_caps_def\n                      full_cap_def all_rights_def create_cap_def null_entity_def\n                      store_connected_direct_s_helper1 store_connected_direct_s_helper2\n               split: if_split_asm)",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64 Architecture State: Maintains architecture-specific state including an ASID table, global page table sets for different VM levels, and a kernel virtual space mapping.",
    "input": "",
    "output": "record arch_state =\n  riscv_asid_table :: \"asid_high_index \\<rightharpoonup> obj_ref\"\n  riscv_global_pts :: \"RISCV64_A.vm_level \\<Rightarrow> obj_ref set\"\n  riscv_kernel_vspace :: \"obj_ref \\<Rightarrow> RISCV64_H.riscvvspace_region_use\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VM Attributes: Define a set of attributes that can be applied to virtual memory, including global, execute, and device-specific attributes. These attributes allow for fine-grained control over the properties and behavior of memory pages in the system.",
    "input": "",
    "output": "(* This datatype does not match up with the executable spec directly:\n   This one here models all \"things\" one can set on a page entry.\n   The attributes accessible to users are the ones returned by attribs_from_word. *)\ndatatype vm_attribute = Global | Execute | Device\ntype_synonym vm_attributes = \"vm_attribute set\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization State: Defines the initial state of the kernel, including the boot end address, ARM vector table, ARM kernel stack, and the start of the idle thread. These constants ensure that the kernel has a well-defined starting point for its execution and resource management.",
    "input": "",
    "output": "consts\n  ki_boot_end :: paddr\n  arm_vector_table :: obj_ref\n  arm_kernel_stack :: obj_ref\n  idle_thread_start :: vspace_ref (* &idle_thread *)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Scheduler Flexibility: The scheduler can choose any active thread or the idle thread for execution. If the selected thread is the current thread, it may skip the context switch. Similarly, if the idle thread is the current thread, it may omit the switch to the idle thread.",
    "input": "",
    "output": "definition schedule_unit :: \"(unit,unit) s_monad\" where\n\"schedule_unit \\<equiv> (do\n   cur \\<leftarrow> gets cur_thread;\n   threads \\<leftarrow> allActiveTCBs;\n   thread \\<leftarrow> select threads;\n   (if thread = cur then\n     return () \\<sqinter> switch_to_thread thread\n   else\n     switch_to_thread thread)\n od) \\<sqinter>\n (do\n   cur \\<leftarrow> gets cur_thread;\n   idl \\<leftarrow> gets idle_thread;\n   if idl = cur then\n     return () \\<sqinter> switch_to_idle_thread\n   else switch_to_idle_thread\n  od)\"\n\ninstance ..\nend\n\n\nlemmas schedule_def = schedule_det_ext_ext_def schedule_unit_def\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve ETCB Information: Obtain and return a specific attribute of an extended thread control block (ETCB) by applying a given function to the ETCB.",
    "input": "",
    "output": "definition\n  get_etcb :: \"obj_ref \\<Rightarrow> det_state \\<Rightarrow> etcb option\"\nwhere\n  \"get_etcb tcb_ref es \\<equiv> ekheap es tcb_ref\"\n\ndefinition\n  ethread_get :: \"(etcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> 'a det_ext_monad\"\nwhere\n  \"ethread_get f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_etcb tptr;\n     return $ f tcb\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate ASID Entry: Remove virtual to physical mappings for a given ASID by invalidating the hardware ASID entry if it exists, followed by invalidating the ASID itself.",
    "input": "",
    "output": "definition\ninvalidate_asid_entry :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid_entry asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  when (maybe_hw_asid \\<noteq> None) $ invalidate_hw_asid_entry (the maybe_hw_asid);\n  invalidate_asid asid\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel Badged Sends: Cancels all message send operations for threads queued in a specific endpoint and using a particular badge. Threads with the matching badge are set to the restart state and re-enqueued, while the endpoint is updated to reflect the remaining or cleared queue.",
    "input": "",
    "output": "definition\n  cancel_badged_sends :: \"obj_ref \\<Rightarrow> badge \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_badged_sends epptr badge \\<equiv> do\n    ep \\<leftarrow> get_endpoint epptr;\n    case ep of\n          IdleEP \\<Rightarrow> return ()\n        | RecvEP _ \\<Rightarrow>  return ()\n        | SendEP queue \\<Rightarrow>  do\n            set_endpoint epptr IdleEP;\n            queue' \\<leftarrow> (swp filterM queue) (\\<lambda> t. do\n                st \\<leftarrow> get_thread_state t;\n                if blocking_ipc_badge st = badge then do\n                  set_thread_state t Restart;\n                  do_extended_op (tcb_sched_action (tcb_sched_enqueue) t);\n                  return False od\n                else return True\n            od);\n            ep' \\<leftarrow> return (case queue' of\n                           [] \\<Rightarrow> IdleEP\n                         | _ \\<Rightarrow> SendEP queue');\n            set_endpoint epptr ep';\n            do_extended_op (reschedule_required)\n        od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Address Space Switch for Flush: Switch to a specific address space to perform a flush operation. If the current page directory does not match the target, a context switch is performed, and the flush operation is executed. The type of flush (clean, invalidate, clean-invalidate, or unify) determines the specific cache operations to be carried out.",
    "input": "",
    "output": "definition\nset_vm_root_for_flush :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"set_vm_root_for_flush pd asid \\<equiv> do\n    tcb \\<leftarrow> gets cur_thread;\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    not_is_pd \\<leftarrow> (case thread_root of\n                    ArchObjectCap (PageDirectoryCap cur_pd (Some _)) \\<Rightarrow> return (cur_pd \\<noteq> pd)\n                  | _ \\<Rightarrow> return True);\n    (if not_is_pd then do\n        arm_context_switch pd asid;\n        return True\n    od\n    else return False)\nod\"\n\ndefinition\ndo_flush :: \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\" where\n\"do_flush flush_type vstart vend pstart \\<equiv>\n    let vstart' = ptrFromPAddr pstart;\n        vend'  = vstart' + (vend - vstart)\n    in\n    (case flush_type of\n       Clean \\<Rightarrow> cleanCacheRange_RAM vstart' vend' pstart\n     | Invalidate \\<Rightarrow> invalidateCacheRange_RAM vstart' vend' pstart\n     | CleanInvalidate \\<Rightarrow> cleanInvalidateCacheRange_RAM vstart' vend' pstart\n     | Unify \\<Rightarrow> do\n         cleanCacheRange_PoU vstart' vend' pstart;\n         dsb;\n         invalidateCacheRange_I vstart' vend' pstart;\n         branchFlushRange vstart' vend' pstart;\n         isb\n     od)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural TCB Operations: Define and implement architecture-specific operations for managing thread control blocks, including getting and setting thread state, ensuring that the TCB is correctly managed according to the architectural requirements.",
    "input": "",
    "output": "theory ArchTCB_H\nimports TCBDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/ARM.lhs RegisterSet= CONTEXT ARM_HYP_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "PML4E Access and Modification: Retrieve and modify the PML4E entry at a given pointer in kernel memory. The functions calculate the base address and offset, access the PML4 table, and either return or update the specific PML4E entry.",
    "input": "",
    "output": "definition\n  get_pml4e :: \"obj_ref \\<Rightarrow> (pml4e,'z::state_ext) s_monad\" where\n  \"get_pml4e ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pml4_bits);\n     offset \\<leftarrow> return ((ptr && mask pml4_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pml4 base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pml4e :: \"obj_ref \\<Rightarrow> pml4e \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pml4e p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pml4_bits);\n    offset \\<leftarrow> return ((p && mask pml4_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pml4 base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pml4 base pt'\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Wrapper Consistency: The wrapper function `ignore_failure` behaves identically to the original function `f` when `f` is guaranteed not to fail and not to return a failure.",
    "input": "",
    "output": "lemma failure_consistent:\n  \"\\<lbrakk> empty_fail f; no_fail \\<top> f \\<rbrakk> \\<Longrightarrow> ignore_failure f = f\"\n  apply (simp add: ignore_failure_def empty_fail_def no_fail_def)\n  apply (rule ext)\n  apply (auto intro: prod_eqI)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Memory Lookup: Perform a lookup in the page table for a given ASID and virtual space reference down to a specified level, returning the level and corresponding object reference. If the lookup reaches the bottom level or encounters a page or invalid entry, it terminates early.",
    "input": "",
    "output": "definition vs_lookup_table ::\n  \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"vs_lookup_table bot_level asid vptr \\<equiv> do {\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     if bot_level = asid_pool_level\n     then oreturn (asid_pool_level, pool_ptr)\n     else do {\n       top_level_pt \\<leftarrow> vspace_for_pool pool_ptr asid \\<circ> asid_pools_of;\n       pt_walk max_pt_level bot_level top_level_pt vptr \\<circ> ptes_of\n     }\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Finalization: Prepare a VCPU for removal by dissociating it from its associated TCB, if any, and cleaning up the current VCPU state.",
    "input": "",
    "output": "definition vcpu_finalise :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_finalise vr \\<equiv> do\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of\n      Some t \\<Rightarrow> dissociate_vcpu_tcb vr t\n    | None \\<Rightarrow> return ()\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Empty a Capability Slot: Ensures that a capability slot is emptied by setting it to `NullCap` and updating the CDT (Capability Descriptor Table) to remove any references to the slot. If the slot is not already empty, it performs additional cleanup operations, including updating parent references and executing extended operations for slot finalization.",
    "input": "",
    "output": "definition\n  empty_slot :: \"cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"empty_slot slot cleanup_info \\<equiv> do\n      cap \\<leftarrow> get_cap slot;\n      if cap = NullCap then\n        return ()\n      else do\n        slot_p \\<leftarrow> gets (\\<lambda>s. cdt s slot);\n        cdt \\<leftarrow> gets cdt;\n        parent \\<leftarrow> return $ cdt slot;\n        set_cdt ((\\<lambda>p. if cdt p = Some slot\n                     then parent\n                     else cdt p) (slot := None));\n        do_extended_op (empty_slot_ext slot slot_p);\n        set_original slot False;\n        set_cap NullCap slot;\n\n        post_cap_deletion cleanup_info\n      od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access and Modification: Provides functions to access and modify the x64 virtual space, including retrieving and storing PTEs, and getting and setting PDPTs. These functions ensure that the kernel can effectively manage and manipulate the virtual memory structures.",
    "input": "",
    "output": "definition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\"\n\ndefinition\n  get_pdpt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pdpte,'z::state_ext) s_monad\" where\n  \"get_pdpt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PDPointerTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pdpt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pdpte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pdpt ptr pt \\<equiv> set_object ptr (ArchObj (PDPointerTable pt))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flush Page Mappings: Invalidate the mappings associated with a given page in the virtual address space. This involves setting the virtual machine root for flushing, loading the hardware ASID, and invalidating the local TLB if the hardware ASID is present. If the root was switched during the process, it is reset to the current thread's virtual machine root.",
    "input": "",
    "output": "definition\nflush_page :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_page page_size pd asid vptr\\<equiv> do\n    assert (vptr && mask pageBits = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_VAASID (vptr || ucast hw_asid);\n      when root_switched $ do\n          tcb \\<leftarrow> gets cur_thread;\n          set_vm_root tcb\n      od\n   od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup and Validation: Ensures that the mapping size for a virtual space is valid by checking that the size is within the allowed maximum object size.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  Untyped_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/X64.lhs CONTEXT X64_H bodies_only ArchInv=ArchRetypeDecls_H NOT checkPML4At checkPDPTAt checkPDAt checkPTAt checkValidMappingSize\n#INCLUDE_HASKELL SEL4/Object/IOPort/X64.lhs CONTEXT X64_H bodies_only ArchInv=ArchRetypeDecls_H\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert\n    (\\<lambda>s. 2 ^ pageBitsForSize sz <= gsMaxObjectSize s) []\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate Page Directory: Find the page directory associated with a given virtual ASID by looking up the ASID in the ASID table and then in the corresponding ASID pool. If the ASID or the page directory is not found, an error is thrown.",
    "input": "",
    "output": "definition\nfind_pd_for_asid :: \"asid \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"find_pd_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pd \\<leftarrow> returnOk (pool (ucast asid));\n    (case pd of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Conjunction Congruence: Establishes a congruence rule for conjunction, allowing the substitution of equivalent propositions within a conjunction.",
    "input": "",
    "output": "lemmas conj_cong = HOL.conj_cong",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Recycle and Reset: The target object is reset to its initial state, with any children capabilities first being revoked. The process involves clearing the object's capabilities, resetting memory mappings, and merging the object with a default template to restore its initial configuration.",
    "input": "",
    "output": "definition\n  clear_object_caps :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n \"clear_object_caps ptr = do\n    ptrs \\<leftarrow> gets (\\<lambda>s. {cptr. fst cptr = ptr \\<and> opt_cap cptr s \\<noteq> None});\n    ptrlist \\<leftarrow> select {xs. set xs = ptrs \\<and> distinct xs};\n    mapM_x empty_slot ptrlist\n  od\"\n\ndefinition cdl_default_tcb :: \"cdl_object\"\nwhere \"cdl_default_tcb \\<equiv>  Tcb \\<lparr>cdl_tcb_caps =\n           [tcb_cspace_slot \\<mapsto> cdl_cap.NullCap, tcb_vspace_slot \\<mapsto> cdl_cap.NullCap, tcb_replycap_slot \\<mapsto>\n            cdl_cap.NullCap, tcb_caller_slot \\<mapsto> cdl_cap.NullCap, tcb_ipcbuffer_slot \\<mapsto> cdl_cap.NullCap,\n            tcb_pending_op_slot \\<mapsto> cdl_cap.NullCap, tcb_boundntfn_slot \\<mapsto> cdl_cap.NullCap],\n           cdl_tcb_fault_endpoint = 0,\n           cdl_tcb_intent =\n             \\<lparr>cdl_intent_op = None, cdl_intent_error = False,cdl_intent_cap = 0, cdl_intent_extras = [],\n                cdl_intent_recv_slot = None\\<rparr>, cdl_tcb_has_fault = False, cdl_tcb_domain = minBound\\<rparr>\"\n\ndefinition obj_tcb :: \"cdl_object \\<Rightarrow> cdl_tcb\"\nwhere \"obj_tcb obj \\<equiv> case obj of Tcb tcb \\<Rightarrow> tcb\"\n\ndefinition tcb_caps_merge :: \"cdl_tcb \\<Rightarrow> cdl_tcb \\<Rightarrow> cdl_tcb\"\n  where \"tcb_caps_merge regtcb captcb \\<equiv> regtcb\\<lparr>cdl_tcb_caps\n  := (cdl_tcb_caps captcb)(tcb_pending_op_slot \\<mapsto> the (cdl_tcb_caps regtcb tcb_pending_op_slot), tcb_boundntfn_slot \\<mapsto> the (cdl_tcb_caps regtcb tcb_boundntfn_slot))\\<rparr>\"\n\ndefinition merge_with_dft_tcb :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere \"merge_with_dft_tcb o_id \\<equiv>\n do\n  new_intent \\<leftarrow> select UNIV;\n  KHeap_D.update_thread o_id (cdl_tcb_intent_update (\\<lambda>x. new_intent) \\<circ> (tcb_caps_merge (obj_tcb cdl_default_tcb)))\n od\"\n\nfun\n  reset_mem_mapping :: \"cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"reset_mem_mapping (FrameCap dev p rts sz b mp) = FrameCap dev p rts sz b None\"\n| \"reset_mem_mapping (PageTableCap ptr b mp) = PageTableCap ptr b None\"\n| \"reset_mem_mapping (PageDirectoryCap ptr b ma) = PageDirectoryCap ptr b None\"\n| \"reset_mem_mapping cap = cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ghost State Management: Manipulates the ghost state to manage memory regions, including clearing regions, adding new frames, and adding new capability nodes. These operations ensure that the ghost state accurately reflects the system's memory layout and capabilities, supporting verification and analysis.",
    "input": "",
    "output": "theory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . \n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> machine_word\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> machine_word \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Capabilities for Same Object: Determine if two capabilities refer to the same object by comparing their types and properties, ensuring that they are either of the same region or, in the case of architecture-specific capabilities, that they refer to the same architectural object.",
    "input": "",
    "output": "definition\n  same_object_as :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\" where\n \"same_object_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (UntypedCap dev r bits free, _) \\<Rightarrow> False\n    | (IRQControlCap, IRQHandlerCap n) \\<Rightarrow> False\n    | (ArchObjectCap ac, ArchObjectCap ac') \\<Rightarrow> same_aobject_as ac ac'\n    | _ \\<Rightarrow> same_region_as cp cp')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Initialization and Management: The ASID pool is initialized with a function array where each entry is set to `Nothing`. The loading and updating of the ASID pool object are handled by default methods, ensuring that the ASID pool can be managed within the kernel's memory space.",
    "input": "",
    "output": "instantiation RISCV64_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide Unqualified Names: Ensures that unqualified names conflicting with Kernel_Config names are hidden, requiring the use of the Kernel_C prefix for these names to avoid conflicts and maintain clarity.",
    "input": "",
    "output": "hide_const (open)\n  numDomains",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Preemptable Cap Deletion: Ensures the deletion of a capability without causing preemption, suitable for capabilities that exist at the CapDL level but not at lower levels. The operation checks if the capability is not null, determines if it is a final capability, and then finalizes and empties the slot.",
    "input": "",
    "output": "definition\n  delete_cap_simple :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"delete_cap_simple cap_ref \\<equiv> do\n    cap \\<leftarrow> get_cap cap_ref;\n    unless (cap = NullCap) $ do\n      final \\<leftarrow> is_final_cap cap;\n      fast_finalise cap final;\n      always_empty_slot cap_ref\n    od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Fault Handling: Manages and processes hypervisor faults, ensuring the system can respond appropriately to exceptions and errors at the hypervisor level.",
    "input": "",
    "output": "(*\n    Hypervisor code.\n*)\n\ntheory Hypervisor_H\nimports\n  CNode_H\n  ArchHypervisor_H\n  KernelInitMonad_H\nbegin\n\narch_requalify_consts (H)\n  handleHypervisorFault\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Switch to Thread's Virtual Address Space: Transition the system to a specified thread's virtual address space context and clear the load-exclusive monitor, ensuring that the memory operations are correctly aligned with the new context.",
    "input": "",
    "output": "definition\n  arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> do\n     set_vm_root t;\n     do_machine_op $ clearExMonitor\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Handling:\n- Get Active IRQ: Determines the active interrupt request (IRQ) by updating the IRQ state and checking if the IRQ is masked or if it is a non-kernel IRQ while in kernel mode. If the IRQ is valid, it returns the active IRQ; otherwise, it returns None.\n- Mask Interrupt: Updates the masking status of a specific IRQ, allowing or preventing its processing.\n- Acknowledge Interrupt: Acknowledges an interrupt, indicating that it has been processed.\n- Set Interrupt Mode: Configures the triggering mode and polarity for a specific IRQ.",
    "input": "",
    "output": "definition getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\" where\n  \"getActiveIRQ in_kernel \\<equiv> do\n     is_masked \\<leftarrow> gets $ irq_masks;\n     modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n     active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n     if is_masked active_irq \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n     then return None\n     else return (Some active_irq)\n   od\"\n\ndefinition maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\" where\n  \"maskInterrupt m irq \\<equiv> modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\" where\n  \"ackInterrupt \\<equiv> \\<lambda>irq. return ()\"\n\ndefinition setInterruptMode :: \"irq \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\" where\n  \"setInterruptMode \\<equiv> \\<lambda>irq levelTrigger polarityLow. return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Definitions and Abbreviations: Defines types for C pointers, commands, bodies, and states, and provides an abbreviation for lifting a C state to a higher-level representation. This ensures that the system can handle and manipulate C-level data structures in a type-safe and consistent manner.",
    "input": "",
    "output": "(* The base theory for generated bitfield proofs about the kernel *)\n\ntheory KernelState_C\nimports\n  \"Word_Lib.WordSetup\"\n  \"CLib.BitFieldProofsLib\"\n  \"Substitute\"\nbegin\n\ntype_synonym c_ptr_name = int\ntype_synonym 't c_com = \"('t, c_ptr_name, strictc_errortype) com\"\ntype_synonym 't c_body = \"('t, c_ptr_name, strictc_errortype) body\"\ntype_synonym 't c_xstate = \"('t, strictc_errortype) xstate\"\n\ntype_synonym cstate = \"globals myvars\"\ntype_synonym rf_com = \"cstate c_com\"\n\nabbreviation\n  \"cslift (s :: cstate) \\<equiv> clift (t_hrs_' (globals s))\"\n\nlemma cslift_def: \"is_an_abbreviation\" by (simp add: is_an_abbreviation_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definitions: Define and requalify types for machine state components such as registers, virtual CPU registers, virtual PPI event IRQs, and virtual timers, ensuring proper handling and management of these components in the ARM_HYP architecture.",
    "input": "",
    "output": "end\n\narch_requalify_types register vcpureg vppievent_irq virt_timer\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP instanceproofs ONLY VPPIEventIRQ VirtTimer",
    "system": "",
    "history": []
  },
  {
    "instruction": "Send Fault IPC: When a thread encounters a fault, retrieve its fault handler capability and send a fault message to the designated endpoint. The message is sent only if the handler capability has the necessary permissions (AllowSend and either AllowGrant or AllowGrantReply). If the handler does not have the required permissions, a CapFault is thrown.",
    "input": "",
    "output": "text \\<open>When a thread encounters a fault, retreive its fault handler capability\nand send a fault message.\\<close>\ndefinition\n  send_fault_ipc :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n  \"send_fault_ipc tptr fault \\<equiv> doE\n     handler_cptr \\<leftarrow> liftE $ thread_get tcb_fault_handler tptr;\n     handler_cap \\<leftarrow> cap_fault_on_failure (of_bl handler_cptr) False $\n         lookup_cap tptr handler_cptr;\n\n     let f = CapFault (of_bl handler_cptr) False (MissingCapability 0)\n     in\n     (case handler_cap\n       of EndpointCap ref badge rights \\<Rightarrow>\n           if AllowSend \\<in> rights \\<and> (AllowGrant \\<in> rights \\<or> AllowGrantReply \\<in> rights)\n           then liftE $ (do\n               thread_set (\\<lambda>tcb. tcb \\<lparr> tcb_fault := Some fault \\<rparr>) tptr;\n               send_ipc True True (cap_ep_badge handler_cap)\n                        (AllowGrant \\<in> rights) True tptr (cap_ep_ptr handler_cap)\n             od)\n           else throwError f\n        | _ \\<Rightarrow> throwError f)\n   odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Switch to Thread's Virtual Address Space: Switch the virtual address space context to the specified thread, update the VCPU state, and clear the load-exclusive monitor.",
    "input": "",
    "output": "definition\n  arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> do\n     t' \\<leftarrow> gets_the $ get_tcb t;\n     vcpu_switch $ tcb_vcpu $ tcb_arch t';\n     set_vm_root t;\n     do_machine_op $ clearExMonitor\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Window Sizing: Ensures that the kernel's memory window is sufficiently large, with the base address of the kernel ELF plus 2^22 being less than or equal to the kernel ELF base, and the kernel ELF base plus at least one page (2^12) being less than or equal to the device base. This guarantees that the kernel and its associated data fit within the allocated memory regions without overlap.",
    "input": "",
    "output": "lemma kernel_window_sufficient:\n  \"pptrBase + (1 << 22) \\<le> kernelELFBase\"\n  unfolding pptrBase_def canonical_bit_def kernelELFBase_def kernelELFPAddrBase_def pptrTop_def\n  by (simp add: mask_def Kernel_Config.physBase_def)\n\nlemma kernel_elf_window_at_least_page:\n  \"kernelELFBase + 2 ^ 12 \\<le> kdevBase\"\n  unfolding kernelELFBase_def kernelELFPAddrBase_def kdevBase_def pptrTop_def\n  by (simp add: mask_def Kernel_Config.physBase_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel ELF Base: Specifies the virtual address at which the kernel code is mapped in the virtual address space.",
    "input": "",
    "output": "definition kernel_elf_base :: \"vspace_ref\"\n  where\n  \"kernel_elf_base \\<equiv> Platform.RISCV64.kernelELFBase\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate Hardware ASID Entry: Remove the mapping from a specified hardware ASID to its corresponding virtual ASID, ensuring that the hardware ASID is no longer associated with any virtual ASID in the system.",
    "input": "",
    "output": "definition\ninvalidate_hw_asid_entry :: \"hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_hw_asid_entry hw_asid \\<equiv> do\n  hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n  hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid:= None));\n  modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Save: Saves the state of a VCPU, including its registers and context. It updates the VCPU's control registers, saves the virtual timer, and retrieves and updates the GIC (Generic Interrupt Controller) related registers. This ensures that the VCPU's state is preserved and can be restored accurately.",
    "input": "",
    "output": "definition\n  vcpu_save :: \"(obj_ref \\<times> bool) option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_save vb \\<equiv>\n     case vb\n     of Some (vr, active) \\<Rightarrow> do\n          do_machine_op dsb;\n\n          when active $ do\n            vcpu_save_reg vr VCPURegSCTLR;\n            hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n            vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n            save_virt_timer vr\n          od;\n\n          vmcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_vmcr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_vmcr := vmcr\\<rparr>);\n\n          apr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_apr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_apr := apr\\<rparr>);\n\n          num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n          gicIndices \\<leftarrow> return [0..<num_list_regs];\n\n          mapM (\\<lambda>vreg. do\n                    val \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat vreg);\n                    vgic_update_lr vr vreg val\n                  od)\n            gicIndices;\n\n          vcpu_save_reg_range vr VCPURegACTLR VCPURegSPSRfiq;\n          do_machine_op isb\n       od\n     | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Capabilities: Define the structure of capabilities, which include attributes such as the object they point to, the rights they confer to the holder, and the allowed interactions with the target object.",
    "input": "",
    "output": "datatype cdl_cap =\n    NullCap",
    "system": "",
    "history": []
  },
  {
    "instruction": "First Capability Slot Determination: Identify the first capability slot of a given kernel object, such as a thread, CNode, or zombie, by returning the appropriate cslot pointer.",
    "input": "",
    "output": "primrec (nonexhaustive)\n  first_cslot_of :: \"cap \\<Rightarrow> cslot_ptr\"\nwhere\n  \"first_cslot_of (ThreadCap oref) = (oref, tcb_cnode_index 0)\"\n| \"first_cslot_of (CNodeCap oref bits g) = (oref, replicate bits False)\"\n| \"first_cslot_of (Zombie oref bits n) = (oref, replicate (zombie_cte_bits bits) False)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle VM Fault: Generate a formatted VM fault message for a thread's supervisor after encountering a page fault. The message includes the fault address and relevant fault information, ensuring that the supervisor can appropriately handle the fault.",
    "input": "",
    "output": "fun\nhandle_vm_fault :: \"word32 \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n\"handle_vm_fault thread ARMDataAbort = doE\n    addr \\<leftarrow> liftE $ do_machine_op getHDFAR;\n    uaddr \\<leftarrow> liftE $ do_machine_op (addressTranslateS1 addr);\n    fault \\<leftarrow> liftE $ do_machine_op getHSR;\n    let faddr = (uaddr && complement (mask pageBits)) || (addr && mask pageBits)\n    in\n    throwError $ ArchFault $ VMFault faddr [0, fault && 0x3ffffff]\nodE\"\n|\n\"handle_vm_fault thread ARMPrefetchAbort = doE\n    pc \\<leftarrow> liftE $ as_user thread $ getRestartPC;\n    upc \\<leftarrow> liftE $ do_machine_op (addressTranslateS1 pc);\n    fault \\<leftarrow> liftE $ do_machine_op getHSR;\n    let faddr = (upc && complement (mask pageBits)) || (pc && mask pageBits)\n    in\n    throwError $ ArchFault $ VMFault faddr [1, fault && 0x3ffffff]\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Mapping: Verify that a given frame is correctly mapped by a specified mapping entry. The function checks if the physical address and page size of the frame match the corresponding values in the page table or page directory entry.",
    "input": "",
    "output": "definition\ncheck_mapping_pptr :: \"obj_ref \\<Rightarrow> vmpage_size \\<Rightarrow> (obj_ref + obj_ref) \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"check_mapping_pptr pptr pgsz tablePtr \\<equiv> case tablePtr of\n   Inl ptePtr \\<Rightarrow> do\n     pte \\<leftarrow> get_pte ptePtr;\n     return $ case pte of\n       SmallPagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSmallPage\n     | LargePagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMLargePage\n     | _ \\<Rightarrow> False\n   od\n | Inr pdePtr \\<Rightarrow> do\n     pde \\<leftarrow> get_pde pdePtr;\n     return $ case pde of\n       SectionPDE x _ _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSection\n     | SuperSectionPDE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSuperSection\n     | _ \\<Rightarrow> False\n   od\"\n\n\ndefinition\n  \"last_byte_pte x \\<equiv> let pte_bits = 2 in x + ((1 << pte_bits) - 1)\"\n\ndefinition\n  \"last_byte_pde x \\<equiv> let pde_bits = 2 in x + ((1 << pde_bits) - 1)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Disable: Disables the VCPU mode on the hardware level by turning off the VGIC, saving relevant VCPU registers, and adjusting system control settings to ensure proper state transition. This includes saving the SCTLR and CPACR registers, disabling the S1 MMU, setting the HCR to native mode, enabling FPU instructions in EL0 and EL1, and masking the virtual timer interrupt.",
    "input": "",
    "output": "definition vcpu_disable :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_disable vo \\<equiv> do\n    do_machine_op dsb;\n    case vo of\n      Some vr \\<Rightarrow> do\n        hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n        vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n        vcpu_save_reg vr VCPURegSCTLR;\n        vcpu_save_reg vr VCPURegCPACR; \\<comment> \\<open>since FPU enabled\\<close>\n        do_machine_op isb\n      od\n    | _ \\<Rightarrow> return ();\n    do_machine_op $ do\n        set_gic_vcpu_ctrl_hcr 0; \\<comment> \\<open>turn VGIC off\\<close>\n        isb;\n        setSCTLR sctlrDefault; \\<comment> \\<open>turn S1 MMU off\\<close>\n        isb;\n        setHCR hcrNative;\n        isb;\n        \\<comment> \\<open>allow FPU instructions in EL0 and EL1 for native threads\\<close>\n        enableFpuEL01\n      od;\n    case vo of\n      Some vr \\<Rightarrow> do\n          save_virt_timer vr;\n          do_machine_op $ maskInterrupt True irqVTimerEvent\n        od\n    | _ \\<Rightarrow> return ()\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "FPU Register Management: The system manages 64 general FPU registers, ensuring that floating-point operations are supported and state is maintained effectively.",
    "input": "",
    "output": "type_synonym fpu_regs = 64",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Initialization: Initialize memory to be used as user memory, ensuring it is cleared and ready for use. This process includes a call to clean the cache range, which is essential for maintaining memory integrity and performance.",
    "input": "",
    "output": "abbreviation (input) \"initMemory == clearMemory\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Stub for RISCV64: Provides the necessary declarations and implementations for hypervisor functionality specific to the RISCV64 architecture, ensuring that the hypervisor can manage and interact with virtual machines effectively.",
    "input": "",
    "output": "(*\n  Hypervisor stub for RISCV64\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/RISCV64.hs Arch= CONTEXT RISCV64_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/RISCV64.hs Arch= CONTEXT RISCV64_H bodies_only ArchInv= ArchLabels=\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definition: Defines the machine state with components including IRQ masks, IRQ state, underlying memory, and device state, along with an underspecified rest of the machine state. This structure allows for the declaration of interface functions without detailing the transformations or effects on the machine.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\nend\n\nqualify X64 (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"X64.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"word64 \\<Rightarrow> word8\"\n  device_state :: \"word64 \\<Rightarrow> word8 option\"\n  machine_state_rest :: X64.machine_state_rest\n\nconsts irq_oracle :: \"nat \\<Rightarrow> word8\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Lookup: Recursively searches the page table hierarchy starting from a given level, using the provided virtual address and target page table pointer, to find the slot that points to the target page table. Ensures that the search is valid by checking the level and PTE type, and continues the search at lower levels if the current level does not match the target.",
    "input": "",
    "output": "fun pt_lookup_from_level ::\n  \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (machine_word, 'z::state_ext) lf_monad\"\n  where\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr s = (doE\n     unlessE (0 < level) $ throwError InvalidRoot;\n     slot <- returnOk $ pt_slot_offset level pt_ptr vptr;\n     pte <- liftE $ gets_the $ oapply slot o ptes_of;\n     unlessE (is_PageTablePTE pte) $ throwError InvalidRoot;\n     ptr <- returnOk (pptr_from_pte pte);\n     if ptr = target_pt_ptr\n       then returnOk slot\n       else pt_lookup_from_level (level - 1) ptr vptr target_pt_ptr\n   odE) s\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "SysTake Operation: The operation `op4` is legal and its execution transitions the system state from `s4` to either `s4` or `s5`, ensuring that the system remains in a valid state.",
    "input": "",
    "output": "lemma op4_legal:\n  \"legal op4 s4\"\n  by  (clarsimp simp: op4_def all_rights_def)\n\nlemma execute_op4_safe:\n  \"step op4 s4 \\<subseteq> ({s4, s5})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s4_def s5_def op4_def step_def takeOperation_def\n                    diminish_def all_rights_def write_cap_def\n             split: if_split_asm)\n  done\n\nlemma execute_op4_live:\n  \"step op4 s4 \\<supseteq> ({s4, s5})\"\n  apply clarsimp\n  apply (simp add: op4_legal step_def)\n  apply (rule disjI2)\n  apply (simp add: op4_def)\n  apply (rule ext)\n  apply (fastforce simp: s4_def s5_def takeOperation_def diminish_def all_rights_def write_cap_def)\n  done\n\nlemma execute_op4:\n  \"step op4 s4 = ({s4, s5})\"\n  apply rule\n   apply (rule execute_op4_safe)\n  apply (rule execute_op4_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define and initialize various platform-specific constants, including base addresses, offsets, top addresses, and interrupt request (IRQ) values. These constants are used to manage memory addresses and IRQs, ensuring consistent and predictable behavior across the system.",
    "input": "",
    "output": "context Arch begin global_naming AARCH64\n\nvalue_type irq_len = Kernel_Config.irqBits \n\n\n\ndefinition paddrBase :: machine_word where\n  \"paddrBase \\<equiv> 0\"\n\ndefinition pptrBaseOffset :: machine_word where\n  \"pptrBaseOffset = pptrBase - paddrBase\"\n\ndefinition paddrTop :: machine_word where\n  \"paddrTop = pptrTop - pptrBaseOffset\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> machine_word\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"machine_word \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"machine_word \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr pptr \\<equiv> pptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition irqVGICMaintenance :: irq where\n  \"irqVGICMaintenance \\<equiv> 25\"\n\ndefinition irqVTimerEvent :: irq where\n  \"irqVTimerEvent \\<equiv> 27\"\n\ndefinition pageColourBits :: nat where\n  \"pageColourBits \\<equiv> undefined\" \\<comment> \\<open>not implemented on this platform\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Entry Point: Processes events, handles potential preemption interrupts, schedules threads, and activates the next thread. This ensures that the kernel efficiently manages events and thread execution while maintaining system responsiveness and integrity.",
    "input": "",
    "output": "text \\<open>\n  This function is the main kernel entry point. The main event loop of the\n  kernel handles events, handles a potential preemption interrupt, schedules\n  and switches back to the active thread.\n\\<close>\n\ndefinition\n  call_kernel :: \"event \\<Rightarrow> (unit,'z::state_ext_sched) s_monad\" where\n  \"call_kernel ev \\<equiv> do\n       handle_event ev <handle>\n           (\\<lambda>_. without_preemption $ do\n                  irq \\<leftarrow> do_machine_op (getActiveIRQ True);\n                  when (irq \\<noteq> None) $ handle_interrupt (the irq)\n                od);\n       schedule;\n       activate_thread\n   od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Initialization: Clear and initialize memory to be used as user memory, ensuring it is properly prepared for subsequent operations.",
    "input": "",
    "output": "abbreviation (input) \"initMemory == clearMemory\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific State: The `arch_state` record maintains architecture-specific data for the AARCH64 system, including ASID tables, kernel virtual space, VMID tables, the next VMID, a global user-space virtual space, the current VCPU (with an active flag), and the number of GICvCPU list registers. This ensures that the system can manage and track the state of virtual memory, virtual CPUs, and interrupt handling effectively.",
    "input": "",
    "output": "record arch_state =\n  arm_asid_table :: \"asid_high_index \\<rightharpoonup> obj_ref\"\n  arm_kernel_vspace :: \"AARCH64_A.arm_vspace_region_uses\"\n  arm_vmid_table :: \"AARCH64_A.vmid \\<rightharpoonup> asid\"\n  arm_next_vmid :: AARCH64_A.vmid\n  arm_us_global_vspace :: \"obj_ref\"\n  arm_current_vcpu    :: \"(obj_ref \\<times> bool) option\"\n  arm_gicvcpu_numlistregs :: nat\n\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Register Initialization: Defines the initial state for the FPU and user context, setting all registers to a default value of 0. This ensures that the system starts in a known and consistent state.",
    "input": "",
    "output": "chapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition newFPUState :: \"fpu_state\" where\n  \"newFPUState \\<equiv> FPUState (K 0) 0 0 \"\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext newFPUState ((K 0) aLU initContext)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reserve Memory Region: Reserve a specified number of bytes in memory, potentially tagging the region as kernel data. The function currently acts as a placeholder and does not perform any actual reservation or tagging.",
    "input": "",
    "output": "definition\n  reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Qualified Aliases: Define and qualify constants for different page sizes and TCB-related values, ensuring consistent and appropriately scoped naming within the architecture context.",
    "input": "",
    "output": "context begin interpretation Arch . global_naming vmpage_size\nrequalify_consts RISCVSmallPage RISCVLargePage RISCVHugePage\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 9\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Memory Levels: The architecture defines four levels of virtual memory, with the highest level containing ASID pools and the lower levels containing page tables. The top level is designated for ASID pools, followed by three levels of page tables, where the bottom level (level 0) contains only InvalidPTEs or PagePTEs.",
    "input": "",
    "output": "type_synonym vm_level = 4\n\ndefinition asid_pool_level :: vm_level\n  where\n  \"asid_pool_level = maxBound\"\n\ndefinition max_pt_level :: vm_level\n  where\n  \"max_pt_level = asid_pool_level - 1\"\n\nend\n\nqualify RISCV64_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode and Validate Intent: Decode the given intent into an appropriate invocation based on the type of capability. For endpoint-like capabilities, perform a specific operation regardless of the user's intent. For other capabilities, validate that the user's intent matches the capability type before proceeding with the corresponding invocation. If the intent does not match or the capability type is unsupported, the operation is aborted.",
    "input": "",
    "output": "definition\n  decode_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_intent \\<Rightarrow> cdl_invocation except_monad\"\nwhere\n  \"decode_invocation invoked_cap invoked_cap_ref caps intent \\<equiv>\n    case invoked_cap of\n       \\<comment> \\<open>For endpoint-like caps, we always perform an operation,\n          regardless of the user's actual intent.\\<close>\n         EndpointCap o_id badge rights \\<Rightarrow>\n           (if Write \\<in> rights then\n             returnOk $ InvokeEndpoint (SyncMessage badge (Grant \\<in> rights) (GrantReply \\<in> rights) o_id)\n           else\n             throw)\n       | NotificationCap o_id badge rights \\<Rightarrow>\n           (if Write \\<in> rights then\n             returnOk $ InvokeNotification (Signal badge o_id)\n           else\n             throw)\n       | ReplyCap o_id rights \\<Rightarrow>\n           returnOk $ InvokeReply (ReplyMessage o_id invoked_cap_ref (Grant \\<in> rights))\n\n       \\<comment> \\<open>\n         For other operations, we only perform the user's intent\n         if it matches up with the cap.\n        \n         Note that this does not currently match the current\n         implementation: instead, the user's message will be\n         decoded into a new (undefined) intent for what the\n         cap happened to be. I propose modifying labels used to\n         avoid overlaps between different items so that we can\n         recognise when the user is invoking the wrong item.\n       \\<close>\n       | CNodeCap _ _ _ _ \\<Rightarrow>\n           doE\n             cnode_intent \\<leftarrow> throw_opt undefined $ get_cnode_intent intent;\n             liftME InvokeCNode $ decode_cnode_invocation invoked_cap invoked_cap_ref caps cnode_intent\n           odE\n       | TcbCap _ \\<Rightarrow>\n           doE\n             tcb_intent \\<leftarrow> throw_opt undefined $ get_tcb_intent intent;\n             liftME InvokeTcb $ decode_tcb_invocation invoked_cap invoked_cap_ref caps tcb_intent\n           odE\n       | IrqControlCap \\<Rightarrow>\n           doE\n             irq_control_intent \\<leftarrow> throw_opt undefined $ get_irq_control_intent intent;\n             liftME InvokeIrqControl $ decode_irq_control_invocation\n                 invoked_cap invoked_cap_ref caps irq_control_intent\n           odE\n       | IrqHandlerCap _ \\<Rightarrow>\n           doE\n             irq_handler_intent \\<leftarrow> throw_opt undefined $ get_irq_handler_intent intent;\n             liftME InvokeIrqHandler $ decode_irq_handler_invocation\n                 invoked_cap invoked_cap_ref caps irq_handler_intent\n           odE\n       | AsidPoolCap _ _\\<Rightarrow>\n           doE\n             asid_pool_intent \\<leftarrow> throw_opt undefined $ get_asid_pool_intent intent;\n             liftME InvokeAsidPool $ decode_asid_pool_invocation\n                 invoked_cap invoked_cap_ref caps asid_pool_intent\n           odE\n       | AsidControlCap \\<Rightarrow>\n           doE\n             asid_control_intent \\<leftarrow> throw_opt undefined $ get_asid_control_intent intent;\n             liftME InvokeAsidControl $ decode_asid_control_invocation\n                 invoked_cap invoked_cap_ref caps asid_control_intent\n           odE\n       | UntypedCap _ _ _ \\<Rightarrow>\n           doE\n             untyped_intent \\<leftarrow> throw_opt undefined $ get_untyped_intent intent;\n             liftME InvokeUntyped $ decode_untyped_invocation\n                 invoked_cap invoked_cap_ref caps untyped_intent\n           odE\n       | FrameCap _ _ _ _ _ _ \\<Rightarrow>\n           doE\n             page_intent \\<leftarrow> throw_opt undefined $ get_page_intent intent;\n             liftME InvokePage $ decode_page_invocation\n                 invoked_cap invoked_cap_ref caps page_intent\n           odE\n       | PageTableCap _ _ _ \\<Rightarrow>\n           doE\n             page_table_intent \\<leftarrow> throw_opt undefined $ get_page_table_intent intent;\n             liftME InvokePageTable $ decode_page_table_invocation\n                 invoked_cap invoked_cap_ref caps page_table_intent\n           odE\n       | PageDirectoryCap _ _ _ \\<Rightarrow>\n          doE\n             page_directory_intent \\<leftarrow> throw_opt undefined $ get_page_directory_intent intent;\n             liftME InvokePageDirectory $ decode_page_directory_invocation\n                 invoked_cap invoked_cap_ref caps page_directory_intent\n           odE\n       | DomainCap \\<Rightarrow>\n          doE\n            domain_intent \\<leftarrow> throw_opt undefined $ get_domain_intent intent;\n            liftME InvokeDomain $ decode_domain_invocation caps domain_intent\n          odE\n\n       \\<comment> \\<open>Don't support operations on other types of caps.\\<close>\n       | _ \\<Rightarrow> throw\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Index Sizes: Define the size of virtual space index and page table index types, ensuring that the virtual space index length is less than a symbolic value (vs_index_bits) and the page table index length is fixed at 9 bits. This allows for flexible and precise management of memory addressing and page table structures.",
    "input": "",
    "output": "typedef vs_index_len = \"{n :: nat. n < vs_index_bits}\" by auto\n\nend\n\ninstantiation AARCH64.vs_index_len :: len0\nbegin\n  interpretation Arch .\n  definition len_of_vs_index_len: \"len_of (x::vs_index_len itself) \\<equiv> CARD(vs_index_len)\"\n  instance ..\nend\n\ninstantiation AARCH64.vs_index_len :: len\nbegin\n  interpretation Arch .\n  instance\n  proof\n   show \"0 < LENGTH(vs_index_len)\"\n     by (simp add: len_of_vs_index_len type_definition.card[OF type_definition_vs_index_len])\n  qed\nend\n\ncontext Arch begin global_naming AARCH64\n\ntype_synonym vs_index = \"vs_index_len word\"\n\ntype_synonym pt_index_len = 9\ntype_synonym pt_index = \"pt_index_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure No Children: Verify that the given capability does not have any children in the CDT. If it does, an exception is thrown.",
    "input": "",
    "output": "definition\n  ensure_no_children :: \"cdl_cap_ref \\<Rightarrow> unit except_monad\"\nwhere\n  \"ensure_no_children x \\<equiv> doE\n     c \\<leftarrow> liftE $ gets (has_children x);\n     whenE c $ throw\n   odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64 Global Page Tables: The architecture-specific state includes generalized global page tables, with constraints that limit the set of tables at the maximum page table level to a singleton and ensure that the ASID pool level contains no tables. Other levels may have multiple or no tables, depending on kernel initialization.",
    "input": "",
    "output": "end_qualify\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Deletion: When deleting a Page Map Level 4 (PML4) from an ASID pool, the corresponding ASID is deactivated by invalidating the hardware ASID, updating the ASID pool to remove the PML4, and setting the virtual memory root for the current thread. This ensures that the ASID is properly deactivated and the system's memory management is maintained.",
    "input": "",
    "output": "definition\ndelete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pml4 \\<equiv> do\n  asid_table \\<leftarrow> gets (x64_asid_table \\<circ> arch_state);\n  case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (asid_low_bits_of asid) = Some pml4) $ do\n                hw_asid_invalidate asid pml4;\n                pool' \\<leftarrow> return (pool (asid_low_bits_of asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od\nod\"\n\ndefinition\n  flush_all :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_all vspace asid \\<equiv> do_machine_op $ invalidateASID vspace (ucast asid)\"\n\nabbreviation\n  flush_pdpt :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_pdpt \\<equiv> flush_all\"\n\nabbreviation\n  flush_pd :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_pd \\<equiv> flush_all\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Default Capability Construction: Generate a default capability for a new object based on its type, a set of available object IDs, size in bits, and a device flag. The generated capability is tailored to the specific object type, ensuring it is correctly configured with the appropriate permissions and attributes.",
    "input": "",
    "output": "definition\n  default_cap :: \"cdl_object_type \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_size_bits \\<Rightarrow> bool \\<Rightarrow> cdl_cap\"\nwhere\n  \"default_cap t id_set sz dev \\<equiv>\n    case t of\n        EndpointType \\<Rightarrow> EndpointCap (pick id_set) 0 UNIV\n      | NotificationType \\<Rightarrow> NotificationCap (THE i. i \\<in> id_set) 0 {Read,Write}\n      | TcbType \\<Rightarrow> TcbCap (pick id_set)\n      | CNodeType \\<Rightarrow> CNodeCap (pick id_set) 0 0 sz\n      | IRQNodeType \\<Rightarrow> IrqHandlerCap undefined\n      | UntypedType \\<Rightarrow> UntypedCap dev id_set id_set\n      | AsidPoolType \\<Rightarrow> AsidPoolCap (pick id_set) 0\n      | PageTableType \\<Rightarrow> PageTableCap (pick id_set) Real None\n      | PageDirectoryType \\<Rightarrow> PageDirectoryCap (pick id_set) Real None\n      | FrameType frame_size \\<Rightarrow> FrameCap dev (pick id_set) {Read, Write} frame_size Real None\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Remove Operation Effects on Capabilities: The removal of a capability through the `removeOperation` function affects the direct and overall capabilities associated with an entity. Specifically, the direct capabilities of the target entity are updated by removing the specified capability, while the overall set of capabilities remains a subset of the original, ensuring that no new capabilities are introduced and existing ones are appropriately adjusted.",
    "input": "",
    "output": "lemma direct_caps_of_remove:\n  \"c \\<in> direct_caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x \\<Longrightarrow>\n  c \\<in> direct_caps_of s x\"\n  by (clarsimp simp: removeOperation_simpler direct_caps_of_def\n              split: option.splits if_split_asm)\n\nlemma direct_caps_of_remove_eq:\n  \"direct_caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x =\n  ( if   is_entity s (target c\\<^sub>1) \\<and> x = target c\\<^sub>1\n   then  direct_caps_of s (target c\\<^sub>1) - {c\\<^sub>2}\n   else  direct_caps_of s x )\"\n  by(simp add: direct_caps_of_def is_entity_def removeOperation_def)\n\nlemma store_connected_remove [rule_format]:\n  \"(x, y) \\<in> store_connected (s(e \\<mapsto> Entity C')) \\<Longrightarrow>\n  s e = Some (Entity C) \\<longrightarrow> C' \\<subseteq> C \\<longrightarrow> (x, y) \\<in> store_connected s\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply clarsimp\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (erule rtrancl_trans)\n   apply fastforce\n  apply (fold store_connected_def)\n  apply (clarsimp simp add: store_connected_direct_def)\n  apply (fastforce simp: direct_caps_of_def\n                  split: option.splits if_split_asm)\n  done\n\nlemma caps_of_remove:\n  \"c \\<in> caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x \\<Longrightarrow>\n  c \\<in> caps_of s x\"\n  apply (clarsimp simp: caps_of_def)\n  apply (rule_tac x=xa in exI)\n  apply (drule direct_caps_of_remove)\n  apply (simp add: removeOperation_simpler\n            split: option.splits)\n  apply (erule (1) store_connected_remove)\n  apply blast\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Direct and Indirect Capabilities: The lemmas define the direct and indirect capabilities associated with different states (s0, s1, s2, etc.) and their respective indices. Each state has a specific set of capabilities, which may include full, create, and write/store rights, and these capabilities are combined or extended in subsequent states.",
    "input": "",
    "output": "lemma direct_caps_of_s0_e0_caps [simp]:\n  \"direct_caps_of s0 0 = e0_caps\"\n  by (simp add: direct_caps_of_def s0_def e0_caps_def)\n\nlemma direct_caps_of_s1_e0_caps [simp]:\n  \"direct_caps_of s1 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s1_def e0_caps_def)\n\nlemma direct_caps_of_s2_e0_caps [simp]:\n  \"direct_caps_of s2 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s2_def e0_caps_def)\n\nlemma direct_caps_of_s4_e0_caps [simp]:\n  \"direct_caps_of s4 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s4_def e0_caps_def)\n\nlemma direct_caps_of_s5_e0_caps [simp]:\n  \"direct_caps_of s5 0 = e0_caps \\<union> {full_cap 1, write_cap 2}\"\n  by (simp add: direct_caps_of_def s5_def e0_caps_def)\n\nlemma direct_caps_of_s6_e0_caps [simp]:\n  \"direct_caps_of s6 0 = e0_caps \\<union> {full_cap 1, write_cap 2}\"\n  by (simp add: direct_caps_of_def s6_def e0_caps_def)\n\nlemma direct_caps_of_s8_e0_caps [simp]:\n  \"direct_caps_of s8 0 = e0_caps \\<union> {full_cap 1, full_cap 3}\"\n  by (simp add: direct_caps_of_def s8_def e0_caps_def)\n\nlemma direct_caps_of_s9_e0_caps [simp]:\n  \"direct_caps_of s9 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s9_def e0_caps_def)\n\n\nlemma direct_caps_of_s2_e1 [simp]:\n  \"direct_caps_of s2 1 = {create_cap 2}\"\n  by (simp add: direct_caps_of_def s2_def)\n\nlemma direct_caps_of_s3_e1 [simp]:\n  \"direct_caps_of s3 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>}\"\n  by (simp add: direct_caps_of_def s3_def)\n\nlemma direct_caps_of_s4_e1 [simp]:\n  \"direct_caps_of s4 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s4_def)\n\nlemma direct_caps_of_s6_e1 [simp]:\n  \"direct_caps_of s5 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s5_def)\n\nlemma direct_caps_of_s9_e1 [simp]:\n  \"direct_caps_of s9 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s9_def)\n\n\nlemma full_cap_e0_caps_in_caps_of_s0_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s0 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e1_in_caps_of_s1_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s1 0\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e1_in_caps_of_s2_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s2 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e0_caps_in_caps_of_s4_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e1_in_caps_of_s4_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e2_in_caps_of_s4_e1 [simp]:\n  \"full_cap 2 \\<in> caps_of s4 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e1_in_caps_of_s5_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s5 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e2_in_caps_of_s5_e0_caps [simp]:\n  \"full_cap 2 \\<in> caps_of s5 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e0_caps_in_caps_of_s8_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s8 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s0_e0_caps [simp]:\n  \"create_cap i \\<in> caps_of s0 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s1_e0_caps [simp]:\n  \"create_cap i \\<in> caps_of s1 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s2_e1 [simp]:\n  \"create_cap 2 \\<in> caps_of s2 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma create_cap_in_caps_of_s3_e1 [simp]:\n  \"create_cap 2 \\<in> caps_of s3 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma create_cap_in_caps_of_s4_e3 [simp]:\n  \"create_cap 3 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s9_e3 [simp]:\n  \"create_cap 3 \\<in> caps_of s9 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma write_store_e1_in_caps_of_s3_e1 [simp]:\n  \"\\<lparr>target = 1, rights = {Write, Store}\\<rparr>  \\<in> caps_of s3 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma write_store_e1_in_caps_of_s5_e1 [simp]:\n  \"\\<lparr>target = 1, rights = {Write, Store}\\<rparr> \\<in> caps_of s5 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma write_cap_e2_in_caps_of_s6_e0_caps [simp]:\n  \"write_cap 2 \\<in> caps_of s6 0\"\n  by (rule direct_cap_in_cap, simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Revoking and Deleting IRQ Handler Capabilities: Upon deletion of an IRQ handler capability, the system retrieves the slot associated with the specified IRQ and deletes the capability from that slot.",
    "input": "",
    "output": "definition\n  deleting_irq_handler :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"deleting_irq_handler irq \\<equiv> do\n    slot \\<leftarrow> get_irq_slot irq;\n    cap_delete_one slot\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Space Lookup Slot: Returns a pointer to a slot in the virtual space table at the specified level. If the level is the ASID pool level, it returns a pointer to the ASID pool itself, otherwise, it returns a pointer to the specific slot within the table.",
    "input": "",
    "output": "definition vs_lookup_slot :: \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"vs_lookup_slot bot_level asid vref \\<equiv> do {\n     (level', table) \\<leftarrow> vs_lookup_table bot_level asid vref;\n     if level' = asid_pool_level then\n       oreturn (level', table)\n     else\n       oreturn (level', pt_slot_offset level' table vref)\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Requalification of Constants: Re-allow fully qualified accesses to constants related to page sizes (X64SmallPage, X64LargePage, X64HugePage) for consistency, ensuring that these constants can be referenced with their full qualification.",
    "input": "",
    "output": "context Arch begin\nglobal_naming \"X64.vmpage_size\" requalify_consts X64SmallPage X64LargePage X64HugePage\nglobal_naming \"X64\" requalify_consts X64SmallPage X64LargePage X64HugePage\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "PageTable Capabilities: Allow the mapping and unmapping of page tables. This includes setting and storing page directory entries, cleaning the cache by virtual address, unmaping page tables, invalidating page table entries, and updating the capability's mapping data.",
    "input": "",
    "output": "definition\nperform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_table_invocation iv \\<equiv>\ncase iv of PageTableMap cap ct_slot pde pd_slot \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pde pd_slot pde;\n    do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot)\n  od\n  | PageTableUnmap (ArchObjectCap (PageTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_page_table asid vaddr p;\n      slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 << pt_bits) - 1];\n      mapM_x (swp store_pte InvalidPTE) slots;\n      do_machine_op $ cleanCacheRange_PoU p (p + (1 << pt_bits) - 1)\n                                          (addrFromPPtr p)\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure No Children: Verify that a capability stored in a slot does not have any children. If the capability is a parent, an error is thrown to prevent further operations.",
    "input": "",
    "output": "definition\n  ensure_no_children :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"ensure_no_children cslot_ptr \\<equiv> doE\n    cdt \\<leftarrow> liftE $ gets cdt;\n    whenE (\\<exists>c. cdt c = Some cslot_ptr) (throwError RevokeFirst)\n  odE\"\n\ndefinition\n  max_free_index :: \"nat \\<Rightarrow> nat\" where\n  \"max_free_index magnitude_bits \\<equiv> 2 ^ magnitude_bits\"\n\ndefinition\n  free_index_update :: \"(nat \\<Rightarrow> nat) \\<Rightarrow> cap \\<Rightarrow> cap\"\nwhere\n  \"free_index_update g cap \\<equiv>\n   case cap of UntypedCap dev ref sz f \\<Rightarrow> UntypedCap dev ref sz (g f) | _ \\<Rightarrow> cap\"\n\nprimrec (nonexhaustive)\n  untyped_sz_bits :: \"cap \\<Rightarrow> nat\"\nwhere\n  \"untyped_sz_bits (UntypedCap dev ref sz f) = sz\"\n\nabbreviation\n  max_free_index_update :: \"cap \\<Rightarrow> cap\"\nwhere\n  \"max_free_index_update cap \\<equiv> cap \\<lparr> free_index:= max_free_index (untyped_sz_bits cap) \\<rparr>\"\n\ndefinition\n  set_untyped_cap_as_full :: \"cap \\<Rightarrow> cap \\<Rightarrow> obj_ref \\<times> bool list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_untyped_cap_as_full src_cap new_cap src_slot \\<equiv>\n   if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n       \\<and> obj_ref_of src_cap = obj_ref_of new_cap \\<and> cap_bits_untyped src_cap = cap_bits_untyped new_cap)\n       then set_cap (max_free_index_update src_cap) src_slot else return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Modify TCB Intent Error: Update the TCB's intent to indicate whether an error occurred during decode. This ensures that the TCB's state accurately reflects the outcome of the decoding process.",
    "input": "",
    "output": "definition\n  mark_tcb_intent_error :: \"cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"mark_tcb_intent_error target_tcb has_error \\<equiv>\n      update_thread target_tcb (\\<lambda>t. (t\\<lparr>cdl_tcb_intent := (cdl_tcb_intent t)\\<lparr>cdl_intent_error := has_error\\<rparr>\\<rparr>))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Management: Provides mechanisms to access and update the underlying memory, device state, and interrupt masks, ensuring that the machine state is correctly maintained and modified.",
    "input": "",
    "output": "theory MachineMonad\nimports MachineTypes\nbegin\n\narch_requalify_types\n  machine_state\n  machine_state_rest\n\narch_requalify_consts\n  underlying_memory\n  underlying_memory_update\n  device_state\n  device_state_update\n  irq_masks\n  machine_state_rest\n  machine_state_rest_update",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Operation Wrapper: Lifts monadic operations on the underlying machine state to monadic operations on the kernel state, ensuring that the machine state is updated and the result is returned within the kernel state context.",
    "input": "",
    "output": "text \\<open>This wrapper lifts monadic operations on the underlying machine state to\nmonadic operations on the kernel state.\\<close>\ndefinition\n  do_machine_op :: \"(machine_state, 'a) nondet_monad \\<Rightarrow> ('z state, 'a) nondet_monad\"\nwhere\n \"do_machine_op mop \\<equiv> do\n    ms \\<leftarrow> gets machine_state;\n    (r, ms') \\<leftarrow> select_f (mop ms);\n    modify (\\<lambda>state. state \\<lparr> machine_state := ms' \\<rparr>);\n    return r\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Strengthen C Guards: Modify the guards in the term by rewriting them to include additional conditions. The rewrite rules ensure that the guards are strengthened with `h_t_valid` or `ptr_safe` and `c_guard` conditions, depending on the specified set of symbols.",
    "input": "",
    "output": "val xTs = xs ~~ (fastype_of h |> strip_type |> fst);\n        fun upd_arg (x, T) = if T = comT then (inner x, []) else f x;\n        val (ys, gss) = map_split upd_arg xTs;\n      in add_guards (list_comb (h, ys)) (flat gss) end\n  in inner (Envir.beta_eta_contract t) end\n  | _ => t;\n\n\\<close>\n\nsetup \\<open>DefineGlobalsList.define_globals_list_i\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\" @{typ globals}\\<close>\n\n\nlocale substitute_pre\n  = fixes symbol_table :: \"string \\<Rightarrow> addr\"\n      and domain :: \"addr set\"\n\nbegin\n\nabbreviation\n \"globals_list \\<equiv> kernel_all_global_addresses.global_data_list\"\n\nend\n\nlocale kernel_all_substitute = substitute_pre\nbegin\n\nML \\<open>\nfun mk_rew (t as Abs (s, T, _)) = mk_rew (betapply (t, Var ((s, 0), T)))\n  | mk_rew t = HOLogic.dest_eq t\n\nval mk_varifyT = Term.map_types Logic.varifyT_global\n\nlocal\nval c_guard_rew =\n  @{term \"\\<lambda>p b. Guard C_Guard {s. c_guard (p s)} b\n     = Guard C_Guard {s. h_t_valid (hrs_htd (t_hrs_' (globals s))) c_guard (p s)} b\"}\n  |> mk_varifyT |> mk_rew\n\nval c_guard_rew_weak =\n  @{term \"\\<lambda>p b. Guard C_Guard {s. c_guard (p s)} b\n         = Guard C_Guard {s. ptr_safe (p s) (hrs_htd (t_hrs_' (globals s)))\n            \\<and> c_guard (p s)} b\"}\n      |> mk_varifyT |> mk_rew\n\nin\nfun strengthen_c_guards ss thy s =\n  if (exists (curry (=) s) ss)\n  then Pattern.rewrite_term thy [c_guard_rew_weak] []\n  else Pattern.rewrite_term thy [c_guard_rew] []\nend;\n\\<close>\n\nlemmas global_data_defs\n    = kernel_all_global_addresses.global_data_defs\n\nlemmas globals_list_def\n    = kernel_all_global_addresses.global_data_list_def\n\nML \\<open>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Requalification: The requalification of types is architecture-specific, allowing for the handling of unique architectural features such as vCPU. This ensures that the system can adapt to the specific requirements and capabilities of different architectures.",
    "input": "",
    "output": "arch_requalify_types (H)\n  vcpu\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Basic Monads for capDL: Defines the fundamental monadic structures used in the capDL system, providing a foundation for handling non-determinism and verification conditions within the system.",
    "input": "",
    "output": "(*\n * The basic monads used in capDL\n *)\n\ntheory Monads_D\nimports\n  Types_D\n  Monads.Nondet_In_Monad\n  Monads.Nondet_VCG\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Initialization and Management: Initialize and manage the virtual space, including creating and activating the global virtual space, initializing the IRQ controller, creating and managing frames for IPC buffers, device frames, and other regions, and handling VM faults. This ensures that the virtual memory is properly set up and maintained for efficient and secure operation.",
    "input": "",
    "output": "(*\n    VSpace lookup code.\n*)\n\ntheory VSpace_H\nimports\n  CNode_H\n  ArchVSpace_H\n  KernelInitMonad_H\nbegin\n\narch_requalify_consts (H)\n  mapKernelWindow\n  activateGlobalVSpace\n  initIRQController\n  createIPCBufferFrame\n  createBIFrame\n  createFramesOfRegion\n  createITPDPTs\n  writeITPDPTs\n  createITASIDPool\n  writeITASIDPool\n  createDeviceFrames\n  handleVMFault\n  isValidVTableRoot\n  checkValidIPCBuffer\n  lookupIPCBuffer\n  vptrFromPPtr\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace.lhs Arch= ONLY initKernelVM initPlatform initCPU\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Stub for ARM: Provides the necessary declarations and implementations for hypervisor functionality specific to the ARM architecture, ensuring that the hypervisor can manage and interact with ARM-specific hardware features.",
    "input": "",
    "output": "(*\n  Hypervisor stub for ARM\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_H bodies_only ArchInv= ArchLabels=\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IRQ Node Pointer: The IRQ node pointer is initialized to a memory address that is sufficiently aligned for the IRQ type and CTE level bits, ensuring proper alignment and access.",
    "input": "",
    "output": "definition init_irq_node_ptr :: obj_ref\n  where\n  \"init_irq_node_ptr = pptr_base + 0x3000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Type Access Functions: Provide various functions to extract and determine specific properties of capability objects, such as badge, pointer, bits, free index, and type-specific attributes. These functions enable efficient and accurate manipulation and inspection of capabilities, ensuring the integrity and security of the system.",
    "input": "",
    "output": "definition\n  the_cnode_cap :: \"cap \\<Rightarrow> obj_ref \\<times> nat \\<times> bool list\" where\n  \"the_cnode_cap cap \\<equiv>\n  case cap of\n    CNodeCap oref bits guard \\<Rightarrow> (oref, bits, guard)\"\n\nprimrec (nonexhaustive)\n  cap_ep_badge :: \"cap \\<Rightarrow> badge\"\nwhere\n  \"cap_ep_badge (EndpointCap _ badge _) = badge\"\n| \"cap_ep_badge (NotificationCap _ badge _) = badge\"\n\nprimrec (nonexhaustive)\n  cap_ep_ptr :: \"cap \\<Rightarrow> badge\"\nwhere\n  \"cap_ep_ptr (EndpointCap obj_ref _ _) = obj_ref\"\n| \"cap_ep_ptr (NotificationCap obj_ref _ _) = obj_ref\"\n\ndefinition\n  bits_of :: \"cap \\<Rightarrow> nat\" where\n  \"bits_of cap \\<equiv> case cap of\n    UntypedCap _ _ bits _ \\<Rightarrow> bits\n  | CNodeCap _ radix_bits _ \\<Rightarrow> radix_bits\"\n\ndefinition\n  free_index_of :: \"cap \\<Rightarrow> nat\" where\n  \"free_index_of cap \\<equiv> case cap of\n    UntypedCap _ _ _ free_index \\<Rightarrow> free_index\"\n\ndefinition\n  is_reply_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_reply_cap cap \\<equiv> case cap of ReplyCap _ m _ \\<Rightarrow> \\<not> m | _ \\<Rightarrow> False\"\ndefinition\n  is_master_reply_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_master_reply_cap cap \\<equiv> case cap of ReplyCap _ m _ \\<Rightarrow> m | _ \\<Rightarrow> False\"\ndefinition\n  is_zombie :: \"cap \\<Rightarrow> bool\" where\n  \"is_zombie cap \\<equiv> case cap of Zombie _ _ _ \\<Rightarrow> True | _ \\<Rightarrow> False\"\ndefinition\n  is_arch_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_arch_cap cap \\<equiv> case cap of ArchObjectCap _ \\<Rightarrow> True | _ \\<Rightarrow> False\"\n\ncontext\nnotes [[function_internals =true]]\nbegin\n\nfun is_cnode_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_cnode_cap (CNodeCap _ _ _) = True\"\n| \"is_cnode_cap _                = False\"\n\nfun is_thread_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_thread_cap (ThreadCap _) = True\"\n| \"is_thread_cap _             = False\"\n\nfun is_domain_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_domain_cap DomainCap = True\"\n| \"is_domain_cap _ = False\"\n\nfun is_untyped_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_untyped_cap (UntypedCap _ _ _ _) = True\"\n| \"is_untyped_cap _                  = False\"\n\nfun is_ep_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_ep_cap (EndpointCap _ _ _) = True\"\n| \"is_ep_cap _                   = False\"\n\nfun is_ntfn_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_ntfn_cap (NotificationCap _ _ _) = True\"\n| \"is_ntfn_cap _                        = False\"\n\nprimrec (nonexhaustive)\n  cap_rights :: \"cap \\<Rightarrow> cap_rights\"\nwhere\n  \"cap_rights (EndpointCap _ _ cr) = cr\"\n| \"cap_rights (NotificationCap _ _ cr) = cr\"\n| \"cap_rights (ReplyCap _ _ cr) = cr\"\n| \"cap_rights (ArchObjectCap acap) = acap_rights acap\"\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Double Fault: Set the thread state to inactive if a fault message cannot be sent, ensuring that the thread remains in an inactive state to prevent further execution.",
    "input": "",
    "output": "definition\n  handle_double_fault :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_double_fault tptr ex1 ex2 \\<equiv> set_thread_state tptr Inactive\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Badge Bits Definition: The badge word is defined to have 28 bits.",
    "input": "",
    "output": "definition\n  badge_bits :: nat where\n  badge_bits_def [simp]: \"badge_bits \\<equiv> 28\"\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Revoke Capability: Revokes a capability at a specified index and depth within a CNode, ensuring that the targeted capability is removed and no longer accessible.",
    "input": "",
    "output": "|  CNodeRevokeIntent word32 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Initializes the kernel by creating essential components, including an idle thread and root capability node. The idle thread is created and configured, while the root capability node is set up with a specified size and its slot position is updated. This ensures that the kernel has the necessary structures in place for proper operation.",
    "input": "",
    "output": "consts \n  sync_bootinfo_frame :: \"paddr \\<Rightarrow> (unit,'z::state_ext) ki_monad\"\n\ndefinition \n      returnOk pptr\n   odE\"\n\ndefinition\n  create_idle_thread :: \"(unit,'z::state_ext) ki_monad\" where\n  \"create_idle_thread \\<equiv> doE\n     pptr \\<leftarrow> create_objects (obj_bits $ TCB undefined)\n                           (obj_bits $ TCB undefined) TCBObject;\n     do_kernel_op $ do\n       modify (\\<lambda>s. s \\<lparr> idle_thread := pptr \\<rparr>);\n       configure_idle_thread pptr\n     od\n   odE\"\n\ndefinition\n  create_root_cnode :: \"(cap,'z::state_ext) ki_monad\" where\n  \"create_root_cnode \\<equiv>\n   let sz = (ROOT_CNODE_SIZE_BITS + CTE_SIZE_BITS) in\n   doE\n     liftE $ modify\n               (\\<lambda>s. s \\<lparr> ndks_boot_slot_pos_max := 2 ^ ROOT_CNODE_SIZE_BITS \\<rparr>);\n\n     pptr \\<leftarrow> create_objects sz sz CapTableObject;\n\n     let cap = CNodeCap pptr ROOT_CNODE_SIZE_BITS\n                             (replicate (32 - ROOT_CNODE_SIZE_BITS) False)\n     in (doE\n           do_kernel_op $ write_slot (cap_slot_pptr cap BI_CAP_IT_CNODE) cap;\n           returnOk cap\n         odE)\n   odE\"\n\ndefinition\n  create_irq_cnode :: \"(unit,'z::state_ext) ki_monad\" where\n  \"create_irq_cnode \\<equiv> doE",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Operations: Provides functions to manage capabilities within CNodes, including revoking a capability at a specified location. This ensures that the system can dynamically modify and control the capabilities stored in CNodes, maintaining the integrity and security of the capability space.",
    "input": "",
    "output": "chapter \"CNodes\"\n\ntheory CNode_H\nimports\n  FaultMonad_H\n  ThreadDecls_H\n  RetypeDecls_H\n  TCBDecls_H\n  CSpaceDecls_H\n  EndpointDecls_H\n  PSpaceFuns_H\nbegin\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs decls_only NOT cteRevoke\n\nfunction\n  cteRevoke :: \"machine_word \\<Rightarrow> unit kernel_p\"\nwhere\n \"cteRevoke p s =\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteRevoke\n\n  p s\"\nby auto\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs bodies_only NOT finaliseSlot cteRevoke cteDeleteOne noReplyCapsFor\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page Table: Unmaps a specified page table from a given memory address. If the page table is found, it is removed; otherwise, no action is taken.",
    "input": "",
    "output": "definition\n  unmap_page_table  :: \"cdl_mapped_addr \\<Rightarrow> cdl_object_id  \\<Rightarrow> unit k_monad\"\nwhere\n  \"unmap_page_table maddr pt_id\\<equiv>\n    do\n      pt_slot \\<leftarrow> cdl_page_table_mapped maddr pt_id;\n      case pt_slot of (Some slot) \\<Rightarrow> delete_cap_simple slot\n      | None \\<Rightarrow> return ()\n    od\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate and Validate Page Directory: Find the page directory for a given ASID, ensuring that the operation is successful and returns a valid pointer to an existing page directory.",
    "input": "",
    "output": "definition\nfind_vspace_for_asid_assert :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) s_monad\" where\n\"find_vspace_for_asid_assert asid \\<equiv> do\n   pml4 \\<leftarrow> find_vspace_for_asid asid <catch> K fail;\n   get_pml4 pml4;\n   return pml4\n od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Qualified Aliases: Define and qualify constants for specific architecture page sizes and TCB-related values, ensuring consistent and accessible naming within the system.",
    "input": "",
    "output": "context begin interpretation Arch . global_naming vmpage_size\n\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 8\"\n\ndefinition\n  ctcb_offset :: \"32 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Monadic Combinators for Nondeterministic Computations: Provide functions to sequence, map, and fold over lists in a nondeterministic monad, allowing for the execution of multiple monadic actions and accumulation of results. These combinators enable the construction of complex monadic operations from simpler ones, supporting both successful and error-handling scenarios.",
    "input": "",
    "output": "definition sequence :: \"('s, 'a) nondet_monad list \\<Rightarrow> ('s, 'a list) nondet_monad\" where\n  \"sequence xs \\<equiv> let mcons = (\\<lambda>p q. p >>= (\\<lambda>x. q >>= (\\<lambda>y. return (x#y))))\n                 in foldr mcons xs (return [])\"\n\ndefinition mapM :: \"('a \\<Rightarrow> ('s,'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s, 'b list) nondet_monad\" where\n  \"mapM f xs \\<equiv> sequence (map f xs)\"\n\ndefinition zipWithM ::\n  \"('a \\<Rightarrow> 'b \\<Rightarrow> ('s,'c) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> 'b list \\<Rightarrow> ('s, 'c list) nondet_monad\"\n  where\n  \"zipWithM f xs ys \\<equiv> sequence (zipWith f xs ys)\"\n\ndefinition foldM ::\n  \"('b \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad) \\<Rightarrow> 'b list \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad\"\n  where\n  \"foldM m xs a \\<equiv> foldr (\\<lambda>p q. q >>= m p) xs (return a) \"\n\ndefinition foldME ::\n  \"('b \\<Rightarrow> 'a \\<Rightarrow> ('s,('e + 'b)) nondet_monad) \\<Rightarrow> 'b \\<Rightarrow> 'a list \\<Rightarrow> ('s, ('e + 'b)) nondet_monad\"\n  where\n  \"foldME m a xs \\<equiv> foldr (\\<lambda>p q. q >>=E swp m p) xs (returnOk a)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Declarations: Define the declarations and operations for handling interrupts in the RISCV64 architecture, including the necessary context and global naming conventions.",
    "input": "",
    "output": "theory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/RISCV64.hs CONTEXT RISCV64_H decls_only ArchInv= Arch=MachineOps NOT plic_complete_claim\n\nend (* context RISCV64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup IPC Buffer Authority: Verify that a thread has the necessary authority to read from or write to its IPC buffer. The function checks the buffer's capabilities and ensures that the thread's access rights are appropriate for the operation, either reading or writing, based on whether the thread is a receiver or not.",
    "input": "",
    "output": "definition lookup_ipc_buffer :: \"bool \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n  \"lookup_ipc_buffer is_receiver thread \\<equiv> do\n     buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n     buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n     buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n     case buffer_cap of\n       ArchObjectCap (FrameCap p R vms False _) \\<Rightarrow>\n         if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n         then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n         else return None\n     | _ \\<Rightarrow> return None\n   od\"\n\ndefinition pool_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\" where\n  \"pool_for_asid asid \\<equiv> \\<lambda>s. asid_table s (asid_high_bits_of asid)\"\n\ndefinition entry_for_pool :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (obj_ref \\<rightharpoonup> asid_pool) \\<Rightarrow> asid_pool_entry option\"\n  where\n  \"entry_for_pool pool_ptr asid \\<equiv> do {\n     pool \\<leftarrow> oapply pool_ptr;\n     K $ pool (asid_low_bits_of asid)\n   }\"\n\ndefinition vspace_for_pool :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (obj_ref \\<rightharpoonup> asid_pool) \\<Rightarrow> obj_ref option\" where\n  \"vspace_for_pool pool_ptr asid \\<equiv> do {\n     entry \\<leftarrow> entry_for_pool pool_ptr asid;\n     oreturn $ ap_vspace entry\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Signal Notification: A signal is associated with a badge (notification word) and a notification object, allowing for the delivery of notifications to specific objects with designated badges.",
    "input": "",
    "output": "Signal cdl_badge cdl_object_id\n\ndatatype cdl_reply_invocation =\n    ReplyMessage cdl_object_id cdl_cap_ref bool (* can grant *)\n\ndatatype cdl_page_table_invocation =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Parent Swapping: Exchanges the parent-child relationships between two capability references, ensuring that the children of each reference are reassigned to the other parent. This operation maintains the integrity of the capability tree by updating the parent-child relationships accordingly.",
    "input": "",
    "output": "definition\n  swap_parents :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\" where\n  \"swap_parents p p' = modify (cdl_cdt_update\n     (\\<lambda>cd. Fun.swap p p'\n          (\\<lambda>x. if cd x = Some p then Some p' else\n              if cd x = Some p' then Some p else cd x)))\"\n\ndefinition\n  is_cdt_parent :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\" where\n  \"is_cdt_parent s p c \\<equiv> cdl_cdt s c = Some p\"\n\ndefinition\n  cdt_parent_rel :: \"cdl_state \\<Rightarrow> (cdl_cap_ref \\<times> cdl_cap_ref) set\" where\n  \"cdt_parent_rel \\<equiv> \\<lambda>s. {(p,c). is_cdt_parent s p c}\"\n\nabbreviation\n  parent_of :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> p cdt_parent_of c \\<equiv> (p,c) \\<in> cdt_parent_rel s\"\n\nabbreviation\n  parent_of_trancl :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>+ _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x cdt_parent_of\\<^sup>+ y \\<equiv> (x, y) \\<in> (cdt_parent_rel s)\\<^sup>+\"\n\nabbreviation\n  parent_of_rtrancl :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>* _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x cdt_parent_of\\<^sup>* y \\<equiv> (x, y) \\<in> (cdt_parent_rel s)\\<^sup>*\"\n\n\\<comment> \\<open>descendants of a slot\\<close>\ndefinition\n  descendants_of :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\" where\n  \"descendants_of p s \\<equiv> {q. (p,q) \\<in> (cdt_parent_rel s)\\<^sup>+}\"\n\n\n\ndefinition\n  tcb_ipcframe_id :: \"cdl_tcb \\<Rightarrow> cdl_object_id option\"\nwhere\n  \"tcb_ipcframe_id tcb \\<equiv> case (cdl_tcb_caps tcb tcb_ipcbuffer_slot) of\n                              Some (FrameCap _ oid _ _ _ _) \\<Rightarrow> Some oid\n                              | _                       \\<Rightarrow> None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Mapping Entries: Generate the necessary page table entries (PTEs) or page directory entries (PDEs) to map a given frame size at a specified virtual address, ensuring the correct attributes and rights are applied. The function handles different frame sizes, including small pages, large pages, sections, and super sections, and calculates the appropriate offsets for large and super section mappings.",
    "input": "",
    "output": "definition largePagePTE_offsets :: \"obj_ref list\"\n  where\n  \"largePagePTE_offsets \\<equiv>\n    let pts = of_nat 2\n    in [0, 2 ^ pts  .e.  (15 << 2)]\"\n\ndefinition superSectionPDE_offsets :: \"obj_ref list\"\n  where\n  \"superSectionPDE_offsets \\<equiv>\n    let pts = of_nat 2\n    in [0, 2 ^ pts  .e.  (15 << 2)]\"\n\nfun create_mapping_entries ::\n  \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vm_rights \\<Rightarrow> vm_attributes \\<Rightarrow> word32 \\<Rightarrow>\n  ((pte * word32 list) + (pde * word32 list),'z::state_ext) se_monad\"\nwhere\n  \"create_mapping_entries base vptr ARMSmallPage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (SmallPagePTE base (attrib - {Global, ParityEnabled})\n                                 vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMLargePage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (LargePagePTE base (attrib - {Global, ParityEnabled})\n                                 vm_rights, map (\\<lambda>x. x + p) largePagePTE_offsets)\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SectionPDE base (attrib - {Global}) 0 vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSuperSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SuperSectionPDE base (attrib - {Global}) vm_rights, map (\\<lambda>x. x + p) superSectionPDE_offsets)\n  odE\"\n\ndefinition get_master_pde :: \"word32 \\<Rightarrow> (pde,'z::state_ext)s_monad\"\n  where \"get_master_pde ptr \\<equiv> do\n    pde \\<leftarrow> (get_pde (ptr && ~~ mask 6));\n    (case pde of SuperSectionPDE _ _ _ \\<Rightarrow> return pde\n    | _ \\<Rightarrow> get_pde ptr)\n  od\"\n\ndefinition get_master_pte :: \"word32 \\<Rightarrow> (pte, 'z::state_ext)s_monad\"\n  where \"get_master_pte ptr \\<equiv> do\n    pte \\<leftarrow> (get_pte (ptr && ~~ mask 6));\n    (case pte of LargePagePTE _ _ _ \\<Rightarrow> return pte\n    | _ \\<Rightarrow> get_pte ptr)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Page Directory Index: The initial index into the page directory is calculated by shifting the kernel base address right by the number of bits corresponding to the ARM section size, ensuring that the index is divisible by 16.",
    "input": "",
    "output": "idx \\<leftarrow> return $ kernel_base >> pageBitsForSize ARMSection;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Advance Index and Physical Address: Update the index and physical address by adding the product of the number of iterations and their respective increments, ensuring they match the exit condition of the C loop.",
    "input": "",
    "output": "idx \\<leftarrow> return $ idx + iterations * 16; (* should be 2^PD_BITS - 16 *)\n     phys \\<leftarrow> return $ phys + iterations * (2^pageBitsForSize(ARMSuperSection));",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IRQ Controller: Provides the ARM/ARM_HYP machine operation for initializing the IRQ controller, ensuring that the system can handle interrupts effectively.",
    "input": "",
    "output": "abbreviation (input) initIRQController where\n  \"initIRQController \\<equiv> ARM.initIRQController\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Conversions: Define conversions between different data types, including identity functions for object and virtual space references, conversion from natural numbers to length types, and bitwise operations for combining notification badges and messages. Additionally, it includes conversions from data to various word sizes and capability pointers.",
    "input": "",
    "output": "definition\n  oref_to_data   :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_oref   :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition\n  vref_to_data   :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_vref   :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition\n  nat_to_len     :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition\n  data_to_nat    :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition\n  data_to_16     :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition\n  data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition\n  combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition\n  combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Abstract State Extension: Provides a framework for extending the state with deterministic and nondeterministic behaviors. It includes operations to unwrap and wrap the extended state, handle monadic operations, and select switch conditions, enabling flexible and modular state management.",
    "input": "",
    "output": "class state_ext =\n fixes unwrap_ext :: \"'a state \\<Rightarrow> det_ext state\"\n fixes wrap_ext :: \"(det_ext \\<Rightarrow> det_ext) \\<Rightarrow> ('a \\<Rightarrow> 'a)\"\n fixes wrap_ext_op :: \"unit det_ext_monad \\<Rightarrow> ('a state,unit) nondet_monad\"\n fixes wrap_ext_bool :: \"bool det_ext_monad \\<Rightarrow> ('a state,bool) nondet_monad\"\n fixes select_switch :: \"'a \\<Rightarrow> bool\"\n fixes ext_init :: \"'a\"\n\ndefinition detype_ext :: \"obj_ref set \\<Rightarrow> 'z::state_ext \\<Rightarrow> 'z\" where\n \"detype_ext S \\<equiv> wrap_ext (\\<lambda>s. s\\<lparr>ekheap_internal := (\\<lambda>x. if x \\<in> S then None else ekheap_internal s x)\\<rparr>)\"\n\ninstantiation  det_ext_ext :: (type) state_ext\nbegin\n\ndefinition \"unwrap_ext_det_ext_ext == (\\<lambda>x. x) :: det_ext state \\<Rightarrow> det_ext state\"\n\ndefinition \"wrap_ext_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext \\<Rightarrow> det_ext) \\<Rightarrow> det_ext \\<Rightarrow> det_ext\"\n\ndefinition \"wrap_ext_op_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext state \\<Rightarrow> ((unit \\<times> det_ext state) set) \\<times> bool)\n  \\<Rightarrow> det_ext state  \\<Rightarrow> ((unit \\<times> det_ext state) set) \\<times> bool\"\n\ndefinition \"wrap_ext_bool_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext state \\<Rightarrow> ((bool \\<times> det_ext state) set) \\<times> bool)\n  \\<Rightarrow> det_ext state \\<Rightarrow> ((bool \\<times> det_ext state) set) \\<times> bool\"\n\ndefinition \"select_switch_det_ext_ext == (\\<lambda>_. True)  :: det_ext\\<Rightarrow> bool\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value Properties: The maximum IRQ value (`maxIRQ`) is constrained and related to the bit length of the IRQ, ensuring that any word less than or equal to `maxIRQ` has a natural number representation less than \\(2^{LENGTH(irq\\_len)}\\). Additionally, the `maxIRQ` value can be cast and manipulated between different word types (signed, unsigned, and machine words) while preserving its value and properties.",
    "input": "",
    "output": "lemma le_maxIRQ_machine_less_irqBits_val[simplified]:\n  \"w \\<le> maxIRQ \\<Longrightarrow> unat w < 2^LENGTH(irq_len)\" for w::machine_word\n  using maxIRQ_less_2p_irq_len\n  by (simp add: word_le_nat_alt)\n\nlemma irq_machine_le_maxIRQ_irq:\n  \"irq \\<le> Kernel_Config.maxIRQ \\<Longrightarrow> (ucast irq::irq) \\<le> maxIRQ\" for irq::machine_word\n  by (simp add: Kernel_Config.maxIRQ_def word_le_nat_alt unat_ucast)\n\nlemma maxIRQ_eq_ucast_irq_32_signed_uint:\n  \"(maxIRQ = (ucast b :: 32 signed word)) = (uint b = maxIRQ)\" for b::irq\n  unfolding Kernel_Config.maxIRQ_def\n  apply uint_arith\n  apply (simp add: uint_up_ucast is_up)\n  done\n\nlemma sint_maxIRQ_32[simp]:\n  \"sint (maxIRQ :: 32 signed word) = maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_machine[simp]:\n  \"scast (maxIRQ::32 signed word) = (maxIRQ::machine_word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_irq[simp]:\n  \"scast (maxIRQ :: 32 signed word) = (maxIRQ::irq)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_machine:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = x\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_irq:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = (ucast x :: irq)\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_1_plus_eq_Suc_machine[simp]:\n  \"unat (1 + Kernel_Config.maxIRQ :: machine_word) = Suc Kernel_Config.maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create and Update Capabilities: Create new capabilities for objects, set their default properties, and update the available range for untyped capabilities. This ensures that new objects are properly initialized and integrated into the system, while maintaining the integrity of the available object ranges.",
    "input": "",
    "output": "definition\n  create_cap :: \"cdl_object_type \\<Rightarrow> nat \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool \\<Rightarrow> (cdl_cap_ref \\<times> cdl_object_id set) \\<Rightarrow> unit k_monad\"\nwhere\n  \"create_cap new_type sz parent_slot dev \\<equiv> \\<lambda>(dest_slot, obj_refs).\n  do\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_cap dest_slot (default_cap new_type obj_refs sz dev);\n    set_parent dest_slot parent_slot\n  od\"\n\n\ndefinition\n  update_available_range :: \"(cdl_object_id set) => (cdl_object_id list) \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere \"update_available_range orange newids cap_ref cap \\<equiv>\n  do\n     new_range  \\<leftarrow> select {x. x \\<subseteq> orange - set newids};\n     set_cap cap_ref $ set_available_range cap new_range\n  od\"\n\n\ndefinition\n  retype_region :: \"nat \\<Rightarrow> cdl_object_type \\<Rightarrow> (cdl_object_id set list)\n  \\<Rightarrow> ((cdl_object_id set) list) k_monad\"\nwhere\n  \"retype_region target_bits target_type target_object_ids \\<equiv>\n    do\n      \\<comment> \\<open>Get a list of target locations. We are happy with any unused name\n         within the target range.\\<close>\n\n      if (target_type \\<noteq> UntypedType) then\n       do\n         current_domain \\<leftarrow> gets cdl_current_domain;\n         create_objects target_object_ids (default_object target_type target_bits current_domain)\n       od\n      else return ();\n\n      \\<comment> \\<open>Get a list of target locations. We are happy with any unused name\n         within the target range.\\<close>\n      return target_object_ids\n    od\"\n\nprimrec (nonexhaustive)\n  untyped_is_device :: \"cdl_cap \\<Rightarrow> bool\"\nwhere\n    \"untyped_is_device (UntypedCap d _ _) = d\"\n\ndefinition\n  reset_untyped_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"reset_untyped_cap cref \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap cref;\n    whenE (available_range cap \\<noteq> cap_objects cap) $ doE\n      liftE $ modify (detype (cap_objects cap));\n      new_rans \\<leftarrow> liftE $ select {xs. (\\<forall>S \\<in> set xs.\n              S \\<subseteq> cap_objects cap \\<and> available_range cap \\<subset> S)\n          \\<and> xs \\<noteq> [] \\<and> List.last xs = cap_objects cap};\n      mapME_x (\\<lambda>r. doE\n        liftE $ set_cap cref $ set_available_range cap r;\n        returnOk () \\<sqinter> throw\n      odE) new_rans\n    odE\n  odE\"\n\ndefinition\n  invoke_untyped :: \"cdl_untyped_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_untyped params \\<equiv> case params of\n     Retype untyped_ref new_type type_size target_slots has_kids num_objects \\<Rightarrow>\n   doE\n     unlessE has_kids $ reset_untyped_cap untyped_ref;\n       liftE $ do\n         untyped_cap \\<leftarrow> get_cap untyped_ref;\n\n         new_range \\<leftarrow> return $ available_range untyped_cap;\n         new_obj_refs \\<leftarrow> generate_object_ids num_objects new_type new_range;\n\n         update_available_range new_range (map (\\<lambda>s. pick s) new_obj_refs) untyped_ref untyped_cap;\n\n         \\<comment> \\<open>Construct new objects within the covered range.\\<close>\n         retype_region type_size new_type new_obj_refs;\n\n         \\<comment> \\<open>Construct caps for the new objects.\\<close>\n         mapM_x (create_cap new_type type_size untyped_ref (untyped_is_device untyped_cap)) (zip target_slots new_obj_refs);\n\n         \\<comment> \\<open>Ideally, we should return back to the user how many\n            objects were created.\\<close>\n\n         return ()\n       od\n    odE\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific State: The ARM model maintains a set of architecture-specific state components, including the first level of the ASID table, a mapping from hardware ASIDs to seL4 ASIDs, the next hardware ASID to be preempted, an inverse map from seL4 ASIDs to hardware ASIDs, and the address and description of the page directory and page tables for the shared address space. These components ensure that the ARM architecture's memory management and virtualization are correctly managed and synchronized.",
    "input": "",
    "output": "text \\<open>The architecture-specific state for the ARM model\nconsists of the first level of the ASID table (@{text \"arm_asid_table\"}), a\nmap from hardware ASIDs to seL4 ASIDs (@{text \"arm_hwasid_table\"}),\nthe next hardware ASID to preempt (@{text \"arm_next_asid\"}), the\ninverse map from seL4 ASIDs to hardware ASIDs (first component of\n@{text \"arm_asid_map\"}), and the address of the page directory and\npage tables mapping the shared address space, along with a description\nof this space (@{text \"arm_global_pd\"}, @{text \"arm_global_pts\"}, and\n@{text \"arm_kernel_vspace\"} respectively).\n\nHardware ASIDs are only ever associated with seL4 ASIDs that have a\ncurrently active page directory. The second component of\n@{text \"arm_asid_map\"} values is the address of that page directory.\n\\<close>\n\nend\n\nqualify ARM_HYP_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Acknowledge VCPU VPPI: The system acknowledges a VPPI (Virtual Platform Performance Interrupt) event for a VCPU by unmasking the corresponding VPPI in the VCPU's state, allowing the VCPU to handle the interrupt.",
    "input": "",
    "output": "definition decode_vcpu_ack_vppi ::\n  \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_ack_vppi mrs cap \\<equiv>\n     case (mrs, cap)\n       of (mr0 # _, VCPUCap vcpu_ptr) \\<Rightarrow> doE\n           arch_check_irq mr0;\n           (case irq_vppi_event_index (ucast mr0)\n            of None \\<Rightarrow> throwError $ InvalidArgument 0\n             | Some vppi \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUAckVPPI vcpu_ptr vppi)\n         odE\n       | _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_ack_vppi :: \"obj_ref \\<Rightarrow> vppievent_irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"invoke_vcpu_ack_vppi vcpu_ptr vppi =\n     vcpu_update vcpu_ptr\n                 (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := False) \\<rparr>)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Handling: Defines the architecture-specific interrupt handling mechanisms for AARCH64, including declarations and configurations for interrupt objects and hypervisor interactions.",
    "input": "",
    "output": "theory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv= Arch= NOT plic_complete_claim\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Endpoint Communication States: An endpoint can be in one of three states: idle, waiting to send, or waiting to receive. When both sending and receiving threads are present, messages are transferred immediately.",
    "input": "",
    "output": "text \\<open>Endpoints are synchronous points of communication for threads. At any\ntime an endpoint may contain a queue of threads waiting to send, a queue of\nthreads waiting to receive or be idle. Whenever threads would be waiting to\nsend and receive simultaneously messages are transferred immediately.\n\\<close>\n\ndatatype endpoint\n           = IdleEP\n           | SendEP \"obj_ref list\"\n           | RecvEP \"obj_ref list\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lifting with Exception Handling: Lifts a function to handle exceptions, where if the input is an exception, it returns that exception; otherwise, it continues with the function execution.",
    "input": "",
    "output": "definition lift :: \"('a \\<Rightarrow> ('s, 'e + 'b) nondet_monad) \\<Rightarrow> 'e +'a \\<Rightarrow> ('s, 'e + 'b) nondet_monad\" where\n  \"lift f v \\<equiv> case v of Inl e \\<Rightarrow> throwError e | Inr v' \\<Rightarrow> f v'\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM-Specific TCB: Defines architecture-specific data types and configurations for the Thread Control Block (TCB) in an ARM hypervisor environment, ensuring that the TCB is tailored to the specific requirements and capabilities of ARM architecture.",
    "input": "",
    "output": "qualify ARM_HYP_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create New Memory Objects: Generate new memory objects (pages or tables) and their corresponding capabilities based on the specified type, region base, number of objects, and device status. The function initializes the mappings, updates the user pages, and performs cache cleaning as necessary.",
    "input": "",
    "output": "chapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewPageCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        when (\\<not>dev) $\n          mapM_x (\\<lambda>addr. doMachineOp $\n                            cleanCacheRange_RAM addr\n                                                (addr + mask (pageBitsForSize pSize))\n                                                (addrFromPPtr addr)) addrs;\n        return $ map (\\<lambda>n. PageCap dev (PPtr (fromPPtr n)) VMReadWrite pSize Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      mapM_x (\\<lambda>addr. doMachineOp $\n                       cleanCacheRange_PoU addr (addr + mask tableBits) (addrFromPPtr addr)) addrs;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 0 ARMSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 4 ARMLargePage\n        | SectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 8 ARMSection\n        | SuperSectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 12 ARMSuperSection\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        | PageDirectoryObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdBits (makeObject::pde) PageDirectoryCap\n              (\\<lambda>pds. do objSize \\<leftarrow> return (((1::nat) `~shiftL~` pdBits));\n                        mapM_x copyGlobalMappings pds\n                     od)\n        )\"\n\nend\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware Abstraction: Provides a set of hardware-specific operations and constants for the RISCV64 architecture, including memory management, interrupt handling, timer configuration, and virtual memory operations. These functions and values enable the operating system to interact with the underlying hardware effectively, ensuring proper resource management and system stability.",
    "input": "",
    "output": "theory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs Platform=Platform.RISCV64 CONTEXT RISCV64_H NOT plic_complete_claim getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory setHardwareASID wordFromPDE wordFromPTE VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize toPAddr addrFromPPtr ptrFromPAddr sfence physBase paddrBase pptrBase pptrBaseOffset pptrTop pptrUserTop kernelELFBase kernelELFBaseOffset kernelELFPAddrBase addrFromKPPtr ptTranslationBits vmFaultTypeFSR read_stval setVSpaceRoot hwASIDFlush setIRQTrigger\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64_H instanceproofs NOT plic_complete_claim HardwareASID VMFaultType VMPageSize VMPageEntry HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64_H ONLY wordFromPTE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lift Function into Monad: Elevates a pure function into the nondeterministic monad, allowing it to operate on values within the monadic context.",
    "input": "",
    "output": "text \\<open>Lifting a normal function into the monad type:\\<close>\ndefinition liftM :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> ('s,'a) nondet_monad \\<Rightarrow> ('s, 'b) nondet_monad\" where\n  \"liftM f m \\<equiv> do x \\<leftarrow> m; return (f x) od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Guarded Memory and State Updates: Ensures that memory and state updates, such as those involving the heap and global variables, are performed safely by applying guards and assertions. This includes verifying the safety of heap table descriptor (HTD) updates, handling pointer arithmetic, and ensuring that certain operations do not reach a halt state.",
    "input": "",
    "output": "val global_datas = @{thms global_data_defs}\n  |> map (Thm.concl_of #> Logic.unvarify_global\n        #> Logic.dest_equals #> snd #> Envir.beta_eta_contract)\n\nval const_globals = map_filter\n    (fn (Const (@{const_name const_global_data}, _) $ nm $ t)\n        => SOME (HOLogic.dest_string nm, t)\n        | _ => NONE) global_datas\n\nlocal\n\nval hrs_htd_update_guard_rew1 =\n    @{term \"\\<lambda>u. Basic (\\<lambda>s. globals_update (t_hrs_'_update (hrs_htd_update (u s))) s)\n         = Guard C_Guard {s. globals_list_distinct (fst ` dom_s (u s (hrs_htd (t_hrs_' (globals s)))))\n                         symbol_table globals_list}\n           (Basic (\\<lambda>s. globals_update (t_hrs_'_update (id hrs_htd_update (u s))) s))\"}\n        |> mk_rew\n\nval hrs_htd_update_guard_rew2 =\n  @{term \"t_hrs_'_update (id hrs_htd_update f) = t_hrs_'_update (hrs_htd_update f)\"}\n  |> Logic.varify_global |> HOLogic.dest_eq;\n\nval consts = map snd const_globals\n\nval index_eq_set_helper\n  = Syntax.parse_term @{context} (String.concat\n    [\"\\<lambda>str t n c. {s :: globals myvars. c \\<longrightarrow>\",\n        \"h_val (hrs_mem (t_hrs_' (globals s)))\",\n        \" (CTypesDefs.ptr_add (Ptr (symbol_table str)) (of_nat (n s)))\",\n        \" = t s}\"])\n\nval eq_set_helper\n  = Syntax.parse_term @{context} (String.concat\n    [\"\\<lambda>str t c. {s :: globals myvars. c \\<longrightarrow>\",\n        \"h_val (hrs_mem (t_hrs_' (globals s)))\",\n        \" (Ptr (symbol_table str)) = t}\"])\n\nval s = @{term \"s :: globals myvars\"}\n\nval grab_name_str = head_of #> dest_Const #> fst #> Long_Name.base_name\n    #> HOLogic.mk_string\n\nin\n\nfun const_global_asserts ctxt cond\n  (t as (Const (@{const_name index}, _) $ arr $ n)) = if member (=) consts arr\n    then [(index_eq_set_helper $ grab_name_str arr\n        $ lambda s t $ lambda s n $ cond) |> Syntax.check_term ctxt]\n    else []\n  | const_global_asserts ctxt cond (Const c) = if member (=) consts (Const c)\n    then [(eq_set_helper $ grab_name_str (Const c) $ Const c $ cond)\n        |> Syntax.check_term ctxt]\n    else []\n  | const_global_asserts ctxt cond (f $ x) = if member (=) consts (f $ x)\n    then [(eq_set_helper $ grab_name_str (f $ x) $ (f $ x) $ cond)\n        |> Syntax.check_term ctxt]\n    else const_global_asserts ctxt cond f @ const_global_asserts ctxt cond x\n  | const_global_asserts ctxt cond (a as Abs (_, @{typ \"globals myvars\"}, _))\n    = const_global_asserts ctxt cond (betapply (a, s))\n  | const_global_asserts ctxt cond (Abs (_, _, t))\n    = const_global_asserts ctxt cond t\n  | const_global_asserts _ _ _ = []\n\nfun guard_rewritable_globals const_cond ctxt =\n  Pattern.rewrite_term @{theory} [hrs_htd_update_guard_rew2] []\n  o Pattern.rewrite_term @{theory} [hrs_htd_update_guard_rew1] []\n  o com_rewrite (fn t =>\n     (t, map (pair @{term C_Guard})\n        (case const_cond of SOME cond => const_global_asserts ctxt cond t\n                | NONE => [])))\n\nval guard_htd_updates_with_domain = com_rewrite\n  (fn t => if fastype_of t = @{typ \"globals myvars \\<Rightarrow> globals myvars\"}\n        andalso Term.exists_Const (fn (s, _) => s = @{const_name \"hrs_htd_update\"}) t\n        then (t, [(@{term MemorySafety}, betapply (@{term \"\\<lambda>f :: globals myvars \\<Rightarrow> globals myvars.\n                {s. htd_safe domain (hrs_htd (t_hrs_' (globals s)))\n              \\<and> htd_safe domain (hrs_htd (t_hrs_' (globals (f s))))}\"}, t))])\n        else (t, []))\n\nval guard_halt = com_rewrite\n  (fn t => if t = @{term \"halt_'proc\"}\n    then (t, [(@{term DontReach}, @{term \"{} :: globals myvars set\"})])\n    else (t, []))\n\nfun acc_ptr_adds (Const (@{const_name h_val}, _) $ m $ (Const (@{const_name ptr_add}, _) $ p $ n))\n    = [(p, n, true)] @ maps acc_ptr_adds [m, p, n]\n  | acc_ptr_adds (Const (@{const_name heap_update}, _) $ (Const (@{const_name ptr_add}, _) $ p $ n))\n    = [(p, n, true)] @ maps acc_ptr_adds [p, n]\n  | acc_ptr_adds (Const (@{const_name ptr_add}, _) $ p $ n)\n    = [(p, n, false)] @ maps acc_ptr_adds [p, n]\n  | acc_ptr_adds (f $ x) = maps acc_ptr_adds [f, x]\n  | acc_ptr_adds (abs as Abs (_, T, t)) = if T = @{typ \"globals myvars\"}\n    then acc_ptr_adds (betapply (abs, @{term \"s :: globals myvars\"}))\n    else acc_ptr_adds t\n  | acc_ptr_adds _ = []\n\nfun mk_bool true = @{term True} | mk_bool false = @{term False}\n\nval guard_acc_ptr_adds = com_rewrite\n  (fn t => (t, acc_ptr_adds t |> map (fn (p, n, strong) => let\n    val assn = Const (@{const_name ptr_add_assertion'},\n            fastype_of p --> @{typ \"int \\<Rightarrow> bool \\<Rightarrow> heap_typ_desc \\<Rightarrow> bool\"})\n        $ p $ n $ mk_bool strong\n        $ @{term \"hrs_htd (t_hrs_' (globals (s :: globals myvars)))\"}\n    val gd = HOLogic.mk_Collect (\"s\", @{typ \"globals myvars\"}, assn)\n  in (@{term MemorySafety}, gd) end)))\n\nend\n\n\\<close>\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\nML \\<open>\n  Feedback.verbosity_level := ~1;\n\\<close>\n\nlocal_setup \\<open>\nSubstituteSpecs.take_all_actions\n  \"Kernel_C.kernel_all_global_addresses.\"\n  (Locale.init \"Kernel_C.kernel_all_global_addresses\" @{theory})\n  (fn ctxt => fn s => guard_rewritable_globals NONE ctxt\n    o (strengthen_c_guards [\"memset_body\", \"memcpy_body\", \"memzero_body\"]\n          (Proof_Context.theory_of ctxt) s)\n    o guard_halt\n    o guard_htd_updates_with_domain\n    o guard_acc_ptr_adds)\n  @{term kernel_all_global_addresses.\\<Gamma>}\n  (CalculateState.get_csenv @{theory} \"../c/build/$L4V_ARCH/kernel_all.c_pp\" |> the)\n  [@{typ \"globals myvars\"}, @{typ int}, @{typ strictc_errortype}]\n\\<close>\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Lookup: Recursively searches the page table hierarchy starting from a specified level, using the provided virtual address to find the slot that points to the target page table pointer. Ensures that the search is valid by checking the level and verifying that each PTE encountered is a valid page table entry.",
    "input": "",
    "output": "fun pt_lookup_from_level ::\n  \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (machine_word \\<times> vm_level, 'z::state_ext) lf_monad\"\n  where\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr s = (doE\n     unlessE (0 < level) $ throwError InvalidRoot;\n     slot <- returnOk $ pt_slot_offset level pt_ptr vptr;\n     pte <- liftE $ gets_the $ oapply slot o swp ptes_of level;\n     unlessE (is_PageTablePTE pte) $ throwError InvalidRoot;\n     ptr <- returnOk (pptr_from_pte pte);\n     if ptr = target_pt_ptr\n       then returnOk (slot, level)\n       else pt_lookup_from_level (level - 1) ptr vptr target_pt_ptr\n   odE) s\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Page Directory Bit Sizes: Define the bit sizes for page directories (PD_BITS), page tables (PT_BITS), page directory entries (PDE_SIZE_BITS), and page table entries (PTE_SIZE_BITS).",
    "input": "",
    "output": "definition \"PD_BITS \\<equiv> 12 :: nat\"\ndefinition \"PT_BITS \\<equiv> 8 :: nat\"\n\ndefinition \"PDE_SIZE_BITS \\<equiv> 2 :: nat\"\ndefinition \"PTE_SIZE_BITS \\<equiv> 2 :: nat\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Message Information: Obtain the message information from the specified thread's message info register and convert it to a structured message information format.",
    "input": "",
    "output": "definition\n  get_message_info :: \"obj_ref \\<Rightarrow> (message_info,'z::state_ext) s_monad\"\nwhere\n  \"get_message_info thread \\<equiv> do\n     x \\<leftarrow> as_user thread $ getRegister msg_info_register;\n     return $ data_to_message_info x\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Interrupt Handler Intent: Clears the intent associated with an interrupt handler, ensuring that any pending or specified actions are removed or reset.",
    "input": "",
    "output": "|  IrqHandlerClearIntent\n\ndatatype cdl_arch_irq_control_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Type Classification: Categorizes different types of capabilities, such as Untyped, Endpoint, Notification, TCB, CNode, ASID Pool, Page Table, Page Directory, Frame, and IRQ Node, based on their specific attributes. Each capability type is uniquely identified, and the type remains unchanged under certain updates like badge, rights, mapping status, and guard. Additionally, it identifies pending capabilities, which include PendingSyncRecv, PendingNtfnRecv, and PendingSyncSend.",
    "input": "",
    "output": "definition cap_type :: \"cdl_cap \\<Rightarrow> cdl_object_type option\"\nwhere\n  \"cap_type x \\<equiv> case x of\n    UntypedCap _ _ _         \\<Rightarrow> Some UntypedType\n  | EndpointCap _ _ _      \\<Rightarrow> Some EndpointType\n  | NotificationCap _ _ _ \\<Rightarrow> Some NotificationType\n  | TcbCap _               \\<Rightarrow> Some TcbType\n  | CNodeCap _ _ _ _       \\<Rightarrow> Some CNodeType\n  | AsidPoolCap _ _        \\<Rightarrow> Some AsidPoolType\n  | PageTableCap _ _ _     \\<Rightarrow> Some PageTableType\n  | PageDirectoryCap _ _ _ \\<Rightarrow> Some PageDirectoryType\n  | FrameCap _ _ _ f _ _     \\<Rightarrow> Some (FrameType f)\n  | IrqHandlerCap _        \\<Rightarrow> Some IRQNodeType\n  | _                      \\<Rightarrow> None \"\n\nabbreviation \"is_untyped_cap cap    \\<equiv> (cap_type cap = Some UntypedType)\"\nabbreviation \"is_ep_cap cap         \\<equiv> (cap_type cap = Some EndpointType)\"\nabbreviation \"is_ntfn_cap cap        \\<equiv> (cap_type cap = Some NotificationType)\"\nabbreviation \"is_tcb_cap cap        \\<equiv> (cap_type cap = Some TcbType)\"\nabbreviation \"is_cnode_cap cap      \\<equiv> (cap_type cap = Some CNodeType)\"\nabbreviation \"is_asidpool_cap cap   \\<equiv> (cap_type cap = Some AsidPoolType)\"\nabbreviation \"is_pt_cap cap         \\<equiv> (cap_type cap = Some PageTableType)\"\nabbreviation \"is_pd_cap cap         \\<equiv> (cap_type cap = Some PageDirectoryType)\"\nabbreviation \"is_frame_cap cap      \\<equiv> (\\<exists>sz. cap_type cap = Some (FrameType sz))\"\nabbreviation \"is_irqhandler_cap cap \\<equiv> (cap_type cap = Some IRQNodeType)\"\ndefinition   \"is_irqcontrol_cap cap \\<equiv> (cap = IrqControlCap)\"\n\nlemma cap_type_simps [simp]:\n  \"is_untyped_cap    (UntypedCap dev a a')\"\n  \"is_ep_cap         (EndpointCap b c d)\"\n  \"is_ntfn_cap        (NotificationCap e f g)\"\n  \"is_tcb_cap        (TcbCap h)\"\n  \"is_cnode_cap      (CNodeCap j k l m)\"\n  \"is_asidpool_cap   (AsidPoolCap n p)\"\n  \"is_pd_cap         (PageDirectoryCap r s t)\"\n  \"is_pt_cap         (PageTableCap u v w)\"\n  \"is_frame_cap      (FrameCap dev a1 a2 a3 a4 a5)\"\n  \"is_irqhandler_cap (IrqHandlerCap a6)\"\n  \"cap_type (FrameCap dev obj_id rights sz rs asid) = Some (FrameType sz)\"\n  by (clarsimp simp: cap_type_def)+\n\nabbreviation \"cap_has_type cap \\<equiv> (\\<exists>type. cap_type cap = Some type)\"\n\nlemma cap_type_update_cap_badge [simp]:\n  \"cap_type (update_cap_badge x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_badge_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_cap_rights [simp]:\n  \"cap_type (update_cap_rights x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_rights_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_mapping_cap_status [simp]:\n  \"cap_type (update_mapping_cap_status x cap) = cap_type cap\"\n  by (clarsimp simp: update_mapping_cap_status_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_cap_guard [simp]:\n  \"cap_type (update_cap_guard x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_guard_def cap_type_def split: cdl_cap.splits)\n\nlemma update_cap_guard_size [simp]:\n  \"cap_type (update_cap_guard_size x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_guard_size_def cap_type_def split: cdl_cap.splits)\n\n\n\ndefinition is_pending_cap :: \"cdl_cap \\<Rightarrow> bool\"\nwhere \"is_pending_cap c \\<equiv> case c of\n  PendingSyncRecvCap _ _ _ \\<Rightarrow> True\n  | PendingNtfnRecvCap _ \\<Rightarrow> True\n  | PendingSyncSendCap _ _ _ _ _ _ \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Valid CDT List: Ensures that for each pointer, the list of capabilities associated with it in the CDT list is exactly the set of capabilities that map to that pointer in the CDT, and all such lists are distinct.",
    "input": "",
    "output": "definition valid_list_2 :: \"cdt_list \\<Rightarrow> cdt \\<Rightarrow> bool\" where\n  \"valid_list_2 t m \\<equiv> (\\<forall>p. set (t p) = {c. m c = Some p}) \\<and> (\\<forall>p. distinct (t p))\"\n\nabbreviation valid_list :: \"det_ext state \\<Rightarrow> bool\" where\n  \"valid_list s \\<equiv> valid_list_2 (cdt_list s) (cdt s)\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VMID Retrieval and Assignment: Retrieve the VMID associated with an ASID, and if no VMID is assigned, allocate a new one and associate it with the ASID.",
    "input": "",
    "output": "definition get_vmid :: \"asid \\<Rightarrow> (vmid, 'z::state_ext) s_monad\" where\n  \"get_vmid asid \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     case maybe_vmid of\n       Some vmid \\<Rightarrow> return vmid\n     | None \\<Rightarrow>  do\n         new_hw_asid \\<leftarrow> find_free_vmid;\n         store_vmid asid new_hw_asid;\n         return new_hw_asid\n       od\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Acknowledge Interrupt: The operation acknowledges an interrupt but performs no actual action on the imx31 platform.",
    "input": "",
    "output": "definition\n  ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ackInterrupt \\<equiv> \\<lambda>irq. return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Preemptible Execution: Ensures that operations within preemptible blocks are executed without preemption, maintaining the atomicity and integrity of critical sections.",
    "input": "",
    "output": "definition\n  without_preemption :: \"('a,'z::state_ext) s_monad \\<Rightarrow> ('a,'z::state_ext) p_monad\"\nwhere without_preemption_def[simp]:\n \"without_preemption \\<equiv> liftE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Thread Fault: Modify the fault status of a thread by updating the `cdl_tcb_has_fault` field in the thread control block. This ensures that the thread's fault status is accurately reflected in the system.",
    "input": "",
    "output": "definition\n  update_thread_fault :: \"cdl_object_id \\<Rightarrow> (bool\\<Rightarrow>bool) \\<Rightarrow> unit k_monad\"\nwhere\n  \"update_thread_fault p f \\<equiv>\n     do\n       t \\<leftarrow> get_object p;\n       case t of\n          Tcb tcb \\<Rightarrow> set_object p (Tcb (tcb\\<lparr>cdl_tcb_has_fault := f (cdl_tcb_has_fault tcb)\\<rparr>))\n       | _ \\<Rightarrow> fail\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache and Barrier Operations: Initialize the L2 cache, flush the hardware ASID, and perform a store fence (sfence) to ensure memory ordering and coherence.",
    "input": "",
    "output": "consts' initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition initL2Cache :: \"unit machine_monad\"\n  where\n  \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\nconsts' hwASIDFlush_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition hwASIDFlush :: \"machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"hwASIDFlush asid \\<equiv> machine_op_lift (hwASIDFlush_impl asid)\"\n\nconsts' sfence_impl :: \"unit machine_rest_monad\"\ndefinition sfence :: \"unit machine_monad\"\n  where\n  \"sfence \\<equiv> machine_op_lift sfence_impl\"\n\nlemmas cache_machine_op_defs = sfence_def hwASIDFlush_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Thread Fault: Manages a thread fault by attempting to send a fault message. If sending the fault message fails, it catches the exception and handles a double fault.",
    "input": "",
    "output": "definition\n  handle_fault :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_fault thread ex \\<equiv> do\n     _ \\<leftarrow> gets_the $ get_tcb thread;\n     send_fault_ipc thread ex\n          <catch> handle_double_fault thread ex;\n     return ()\n   od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Execute Extended Operation: Perform an extended operation on the extended state, updating it based on the result of the operation while ignoring any return value.",
    "input": "",
    "output": "definition do_extended_op :: \"unit det_ext_monad \\<Rightarrow> ('z::state_ext state,unit) nondet_monad\" where\n \"do_extended_op eop \\<equiv> do\n                         ex \\<leftarrow> get;\n                         (_,es') \\<leftarrow> select_f (mk_ef ((wrap_ext_op eop) ex));\n                         modify (\\<lambda> state. state\\<lparr>exst := (exst es')\\<rparr>)\n                        od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Table Base Calculation: Compute the base address of the table that a page table entry at a given address belongs to, assuming proper alignment. This ensures that the correct table is accessed for further operations in the virtual address space.",
    "input": "",
    "output": "locale_abbrev table_base :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref\" where\n  \"table_base pt_t p \\<equiv> p && ~~mask (pt_bits pt_t)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Low Bits Extraction: Extract the low bits of a virtual ASID and convert them to an ASID low index.",
    "input": "",
    "output": "definition asid_low_bits_of :: \"asid \\<Rightarrow> asid_low_index\"\n  where\n  \"asid_low_bits_of asid \\<equiv> ucast asid\"\n\nlemmas asid_bits_of_defs = asid_high_bits_of_def asid_low_bits_of_def\n\nlocale_abbrev\n  \"asid_table \\<equiv> \\<lambda>s. riscv_asid_table (arch_state s)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate Page Directory: Find the page directory associated with a given virtual ASID by checking the ASID table and the corresponding ASID pool. If the ASID or the page directory is not found, an error is thrown.",
    "input": "",
    "output": "definition\nfind_pd_for_asid :: \"asid \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"find_pd_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pd \\<leftarrow> returnOk (pool (ucast asid));\n    (case pd of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Thread: Obtain the thread control block (TCB) from a given object pointer, ensuring that the object is indeed a TCB.",
    "input": "",
    "output": "definition\n  get_thread :: \"cdl_object_id \\<Rightarrow> cdl_tcb k_monad\"\nwhere\n  \"get_thread p \\<equiv>\n    do\n      t \\<leftarrow> get_object p;\n      case t of\n          Tcb tcb \\<Rightarrow> return tcb\n        | _ \\<Rightarrow> fail\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Monad: Represents operations on the machine state, encapsulating non-deterministic behaviors and effects on the system's hardware state.",
    "input": "",
    "output": "type_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c AARCH64.machine_monad\" <= (type) \"(AARCH64.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "Allocate TCB: Creates and initializes a new TCB object with the specified number of bits, ensuring that the TCB is properly set up for thread management.",
    "input": "",
    "output": "tcb_pptr \\<leftarrow> create_objects tcb_bits tcb_bits TCBObject;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity Capabilities: Returns the set of all capabilities an entity has access to, either directly or through store connections. This ensures a comprehensive view of the entity's permissions and access rights within the system.",
    "input": "",
    "output": "caps_of :: \"state \\<Rightarrow> entity_id \\<Rightarrow> cap set\" where\n  \"caps_of s e  \\<equiv> \\<Union>(direct_caps_of s ` {e' . (e,e') \\<in> store_connected s})\"\n\nlemma caps_rel:\n  \"caps_of s e = \\<Union>(direct_caps_of s ` store_connected s `` {e})\"\n  by (simp add: caps_of_def Image_def)\n\ndefinition  (* All the different capabilities of the system *)\n  all_caps_of :: \"state \\<Rightarrow> cap set\" where\n  \"all_caps_of s \\<equiv> \\<Union>e. direct_caps_of s e\"\n\ndefinition\n  read_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"read_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Read}\\<rparr>\"\n\ndefinition\n  write_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"write_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Write}\\<rparr>\"\n\ndefinition\n  take_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"take_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Take}\\<rparr>\"\n\ndefinition\n  grant_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"grant_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Grant}\\<rparr>\"\n\ndefinition\n  create_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"create_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Create}\\<rparr>\"\n\ndefinition\n  store_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"store_cap e \\<equiv> \\<lparr>target = e, rights = {Store}\\<rparr>\"\n\ndefinition\n  full_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"full_cap e \\<equiv> \\<lparr>target = e, rights = all_rights \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "TCB Registers and Capabilities Merge: Overwrite the capabilities stored in a TCB (such as ctable, vtable, reply, caller, and ipcframe) with those from another TCB while preserving the register set and other fields.",
    "input": "",
    "output": "definition\n  tcb_registers_caps_merge :: \"tcb \\<Rightarrow> tcb \\<Rightarrow> tcb\"\nwhere\n \"tcb_registers_caps_merge regtcb captcb \\<equiv>\n  regtcb \\<lparr> tcb_ctable := tcb_ctable captcb,\n           tcb_vtable := tcb_vtable captcb,\n           tcb_reply := tcb_reply captcb,\n           tcb_caller := tcb_caller captcb,\n           tcb_ipcframe := tcb_ipcframe captcb \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Endpoint: Assigns a specified endpoint to a target, establishing the target's association with the endpoint for interrupt handling.",
    "input": "",
    "output": "|  IrqHandlerSetEndpointIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Representation: The ASID is represented as a machine word with a length of 17 bits, requiring invariants to ensure that any extra bits beyond the 17-bit length are zero.",
    "input": "",
    "output": "type_synonym asid_len           = 17\ntype_synonym asid_rep_len       = machine_word_len\ntype_synonym asid               = \"asid_rep_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization Functions: Initialize and configure kernel resources, including creating ASID control capabilities, generating frame capabilities for a specified region, writing ASID pool mappings, and mapping page table capabilities. These functions ensure that the kernel's memory management and address space isolation are properly set up, facilitating secure and efficient operation.",
    "input": "",
    "output": "do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap BI_CAP_ASID_CTRL)\n                               (ArchObjectCap ASIDControlCap);\n\n     returnOk ap_cap\n   odE\"\n\ndefinition\n  create_frames_of_region :: \"cap \\<Rightarrow> (paddr \\<times> paddr) \\<Rightarrow> bool \\<Rightarrow> word32\n                              \\<Rightarrow> (nat \\<times> nat,'z::state_ext) ki_monad\" where\n  \"create_frames_of_region root_cnode_cap reg do_map pv_offset \\<equiv> doE\n\n     slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     (swp mapME)\n       [(fst reg),(fst reg + of_nat (2 ^ pageBits)) .e. (snd reg - 1)]\n       (\\<lambda>f. doE\n              frame_cap \\<leftarrow> (if do_map\n                           then create_it_frame_cap f\n                                  (f - BASE_OFFSET - pv_offset) (Some IT_ASID) False\n                           else create_it_frame_cap f 0 None False);\n              provide_cap root_cnode_cap frame_cap\n            odE);\n\n     slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     returnOk (slot_pos_before, slot_pos_after)\n   odE\"\n\ndefinition\n  write_it_asid_pool :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"write_it_asid_pool it_ap_cap it_pd_cap \\<equiv>\n   let ap_ptr = obj_ref_of it_ap_cap;\n       pd_ptr = obj_ref_of it_pd_cap;\n       asid_idx = ucast (IT_ASID >> asid_low_bits)\n   in\n   do\n     ap \\<leftarrow> get_asid_pool ap_ptr;\n     ap' \\<leftarrow> return (ap (ucast IT_ASID \\<mapsto> pd_ptr));\n     set_asid_pool ap_ptr ap';\n\n     asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n     asid_table' \\<leftarrow> return (asid_table(asid_idx \\<mapsto> ap_ptr));\n     modify (\\<lambda>s. s \\<lparr> arch_state :=\n                      arch_state s \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>)\n\n   od\"\n\ndefinition\n  map_it_pt_cap :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"map_it_pt_cap pd_cap pt_cap \\<equiv> do\n\n     pd \\<leftarrow> return $ obj_ref_of pd_cap; (* C uses specific PD version *)\n\n     (pt,vptr) \\<leftarrow> return $ case the_arch_cap pt_cap\n                            of PageTableCap ref (Some (_, vref)) \\<Rightarrow> (ref,vref);\n\n     slot \\<leftarrow> return $ vptr >> pageBitsForSize ARMSection;",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Deletion: Allows the deletion of a capability at a specified index and depth within a CNode, ensuring that the targeted capability is removed from the system.",
    "input": "",
    "output": "|  CNodeDeleteIntent word32 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Memory: Clear a specified range of memory by setting each word in the range to zero, preparing it for reuse as user memory without flushing the cache.",
    "input": "",
    "output": "text \\<open>Clear memory contents to recycle it as user memory. Do not yet flush the cache.\\<close>\ndefinition clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"clearMemory ptr bytelength \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access: Convert a page table entry (PTE) to a physical pointer and calculate the offset of a specific slot in a page table based on the virtual address, allowing for precise manipulation and access within the AARCH64 virtual address space.",
    "input": "",
    "output": "definition pptr_from_pte :: \"pte \\<Rightarrow> vspace_ref\" where\n  \"pptr_from_pte pte \\<equiv> ptrFromPAddr (pte_base_addr pte)\"\n\ndefinition pt_slot_offset :: \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\" where\n  \"pt_slot_offset level pt_ptr vptr = pt_ptr + (pt_index level vptr << pte_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Prepare VCPU for Removal: Invalidate the active VCPU by disabling it and clearing the current VCPU reference in the system state.",
    "input": "",
    "output": "definition\n  vcpu_invalidate_active :: \"(unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_invalidate_active \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    case cur_v of\n      Some (vr, True) \\<Rightarrow> vcpu_disable None\n    | _ \\<Rightarrow> return ();\n    modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := None \\<rparr>\\<rparr>)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate VSpace for ASID: Find the top-level page table associated with a given virtual ASID, ensuring that the ASID is valid and returning an error if it is not. Load VMID: Retrieve the VMID associated with a given ASID by accessing the corresponding entry in the system state.",
    "input": "",
    "output": "definition find_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n  \"find_vspace_for_asid asid \\<equiv> doE\n     vspace_opt \\<leftarrow> liftE $ gets $ vspace_for_asid asid;\n     throw_opt InvalidRoot vspace_opt\n   odE\"\n\ndefinition load_vmid :: \"asid \\<Rightarrow> (vmid option, 'z::state_ext) s_monad\" where\n  \"load_vmid asid \\<equiv> do\n     entry \\<leftarrow> gets_the $ entry_for_asid asid;\n     return $ ap_vmid entry\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Receive System Call: Processes a receive system call by checking the current thread's capability and performing the receive operation if the capability is a notification with the appropriate rights. If the capability is valid and allows receiving, it checks the notification's bound TCB and either receives the signal or throws a fault.",
    "input": "",
    "output": "definition\n  handle_recv :: \"bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"handle_recv is_blocking \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n\n     ep_cptr \\<leftarrow> liftM data_to_cptr $ as_user thread $\n                 getRegister cap_register;\n\n     (cap_fault_on_failure (of_bl ep_cptr) True $ doE\n        ep_cap \\<leftarrow> lookup_cap thread ep_cptr;\n\n        let flt = (throwError $ MissingCapability 0)\n        in\n        case ep_cap\n          of\n            NotificationCap ref badge rights \\<Rightarrow>\n             (if AllowRecv \\<in> rights\n              then doE\n                ntfn \\<leftarrow> liftE $ get_notification ref;\n                boundTCB \\<leftarrow> returnOk $ ntfn_bound_tcb ntfn;\n                if boundTCB = Some thread \\<or> boundTCB = None\n                then liftE $ receive_signal thread ep_cap is_blocking\n                else flt\n               odE\n              else flt)\n           | _ \\<Rightarrow> flt\n      odE)\n      <catch> handle_fault thread\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Switching: Manages the activation and deactivation of a VCPU. If a new VCPU is specified, it saves the state of the current VCPU (if active) and restores the state of the new VCPU, marking it as active. If no VCPU is specified, it deactivates the current VCPU and disables VCPU mode, preserving the state for potential future reactivation.",
    "input": "",
    "output": "definition vcpu_switch :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_switch v \\<equiv> case v of\n     None \\<Rightarrow> do\n       cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n       (case cur_v of\n          None \\<Rightarrow> return () \\<comment> \\<open>both null, current cannot be active\\<close>\n        | Some (vr, active) \\<Rightarrow> do \\<comment> \\<open>switch to thread without vcpu\\<close>\n            when active $ do  \\<comment> \\<open> save state if not saved already\\<close>\n              vcpu_disable (Some vr);\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (vr, False) \\<rparr>\\<rparr>)\n            od;\n            return ()\n          od)\n       od\n   | Some new \\<Rightarrow> do\n       cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n       (case cur_v of\n          None \\<Rightarrow> do \\<comment> \\<open>switch to the new vcpu with no current one\\<close>\n            vcpu_restore new;\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n          od\n        | Some (vr, active) \\<Rightarrow> \\<comment> \\<open>switch from an existing vcpu\\<close>\n            (if vr \\<noteq> new\n            then do \\<comment> \\<open>different vcpu\\<close>\n              vcpu_save cur_v;\n              vcpu_restore new;\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n            od\n            else \\<comment> \\<open>same vcpu\\<close>\n              when (\\<not> active) $ do\n                do_machine_op isb;\n                vcpu_enable new;\n                modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n              od))\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Message Reception on Endpoint: Handle a message receive operation on an endpoint by a thread. If a sender is waiting, the message is transferred; otherwise, the thread is placed in the endpoint's receiving queue.",
    "input": "",
    "output": "definition\n  isActive :: \"notification \\<Rightarrow> bool\"\nwhere\n  \"isActive ntfn \\<equiv> case ntfn_obj ntfn\n     of ActiveNtfn _ \\<Rightarrow> True\n      | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value: Defines the maximum value for an interrupt request (IRQ) in the system, which is specified by the Kernel_Config.",
    "input": "",
    "output": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Kernel_Config.maxIRQ\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocation Dispatcher: Dispatches ARM-specific system calls to their respective handlers for page tables, page directories, pages, ASID control, ASID pools, and VCPUs. Ensures that each invocation is processed by the appropriate function, maintaining the integrity and functionality of the memory management and virtualization components.",
    "input": "",
    "output": "definition\n  arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\" where\n  \"arch_perform_invocation i \\<equiv> liftE $\n    case i of\n          InvokePageTable oper \\<Rightarrow> do perform_page_table_invocation oper; return [] od\n        | InvokePageDirectory oper \\<Rightarrow> do perform_page_directory_invocation oper; return [] od\n        | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n        | InvokeASIDControl oper \\<Rightarrow> do perform_asid_control_invocation oper; return [] od\n        | InvokeASIDPool oper \\<Rightarrow> do perform_asid_pool_invocation oper; return [] od\n        | InvokeVCPU oper \\<Rightarrow> perform_vcpu_invocation oper\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Entry Access: Retrieve and store PTEs in the page table. The functions calculate the base address and offset of the PTE, access the page table, and either return or update the PTE at the specified location.",
    "input": "",
    "output": "definition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> pte_bits);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> pte_bits);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Entry Access: Retrieve and store PTEs in the page table. The functions calculate the base address and offset of the PTE, access the page table, and either return or update the PTE at the specified location.",
    "input": "",
    "output": "definition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> 2);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> 2);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Bind Notification: Associates a thread with a notification, allowing the thread to receive notifications.",
    "input": "",
    "output": "|  TcbBindNTFNIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Perform operations on the underspecified part of the machine state, ensuring that they do not fail and always return a non-empty set of follow-on states. These operations are designed to avoid the need for additional axioms by explicitly setting the failure flag to False and handling the non-existing case as a null operation.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine operations below work on the underspecified part of the machine state @{typ\n  machine_state_rest} and cannot fail. We could express the latter by type (leaving out the failure\n  flag), but if we later wanted to implement them, we'd have to set up a new Hoare logic framework\n  for that type. So instead, we provide a wrapper for these operations that explicitly ignores the\n  fail flag and sets it to False. Similarly, these operations never return an empty set of follow-on\n  states, which would require the operation to fail. So we explicitly make this (non-existing) case\n  a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\\<close>\n\ncontext Arch begin global_naming AARCH64",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object References of Capabilities: The function `obj_refs` determines the set of all objects referenced by a given capability. It returns an empty set for capabilities that do not reference any objects, and it returns a set containing the object references for those that do, such as CNodeCap, EndpointCap, NotificationCap, ThreadCap, and Zombie.",
    "input": "",
    "output": "primrec\n  obj_refs :: \"cap \\<Rightarrow> obj_ref set\"\nwhere\n  \"obj_refs NullCap = {}\"\n| \"obj_refs (ReplyCap r m cr) = {}\"\n| \"obj_refs IRQControlCap = {}\"\n| \"obj_refs (IRQHandlerCap irq) = {}\"\n| \"obj_refs (UntypedCap dev r s f) = {}\"\n| \"obj_refs (CNodeCap r bits guard) = {r}\"\n| \"obj_refs (EndpointCap r b cr) = {r}\"\n| \"obj_refs (NotificationCap r b cr) = {r}\"\n| \"obj_refs (ThreadCap r) = {r}\"\n| \"obj_refs DomainCap = {}\"\n| \"obj_refs (Zombie ptr b n) = {ptr}\"\n| \"obj_refs (ArchObjectCap x) = set_option (aobj_ref x)\"",
    "system": "",
    "history": []
  }
]