{"spec": "arch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend", "property": "Arch-Specific Invocation Label Requalification: The code requalifies arch-specific invocation labels within the Arch context, ensuring that the enum instance proofs are correctly handled outside of the Arch locale.", "title": "./spec/design/skel/ARM/ArchInvocationLabels_H.thy", "chapter": "", "section": "", "comment": " not possible to move this requalification to generic, since enum instance proofs must\n   be done outside of Arch locale "}
{"spec": "lemma unat_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> unat (maxIRQ::'a word) = maxIRQ\"\n  by (metis maxIRQ_less_2p_irq_len Word.of_nat_unat of_nat_inverse of_nat_maxIRQ unat_ucast_up_simp)", "property": "IRQ Length Property: The unat (unsigned natural number) value of maxIRQ is equal to maxIRQ when the length of irq_len is less than or equal to the length of the word type 'a.", "title": "./spec/machine/AARCH64/Arch_Kernel_Config_Lemmas.thy", "chapter": "", "section": "", "comment": " Safe for [simp] because we don't use maxIRQ at lower than irq_len "}
{"spec": "lemma returnOk_liftE:\n  \"returnOk x = liftE (return x)\"\n  by (simp add: liftE_def returnOk_def)", "property": "Nondeterministic State Monad with Failure: The `returnOk` function can be equivalently defined using the `liftE` function, ensuring that both functions behave identically in the context of the monad.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "@{const returnOk} could also be defined via @{const liftE}:"}
{"spec": "lemma irqVTimerEvent_le_maxIRQ[simp, intro!]:\n  \"irqVTimerEvent \\<le> maxIRQ\"\n  by (simp add: irqVTimerEvent_def Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_less_2p_irqBits:\n  \"(maxIRQ::nat) < 2^irqBits\"\n  by (simp add: Kernel_Config.maxIRQ_def Kernel_Config.irqBits_def)", "property": "IRQ Limits: The maximum IRQ (maxIRQ) is bounded by specific constraints, ensuring it is less than 2 to the power of irqBits and irqVTimerEvent does not exceed maxIRQ.", "title": "./spec/machine/ARM_HYP/Arch_Kernel_Config_Lemmas.thy", "chapter": "", "section": "", "comment": " maxIRQ conditions "}
{"spec": "text \\<open>This definition decodes architecture-specific invocations.\n\\<close>\n\ndefinition\n  page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\nwhere\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"\n\n\ndefinition\n  arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n\"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n\n  PageDirectoryCap _ _ \\<Rightarrow>\n    if isPDFlushLabel (invocation_type label) then\n    if length args > 1\n    then let start = args ! 0;\n             end = args ! 1\n    in doE\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            whenE (start \\<ge> kernel_base \\<or> end > kernel_base) $ throwError IllegalOperation;\n            (pd,asid) \\<leftarrow> (case cap of\n                    PageDirectoryCap pd (Some asid) \\<Rightarrow> returnOk (pd,asid)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 0);\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 0;\n            frame_info \\<leftarrow> liftE $ resolve_vaddr pd start;\n            case frame_info of\n                None \\<Rightarrow> returnOk $ InvokePageDirectory PageDirectoryNothing\n              | Some (frame_size, frame_base) \\<Rightarrow>\n                    let base_start = page_base start frame_size;\n                        base_end = page_base (end - 1) frame_size;\n                        offset = start && mask (pageBitsForSize frame_size);\n                        pstart = frame_base + offset\n                    in doE\n                        whenE (base_start \\<noteq> base_end) $ throwError $\n                            RangeError start (base_start + mask (pageBitsForSize frame_size));\n                        returnOk $ InvokePageDirectory $\n                            PageDirectoryFlush (label_to_flush_type (invocation_type label))\n                            start (end - 1) pstart pd asid\n                    odE\n    odE\n    else throwError TruncatedMessage\n    else throwError IllegalOperation\n\n| PageTableCap p mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageTableMap then\n    if length args > 1 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             attr = args ! 1;\n             pd_cap = fst (extra_caps ! 0)\n    in doE\n            whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            whenE (vaddr \\<ge> kernel_base) $ throwError $ InvalidArgument 0;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            pd_index \\<leftarrow> returnOk (shiftr vaddr 20);\n            vaddr' \\<leftarrow> returnOk (vaddr && ~~ mask 20);\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << 2));\n            oldpde \\<leftarrow> liftE $ get_master_pde pd_slot;\n            unlessE (oldpde = InvalidPDE) $ throwError DeleteFirst;\n            pde \\<leftarrow> returnOk (PageTablePDE (addrFromPPtr p)\n                               (attribs_from_word attr \\<inter> {ParityEnabled}) 0);\n            returnOk $ InvokePageTable $\n                PageTableMap\n                (ArchObjectCap $ PageTableCap p (Some (asid, vaddr')))\n                cte pde pd_slot\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageTableUnmap\n    then doE\n            final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n            unlessE final $ throwError RevokeFirst;\n            returnOk $ InvokePageTable $ PageTableUnmap (ArchObjectCap cap) cte\n    odE\n    else throwError IllegalOperation\n\n| PageCap dev p R pgsz mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageMap then\n    if length args > 2 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             rights_mask = args ! 1;\n             attr = args ! 2;\n             pd_cap = fst (extra_caps ! 0)\n        in doE\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            case mapped_address of\n              Some (asid', vaddr') \\<Rightarrow> doE\n                whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n                whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0)\n              odE\n            | None \\<Rightarrow> doE\n                vtop \\<leftarrow> returnOk (vaddr + (1 << (pageBitsForSize pgsz)) - 1);\n                whenE (vtop \\<ge> kernel_base) $ throwError $ InvalidArgument 0\n              odE;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            vm_rights \\<leftarrow> returnOk (mask_vm_rights R (data_to_rights rights_mask));\n            check_vp_alignment pgsz vaddr;\n            entries \\<leftarrow> create_mapping_entries (addrFromPPtr p)\n                                              vaddr pgsz vm_rights\n                                              (attribs_from_word attr) pd;\n            ensure_safe_mapping entries;\n            returnOk $ InvokePage $ PageMap asid\n                (ArchObjectCap $ PageCap dev p R pgsz (Some (asid, vaddr)))\n                cte entries\n        odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageUnmap\n    then  returnOk $ InvokePage $ PageUnmap cap cte\n    else if isPageFlushLabel (invocation_type label) then\n        if length args > 1\n        then let start = args ! 0;\n                 end = args ! 1\n        in doE\n            (asid, vaddr) \\<leftarrow> (case mapped_address of\n                Some a \\<Rightarrow> returnOk a\n              | _ \\<Rightarrow> throwError IllegalOperation);\n            pd \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            page_size \\<leftarrow> returnOk $ 1 << pageBitsForSize pgsz;\n            whenE (start \\<ge> page_size \\<or> end > page_size) $ throwError $ InvalidArgument 0;\n            returnOk $ InvokePage $ PageFlush\n                (label_to_flush_type (invocation_type label)) (start + vaddr)\n                (end + vaddr - 1) (addrFromPPtr p + start) pd asid\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageGetAddress\n    then returnOk $ InvokePage $ PageGetAddr p\n  else  throwError IllegalOperation\n\n| ASIDControlCap \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMASIDControlMakePool then\n    if length args > 1 \\<and> length extra_caps > 1\n    then let index = args ! 0;\n             depth = args ! 1;\n             (untyped, parent_slot) = extra_caps ! 0;\n             root = fst (extra_caps ! 1)\n         in doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            free_set \\<leftarrow> returnOk (- dom asid_table \\<inter> {x. x \\<le> 2 ^ asid_high_bits - 1});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n            base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n            (p,n) \\<leftarrow> (case untyped of UntypedCap False p n f \\<Rightarrow> returnOk (p,n)\n                                    | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            frame \\<leftarrow> (if n = pageBits\n                      then doE\n                        ensure_no_children parent_slot;\n                        returnOk p\n                      odE\n                      else  throwError $ InvalidCapability 1);\n            dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n            ensure_empty dest_slot;\n            returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n        odE\n    else  throwError TruncatedMessage\n    else  throwError IllegalOperation\n\n| ASIDPoolCap p base \\<Rightarrow>\n  if invocation_type label = ArchInvocationLabel ARMASIDPoolAssign then\n  if length extra_caps > 0\n  then\n    let (pd_cap, pd_cap_slot) = extra_caps ! 0\n     in case pd_cap of\n          ArchObjectCap (PageDirectoryCap _ None) \\<Rightarrow> doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n            whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n            whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n            pool \\<leftarrow> liftE $ get_asid_pool p;\n            free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n            returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pd_cap_slot\n          odE\n        | _ \\<Rightarrow>  throwError $ InvalidCapability 1\n  else  throwError TruncatedMessage\n  else  throwError IllegalOperation\"\n\n\ndefinition\n  arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n \"arch_data_to_obj_type n \\<equiv>\n  if n = 0 then Some PageDirectoryObj\n  else if n = 1 then Some SmallPageObj\n  else if n = 2 then Some LargePageObj\n  else if n = 3 then Some SectionObj\n  else if n = 4 then Some SuperSectionObj\n  else if n = 5 then Some PageTableObj\n  else None\"\n\ndefinition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> whenE (irq > maxIRQ) $ throwError (RangeError 0 maxIRQ)\"\n\ndefinition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n    (if invocation_type label = ArchInvocationLabel ARMIRQIssueIRQHandler\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n\n          returnOk $ ArchIRQControlIssue irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\nend\n\nend", "property": "Architecture-specific Invocation Decoding: Decode and validate architecture-specific system calls, including operations on page directories, page tables, pages, ASID controls, and ASID pools. These operations ensure that the system call parameters are correctly interpreted and validated, and appropriate actions such as mapping, unmapping, flushing, and managing ASID pools are performed. \n\n- **Page Directory Operations**: Validate and perform operations like flushing page directories, ensuring valid addresses and permissions.\n- **Page Table Operations**: Map and unmap page tables, ensuring correct alignment and permissions, and handling additional capabilities.\n- **Page Operations**: Map, unmap, and flush pages, ensuring valid addresses, permissions, and alignments.\n- **ASID Control Operations**: Create ASID pools, ensuring free ASIDs and valid frame allocations.\n- **ASID Pool Operations**: Assign ASIDs to page directories, ensuring valid pool and directory associations.\n- **IRQ Control Operations**: Issue IRQ handlers, ensuring valid IRQ numbers and target slots.", "title": "./spec/abstract/ARM/ArchDecode_A.thy", "chapter": "Decoding Architecture-specific System Calls", "section": "Architecture calls", "comment": ""}
{"spec": "definition\n  is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv> \\<exists>r a. c = ArchObjectCap (PML4Cap r (Some a))\"\n\ndefinition\ncheck_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n\"check_valid_ipc_buffer vptr c \\<equiv> case c of\n  (ArchObjectCap (PageCap False _ _ _ _ _)) \\<Rightarrow> doE\n    whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError;\n    returnOk ()\n  odE\n| _ \\<Rightarrow> throwError IllegalOperation\"", "property": "Virtual Address Space Validation: Ensures that a thread's virtual address space capability is valid by checking if it points to a mapped PML4, which is a requirement for the x64 architecture. For IPC buffer validation, it specifically checks if the capability is a PageCap and if the provided virtual pointer is aligned; otherwise, it throws an error.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "A thread's virtual address space capability must be to a mapped PML4 (page map level 4)\nto be valid on the x64 architecture."}
{"spec": "definition\n  init_global_pd :: obj_ref where\n  \"init_global_pd = kernel_base + 0x6000\"\n\ndefinition\n  \"init_arch_state \\<equiv> \\<lparr>\n    x64_asid_table = Map.empty,\n    x64_global_pml4 = init_global_pml4,\n    x64_kernel_vspace =\n      \\<lambda>ref. if ref \\<in> {pptr_base .. pptr_base + mask pml4_shift_bits}\n              then X64VSpaceKernelWindow\n              else X64VSpaceInvalidRegion,\n    x64_global_pts = [],\n    x64_global_pdpts = [init_global_pdpt],\n    x64_global_pds = [init_global_pd],\n    x64_current_cr3 = cr3 0 0,\n    x64_allocated_io_ports = \\<lambda>_. False,\n    x64_num_ioapics = 1,\n    x64_ioapic_nirqs = \\<lambda>_. ucast ioapicIRQLines,\n    x64_irq_state = K IRQFree\n   \\<rparr>\"\n\ndefinition [simp]:\n  \"global_pml4 \\<equiv> (\\<lambda>_ :: 9 word. InvalidPML4E)\n    (0x1FF := PDPointerTablePML4E (addrFromPPtr init_global_pdpt) {} {})\"", "property": "Initialization of Architecture State: The architecture state is initialized with an empty ASID table, a global PML4, kernel virtual space mapping, and other essential structures such as page tables, page directories, and interrupt controllers.\n\nSubproperties:\n- ASID Table Initialization: The ASID table is initialized as an empty map.\n- Global PML4 Initialization: The global PML4 is initialized with a specific configuration, including a PD pointer table entry.\n- Kernel Virtual Space Mapping: The kernel virtual space is mapped to a specific range of physical addresses.\n- Page Tables and Directories Initialization: The global page tables and directories are initialized with specific values.\n- Interrupt Controllers Initialization: The interrupt controllers are initialized with a specific configuration, including the number of IOAPICs and IRQ lines.", "title": "./spec/abstract/X64/Init_A.thy", "chapter": "", "section": "", "comment": " 4KiB "}
{"spec": "CNodeCopyIntent word32 word32 word32 word32 \"cdl_right set\"", "property": "Copy Capability: Copy a capability from a source root to a destination root, specifying the source and destination indices, depths, and rights.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " Copy: (target), dest_index, dest_depth, (src_root), src_index, src_depth, rights "}
{"spec": "definition\n  schedule :: \"unit k_monad\"\nwhere\n  \"schedule \\<equiv> do\n     change_current_domain;\n     next_domain \\<leftarrow> gets cdl_current_domain;\n     threads     \\<leftarrow> gets (active_tcbs_in_domain next_domain);\n     next_thread \\<leftarrow> select threads;\n     switch_to_thread (Some next_thread)\n   od \\<sqinter> do\n     change_current_domain;\n     switch_to_thread None\n   od\"\n\n\nend", "property": "Scheduling Nondeterminism: The scheduling process is fully nondeterministic, allowing for the selection of any active thread within the current domain or switching to an idle state.", "title": "./spec/capDL/Schedule_D.thy", "chapter": "", "section": "", "comment": "\n * Scheduling is fully nondeterministic at this level.\n "}
{"spec": "chapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/ARM.lhs CONTEXT ARM_H Arch.Types= ArchInv= bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs bodies_only CONTEXT ARM_H NOT isPDFlushLabel isPageFlushLabel\n\nend\nend", "property": "Retyping Objects: Allows the redefinition of object types in the system, enabling the transformation of one type of object into another while preserving the underlying memory and maintaining the integrity of the system.", "title": "./spec/design/skel/ARM/ArchRetype_H.thy", "chapter": "Retyping Objects", "section": "", "comment": ""}
{"spec": "definition\n  corrupt_frame :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\n  where\n  \"corrupt_frame bufp \\<equiv> do\n      f \\<leftarrow> select UNIV;\n      modify (corrupt_intents f bufp)\n    od\"\n\nend", "property": "Corrupt Frame Handling: When a memory frame is corrupted, update the intents of all TCBs whose IPC buffer is located within that frame to reflect the corruption.", "title": "./spec/capDL/KHeap_D.thy", "chapter": "", "section": "", "comment": " When a memory frame has been corrupted,\n * we need to change all the intents of tcbs\n * whose ipc_buffer is located within that frame\n "}
{"spec": "definition \"PD_SIZE_BITS \\<equiv> PD_BITS + PDE_SIZE_BITS\"\ndefinition \"PT_SIZE_BITS \\<equiv> PT_BITS + PTE_SIZE_BITS\"", "property": "Page Table and Page Directory Size Bits: Define the size bits for page directories and page tables by summing the base bits with the corresponding entry size bits.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "ARM constants", "comment": "in abstract, these are pd_bits and pt_bits respectively"}
{"spec": "text \\<open>This section defines traditional Haskell-like do-syntax\n  for the state monad in Isabelle.\\<close>", "property": "Monad Laws: Ensure that the state monad satisfies the traditional monad laws, specifically the left identity, right identity, and associativity laws, providing a sound foundation for monadic computations.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Syntax", "comment": ""}
{"spec": "definition\n  handle_fault :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_fault thread ex \\<equiv> do\n     _ \\<leftarrow> gets_the $ get_tcb thread;\n     send_fault_ipc thread ex\n          <catch> handle_double_fault thread ex;\n     return ()\n   od\"\n\nend", "property": "Handle Thread Fault: Manages a thread fault by attempting to send a fault message. If sending the fault message fails, it catches the exception and handles a double fault.", "title": "./spec/abstract/Ipc_A.thy", "chapter": "IPC", "section": "Sending Fault Messages", "comment": "Handle a thread fault by sending a fault message if possible."}
{"spec": "context Arch begin global_naming ARM_HYP\n\nvalue_type irq_len = Kernel_Config.irqBits (* IRQ_CNODE_SLOT_BITS *)\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = word32\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\ndefinition pageColourBits :: nat where\n  \"pageColourBits \\<equiv> 2\"\n\ndefinition cacheLineBits :: nat where\n  \"cacheLineBits = CONFIG_L1_CACHE_LINE_SIZE_BITS\"\n\ndefinition cacheLine :: nat where\n  \"cacheLine = 2^cacheLineBits\"", "property": "Platform Constants: Define and specify the bit lengths and sizes for IRQs, physical addresses, page colors, and cache lines. These constants ensure consistent and predictable behavior of the platform-specific hardware features.", "title": "./spec/machine/ARM_HYP/Platform.thy", "chapter": "Platform Definitions", "section": "Platform Constants", "comment": ""}
{"spec": "definition\nstore_hw_asid :: \"asid \\<Rightarrow> hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"store_hw_asid asid hw_asid \\<equiv> do\n    pd \\<leftarrow> find_pd_for_asid_assert asid;\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid \\<mapsto> (hw_asid, pd)));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>);\n    hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid \\<mapsto> asid));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"", "property": "Associate a Hardware ASID: Map a virtual ASID to a hardware ASID and update the corresponding page directory. Ensure that both the ASID map and the hardware ASID table are updated to reflect the new association, maintaining the integrity of the address space mappings.", "title": "./spec/abstract/ARM/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Associate a hardware ASID with a virtual ASID."}
{"spec": "|  TcbSetSchedParamsIntent word8 word8", "property": "Set Scheduling Parameters: Set the scheduling parameters for a thread, including the maximum controlled priority (MCP) and priority.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " SetSchedParams: (target), mcp, priority "}
{"spec": "definition\n  init_underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"", "property": "Initial Memory State: The user-visible memory is initialized with all contents set to 0.", "title": "./spec/design/m-skel/ARM/MachineTypes.thy", "chapter": "ARM Machine Types", "section": "Machine State", "comment": "\n  The initial contents of the user-visible memory is 0.\n"}
{"spec": "text \\<open>This definition decodes CNode invocations.\\<close>\n\ndefinition\n  decode_cnode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap \\<Rightarrow> cap list \\<Rightarrow> (cnode_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_cnode_invocation label args cap excaps \\<equiv> doE\n  unlessE (gen_invocation_type label \\<in> set [CNodeRevoke .e. CNodeSaveCaller]) $\n    throwError IllegalOperation;\n  whenE (length args < 2) (throwError TruncatedMessage);\n  index \\<leftarrow> returnOk $ data_to_cptr $ args ! 0;\n  bits \\<leftarrow> returnOk $ data_to_nat $ args ! 1;\n  args \\<leftarrow> returnOk $ drop 2 args;\n  dest_slot \\<leftarrow> lookup_target_slot cap index bits;\n  if length args \\<ge> 2 \\<and> length excaps > 0\n        \\<and> gen_invocation_type label \\<in> set [CNodeCopy .e. CNodeMutate] then\n  doE\n    src_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 0;\n    src_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 1;\n    args \\<leftarrow> returnOk $ drop 2 args;\n    src_root_cap \\<leftarrow> returnOk $ excaps ! 0;\n    ensure_empty dest_slot;\n    src_slot \\<leftarrow>\n         lookup_source_slot src_root_cap src_index src_depth;\n    src_cap \\<leftarrow> liftE $ get_cap src_slot;\n    whenE (src_cap = NullCap) $\n         throwError $ FailedLookup True $ MissingCapability src_depth;\n    (rights, cap_data, is_move) \\<leftarrow> case (gen_invocation_type label, args) of\n      (CNodeCopy, rightsWord # _) \\<Rightarrow> doE\n                    rights \\<leftarrow> returnOk $ data_to_rights $ rightsWord;\n                    returnOk $ (rights, None, False)\n                odE\n     | (CNodeMint, rightsWord # capData # _) \\<Rightarrow> doE\n                    rights \\<leftarrow> returnOk $ data_to_rights $ rightsWord;\n                    returnOk $ (rights, Some capData, False)\n                odE\n     | (CNodeMove, _) \\<Rightarrow> returnOk (all_rights, None, True)\n     | (CNodeMutate, capData # _) \\<Rightarrow> returnOk (all_rights, Some capData, True)\n     | _ \\<Rightarrow> throwError TruncatedMessage;\n    src_cap \\<leftarrow> returnOk $ mask_cap rights src_cap;\n    new_cap \\<leftarrow> (if is_move then returnOk else derive_cap src_slot) (case cap_data of\n                  Some w \\<Rightarrow> update_cap_data is_move w src_cap\n                | None \\<Rightarrow> src_cap);\n    whenE (new_cap = NullCap) $ throwError IllegalOperation;\n    returnOk $ (if is_move then MoveCall else InsertCall) new_cap src_slot dest_slot\n  odE\n  else if gen_invocation_type label = CNodeRevoke then returnOk $ RevokeCall dest_slot\n  else if gen_invocation_type label = CNodeDelete then returnOk $ DeleteCall dest_slot\n  else if gen_invocation_type label = CNodeSaveCaller then doE\n    ensure_empty dest_slot;\n    returnOk $ SaveCall dest_slot\n  odE\n  else if gen_invocation_type label = CNodeCancelBadgedSends then doE\n    cap \\<leftarrow> liftE $ get_cap dest_slot;\n    unlessE (has_cancel_send_rights cap) $ throwError IllegalOperation;\n    returnOk $ CancelBadgedSendsCall cap\n  odE\n  else if gen_invocation_type label = CNodeRotate \\<and> length args > 5\n          \\<and> length excaps > 1 then\n  doE\n    pivot_new_data \\<leftarrow> returnOk $ args ! 0;\n    pivot_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 1;\n    pivot_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 2;\n    src_new_data \\<leftarrow> returnOk $ args ! 3;\n    src_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 4;\n    src_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 5;\n    pivot_root_cap <- returnOk $ excaps ! 0;\n    src_root_cap <- returnOk $ excaps ! 1;\n\n    src_slot <- lookup_source_slot src_root_cap src_index src_depth;\n    pivot_slot <- lookup_pivot_slot pivot_root_cap pivot_index pivot_depth;\n\n    whenE (pivot_slot = src_slot \\<or> pivot_slot = dest_slot) $\n      throwError IllegalOperation;\n\n    unlessE (src_slot = dest_slot) $ ensure_empty dest_slot;\n\n    src_cap <- liftE $ get_cap src_slot;\n    whenE (src_cap = NullCap) $\n      throwError $ FailedLookup True $ MissingCapability src_depth;\n\n    pivot_cap <- liftE $ get_cap pivot_slot;\n    whenE (pivot_cap = NullCap) $\n      throwError $ FailedLookup False $ MissingCapability pivot_depth;\n\n    new_src_cap \\<leftarrow> returnOk $ update_cap_data True src_new_data src_cap;\n    new_pivot_cap \\<leftarrow> returnOk $ update_cap_data True pivot_new_data pivot_cap;\n\n    whenE (new_src_cap = NullCap) $ throwError IllegalOperation;\n    whenE (new_pivot_cap = NullCap) $ throwError IllegalOperation;\n\n    returnOk $ RotateCall new_src_cap new_pivot_cap src_slot pivot_slot dest_slot\n  odE\n  else\n    throwError TruncatedMessage\nodE\"", "property": "CNode Invocation Decoding: Decodes CNode invocations to perform various operations such as copying, moving, revoking, deleting, saving, canceling badged sends, and rotating capabilities. Ensures the integrity of the operation by validating the invocation type, arguments, and capability rights, and handles the appropriate actions based on the decoded information.", "title": "./spec/abstract/Decode_A.thy", "chapter": "Decoding System Calls", "section": "Threads", "comment": ""}
{"spec": "definition\n  update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 18;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"", "property": "Update CNode Capability Data: Extract new guard size and guard bits from the provided data, using specific bit masking and shifting operations to isolate the relevant information.", "title": "./spec/abstract/ARM_HYP/ArchCSpace_A.thy", "chapter": "", "section": "", "comment": "On a user request to modify a cnode capability, extract new guard bits and guard."}
{"spec": "theory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H decls_only\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H bodies_only\n\ndatatype arch_kernel_object_type =\n    PTET\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\nend", "property": "Architectural Object Classification: Classify architectural kernel objects into distinct types, specifically Page Table Entries (PTET) and ASID Pool objects (ASIDPoolT), to facilitate proper management and handling of these objects within the kernel.", "title": "./spec/design/skel/RISCV64/ArchStructures_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "(*\n  Hypervisor stub for RISCV64\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/RISCV64.hs Arch= CONTEXT RISCV64_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/RISCV64.hs Arch= CONTEXT RISCV64_H bodies_only ArchInv= ArchLabels=\n\nend\nend", "property": "Hypervisor Stub for RISCV64: Provides the necessary declarations and implementations for hypervisor functionality specific to the RISCV64 architecture, ensuring that the hypervisor can manage and interact with virtual machines effectively.", "title": "./spec/design/skel/RISCV64/ArchHypervisor_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "theory ArchTCB_H\nimports TCBDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/RISCV64.hs RegisterSet= CONTEXT RISCV64_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend", "property": "Architectural TCB Properties: Provides architectural-specific TCB (Thread Control Block) functions for RISCV64, including register set management and thread get/set operations.", "title": "./spec/design/skel/RISCV64/ArchTCB_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "text \\<open>The x64 kernel supports capabilities for ASID pools and an ASID controller capability,\nalong with capabilities for IO ports and spaces, as well as virtual memory mappings.\\<close>\n\ndatatype arch_cap =\n   ASIDPoolCap (acap_asid_pool : obj_ref) (acap_asid_base : asid)\n | ASIDControlCap\n | IOPortCap (acap_io_port_first_port : io_port) (acap_io_port_last_port : io_port)\n | IOPortControlCap\n\n | PageCap bool obj_ref (acap_rights : cap_rights) vmmap_type vmpage_size \"(asid * vspace_ref) option\"\n | PageTableCap obj_ref \"(asid * vspace_ref) option\"\n | PageDirectoryCap obj_ref \"(asid * vspace_ref) option\"\n | PDPointerTableCap obj_ref \"(asid * vspace_ref) option\"\n | PML4Cap obj_ref \"asid option\"", "property": "x64-Specific Capabilities: The x64 kernel supports various architecture-specific capabilities, including ASID pools, ASID controller, IO ports, IO port controller, and different types of virtual memory mappings such as page, page table, page directory, PD pointer table, and PML4. These capabilities enable the management and control of memory and I/O resources specific to the x64 architecture.", "title": "./spec/abstract/X64/Arch_Structs_A.thy", "chapter": "x64-Specific Data Types", "section": "Architecture-specific objects", "comment": ""}
{"spec": "IrqControlIssueIrqHandlerIntent irq word32 word32", "property": "Issue IRQ Handler Intent: Specify the intent to issue an IRQ handler for a specific IRQ, with a target, root, index, and depth.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " IssueIrqHandler: (target), irq, (root), index, depth "}
{"spec": "definition\n  is_final_cap' :: \"cap \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n \"is_final_cap' cap s \\<equiv>\n    \\<exists>cref. {cref. \\<exists>cap'. fst (get_cap cref s) = {(cap', s)}\n                       \\<and> (gen_obj_refs cap \\<inter> gen_obj_refs cap' \\<noteq> {})}\n         = {cref}\"\n\ndefinition\n  is_final_cap :: \"cap \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n  \"is_final_cap cap \\<equiv> gets (is_final_cap' cap)\"", "property": "Detect Final Capability: Determine if a capability is the last one referencing a specific object in the system, requiring finalization actions upon its deletion. \n\nIs Final Capability: Check if a capability is the final capability to an object by verifying that there are no other capabilities referencing the same object.", "title": "./spec/abstract/IpcCancel_A.thy", "chapter": "", "section": "", "comment": "Detect whether a capability is the final capability to a given object\nremaining in the system. Finalisation actions need to be taken when the final\ncapability to the object is deleted."}
{"spec": "(*\n * Operations on interrupt objects.\n *)\n\ntheory Interrupt_D\nimports Endpoint_D \"ExecSpec.Platform\"\nbegin\n\ncontext begin interpretation Arch .\nrequalify_types\n  irq\nend", "property": "Interrupt Object Operations: Provide operations for managing interrupt objects, including handling and manipulating interrupt requests (IRQs).", "title": "./spec/capDL/Interrupt_D.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "#INCLUDE_HASKELL SEL4/API/InvocationLabels/RISCV64.hs CONTEXT RISCV64_H ONLY ArchInvocationLabel\n\nend", "property": "Arch Invocation Labels: Define a set of architecture-specific system call labels for RISCV64.", "title": "./spec/design/skel/RISCV64/ArchInvocationLabels_H.thy", "chapter": "", "section": "", "comment": "\n  An enumeration of arch-specific system call labels.\n"}
{"spec": "fun\n  finalise_cap :: \"cdl_cap \\<Rightarrow> bool \\<Rightarrow> (cdl_cap \\<times> cdl_cap) k_monad\"\nwhere\n  \"finalise_cap NullCap                  final = return (NullCap, NullCap)\"\n| \"finalise_cap RestartCap               final = return (NullCap, NullCap)\"\n| \"finalise_cap (UntypedCap dev r a)           final = return (NullCap, NullCap)\"\n| \"finalise_cap (EndpointCap r b R)      final =\n      (liftM (K (NullCap, NullCap)) $ when  final $ cancel_all_ipc r)\"\n| \"finalise_cap (NotificationCap r b R) final =\n      (liftM (K (NullCap, NullCap)) $ when  final $\n       do\n         unbind_maybe_notification r;\n         cancel_all_ipc r\n       od)\"\n| \"finalise_cap (ReplyCap r R)           final = return (NullCap, NullCap)\"\n| \"finalise_cap (MasterReplyCap r)       final = return (NullCap, NullCap)\"\n| \"finalise_cap (CNodeCap r bits g sz)   final =\n      (return (if final then ZombieCap r else NullCap, NullCap))\"\n| \"finalise_cap (TcbCap r)               final =\n      (do\n         when final $ (do unbind_notification r;\n         cancel_ipc r;\n         KHeap_D.set_cap (r, tcb_pending_op_slot) cdl_cap.NullCap;\n         prepare_thread_delete r od);\n         return (if final then (ZombieCap r) else NullCap, NullCap)\n       od)\"\n| \"finalise_cap (PendingSyncSendCap r _ _ _ _ _) final = return (NullCap, NullCap)\"\n| \"finalise_cap (PendingSyncRecvCap r _ _) final = return (NullCap, NullCap)\"\n| \"finalise_cap (PendingNtfnRecvCap r)  final = return (NullCap, NullCap)\"\n| \"finalise_cap IrqControlCap            final = return (NullCap, NullCap)\"\n| \"finalise_cap (IrqHandlerCap irq)      final = (\n       if final then do\n         deleting_irq_handler irq;\n         return (NullCap, (IrqHandlerCap irq))\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (ZombieCap r)            final =\n      (do assert final; return (ZombieCap r, NullCap) od)\"\n| \"finalise_cap (AsidPoolCap ptr asid)        final = (\n       if final then do\n         delete_asid_pool asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap AsidControlCap           final = return (NullCap,NullCap)\"\n| \"finalise_cap (PageDirectoryCap ptr x (Some asid))   final = (\n       if final \\<and> x = Real then do\n         delete_asid asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (PageTableCap ptr x (Some asid))     final = (\n       if (final \\<and> x = Real) then do\n         unmap_page_table asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (FrameCap dev ptr _ s x (Some asid))       final = (\n       if x = Real then do\n         unmap_page asid ptr s;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap _ final = return (NullCap, NullCap)\"", "property": "Capability Deletion Actions: Ensure that when a capability is deleted, necessary actions are taken to maintain system integrity, such as canceling IPC, unbinding notifications, and updating kernel data structures. If deletion requires a long-running operation, a Zombie capability is returned, and a possible IRQ is cleared.\n\nSubproperties:\n- Cancel IPC and unbind notifications for Endpoint and Notification capabilities.\n- Update kernel data structures for CNode and Tcb capabilities.\n- Clear possible IRQ for IrqHandler capabilities.\n- Delete AsidPool, PageDirectory, PageTable, and Frame capabilities when finalising.\n- Return Zombie capability if deletion requires a long-running operation.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": "Actions that must be taken when a capability is deleted. Returns a\nZombie capability if deletion requires a long-running operation and also a\npossible IRQ to be cleared."}
{"spec": "tcb_pptr \\<leftarrow> create_objects tcb_bits tcb_bits TCBObject;", "property": "Allocate TCB: Creates and initializes a new TCB object with the specified number of bits, ensuring that the TCB is properly set up for thread management.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " allocate TCB "}
{"spec": "arch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=ARM CONTEXT ARM_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend", "property": "Architectural Constants and Definitions: Define and requalify architectural constants and functions, including word bits, pointer conversions, and null pointer representation, to ensure consistency and compatibility across different architectures.", "title": "./spec/design/skel/ARM/State_H.thy", "chapter": "", "section": "", "comment": " Note: while this requalify and arch-generic Haskell import of WordLib.lhs could be moved to\n   a generic theory, no good candidate theory exists at the moment. "}
{"spec": "definition\n  decode_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_intent \\<Rightarrow> cdl_invocation except_monad\"\nwhere\n  \"decode_invocation invoked_cap invoked_cap_ref caps intent \\<equiv>\n    case invoked_cap of\n       \\<comment> \\<open>For endpoint-like caps, we always perform an operation,\n          regardless of the user's actual intent.\\<close>\n         EndpointCap o_id badge rights \\<Rightarrow>\n           (if Write \\<in> rights then\n             returnOk $ InvokeEndpoint (SyncMessage badge (Grant \\<in> rights) (GrantReply \\<in> rights) o_id)\n           else\n             throw)\n       | NotificationCap o_id badge rights \\<Rightarrow>\n           (if Write \\<in> rights then\n             returnOk $ InvokeNotification (Signal badge o_id)\n           else\n             throw)\n       | ReplyCap o_id rights \\<Rightarrow>\n           returnOk $ InvokeReply (ReplyMessage o_id invoked_cap_ref (Grant \\<in> rights))\n\n       \\<comment> \\<open>\n         For other operations, we only perform the user's intent\n         if it matches up with the cap.\n        \n         Note that this does not currently match the current\n         implementation: instead, the user's message will be\n         decoded into a new (undefined) intent for what the\n         cap happened to be. I propose modifying labels used to\n         avoid overlaps between different items so that we can\n         recognise when the user is invoking the wrong item.\n       \\<close>\n       | CNodeCap _ _ _ _ \\<Rightarrow>\n           doE\n             cnode_intent \\<leftarrow> throw_opt undefined $ get_cnode_intent intent;\n             liftME InvokeCNode $ decode_cnode_invocation invoked_cap invoked_cap_ref caps cnode_intent\n           odE\n       | TcbCap _ \\<Rightarrow>\n           doE\n             tcb_intent \\<leftarrow> throw_opt undefined $ get_tcb_intent intent;\n             liftME InvokeTcb $ decode_tcb_invocation invoked_cap invoked_cap_ref caps tcb_intent\n           odE\n       | IrqControlCap \\<Rightarrow>\n           doE\n             irq_control_intent \\<leftarrow> throw_opt undefined $ get_irq_control_intent intent;\n             liftME InvokeIrqControl $ decode_irq_control_invocation\n                 invoked_cap invoked_cap_ref caps irq_control_intent\n           odE\n       | IrqHandlerCap _ \\<Rightarrow>\n           doE\n             irq_handler_intent \\<leftarrow> throw_opt undefined $ get_irq_handler_intent intent;\n             liftME InvokeIrqHandler $ decode_irq_handler_invocation\n                 invoked_cap invoked_cap_ref caps irq_handler_intent\n           odE\n       | AsidPoolCap _ _\\<Rightarrow>\n           doE\n             asid_pool_intent \\<leftarrow> throw_opt undefined $ get_asid_pool_intent intent;\n             liftME InvokeAsidPool $ decode_asid_pool_invocation\n                 invoked_cap invoked_cap_ref caps asid_pool_intent\n           odE\n       | AsidControlCap \\<Rightarrow>\n           doE\n             asid_control_intent \\<leftarrow> throw_opt undefined $ get_asid_control_intent intent;\n             liftME InvokeAsidControl $ decode_asid_control_invocation\n                 invoked_cap invoked_cap_ref caps asid_control_intent\n           odE\n       | UntypedCap _ _ _ \\<Rightarrow>\n           doE\n             untyped_intent \\<leftarrow> throw_opt undefined $ get_untyped_intent intent;\n             liftME InvokeUntyped $ decode_untyped_invocation\n                 invoked_cap invoked_cap_ref caps untyped_intent\n           odE\n       | FrameCap _ _ _ _ _ _ \\<Rightarrow>\n           doE\n             page_intent \\<leftarrow> throw_opt undefined $ get_page_intent intent;\n             liftME InvokePage $ decode_page_invocation\n                 invoked_cap invoked_cap_ref caps page_intent\n           odE\n       | PageTableCap _ _ _ \\<Rightarrow>\n           doE\n             page_table_intent \\<leftarrow> throw_opt undefined $ get_page_table_intent intent;\n             liftME InvokePageTable $ decode_page_table_invocation\n                 invoked_cap invoked_cap_ref caps page_table_intent\n           odE\n       | PageDirectoryCap _ _ _ \\<Rightarrow>\n          doE\n             page_directory_intent \\<leftarrow> throw_opt undefined $ get_page_directory_intent intent;\n             liftME InvokePageDirectory $ decode_page_directory_invocation\n                 invoked_cap invoked_cap_ref caps page_directory_intent\n           odE\n       | DomainCap \\<Rightarrow>\n          doE\n            domain_intent \\<leftarrow> throw_opt undefined $ get_domain_intent intent;\n            liftME InvokeDomain $ decode_domain_invocation caps domain_intent\n          odE\n\n       \\<comment> \\<open>Don't support operations on other types of caps.\\<close>\n       | _ \\<Rightarrow> throw\"\n\nend", "property": "Decode and Validate Intent: Decode the given intent into an appropriate invocation based on the type of capability. For endpoint-like capabilities, perform a specific operation regardless of the user's intent. For other capabilities, validate that the user's intent matches the capability type before proceeding with the corresponding invocation. If the intent does not match or the capability type is unsupported, the operation is aborted.", "title": "./spec/capDL/Decode_D.thy", "chapter": "", "section": "", "comment": "\n * Decode and validate the given intent, turning it into an\n * invocation.\n "}
{"spec": "lemma island_e0:\n  \"island s 0 = {i. i \\<noteq> 1 \\<and> i \\<noteq> 2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (drule (1) e0_connected_to)\n  apply (drule directly_tgs_connected_comm)\n  by (metis directly_tgs_connected_def2 tgs_connected_comm leakImplyConnectedTrans)\n\nlemma island_e1:\n  \"island s 1 = {1,2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (rule e1_connected_trans_to_e2)\n  done\n\nlemma island_e2:\n  \"island s 2 = {1,2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (rule e1_connected_trans_to_e2  [THEN tgs_connected_comm])\n  done\n\nlemma island_e3:\n  \"\\<lbrakk>x \\<noteq> 1; x \\<noteq> 2\\<rbrakk> \\<Longrightarrow> island s x =  {i. i \\<noteq> 1 \\<and> i \\<noteq> 2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (frule_tac x=x  in e0_connected_to, simp)\n  apply (frule_tac x=xa in e0_connected_to, simp)\n  apply (drule_tac x=0 and y=xa in directly_tgs_connected_comm)\n  apply (rule tgs_connected_comm)\n  apply (simp add: tgs_connected_def)\n  done", "property": "Island Formation: The island function defines the set of elements connected to a given element in the system. Specifically, elements 1 and 2 form an isolated island, while all other elements (excluding 1 and 2) form a separate island. This ensures that the connectivity and isolation properties are maintained within the system.", "title": "./spec/take-grant/Example2.thy", "chapter": "", "section": "", "comment": "*******************************"}
{"spec": "lemmas ThreadState_defs = StrictC'_thread_state_defs", "property": "Thread State Definitions Collection: Provide an alias for a collection of thread state definitions for easier reference and usage.", "title": "./spec/cspec/RISCV64/Kernel_C.thy", "chapter": "", "section": "", "comment": "Add a more usable name for the collection of ThreadState definitions"}
{"spec": "definition perform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_page_table_invocation iv \\<equiv> case iv of\n     PageTableMap cap ct_slot pte slot \\<Rightarrow> perform_pt_inv_map cap ct_slot pte slot\n   | PageTableUnmap cap ct_slot \\<Rightarrow> perform_pt_inv_unmap cap ct_slot\"\n\nlocale_abbrev arch_no_return :: \"(unit, 'z::state_ext) s_monad \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\n  where\n  \"arch_no_return oper \\<equiv> do oper; return [] od\"", "property": "Page Table Invocation Actions: Allow mapping and unmapping of page tables, conferring the authority to manage page table capabilities. \n\nMapping: Map a page table into a capability table slot with a specified page table entry.\nUnmapping: Unmap a page table from a capability table slot.", "title": "./spec/abstract/RISCV64/Arch_A.thy", "chapter": "", "section": "", "comment": "PageTable capabilities confer the authority to map and unmap page tables."}
{"spec": "| BoundNotificationCap cdl_object_id", "property": "Bound Notification Capability: Represents a capability that signifies a TCB is bound to a notification, allowing the TCB to receive and handle notifications.", "title": "./spec/capDL/Types_D.thy", "chapter": "", "section": "", "comment": " Bound NTFN caps signifying when a tcb is bound to an NTFN "}
{"spec": "hide_const (open)\n  numDomains", "property": "Hide Unqualified Names: Ensures that unqualified names conflicting with Kernel_Config names are hidden, requiring the use of the Kernel_C prefix to access these names.", "title": "./spec/cspec/ARM/Kernel_C.thy", "chapter": "", "section": "", "comment": "Hide unqualified names conflicting with Kernel_Config names. Force use of Kernel_C prefix\n  for these:"}
{"spec": "(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"sanitise_register t r v \\<equiv> case r of\n      CPSR \\<Rightarrow>\n       if t \\<and>\n          v && 0x1f \\<in> {0x10, 0x11, 0x12, 0x13, 0x17, 0x1b, 0x1f}\n            \\<comment> \\<open>@{text \\<open>PMODE_(USER/FIQ/IRQ/SUPERVISOR/ABORT/UNDEFINED/SYSTEM)\\<close>}\\<close>\n       then v\n       else (v && 0xf8000000) || 0x150\n    | _    \\<Rightarrow> v\"\n\ndefinition\n  arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\nwhere\n  \"arch_get_sanitise_register_info t \\<equiv> do\n          vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n          return (vcpu \\<noteq> None)\n   od\"\n\ndefinition\n  arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\nwhere\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend", "property": "TCB Register Management: Sanitizes and manages registers, ensuring that certain registers are modified according to specific rules, while others remain unchanged.\n\nSubproperties:\n- Sanitize Register: Modifies the CPSR register to ensure it only contains specific values, otherwise, it sets the register to a default value.\n- Get Sanitise Register Info: Retrieves information about whether the thread's VCPU is set, indicating whether sanitization is required.\n- Post Modify Registers: Currently a no-op, intended to perform additional actions after modifying registers.", "title": "./spec/abstract/ARM_HYP/ArchTcb_A.thy", "chapter": "Architecture-specific TCB functions", "section": "", "comment": ""}
{"spec": "definition\n  move_cap :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"move_cap cap src_slot dest_slot \\<equiv> do\n     insert_cap_orphan cap dest_slot;\n     set_cap src_slot NullCap;\n     swap_parents src_slot dest_slot\n  od\"\n\ndefinition\n  monadic_rel_optionation_form :: \"('a \\<Rightarrow> ('s, 'b) nondet_monad)\n      \\<Rightarrow> (('a \\<times> 's) option \\<times> ('b \\<times> 's) option) set\"\nwhere\n \"monadic_rel_optionation_form f =\n    {(x, y). (x \\<noteq> None \\<and> y \\<noteq> None \\<and> the y \\<in> fst (case_prod f (the x)))\n           \\<or> (x \\<noteq> None \\<and> y = None \\<and> snd (case_prod f (the x)))\n           \\<or> (x = None \\<and> y = None)}\"\n\ndefinition\n  monadic_option_dest :: \"('a \\<times> 's) option set \\<Rightarrow> (('a \\<times> 's) set \\<times> bool)\"\nwhere\n \"monadic_option_dest S = (Some -` S, None \\<in> S)\"\n\nlemma use_option_form:\n  \"f x = (\\<lambda>s. monadic_option_dest  (monadic_rel_optionation_form f `` {Some (x, s)}))\"\n  by (simp add: monadic_rel_optionation_form_def monadic_option_dest_def)\n\nlemma ex_option: \" (\\<exists>x. P x) = ((\\<exists>y. P (Some y)) \\<or> P None)\"\n  apply safe\n  apply (case_tac x, auto)\n  done\n\nlemma use_option_form_bind:\n  \"f x >>= g = (\\<lambda>s. monadic_option_dest\n       ((monadic_rel_optionation_form f O monadic_rel_optionation_form g) `` {Some (x, s)}))\"\n  apply (rule ext)\n  apply (simp add: monadic_rel_optionation_form_def monadic_option_dest_def\n                   bind_def split_def)\n  apply (simp add: relcomp_unfold ex_option image_def prod_eq_iff Bex_def)\n  apply fastforce\n  done\n\ndefinition\n  monadic_trancl :: \"('a \\<Rightarrow> ('s, 'a) nondet_monad)\n       \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad\"\nwhere\n \"monadic_trancl f x = (\\<lambda>s. monadic_option_dest ((monadic_rel_optionation_form f)\\<^sup>* `` {Some (x, s)}))\"\n\ndefinition\n  monadic_trancl_preemptible ::\n     \"('a \\<Rightarrow> ('s, 'e + 'a) nondet_monad)\n         \\<Rightarrow> ('a \\<Rightarrow> ('s, 'e + 'a) nondet_monad)\"\nwhere\n \"monadic_trancl_preemptible f x\n    = monadic_trancl (lift f) (Inr x)\"\n\ndefinition\n  cap_removeable :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> bool\"\nwhere\n \"cap_removeable cap slot s =\n   (cap = NullCap\n      \\<or> (\\<exists>p. cap = ZombieCap p \\<and> swp opt_cap s ` (({p} \\<times> UNIV) - {slot})\n              \\<subseteq> {Some NullCap, None}))\"\n\ndefinition\n  finalise_slot_inner1 :: \"cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> bool) k_monad\"\nwhere\n \"finalise_slot_inner1 victim = do\n    cap \\<leftarrow> get_cap victim;\n    final \\<leftarrow> is_final_cap cap;\n    (cap', irqopt) \\<leftarrow> finalise_cap cap final;\n    removeable \\<leftarrow> gets $ cap_removeable cap' victim;\n    when (\\<not> removeable) (set_cap victim cap')\n        \\<sqinter> set_cap victim cap';\n    return (cap', removeable)\n  od\"\n\ndefinition\n  get_zombie_range :: \"cdl_cap \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n \"get_zombie_range cap =\n    (\\<lambda>s. case cap of ZombieCap p \\<Rightarrow> dom (swp opt_cap s) \\<inter> ({p} \\<times> UNIV)\n               | _ \\<Rightarrow> {})\"\n\ndefinition\n  swap_for_delete :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n \"swap_for_delete ptr1 ptr2 = do\n    cap1 \\<leftarrow> get_cap ptr1;\n    cap2 \\<leftarrow> get_cap ptr2;\n    swap_cap cap1 ptr1 cap2 ptr2\n  od\"\n\ndefinition\n \"finalise_slot_inner2 =\n      (\\<lambda>(region, finalised).\n        liftE (do (victim', remove) \\<leftarrow> select region;\n          (cap', removeable) \\<leftarrow> finalise_slot_inner1 victim';\n          region' \\<leftarrow> gets $ get_zombie_range cap';\n          return (region \\<union> (region' \\<times> {True}), if removeable then {(victim', remove)} else {})\n        od) \\<sqinter>\n        liftE (do (slot, slot') \\<leftarrow> select {(x, y). (x, True) \\<in> region \\<and> (y, True) \\<in> region \\<and> x \\<noteq> y};\n          swap_for_delete slot slot';\n          return (region, {})\n        od) \\<sqinter>\n        liftE (do victim' \\<leftarrow> select {x. (x, True) \\<in> finalised};\n          empty_slot victim';\n          return (region, {})\n        od) \\<sqinter>\n        throw\n      )\"\n\ndefinition\n  finalise_slot :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n \"finalise_slot victim = doE\n    (region, finalised) \\<leftarrow>\n      monadic_trancl_preemptible finalise_slot_inner2\n        ({(victim, False)}, {});\n    whenE (victim \\<notin> fst ` finalised) throw\n  odE\"\n\ndefinition\n  delete_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n \"delete_cap victim = doE\n    finalise_slot victim;\n    liftE $ empty_slot victim\n  odE\"", "property": "Cap Management: Move, finalise, and delete capabilities while maintaining system integrity, ensuring that capability removal and deletion are handled correctly and securely.\n\nSubproperties:\n- Capability Movement: Move a capability from one location to another, possibly modifying it in the process.\n- Capability Finalisation: Finalise a capability, handling its removal and ensuring system integrity.\n- Capability Deletion: Delete a capability, securely removing it from the system.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": "\n * Move the given cap from one location to another,\n * possibly modifying it along the way.\n "}
{"spec": "SyncMessage cdl_badge bool bool cdl_object_id\n\ndatatype cdl_notification_invocation =", "property": "Notification Invocation: Allows the management of notifications, including setting a badge, granting, and replying to notifications. This ensures that threads can communicate and coordinate effectively through notification mechanisms.", "title": "./spec/capDL/Invocations_D.thy", "chapter": "", "section": "", "comment": " badge, grant, grant reply, ep "}
{"spec": "definition\nunmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page pgsz asid vptr pptr \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    (case pgsz of\n          ARMSmallPage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                store_pte p InvalidPTE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMLargePage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                assert $ p && mask 7 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) largePagePTE_offsets);\n                mapM (swp store_pte InvalidPTE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE\n        | ARMSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                store_pde p InvalidPDE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMSuperSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                assert $ p && mask 7 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) superSectionPDE_offsets);\n                mapM (swp store_pde InvalidPDE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE);\n    liftE $ flush_page pgsz pd asid vptr\nodE <catch> (K $ return ())\"", "property": "Unmap Page: Unmaps a page from the virtual address space if the provided mapping details are still current. This involves finding the appropriate page directory, checking the mapping, invalidating the corresponding page table entry or page directory entry, and cleaning the cache. The operation ensures that the page is properly unmapped and the cache is updated to reflect the changes.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Unmap a mapped page if the given mapping details are still current."}
{"spec": "definition\n  update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 18;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"", "property": "Cnode Capability Modification: Extract new guard bits and guard from user-provided data for modifying a cnode capability.", "title": "./spec/abstract/ARM/ArchCSpace_A.thy", "chapter": "", "section": "", "comment": "On a user request to modify a cnode capability, extract new guard bits and guard."}
{"spec": "definition\n  has_children :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> bool\"\nwhere\n  \"has_children parent s = (\\<exists>child. is_cdt_parent s parent child)\"", "property": "Check Capability Children Existence: Determine if a given capability has any child capabilities in the current state.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": " Does the given cap have any children? "}
{"spec": "#INCLUDE_HASKELL SEL4.lhs decls_only NOT callKernel\n\n#INCLUDE_HASKELL SEL4.lhs NOT kernelExitAssertions fastpathKernelAssertions\n\nend", "property": "API Module Collection: Aggregates all API modules, providing a comprehensive set of functions and declarations for the system.", "title": "./spec/design/skel/API_H.thy", "chapter": "", "section": "", "comment": "collects all API modules"}
{"spec": "| IOPortsCap cdl_object_id \"cdl_io_port set\"\n  | IOSpaceMasterCap\n  | IOSpaceCap cdl_object_id\n  | IOPageTableCap cdl_object_id", "property": "X86-Specific Capabilities: Provide capabilities for managing x86-specific resources, including I/O ports, I/O spaces, and I/O page tables. \n\nSubproperties:\n- I/O Port Management: Manage access to specific I/O ports.\n- I/O Space Management: Control I/O spaces, including master and specific I/O space capabilities.\n- I/O Page Table Management: Manage I/O page tables for efficient memory management.", "title": "./spec/capDL/Types_D.thy", "chapter": "", "section": "", "comment": " x86-specific capabilities "}
{"spec": "definition\n  same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n \"same_aobject_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (PageCap dev ref _ pgsz _,PageCap dev' ref' _ pgsz' _)\n          \\<Rightarrow> (dev, ref, pgsz) = (dev', ref', pgsz')\n              \\<and> ref \\<le> ref + 2 ^ pageBitsForSize pgsz - 1\n    | _ \\<Rightarrow> arch_same_region_as cp cp')\"", "property": "Check Arch Capabilities for Same Object: Determine if two architecture capabilities refer to the same object by comparing their device, reference, and page size, and ensuring the reference is within the valid range. If they are not of the same type, use a generic region comparison.", "title": "./spec/abstract/ARM/ArchCSpace_A.thy", "chapter": "", "section": "", "comment": "Check whether two arch capabilities are to the same object."}
{"spec": "definition\n  revoke_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"revoke_cap victim = doE\n     fin \\<leftarrow> monadic_trancl_preemptible (K (doE\n          S \\<leftarrow> liftE $ gets $ descendants_of victim;\n          if S = {} then returnOk True\n          else doE\n            child \\<leftarrow> liftE $ select S;\n            cap \\<leftarrow> liftE $ get_cap child;\n            assertE (cap \\<noteq> NullCap);\n            delete_cap child;\n            Monads_D.throw \\<sqinter> returnOk False\n          odE\n       odE)) False;\n     unlessE fin throw\n   odE\"", "property": "Revoke Capability: Revoke all descendants of a given capability, deleting them if the Capability Derivation Tree (CDT) is being modeled, and handling potential recursive deletion of capabilities containing the cap being revoked.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": "\n * Revoke all the descendants of the given cap.\n *\n * If the CDT is being modelled, this will delete all the\n * descendants of the given cap. Wonderful things happen\n * if we happen to, in this process, delete something\n * that contains the cap we are trying to revoke.\n "}
{"spec": "end_qualify\n\ncontext Arch begin arch_global_naming (A)", "property": "RISCV64 Global Page Tables: The architecture-specific state includes generalized global page tables, with constraints that limit the set of tables at the maximum page table level to a singleton and ensure that the ASID pool level contains no tables. Other levels may have multiple or no tables, depending on kernel initialization.", "title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "chapter": "RISCV64-Specific Data Types", "section": "Architecture-specific state", "comment": "\n  The @{const riscv_global_pts} generalise the concept of global page tables.\n  The invariants will constrain the set of tables for @{term max_pt_level} to a\n  singleton, and for @{term asid_pool_level} to empty. All other levels may contain\n  multiple or no tables, depending on how kernel initialisation sets up the kernel window.\n"}
{"spec": "(*\n * The basic monads used in capDL\n *)\n\ntheory Monads_D\nimports\n  Types_D\n  Monads.Nondet_In_Monad\n  Monads.Nondet_VCG\nbegin", "property": "No specific property can be summarized from the given code as it only contains imports and no actual specification or implementation details.", "title": "./spec/capDL/Monads_D.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "definition\n  do_kernel_op :: \"('a,'z::state_ext) s_monad \\<Rightarrow> ('a,'z) ki_monad\" where\n \"do_kernel_op kop \\<equiv> liftE $ do\n    ms \\<leftarrow> gets ki_kernel_state;\n    (r, ms') \\<leftarrow> select_f (kop ms);\n    modify (\\<lambda>ks. ks \\<lparr> ki_kernel_state := ms' \\<rparr>);\n    return r\n  od\"", "property": "Lift Kernel State Monad Operations: Elevate operations from the kernel state monad to the kernel init monad, ensuring that the kernel state is properly updated and the result is returned.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init monad", "comment": "Lift kernel state monad ops to the kernel init monad."}
{"spec": "lemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\ndefinition check_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_valid_ipc_buffer vptr c \\<equiv>\n     case c of\n       ArchObjectCap (FrameCap _ _ _ False _) \\<Rightarrow>\n         whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError\n     | _ \\<Rightarrow> throwError IllegalOperation\"", "property": "Check Valid IPC Buffer: Validate the alignment of the virtual pointer for an IPC buffer. If the virtual pointer is not aligned according to the specified `msg_align_bits`, an `AlignmentError` is thrown. For any other type of capability, an `IllegalOperation` error is thrown.", "title": "./spec/abstract/AARCH64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Make numeric value of @{const msg_align_bits} visible."}
{"spec": "create_initial_thread root_cnode_cap it_pd_cap v_entry bi_frame_vptr\n                           (snd ipcbuf_ret) (fst ipcbuf_ret);", "property": "Create Initial Thread: Create the initial thread with the specified root capability node, initial thread page directory capability, virtual entry point, boot info frame virtual pointer, IPC buffer virtual address, and IPC buffer capability.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " create_initial_thread "}
{"spec": "definition clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"", "property": "Clear Memory: Clears a specified number of bits starting from a given memory address.", "title": "./spec/machine/RISCV64/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": "Haskell simulator interface stub."}
{"spec": "theory Example2\nimports Isolation_S\nbegin\n\nlemma direct_caps_of_update [simp]:\n  \"direct_caps_of (s(x := y)) =\n  (direct_caps_of s)(x:= case y of None \\<Rightarrow> {} | Some (Entity c) \\<Rightarrow> c)\"\n  by (rule ext, simp add: direct_caps_of_def split:option.splits)\n\nlemma direct_caps_of_empty [simp]:\n  \"direct_caps_of Map.empty = ( \\<lambda> x. {})\"\n  by (simp add: direct_caps_of_def fun_eq_iff)\n\ndefinition \"id\\<^sub>0 \\<equiv> 0\"\ndefinition \"id\\<^sub>1 \\<equiv> 1\"\ndefinition \"id\\<^sub>2 \\<equiv> 2\"\ndefinition \"id\\<^sub>3 \\<equiv> 3\"\ndefinition \"id\\<^sub>4 \\<equiv> 4\"\ndefinition \"id\\<^sub>5 \\<equiv> 5\"", "property": "Direct Caps Update: The direct capabilities of a system state are updated when an entity is added or removed, ensuring that the capabilities are correctly propagated.\nEmpty Direct Caps: The direct capabilities of an empty system state are empty for all entities.", "title": "./spec/take-grant/Example2.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "lemmas ThreadState_defs = StrictC'_thread_state_defs", "property": "Thread State Definitions Collection: Provide an alias for a collection of thread state definitions for easier reference and usage.", "title": "./spec/cspec/X64/Kernel_C.thy", "chapter": "", "section": "", "comment": "Add a more usable name for the collection of ThreadState definitions"}
{"spec": "definition condition ::\n  \"('s \\<Rightarrow> bool) \\<Rightarrow> ('s, 'r) nondet_monad \\<Rightarrow> ('s, 'r) nondet_monad \\<Rightarrow> ('s, 'r) nondet_monad\"\n  where\n  \"condition P L R \\<equiv> \\<lambda>s. if (P s) then (L s) else (R s)\"\n\nnotation (output)\n  condition  (\"(condition (_)//  (_)//  (_))\" [1000,1000,1000] 1000)", "property": "Conditional Execution: Execute one of two monads based on a condition applied to the current state. If the condition is true, execute the first monad; otherwise, execute the second monad.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "\n  Perform a test on the current state, performing the left monad if\n  the result is true or the right monad if the result is false. "}
{"spec": "type_synonym cnode_contents = \"cnode_index \\<Rightarrow> cap option\"", "property": "CNode Contents: A CNode is represented as an array of capability slots, where each slot is indexed and may contain a capability or be empty (Null capability).", "title": "./spec/abstract/Structures_A.thy", "chapter": "", "section": "", "comment": "The CNode object is an array of capability slots. The domain of the\nfunction will always be the set of boolean lists of some specific length.\nEmpty slots contain a Null capability.\n"}
{"spec": "chapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT RISCV64_H\n#INCLUDE_HASKELL_PREPARSE SEL4/API/InvocationLabels/RISCV64.hs CONTEXT RISCV64\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/RISCV64.hs CONTEXT RISCV64_H decls_only ArchInv= NOT lookupPTSlotFromLevel lookupPTFromLevel\n\nend (* context RISCV64 *)\n\nend", "property": "Object Retyping: Allows the redefinition of an object's type and structure, enabling the transformation of one type of object into another. This process ensures that the system can dynamically adapt and manage memory and resources efficiently.", "title": "./spec/design/skel/RISCV64/ArchVSpaceDecls_H.thy", "chapter": "Retyping Objects", "section": "", "comment": ""}
{"spec": "consts'\n  writeContextIDAndPD_impl :: \"hardware_asid \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeContextIDAndPD :: \"hardware_asid \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere \"writeContextIDAndPD a b \\<equiv> machine_op_lift (writeContextIDAndPD_impl a b)\"\n\nconsts'\n  HSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  HDFAR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  SCTLR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  ACTLR_val :: \"machine_state \\<Rightarrow> machine_word\"\n\ndefinition\n  getHSR :: \"machine_word machine_monad\"\nwhere \"getHSR \\<equiv> gets HSR_val\"\n\ndefinition\n  getHDFAR :: \"machine_word machine_monad\"\nwhere \"getHDFAR \\<equiv> gets HDFAR_val\"\n\nconsts'\n  setHCR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setHCR :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setHCR w \\<equiv> machine_op_lift (setHCR_impl w)\"\n\nconsts'\n  addressTranslateS1_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\n  addressTranslateS1_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  addressTranslateS1 :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"addressTranslateS1 w \\<equiv> do\n    machine_op_lift (addressTranslateS1_impl w);\n    gets (addressTranslateS1_val w)\n  od\"\n\ndefinition\n  getSCTLR :: \"machine_word machine_monad\"\nwhere \"getSCTLR \\<equiv> gets SCTLR_val\"\n\nconsts'\n  setSCTLR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setSCTLR :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setSCTLR w \\<equiv> machine_op_lift (setSCTLR_impl w)\"\n\ndefinition\n  vgic_irq_active :: \"machine_word\"\nwhere\n  \"vgic_irq_active \\<equiv> 2 << 28\"\n\ndefinition\n  vgic_irq_mask :: \"machine_word\"\nwhere\n  \"vgic_irq_mask \\<equiv> 3 << 28\"\n\nconsts'\n  gic_vcpu_ctrl_hcr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_hcr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_hcr \\<equiv> gets gic_vcpu_ctrl_hcr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_hcr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_hcr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_hcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_hcr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_vmcr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_vmcr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_vmcr \\<equiv> gets gic_vcpu_ctrl_vmcr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_vmcr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_vmcr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_vmcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vmcr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_apr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_apr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_apr \\<equiv> gets gic_vcpu_ctrl_apr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_apr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_apr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_apr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_apr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_vtr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_vtr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_vtr \\<equiv> gets gic_vcpu_ctrl_vtr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_vtr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_vtr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_vtr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vtr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_misr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_misr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_misr \\<equiv> gets gic_vcpu_ctrl_misr_val\"\n\nconsts'\n  gic_vcpu_ctrl_eisr0_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_eisr0 :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_eisr0 \\<equiv> gets gic_vcpu_ctrl_eisr0_val\"\n\nconsts'\n  gic_vcpu_ctrl_eisr1_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_eisr1 :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_eisr1 \\<equiv> gets gic_vcpu_ctrl_eisr1_val\"\n\nconsts'\n  get_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\n  gic_vcpu_ctrl_lr_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_lr n \\<equiv> do\n      machine_op_lift (get_gic_vcpu_ctrl_lr_impl n);\n      gets (gic_vcpu_ctrl_lr_val n)\n    od\"\n\nconsts'\n  set_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_lr n w  \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_lr_impl n w)\"", "property": "Machine Operations: Provide low-level machine operations for managing hardware resources, including writing context IDs and page directories, getting and setting system registers (HSR, HDFAR, SCTLR, etc.), performing address translations, and controlling GIC (Generic Interrupt Controller) vCPU settings. These operations ensure that the kernel can interact with the hardware efficiently and securely.\n\nSubproperties:\n\n* System Register Management: Get and set system registers, such as HSR, HDFAR, SCTLR, and ACTLR.\n* Address Translation: Perform address translations using the addressTranslateS1 operation.\n* GIC vCPU Control: Get and set GIC vCPU control registers, including HCR, VMCR, APR, VTR, MISR, EISRs, and LRs.", "title": "./spec/machine/ARM_HYP/MachineOps.thy", "chapter": "Machine Operations", "section": "User Monad", "comment": ""}
{"spec": "\"ops \\<equiv> [op10, op9, op8, op7, op3, op2, op1, op0]\"", "property": "Operation Sequence: Define a sequence of operations, excluding op6 and op5, to be used in the system.", "title": "./spec/take-grant/Example2.thy", "chapter": "", "section": "", "comment": " since the CDT isn't defined, op6 is skipped\n  \"ops \\<equiv> [op10, op9, op8, op7, op6, op5, op4, op3, op2, op1, op0]\"\n"}
{"spec": "datatype (discs_sels) arch_kernel_obj =\n    ASIDPool asid_pool\n  | PageTable pt\n  | DataPage bool vmpage_size\n  | VCPU vcpu\n\ndefinition asid_pool_of :: \"arch_kernel_obj \\<rightharpoonup> asid_pool\" where\n  \"asid_pool_of ko \\<equiv> case ko of ASIDPool pool \\<Rightarrow> Some pool | _ \\<Rightarrow> None\"\n\ndefinition pt_of :: \"arch_kernel_obj \\<rightharpoonup> pt\" where\n  \"pt_of ko \\<equiv> case ko of PageTable pt \\<Rightarrow> Some pt | _ \\<Rightarrow> None\"\n\ndefinition vcpu_of :: \"arch_kernel_obj \\<rightharpoonup> vcpu\" where\n  \"vcpu_of ko \\<equiv> case ko of VCPU vcpu \\<Rightarrow> Some vcpu | _ \\<Rightarrow> None\"\n\ndefinition pte_bits :: nat where\n  \"pte_bits = word_size_bits\"\n\ndefinition table_size :: \"pt_type \\<Rightarrow> nat\" where\n  \"table_size pt_t = ptTranslationBits pt_t + pte_bits\"\n\ndefinition pt_bits :: \"pt_type \\<Rightarrow> nat\" where\n  \"pt_bits pt_t \\<equiv> table_size pt_t\"", "property": "Architecture-Specific Kernel Objects: Define and categorize architecture-specific kernel objects, including ASID pools, page tables, data pages, and VCPUs. Discriminators and selectors are provided for each type, allowing for the extraction of specific components such as ASID pools, page tables, and VCPUs from the kernel object.", "title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "chapter": "AARCH64-Specific Data Types", "section": "Architecture-specific object types and default objects", "comment": " produce discriminators and selectors even though no field names are mentioned "}
{"spec": "definition\n  arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n    (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n    delete_asid_pool b ptr;\n    return (NullCap, NullCap)\n    od\n  | (PML4Cap ptr (Some a), True) \\<Rightarrow> do\n    delete_asid a ptr;\n    return (NullCap, NullCap)\n  od\n  | (PDPointerTableCap ptr (Some (a,v)), True) \\<Rightarrow> do\n    unmap_pdpt a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageDirectoryCap ptr (Some (a,v)), True) \\<Rightarrow> do\n    unmap_pd a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n    unmap_page_table a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageCap _ ptr _ _ s (Some (a, v)), _) \\<Rightarrow> do\n     unmap_page s a v ptr;\n     return (NullCap, NullCap)\n  od\n  | (IOPortCap f l, True) \\<Rightarrow> return (NullCap, (ArchObjectCap (IOPortCap f l)))\n  \\<comment> \\<open>FIXME x64-vtd: IOSpaceCap and IOPageTableCap for @{text arch_finalise_cap}\\<close>\n  | _ \\<Rightarrow> return (NullCap, NullCap)\"", "property": "X64 Capability Finalisation: Ensure that x64-specific capabilities are properly finalised by deleting or unmapping relevant architecture-specific objects, such as ASID pools, page tables, and page directories, when they are no longer needed.\n\nSubproperties:\n- ASID Pool Deletion: Delete ASID pools when their corresponding capability is finalised.\n- Page Table and Directory Unmapping: Unmap page tables, page directories, and PDPTs when their corresponding capability is finalised.\n- Page Unmapping: Unmap pages when their corresponding capability is finalised, considering the page size.\n- IOPort Capability Preservation: Preserve IOPort capabilities when finalising, returning the same capability.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Actions that must be taken on finalisation of x64-specific\ncapabilities."}
{"spec": "definition loadWord :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\n  where\n  \"loadWord p \\<equiv> do\n     m \\<leftarrow> gets underlying_memory;\n     assert (p && mask 3 = 0);\n     return (word_rcat (map (\\<lambda>i. m (p + (7 - of_int i))) [0 .. 7]))\n   od\"\n\ndefinition storeWord :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"storeWord p w \\<equiv> do\n     assert (p && mask 3 = 0);\n     modify (underlying_memory_update\n              (fold (\\<lambda>i m. m((p + (of_int i)) := word_rsplit w ! (7 - nat i))) [0 .. 7]))\n   od\"\n\nlemma upto0_7_def:\n  \"[0..7] = [0,1,2,3,4,5,6,7]\" by eval\n\nlemma loadWord_storeWord_is_return:\n  \"p && mask 3 = 0 \\<Longrightarrow> (do w \\<leftarrow> loadWord p; storeWord p w od) = return ()\"\n  by (auto simp: loadWord_def storeWord_def bind_def assert_def return_def word_rsplit_rcat_size\n                 modify_def gets_def get_def eval_nat_numeral put_def upto0_7_def word_size)\n\nconsts' memory_regions :: \"(paddr \\<times> paddr) list\"\ndefinition getMemoryRegions :: \"(paddr * paddr) list machine_monad\"\n  where\n  \"getMemoryRegions \\<equiv> return memory_regions\"", "property": "Memory Management: Provides fundamental operations for managing memory at the machine level, including loading and storing words, and retrieving memory regions. Ensures that memory operations are correctly aligned and that memory regions are accurately defined.", "title": "./spec/machine/RISCV64/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": ""}
{"spec": "it_ap_cap \\<leftarrow> create_it_asid_pool root_cnode_cap;\n     do_kernel_op $ write_it_asid_pool it_ap_cap it_pd_cap;\n\n     create_idle_thread;", "property": "Kernel Initialization: Create and initialize the initial thread's ASID pool, and write it to the IT ASID pool. Additionally, create the idle thread to ensure the kernel's basic execution environment is set up correctly. \n\nSubproperties:\n- ASID Pool Creation: Create the initial thread's ASID pool using the root CNode capability.\n- ASID Pool Initialization: Write the created ASID pool to the IT ASID pool using the IT PD capability.\n- Idle Thread Creation: Create the idle thread to establish a foundational execution context for the kernel.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " create/init initial thread's ASID pool "}
{"spec": "text \\<open>Threads fault when they attempt to access services that are not backed\nby any resources. Such a thread is then blocked and a fault messages is sent to\nits supervisor. When a reply to that message is sent the thread is reactivated.\n\\<close>", "property": "Fault Handling: A thread that attempts to access services without backing resources is blocked and a fault message is sent to its supervisor, allowing for reactivation upon receiving a reply.", "title": "./spec/abstract/Ipc_A.thy", "chapter": "IPC", "section": "Fault Handling", "comment": ""}
{"spec": "definition\nhandle_vm_fault :: \"obj_ref \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n\"handle_vm_fault thread fault_type = doE\n    addr \\<leftarrow> liftE $ do_machine_op getFaultAddress;\n    fault \\<leftarrow> liftE $ as_user thread $ getRegister ErrorRegister;\n    case fault_type of\n        X64DataFault \\<Rightarrow> throwError $ ArchFault $ VMFault addr [0, fault && mask 5]\n      | X64InstructionFault \\<Rightarrow> throwError $ ArchFault $ VMFault addr [1, fault && mask 5]\nodE\"\n\ndefinition\n  get_current_cr3 :: \"(cr3, 'z::state_ext) s_monad\"\nwhere\n  \"get_current_cr3 \\<equiv> gets (x64_current_cr3 \\<circ> arch_state)\"\n\ndefinition\n  set_current_cr3 :: \"cr3 \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_current_cr3 c \\<equiv>\n     modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>x64_current_cr3 := c\\<rparr>\\<rparr>)\"\n\ndefinition\n  invalidate_page_structure_cache_asid :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"invalidate_page_structure_cache_asid vspace asid \\<equiv>\n     do_machine_op $ invalidateLocalPageStructureCacheASID vspace (ucast asid)\"\n\ndefinition\n  getCurrentVSpaceRoot :: \"(obj_ref, 'z::state_ext) s_monad\"\nwhere\n  \"getCurrentVSpaceRoot \\<equiv> do\n      cur \\<leftarrow> get_current_cr3;\n      return $ cr3_base_address cur\n   od\"\n\ndefinition\n  \"cr3_addr_mask \\<equiv> mask pml4_shift_bits << asid_bits\"\n\ndefinition\n  make_cr3 :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> cr3\"\nwhere\n  \"make_cr3 vspace asid \\<equiv> cr3 (vspace && cr3_addr_mask) asid\"\n\ndefinition\n  set_current_vspace_root :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"set_current_vspace_root vspace asid \\<equiv> set_current_cr3 $ make_cr3 vspace asid\"", "property": "VM Fault Handling: Formats a VM fault message to be passed to a thread's supervisor after encountering a page fault, providing the fault address and relevant error information.\n\nPage Table Management: Provides functions to manage the current CR3 (page table root), including getting and setting its value, invalidating the page structure cache for a given ASID, and constructing a new CR3 value from a given virtual space address and ASID.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Format a VM fault message to be passed to a thread's supervisor after\nit encounters a page fault."}
{"spec": "lemma le_maxIRQ_machine_less_irqBits_val[simplified]:\n  \"w \\<le> maxIRQ \\<Longrightarrow> unat w < 2^LENGTH(irq_len)\" for w::machine_word\n  using maxIRQ_less_2p_irq_len\n  by (simp add: word_le_nat_alt)\n\nlemma irq_machine_le_maxIRQ_irq:\n  \"irq \\<le> Kernel_Config.maxIRQ \\<Longrightarrow> (ucast irq::irq) \\<le> maxIRQ\" for irq::machine_word\n  by (simp add: Kernel_Config.maxIRQ_def word_le_nat_alt unat_ucast)\n\nlemma maxIRQ_eq_ucast_irq_32_signed_uint:\n  \"(maxIRQ = (ucast b :: int_word)) = (uint b = maxIRQ)\" for b::irq\n  unfolding Kernel_Config.maxIRQ_def\n  apply uint_arith\n  apply (simp add: uint_up_ucast is_up)\n  done\n\nlemma sint_maxIRQ_32[simp]:\n  \"sint (maxIRQ :: int_word) = maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_machine[simp]:\n  \"scast (maxIRQ :: int_word) = (maxIRQ::machine_word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_irq[simp]:\n  \"scast (maxIRQ :: int_word) = (maxIRQ::irq)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_machine:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = x\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_irq:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = (ucast x :: irq)\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_1_plus_eq_Suc_machine[simp]:\n  \"unat (1 + maxIRQ :: machine_word) = Suc Kernel_Config.maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)", "property": "IRQ Value Properties: Ensure that IRQ values are correctly represented and converted between different types (machine word, IRQ, and int word) while maintaining their relationships and bounds with respect to the maximum IRQ value.", "title": "./spec/machine/ARM/Arch_Kernel_Config_Lemmas.thy", "chapter": "", "section": "", "comment": " The following are instances -- for some we could derive general rules, but the number of\n   instances is limited and the concrete proofs are much simpler: "}
{"spec": "lemma Suc_unat_mask_div_obfuscated:\n  \"Suc (unat (mask sz div (word_size::machine_word))) = 2 ^ (min sz word_bits - word_size_bits)\"\n  by (rule Suc_unat_mask_div)\n\nlemma word_size_size_bits_nat:\n  \"2^word_size_bits = (word_size :: nat)\"\n  by (simp add: word_size_bits_def word_size_def)\n\nlemma word_size_size_bits_word:\n  \"2^word_size_bits = (word_size :: 'a :: len word)\"\n  by (simp add: word_size_bits_def word_size_def)\n\nend", "property": "Word Size and Mask Properties: Define relationships between word sizes, mask operations, and exponentiation for various architectures, ensuring consistency and correctness in bit-level operations.\n\nSubproperties:\n- Suc Unat Mask Div: Establishes a relationship between the successor of an unsigned integer mask division and exponentiation.\n- Word Size Size Bits Nat: Relates the exponentiation of word size bits to the natural number representation of word size.\n- Word Size Size Bits Word: Relates the exponentiation of word size bits to the word representation of word size.", "title": "./spec/machine/MachineExports.thy", "chapter": "", "section": "", "comment": " HERE IS THE PLACE FOR GENERIC WORD LEMMAS FOR ALL ARCHITECTURES "}
{"spec": "definition\n  get_active_irq :: \"(cdl_irq option) k_monad\"\nwhere\n  \"get_active_irq \\<equiv>\n    do\n      irq \\<leftarrow> select UNIV;\n      return $ Some irq\n    od \\<sqinter> (return None)\n  \"\n\ndefinition\n  arch_decode_irq_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_arch_irq_control_intent \\<Rightarrow> cdl_irq_control_invocation except_monad\"\nwhere\n  \"arch_decode_irq_control_invocation target target_ref caps intent \\<equiv> case intent of\n      ARMIrqControlIssueIrqHandlerIntent irq index depth \\<Rightarrow>\n        doE\n          root \\<leftarrow> throw_on_none $ get_index caps 0;\n          cnode_cap \\<leftarrow> returnOk $ fst root;\n          dest_slot_cap_ref \\<leftarrow> lookup_slot_for_cnode_op cnode_cap index (unat depth);\n          returnOk $ IssueIrqHandler irq target_ref dest_slot_cap_ref\n        odE \\<sqinter> throw\"\n\ndefinition\n  decode_irq_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_irq_control_intent \\<Rightarrow> cdl_irq_control_invocation except_monad\"\nwhere\n  \"decode_irq_control_invocation target target_ref caps intent \\<equiv> case intent of\n      \\<comment> \\<open>Create an IRQ handler cap for the given IRQ, placing it\n         in the specified CNode slot.\\<close>\n      IrqControlIssueIrqHandlerIntent irq index depth \\<Rightarrow>\n        doE\n          root \\<leftarrow> throw_on_none $ get_index caps 0;\n          cnode_cap \\<leftarrow> returnOk $ fst root;\n          dest_slot_cap_ref \\<leftarrow> lookup_slot_for_cnode_op cnode_cap index (unat depth);\n          returnOk $ IssueIrqHandler irq target_ref dest_slot_cap_ref\n        odE \\<sqinter> throw\n    | ArchIrqControlIssueIrqHandlerIntent arch_intent \\<Rightarrow> arch_decode_irq_control_invocation target target_ref caps arch_intent\"\n\ndefinition\n  decode_irq_handler_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_irq_handler_intent \\<Rightarrow> cdl_irq_handler_invocation except_monad\"\nwhere\n  \"decode_irq_handler_invocation target target_ref caps intent \\<equiv> case intent of\n    \\<comment> \\<open>Acknowledge an IRQ.\\<close>\n    IrqHandlerAckIntent \\<Rightarrow>\n      doE\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        returnOk $ AckIrq irq\n      odE \\<sqinter> throw\n\n    \\<comment> \\<open>Modify the IRQ so that it no longer sends to an endpoint.\\<close>\n    | IrqHandlerClearIntent \\<Rightarrow>\n      doE\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        returnOk $ ClearIrqHandler irq\n      odE \\<sqinter> throw\n\n    \\<comment> \\<open>Setup an IRQ to cause an endpoint to be sent to.\\<close>\n    | IrqHandlerSetEndpointIntent \\<Rightarrow>\n      doE\n        endpoint \\<leftarrow> throw_on_none $ get_index caps 0;\n        endpoint_cap \\<leftarrow> returnOk $ fst endpoint;\n        endpoint_cap_ref \\<leftarrow> returnOk $ snd endpoint;\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        case endpoint_cap of\n              NotificationCap x _ _ \\<Rightarrow> returnOk ()\n              | _                    \\<Rightarrow> throw;\n        returnOk $ SetIrqHandler irq endpoint_cap endpoint_cap_ref\n      odE \\<sqinter> throw\n  \"\n\ndefinition\n  arch_invoke_irq_control :: \"arch_cdl_irq_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"arch_invoke_irq_control params \\<equiv> case params of\n      \\<comment> \\<open>Create a new IRQ handler cap.\\<close>\n      ARMIssueIrqHandler irq control_slot dest_slot trigger \\<Rightarrow>\n        insert_cap_child (IrqHandlerCap irq) control_slot dest_slot\n  \"\n\ndefinition\n  invoke_irq_control :: \"cdl_irq_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_irq_control params \\<equiv> case params of\n      \\<comment> \\<open>Create a new IRQ handler cap.\\<close>\n      IssueIrqHandler irq control_slot dest_slot \\<Rightarrow>\n        insert_cap_child (IrqHandlerCap irq) control_slot dest_slot\n    | ArchIssueIrqHandler arch_inv \\<Rightarrow>\n        arch_invoke_irq_control arch_inv\"\n\ndefinition\n  invoke_irq_handler :: \"cdl_irq_handler_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_irq_handler params \\<equiv> case params of\n      \\<comment> \\<open>Acknowledge and unmask an IRQ.\\<close>\n      AckIrq irq \\<Rightarrow> return ()\n\n      \\<comment> \\<open>Attach an IRQ handler to write to an endpoint.\\<close>\n    | SetIrqHandler irq cap slot \\<Rightarrow>\n        do\n          irqslot \\<leftarrow> gets (get_irq_slot irq);\n          delete_cap_simple irqslot;\n          insert_cap_child cap slot irqslot \\<sqinter> insert_cap_sibling cap slot irqslot\n        od\n\n      \\<comment> \\<open>Deassociate this handler with all endpoints.\\<close>\n    | ClearIrqHandler irq \\<Rightarrow>\n        do\n          irqslot \\<leftarrow> gets (get_irq_slot irq);\n          delete_cap_simple irqslot\n        od\n  \"", "property": "IRQ Management: Enables the creation, acknowledgment, and modification of IRQ handlers. It supports creating new IRQ handler capabilities, acknowledging and unmasking IRQs, setting endpoints for IRQs, and clearing IRQ handlers. These operations ensure that IRQs are managed effectively, allowing for proper handling and dispatching of interrupts in the system.", "title": "./spec/capDL/Interrupt_D.thy", "chapter": "", "section": "", "comment": " Return the currently pending IRQ. "}
{"spec": "definition make_virq :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> virq\" where\n  \"make_virq grp prio irq \\<equiv>\n    let\n      groupShift = 30;\n      prioShift = 23;\n      irqPending = 1 << 28;\n      eoiirqen = 1 << 19\n    in ((grp && 1) << groupShift) || ((prio && 0x1F) << prioShift) || (irq && 0x3FF)\n       || irqPending || eoiirqen\"\n\ndefinition virq_type :: \"virq \\<Rightarrow> nat\" where\n  \"virq_type virq \\<equiv> unat ((virq >> 28) && 3)\"\n\ndefinition is_virq_active :: \"virq \\<Rightarrow> bool\" where\n  \"is_virq_active virq \\<equiv> virq_type virq = 2\"\n\ndefinition decode_vcpu_inject_irq ::\n  \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_inject_irq ptrs cap \\<equiv> case (ptrs, cap) of\n  (mr0 # _, VCPUCap p) \\<Rightarrow> doE\n     vid \\<leftarrow> returnOk (mr0 && 0xFFFF);\n     priority \\<leftarrow> returnOk ((mr0 >> 16) && 0xFF);\n     group \\<leftarrow> returnOk ((mr0 >> 24) && 0xFF);\n     index \\<leftarrow> returnOk ((mr0 >> 32) && 0xFF);\n     range_check vid 0 ((1 << 10) - 1);\n     range_check priority 0 31;\n     range_check group 0 1;\n     num_list_regs \\<leftarrow> liftE $ gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     whenE (index \\<ge> of_nat num_list_regs) $\n        (throwError $ RangeError 0 (of_nat num_list_regs - 1));\n\n     vcpu \\<leftarrow> liftE $ get_vcpu p;\n     vcpuLR \\<leftarrow> returnOk (vgic_lr $ vcpu_vgic $ vcpu);\n\n     whenE (is_virq_active (vcpuLR (unat index))) $ throwError DeleteFirst;\n\n     virq \\<leftarrow> returnOk (make_virq group priority vid);\n     returnOk $ InvokeVCPU $ VCPUInjectIRQ p (unat index) virq\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_inject_irq :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invoke_vcpu_inject_irq vr index virq \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    if (cur_v \\<noteq> None \\<and> fst (the cur_v) = vr)\n    then do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat index) virq\n    else vgic_update_lr vr index virq\n   od\"", "property": "VCPU Interrupt Injection: Allows the injection of a virtual interrupt into a VCPU by constructing a virtual interrupt (virq) with specified parameters (group, priority, and ID), validating the input values, and updating the VCPU's state. The function ensures that the virq is not already active before injecting it, maintaining the integrity of the VCPU's interrupt state.", "title": "./spec/abstract/AARCH64/VCPU_A.thy", "chapter": "VCPU", "section": "", "comment": " This following function does not correspond to exactly what the C does, but\n   it is the value that is stored inside of lr in the vgic  "}
{"spec": "definition\ndelete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pml4 \\<equiv> do\n  asid_table \\<leftarrow> gets (x64_asid_table \\<circ> arch_state);\n  case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (asid_low_bits_of asid) = Some pml4) $ do\n                hw_asid_invalidate asid pml4;\n                pool' \\<leftarrow> return (pool (asid_low_bits_of asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od\nod\"\n\ndefinition\n  flush_all :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_all vspace asid \\<equiv> do_machine_op $ invalidateASID vspace (ucast asid)\"\n\nabbreviation\n  flush_pdpt :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_pdpt \\<equiv> flush_all\"\n\nabbreviation\n  flush_pd :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_pd \\<equiv> flush_all\"", "property": "ASID Management: Ensure proper deactivation and flushing of page map levels when deleting or modifying ASID-related structures, maintaining the integrity of the virtual memory system.\n\nSubproperties:\n- Deactivate Page Map Level 4: When deleting a page map level 4 from an ASID pool, deactivate it to prevent unauthorized access.\n- Flush ASID-Related Structures: Flush all relevant structures (e.g., page directories, page directory pointer tables) when modifying ASID-related information to ensure consistency and prevent stale data.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "When deleting a page map level 4 from an ASID pool we must deactivate\nit."}
{"spec": "definition mapM_x :: \"('a \\<Rightarrow> ('s,'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"mapM_x f xs \\<equiv> sequence_x (map f xs)\"", "property": "Map Function Over List: Apply a monadic function to each element of a list from left to right, ignoring return values.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Library of additional Monadic Functions and Combinators", "comment": "\n  Map a monadic function over a list by applying it to each element\n  of the list from left to right, ignoring return values."}
{"spec": "definition\nstore_hw_asid :: \"asid \\<Rightarrow> hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"store_hw_asid asid hw_asid \\<equiv> do\n    pd \\<leftarrow> find_pd_for_asid_assert asid;\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid \\<mapsto> (hw_asid, pd)));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>);\n    hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid \\<mapsto> asid));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"", "property": "Associate a hardware ASID with a virtual ASID: Store the association between a virtual ASID and a hardware ASID in the system's ASID map, and update the hardware ASID table to reflect this mapping.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Associate a hardware ASID with a virtual ASID."}
{"spec": "(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Main Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_HYP_H ONLY ArmVSpaceRegionUse\n\nend\nend", "property": "Define and Share Architecture-Specific Data Types: Establish common, architecture-specific data types that are utilized across both the specification and the abstract model, ensuring consistency and reusability in the system's formalization.", "title": "./spec/design/skel/ARM_HYP/Arch_Structs_B.thy", "chapter": "Common, Architecture-Specific Data Types", "section": "", "comment": ""}
{"spec": "|  PageFlushCachesIntent", "property": "Flush Caches: Ensure cache coherence by flushing the caches of a target, maintaining data consistency across the system.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " FlushCaches: (target) "}
{"spec": "definition pptr_from_pte :: \"pte \\<Rightarrow> vspace_ref\"\n  where\n  \"pptr_from_pte pte \\<equiv> ptrFromPAddr (addr_from_pte pte)\"\n\ndefinition pt_slot_offset :: \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\n  where\n  \"pt_slot_offset level pt_ptr vptr = pt_ptr + (pt_index level vptr << pte_bits)\"", "property": "Virtual Space Access: Provide basic operations to access and manipulate the RISCV64 virtual space, ensuring proper address alignment and calculation of page table slot offsets.\n\nAddress Calculation: Calculate the physical pointer from a page table entry (PTE) and compute the page table slot offset for a given virtual pointer and page table level.", "title": "./spec/abstract/RISCV64/ArchVSpaceAcc_A.thy", "chapter": "Accessing the RISCV64 VSpace", "section": "Basic Operations", "comment": " pte addresses will always be at least page aligned "}
{"spec": "definition\n  \"non_kernel_IRQs = {}\"", "property": "Non-Kernel Interrupts: No interrupts can occur while the kernel is running that are not handled by the kernel itself.", "title": "./spec/machine/X64/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": "\n  Interrupts that cannot occur while the kernel is running (e.g. at preemption points),\n  but that can occur from user mode. Empty on plain x86-64.\n"}
{"spec": "end\n\nqualify ARM_HYP (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"ARM_HYP.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  device_state :: \"word32 \\<Rightarrow> word8 option\"\n  exclusive_state :: ARM_HYP.exclusive_monitors\n  machine_state_rest :: ARM_HYP.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> ARM_HYP.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall> n. irq_oracle n <= Kernel_Config.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming", "property": "Machine State: The machine state consists of the interrupt controller state (IRQ masks and IRQ state), memory (underlying memory, device state, and exclusive state), and additional underspecified state (machine state rest). The interrupt controller state determines which IRQs are masked, while the memory state reflects the kernel's abstract view of memory and the underlying machine's memory.", "title": "./spec/design/m-skel/ARM_HYP/MachineTypes.thy", "chapter": "ARM\\_HYP Machine Types", "section": "Machine State", "comment": "\n  The full machine state is the state observable by the kernel plus\n  the underspecified rest above. The observable parts are the\n  interrupt controller (which IRQs are masked) and the memory of the\n  machine. The latter is shadow state: kernel memory is kept in a\n  separate, more abstract datatype; user memory is reflected down\n  to the underlying memory of the machine.\n"}
{"spec": "definition\n  send_ipc :: \"bool \\<Rightarrow> bool \\<Rightarrow> badge \\<Rightarrow> bool \\<Rightarrow> bool\n                \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"send_ipc block call badge can_grant can_grant_reply thread epptr \\<equiv> do\n     ep \\<leftarrow> get_endpoint epptr;\n     case (ep, block) of\n         (IdleEP, True) \\<Rightarrow> do\n               set_thread_state thread (BlockedOnSend epptr\n                                   \\<lparr> sender_badge = badge,\n                                     sender_can_grant = can_grant,\n                                     sender_can_grant_reply = can_grant_reply,\n                                     sender_is_call = call \\<rparr>);\n               set_endpoint epptr $ SendEP [thread]\n             od\n       | (SendEP queue, True) \\<Rightarrow> do\n               set_thread_state thread (BlockedOnSend epptr\n                                   \\<lparr> sender_badge = badge,\n                                     sender_can_grant = can_grant,\n                                     sender_can_grant_reply = can_grant_reply,\n                                     sender_is_call = call\\<rparr>);\n               set_endpoint epptr $ SendEP (queue @ [thread])\n             od\n       | (IdleEP, False) \\<Rightarrow> return ()\n       | (SendEP queue, False) \\<Rightarrow> return ()\n       | (RecvEP (dest # queue), _) \\<Rightarrow> do\n                set_endpoint epptr $ (case queue of [] \\<Rightarrow> IdleEP\n                                                     | _ \\<Rightarrow> RecvEP queue);\n                recv_state \\<leftarrow> get_thread_state dest;\n                reply_can_grant \\<leftarrow> case recv_state\n                  of (BlockedOnReceive x data) \\<Rightarrow> do\n                           do_ipc_transfer thread (Some epptr) badge can_grant dest;\n                           return (receiver_can_grant data)\n                           od\n                  | _ \\<Rightarrow> fail;\n                set_thread_state dest Running;\n                do_extended_op (possible_switch_to dest);\n                when call $\n                  if (can_grant \\<or> can_grant_reply)\n                  then setup_caller_cap thread dest reply_can_grant\n                  else set_thread_state thread Inactive\n                od\n\n       | (RecvEP [], _) \\<Rightarrow> fail\n   od\"", "property": "Synchronous Message Transfer: Handle a message send operation performed by a thread on an endpoint, transferring the message to a waiting receiver if available, or blocking the thread in the endpoint's sending queue if no receiver is available and the thread is willing to wait.\n\nSubproperties:\n- If a receiver is waiting, transfer the message and update the receiver's state.\n- If no receiver is available and the thread is willing to block, add the thread to the endpoint's sending queue.\n- If no receiver is available and the thread is not willing to block, do nothing.\n- If the endpoint is in an invalid state, fail the operation.", "title": "./spec/abstract/Ipc_A.thy", "chapter": "IPC", "section": "Synchronous Message Transfers", "comment": "Handle a message send operation performed on an endpoint by a thread.\nIf a receiver is waiting then transfer the message. If no receiver is available\nand the thread is willing to block waiting to send then put it in the endpoint\nsending queue."}
{"spec": "definition find_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\"\n  where\n  \"find_vspace_for_asid asid \\<equiv> doE\n    vspace_opt \\<leftarrow> liftE $ gets $ vspace_for_asid asid;\n    throw_opt InvalidRoot vspace_opt\n  odE\"", "property": "Locate VSpace for ASID: Retrieve the top-level page table (vspace) associated with a given virtual ASID. If no vspace is found, an `InvalidRoot` exception is thrown.", "title": "./spec/abstract/RISCV64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Locate the top-level page table associated with a given virtual ASID."}
{"spec": "text \\<open>The architecture-specific state for the ARM model\nconsists of the first level of the ASID table (@{text \"arm_asid_table\"}), a\nmap from hardware ASIDs to seL4 ASIDs (@{text \"arm_hwasid_table\"}),\nthe next hardware ASID to preempt (@{text \"arm_next_asid\"}), the\ninverse map from seL4 ASIDs to hardware ASIDs (first component of\n@{text \"arm_asid_map\"}), and the address of the page directory and\npage tables mapping the shared address space, along with a description\nof this space (@{text \"arm_global_pd\"}, @{text \"arm_global_pts\"}, and\n@{text \"arm_kernel_vspace\"} respectively).\n\nHardware ASIDs are only ever associated with seL4 ASIDs that have a\ncurrently active page directory. The second component of\n@{text \"arm_asid_map\"} values is the address of that page directory.\n\\<close>\n\nend\n\nqualify ARM_HYP_A (in Arch)", "property": "ARM Architecture State: Maintains architecture-specific state, including the ASID table, hardware ASID to seL4 ASID mapping, next hardware ASID, inverse mapping from seL4 ASIDs to hardware ASIDs, and shared address space mappings.", "title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "chapter": "ARM-Specific Data Types", "section": "Architecture-specific state", "comment": ""}
{"spec": "definition perform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_page_invocation iv \\<equiv> case iv of\n     PageMap cap ct_slot (pte,slot,level) \\<Rightarrow> do\n       perform_pg_inv_map cap ct_slot pte slot level;\n       return []\n     od\n   | PageUnmap cap ct_slot \\<Rightarrow> do perform_pg_inv_unmap cap ct_slot; return [] od\n   | PageGetAddr ptr \\<Rightarrow> perform_pg_inv_get_addr ptr\n   | PageFlush type start end pstart space asid \\<Rightarrow> do\n       perform_flush type start end pstart space asid;\n       return []\n     od\"\n\n\ndefinition perform_pt_inv_map ::\n  \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> vm_level \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pt_inv_map cap ct_slot pte slot level = do\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte level slot pte;\n     do_machine_op $ cleanByVA_PoU slot (addrFromPPtr slot)\n   od\"\n\ndefinition perform_pt_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pt_inv_unmap cap ct_slot = do\n     assert $ is_PageTableCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> do\n         p \\<leftarrow> return $ acap_obj cap;\n         unmap_page_table asid vaddr p;\n         slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + mask (pt_bits (acap_pt_type cap))];\n         mapM_x (swp (store_pte (acap_pt_type cap)) InvalidPTE) slots;\n         do_machine_op $ cleanCacheRange_PoU p (p + mask (pt_bits (acap_pt_type cap)))\n                                             (addrFromPPtr p)\n       od\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data old_cap None) ct_slot\n   od\"", "property": "Frame Capability Actions: Allow mapping and unmapping of memory, querying the physical address of a page, and flushing of memory regions. These actions ensure that memory can be effectively managed and accessed within the system.\n\nSubproperties:\n- Map Memory: Set the capability and store the page table entry, then clean the memory region.\n- Unmap Memory: Unmap the page table, invalidate the page table entries, and clean the cache range.\n- Query Physical Address: Retrieve the physical address of a page.\n- Flush Memory: Flush the specified memory region.", "title": "./spec/abstract/AARCH64/Arch_A.thy", "chapter": "", "section": "", "comment": "\n  The Frame capability confers the authority to map and unmap memory, to query the physical\n  address of a page and to flush.\n"}
{"spec": "(*\n   Types visible in the API.\n*)\n\nchapter \"Types visible in the API\"\n\ntheory Types_H\nimports\n  MachineExports\n  ArchTypes_H\nbegin\n\narch_requalify_types (H)\n  object_type\n  paddr\n  vptr\n\narch_requalify_consts (H)\n  getObjectSize\n  fromAPIType\n  toAPIType\n  isFrameType\n  pageType\n  tcbBlockSizeBits\n\narch_requalify_facts (H)\n  tcbBlockSizeBits_def\n\n#INCLUDE_HASKELL SEL4/API/Types.lhs all_bits NOT wordsFromBootInfo messageInfoFromWord wordFromMessageInfo ObjectType getObjectSize fromAPIType toAPIType isFrameType pageType\n#INCLUDE_HASKELL SEL4/API/Types.lhs all_bits ONLY wordsFromBootInfo messageInfoFromWord wordFromMessageInfo\n\nend", "property": "API Type Definitions: Define and requalify various types and constants for the API, including object types, addresses, and frame types, to ensure consistency and correctness in API interactions.", "title": "./spec/design/skel/Types_H.thy", "chapter": "Types visible in the API", "section": "", "comment": ""}
{"spec": "definition\n  generate_object_ids :: \"nat \\<Rightarrow> cdl_object_type \\<Rightarrow> cdl_object_id set \\<Rightarrow>  ((cdl_object_id set) list) k_monad\"\n  where \"generate_object_ids num_objects type object_range\n  \\<equiv> do\n    s \\<leftarrow> get;\n    available_names \\<leftarrow> return $ (cdl_objects s) -` {Some Untyped};\n    setlist \\<leftarrow> select {x. distinct  x \\<and> (\\<forall>a\\<in> set x. \\<forall>b \\<in> set x. a \\<noteq> b \\<longrightarrow> a \\<inter> b = {})\n           \\<and> (\\<forall>y \\<in> set x. y \\<noteq> {} \\<and> y \\<subseteq> object_range \\<inter> available_names)\n           \\<and> (num_objects = (size x)) };\n    if (type \\<noteq> UntypedType) then (return $ map (\\<lambda>x. {pick x}) setlist)\n    else return setlist\n    od\"\n\ndefinition create_objects :: \"(cdl_object_id set) list \\<Rightarrow> cdl_object option \\<Rightarrow> unit k_monad\"\nwhere\n  \"create_objects target_object_ids object \\<equiv>\n    (modify (\\<lambda>s. s\\<lparr>cdl_objects := (\\<lambda>x.\n     if {x} \\<in> set target_object_ids then\n      object\n     else\n      cdl_objects s x)\\<rparr>))\"", "property": "Generate and Create Objects: Generate a list of unique object IDs within a specified range, ensuring that the IDs are distinct and do not overlap. If the target object type is not Untyped, each set in the list is converted to a single object ID. The generated IDs are then used to create new objects of the specified type, updating the system state with the new objects.", "title": "./spec/capDL/Untyped_D.thy", "chapter": "", "section": "", "comment": "\n * Retype the given untyped object into a new object type,\n * and return a list of pointers to the newly constructed items.\n "}
{"spec": "definition\n  lookup_pd_slot_no_fail :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\nwhere\n  \"lookup_pd_slot_no_fail pd vptr \\<equiv>\n     pd + (get_pd_index vptr << word_size_bits)\"", "property": "Non-Failing Page Directory Slot Lookup: Calculate the page directory slot address for a given virtual space reference and page directory object reference without failing.", "title": "./spec/abstract/X64/ArchVSpaceAcc_A.thy", "chapter": "Accessing the x64 VSpace", "section": "Basic Operations", "comment": "A non-failing version of @{const lookup_pd_slot} when the pdpt is already known"}
{"spec": "definition\n  cacheRangeOp :: \"(machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad)\n                 \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cacheRangeOp operation vstart vend pstart \\<equiv>\n    let pend = pstart + (vend - vstart);\n        vptrs = [lineStart vstart, lineStart vstart + of_nat cacheLine .e. lineStart vend];\n        pptrs = [lineStart pstart, lineStart pstart + of_nat cacheLine .e. lineStart pend]\n    in mapM_x (\\<lambda>(v, p). operation v p) (zip vptrs pptrs)\"\n\ndefinition\n  cleanCacheRange_PoC :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoC vstart vend pstart \\<equiv> cacheRangeOp cleanByVA vstart vend pstart\"\n\ndefinition\n  cleanInvalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanInvalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanInvalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp cleanInvalByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  cleanCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanL2Range pstart (pstart + (vend - vstart))\n  od\"\n\ndefinition\n  cleanCacheRange_PoU :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoU vstart vend pstart \\<equiv> cacheRangeOp cleanByVA_PoU vstart vend pstart\"\n\ndefinition\n  invalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    when (vstart \\<noteq> lineStart vstart) $\n        cleanCacheRange_RAM vstart vstart pstart;\n    when (vend + 1 \\<noteq> lineStart (vend + 1)) $\n        cleanCacheRange_RAM (lineStart vend) (lineStart vend)\n           (pstart + ((lineStart vend) - vstart));\n    invalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp invalidateByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  invalidateCacheRange_I :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_I vstart vend pstart \\<equiv> cacheRangeOp invalidateByVA_I vstart vend pstart\"\n\ndefinition\n  branchFlushRange :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"branchFlushRange vstart vend pstart \\<equiv> cacheRangeOp branchFlush vstart vend pstart\"\n\ndefinition\n  cleanCaches_PoU :: \"unit machine_monad\"\nwhere\n  \"cleanCaches_PoU \\<equiv> do\n    dsb;\n    clean_D_PoU;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\"\n\ndefinition\n  cleanInvalidateL1Caches :: \"unit machine_monad\"\nwhere\n  \"cleanInvalidateL1Caches \\<equiv> do\n    dsb;\n    cleanInvalidate_D_PoC;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\"", "property": "Cache Operations: Perform various cache operations (cleaning, invalidating, flushing) on a range of cache lines, ensuring cache coherence and consistency.\n\nSubproperties:\n\n* Clean Cache Range: Clean the cache lines in a specified range, ensuring that the cache is up-to-date with the latest memory values.\n* Invalidate Cache Range: Invalidate the cache lines in a specified range, ensuring that the cache is cleared of stale data.\n* Flush Cache Range: Flush the cache lines in a specified range, ensuring that the cache is cleared of all data.\n* Clean and Invalidate Cache Range: Clean and invalidate the cache lines in a specified range, ensuring that the cache is both up-to-date and cleared of stale data.\n* Branch Flush Range: Flush the branch predictor cache lines in a specified range, ensuring that the branch predictor is cleared of stale data.", "title": "./spec/machine/ARM/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": "\n  Performs the given operation on every cache line that intersects the\n  supplied range.\n"}
{"spec": "abbreviation\n  \"c_h_t_valid\" :: \"cstate \\<Rightarrow> 'a::c_type ptr \\<Rightarrow> bool\"  (\"_ \\<Turnstile>\\<^sub>c _\" [99,99] 100)\nwhere\n  \"s \\<Turnstile>\\<^sub>c p == hrs_htd (t_hrs_' (globals s)),c_guard \\<Turnstile>\\<^sub>t p\"", "property": "C State Validity: A cstate is valid with respect to a pointer if the heap satisfies the type and guard conditions for that pointer.", "title": "./spec/cspec/KernelState_C.thy", "chapter": "", "section": "", "comment": " Add an abbreviation for the common case of hrs_htd (t_hrs_' (globals s)) \\<Turnstile>\\<^sub>t p "}
{"spec": "definition\n  init_global_pdpt :: obj_ref where\n  \"init_global_pdpt = kernel_base + 0x5000\"", "property": "Initialization of Global Page Directory Pointer Table (PDPT): The global PDPT is initialized at a fixed address, 0x5000 offset from the kernel base, with a size of 4KiB.", "title": "./spec/abstract/X64/Init_A.thy", "chapter": "", "section": "", "comment": " 4KiB "}
{"spec": "type_synonym pte_ppn_len = 52 (* machine_word_len - pt_bits *)\ntype_synonym pte_ppn = \"pte_ppn_len word\"\n\ndefinition ppn_len :: nat where\n  \"ppn_len \\<equiv> LENGTH(pte_ppn_len)\"\n\ndatatype pte =\n    InvalidPTE\n  | PagePTE (pte_ppn : pte_ppn) (pte_attr : vm_attributes) (pte_rights : vm_rights)\n  | PageTablePTE (pte_ppn : pte_ppn) (pte_attr : vm_attributes)\n\ntype_synonym pt_index_len = 9\ntype_synonym pt_index = \"pt_index_len word\"", "property": "RISCV64 Page Table Entry (PTE) Structure: Defines a PTE with three possible types: `InvalidPTE`, `PagePTE`, and `PageTablePTE`. Each valid PTE type includes a page number (ppn) of 52 bits, attributes, and, for `PagePTE`, additional rights. The ppn is stored as a shifted address, and the actual address can be retrieved using `addr_from_pte`.", "title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "chapter": "RISCV64-Specific Data Types", "section": "Architecture-specific object types and default objects", "comment": " The address of the target object is stored shifted right by pt_bits and stored as a ppn (page\n   number). To get the address, use addr_from_pte "}
{"spec": "definition\n  decode_page_table_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_page_table_intent \\<Rightarrow> cdl_page_table_invocation except_monad\"\nwhere\n  \"decode_page_table_invocation target target_ref caps intent \\<equiv> case intent of\n    \\<comment> \\<open>\n      Map the given PageTable into the given PageDirectory at the given\n      virtual address.\n\n      The concrete implementation only allows a PageTable to be mapped\n      once at any point in time, but we don't enforce that here.\n     \\<close>\n    PageTableMapIntent vaddr attr \\<Rightarrow>\n      doE\n        case cdl_get_pt_mapped_addr target of Some a \\<Rightarrow> throw\n        | None \\<Rightarrow> returnOk ();\n        \\<comment> \\<open>Ensure that a PD was passed in.\\<close>\n        pd \\<leftarrow> throw_on_none $ get_index caps 0;\n        (pd_object_id, asid) \\<leftarrow>\n          case (fst pd) of\n              PageDirectoryCap x _ (Some asid) \\<Rightarrow> returnOk (x, asid)\n            | _ \\<Rightarrow> throw;\n\n        target_slot \\<leftarrow> returnOk $ cdl_lookup_pd_slot pd_object_id vaddr;\n\n        returnOk $ PageTableMap (PageTableCap (cap_object target) Real (Some (asid,vaddr && ~~ mask 20)))\n          (PageTableCap (cap_object target) Fake None) target_ref target_slot\n      odE \\<sqinter> throw\n    \\<comment> \\<open>Unmap this PageTable.\\<close>\n    | PageTableUnmapIntent \\<Rightarrow> (\n        case target of PageTableCap pid ctype maddr \\<Rightarrow>\n        (returnOk $ PageTableUnmap maddr pid target_ref)\n        | _ \\<Rightarrow> throw\n      ) \\<sqinter> throw\n  \"", "property": "Page Table Invocation Decoding: Decode a page table intent into a specific invocation, supporting mapping and unmapping operations. For mapping, it ensures the page table is not already mapped, retrieves the page directory and ASID, and sets up the necessary mappings. For unmapping, it validates the target as a page table and performs the unmap operation.", "title": "./spec/capDL/PageTable_D.thy", "chapter": "", "section": "", "comment": " Decode a page table intent into an invocation. "}
{"spec": "definition\n  update_cap_data :: \"bool \\<Rightarrow> word32 \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap k_monad\"\nwhere\n  \"update_cap_data preserve data cap \\<equiv>\n    return $ case cap of\n        EndpointCap _ b _ \\<Rightarrow>\n          if b = 0 \\<and> \\<not> preserve then\n            badge_update data cap\n          else\n            NullCap\n      | NotificationCap _ b _ \\<Rightarrow>\n          if b = 0 \\<and> \\<not> preserve then\n            badge_update data cap\n          else\n            NullCap\n      | CNodeCap object guard guard_size sz \\<Rightarrow>\n          let\n            reserved_bits = 3;\n            guard_bits = 18;\n            guard_size_bits = 5;\n\n            new_guard_size = unat ((data >> reserved_bits) && mask guard_size_bits);\n            new_guard = (data >> (reserved_bits + guard_size_bits)) && mask (min (unat ((data >> reserved_bits) && mask guard_size_bits)) guard_bits)\n          in\n            if new_guard_size + sz > word_bits then NullCap else\n            (CNodeCap object new_guard new_guard_size sz)\n      | _ \\<Rightarrow> cap\"", "property": "Update Capability Data: Transform a capability based on user request, interpreting the \"data\" word differently for various cap types. For Endpoint and Notification caps, update the badge if the current badge is 0 and preservation is not required. For CNode caps, update the guard and guard size based on the data, ensuring the new guard size does not exceed the word bits. Other cap types remain unchanged.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": "\n * Transform a capability based on a request from the user.\n *\n * The \"data\" word is interpreted differently for different cap types.\n *\n * We return a set of possible caps to allow for non-deterministic\n * implementations, to avoid messy implementation details of the CDT\n * in lower-level models.\n "}
{"spec": "definition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> 2);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> 2);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\"", "property": "Kernel Heap Accessors: Access and modify page table entries (PTEs) in kernel memory. \n\nGet PTE: Retrieve the actual PTE from a given pointer to a PTE in kernel memory, using bitwise operations to extract the base address and offset.\n\nStore PTE: Update a PTE at a given pointer in kernel memory, using bitwise operations to extract the base address and offset, and then modifying the corresponding page table.", "title": "./spec/abstract/ARM/ArchVSpaceAcc_A.thy", "chapter": "Accessing the ARM VSpace", "section": "Kernel Heap Accessors", "comment": "The following function takes a pointer to a PTE in kernel memory\n  and returns the actual PTE."}
{"spec": "definition \"PPTR_VECTOR_TABLE \\<equiv> 0xffff0000 :: word32\"\ndefinition \"PPTR_GLOBALS_PAGE \\<equiv> 0xffffc000 :: word32\"\ndefinition \"PPTR_KERNEL_STACK \\<equiv> 0xfffff000 :: word32\"\n\ndefinition \"IT_ASID     \\<equiv> 1 :: asid\" (* initial thread ASID *)\n\ndefinition \"WORD_SIZE_BITS \\<equiv> 2 :: nat\"\ndefinition \"ASID_POOL_BITS \\<equiv> asid_low_bits :: nat\"\ndefinition \"ASID_POOL_SIZE_BITS \\<equiv> ASID_POOL_BITS + WORD_SIZE_BITS\"\n\ndefinition \"CTE_SIZE_BITS \\<equiv> 4 :: nat\" (* from ARM structures.h *)", "property": "Memory and ASID Constants: Define specific memory addresses for the vector table, globals page, and kernel stack, as well as constants for ASID and bit sizes for word, ASID pool, and CTE. These constants ensure consistent and predictable memory and ASID management in the system.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "ARM constants", "comment": ""}
{"spec": "type_synonym 'a preempt_monad = \"(cdl_state, cdl_preempt_error + 'a) nondet_monad\"", "property": "Preemption Monad: Represents a non-deterministic monad that handles preemption errors, providing a way to manage exceptions in a preemptive environment.", "title": "./spec/capDL/Monads_D.thy", "chapter": "", "section": "", "comment": " Exception monad, no further exception information "}
{"spec": "requalify_consts\n  checkIRQ\n  handleReservedIRQ\n  maskIrqSignal", "property": "IRQ Management: Provides functions to check, handle, and mask IRQ signals, ensuring proper interrupt handling and management in the system.", "title": "./spec/design/skel/Interrupt_H.thy", "chapter": "", "section": "", "comment": " match Haskell, expects these under Arch. "}
{"spec": "definition handleE' ::\n  \"('s, 'e1 + 'a) nondet_monad \\<Rightarrow> ('e1 \\<Rightarrow> ('s, 'e2 + 'a) nondet_monad) \\<Rightarrow> ('s, 'e2 + 'a) nondet_monad\"\n  (infix \"<handle2>\" 10) where\n  \"f <handle2> handler \\<equiv>\n   do\n      v \\<leftarrow> f;\n      case v of\n        Inl e \\<Rightarrow> handler e\n      | Inr v' \\<Rightarrow> return (Inr v')\n   od\"", "property": "Exception Handling: Catch and handle exceptions in a nondeterministic state monad, allowing the handler to throw a different type of exception than the original computation.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Catching and Handling Exceptions", "comment": "\n  Handling exceptions, but staying in the exception monad.\n  The handler may throw a type of exceptions different from\n  the left side."}
{"spec": "definition\nflush_space :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_space asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    do_machine_op cleanCaches_PoU;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"", "property": "Flush Virtual ASID: Flush all cache and TLB entries associated with a given virtual ASID, ensuring that the corresponding hardware ASID is cleaned and invalidated. \n\nCache Cleaning: Clean the caches to the point of unification (PoU) to ensure consistency across the system.\n\nTLB Invalidation: Invalidate the local TLB entries for the given hardware ASID, if it exists, to prevent stale translations from being used.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Flush all cache and TLB entries associated with this virtual ASID."}
{"spec": "definition\npage_table_mapped :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n\"page_table_mapped asid vaddr pt \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    pd_slot \\<leftarrow> returnOk $ lookup_pd_slot pd vaddr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    case pde of\n      PageTablePDE addr \\<Rightarrow> returnOk $\n             if addrFromPPtr pt = addr then Some pd else None\n    | _ \\<Rightarrow> returnOk None\nodE <catch> (K $ return None)\"", "property": "Page Table Mapping: Return the optional page directory that a page table is mapped in, based on the address space identifier, virtual address, and page table object reference. \n\nSubproperties:\n- Find the page directory for the given address space identifier.\n- Determine the page directory slot for the virtual address.\n- Retrieve the page directory entry for the slot.\n- Check if the page directory entry matches the page table object reference and return the page directory if it does.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Return the optional page directory a page table is mapped in."}
{"spec": "theory PSpaceStorable_H\nimports\n  Structures_H\n  KernelStateData_H\n  \"Lib.DataMap\"\nbegin\n\narch_requalify_types (H)\n  arch_kernel_object_type\n\narch_requalify_consts (H)\n  archTypeOf\n\nlemma UserData_singleton [simp]:\n  \"(v = UserData) = True\" \"(UserData = v) = True\"\n  by (cases v, simp)+\n\nlemma UserDataDevice_singleton [simp]:\n  \"(v = UserDataDevice) = True\" \"(UserDataDevice = v) = True\"\n  by (cases v, simp)+\n\ndatatype\n  kernel_object_type =\n    EndpointT\n  | NotificationT\n  | CTET\n  | TCBT\n  | UserDataT\n  | UserDataDeviceT\n  | KernelDataT\n  | ArchT arch_kernel_object_type\n\nprimrec\n  koTypeOf :: \"kernel_object \\<Rightarrow> kernel_object_type\"\nwhere\n  \"koTypeOf (KOEndpoint e) = EndpointT\"\n| \"koTypeOf (KONotification e) = NotificationT\"\n| \"koTypeOf (KOCTE e) = CTET\"\n| \"koTypeOf (KOTCB e) = TCBT\"\n| \"koTypeOf (KOUserData) = UserDataT\"\n| \"koTypeOf (KOUserDataDevice) = UserDataDeviceT\"\n| \"koTypeOf (KOKernelData) = KernelDataT\"\n| \"koTypeOf (KOArch e) = ArchT (archTypeOf e)\"\n\ndefinition\n  typeError :: \"unit list \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\" where\n  \"typeError t1 t2 \\<equiv> fail\"\n\ndefinition\n  alignError :: \"nat \\<Rightarrow> 'a kernel\" where\n  \"alignError n \\<equiv> fail\"\n\ndefinition\n  alignCheck :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit kernel\" where\n  \"alignCheck x n \\<equiv> unless ((x && mask n) = 0) $ alignError n\"\n\ndefinition\n  magnitudeCheck :: \"machine_word \\<Rightarrow> machine_word option \\<Rightarrow> nat \\<Rightarrow> unit kernel\"\nwhere\n \"magnitudeCheck x y n \\<equiv> case y of None \\<Rightarrow> return ()\n               | Some z \\<Rightarrow> when (z - x < 1 << n) fail\"\n\nclass pre_storable =\n  fixes injectKO :: \"'a \\<Rightarrow> kernel_object\"\n  fixes projectKO_opt :: \"kernel_object \\<Rightarrow> 'a option\"\n  fixes koType :: \"'a itself \\<Rightarrow> kernel_object_type\"\n\n  assumes project_inject: \"(projectKO_opt ko = Some v) = (injectKO v = ko)\"\n  assumes project_koType: \"(\\<exists>v. projectKO_opt ko = Some (v::'a)) = (koTypeOf ko = koType TYPE('a))\"\nbegin\n\ndefinition\n  projectKO :: \"kernel_object \\<Rightarrow> 'a kernel\"\nwhere\n  \"projectKO e \\<equiv>\n  case projectKO_opt e of None \\<Rightarrow> fail | Some k \\<Rightarrow> return k\"\n\ndefinition\n  objBits :: \"'a \\<Rightarrow> nat\"\nwhere\n  \"objBits v \\<equiv> objBitsKO (injectKO v)\"\n\ndefinition\n  loadObject_default :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\"\nwhere\n  \"loadObject_default ptr ptr' next obj \\<equiv> do\n     assert (ptr = ptr');\n     val \\<leftarrow> projectKO obj;\n     alignCheck ptr (objBits val);\n     magnitudeCheck ptr next (objBits val);\n     return val\n  od\"\n\ndefinition\n  updateObject_default :: \"'a \\<Rightarrow> kernel_object \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object kernel\"\nwhere\n  \"updateObject_default val oldObj ptr ptr' next \\<equiv> do\n     assert (ptr = ptr');\n     (_ :: 'a) \\<leftarrow> projectKO oldObj;\n     alignCheck ptr (objBits val);\n     magnitudeCheck ptr next (objBits val);\n     return (injectKO val)\n  od\"\n\nend\n\nclass pspace_storable = pre_storable +\n  fixes makeObject :: 'a\n\n  \\<comment>\\<open>\n    `loadObject` is only used in the generic definition of `getObject`. It\n    describes how to extract a value of type `'a` from memory.\n\n    If `(obj, _) \\<in> loadObjext p before after ko` within `getObject`, then:\n      - @{term \"p :: machine_word\"} is the addres that we want to read an\n        instance of `'a` from.\n      - @{term \"before :: machine_word\"} is the address of the nearest\n        object at or before `p`.\n      - @{term \"after :: machine_word option\"} is the address of the nearest\n        object after `p`, if any (for checking overlap).\n      - @{term \"ko :: kernel_object\"} is the object currently at `before`.\n      - @{term \"obj :: 'a\"} is the value extracted from `ko`.\n\n    Graphically, the \"memory\" looks like this:\n\n    before  p              after\n    |-------|--+-----+-----|---|\n    |       +~~+ <---+---------- The span of obj, the object we want to extract.\n    +~~~~~~~~~~~~~~~~+ <-------- The span of ko, the existing object that spans obj.\n\n                           +~~~+ The span of whatever object comes after obj.\n                                 We don't care about this beyond making sure\n                                 it doesn't overlap with ko.\n\n    In almost every case, the object in memory (ko) is the same type of object\n    as the one being loaded (obj). For example, for a reply object our parameters\n    look like this:\n\n    p, before\n    |-----------|\n    +~~~~~~~~~~~+ <- The span of two objects:\n                     - ko, the existing object (which should be a reply object).\n                     - obj, the object that we want to load from memory. This will\n                       just be ko projected through @{term projectKO}.\n\n    In these simple cases, @{term loadObject_default} is a good specification\n    for how to load an instance of `'a` from memory.\n\n    The only interesting case is when we're loading a CTE, which might be\n    inside a TCB. Then memory looks like this:\n\n    before  p\n    |-------|--+-----+\n    |       +~~+ <---+---- The span of obj, i.e. the CTE which we're reading from\n    |                |     memory.\n    +~~~~~~~~~~~~~~~~+ <-- The span of ko, i.e. the TCB surrounding and containing\n                           obj.\n\n    In this case, the process for extracting the CTE from the surrounding TCB\n    is more involved. See `loadObject_cte` in `ObjectInstances_H`.\n  \\<close>\n  fixes loadObject :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\"\n\n  \\<comment>\\<open>\n    `updateObject` is only used in the generic definition of `setObject`,\n    but it shows up in a few lemma statements as well. It describes how to update\n    the kernel object contents of memory depending on what's already in that\n    memory.\n\n    If `(ko', _) \\<in> updateObject v ko p before after s` within `setObject`, then:\n      - @{term \"v :: 'a\"} is the new object you want to write at pointer\n        @{term \"p :: machine_word\"}.\n      - @{term \"before :: machine_word\"} is the address of the nearest\n        object at or before `p`.\n      - @{term \"ko :: kernel_object\"} is the object currently at `before`.\n      - @{term \"after :: machine_word option\"} should be the address of the nearest\n        object after `p`, if any (for checking overlap).\n      - The returned value @{term \"ko' :: kernel_object\"} is the old object `ko`,\n        updated as required by `v`. This value gets inserted by `setObject` into\n        memory at the address `before`.\n\n    Graphically, the \"memory\" looks like this:\n\n    before  p              after\n    |-------|--+-----+-----|---|\n    |       +~~+ <---+---------- The span of v, the object we want to insert.\n    +~~~~~~~~~~~~~~~~+ <-------- The span of ko, the existing object that spans v.\n                                 This is also the span of ko', which will be what\n                                 gets put into memory after the update.\n\n                           +~~~+ The span of whatever object comes after ko.\n                                 We don't care about this beyond making sure\n                                 it doesn't overlap with ko before or after it\n                                 gets updated with v.\n\n    In almost every case, the object in memory (ko) is the same type of object\n    as the one being inserted (v). For example, for a reply object our parameters\n    look like this:\n\n    p, before\n    |-----------|\n    +~~~~~~~~~~~+ <- The span of three objects:\n                     - v, the new reply object we want to insert.\n                     - ko, the existing object (which should be a reply object).\n                     - ko', the new object (which should be a reply object if\n                       the previous one was).\n\n    In these simple cases, @{term updateObject_default} is a good specification\n    for how to update the existing kernel object.\n\n    The only interesting case is when we're updating a CTE, which might be\n    inside a TCB. Then memory looks like this:\n\n    before  p\n    |-------|--+-----+\n    |       +~~+ <---+---- The span of v, i.e. the CTE which we're inserting into\n    |                |     memory.\n    +~~~~~~~~~~~~~~~~+ <-- The span of ko, i.e. the TCB surrounding and containing v.\n                           This is also the span of ko', which is \"just\" a copy\n                           of ko with the relevant CTE updated.\n\n    In this case, the process for updating the surrounding TCB is more involved.\n    See `updateObject_cte` in `ObjectInstances_H`.\n  \\<close>\n  fixes updateObject :: \"'a \\<Rightarrow> kernel_object \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow>\n                              machine_word option \\<Rightarrow> kernel_object kernel\"\n\n  \\<comment>\\<open>\n    If updating an object succeeds, then the type of the updated object (ko')\n    should be the same as the original object (ko).\n  \\<close>\n  assumes updateObject_type:\n  \"(ko', s') \\<in> fst (updateObject v ko p p' p'' s) \\<Longrightarrow> koTypeOf ko' = koTypeOf ko\"\n\nend", "property": "Kernel Object Management: Provides a framework for managing kernel objects, including injecting and projecting objects, checking object types, and updating object contents while ensuring type consistency and alignment. \n\nType Consistency: Ensures that updating an object preserves its type, maintaining the integrity of kernel object management. \n\nAlignment and Magnitude Checks: Enforces alignment and magnitude constraints on object addresses to prevent memory corruption and ensure proper object placement.", "title": "./spec/design/skel/PSpaceStorable_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "|  CNodeRevokeIntent word32 word32", "property": "Revoke Capability: Revokes a capability at a specified index and depth within a CNode, ensuring that the targeted capability is removed and no longer accessible.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " Revoke: (target), index, depth "}
{"spec": "fun ensure_safe_mapping ::\n  \"(pte * word32 list) + (pde * word32 list) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n\"ensure_safe_mapping (Inl (InvalidPTE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inl (SmallPagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda>slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | SmallPagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inl (LargePagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | LargePagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inr (InvalidPDE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inr (PageTablePDE _ _ _, _)) = fail\"\n|\n\"ensure_safe_mapping (Inr (SectionPDE _ _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SectionPDE _ _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"\n|\n\"ensure_safe_mapping (Inr (SuperSectionPDE _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SuperSectionPDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"", "property": "Ensure Safe Mapping: Verify that page table or directory entries being replaced are either invalid or have the same granularity as the new entry, preventing unsafe mappings that could compromise memory integrity. \n\nSubproperties:\n- Invalid entries can be safely replaced.\n- Entries of the same granularity (e.g., SmallPagePTE, LargePagePTE, SectionPDE, SuperSectionPDE) can be safely replaced.\n- Entries of different granularities cannot be replaced, throwing a DeleteFirst error.", "title": "./spec/abstract/ARM/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Placing an entry which maps a frame within the set of entries that map a\nlarger frame is unsafe. This function checks that given entries replace either\ninvalid entries or entries of the same granularity."}
{"spec": "end", "property": "Unfortunately, you haven't provided any code or comment for me to summarize. Please provide the necessary information, and I'll be happy to help you summarize the property.", "title": "./spec/abstract/Intro_Doc.thy", "chapter": "", "section": "", "comment": "<"}
{"spec": "text\\<open>The @{term syscall} operation generically describes the usual\nexecution of system calls in three phases, where the first phase may\nresult in a fault, the second phase may result in an error and the third\nphase may be interrupted. The first two phases are used for argument decoding\nand checking. The last phase commits and executes the system call.\n\nThe @{term syscall} operation has five arguments:\n\\begin{itemize}\n\\item the first operation @{text m_fault} to execute, that may\nresult in a fault;\n\\item the fault handler @{text h_fault} to execute if the first\noperation resulted in a fault;\n\\item the second operation @{text m_error} to execute (if no fault\noccurred in the first operation); this second operation may result in\nan error;\n\\item the error handler @{text h_error} to execute if the second\noperation resulted in an error;\n\\item the third and last operation @{text m_finalise} to execute (if\nno error occurred in the second operation); this operation may be\ninterrupted.\n\\end{itemize}\n\\<close>\n\ndefinition\n  syscall :: \"('a,'z::state_ext) f_monad\n                  \\<Rightarrow> (fault \\<Rightarrow> ('c,'z::state_ext) s_monad)\n                  \\<Rightarrow> ('a \\<Rightarrow> ('b,'z::state_ext) se_monad)\n                  \\<Rightarrow> (syscall_error \\<Rightarrow> ('c,'z::state_ext) s_monad)\n               \\<Rightarrow> ('b \\<Rightarrow> ('c,'z::state_ext) p_monad) \\<Rightarrow> ('c,'z::state_ext) p_monad\"\nwhere\n\"syscall m_fault h_fault m_error h_error m_finalise \\<equiv> doE\n    r_fault \\<leftarrow> without_preemption $ m_fault;\n    case r_fault of\n          Inl f \\<Rightarrow>   without_preemption $ h_fault f\n        | Inr a \\<Rightarrow>   doE\n            r_error \\<leftarrow> without_preemption $ m_error a;\n            case r_error of\n                  Inl e \\<Rightarrow>   without_preemption $ h_error e\n                | Inr b \\<Rightarrow>   m_finalise b\n        odE\nodE\"", "property": "System Call Execution: The system call operation is divided into three phases, each with its own handler for faults and errors. The first phase may result in a fault, the second phase may result in an error, and the third phase may be interrupted. Handlers are provided to manage faults and errors, ensuring that the system call can be executed correctly and safely.", "title": "./spec/abstract/Syscall_A.thy", "chapter": "System Calls", "section": "System call entry point", "comment": ""}
{"spec": "lemma ppn_len_def':\n  \"ppn_len = ipa_size - pageBits\"\n  by (simp add: ppn_len_val pageBits_def ipa_size_def Kernel_Config.config_ARM_PA_SIZE_BITS_40_def)\n\ndatatype pte =\n    InvalidPTE\n  | PagePTE\n      (pte_page_addr : paddr)\n      (pte_is_small_page : bool)\n      (pte_attr : vm_attributes)\n      (pte_rights : vm_rights)\n  | PageTablePTE\n      (pte_ppn : ppn)\n\ndefinition paddr_from_ppn :: \"ppn \\<Rightarrow> paddr\" where\n  \"paddr_from_ppn addr \\<equiv> ucast addr << pageBits\"\n\ndefinition pte_base_addr :: \"pte \\<Rightarrow> paddr\" where\n  \"pte_base_addr pte \\<equiv>\n    if is_PageTablePTE pte then paddr_from_ppn (pte_ppn pte) else pte_page_addr pte\"\n\ndefinition ppn_from_pptr :: \"obj_ref \\<Rightarrow> ppn\" where\n  \"ppn_from_pptr p = ucast (addrFromPPtr p >> pageBits)\"", "property": "Page Table Entry (PTE) Structure: Defines the structure of a page table entry, which can represent an invalid entry, a small or large page with associated attributes and rights, or a page table. The base address of a PTE is determined based on its type, either from the page address for a page entry or from the page table physical number for a page table entry.", "title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "chapter": "AARCH64-Specific Data Types", "section": "Architecture-specific object types and default objects", "comment": "This lemma encodes @{typ ppn_len} value above as a term, so we can use it generically:"}
{"spec": "definition\n  cap_delete :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n \"cap_delete slot \\<equiv> doE rec_del (CTEDeleteCall slot True); returnOk () odE\"", "property": "Capability Deletion: Delete a capability from the capability space by performing a recursive delete operation on the specified slot.", "title": "./spec/abstract/CSpace_A.thy", "chapter": "CSpace", "section": "Revoking and deleting capabilities", "comment": "Delete a capability by calling the recursive delete operation."}
{"spec": "text \\<open>\n  The kernel init monad can fail. The actual value of the failure is largely\n  irrelevant, just so long as we don't have assertion failures for no reason.\n\\<close>\n\ndatatype ki_failure = InitFailure\ntype_synonym ('a,'z) ki_monad = \"('z ki_state, ki_failure + 'a) nondet_monad\"\ntranslations\n  (type) \"'a ki_monad\" <=\n    (type) \"((ki_failure + 'a) \\<times> ki_state \\<Rightarrow> bool) \\<times> bool\"", "property": "Kernel Initialization Monad: The kernel initialization monad can fail, with the failure value being largely irrelevant. It is designed to prevent assertion failures without a valid reason.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init monad", "comment": ""}
{"spec": "lemma cap_in_caps_insert [simp]:\n  \"c \\<in>cap insert c' S = (target c = target c' \\<and>\n  rights (extra_rights c) \\<subseteq> rights (extra_rights c') \\<or> c \\<in>cap S)\"\n  by (simp add: cap_in_caps_def)\n\nlemma cap_in_caps_singleton [simp]:\n  \"c \\<in>cap {c'} = (target c = target c' \\<and> rights (extra_rights c) \\<subseteq> rights (extra_rights c'))\"\n  by (simp add: cap_in_caps_def)\n\nlemma not_in [simp]:\n  \"{} \\<le>cap c\"\n  by(simp add: caps_dominated_by_def)\n\nlemma extra_rights_diminish:\n  \"x \\<in> rights (extra_rights (diminish r c))\n   \\<Longrightarrow> x \\<in> rights (extra_rights c)\"\n  by (auto simp: rights_extra_rights all_rights_def split:if_split_asm)", "property": "Capability Set Properties: \n- A capability is in the set of capabilities after inserting a new capability if the new capability has the same target and its rights are a superset of the original capability's rights, or if the original capability is already in the set.\n- A capability is in a singleton set of capabilities if the targets match and the rights of the original capability are a subset of the rights of the capability in the set.\n- An empty set of capabilities is dominated by any capability.\n- Diminishing the rights of a capability does not add new rights to the capability.", "title": "./spec/take-grant/Confine_S.thy", "chapter": "", "section": "", "comment": " Lemmas on caps "}
{"spec": "definition gets_map :: \"('s \\<Rightarrow> 'a \\<Rightarrow> 'b option) \\<Rightarrow> 'a \\<Rightarrow> ('s, 'b) nondet_monad\" where\n  \"gets_map f p \\<equiv> gets f >>= (\\<lambda>m. assert_opt (m p))\"", "property": "Get Value from State Map: Retrieves a value from a map in the current state by applying a given argument to the map, failing if the map returns None. \n\nGet Map Value Existence: The map must contain the requested key to retrieve a value successfully. \n\nGet Map Value Failure: If the map does not contain the requested key, the operation will fail.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "\n  Get a map (such as a heap) from the current state and apply an argument to the map.\n  Fail if the map returns @{const None}, otherwise return the value."}
{"spec": "lemma uint_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> uint (maxIRQ::'a word) = maxIRQ\"\n  by (metis Kernel_Config.maxIRQ_def of_nat_numeral uint_nat unat_maxIRQ)", "property": "Uint Conversion for maxIRQ: Ensures that the conversion of `maxIRQ` to its unsigned integer representation is safe and retains the original value, provided that the length of `irq_len` does not exceed the bit width of the word type.", "title": "./spec/machine/ARM_HYP/Arch_Kernel_Config_Lemmas.thy", "chapter": "", "section": "", "comment": " Safe for [simp] because we don't use maxIRQ at lower than irq_len "}
{"spec": "instantiation X64_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pte updateObject_pte\n  loadObject_pde updateObject_pde\n  loadObject_pdpte updateObject_pdpte\n  loadObject_pml4e updateObject_pml4e\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend", "property": "ASID Pool Object Management: Create, load, and update ASID pool objects with a fixed-size array of 2^32 entries, initialized with null values, ensuring efficient management of address space identifiers.", "title": "./spec/design/skel/X64/ArchObjInsts_H.thy", "chapter": "", "section": "", "comment": " This is hard coded since using funArray in haskell for 2^32 bound is risky "}
{"spec": "definition\n  get_pdpte :: \"obj_ref \\<Rightarrow> (pdpte,'z::state_ext) s_monad\" where\n  \"get_pdpte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pdpt_bits);\n     offset \\<leftarrow> return ((ptr && mask pdpt_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pdpt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pdpte :: \"obj_ref \\<Rightarrow> pdpte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pdpte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pdpt_bits);\n    offset \\<leftarrow> return ((p && mask pdpt_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pdpt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pdpt base pt'\n  od\"\n\ndefinition\n  get_pml4 :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pml4e,'z::state_ext) s_monad\" where\n  \"get_pml4 ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageMapL4 pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pml4 :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pml4e) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pml4 ptr pt \\<equiv> set_object ptr (ArchObj (PageMapL4 pt))\"", "property": "VSpace Access and Modification: Provides functions to access and modify the x64 virtual address space, including retrieving and storing PDPTEs, and getting and setting the PML4 table. These operations ensure that the kernel can manage and manipulate the virtual memory mappings effectively.", "title": "./spec/abstract/X64/ArchVSpaceAcc_A.thy", "chapter": "Accessing the x64 VSpace", "section": "Kernel Heap Accessors", "comment": "The following function takes a pointer to a PDPTE in kernel memory\n  and returns the actual PDPTE."}
{"spec": "definition\ndelete_asid :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pd \\<equiv> do\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  (case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (ucast asid) = Some pd) $ do\n                flush_space asid;\n                invalidate_asid_entry asid;\n                pool' \\<leftarrow> return (pool (ucast asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od)\nod\"", "property": "Delete ASID: Deactivate and remove a page directory from an ASID pool. If the ASID is found in the pool, it flushes the space, invalidates the ASID entry, updates the pool to remove the page directory, and sets the VM root for the current thread.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "When deleting a page directory from an ASID pool we must deactivate\nit."}
{"spec": "definition\n  slot_bits :: nat where\n  \"slot_bits \\<equiv> 4\"\n\ndefinition\n  msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 20\"\n\ndefinition\n  new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext ((\\<lambda>r. 0) (CPSR := 0x150))\"", "property": "Architecture-Dependent Sizes: Define the standard sizes for slots and message labels, as well as the initial user context, which are specific to the underlying machine architecture.", "title": "./spec/abstract/ARM/Machine_A.thy", "chapter": "", "section": "", "comment": "The following definitions provide architecture-dependent sizes\n  such as the standard page size and capability size of the underlying\n  machine.\n"}
{"spec": "definition riscv_global_pt :: \"arch_state \\<Rightarrow> obj_ref\"\n  where\n  \"riscv_global_pt s = the_elem (riscv_global_pts s max_pt_level)\"\n\nlocale_abbrev global_pt :: \"'z state \\<Rightarrow> obj_ref\"\n  where\n  \"global_pt s \\<equiv> riscv_global_pt (arch_state s)\"", "property": "Extract Top-Level Global Page Table: Retrieve the single top-level global page table from the architecture state.", "title": "./spec/abstract/RISCV64/ArchVSpaceAcc_A.thy", "chapter": "Accessing the RISCV64 VSpace", "section": "Basic Operations", "comment": "Interface function to extract the single top-level global page table:"}
{"spec": "(*\n * Operations on CSpace\n *)\n\ntheory CSpace_D\nimports\n  PageTableUnmap_D\nbegin", "property": "CSpace Operations: Define and manage the operations related to the capability space, ensuring the proper allocation, manipulation, and deallocation of capabilities within the system.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "definition\nfind_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"find_vspace_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (x64_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pml4 \\<leftarrow> returnOk (pool (asid_low_bits_of asid));\n    (case pml4 of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"", "property": "Locate Page Directory: Find the page directory associated with a given virtual ASID by navigating through the ASID table and ASID pool, ensuring the ASID is valid and returning the corresponding PML4 pointer. If the ASID or PML4 entry is not found, an error is thrown.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Locate the page directory associated with a given virtual ASID."}
{"spec": "(*\n    VSpace lookup code.\n*)\n\ntheory VSpace_H\nimports\n  CNode_H\n  ArchVSpace_H\n  KernelInitMonad_H\nbegin\n\narch_requalify_consts (H)\n  mapKernelWindow\n  activateGlobalVSpace\n  initIRQController\n  createIPCBufferFrame\n  createBIFrame\n  createFramesOfRegion\n  createITPDPTs\n  writeITPDPTs\n  createITASIDPool\n  writeITASIDPool\n  createDeviceFrames\n  handleVMFault\n  isValidVTableRoot\n  checkValidIPCBuffer\n  lookupIPCBuffer\n  vptrFromPPtr\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace.lhs Arch= ONLY initKernelVM initPlatform initCPU\n\nend", "property": "VSpace Initialization and Management: Initialize and manage the virtual space, including creating and activating the global virtual space, initializing the IRQ controller, creating and managing frames for IPC buffers, device frames, and other regions, and handling VM faults. This ensures that the virtual memory is properly set up and maintained for efficient and secure operation.", "title": "./spec/design/skel/VSpace_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "definition vcpu_finalise :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_finalise vr \\<equiv> do\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of\n      Some t \\<Rightarrow> dissociate_vcpu_tcb vr t\n    | None \\<Rightarrow> return ()\n   od\"\n\nend\nend", "property": "VCPU Finalisation: Prepare a VCPU for removal by dissociating it from its associated TCB and cleaning up current VCPU state if necessary.", "title": "./spec/abstract/AARCH64/VCPUAcc_A.thy", "chapter": "AARCH64 VCPU Accessor Functions", "section": "Manipulation of VCPU-related state and registers", "comment": "\n  Prepare a given VCPU for removal: dissociate it, and clean up current VCPU state\n  if necessary."}
{"spec": "lemma returnOk_bindE[simp]: \"(returnOk x >>=E f) = f x\"\n  unfolding bindE_def returnOk_def\n  by (clarsimp simp: lift_def)\n\nlemma lift_return[simp]:\n  \"lift (return \\<circ> Inr) = return\"\n  by (auto simp: lift_def throwError_def split: sum.splits)", "property": "Left Return Absorption: The `returnOk` function, when bound with another function `f` using the `bindE` operator, is equivalent to simply applying `f` to the value. This property ensures that `returnOk` acts as a left identity for the `bindE` operation, maintaining the integrity and consistency of the monadic computation.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "Left @{const returnOk} absorbtion over @{term bindE}:"}
{"spec": "definition\n  decode_page_directory_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_page_directory_intent \\<Rightarrow> cdl_page_directory_invocation except_monad\"\nwhere\n  \"decode_page_directory_invocation target target_ref caps intent \\<equiv>\n      (returnOk $ PageDirectoryNothing) \\<sqinter>\n      (returnOk $ PageDirectoryFlush Unify)  \\<sqinter>  (returnOk $ PageDirectoryFlush Clean)  \\<sqinter>\n      (returnOk $ PageDirectoryFlush CleanInvalidate )  \\<sqinter> (returnOk $ PageDirectoryFlush Invalidate)\n      \\<sqinter> throw \"", "property": "Page Directory Invocation Decoding: Decode a page directory intent into a specific invocation, which can result in either no action (PageDirectoryNothing) or various flushing operations (Unify, Clean, CleanInvalidate, Invalidate) on the page directory.", "title": "./spec/capDL/PageTable_D.thy", "chapter": "", "section": "", "comment": " Decode a page table intent into an invocation. "}
{"spec": "| PendingSyncRecvCap cdl_object_id bool bool\n  | PendingNtfnRecvCap cdl_object_id", "property": "Pending Synchronization and Notification Capabilities: A thread can be in a state where it is waiting for a reply, during which it can grant synchronization or notification capabilities.", "title": "./spec/capDL/Types_D.thy", "chapter": "", "section": "", "comment": " thread, is waiting for reply, can grant "}
{"spec": "text \\<open>\n  This function is the main kernel entry point. The main event loop of the\n  kernel handles events, handles a potential preemption interrupt, schedules\n  and switches back to the active thread.\n\\<close>\n\ndefinition\n  call_kernel :: \"event \\<Rightarrow> (unit,'z::state_ext_sched) s_monad\" where\n  \"call_kernel ev \\<equiv> do\n       handle_event ev <handle>\n           (\\<lambda>_. without_preemption $ do\n                  irq \\<leftarrow> do_machine_op $ getActiveIRQ True;\n                  when (irq \\<noteq> None) $ handle_interrupt (the irq)\n                od);\n       schedule;\n       activate_thread\n   od\"\n\nend", "property": "Kernel Entry Point: Manages the main event loop by handling events, managing potential preemption interrupts, and scheduling threads. It ensures that the system processes events, handles interruptions, and switches to the active thread efficiently.", "title": "./spec/abstract/Syscall_A.thy", "chapter": "System Calls", "section": "Kernel entry point", "comment": ""}
{"spec": "lemma direct_caps_of_s0_e0_caps [simp]:\n  \"direct_caps_of s0 0 = e0_caps\"\n  by (simp add: direct_caps_of_def s0_def e0_caps_def)\n\nlemma direct_caps_of_s1_e0_caps [simp]:\n  \"direct_caps_of s1 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s1_def e0_caps_def)\n\nlemma direct_caps_of_s2_e0_caps [simp]:\n  \"direct_caps_of s2 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s2_def e0_caps_def)\n\nlemma direct_caps_of_s4_e0_caps [simp]:\n  \"direct_caps_of s4 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s4_def e0_caps_def)\n\nlemma direct_caps_of_s5_e0_caps [simp]:\n  \"direct_caps_of s5 0 = e0_caps \\<union> {full_cap 1, write_cap 2}\"\n  by (simp add: direct_caps_of_def s5_def e0_caps_def)\n\nlemma direct_caps_of_s6_e0_caps [simp]:\n  \"direct_caps_of s6 0 = e0_caps \\<union> {full_cap 1, write_cap 2}\"\n  by (simp add: direct_caps_of_def s6_def e0_caps_def)\n\nlemma direct_caps_of_s8_e0_caps [simp]:\n  \"direct_caps_of s8 0 = e0_caps \\<union> {full_cap 1, full_cap 3}\"\n  by (simp add: direct_caps_of_def s8_def e0_caps_def)\n\nlemma direct_caps_of_s9_e0_caps [simp]:\n  \"direct_caps_of s9 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s9_def e0_caps_def)\n\n\nlemma direct_caps_of_s2_e1 [simp]:\n  \"direct_caps_of s2 1 = {create_cap 2}\"\n  by (simp add: direct_caps_of_def s2_def)\n\nlemma direct_caps_of_s3_e1 [simp]:\n  \"direct_caps_of s3 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>}\"\n  by (simp add: direct_caps_of_def s3_def)\n\nlemma direct_caps_of_s4_e1 [simp]:\n  \"direct_caps_of s4 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s4_def)\n\nlemma direct_caps_of_s6_e1 [simp]:\n  \"direct_caps_of s5 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s5_def)\n\nlemma direct_caps_of_s9_e1 [simp]:\n  \"direct_caps_of s9 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s9_def)\n\n\nlemma full_cap_e0_caps_in_caps_of_s0_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s0 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e1_in_caps_of_s1_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s1 0\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e1_in_caps_of_s2_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s2 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e0_caps_in_caps_of_s4_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e1_in_caps_of_s4_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e2_in_caps_of_s4_e1 [simp]:\n  \"full_cap 2 \\<in> caps_of s4 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e1_in_caps_of_s5_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s5 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e2_in_caps_of_s5_e0_caps [simp]:\n  \"full_cap 2 \\<in> caps_of s5 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e0_caps_in_caps_of_s8_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s8 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s0_e0_caps [simp]:\n  \"create_cap i \\<in> caps_of s0 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s1_e0_caps [simp]:\n  \"create_cap i \\<in> caps_of s1 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s2_e1 [simp]:\n  \"create_cap 2 \\<in> caps_of s2 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma create_cap_in_caps_of_s3_e1 [simp]:\n  \"create_cap 2 \\<in> caps_of s3 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma create_cap_in_caps_of_s4_e3 [simp]:\n  \"create_cap 3 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s9_e3 [simp]:\n  \"create_cap 3 \\<in> caps_of s9 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma write_store_e1_in_caps_of_s3_e1 [simp]:\n  \"\\<lparr>target = 1, rights = {Write, Store}\\<rparr>  \\<in> caps_of s3 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma write_store_e1_in_caps_of_s5_e1 [simp]:\n  \"\\<lparr>target = 1, rights = {Write, Store}\\<rparr> \\<in> caps_of s5 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma write_cap_e2_in_caps_of_s6_e0_caps [simp]:\n  \"write_cap 2 \\<in> caps_of s6 0\"\n  by (rule direct_cap_in_cap, simp)", "property": "Direct and Indirect Capabilities: The lemmas define the direct and indirect capabilities associated with different states (s0, s1, s2, etc.) and their respective indices. Each state has a specific set of capabilities, which may include full, create, and write/store rights, and these capabilities are combined or extended in subsequent states.", "title": "./spec/take-grant/Example2.thy", "chapter": "", "section": "", "comment": " direct_caps_of, caps_of and similar lemmas "}
{"spec": "definition assert :: \"bool \\<Rightarrow> ('a, unit) nondet_monad\" where\n  \"assert P \\<equiv> if P then return () else fail\"", "property": "Property: Assertion Validation: Ensures that a given property \\( P \\) holds, failing the computation if \\( P \\) is not true.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "Assertions: fail if the property @{text P} is not true"}
{"spec": "text \\<open>The following two definitions decode system calls for the\ninterrupt controller and interrupt handlers\\<close>\n\ndefinition\n  decode_irq_control_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list\n                                     \\<Rightarrow> (irq_control_invocation,'z::state_ext) se_monad\" where\n \"decode_irq_control_invocation label args src_slot cps \\<equiv>\n  (if gen_invocation_type label = IRQIssueIRQHandler\n    then if length args \\<ge> 3 \\<and> length cps \\<ge> 1\n      then let irq_word = args ! 0;\n               index = args ! 1;\n               depth = args ! 2;\n               cnode = cps ! 0;\n               irq = ucast irq_word\n      in doE\n        arch_check_irq irq_word;\n        irq_active \\<leftarrow> liftE $ is_irq_active irq;\n        whenE irq_active $ throwError RevokeFirst;\n\n        dest_slot \\<leftarrow> lookup_target_slot\n               cnode (data_to_cptr index) (unat depth);\n        ensure_empty dest_slot;\n\n        returnOk $ IRQControl irq dest_slot src_slot\n      odE\n    else throwError TruncatedMessage\n  else liftME ArchIRQControl $ arch_decode_irq_control_invocation label args src_slot cps)\"\n\ndefinition\n  decode_irq_handler_invocation :: \"data \\<Rightarrow> irq \\<Rightarrow> (cap \\<times> cslot_ptr) list\n                                     \\<Rightarrow> (irq_handler_invocation,'z::state_ext) se_monad\" where\n \"decode_irq_handler_invocation label irq cps \\<equiv>\n  if gen_invocation_type label = IRQAckIRQ\n    then returnOk $ ACKIrq irq\n  else if gen_invocation_type label = IRQSetIRQHandler\n    then if cps \\<noteq> []\n      then let (cap, slot) = hd cps in\n      if is_ntfn_cap cap \\<and> AllowSend \\<in> cap_rights cap\n      then returnOk $ SetIRQHandler irq cap slot\n      else throwError $ InvalidCapability 0\n    else throwError TruncatedMessage\n  else if gen_invocation_type label = IRQClearIRQHandler\n    then returnOk $ ClearIRQHandler irq\n  else throwError IllegalOperation\"", "property": "IRQ Decoding: Decodes system calls for interrupt controller and interrupt handlers, ensuring that the invocation type matches the expected format and that the provided arguments and capabilities are valid.\n\nSubproperties:\n- IRQ Issue IRQ Handler: Validates the IRQ word, checks if the IRQ is active, and ensures the destination slot is empty before issuing the IRQ handler.\n- IRQ Handler Invocation: Decodes the invocation type and validates the provided capabilities and arguments for ACK IRQ, Set IRQ Handler, and Clear IRQ Handler operations.", "title": "./spec/abstract/Decode_A.thy", "chapter": "Decoding System Calls", "section": "IRQ", "comment": ""}
{"spec": "definition canonical_user :: \"vspace_ref\" where\n  \"canonical_user \\<equiv> mask ipa_size\"", "property": "Canonical User Address: The highest user-virtual address that is still canonical, defining the upper limit of the canonical address space for users.", "title": "./spec/abstract/AARCH64/Init_A.thy", "chapter": "", "section": "", "comment": " The highest user-virtual address that is still canonical.\n   It can be larger than user_vtop, which is the highest address we allow to be mapped.\n   For AArch64-hyp, user-virtual addresses are IPAs and since there is no sign extension,\n   the value is the top of the entire IPA address space. "}
{"spec": "|  ArchIrqControlIssueIrqHandlerIntent cdl_arch_irq_control_intent\n\ndatatype cdl_page_table_intent =", "property": "Interrupt Control: Manage interrupt-related operations, including issuing IRQ handler intents for specific architectures.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " InterruptControl "}
{"spec": "(*\nFunctions for fault handling.\n*)\n\nchapter \\<open>arch fault related functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n  \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData) od\"\n| \"make_arch_fault_msg (VCPUFault hsr) thread = return (7, [hsr])\"\n| \"make_arch_fault_msg (VPPIEvent irq) thread = return (8, [ucast irq])\"\n| \"make_arch_fault_msg (VGICMaintenance archData) thread = do\n      msg \\<leftarrow> return $ (case archData of None \\<Rightarrow> [-1] | Some idx \\<Rightarrow> [idx]);\n      return (6, msg)\n   od\"\n\ndefinition\n  handle_arch_fault_reply :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_arch_fault_reply af thread x y = return True\"\n\n\nend\n\nend", "property": "Arch Fault Handling: Provides functions for creating architecture-specific fault messages and handling replies to these faults, ensuring proper communication and error handling in the system.\n\nSubproperties:\n- Make Arch Fault Message: Creates a fault message based on the type of architecture-specific fault (e.g., VM fault, VCPU fault, VPPI event, VGIC maintenance) and the thread experiencing the fault.\n- Handle Arch Fault Reply: Handles the reply to an architecture-specific fault, currently always returning True.", "title": "./spec/abstract/ARM_HYP/ArchFault_A.thy", "chapter": "arch fault related functions", "section": "", "comment": ""}
{"spec": "definition assertE :: \"bool \\<Rightarrow> ('a, 'e + unit) nondet_monad\" where\n  \"assertE P \\<equiv> if P then returnOk () else fail\"", "property": "Assert Property: Ensure that a condition is met, returning success if true and failure if false.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "\n  Failure in the exception monad is redefined in the same way\n  as @{const whenE} and @{const unlessE}, with @{term returnOk}\n  instead of @{term return}."}
{"spec": "pd_pptr \\<leftarrow> create_objects PD_SIZE_BITS PD_SIZE_BITS\n                              (ArchObject PageDirectoryObj);\n     pd_cap \\<leftarrow> returnOk $ ArchObjectCap $\n                           PageDirectoryCap pd_pptr (Some IT_ASID);\n     do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_PD)\n                               pd_cap;", "property": "Create and Initialize Page Directory: Create a page directory object and its corresponding capability, then write the capability to the specified slot in the root CNode. This ensures that the page directory is properly set up and accessible for memory management operations.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " create PD obj and cap "}
{"spec": "datatype arch_gen_obj_ref = unit\n\ndefinition arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\" where\n  \"arch_gen_obj_refs ac \\<equiv> {}\"\n\ndefinition arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\" where\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend", "property": "Arch-Specific Generic Object References: The system defines arch-specific generic object references, but they are not covered by the generic references. The set of arch-specific generic object references for any arch_cap is empty, and the cleanup operation for any arch_cap results in a NullCap.", "title": "./spec/abstract/AARCH64/ArchIpcCancel_A.thy", "chapter": "", "section": "", "comment": "Arch specific generic object references not covered by generic references"}
{"spec": "record arch_state =\n  x64_asid_table            :: \"3 word \\<rightharpoonup> obj_ref\"\n  x64_global_pml4           :: obj_ref\n  x64_kernel_vspace         :: X64_A.x64_vspace_region_uses\n  x64_global_pts            :: \"obj_ref list\"\n  x64_global_pdpts          :: \"obj_ref list\"\n  x64_global_pds            :: \"obj_ref list\"\n  x64_current_cr3           :: \"X64_A.cr3\"\n  x64_allocated_io_ports    :: \"X64_A.io_port \\<Rightarrow> bool\"\n  x64_num_ioapics           :: \"64 word\"\n  x64_ioapic_nirqs          :: \"machine_word \\<Rightarrow> 8 word\"\n  x64_irq_state             :: \"8 word \\<Rightarrow> X64_A.X64IRQState\"\n\n\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  pd_shift_bits :: \"nat\" where\n  \"pd_shift_bits \\<equiv> pageBits + ptTranslationBits\"\n\ndefinition\n  pt_shift_bits :: \"nat\" where\n  \"pt_shift_bits \\<equiv> pageBits\"\n\ndefinition\n  pdpt_shift_bits :: \"nat\" where\n  \"pdpt_shift_bits \\<equiv> pageBits + ptTranslationBits + ptTranslationBits\"\n\ndefinition\n  pml4_shift_bits :: \"nat\" where\n  \"pml4_shift_bits \\<equiv> pageBits + ptTranslationBits + ptTranslationBits + ptTranslationBits\"\n\ndefinition\n  pt_bits :: \"nat\" where\n  \"pt_bits \\<equiv> table_size\"\n\ndefinition\n  pd_bits :: \"nat\" where\n  \"pd_bits \\<equiv> table_size\"\n\ndefinition\n  pdpt_bits :: \"nat\" where\n  \"pdpt_bits \\<equiv> table_size\"\n\ndefinition\n  pml4_bits :: \"nat\" where\n  \"pml4_bits \\<equiv> table_size\"\n\ndefinition\n  iopt_bits :: \"nat\" where\n  \"iopt_bits \\<equiv> iotable_size\"\n\ndefinition\n  vtd_cte_size_bits :: \"nat\" where\n  \"vtd_cte_size_bits \\<equiv> 8\"\n\ndefinition\n  vtd_pt_bits :: \"nat\" where\n  \"vtd_pt_bits \\<equiv> iotable_size\"\n\ndefinition\n  x64_num_io_pt_levels :: \"nat\" where\n  \"x64_num_io_pt_levels \\<equiv> 4\"", "property": "x64 Architecture State: Defines the architecture-specific state for x64, including the ASID table, global PML4, kernel virtual space, global page tables, and I/O port management. It provides a set of definitions for various bit shifts and sizes used in the x64 architecture, such as page directory shifts, page table shifts, and I/O port table sizes.\n\nSubproperties:\n- ASID Table Management: Manages the x64 ASID table, which maps ASIDs to object references.\n- Global Page Table Management: Manages the global PML4, page directories, and page tables for the x64 architecture.\n- I/O Port Management: Manages the allocated I/O ports, I/O APICs, and IRQ states for the x64 architecture.\n- Bit Shift and Size Definitions: Defines various bit shifts and sizes used in the x64 architecture, such as page directory shifts, page table shifts, and I/O port table sizes.", "title": "./spec/abstract/X64/Arch_Structs_A.thy", "chapter": "x64-Specific Data Types", "section": "Architecture-specific state", "comment": ""}
{"spec": "definition\n  ptrBits_def[simp]:\n \"ptrBits \\<equiv> to_bl\"\n\n#INCLUDE_HASKELL SEL4/Model/PSpace.lhs ONLY ptrBitsForSize", "property": "Pointer Bits Conversion: Convert a pointer to a list of bits.", "title": "./spec/design/skel/PSpaceStruct_H.thy", "chapter": "", "section": "", "comment": "Helper Functions"}
{"spec": "ap_pptr \\<leftarrow> create_objects ASID_POOL_SIZE_BITS\n                              ASID_POOL_SIZE_BITS (ArchObject ASIDPoolObj);\n\n     ap_cap \\<leftarrow> returnOk $ ArchObjectCap $\n                 ASIDPoolCap ap_pptr (IT_ASID >> asid_low_bits);\n\n     do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap\n                                BI_CAP_IT_ASID_POOL) ap_cap;", "property": "ASID Pool Initialization: Create an ASID pool and initialize it with a specified size, then generate a capability for the ASID pool and write this capability into the root CNode.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " create ASID pool "}
{"spec": "chapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT ARM_H ARMHardware=ARM bodies_only\n\nend\nend", "property": "No specific property can be summarized from the given code snippet as it appears to be a header or import section, and does not contain any specific functionality or behavior that can be described as a property.", "title": "./spec/design/skel/ARM/ArchThread_H.thy", "chapter": "Threads", "section": "", "comment": ""}
{"spec": "| PageGetAddressIntent\n\n\ndatatype cdl_page_directory_intent =\n   PageDirectoryFlushIntent\n | PageDirectoryNothingIntent\n\ndatatype cdl_asid_control_intent =", "property": "Get Address Intent: Retrieve the address associated with a page or other memory-related entity.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " GetAddress "}
{"spec": "datatype flush_type = Clean | Invalidate | CleanInvalidate | Unify\n\ndatatype page_directory_invocation =\n    PageDirectoryFlush (pd_flush_type: flush_type) (pd_flush_start: vspace_ref)\n                       (pd_flush_end: vspace_ref) (pd_flush_pstart: word32)\n                       (pd_flush_pd: obj_ref) (pd_flush_asid: asid)\n  | PageDirectoryNothing\n\ndatatype page_table_invocation =\n    PageTableMap cap cslot_ptr pde obj_ref\n  | PageTableUnmap cap cslot_ptr\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation\n     = PageMap\n         (page_map_asid: asid)\n         (page_map_cap: cap)\n         (page_map_ct_slot: cslot_ptr)\n         (page_map_entries: \"pte \\<times> (obj_ref list) + pde \\<times> (obj_ref list)\")\n     | PageUnmap\n         (page_unmap_cap: arch_cap)\n         (page_unmap_cap_slot: cslot_ptr)\n     | PageFlush\n         (page_flush_type: flush_type)\n         (page_flush_start: vspace_ref)\n         (page_flush_end: vspace_ref)\n         (page_flush_pstart: word32)\n         (page_flush_pd: obj_ref)\n         (page_flush_asid: asid)\n     | PageGetAddr\n         (page_get_paddr: obj_ref)\n\ndatatype arch_invocation\n     = InvokePageTable page_table_invocation\n     | InvokePageDirectory page_directory_invocation\n     | InvokePage page_invocation\n     | InvokeASIDControl asid_control_invocation\n     | InvokeASIDPool asid_pool_invocation\n\ndatatype arch_copy_register_sets = ARMNoExtraRegisters\n\ndefinition \"ArchDefaultExtraRegisters \\<equiv> ARMNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    ArchIRQControlIssue irq cslot_ptr cslot_ptr bool\n\nend\n\nend", "property": "ARM-Specific System Call Arguments: Define the arguments for various ARM-specific system calls, including page directory, page table, ASID control, ASID pool, page, and IRQ control invocations. These arguments specify the necessary parameters for each system call, ensuring that the kernel can correctly manage memory, interrupts, and other ARM-specific features.\n\nSubproperties:\n- Page Directory Invocation: Specify the type of flush operation, start and end addresses, page directory, and ASID for page directory flush operations.\n- Page Table Invocation: Define the parameters for mapping and unmapping page tables, including the capability, slot pointer, and object reference.\n- ASID Control Invocation: Specify the parameters for creating an ASID pool, including the object reference, slot pointers, and ASID.\n- ASID Pool Invocation: Define the parameters for assigning an ASID to a pool, including the ASID, object reference, and slot pointer.\n- Page Invocation: Specify the parameters for page operations, including mapping, unmapping, flushing, and getting the physical address of a page.\n- IRQ Control Invocation: Define the parameters for issuing an IRQ, including the IRQ number, slot pointers, and a boolean flag.", "title": "./spec/abstract/ARM/ArchInvocation_A.thy", "chapter": "", "section": "", "comment": "These datatypes encode the arguments to the various possible\nARM-specific system calls. Selectors are defined for various fields\nfor convenience elsewhere."}
{"spec": "theory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H decls_only NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H instanceproofs NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H bodies_only NOT makeVCPUObject", "property": "Architectural Structures: Define the structures and settings for the ARM architecture, including ASID pools and architectural TCBs, to provide a foundation for the kernel's hardware interactions and management.", "title": "./spec/design/skel/ARM_HYP/ArchStructures_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "definition\n  get_mrs :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> message_info \\<Rightarrow>\n              (message list,'z::state_ext) s_monad\" where\n  \"get_mrs thread buf info \\<equiv> do\n     context \\<leftarrow> thread_get (arch_tcb_get_registers o tcb_arch) thread;\n     cpu_mrs \\<leftarrow> return (map context msg_registers);\n     buf_mrs \\<leftarrow> case buf\n       of None      \\<Rightarrow> return []\n        | Some pptr \\<Rightarrow> mapM (\\<lambda>x. load_word_offs pptr x)\n               [length msg_registers + 1 ..< Suc msg_max_length];\n     return (take (unat (mi_length info)) $ cpu_mrs @ buf_mrs)\n   od\"\n\nend", "property": "Message Register Retrieval: Collects message registers from both the sending thread's current register file and its IPC buffer, ensuring that all necessary data for the message is gathered.", "title": "./spec/abstract/Tcb_A.thy", "chapter": "Threads and TCBs", "section": "Thread Message Formats", "comment": "Get all of the message registers, both from the sending thread's current\nregister file and its IPC buffer."}
{"spec": "definition check_vp_alignment :: \"vmpage_size \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $ throwError AlignmentError\"\n\ndefinition page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\" where\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"", "property": "Virtual Address Alignment and Page Base Calculation: Ensure that a virtual address is properly aligned according to the given page size, and calculate the base address of a page in a virtual address space. \n\nSubproperties:\n- Virtual Address Alignment: Verify that a virtual address is aligned to the required page size to prevent alignment errors.\n- Page Base Calculation: Calculate the base address of a page by masking the lower bits of the virtual address according to the page size.", "title": "./spec/abstract/AARCH64/ArchDecode_A.thy", "chapter": "Decoding Architecture-specific System Calls", "section": "Architecture-specific Decode Functions", "comment": ""}
{"spec": "definition\nget_hw_asid :: \"asid \\<Rightarrow> (hardware_asid,'z::state_ext) s_monad\" where\n\"get_hw_asid asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  (case maybe_hw_asid of\n    Some hw_asid \\<Rightarrow> return hw_asid\n  | None \\<Rightarrow>  do\n      new_hw_asid \\<leftarrow> find_free_hw_asid;\n      store_hw_asid asid new_hw_asid;\n      return new_hw_asid\n  od)\nod\"\n\n\nabbreviation\n  \"arm_context_switch_hwasid pd hwasid \\<equiv> do\n              set_current_pd $ addrFromPPtr pd;\n              setHardwareASID hwasid\n          od\"\n\ndefinition\n  arm_context_switch :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arm_context_switch pd asid \\<equiv> do\n      hwasid \\<leftarrow> get_hw_asid asid;\n      do_machine_op $ arm_context_switch_hwasid pd hwasid\n    od\"", "property": "Hardware ASID Retrieval and Assignment: Retrieve the hardware ASID associated with a given virtual ASID, and if none is assigned, find and assign a new hardware ASID. This ensures that each virtual ASID has a corresponding hardware ASID for proper memory management.", "title": "./spec/abstract/ARM/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Get the hardware ASID associated with a virtual ASID, assigning one if\nnone is already assigned."}
{"spec": "definition\ninvalidate_asid_entry :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid_entry asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  when (maybe_hw_asid \\<noteq> None) $ invalidate_hw_asid_entry (the maybe_hw_asid);\n  invalidate_asid asid\nod\"", "property": "Invalidate ASID Entry: Remove virtual to physical mappings associated with a given ASID, including invalidating the hardware ASID entry if it exists.", "title": "./spec/abstract/ARM/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Remove virtual to physical mappings in either direction involving this\nvirtual ASID."}
{"spec": "global_pt \\<leftarrow> get_arm_global_pt;\n     pde \\<leftarrow> return $ PageTablePDE (addrFromPPtr global_pt) {ParityEnabled} 0;\n     store_pde idx pde;", "property": "Kernel Initialization: Map the global page table into the last slot of the global page directory. \n\nSubproperties: \n- Retrieve the global page table.\n- Create a page table PDE with the global page table address and parity enabled.\n- Store the PDE in the specified index.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " now map global PT into last slot in global PD  "}
{"spec": "(* Title:   Confinement_S\n * Description: confinement proof of the security model\n *)\n\ntheory Confine_S\nimports System_S\nbegin", "property": "Confinement Proof: Ensures that the system adheres to the security model by preventing unauthorized access and information flow, maintaining the integrity and confidentiality of the system.", "title": "./spec/take-grant/Confine_S.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "(*\n    The fault datatype.\n*)\n\nchapter \"Fault Structures\"\n\ntheory Fault_H\nimports ArchFault_H\nbegin\n\narch_requalify_types (H)\n  arch_fault\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Types.lhs\n#INCLUDE_HASKELL SEL4/API/Failures.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Failures.lhs bodies_only\n\nend", "property": "Fault Structures: Define the data structures and types for representing faults in the system, providing a foundation for fault handling and management.", "title": "./spec/design/skel/Fault_H.thy", "chapter": "Fault Structures", "section": "", "comment": ""}
{"spec": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Platform.X64.maxIRQ\"\n\nend (* context X64 *)\n\nend", "property": "Maximum IRQ Definition: The maximum interrupt request (IRQ) number is defined based on the platform-specific value for x64 architectures.", "title": "./spec/design/skel/X64/Hardware_H.thy", "chapter": "", "section": "", "comment": " Unlike on Arm architectures, maxIRQ comes from Platform definitions.\n   We provide this abbreviation to match arch-split expectations. "}
{"spec": "definition\nfind_pd_for_asid_assert :: \"asid \\<Rightarrow> (word32,'z::state_ext) s_monad\" where\n\"find_pd_for_asid_assert asid \\<equiv> do\n   pd \\<leftarrow> find_pd_for_asid asid <catch> K fail;\n   get_pde pd;\n   return pd\n od\"", "property": "Page Directory Location: Locate the page directory for a given ASID and verify its validity by successfully retrieving a page directory entry.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Locate the page directory and check that this process succeeds and\nreturns a pointer to a real page directory."}
{"spec": "theory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs Platform=Platform.X64 CONTEXT X64_H NOT getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory wordFromPDE wordFromPTE VMFaultType HypFaultType VMMapType VMPageSize pageBits pageBitsForSize paddrBase pptrBase pptrTop pptrBaseOffset kernelELFBaseOffset kernelELFPAddrBase kernelELFBase toPAddr addrFromPPtr ptrFromPAddr addrFromKPPtr setCurrentUserCR3 getCurrentUserCR3 invalidateTLB invalidateTLBEntry mfence wordFromPML4E wordFromPDPTE firstValidIODomain numIODomainIDBits hwASIDInvalidate getFaultAddress irqIntOffset maxPCIBus maxPCIDev maxPCIFunc ioapicIRQLines ioapicMapPinToVector irqStateIRQIOAPICNew irqStateIRQMSINew updateIRQState in8 out8 in16 out16 in32 out32 invalidatePageStructureCache writeCR3 invalidateASID invalidateTranslationSingleASID invalidateLocalPageStructureCacheASID ptTranslationBits nativeThreadUsingFPU switchFpuOwner\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64_H instanceproofs NOT VMFaultType VMPageSize VMPageEntry VMMapType HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64_H ONLY wordFromPDE wordFromPTE wordFromPML4E wordFromPDPTE", "property": "Hardware Abstraction and Memory Management: Provides a comprehensive set of functions for hardware-level operations, including memory management, interrupt handling, timer configuration, and I/O operations. These functions ensure that the system can interact with the underlying hardware efficiently and safely, supporting critical tasks such as memory initialization, page table manipulation, and interrupt management.", "title": "./spec/design/skel/X64/Hardware_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "definition reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"", "property": "Memory Region Reservation: Reserve a memory region with the specified pointer, byte length, and kernel designation, currently a no-op placeholder for potential future extension to explicitly tag kernel data regions in memory.", "title": "./spec/abstract/AARCH64/ArchRetype_A.thy", "chapter": "", "section": "", "comment": "\n  This is a placeholder function. We may wish to extend the specification\n  with explicitly tagging kernel data regions in memory.\n"}
{"spec": "definition\n  insert_cap_orphan :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"insert_cap_orphan new_cap dest_slot \\<equiv> do\n     old_cap \\<leftarrow> get_cap dest_slot;\n     assert (old_cap = NullCap);\n     set_cap dest_slot new_cap\n   od\"\n\n\n\nprimrec (nonexhaustive)\n  available_range :: \"cdl_cap \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"available_range (UntypedCap _ r available) = available\"\n\ndefinition\n  set_available_range :: \"cdl_cap \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_cap\"\nwhere\n  \"set_available_range cap nrange \\<equiv>\n    case cap of UntypedCap d r available \\<Rightarrow> UntypedCap d r nrange | _ \\<Rightarrow> cap\"\n\nlemmas set_avaiable_range_simps[simp] = set_available_range_def[split_simps cdl_cap.split]\n\ndefinition\n  set_untyped_cap_as_full :: \"cdl_cap \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_untyped_cap_as_full src_cap new_cap src_slot \\<equiv>\n  if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n     \\<and> cap_objects src_cap = cap_objects new_cap) then\n     (set_cap src_slot (set_available_range src_cap {}))\n     else return ()\"", "property": "Insert Orphan Capability: Insert a new capability into a specified slot, ensuring that the destination slot is empty (contains a NullCap) before the insertion. This guarantees that the new capability is added without a parent and does not overwrite an existing capability.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": " Insert a new cap into an object. The cap will have no parent. "}
{"spec": "type_synonym asid_len           = 17\ntype_synonym asid_rep_len       = machine_word_len\ntype_synonym asid               = \"asid_rep_len word\"", "property": "ASID Representation: ASIDs are represented as machine words with a fixed length, where only the first 17 bits are significant and the remaining bits are zero.", "title": "./spec/abstract/ARM_HYP/Machine_A.thy", "chapter": "", "section": "", "comment": " Making asid a machine_word means that we need invariants that the extra bits are zero. "}
{"spec": "definition\n  empty_slot :: \"cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"empty_slot slot cleanup_info \\<equiv> do\n      cap \\<leftarrow> get_cap slot;\n      if cap = NullCap then\n        return ()\n      else do\n        slot_p \\<leftarrow> gets (\\<lambda>s. cdt s slot);\n        cdt \\<leftarrow> gets cdt;\n        parent \\<leftarrow> return $ cdt slot;\n        set_cdt ((\\<lambda>p. if cdt p = Some slot\n                     then parent\n                     else cdt p) (slot := None));\n        do_extended_op (empty_slot_ext slot slot_p);\n        set_original slot False;\n        set_cap NullCap slot;\n\n        post_cap_deletion cleanup_info\n      od\n  od\"", "property": "Empty a Capability Slot: Ensures that a capability slot is emptied by setting it to `NullCap` and updating the CDT (Capability Descriptor Table) to remove any references to the slot. If the slot is not already empty, it performs additional cleanup operations, including updating parent references and executing extended operations for slot finalization.", "title": "./spec/abstract/IpcCancel_A.thy", "chapter": "", "section": "", "comment": "Empty a capability slot assuming that the capability in it has been\nfinalised already."}
{"spec": "definition set_vm_root :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PageTableCap pt (Some (asid, _))) \\<Rightarrow> doE\n           pt' \\<leftarrow> find_vspace_for_asid asid;\n           whenE (pt \\<noteq> pt') $ throwError InvalidRoot;\n           liftE $ do_machine_op $ setVSpaceRoot (addrFromPPtr pt) (ucast asid)\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_pt \\<leftarrow> gets global_pt;\n       do_machine_op $ setVSpaceRoot (addrFromKPPtr global_pt) 0\n    od)\n  od\"\n\n\ndefinition delete_asid_pool :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"delete_asid_pool base ptr \\<equiv> do\n     assert (asid_low_bits_of base = 0);\n     asid_table \\<leftarrow> gets (riscv_asid_table \\<circ> arch_state);\n     when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n       pool \\<leftarrow> get_asid_pool ptr;\n       asid_table' \\<leftarrow> return $ asid_table (asid_high_bits_of base:= None);\n       modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> riscv_asid_table := asid_table' \\<rparr>\\<rparr>);\n       tcb \\<leftarrow> gets cur_thread;\n       set_vm_root tcb\n     od\n   od\"\n\n\ndefinition delete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"delete_asid asid pt \\<equiv> do\n     asid_table \\<leftarrow> gets (riscv_asid_table \\<circ> arch_state);\n     case asid_table (asid_high_bits_of asid) of\n       None \\<Rightarrow> return ()\n     | Some pool_ptr \\<Rightarrow> do\n         pool \\<leftarrow> get_asid_pool pool_ptr;\n         when (pool (asid_low_bits_of asid) = Some pt) $ do\n           do_machine_op $ hwASIDFlush (ucast asid);\n           pool' \\<leftarrow> return $ pool (asid_low_bits_of asid := None);\n           set_asid_pool pool_ptr pool';\n           tcb \\<leftarrow> gets cur_thread;\n           set_vm_root tcb\n         od\n       od\n   od\"\n\ndefinition unmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"unmap_page_table asid vaddr pt \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     pt_slot \\<leftarrow> pt_lookup_from_level max_pt_level top_level_pt vaddr pt;\n     liftE $ store_pte pt_slot InvalidPTE;\n     liftE $ do_machine_op sfence\n   odE <catch> (K $ return ())\"", "property": "Address Space Management: Switch the address space to that of a specified thread or to the global address space if the thread's configuration is invalid. This ensures that the virtual memory root is correctly set, and any necessary ASID pool or page table mappings are updated or deleted, maintaining the integrity and consistency of the virtual memory system.", "title": "./spec/abstract/RISCV64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "\n  Switch into the address space of a given thread or the global address space if none is correctly\n  configured.\n"}
{"spec": "definition \"EPIT_PADDR \\<equiv> 0x53f94000 :: word32\"\ndefinition \"EPIT_PPTR  \\<equiv> 0xfff00000 :: word32\"\ndefinition \"AVIC_PADDR \\<equiv> 0x68000000 :: word32\"\ndefinition \"AVIC_PPTR  \\<equiv> 0xfff01000 :: word32\"\ndefinition \"L2CC_PADDR \\<equiv> 0x30000000 :: word32\"\ndefinition \"L2CC_PPTR  \\<equiv> 0xfff02000 :: word32\"\ndefinition \"UART_PADDR \\<equiv> 0x43f90000 :: word32\"\ndefinition \"UART_PPTR  \\<equiv> 0xfff03000 :: word32\"\n\ndefinition \"BASE_OFFSET = pptrBaseOffset\"", "property": "Platform Constants: Define physical and pseudo-physical addresses for various kernel devices, including EPIT, AVIC, L2CC, and UART, to facilitate memory-mapped I/O operations.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Platform constants (iMX31)", "comment": "Kernel devices for imx31"}
{"spec": "definition\nlookup_pt_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"lookup_pt_slot pd vptr \\<equiv> doE\n    pd_slot \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    (case pde of\n          PageTablePDE ptab _ _ \\<Rightarrow>   (doE\n            pt \\<leftarrow> returnOk (ptrFromPAddr ptab);\n            pt_index \\<leftarrow> returnOk ((vptr >> 12) && 0xff);\n            pt_slot \\<leftarrow> returnOk (pt + (pt_index << 2));\n            returnOk pt_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability 20)\nodE\"", "property": "Lookup Page Table Slot: Given a page-directory reference and a virtual address, the function computes a pointer to the corresponding page table entry (PTE) in kernel memory. The function fails if the virtual address is mapped on a section or super section, ensuring that only valid PTEs are accessed.", "title": "./spec/abstract/ARM/ArchVSpaceAcc_A.thy", "chapter": "Accessing the ARM VSpace", "section": "Basic Operations", "comment": "The following function takes a page-directory reference as well as\n  a virtual address and then computes a pointer to the PTE in kernel memory.\n  Note that the function fails if the virtual address is mapped on a section or\n  super section."}
{"spec": "text \\<open>\n\n  The Separation Kernel maintains separation between processes by limiting the capabilities that are\n  present in the system. We call these the \"restricted capabilities\" in the documentation that\n  follows.\n\n  The specification described here, the Separation Kernel Abstract Specification (abbreviated\n  \\texttt{sep-abstract} from here on in), is identical to the Abstract Specification\n  (aka. \\texttt{abstract}), except that the following system calls have been overridden to\n  provide reduced (fully static) functionality only.\n\n  \\begin{itemize}\n  \\item{handle_fault}\n  \\item{invoke_irq_handler}\n  \\item{decode_invocation}\n  \\item{perform_invocation}\n  \\item{handle_invocation}\n  \\item{handle_reply}\n  \\item{handle_event}\n  \\item{call_kernel}\n  \\end{itemize}\n\n  The resulting kernel API is simplified significantly compared to full seL4.\n  The changes to the original abstract specification are minimal, except that it contains\n  much fewer system calls.\n\n  We achieve this by modifying the cases distinctions that determine which API call is\n  to by executed. The new case distinctions\n  on capabilities only provide code for the restricted capabilities in our reduced setup,\n  otherwise they fail (i.e. throw an exception).\n\n  We then prove that \\texttt{sep-abstract} and \\texttt{abstract} have the same behaviour under the\n  restricted capabilities of the separation kernel via bi-simulation. This simply requires that we\n  prove refinement in both directions. This proof implies that the missing (failing) code branches\n  in the reduced specification can never be executed.\n\n  It is clear that the behaviour will be the same for the \"mostly identical\" overridden\n  definitions. In a few cases, which are documented below, the definitions have bigger differencess.\n  We provide ab informal explanation at the site of the overriden definition in each of these\n  cases. (The bi-simulation proof provides the formal demonstration.)\n\n\\<close>", "property": "Separation Kernel Abstract Specification: The specification restricts the system calls to a reduced, fully static set of functionalities, ensuring that only specific, restricted capabilities are allowed. This simplification maintains the same behavior as the full abstract specification under the restricted capabilities, as proven by bi-simulation.", "title": "./spec/sep-abstract/Syscall_SA.thy", "chapter": "Separation Kernel Abstract Specification", "section": "Generic system call structure\\label{s:spec_syscall}", "comment": ""}
{"spec": "definition bindE ::\n  \"('s, 'e + 'a) nondet_monad \\<Rightarrow> ('a \\<Rightarrow> ('s, 'e + 'b) nondet_monad) \\<Rightarrow> ('s, 'e + 'b) nondet_monad\"\n  (infixl \">>=E\" 60) where\n  \"f >>=E g \\<equiv> f >>= lift g\"", "property": "Bind with Exception: The bind operation in the exception monad skips the execution of the right-hand side if the left-hand side produces an exception, ensuring that exceptions are propagated correctly.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "\n  The definition of @{term bind} in the exception monad (new\n  name @{text bindE}): the same as normal @{term bind}, but\n  the right-hand side is skipped if the left-hand side\n  produced an exception."}
{"spec": "fun\n  transfer_caps_loop :: \"cdl_object_id option \\<Rightarrow> cdl_object_id \\<Rightarrow>\n                         (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_cap_ref option\n                         \\<Rightarrow> unit k_monad\"\nwhere\n  \"transfer_caps_loop ep receiver [] dest = return ()\"\n| \"transfer_caps_loop ep receiver ((cap,slot)#caps) dest =\n      \\<comment> \\<open>Transfer badge, transfer cap, or abort early if more than\n         one cap to transfer\\<close>\n      (if is_ep_cap cap \\<and> ep = Some (cap_object cap)\n      then do\n        \\<comment> \\<open>transfer badge\\<close>\n        corrupt_ipc_buffer receiver True;\n        \\<comment> \\<open>transfer rest of badges or cap\\<close>\n        transfer_caps_loop ep receiver caps dest\n      od\n      else if dest \\<noteq> None then doE\n        new_cap \\<leftarrow> returnOk (update_cap_rights (cap_rights cap - {Write}) cap) \\<sqinter>\n                  returnOk cap;\n\n        \\<comment> \\<open>Target cap is derived. This may abort transfer early.\\<close>\n        target_cap \\<leftarrow> derive_cap slot new_cap;\n        whenE (target_cap = NullCap) throw;\n\n        \\<comment> \\<open>Copy the cap across as either a child or sibling.\\<close>\n        liftE (insert_cap_child target_cap slot (the dest)\n               \\<sqinter> insert_cap_sibling target_cap slot (the dest));\n\n        \\<comment> \\<open>Transfer rest of badges\\<close>\n        liftE $ transfer_caps_loop ep receiver caps None\n      odE <catch> (\\<lambda>_. return ())\n      else\n        return ())\"", "property": "Transfer Caps: Transfer at most one capability and multiple endpoint badges from a sender to a receiver, ensuring that the capability rights are updated and the target capability is derived correctly. If the capability to be transferred is to the endpoint used in the transfer, transfer the badges instead.\n\n Subproperties:\n- Badge Transfer: If the capability to be transferred is to the endpoint used in the transfer, transfer the badges.\n- Capability Transfer: Transfer at most one capability, updating its rights and deriving the target capability.\n- Abort Early: Abort the transfer early if more than one capability is to be transferred or if the target capability is null.", "title": "./spec/capDL/Endpoint_D.thy", "chapter": "", "section": "", "comment": "\n * Transfers at most one cap in addition to a number of endpoint badges.\n *\n * Endpoint badges are transferred if the cap to be transferred is to\n * the endpoint used in the transfer.\n "}
{"spec": "|  CNodeRotateIntent word32 word32 word32 word32 cdl_raw_capdata word32 word32 cdl_raw_capdata\n\ndatatype cdl_tcb_intent =", "property": "CNode Rotation: Allows the rotation of capabilities within a CNode, specifying the target, destination index and depth, pivot root with its index and depth, and source root with its index and depth. This operation facilitates the reorganization of capabilities within the CNode structure, ensuring that the system can dynamically adjust to changing requirements while maintaining the integrity of the capability hierarchy.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " Rotate: (target), dest_index, dest_depth, (pivot_root), pivot_index, pivot_depth, pivot_badge, (src_root), src_index, src_depth, src_badge "}
{"spec": "definition vcpu_update :: \"obj_ref \\<Rightarrow> (vcpu \\<Rightarrow> vcpu) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_update vr f \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    set_vcpu vr (f vcpu)\n  od\"\n\ndefinition vgic_update ::\n  \"obj_ref \\<Rightarrow> (gic_vcpu_interface \\<Rightarrow> gic_vcpu_interface) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vgic_update vr f \\<equiv> vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_vgic := f (vcpu_vgic vcpu) \\<rparr> )\"\n\ndefinition vgic_update_lr :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vgic_update_lr vr irq_idx virq \\<equiv>\n    vgic_update vr (\\<lambda>vgic. vgic \\<lparr> vgic_lr := (vgic_lr vgic)(irq_idx := virq) \\<rparr>)\"\n\ndefinition vcpu_save_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_save_reg vr reg \\<equiv> do\n    rval \\<leftarrow> do_machine_op (readVCPUHardwareReg reg);\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := rval) \\<rparr> )\n  od\"\n\ndefinition vcpu_save_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_save_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_save_reg vr reg) [from .e. to]\"\n\ndefinition vcpu_restore_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_restore_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    do_machine_op (writeVCPUHardwareReg reg (vcpu_regs vcpu reg))\n  od\"\n\ndefinition vcpu_restore_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"vcpu_restore_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_restore_reg vr reg) [from .e. to]\"\n\ndefinition vcpu_read_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word, 'z::state_ext) s_monad\" where\n  \"vcpu_read_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    return (vcpu_regs vcpu reg)\n  od\"\n\ndefinition vcpu_write_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"vcpu_write_reg vr reg val \\<equiv>\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := val) \\<rparr> )\"\n\ndefinition save_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"save_virt_timer vcpu_ptr \\<equiv> do\n     vcpu_save_reg vcpu_ptr VCPURegCNTV_CTL;\n     do_machine_op $ writeVCPUHardwareReg VCPURegCNTV_CTL 0;\n     vcpu_save_reg vcpu_ptr VCPURegCNTV_CVAL;\n     vcpu_save_reg vcpu_ptr VCPURegCNTVOFF;\n     vcpu_save_reg vcpu_ptr VCPURegCNTKCTL_EL1;\n     do_machine_op check_export_arch_timer;\n     cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu_update vcpu_ptr (\\<lambda>vcpu. vcpu\\<lparr>vcpu_vtimer := VirtTimer cntpct \\<rparr>)\n   od\"\n\ndefinition irq_vppi_event_index :: \"irq \\<rightharpoonup> vppievent_irq\" where\n  \"irq_vppi_event_index irq \\<equiv>\n     if irq = irqVTimerEvent\n     then Some VPPIEventIRQ_VTimer\n     else None\"\n\ndefinition restore_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"restore_virt_timer vcpu_ptr \\<equiv> do\n     vcpu_restore_reg vcpu_ptr VCPURegCNTV_CVAL;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTKCTL_EL1;\n     current_cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu \\<leftarrow> get_vcpu vcpu_ptr;\n     last_pcount \\<leftarrow> return $ vtimerLastPCount $ vcpu_vtimer vcpu;\n     delta \\<leftarrow> return $ current_cntpct - last_pcount;\n     cntvoff \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTVOFF;\n     offset \\<leftarrow> return $ cntvoff + ucast delta;\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFF offset;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTVOFF;\n     \\<comment> \\<open>read again, so we don't have to reason about @{const vcpu_write_reg} changes in CRefine\\<close>\n     vcpu \\<leftarrow> get_vcpu vcpu_ptr;\n     masked \\<leftarrow> return $ (vcpu_vppi_masked vcpu (the $ irq_vppi_event_index irqVTimerEvent));\n     \\<comment> \\<open>we do not know here that irqVTimerEvent is IRQReserved, therefore not IRQInactive,\n        so the only way to prove we don't unmask an inactive interrupt is to check\\<close>\n     safe_to_unmask \\<leftarrow> is_irq_active irqVTimerEvent;\n     when safe_to_unmask $ do_machine_op $ maskInterrupt masked irqVTimerEvent;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTV_CTL\n   od\"", "property": "VCPU State and Register Manipulation: Provides functions to update, save, and restore VCPU-related state and registers. This includes updating the VCPU and VGIC state, saving and restoring individual or ranges of VCPU registers, and managing the virtual timer by saving and restoring its control and counter values. These operations ensure that the VCPU's state is accurately maintained and can be effectively managed during context switches and other critical operations.", "title": "./spec/abstract/AARCH64/VCPUAcc_A.thy", "chapter": "AARCH64 VCPU Accessor Functions", "section": "Manipulation of VCPU-related state and registers", "comment": ""}
{"spec": "definition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"", "property": "IRQ Masks Initialization: All IRQs are masked after kernel initialization.", "title": "./spec/design/m-skel/RISCV64/MachineTypes.thy", "chapter": "RISCV 64bit Machine Types", "section": "Machine State", "comment": "\n  After kernel initialisation all IRQs are masked.\n"}
{"spec": "definition\n  has_children :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> bool\"\nwhere\n  \"has_children parent s = (\\<exists>child. is_cdt_parent s parent child)\"", "property": "Cap Has Children: Determines whether a given capability has any children by checking if there exists a child capability in the capability derivation table (CDT) that is associated with the parent.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": " Does the given cap have any children? "}
{"spec": "definition\n  get_blocking_object :: \"thread_state \\<Rightarrow> (obj_ref,'z::state_ext) s_monad\"\nwhere\n \"get_blocking_object state \\<equiv>\n       case state of BlockedOnReceive epptr x \\<Rightarrow> return epptr\n                    | BlockedOnSend epptr x \\<Rightarrow> return epptr\n                    | _ \\<Rightarrow> fail\"", "property": "Get Blocking Object: Retrieve the endpoint pointer for a thread that is blocked on either sending or receiving a message. If the thread is not in a blocked state, the operation fails.", "title": "./spec/abstract/IpcCancel_A.thy", "chapter": "", "section": "", "comment": "The endpoint pointer stored by a thread waiting for a message to be\ntransferred in either direction."}
{"spec": "type_synonym cdl_asid = \"cdl_cnode_index \\<times> cdl_cnode_index\"", "property": "Virtual ASID Representation: A virtual ASID is represented as a pair of CDL cnode indices, allowing for the identification and management of address spaces within the system.", "title": "./spec/capDL/Types_D.thy", "chapter": "", "section": "", "comment": " A virtual ASID. "}
{"spec": "datatype cdl_object =\n    Endpoint\n  | Notification\n  | Tcb cdl_tcb\n  | CNode cdl_cnode\n  | AsidPool cdl_asid_pool\n  | PageTable cdl_page_table\n  | PageDirectory cdl_page_directory\n  | Frame cdl_frame\n  | Untyped\n  | IRQNode cdl_irq_node", "property": "Kernel Object Types: Defines the various types of kernel objects that can be created or deleted by users during system execution, including endpoints, notifications, threads, capability nodes, address space identifier pools, page tables, page directories, frames, untyped objects, and interrupt request nodes.", "title": "./spec/capDL/Types_D.thy", "chapter": "", "section": "", "comment": "\n * Kernel objects.\n *\n * These are in-memory objects that may, over the course of the system\n * execution, be created or deleted by users.\n "}
{"spec": "frame_size \\<leftarrow>\n         returnOk $ if (is_aligned start (pageBitsForSize ARMSection)\n                        \\<and> is_aligned end (pageBitsForSize ARMSection))\n                    then ARMSection\n                    else ARMSmallPage;\n\n       slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n       (swp mapME) [start,(start + 2^(pageBitsForSize frame_size))\n                       .e. (end - 1)]\n         (\\<lambda>f. doE\n                frame_cap \\<leftarrow> create_it_frame_cap f 0 None\n                                                (frame_size = ARMSection);\n                provide_cap root_cnode_cap frame_cap\n              odE);\n\n       slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n       bi_dev_reg \\<leftarrow> returnOk (addrFromPPtr start,\n                              of_nat (pageBitsForSize frame_size),\n                              (slot_pos_before, slot_pos_after));\n\n       liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n         bi_f_dev_reg_list := (bi_f_dev_reg_list $\n                                 ki_bootinfo s) @ [bi_dev_reg]\n         \\<rparr>\\<rparr>);\n\n       bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n       sync_bootinfo_frame bi_frame\n\n     odE);\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_num_dev_regs := of_nat $ length (bi_f_dev_reg_list $\n                                               ki_bootinfo s)\n       \\<rparr>\\<rparr>);\n\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame\n   odE\"\n\nfun (* for (ptr,bits)-style regions which don't straddle the end of memory *)\n  no_region_overlap :: \"(paddr \\<times> nat) \\<Rightarrow> (paddr \\<times> nat) \\<Rightarrow> bool\" where\n  \"no_region_overlap (ptr1,bits1) (ptr2,bits2) =\n     ({ptr1 .. ptr1 + 2 ^ bits1 - 1} \\<inter> {ptr2 .. ptr2 + 2 ^ bits2 - 1} = {})\"\n\ndefinition\n  freemem_regions :: \"obj_ref set \\<Rightarrow> ((paddr \\<times> nat) list,'z::state_ext) s_monad\" where\n  \"freemem_regions free \\<equiv> do\n     regs \\<leftarrow> select {lst. (\\<forall>(ptr,bits) \\<in> set lst. is_aligned ptr bits \\<and>\n                                           {ptr .. ptr + 2 ^ bits - 1} \\<subseteq> free)\n                         \\<and> distinct_prop no_region_overlap lst};\n     return regs\n   od\"\n\ndefinition\n  create_untyped_obj :: \"cap \\<Rightarrow> (paddr \\<times> paddr) \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_untyped_obj root_cnode_cap boot_mem_reuse_reg \\<equiv> doE\n\n     slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;", "property": "Kernel Initialization: Allocate memory frames, preferentially using 1M frames if the start and end addresses are aligned, otherwise using 4K frames. The function creates frame capabilities, updates the boot information with device region details, and ensures that the regions do not overlap, maintaining the integrity of the memory layout.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " use 1M frames if possible, else 4K frames "}
{"spec": "lemma heapAdd_read_cap [simp]:\n  \"target (read_cap e) = e\"\n  by (simp add: read_cap_def)\n\nlemma rights_read_cap [simp]:\n  \"rights (read_cap e) = {Read}\"\n  by (simp add: read_cap_def)\n\nlemma heapAdd_write_cap [simp]:\n  \"target (write_cap e) = e\"\n  by (simp add: write_cap_def)\n\nlemma rights_write_cap [simp]:\n  \"rights (write_cap e) = {Write}\"\n  by (simp add: write_cap_def)\n\nlemma heapAdd_take_cap [simp]:\n  \"target (take_cap e) = e\"\n  by (simp add: take_cap_def)\n\nlemma rights_take_cap [simp]:\n  \"rights (take_cap e) = {Take}\"\n  by (simp add: take_cap_def)\n\nlemma heapAdd_grant_cap [simp]:\n  \"target (grant_cap e) = e\"\n  by (simp add: grant_cap_def)\n\nlemma rights_grant_cap [simp]:\n  \"rights (grant_cap e) = {Grant}\"\n  by (simp add: grant_cap_def)\n\nlemma heapAdd_create_cap [simp]:\n  \"target (create_cap e) = e\"\n  by (simp add: create_cap_def)\n\nlemma rights_create_cap [simp]:\n  \"rights (create_cap e) = {Create}\"\n  by (simp add: create_cap_def)\n\nlemma heapAdd_store_cap [simp]:\n  \"target (store_cap e) = e\"\n  by (simp add: store_cap_def)\n\nlemma rights_store_cap [simp]:\n  \"rights (store_cap e) = {Store}\"\n  by (simp add: store_cap_def)\n\nlemma heapAdd_full_cap [simp]:\n  \"target (full_cap e) = e\"\n  by (simp add: full_cap_def)\n\nlemma rights_full_cap [simp]:\n  \"rights (full_cap e) = all_rights\"\n  by (simp add: full_cap_def)\n\nlemma entity_diminish [simp]:\n  \"target (diminish R c) = target c\"\n  by (simp add: diminish_def)\n\nlemma rights_diminish [simp]:\n  \"rights (diminish R c) = rights c \\<inter> R\"\n  by (simp add: diminish_def)", "property": "Capability Properties: Define the properties of various capability operations, including read, write, take, grant, create, store, and full capabilities, ensuring that each operation has the correct target and rights. Additionally, diminishing a capability preserves its target while restricting its rights to the specified set.", "title": "./spec/take-grant/System_S.thy", "chapter": "", "section": "", "comment": " Lemma on caps "}
{"spec": "definition\n  vcpu_disable :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_disable vo \\<equiv> do\n    do_machine_op dsb;\n    (case vo of\n      Some vr \\<Rightarrow> do\n        hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n        vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n        vcpu_save_reg vr VCPURegSCTLR;\n        do_machine_op isb\n      od\n    | _ \\<Rightarrow> return ());\n    do_machine_op $ do\n        set_gic_vcpu_ctrl_hcr 0; \\<comment> \\<open>turn VGIC off\\<close>\n        isb;\n        setSCTLR sctlrDefault; \\<comment> \\<open>turn SI MMU off\\<close>\n        setHCR hcrNative;\n        isb\n      od;\n    case vo of\n      Some vr \\<Rightarrow> do\n          save_virt_timer vr;\n          do_machine_op $ maskInterrupt True irqVTimerEvent\n        od\n      | _ \\<Rightarrow> return ()\n    od\"", "property": "VPCU Mode Disable: Turn off VPCU mode on the hardware level by updating the VGIC control register, saving the VCPU register, disabling the VGIC and SI MMU, and resetting the HCR. Additionally, save the virtual timer and mask the VTimer event interrupt if a VCPU object reference is provided.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Turn VPCU mode off on the hardware level."}
{"spec": "text \\<open>The high bits of a virtual ASID.\\<close>\ndefinition asid_high_bits_of :: \"asid \\<Rightarrow> asid_high_index\"\n  where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"", "property": "Virtual ASID High Bits Extraction: Extract the high bits of a virtual ASID by shifting the ASID to the right by the number of low bits and then casting the result to an ASID high index.", "title": "./spec/abstract/RISCV64/ArchVSpaceAcc_A.thy", "chapter": "Accessing the RISCV64 VSpace", "section": "Kernel Heap Accessors", "comment": ""}
{"spec": "theory ArchTCB_H\nimports TCBDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/ARM.lhs RegisterSet= CONTEXT ARM_H\n\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend", "property": "Architectural Thread Management: Provides functions for getting and setting thread-specific architectural state, ensuring that the thread's state is correctly managed and updated according to the architecture-specific requirements.", "title": "./spec/design/skel/ARM/ArchTCB_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "text \\<open>\n  We use @{text K_bind} to syntactically indicate the case where the return argument\n  of the left side of a @{term bind} is ignored\\<close>\ndefinition K_bind :: \"'a \\<Rightarrow> 'b \\<Rightarrow> 'a\" where\n  K_bind_def[iff]: \"K_bind \\<equiv> \\<lambda>x y. x\"\n\nnonterminal\n  dobinds and dobind and nobind\n\nsyntax\n  \"_dobind\"    :: \"[pttrn, 'a] => dobind\"             (\"(_ <-/ _)\" 10)\n  \"\"           :: \"dobind => dobinds\"                 (\"_\")\n  \"_nobind\"    :: \"'a => dobind\"                      (\"_\")\n  \"_dobinds\"   :: \"[dobind, dobinds] => dobinds\"      (\"(_);//(_)\")\n\n  \"_do\"        :: \"[dobinds, 'a] => 'a\"               (\"(do ((_);//(_))//od)\" 100)\nsyntax (xsymbols)\n  \"_dobind\"    :: \"[pttrn, 'a] => dobind\"             (\"(_ \\<leftarrow>/ _)\" 10)\n\ntranslations\n  \"_do (_dobinds b bs) e\"  == \"_do b (_do bs e)\"\n  \"_do (_nobind b) e\"      == \"b >>= (CONST K_bind e)\"\n  \"do x <- a; e od\"        == \"a >>= (\\<lambda>x. e)\"", "property": "Nondeterministic State Monad with Failure: Provides syntax for the exception monad, including binding and sequencing operations. The `K_bind` function is used to ignore the return value of the left side of a bind operation, allowing for more flexible and concise do-notation in the monad.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Syntax", "comment": ""}
{"spec": "context Arch begin\ncontext begin global_naming global\nrequalify_types (aliasing)\n  Invocations_H.invocation\nend\nend\n\nend", "property": "Name Disambiguation: Disambiguate name clashes between architecture-specific and non-architecture-specific constants with the same names.", "title": "./spec/design/skel/Invocations_H.thy", "chapter": "", "section": "", "comment": " disambiguate name clash between Arch and non-arch consts with same names "}
{"spec": "definition sequenceE_x :: \"('s, 'e+'a) nondet_monad list \\<Rightarrow> ('s, 'e+unit) nondet_monad\" where\n  \"sequenceE_x xs \\<equiv> foldr (\\<lambda>x y. doE _ <- x; y odE) xs (returnOk ())\"\n\ndefinition mapME_x :: \"('a \\<Rightarrow> ('s,'e+'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s,'e+unit) nondet_monad\" where\n  \"mapME_x f xs \\<equiv> sequenceE_x (map f xs)\"\n\ndefinition sequenceE :: \"('s, 'e+'a) nondet_monad list \\<Rightarrow> ('s, 'e+'a list) nondet_monad\" where\n  \"sequenceE xs \\<equiv> let mcons = (\\<lambda>p q. p >>=E (\\<lambda>x. q >>=E (\\<lambda>y. returnOk (x#y))))\n                   in foldr mcons xs (returnOk [])\"\n\ndefinition mapME ::\n  \"('a \\<Rightarrow> ('s,'e+'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s,'e+'b list) nondet_monad\"\n  where\n  \"mapME f xs \\<equiv> sequenceE (map f xs)\"", "property": "Nondeterministic Monad Sequencing: Provides functions to sequence and map monadic operations, handling both unit and list return values. The `sequenceE_x` and `mapME_x` functions execute a list of monadic actions, discarding their results, while `sequenceE` and `mapME` collect the results into a list.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Library of additional Monadic Functions and Combinators", "comment": "\n  The sequence and map functions above for the exception monad, with and without\n  lists of return value"}
{"spec": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP decls_only NOT UserContext UserMonad Word getRegister setRegister newContext\n\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP ONLY VPPIEventIRQ VirtTimer", "property": "Machine State Management: Defines and manages the machine state for ARM_HYP, including handling virtual timer and VPP event IRQs, as well as providing operations to get and set registers in the context of the ARM_HYP architecture.", "title": "./spec/design/m-skel/ARM_HYP/MachineTypes.thy", "chapter": "ARM\\_HYP Machine Types", "section": "Machine State", "comment": ""}
{"spec": "theory MachineMonad\nimports MachineTypes\nbegin\n\narch_requalify_types\n  machine_state\n  machine_state_rest\n\narch_requalify_consts\n  underlying_memory\n  underlying_memory_update\n  device_state\n  device_state_update\n  irq_masks\n  machine_state_rest\n  machine_state_rest_update", "property": "Machine State Management: Provides mechanisms to access and update the underlying memory, device state, and interrupt masks, ensuring that the machine state is correctly maintained and modified.", "title": "./spec/machine/MachineMonad.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "lemma cacheLineBits_sanity:\n  \"cacheLineBits \\<in> {2..12}\"\n  by (simp add: cacheLineBits_def Kernel_Config.CONFIG_L1_CACHE_LINE_SIZE_BITS_def)\n\nend\nend", "property": "Cache Line Bits Sanity: The value of `cacheLineBits` must be within the range of 2 to 12, ensuring it is suitable for use in cache operations and does not conflict with other values.", "title": "./spec/machine/ARM_HYP/Arch_Kernel_Config_Lemmas.thy", "chapter": "", "section": "", "comment": " Folding cacheLineBits_val in C functions only works reliably if cacheLineBits is not 1 and\n   not too large to conflict with other values used inside cache ops.\n   12 is ptBits, which is only available after ExecSpec. Anything > 1 and smaller than ptBits\n   works. "}
{"spec": "definition vs_apiobj_size where\n  \"vs_apiobj_size ty \\<equiv>\n     case ty of\n       ArchObject SmallPageObj \\<Rightarrow> pageBitsForSize ARMSmallPage\n     | ArchObject LargePageObj \\<Rightarrow> pageBitsForSize ARMLargePage\n     | ArchObject SectionObj \\<Rightarrow> pageBitsForSize ARMSection\n     | ArchObject SuperSectionObj \\<Rightarrow> pageBitsForSize ARMSuperSection\n     | ArchObject PageTableObj \\<Rightarrow> pt_bits\n     | ArchObject PageDirectoryObj \\<Rightarrow> pd_bits\"\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv> do\n     when (new_type = ArchObject PageDirectoryObj) $ mapM_x copy_global_mappings refs;\n     if \\<not>is_device \\<and>\n        new_type \\<in> {ArchObject SmallPageObj, ArchObject LargePageObj,\n                    ArchObject SectionObj, ArchObject SuperSectionObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_RAM ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else if new_type \\<in> {ArchObject PageTableObj, ArchObject PageDirectoryObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_PoU ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else\n       return ()\n   od\"\n\ndefinition\n  empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context, tcb_vcpu = None \\<rparr>\"\n\nend\n\nend", "property": "Initialise Architecture-Specific Objects: \nInitialise architecture-specific objects, including page tables, page directories, and various types of page objects, ensuring correct configuration and cache management for these objects.\nSubproperties:\nCache Management: Clean the cache range for page objects and page tables/directories to ensure data consistency and prevent cache-related issues.\nPage Table/Directory Configuration: Copy global mappings for page directories and configure page tables/directories according to architecture-specific requirements.\nTCB Initialisation: Initialise the architecture-specific components of a TCB (Thread Control Block), including the user context and vcpu (virtual CPU) settings.", "title": "./spec/abstract/ARM_HYP/ArchRetype_A.thy", "chapter": "", "section": "", "comment": "Initialise architecture-specific objects."}
{"spec": "idle_thread \\<leftarrow> gets idle_thread;\n     modify (\\<lambda>s. s\\<lparr> cur_thread := idle_thread \\<rparr>);\n\n     switch_to_thread tcb_pptr;\n\n     cap \\<leftarrow> return $ ThreadCap tcb_pptr;\n     write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_TCB) cap\n   od)\n   odE\"\n\ndefinition\n  create_device_frames :: \"cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_device_frames root_cnode_cap \\<equiv> doE\n     dev_regs \\<leftarrow> do_kernel_op $ do_machine_op getDeviceRegions;\n\n     (swp mapME) dev_regs (\\<lambda>(start,end). doE", "property": "Kernel Initialization: Initializes the kernel by setting the current thread to the idle thread, switching to a new thread, and writing the thread capability to the specified slot in the root cnode. This ensures that the kernel is in a known state and ready for further operations.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " scheduler action not in abstract spec "}
{"spec": "definition\nload_hw_asid :: \"asid \\<Rightarrow> (hardware_asid option,'z::state_ext) s_monad\" where\n\"load_hw_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    return $ option_map fst $ asid_map asid\nod\"", "property": "Load Hardware ASID: Retrieve the optional hardware ASID associated with a given virtual ASID from the ASID map.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Load the optional hardware ASID currently associated with this virtual\nASID."}
{"spec": "lemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def", "property": "Data Conversions: Define conversions between different data types, including object references, virtual references, lengths, and capability pointers, to facilitate automatic unfolding in proofs.", "title": "./spec/abstract/AARCH64/Machine_A.thy", "chapter": "", "section": "", "comment": "These definitions will be unfolded automatically in proofs."}
{"spec": "definition\n  cancel_signal :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_signal threadptr ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     queue \\<leftarrow> (case ntfn_obj ntfn of WaitingNtfn queue \\<Rightarrow> return queue\n                        | _ \\<Rightarrow> fail);\n     queue' \\<leftarrow> return $ remove1 threadptr queue;\n     newNTFN \\<leftarrow> return $ ntfn_set_obj ntfn (case queue' of [] \\<Rightarrow> IdleNtfn\n                                                      | _  \\<Rightarrow> WaitingNtfn queue');\n     set_notification ntfnptr newNTFN;\n     set_thread_state threadptr Inactive\n   od\"", "property": "Cancel Signal: Cancel a thread's message receive operation from a notification object, removing the thread from the notification queue and updating the notification object's state accordingly, ultimately setting the thread's state to inactive.", "title": "./spec/abstract/IpcCancel_A.thy", "chapter": "", "section": "", "comment": "Cancel the message receive operation of a thread queued in an\nnotification object."}
{"spec": "definition\n  tcb_update_ipc_buffer :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_ipc_buffer target_tcb tcb_cap_ref ipc_buffer \\<equiv>\n     doE\n       tcb_empty_thread_slot target_tcb tcb_ipcbuffer_slot;\n       liftE $ corrupt_tcb_intent target_tcb;\n       src_cap \\<leftarrow> liftE $ get_cap (snd ipc_buffer);\n       whenE (cdl_same_arch_obj_as (fst ipc_buffer) src_cap)\n         $ tcb_update_thread_slot target_tcb tcb_cap_ref tcb_ipcbuffer_slot ipc_buffer\n     odE\n\"", "property": "Update IPC Buffer: Updates a thread's IPC buffer by first emptying the existing slot, corrupting the TCB intent, and then updating the thread slot with the new IPC buffer if the source capability is from the same architectural object.", "title": "./spec/capDL/Tcb_D.thy", "chapter": "", "section": "", "comment": " Update a thread's IPC buffer. "}
{"spec": "definition [simp]:\n  \"global_pd \\<equiv> (\\<lambda> i :: 9 word. LargePagePDE (0x03FE00 + ucast i << 21) {} {})\"\n\ndefinition\n  \"init_kheap \\<equiv>\n    (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n           then Some (CNode 0 (empty_cnode 0))\n           else None)\n    (idle_thread_ptr \\<mapsto>\n       TCB \\<lparr>\n         tcb_ctable = NullCap,\n         tcb_vtable = NullCap,\n         tcb_reply = NullCap,\n         tcb_caller = NullCap,\n         tcb_ipcframe = NullCap,\n         tcb_state = IdleThreadState,\n         tcb_fault_handler = replicate word_bits False,\n         tcb_ipc_buffer = 0,\n         tcb_fault = None,\n         tcb_bound_notification = None,\n         tcb_mcpriority = minBound,\n         tcb_arch = init_arch_tcb\n         \\<rparr>,\n     init_global_pml4 \\<mapsto> ArchObj (PageMapL4 global_pml4),\n     init_global_pdpt \\<mapsto> ArchObj (PDPointerTable global_pdpt),\n     init_global_pd \\<mapsto> ArchObj (PageDirectory global_pd)\n    )\"\n\ndefinition\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. Structures_A.IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\nend", "property": "Initialization of Kernel State: The kernel initializes its state with a global page directory, an idle thread, and other essential components. The initial state includes setting up the kheap, capability derivation tree, interrupt controller, and architecture-specific state, ensuring that the system is ready for operation.", "title": "./spec/abstract/X64/Init_A.thy", "chapter": "", "section": "", "comment": " C kernel initialisation refines this down to small pages for devices, but we'll stop here. "}
{"spec": "definition\nperform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_pool_invocation iv \\<equiv> case iv of Assign asid pool_ptr ct_slot \\<Rightarrow>\ndo\n    pml4_cap \\<leftarrow> get_cap ct_slot;\n    case pml4_cap of\n      ArchObjectCap (PML4Cap pml4_base _) \\<Rightarrow> do\n        set_cap (ArchObjectCap $ PML4Cap pml4_base (Some asid)) ct_slot;\n        store_asid_pool_entry pool_ptr asid (Some pml4_base)\n      od\n    | _ \\<Rightarrow> fail\nod\"\n\n\ndefinition\n  pte_check_if_mapped :: \"obj_ref \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pte_check_if_mapped slot \\<equiv> do\n     pt \\<leftarrow> get_pte slot;\n     return (pt \\<noteq> InvalidPTE)\n  od\"\n\ndefinition\n  pde_check_if_mapped :: \"obj_ref \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pde_check_if_mapped slot \\<equiv> do\n     pd \\<leftarrow> get_pde slot;\n     return (pd \\<noteq> InvalidPDE)\n  od\"\n\ndefinition\n  perform_page_invocation_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_page_invocation_unmap cap ct_slot \\<equiv>\n      (case cap\n         of PageCap dev base rights map_type sz mapped \\<Rightarrow> do\n            case mapped of Some (asid, vaddr) \\<Rightarrow> unmap_page sz asid vaddr base\n                          | None \\<Rightarrow> return ();\n            cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n            set_cap (ArchObjectCap $ update_map_data cap None (Some VMNoMap)) ct_slot\n          od\n      | _ \\<Rightarrow> fail)\"", "property": "ASID Pool Management: Assign a virtual ASID to a page directory, updating the PML4 capability and storing the ASID pool entry.\nPage Mapping Management: Check if a page table entry (PTE) or page directory entry (PDE) is mapped, and unmap a page if it is mapped, updating the corresponding capability.", "title": "./spec/abstract/X64/Arch_A.thy", "chapter": "", "section": "", "comment": "The ASIDPool capability confers the authority to assign a virtual ASID\nto a page directory."}
{"spec": "end", "property": "No property is defined.", "title": "./spec/design/skel/X64/ArchLabelFuns_H.thy", "chapter": "", "section": "", "comment": " None for x64 "}
{"spec": "record arch_tcb =\n  tcb_context :: user_context\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition default_arch_tcb :: arch_tcb\n  where\n  \"default_arch_tcb \\<equiv> \\<lparr>tcb_context = new_context\\<rparr>\"", "property": "Arch-Specific TCB Structure: The RISCV64-specific part of a TCB contains a field for the user context. \n\nDefault Arch-Specific TCB: The default arch-specific TCB has a user context initialized with a new context.", "title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "chapter": "RISCV64-Specific Data Types", "section": "Arch-specific TCB", "comment": " Arch-specific part of a TCB: this must have at least a field for user context. "}
{"spec": "record kernel_state =\n  ksPSpace             :: pspace\n  gsUserPages          :: \"machine_word \\<Rightarrow> vmpage_size option\"\n  gsCNodes             :: \"machine_word \\<Rightarrow> nat option\"\n  gsUntypedZeroRanges  :: \"(machine_word \\<times> machine_word) set\"\n  gsMaxObjectSize      :: nat\n  ksDomScheduleIdx     :: nat\n  ksDomSchedule        :: \"(domain \\<times> machine_word) list\"\n  ksCurDomain          :: domain\n  ksDomainTime         :: machine_word\n  ksReadyQueues        :: \"domain \\<times> priority \\<Rightarrow> ready_queue\"\n  ksReadyQueuesL1Bitmap :: \"domain \\<Rightarrow> machine_word\"\n  ksReadyQueuesL2Bitmap :: \"domain \\<times> nat \\<Rightarrow> machine_word\"\n  ksCurThread          :: machine_word\n  ksIdleThread         :: machine_word\n  ksSchedulerAction    :: scheduler_action\n  ksInterruptState     :: interrupt_state\n  ksWorkUnitsCompleted :: machine_word\n  ksArchState          :: Arch.kernel_state\n  ksMachineState       :: machine_state\n\ncontext Arch begin\ncontext begin global_naming global\nrequalify_types KernelStateData_H.kernel_state\nend\nend\n\ntype_synonym 'a kernel = \"(kernel_state, 'a) nondet_monad\"\n\ntranslations\n  (type) \"'c kernel\" <= (type) \"(kernel_state, 'c) nondet_monad\"", "property": "Kernel State Structure: The kernel state is a record that contains various components, including the process space, user pages, CNodes, untyped zero ranges, maximum object size, domain schedule, current domain, domain time, ready queues, current thread, idle thread, scheduler action, interrupt state, work units completed, architecture-specific state, and machine state. This structure encapsulates the essential data for managing the kernel's operation and interactions with the machine.\n\nKernel Monad: The kernel monad is a type synonym for a nondeterministic monad that operates on the kernel state, providing a way to express kernel functions that interact with and modify the kernel state.", "title": "./spec/design/skel/KernelStateData_H.thy", "chapter": "Kernel State and Monads", "section": "", "comment": "We pull a fast one on haskell here ... although Haskell expects\na KernelMonad which is a StateT monad in KernelData that wraps a MachineMonad,\nwe push the extra MachineMonad data into the KernelState. Fortunately the\nupdate and accessor functions all still work."}
{"spec": "definition vcpu_finalise :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_finalise vr \\<equiv> do\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of\n      Some t \\<Rightarrow> dissociate_vcpu_tcb vr t\n    | None \\<Rightarrow> return ()\n   od\"", "property": "VCPU Removal Preparation: Dissociate a given VCPU and clean up its current state if necessary, ensuring it is properly prepared for removal. \n\nDissociation: If the VCPU is associated with a TCB, dissociate the VCPU from the TCB.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "\n  Prepare a given VCPU for removal: dissociate it, and clean up current VCPU state\n  if necessary.\n"}
{"spec": "arch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=ARM_HYP CONTEXT ARM_HYP_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend", "property": "Architectural Constants and Type Definitions: Defines architectural constants, type conversions, and a null pointer for machine words, ensuring consistency and proper handling of memory addresses and pointers in the system.", "title": "./spec/design/skel/ARM_HYP/State_H.thy", "chapter": "", "section": "", "comment": " Note: while this requalify and arch-generic Haskell import of WordLib.lhs could be moved to\n   a generic theory, no good candidate theory exists at the moment. "}
{"spec": "definition\nflush_table :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_table pml4_ref vptr pt_ref asid \\<equiv> do\n    assert (vptr && mask (ptTranslationBits + pageBits) = 0);\n           pt \\<leftarrow> get_pt pt_ref;\n           forM_x [0 .e. (-1::9 word)] (\\<lambda>index. do\n             pte \\<leftarrow> return $ pt index;\n             case pte of\n               InvalidPTE \\<Rightarrow> return ()\n             | _ \\<Rightarrow> do_machine_op $ invalidateTranslationSingleASID (vptr + (ucast index << pageBits)) (ucast asid)\n           od)\nod\"", "property": "Flush Page Table Mappings: Invalidate mappings associated with a specified page table, ensuring that all entries are flushed for a given ASID. This process iterates over each entry in the page table, and if the entry is valid, it invalidates the corresponding translation for the specified virtual address and ASID.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Flush mappings associated with a page table."}
{"spec": "Signal cdl_badge cdl_object_id\n\ndatatype cdl_reply_invocation =\n    ReplyMessage cdl_object_id cdl_cap_ref bool (* can grant *)\n\ndatatype cdl_page_table_invocation =", "property": "Signal Notification: Send a signal to a notification object with a specific badge. \n\nNo subproperties are necessary for this simple property.", "title": "./spec/capDL/Invocations_D.thy", "chapter": "", "section": "", "comment": " badge (notification word) and notification object "}
{"spec": "definition arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\" where\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n     (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n       delete_asid_pool b ptr;\n       return (NullCap, NullCap)\n     od\n   | (PageTableCap ptr VSRootPT_T (Some (a, v)), True) \\<Rightarrow> do\n       delete_asid a ptr;\n       return (NullCap, NullCap)\n     od\n   | (PageTableCap ptr NormalPT_T (Some (a, v)), True) \\<Rightarrow> do\n       unmap_page_table a v ptr;\n       return (NullCap, NullCap)\n     od\n   | (FrameCap ptr _ sz _ (Some (a, v)), _) \\<Rightarrow> do\n       unmap_page sz a v ptr;\n       return (NullCap, NullCap)\n     od\n   | (VCPUCap vcpu_ref, True) \\<Rightarrow> do\n      vcpu_finalise vcpu_ref;\n      return (NullCap, NullCap)\n     od\n   | _ \\<Rightarrow> return (NullCap, NullCap)\"", "property": "Architectural Capability Finalisation: Ensure that AARCH64-specific capabilities are properly cleaned up upon finalisation, including deleting ASID pools, unmapping page tables and frames, and finalising VCPUs, to maintain the integrity of the system's architectural state.", "title": "./spec/abstract/AARCH64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Actions that must be taken on finalisation of AARCH64-specific capabilities."}
{"spec": "definition\n  diminish :: \"right set \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"diminish R cap \\<equiv> cap \\<lparr> rights := rights cap \\<inter> R \\<rparr>\"\n\ndefinition\n  createOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"createOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (full_cap (target c\\<^sub>2))\n                                (direct_caps_of s (target c\\<^sub>1))),\n     target c\\<^sub>2 \\<mapsto> null_entity)\"\n\nlemma createOperation_def2:\n  \"createOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  let new_cap = \\<lparr> target = target c\\<^sub>2, rights = all_rights \\<rparr>;\n      newTarget = ({new_cap} \\<union> direct_caps_of s (target c\\<^sub>1) )\n  in\n  s (target c\\<^sub>1 \\<mapsto> Entity newTarget, target c\\<^sub>2 \\<mapsto> null_entity)\"\n  by (simp add: createOperation_def Let_def full_cap_def null_entity_def)\n\ndefinition\n  takeOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"takeOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (e \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s e)))\"\n\nlemma takeOperation_def2:\n  \"takeOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (e \\<mapsto> Entity ({diminish R c\\<^sub>2} \\<union> direct_caps_of s e))\"\n  by (clarsimp simp: takeOperation_def caps_of_def)\n\ndefinition\n  grantOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"grantOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s (target c\\<^sub>1)) )) \"\n\nlemma grantOperation_def2:\n  \"grantOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity ( {diminish R c\\<^sub>2} \\<union> direct_caps_of s (target c\\<^sub>1)))\"\n  by (clarsimp simp: grantOperation_def caps_of_def)\n\ndefinition\n  copyOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"copyOperation sRef c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s (target c\\<^sub>1)))) \"\n\ndefinition\n  removeOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"removeOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  if is_entity s (target c\\<^sub>1)\n  then\n     s ((target c\\<^sub>1) \\<mapsto> Entity ((direct_caps_of s (target c\\<^sub>1)) - {c\\<^sub>2} ))\n  else\n     s\"\n\nlemma removeOperation_simpler:\n  \"removeOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  (case s (target c\\<^sub>1) of\n    None \\<Rightarrow> s\n  | Some (Entity caps) \\<Rightarrow> s (target c\\<^sub>1 \\<mapsto> Entity (caps - {c\\<^sub>2})))\"\n  by (rule eq_reflection, simp add: removeOperation_def is_entity_def direct_caps_of_def\n                             split: if_split_asm option.splits)\n\ndefinition\n  removeSetOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap set \\<Rightarrow> modify_state\" where\n  \"removeSetOperation e c C s \\<equiv>\n  if is_entity s (target c) then\n   s ((target c) \\<mapsto> Entity ((direct_caps_of s (target c)) - C ))\n  else\n   s\"\n\nlemma removeSetOperation_simpler:\n  \"removeSetOperation e c caps s \\<equiv>\n  (case s (target c) of\n    None \\<Rightarrow> s\n  | Some (Entity caps') \\<Rightarrow> s (target c \\<mapsto> Entity (caps' - caps)))\"\n  by (auto simp: removeSetOperation_def is_entity_def direct_caps_of_def\n         intro!: eq_reflection\n          split: if_split_asm option.splits)\n\nlemma removeSetOperation_fold_removeOperation:\n  \"removeSetOperation e c (set caps) s = fold (removeOperation e c) caps s\"\n  apply (subst foldr_fold [symmetric])\n   apply (fastforce simp: removeOperation_def direct_caps_of_def is_entity_def)\n  apply (rule sym)\n  apply (induct caps)\n   apply (fastforce simp: removeSetOperation_def removeOperation_def direct_caps_of_def is_entity_def)\n  apply (fastforce simp: removeSetOperation_def removeOperation_def direct_caps_of_def is_entity_def)\n  done\n\ndefinition\n  removeSetOfCaps :: \"(entity_id \\<Rightarrow> cap set) \\<Rightarrow> modify_state\"\nwhere\n  \"removeSetOfCaps cap_map s \\<equiv> \\<lambda>e.\n     if is_entity s e\n     then Some (Entity ((direct_caps_of s e) - cap_map e ))\n     else None\"\n\ndefinition\n  caps_to_entity :: \"entity_id \\<Rightarrow> entity_id \\<Rightarrow> state \\<Rightarrow> cap set\"\nwhere\n  \"caps_to_entity e e' s \\<equiv> {cap. cap \\<in> direct_caps_of s e' \\<and> target cap = e}\"\n\ndefinition\n  revokeOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> modify_state_n\" where\n  \"revokeOperation e c s \\<equiv>\n    {s'. \\<exists>cap_map. \\<forall>e'. cap_map e' \\<subseteq> caps_to_entity (target c) e' s \\<and>\n         s' = removeSetOfCaps cap_map s}\"\n\ndefinition\n  destroyOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"destroyOperation e c s \\<equiv> s(target c := None)\"", "property": "System Operations: Define how various system operations (create, take, grant, copy, remove, remove set, revoke, and destroy) modify the system state by manipulating capabilities and entity relationships.\n\nSubproperties:\n- Create Operation: Creates a new capability and adds it to an entity's direct capabilities.\n- Take Operation: Adds a diminished capability to an entity's direct capabilities.\n- Grant Operation: Adds a diminished capability to the direct capabilities of the target entity of another capability.\n- Copy Operation: Copies a diminished capability to the direct capabilities of the target entity of another capability.\n- Remove Operation: Removes a capability from an entity's direct capabilities.\n- Remove Set Operation: Removes a set of capabilities from an entity's direct capabilities.\n- Revoke Operation: Removes a set of capabilities related to a specific entity from the system state.\n- Destroy Operation: Removes an entity from the system state.", "title": "./spec/take-grant/System_S.thy", "chapter": "", "section": "", "comment": " Following functions define how each of the sysOPs modifies the\n * system state_s\n "}
{"spec": "end\n\narch_requalify_types register vcpureg vppievent_irq virt_timer\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP instanceproofs ONLY VPPIEventIRQ VirtTimer", "property": "Machine State Requalification: Requalify ARM_HYP machine types to ensure correct state management, including register, virtual CPU, VPP event IRQ, and virtual timer requalification.", "title": "./spec/design/m-skel/ARM_HYP/MachineTypes.thy", "chapter": "ARM\\_HYP Machine Types", "section": "Machine State", "comment": "<"}
{"spec": "definition freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"freeMemory ptr bits \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\"", "property": "Clearing Memory: Zero out the memory content of a given range to prevent garbage, ensuring that the memory is in a known state after being freed.", "title": "./spec/machine/AARCH64/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": "\n  Free memory that had been initialized as user memory. While freeing memory is a no-op in the\n  implementation, we zero out the underlying memory in the specifications to avoid garbage. If we\n  know that there is no garbage, we can compute from the implementation state what the exact memory\n  content in the specifications is."}
{"spec": "definition vs_apiobj_size where\n  \"vs_apiobj_size ty \\<equiv>\n     case ty of\n       ArchObject SmallPageObj \\<Rightarrow> pageBitsForSize ARMSmallPage\n     | ArchObject LargePageObj \\<Rightarrow> pageBitsForSize ARMLargePage\n     | ArchObject HugePageObj \\<Rightarrow> pageBitsForSize ARMHugePage\n     | ArchObject PageTableObj \\<Rightarrow> table_size NormalPT_T\n     | ArchObject VSpaceObj \\<Rightarrow> table_size VSRootPT_T\"\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv>\n     if \\<not>is_device \\<and>\n        new_type \\<in> {ArchObject SmallPageObj, ArchObject LargePageObj, ArchObject HugePageObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_RAM ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else if new_type \\<in> {ArchObject PageTableObj, ArchObject VSpaceObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_PoU ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else\n       return ()\"\n\ndefinition empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (FPUState (\\<lambda>_. 0) 0 0) (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context, tcb_vcpu = None \\<rparr>\"\n\nend\nend", "property": "Initialise Architecture-Specific Objects: Initialise architecture-specific objects, including page tables, virtual space objects, and page objects, by cleaning the cache range and setting up the object's size and references. \n\nSubproperties:\n- Cache Cleaning: Clean the cache range for the newly created objects to ensure data consistency.\n- Object Size and References: Set up the object's size and references according to the object type and architecture-specific requirements.\n- Architecture-Specific TCB Initialisation: Initialise the architecture-specific parts of the TCB, including the user context and virtual CPU state.", "title": "./spec/abstract/AARCH64/ArchRetype_A.thy", "chapter": "", "section": "", "comment": "Initialise architecture-specific objects."}
{"spec": "arch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=ARM CONTEXT ARM_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend", "property": "Memory and Pointer Management: Define the basic operations and types for managing memory and pointers in the system, including the definition of word bits, pointer types (PPtr), and the null pointer constant. Ensure that the system can correctly represent and manipulate memory addresses and pointers. \n\nPointer Conversion: Provide functions to convert between different pointer types, specifically the identity functions PPtr and fromPPtr, which enable the system to map between machine words and physical pointers.", "title": "./spec/design/skel/ARM/State_H.thy", "chapter": "", "section": "", "comment": " Note: while this requalify and arch-generic Haskell import of WordLib.lhs could be moved to\n   a generic theory, no good candidate theory exists at the moment. "}
{"spec": "definition\n  insert_cap_orphan :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"insert_cap_orphan new_cap dest_slot \\<equiv> do\n     old_cap \\<leftarrow> get_cap dest_slot;\n     assert (old_cap = NullCap);\n     set_cap dest_slot new_cap\n   od\"\n\n\n\nprimrec (nonexhaustive)\n  available_range :: \"cdl_cap \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"available_range (UntypedCap _ r available) = available\"\n\ndefinition\n  set_available_range :: \"cdl_cap \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_cap\"\nwhere\n  \"set_available_range cap nrange \\<equiv>\n    case cap of UntypedCap d r available \\<Rightarrow> UntypedCap d r nrange | _ \\<Rightarrow> cap\"\n\nlemmas set_avaiable_range_simps[simp] = set_available_range_def[split_simps cdl_cap.split]\n\ndefinition\n  set_untyped_cap_as_full :: \"cdl_cap \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_untyped_cap_as_full src_cap new_cap src_slot \\<equiv>\n  if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n     \\<and> cap_objects src_cap = cap_objects new_cap) then\n     (set_cap src_slot (set_available_range src_cap {}))\n     else return ()\"", "property": "Insert Cap Orphan: Insert a new capability into an object without a parent, ensuring the destination slot is empty.\n\nSet Untyped Cap As Full: Update an untyped capability's available range to empty in its original slot, if the new capability has the same objects and is also untyped.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": " Insert a new cap into an object. The cap will have no parent. "}
{"spec": "definition\n  cap_irq_opt :: \"cap \\<Rightarrow> irq option\" where\n \"cap_irq_opt cap \\<equiv> case cap of IRQHandlerCap irq \\<Rightarrow> Some irq | _ \\<Rightarrow> None\"\n\ndefinition\n  cap_irqs :: \"cap \\<Rightarrow> irq set\" where\n \"cap_irqs cap \\<equiv> set_option (cap_irq_opt cap)\"", "property": "IRQ Retrieval: Extract the optional IRQ or set of IRQs associated with a capability. \n\nSubproperties:\n- Optional IRQ: Retrieve the optional IRQ stored in a capability, returning None if the capability is not an IRQHandlerCap.\n- IRQ Set: Convert the optional IRQ to a set, providing a collection of IRQs associated with the capability.", "title": "./spec/abstract/IpcCancel_A.thy", "chapter": "", "section": "", "comment": "The optional IRQ stored in a capability, presented either as an optional\nvalue or a set."}
{"spec": "text \\<open>Set the capability derivation tree.\\<close>\ndefinition\n  set_cdt :: \"cdt \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_cdt t \\<equiv> do\n    s \\<leftarrow> get;\n    put $ s\\<lparr> cdt := t \\<rparr>\n  od\"", "property": "Set Capability Derivation Tree: Update the capability derivation tree (CDT) with a new value, ensuring that the system's capability hierarchy is correctly maintained and updated.", "title": "./spec/abstract/CSpaceAcc_A.thy", "chapter": "Accessing CSpace", "section": "Accessing the capability derivation tree", "comment": ""}
{"spec": "definition\nload_hw_asid :: \"asid \\<Rightarrow> (hardware_asid option,'z::state_ext) s_monad\" where\n\"load_hw_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    return $ option_map fst $ asid_map asid\nod\"", "property": "Load Hardware ASID: Retrieve the optional hardware ASID associated with a given virtual ASID from the ASID map.", "title": "./spec/abstract/ARM/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Load the optional hardware ASID currently associated with this virtual\nASID."}
{"spec": "definition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend", "property": "Canonical Address Assertion: Ensures that a given machine word is considered canonical, which may be defined or delayed differently across various architectures.", "title": "./spec/design/skel/X64/ArchRetypeDecls_H.thy", "chapter": "", "section": "", "comment": " Defined differently and/or delayed on different architectures "}
{"spec": "(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Main Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_H ONLY ArmVSpaceRegionUse\n\nend\nend", "property": "Common, Architecture-Specific Data Types: Define and share architecture-specific data types between the specification and abstract models, ensuring consistency and reusability across different parts of the system.", "title": "./spec/design/skel/ARM/Arch_Structs_B.thy", "chapter": "Common, Architecture-Specific Data Types", "section": "", "comment": ""}
{"spec": "arch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend", "property": "Arch Invocation Label Requalification: Requalify the invocation labels for the ARM architecture to ensure correct enumeration and instance proofs.", "title": "./spec/design/skel/ARM/ArchInvocationLabels_H.thy", "chapter": "", "section": "", "comment": " not possible to move this requalification to generic, since enum instance proofs must\n   be done outside of Arch locale "}
{"spec": "definition\n  label_to_flush_type :: \"invocation_label \\<Rightarrow> flush_type\"\nwhere\n  \"label_to_flush_type label \\<equiv> case label of\n       ArchInvocationLabel ARMPDClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPageClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPDInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPageInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPDCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPageCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPDUnify_Instruction \\<Rightarrow> Unify\n     | ArchInvocationLabel ARMPageUnify_Instruction \\<Rightarrow> Unify\"", "property": "Architecture-specific System Call Decoding: Maps user-supplied invocation labels to specific flush types, determining the method to invoke for various architecture-specific system calls. \n\nFlush Type Mapping: Maps invocation labels to flush types, including Clean, Invalidate, CleanInvalidate, and Unify, to facilitate the execution of architecture-specific system calls.", "title": "./spec/abstract/ARM/ArchDecode_A.thy", "chapter": "Decoding Architecture-specific System Calls", "section": "Architecture calls", "comment": "This definition converts a user-supplied argument into an\ninvocation label, used to determine the method to invoke.\n"}
{"spec": "definition\n  is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"is_cap_revocable new_cap src_cap \\<equiv> case new_cap of\n      ArchObjectCap acap \\<Rightarrow> arch_is_cap_revocable new_cap src_cap\n    | EndpointCap _ _ _ \\<Rightarrow> cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n    | NotificationCap _ _ _ \\<Rightarrow> cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n    | IRQHandlerCap _ \\<Rightarrow> src_cap = IRQControlCap\n    | UntypedCap _ _ _ _ \\<Rightarrow> True\n    | _ \\<Rightarrow> False\"", "property": "Capability Revocability: Determine if a new capability should be considered as the original capability to an object, allowing for exceptions such as newly badged endpoint capabilities, IRQ handlers, untyped caps, and specific architecture capabilities. \n\nSubproperties:\n- Endpoint and Notification Capabilities: Considered revocable if the new capability has a different badge than the source capability.\n- IRQ Handler Capabilities: Considered revocable if the source capability is an IRQ Control Capability.\n- Untyped Capabilities: Always considered revocable.\n- Architecture Capabilities: Determined by architecture-specific rules.", "title": "./spec/abstract/CSpace_A.thy", "chapter": "CSpace", "section": "Inserting and moving capabilities", "comment": "This helper function determines if the new capability\nshould be counted as the original capability to the object. This test\nis usually false, apart from the exceptions listed (newly badged\nendpoint capabilities, irq handlers, untyped caps, and possibly some\narch caps)."}
{"spec": "datatype sysOPs =\n    SysCreate entity_id cap cap\n  | SysTake   entity_id cap cap mask\n  | SysGrant  entity_id cap cap mask\n  | SysCopy   entity_id cap cap mask\n  | SysRemove entity_id cap cap\n  | SysRemoveSet entity_id cap \"cap set\"\n  | SysRevoke entity_id cap\n  | SysDestroy entity_id cap", "property": "System Operations: Define a set of primitive kernel operations for managing entities and their capabilities, including creating, taking, granting, copying, removing, revoking, and destroying capabilities, as well as handling sets of capabilities. These operations ensure the proper management and control of system resources and permissions.", "title": "./spec/take-grant/System_S.thy", "chapter": "", "section": "", "comment": " System operations: primitive kernel operations "}
{"spec": "definition\n  cancel_badged_sends :: \"obj_ref \\<Rightarrow> badge \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_badged_sends epptr badge \\<equiv> do\n    ep \\<leftarrow> get_endpoint epptr;\n    case ep of\n          IdleEP \\<Rightarrow> return ()\n        | RecvEP _ \\<Rightarrow>  return ()\n        | SendEP queue \\<Rightarrow>  do\n            set_endpoint epptr IdleEP;\n            queue' \\<leftarrow> (swp filterM queue) (\\<lambda> t. do\n                st \\<leftarrow> get_thread_state t;\n                if blocking_ipc_badge st = badge then do\n                  set_thread_state t Restart;\n                  do_extended_op (tcb_sched_action (tcb_sched_enqueue) t);\n                  return False od\n                else return True\n            od);\n            ep' \\<leftarrow> return (case queue' of\n                           [] \\<Rightarrow> IdleEP\n                         | _ \\<Rightarrow> SendEP queue');\n            set_endpoint epptr ep';\n            do_extended_op (reschedule_required)\n        od\n  od\"", "property": "Cancel Badged Sends: Cancel all message send operations on threads queued in a specific endpoint that are using a particular badge, and reschedule the affected threads. \n\nSubproperties:\n- Set the endpoint to idle if all send operations are cancelled.\n- Update the thread state to restart and re-enqueue the thread if its blocking IPC badge matches the specified badge.\n- Reschedule the threads after cancelling the send operations.", "title": "./spec/abstract/IpcCancel_A.thy", "chapter": "", "section": "", "comment": "Cancel all message send operations on threads queued in this endpoint\nand using a particular badge."}
{"spec": "definition\n  init_arch_objects :: \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list\n   \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs\n    \\<equiv> when (new_type = ArchObject PML4Obj) (mapM_x copy_global_mappings refs)\"\n\ndefinition\n  empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0) (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context \\<rparr>\"\n\nend\nend", "property": "Initialize Architecture-Specific Objects: Initialize architecture-specific objects based on the object type. If the object type is a PML4 object, copy global mappings for the provided references. Additionally, define an empty user context and an initial architecture-specific thread control block with this empty context.", "title": "./spec/abstract/X64/ArchRetype_A.thy", "chapter": "", "section": "", "comment": "Initialise architecture-specific objects."}
{"spec": "chapter \"Initialisation\"\n\ntheory KI_Decls_H\nimports\n  ThreadDecls_H\n  KernelInitMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/Init.lhs decls_only NOT isAligned funArray newKernelState distinct rangesBy doKernelOp runInit\n\nend", "property": "Kernel Initialisation: Establish the initial state of the kernel, defining the necessary data structures and configurations for kernel operation.", "title": "./spec/design/skel/KI_Decls_H.thy", "chapter": "Initialisation", "section": "", "comment": ""}
{"spec": "abbreviation\n  \"work_units_completed (s::det_state) \\<equiv> work_units_completed_internal (exst s)\"\n\nabbreviation\n  \"work_units_completed_update f (s::det_state) \\<equiv>  trans_state (work_units_completed_internal_update f) s\"\n\nabbreviation\n  \"scheduler_action (s::det_state) \\<equiv> scheduler_action_internal (exst s)\"\n\nabbreviation\n  \"scheduler_action_update f (s::det_state) \\<equiv>  trans_state (scheduler_action_internal_update f) s\"\n\nabbreviation\n  \"ekheap (s::det_state) \\<equiv> ekheap_internal (exst s)\"\n\nabbreviation\n  \"ekheap_update f (s::det_state) \\<equiv> trans_state (ekheap_internal_update f) s\"\n\nabbreviation\n  \"domain_list (s::det_state) \\<equiv> domain_list_internal (exst s)\"\n\nabbreviation\n  \"domain_list_update f (s::det_state) \\<equiv> trans_state (domain_list_internal_update f) s\"\n\nabbreviation\n  \"domain_index (s::det_state) \\<equiv> domain_index_internal (exst s)\"\n\nabbreviation\n  \"domain_index_update f (s::det_state) \\<equiv> trans_state (domain_index_internal_update f) s\"\n\nabbreviation\n  \"cur_domain (s::det_state) \\<equiv> cur_domain_internal (exst s)\"\n\nabbreviation\n  \"cur_domain_update f (s::det_state) \\<equiv> trans_state (cur_domain_internal_update f) s\"\n\nabbreviation\n  \"domain_time (s::det_state) \\<equiv> domain_time_internal (exst s)\"\n\nabbreviation\n  \"domain_time_update f (s::det_state) \\<equiv> trans_state (domain_time_internal_update f) s\"\n\nabbreviation\n  \"ready_queues (s::det_state) \\<equiv> ready_queues_internal (exst s)\"\n\nabbreviation\n  \"ready_queues_update f (s::det_state) \\<equiv> trans_state (ready_queues_internal_update f) s\"\n\nabbreviation\n  \"cdt_list (s::det_state) \\<equiv> cdt_list_internal (exst s)\"\n\nabbreviation\n  \"cdt_list_update f (s::det_state) \\<equiv> trans_state (cdt_list_internal_update f) s\"\n\ntype_synonym 'a det_ext_monad = \"(det_state,'a) nondet_monad\"", "property": "Extended State Accessors and Updates: Provide functions to access and update various components of the extended state in the deterministic abstract specification, including work units completed, scheduler action, ekheap, domain list, domain index, current domain, domain time, ready queues, and CDT list. \n\nSubproperties:\n- Work Units Completed Access and Update\n- Scheduler Action Access and Update\n- Ekheap Access and Update\n- Domain List Access and Update\n- Domain Index Access and Update\n- Current Domain Access and Update\n- Domain Time Access and Update\n- Ready Queues Access and Update\n- CDT List Access and Update", "title": "./spec/abstract/Deterministic_A.thy", "chapter": "", "section": "Nondeterministic Abstract Specification", "comment": "Accessor and update functions for the extended state of the\n  deterministic abstract specification.\n"}
{"spec": "consts'\npageBase :: \"('a :: len word) \\<Rightarrow> vmpage_size \\<Rightarrow> 'a word\"\n\nend\nend", "property": "Page Base Calculation: Compute the base address of a page given a word and a virtual memory page size, ensuring that the calculation adheres to more constrained specifications.", "title": "./spec/design/skel/ARM_HYP/ArchVSpaceDecls_H.thy", "chapter": "", "section": "", "comment": " no \"wordlike\" class with a direct translation available, use more constrained spec "}
{"spec": "text \\<open>This section gives the types and auxiliary definitions for the\narchitecture-specific objects: a page directory entry (@{text \"pde\"})\ncontains either an invalid entry, a page table reference, a section\nreference, or a super-section reference; a page table entry contains\neither an invalid entry, a large page, or a small page mapping;\nfinally, an architecture-specific object is either an ASID pool, a\npage table, a page directory, or a data page used to model user\nmemory.\n\\<close>\n\ndatatype pde =\n   InvalidPDE\n | PageTablePDE obj_ref vm_attributes machine_word\n | SectionPDE obj_ref vm_attributes machine_word cap_rights\n | SuperSectionPDE obj_ref vm_attributes cap_rights\n\ndatatype pte =\n   InvalidPTE\n | LargePagePTE obj_ref vm_attributes cap_rights\n | SmallPagePTE obj_ref vm_attributes cap_rights\n\ndatatype arch_kernel_obj =\n   ASIDPool \"10 word \\<rightharpoonup> obj_ref\"\n | PageTable \"word8 \\<Rightarrow> pte\"\n | PageDirectory \"12 word \\<Rightarrow> pde\"\n | DataPage bool vmpage_size\n\nlemmas arch_kernel_obj_cases =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P,\n                         simplified, rule_format]\n\nlemmas arch_kernel_obj_cases_asm =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n                         simplified, rule_format, rotated -1]\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 4\"\n\nprimrec\n  arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\nwhere\n  \"arch_obj_size (ASIDPoolCap p as) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (PageCap dev x rs sz as4) = pageBitsForSize sz\"\n| \"arch_obj_size (PageDirectoryCap x as2) = 14\"\n| \"arch_obj_size (PageTableCap x as3) = 10\"\n\nprimrec\n  arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_cap_is_device (PageCap dev x rs sz as4) = dev\"\n| \"arch_cap_is_device ASIDControlCap = False\"\n| \"arch_cap_is_device (ASIDPoolCap p as) = False\"\n| \"arch_cap_is_device (PageTableCap x as3) = False\"\n| \"arch_cap_is_device (PageDirectoryCap x as2) = False\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 9\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 4\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 29\"\n\nprimrec\n  arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\nwhere\n  \"arch_kobj_size (ASIDPool p) = pageBits\"\n| \"arch_kobj_size (PageTable pte) = 10\"\n| \"arch_kobj_size (PageDirectory pde) = 14\"\n| \"arch_kobj_size (DataPage dev sz) = pageBitsForSize sz\"\n\nprimrec\n  aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\nwhere\n  \"aobj_ref (ASIDPoolCap p as) = Some p\"\n| \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref (PageCap dev x rs sz as4) = Some x\"\n| \"aobj_ref (PageDirectoryCap x as2) = Some x\"\n| \"aobj_ref (PageTableCap x as3) = Some x\"\n\nprimrec (nonexhaustive)\n  acap_rights :: \"arch_cap \\<Rightarrow> cap_rights\"\nwhere\n \"acap_rights (PageCap dev x rs sz as) = rs\"\n\ndefinition\n  acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n \"acap_rights_update rs ac \\<equiv> case ac of\n    PageCap dev x rs' sz as \\<Rightarrow> PageCap dev x (validate_vm_rights rs) sz as\n  | _                   \\<Rightarrow> ac\"", "property": "Architecture-Specific Objects: Define the structure and properties of architecture-specific objects, including page directory entries (PDEs) and page table entries (PTEs), which can contain various types of mappings and references. Additionally, it defines the size, device status, and object references for different types of architectural capabilities, ensuring that memory and capabilities are correctly managed and referenced in the system.", "title": "./spec/abstract/ARM/Arch_Structs_A.thy", "chapter": "ARM-Specific Data Types", "section": "Architecture-specific objects", "comment": ""}
{"spec": "text \\<open>The high bits of a virtual ASID.\\<close>\ndefinition\n  asid_high_bits_of :: \"asid \\<Rightarrow> 7 word\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"", "property": "ASID High Bits Extraction: Extract the high 7 bits of a given ASID by right-shifting the ASID and converting it to a 7-bit word.", "title": "./spec/abstract/ARM_HYP/ArchVSpaceAcc_A.thy", "chapter": "Accessing the ARM VSpace", "section": "Kernel Heap Accessors", "comment": ""}
{"spec": "definition\n  freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"freeMemory ptr bits \\<equiv>\n  mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\"", "property": "Memory Clearance: Zero out the underlying memory region specified by the pointer and size to ensure that no garbage data remains, allowing for a clean state in the specifications.", "title": "./spec/machine/X64/MachineOps.thy", "chapter": "Machine Operations", "section": "Memory Clearance", "comment": "\n  Free memory that had been initialized as user memory.\n  While freeing memory is a no-(in) the implementation,\n  we zero out the underlying memory in the specifications to avoid garbage.\n  If we know that there is no garbage,\n  we can compute from the implementation state\n  what the exact memory content in the specifications is.\n"}
{"spec": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP bodies_only NOT getRegister setRegister newContext", "property": "Machine State Management: Manage the state of the ARM_HYP machine, including register sets, to ensure correct execution and context switching. \n\nRegister Set Management: Provide functions to get and set registers, as well as create a new context for the ARM_HYP machine.", "title": "./spec/design/m-skel/ARM_HYP/MachineTypes.thy", "chapter": "ARM\\_HYP Machine Types", "section": "Machine State", "comment": ">"}
{"spec": "definition\n  reply_cancel_ipc :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"reply_cancel_ipc tptr \\<equiv> do\n    thread_set (\\<lambda>tcb. tcb \\<lparr> tcb_fault := None \\<rparr>) tptr;\n    cap \\<leftarrow> get_cap (tptr, tcb_cnode_index 2);\n    descs \\<leftarrow> gets (descendants_of (tptr, tcb_cnode_index 2) o cdt);\n    when (descs \\<noteq> {}) $ do\n      assert (\\<exists>cslot_ptr. descs = {cslot_ptr});\n      cslot_ptr \\<leftarrow> select descs;\n      cap_delete_one cslot_ptr\n    od\n  od\"", "property": "Cancel IPC Reply: Cancel the message receive operation of a thread waiting for a Reply capability it has issued to be invoked, by clearing the thread's fault handler, retrieving the Reply capability, and deleting any descendants of the Reply capability.", "title": "./spec/abstract/IpcCancel_A.thy", "chapter": "", "section": "", "comment": "Cancel the message receive operation of a thread waiting for a Reply\ncapability it has issued to be invoked."}
{"spec": "definition vcpu_switch :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_switch v \\<equiv> case v of\n   None \\<Rightarrow> do\n     cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (case cur_v of\n        None \\<Rightarrow> return () \\<comment> \\<open>both null, current cannot be active\\<close>\n      | Some (vr, active) \\<Rightarrow> do \\<comment> \\<open>switch to thread without vcpu\\<close>\n          when active $ do  \\<comment> \\<open> save state if not saved already\\<close>\n            vcpu_disable (Some vr);\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (vr, False) \\<rparr>\\<rparr>)\n          od;\n          return ()\n        od)\n     od\n | Some new \\<Rightarrow> do\n     cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (case cur_v of\n        None \\<Rightarrow> do \\<comment> \\<open>switch to the new vcpu with no current one\\<close>\n          vcpu_restore new;\n          modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n        od\n      | Some (vr, active) \\<Rightarrow> \\<comment> \\<open>switch from an existing vcpu\\<close>\n          (if vr \\<noteq> new\n          then do \\<comment> \\<open>different vcpu\\<close>\n            vcpu_save cur_v;\n            vcpu_restore new;\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n          od\n          else \\<comment> \\<open>same vcpu\\<close>\n            when (\\<not> active) $ do\n              do_machine_op isb;\n              vcpu_enable new;\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n            od))\n   od\"", "property": "VCPU Switching: Switch the active VCPU to a new one, or mark the current VCPU as inactive and disable VCPU mode if no new VCPU is provided. If the new VCPU is different from the current one, save the state of the current VCPU and restore the state of the new VCPU. If the same VCPU is being reactivated, enable it and update its active status.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "\n  Make a new VCPU the active/current VCPU. If passed None, will mark the current VCPU as\n  not active, and disable VCPU mode, but leave the rest intact caching for the case where\n  we switch back to the same VCPU soon.\n"}
{"spec": "definition\n  unmap_page_table  :: \"cdl_mapped_addr \\<Rightarrow> cdl_object_id  \\<Rightarrow> unit k_monad\"\nwhere\n  \"unmap_page_table maddr pt_id\\<equiv>\n    do\n      pt_slot \\<leftarrow> cdl_page_table_mapped maddr pt_id;\n      case pt_slot of (Some slot) \\<Rightarrow> delete_cap_simple slot\n      | None \\<Rightarrow> return ()\n    od\"\n\n\nend", "property": "Unmap Page Table: Unmaps a specified page table from a given memory address. If the page table is found, it is removed; otherwise, no action is taken.", "title": "./spec/capDL/PageTableUnmap_D.thy", "chapter": "", "section": "", "comment": "\n  Unmap a page table.\n\n  This hits the same problems as 'unmap_page', so we also\n  non-deterministically choose a bunch of page-tables to unmap.\n"}
{"spec": "arch_requalify_types (H)\n  vcpu\n\nend", "property": "Requalification of vCPU: The system requalifies the vCPU type, ensuring that it meets the necessary architectural requirements. This process is specific to certain architectures and cannot be generalized due to variations in vCPU implementations across different architectures.", "title": "./spec/design/skel/ARM_HYP/ArchStructures_H.thy", "chapter": "", "section": "", "comment": " not possible to move this requalification to generic, as some arches don't have vcpu "}
{"spec": "theory MachineMonad\nimports MachineTypes\nbegin\n\narch_requalify_types\n  machine_state\n  machine_state_rest\n\narch_requalify_consts\n  underlying_memory\n  underlying_memory_update\n  device_state\n  device_state_update\n  irq_masks\n  machine_state_rest\n  machine_state_rest_update", "property": "Machine State Management: Provides an interface to manage the underlying machine state, including memory, device state, and IRQ masks, allowing for controlled updates and access to these fundamental system resources.", "title": "./spec/machine/MachineMonad.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "text \\<open>An ASID is simply a word.\\<close>\ntype_synonym asid = \"word32\"\n\ndatatype vm_attribute = PageCacheable | XNever\ntype_synonym vm_attributes = \"vm_attribute set\"", "property": "Define ASID and VM Attributes: An ASID is represented as a 32-bit word, and VM attributes are defined as a set of possible values including PageCacheable and XNever.", "title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "chapter": "ARM-Specific Data Types", "section": "Architecture-specific capabilities", "comment": ""}
{"spec": "definition lift :: \"('a \\<Rightarrow> ('s, 'e + 'b) nondet_monad) \\<Rightarrow> 'e +'a \\<Rightarrow> ('s, 'e + 'b) nondet_monad\" where\n  \"lift f v \\<equiv> case v of Inl e \\<Rightarrow> throwError e | Inr v' \\<Rightarrow> f v'\"", "property": "Lifting with Exception Handling: Lifts a function to handle exceptions, where if the input is an exception, it returns that exception; otherwise, it continues with the function execution.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "\n  Lifting a function over the exception type: if the input is an\n  exception, return that exception; otherwise continue execution."}
{"spec": "type_synonym obj_ref            = machine_word\ntype_synonym vspace_ref         = machine_word\n\ntype_synonym data               = machine_word\ntype_synonym cap_ref            = \"bool list\"\ntype_synonym length_type        = machine_word\n\ntype_synonym asid_low_len      = 9\ntype_synonym asid_low_index    = \"asid_low_len word\"\n\ntype_synonym asid_high_len      = 3\ntype_synonym asid_high_index    = \"asid_high_len word\"", "property": "Type Instantiation for x64 Architecture: Defines concrete types for abstract type names, including object references, virtual space references, data, capability references, and length types, as well as specific lengths and indices for ASID (Address Space Identifier) components.", "title": "./spec/abstract/X64/Machine_A.thy", "chapter": "", "section": "", "comment": "\n  The specification is written with abstract type names for object\n  references, user pointers, word-based data, cap references, and so\n  on. This theory provides an instantiation of these names to concrete\n  types for the x64 architecture. Other architectures may have slightly\n  different instantiations.\n"}
{"spec": "arch_requalify_consts\n  maxIRQ\n\nend", "property": "Maximum IRQ Value: The maximum IRQ value is defined as a constant, which is architecture-dependent, ensuring that the kernel is configured to handle the correct range of interrupt requests for the specific architecture.", "title": "./spec/abstract/RISCV64/ArchInterrupt_A.thy", "chapter": "", "section": "", "comment": " On Arm architectures, maxIRQ is defined in Kernel_Config. On RISCV64 it is defined manually. "}
{"spec": "definition\nfind_pd_for_asid :: \"asid \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"find_pd_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pd \\<leftarrow> returnOk (pool (ucast asid));\n    (case pd of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"", "property": "Find Page Directory for ASID: Locate the page directory associated with a given virtual ASID, ensuring the ASID is valid and retrieving the corresponding page directory pointer from the ASID table and pool. \n\nASID Validation: The ASID must be greater than 0. \n\nPage Directory Retrieval: The page directory pointer is retrieved from the ASID pool, and if not found, an InvalidRoot error is thrown.", "title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Locate the page directory associated with a given virtual ASID."}
{"spec": "type_synonym vm_level = 4\n\ndefinition asid_pool_level :: vm_level\n  where\n  \"asid_pool_level = maxBound\"\n\ndefinition max_pt_level :: vm_level\n  where\n  \"max_pt_level = asid_pool_level - 1\"\n\nend\n\nqualify RISCV64_A (in Arch)", "property": "Virtual Memory Levels: The architecture defines four levels of virtual memory, with the highest level containing ASID pools and the lower levels containing page tables. The top level is designated for ASID pools, followed by three levels of page tables, where the bottom level (level 0) contains only InvalidPTEs or PagePTEs.", "title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "chapter": "RISCV64-Specific Data Types", "section": "Architecture-specific state", "comment": "\n  The number of levels over all virtual memory tables.\n  For RISC-V, we have three page table levels plus the ASID pool level.\n\n  The top level (with the highest number) contains ASID pools, the next levels contain the\n  top-level page tables, and level 1 page tables. The bottom-level page tables (level 0)\n  contains only InvalidPTEs or PagePTEs.\n"}
{"spec": "function cap_revoke :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n\"cap_revoke slot s = (doE\n    cap \\<leftarrow> without_preemption $ get_cap slot;\n    cdt \\<leftarrow> without_preemption $ gets cdt;\n    descendants \\<leftarrow> returnOk $ descendants_of slot cdt;\n    whenE (cap \\<noteq> NullCap \\<and> descendants \\<noteq> {}) (doE\n      child \\<leftarrow> without_preemption $ select_ext (next_revoke_cap slot) descendants;\n      cap \\<leftarrow> without_preemption $ get_cap child;\n      assertE (cap \\<noteq> NullCap);\n      cap_delete child;\n      preemption_point;\n      cap_revoke slot\n    odE)\nodE) s\"\nby auto", "property": "Revoke Capability: Revoke and delete all derived capabilities of a given capability, ensuring that all its descendants are removed from the capability derivation tree. \n\nRecursive Revocation: If the capability has non-null descendants, select the next capability to revoke, delete it, and then recursively revoke the original capability to ensure all descendants are removed.", "title": "./spec/abstract/CSpace_A.thy", "chapter": "CSpace", "section": "Revoking and deleting capabilities", "comment": "Revoke the derived capabilities of a given capability, deleting them\nall."}
{"spec": "definition\n  slot_bits :: nat where\n  \"slot_bits \\<equiv> 4\"\n\ndefinition\n  msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 20\"\n\ndefinition\n  new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext ((\\<lambda>r. 0) (CPSR := 0x150))\"", "property": "Architecture-Dependent Sizes: Define the sizes specific to the underlying machine architecture, including the slot size and message label size. \n\nInitial User Context: Provide an initial user context with default register values and a specific CPSR value.", "title": "./spec/abstract/ARM/Machine_A.thy", "chapter": "", "section": "", "comment": "The following definitions provide architecture-dependent sizes\n  such as the standard page size and capability size of the underlying\n  machine.\n"}
{"spec": "abbreviation (input) \"initMemory == clearMemory\"", "property": "Memory Initialization: Initialize memory for user use, ensuring it is properly cleared and prepared for allocation.", "title": "./spec/machine/RISCV64/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": "\n  Initialize memory to be used as user memory. Note that zeroing out the memory is redundant\n  in the specifications. In any case, we cannot abstract from the call to cleanCacheRange, which\n  appears in the implementation.\n"}
{"spec": "type_synonym cdl_right = rights", "property": "Entities have specific rights to kernel objects, which determine the permissible interactions and operations they can perform on those objects.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": "\n * Entities in seL4 have particular rights to kernel objects, which\n * affects how entities can interact with those particular objects.\n "}
{"spec": "consts'\n  vcpuHardwareReg_val :: \"vcpureg \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  readVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"readVCPUHardwareReg reg \\<equiv> gets (vcpuHardwareReg_val reg)\"\n\nconsts'\n  writeVCPUHardwareReg_impl :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"writeVCPUHardwareReg reg val \\<equiv> machine_op_lift (writeVCPUHardwareReg_impl reg val)\"", "property": "Hypervisor Banked Registers Access: Provides mechanisms to read and write hardware registers specific to a virtual CPU (vCPU) in the machine state. Reading a vCPU hardware register retrieves its current value, while writing updates the register with a new value.", "title": "./spec/machine/ARM_HYP/MachineOps.thy", "chapter": "Machine Operations", "section": "User Monad", "comment": ""}
{"spec": "fun\n  arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_same_region_as (PageCap dev r R s x) (PageCap dev' r' R' s' x') =\n   (let\n     topA = r + (1 << pageBitsForSize s) - 1;\n     topB = r' + (1 << pageBitsForSize s') - 1\n   in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB)\"\n| \"arch_same_region_as (PageTableCap r x) (PageTableCap r' x') = (r' = r)\"\n| \"arch_same_region_as (PageDirectoryCap r x) (PageDirectoryCap r' x') = (r' = r)\"\n| \"arch_same_region_as ASIDControlCap ASIDControlCap = True\"\n| \"arch_same_region_as (ASIDPoolCap r a) (ASIDPoolCap r' a') = (r' = r)\"\n| \"arch_same_region_as _ _ = False\"", "property": "Architectural Capability Region Check: Determine if two architectural capabilities refer to the same object or if one is contained within the region of the other, ensuring proper management of memory and resources. \n\nSubproperties:\n- Page Capabilities: Check if two page capabilities overlap in their memory regions.\n- Page Table and Directory Capabilities: Verify if two page table or directory capabilities refer to the same object.\n- ASID Control Capabilities: Always consider ASID control capabilities to be in the same region.\n- ASID Pool Capabilities: Check if two ASID pool capabilities refer to the same object.", "title": "./spec/abstract/ARM/ArchCSpace_A.thy", "chapter": "", "section": "", "comment": "Check whether the second capability is to the same object or an object\ncontained in the region of the first one."}
{"spec": "schematic_goal pt_lookup_from_level_simps:\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr = ?rhs\"\n  by (rule ext, rule pt_lookup_from_level.simps)\n\nend\nend", "property": "Page Table Lookup: Perform a page table lookup from a given level, using a page table pointer and a virtual pointer to retrieve the target page table pointer.", "title": "./spec/abstract/AARCH64/ArchVSpaceAcc_A.thy", "chapter": "Accessing the AARCH64 VSpace", "section": "Basic Operations", "comment": " Recover simp rule without state applied: "}
{"spec": "definition\n  empty_cap_map :: \"nat \\<Rightarrow> cdl_cap_map\"\nwhere\n  \"empty_cap_map sz \\<equiv> (\\<lambda>a. if a < 2^sz then (Some NullCap) else None)\"", "property": "Create an Empty Capability Map: Generate a capability map of a specified size, where all entries are initialized to NullCap.", "title": "./spec/capDL/Types_D.thy", "chapter": "", "section": "", "comment": " Create a capability map that contains no caps. "}
{"spec": "consts\ninsertNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> machine_word list \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> unit kernel\"\n\nconsts\ncreateObjects :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> Structures_H.kernel_object \\<Rightarrow> nat \\<Rightarrow> machine_word list kernel\"\n\nconsts\ncreateObjects' :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> kernel_object \\<Rightarrow> nat \\<Rightarrow> unit kernel\"\n\nconsts\ncreateNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> capability list kernel\"\n\nconsts\nArch_createNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_capability list kernel\"\n\ndefs insertNewCaps_def:\n\"insertNewCaps newType srcSlot destSlots regionBase magnitudeBits dev \\<equiv> (do\n    caps \\<leftarrow> createNewCaps newType regionBase (length destSlots) magnitudeBits dev;\n    zipWithM_x (insertNewCap srcSlot) destSlots caps\n  od)\"\n\ndefs createNewCaps_def:\n\"createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    (case toAPIType t of\n          Some TCBObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::tcb)) 0;\n            curdom \\<leftarrow> curDomain;\n            mapM_x (\\<lambda>tptr. threadSet (tcbDomain_update (\\<lambda>_. curdom)) tptr) addrs;\n            return $ map (\\<lambda> addr. ThreadCap addr) addrs\n          od)\n        | Some EndpointObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::endpoint)) 0;\n            return $ map (\\<lambda> addr. EndpointCap addr 0 True True True True) addrs\n          od)\n        | Some NotificationObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::notification)) 0;\n            return $ map (\\<lambda> addr. NotificationCap addr 0 True True) addrs\n          od)\n        | Some ArchTypes_H.CapTableObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::cte)) userSize;\n            modify (\\<lambda> ks. ks \\<lparr> gsCNodes := (\\<lambda> addr.\n              if addr `~elem~` map fromPPtr addrs then Just userSize\n              else gsCNodes ks addr)\\<rparr>);\n            return $ map (\\<lambda> addr. CNodeCap addr userSize 0 0) addrs\n          od)\n        | Some ArchTypes_H.Untyped \\<Rightarrow>\n            return $ map\n                (\\<lambda> n. UntypedCap dev (regionBase + n * 2 ^ (fromIntegral userSize)) userSize 0)\n                [0  .e.  (fromIntegral numObjects) - 1]\n        | None \\<Rightarrow>   (do\n            archCaps \\<leftarrow> Arch_createNewCaps t regionBase numObjects userSize dev;\n            return $ map ArchObjectCap archCaps\n          od)\n        )\"\n\ndefs createObjects_def:\n\"createObjects ptr numObjects val gSize \\<equiv> (do\n        oBits \\<leftarrow> return ( objBitsKO val);\n        gBits \\<leftarrow> return ( oBits + gSize);\n        createObjects' ptr numObjects val gSize;\n        return (map (\\<lambda> n. (ptr + n `~shiftL~` gBits))\n                [0  .e.  (of_nat numObjects) - 1])\n  od)\"\n\ndefs createObjects'_def:\n\"createObjects' ptr numObjects val gSize\\<equiv> (do\n        oBits \\<leftarrow> return ( objBitsKO val);\n        gBits \\<leftarrow> return ( oBits + gSize);\n        unless (fromPPtr ptr && mask gBits = 0) $\n            alignError gBits;\n        ps \\<leftarrow> gets ksPSpace;\n        end \\<leftarrow> return ( fromPPtr ptr + fromIntegral ((numObjects `~shiftL~` gBits) - 1));\n        (before, _) \\<leftarrow> return ( lookupAround2 end (psMap ps));\n        (case before of\n              None \\<Rightarrow>   return ()\n            | Some (x, _) \\<Rightarrow>   haskell_assert (x < fromPPtr ptr)\n                []\n            );\n        addresses \\<leftarrow> return ( map\n                (\\<lambda> n. fromPPtr ptr + n `~shiftL~` oBits)\n                [0  .e.  (fromIntegral numObjects `~shiftL~` gSize) - 1]);\n        map' \\<leftarrow> return ( foldR\n               (\\<lambda> addr map. data_map_insert addr val map)\n               (psMap ps) addresses);\n        ps' \\<leftarrow> return ( ps \\<lparr> psMap := map' \\<rparr>);\n        modify (\\<lambda> ks. ks \\<lparr> ksPSpace := ps'\\<rparr>)\nod)\"\n\n\nend", "property": "Object Creation and Capability Insertion: Create new objects of various types (TCB, endpoint, notification, cap table, untyped) and insert their corresponding capabilities into the system. The creation process involves allocating memory, initializing the objects, and updating the system's state.\n\n Subproperties:\n- Memory Allocation: Allocate memory for the new objects, ensuring proper alignment and space requirements.\n- Object Initialization: Initialize the new objects with their respective properties and attributes.\n- Capability Creation: Create capabilities for the new objects, which are then inserted into the system.\n- System State Update: Update the system's state to reflect the creation of new objects and capabilities.", "title": "./spec/design/skel/Intermediate_H.thy", "chapter": "", "section": "", "comment": "\n * Intermediate function bodies that were once in the Haskell spec, but are\n * now no longer.\n *\n * The idea is that these \"Old Haskell\" specs allow us to have refinement as\n * follows:\n *\n *  C <---> Haskell <---> Old Haskell <---> Abstract\n *\n * This provides a stepping stone for refactoring the Haskell without breaking\n * the upper proofs until a later time.\n "}
{"spec": "consts \n  sync_bootinfo_frame :: \"paddr \\<Rightarrow> (unit,'z::state_ext) ki_monad\"\n\ndefinition \n      returnOk pptr\n   odE\"\n\ndefinition\n  create_idle_thread :: \"(unit,'z::state_ext) ki_monad\" where\n  \"create_idle_thread \\<equiv> doE\n     pptr \\<leftarrow> create_objects (obj_bits $ TCB undefined)\n                           (obj_bits $ TCB undefined) TCBObject;\n     do_kernel_op $ do\n       modify (\\<lambda>s. s \\<lparr> idle_thread := pptr \\<rparr>);\n       configure_idle_thread pptr\n     od\n   odE\"\n\ndefinition\n  create_root_cnode :: \"(cap,'z::state_ext) ki_monad\" where\n  \"create_root_cnode \\<equiv>\n   let sz = (ROOT_CNODE_SIZE_BITS + CTE_SIZE_BITS) in\n   doE\n     liftE $ modify\n               (\\<lambda>s. s \\<lparr> ndks_boot_slot_pos_max := 2 ^ ROOT_CNODE_SIZE_BITS \\<rparr>);\n\n     pptr \\<leftarrow> create_objects sz sz CapTableObject;\n\n     let cap = CNodeCap pptr ROOT_CNODE_SIZE_BITS\n                             (replicate (32 - ROOT_CNODE_SIZE_BITS) False)\n     in (doE\n           do_kernel_op $ write_slot (cap_slot_pptr cap BI_CAP_IT_CNODE) cap;\n           returnOk cap\n         odE)\n   odE\"\n\ndefinition\n  create_irq_cnode :: \"(unit,'z::state_ext) ki_monad\" where\n  \"create_irq_cnode \\<equiv> doE", "property": "Kernel Initialization: Set up the kernel's initial state by creating essential objects, including the idle thread, root capability node, and interrupt request (IRQ) capability node, ensuring the kernel's fundamental structures are properly initialized for secure and efficient operation.\n\nSubproperties:\n- Idle Thread Creation: Create the idle thread, configuring its properties and setting it as the kernel's idle thread.\n- Root Capability Node Creation: Create the root capability node, initializing its properties and writing its capability to the appropriate slot.\n- IRQ Capability Node Creation: Create the IRQ capability node, ensuring proper interrupt handling and management.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": ""}
{"spec": "lemma e1_connected_trans_to_e2:\n  \"s \\<turnstile> 1 \\<leftrightarrow>* 2\"\n  apply (insert e1_connected_to_e2)\n  apply (simp add: tgs_connected_def)\n  done\n\n\nlemma caps_of_to_e1:\n  \"\\<lbrakk>c \\<in> caps_of s x; target c = 1\\<rbrakk> \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (case_tac \"x = 0\")\n   apply (fastforce simp: caps_of_s_e0_caps_2)\n  apply (case_tac \"x = 1\")\n   apply (fastforce simp: caps_of_s_e1)\n  apply (fastforce simp: caps_of_s_e3)\n  done\n\nlemma caps_of_to_e2:\n  \"\\<lbrakk>c \\<in> caps_of s x; target c = 2\\<rbrakk> \\<Longrightarrow> x = 1\"\n  apply (case_tac \"x = 0\")\n   apply (fastforce simp: caps_of_s_e0_caps_2)\n  apply (case_tac \"x = 1\")\n   apply (fastforce simp: caps_of_s_e1)\n  apply (fastforce simp: caps_of_s_e3)\n  done\n\nlemma cap_in_caps_caps_of_e1:\n  \"c \\<in>cap caps_of s 1 \\<Longrightarrow> target c = 1 \\<or> target c = 2\"\n  by (clarsimp simp: cap_in_caps_def caps_of_s_e1)\n\nlemma cap_in_caps_caps_of_e2:\n  \"c \\<in>cap caps_of s 2 \\<Longrightarrow> False\"\n  by (clarsimp simp: cap_in_caps_def caps_of_s_e2)\n\nlemma cap_in_caps_caps_of_to_e1:\n  \"\\<lbrakk>c \\<in>cap caps_of s x; target c = 1\\<rbrakk> \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (drule (1) caps_of_to_e1, simp)\n  done\n\nlemma cap_in_caps_caps_of_to_e2:\n  \"\\<lbrakk>c \\<in>cap caps_of s x; target c = 2\\<rbrakk> \\<Longrightarrow> x = 1\"\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (erule (1) caps_of_to_e2)\n  done\n\nlemma e1_connected_to:\n  \"s \\<turnstile> 1 \\<leftrightarrow> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (erule disjE)\n   apply (erule cap_in_caps_caps_of_to_e1, simp)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, simp)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, simp)\n  apply (erule disjE)\n   apply (erule cap_in_caps_caps_of_to_e1, simp)\n  apply (fastforce simp: shares_caps_def store_connected_s)\n  done\n\n\nlemma e2_connected_to:\n  \"s \\<turnstile> 2 \\<leftrightarrow> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (erule disjE, rule disjI1)\n   apply (erule cap_in_caps_caps_of_to_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (drule cap_in_caps_caps_of_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (drule cap_in_caps_caps_of_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (erule cap_in_caps_caps_of_to_e2, simp)\n  apply (clarsimp simp: shares_caps_def store_connected_s)\n  done\n\n\nlemma directly_tgs_connected_in_inv_image:\n  \"(directly_tgs_connected s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  by (fastforce simp: inv_image_def\n              dest!: e1_connected_to e1_connected_to [OF directly_tgs_connected_comm]\n                     e2_connected_to e2_connected_to [OF directly_tgs_connected_comm])\n\nlemma connected_inv_image_trans:\n  \"trans (inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\"\n  by (rule trans_inv_image [OF trans_Id])\n\nlemma eq_inv_image_connected:\n  \"(inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\\<^sup>= = inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  by (fastforce simp: inv_image_def)\n\nlemma rtrancl_inv_image_connected:\n  \"(inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\\<^sup>* = inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  apply (subst trancl_reflcl [symmetric])\n  apply (subst eq_inv_image_connected)\n  apply (rule trancl_id)\n  apply (rule connected_inv_image_trans)\n  done\n\nlemma tgs_connected_in_inv_image:\n  \"(tgs_connected s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  apply (simp add: tgs_connected_def)\n  apply (subst rtrancl_inv_image_connected [symmetric])\n  apply (rule rtrancl_mono)\n  apply (rule directly_tgs_connected_in_inv_image)\n  done\n\nlemma e0_not_connected_trans_e1:\n  \"\\<not> s \\<turnstile> 0 \\<leftrightarrow>* 1\"\n  apply clarsimp\n  apply (drule set_mp [OF tgs_connected_in_inv_image])\n  apply (simp add: inv_image_def)\n  done\n\nlemma e0_not_ever_connected_trans_e1:\n  \"s' \\<in> execute cmds s \\<Longrightarrow> \\<not> s' \\<turnstile> 0 \\<leftrightarrow>* 1\"\n  apply clarsimp\n  apply (drule (1) tgs_connected_preserved)\n  apply (simp add: e0_not_connected_trans_e1)\n  done\n\n\nlemma e0_e1_leakage:\n  \"s' \\<in> execute cmds s \\<Longrightarrow> \\<not> leak s' 0 1\"\n  apply (insert e0_not_connected_trans_e1)\n  apply (drule (2) leakage_rule)\n  done", "property": "System Connectivity: The system ensures that certain entities (e.g., 0, 1, and 2) have specific connectivity properties, such as the inability of entity 0 to be transitively connected to entity 1, even after executing commands.\n\nEntity Relationships: Entity 1 is connected to entity 2, and entity 1 can only be connected to entities 1 and 2. Entity 2 can only be connected to entities 1 and 2. Entity 0 is not connected to entity 1, even after executing commands, ensuring no leakage between them.", "title": "./spec/take-grant/Example2.thy", "chapter": "", "section": "", "comment": "*******************************"}
{"spec": "definition invalidate_tlb_by_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_tlb_by_asid asid \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     case maybe_vmid of\n       None \\<Rightarrow> return ()\n     | Some vmid \\<Rightarrow> do_machine_op $ invalidateTranslationASID (ucast vmid)\n   od\"", "property": "Invalidate TLB by ASID: Clear all TLB mappings associated with a given ASID. If the ASID is associated with a VMID, perform a machine operation to invalidate the translation for that VMID.", "title": "./spec/abstract/AARCH64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Clear all TLB mappings associated with this ASID."}
{"spec": "#INCLUDE_HASKELL SEL4/Model/PSpace.lhs Data.Map=DataMap ONLY PSpace\n\nend", "property": "Physical Memory Management: Manages the allocation, deallocation, and organization of physical memory, ensuring efficient and secure memory usage.", "title": "./spec/design/skel/PSpaceStruct_H.thy", "chapter": "", "section": "", "comment": "Physical Memory Structures"}
{"spec": "lemma uint_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> uint (maxIRQ::'a word) = maxIRQ\"\n  by (metis Kernel_Config.maxIRQ_def of_nat_numeral uint_nat unat_maxIRQ)", "property": "IRQ Length Property: The length of irq_len is less than or equal to the length of the word type 'a, ensuring that the unsigned integer representation of maxIRQ is equal to maxIRQ.", "title": "./spec/machine/ARM/Arch_Kernel_Config_Lemmas.thy", "chapter": "", "section": "", "comment": " Safe for [simp] because we don't use maxIRQ at lower than irq_len "}
{"spec": "text \\<open>Ghost state representing the contents of the boot info frame\\<close>\nrecord bi_frame_data =\n  bi_f_node_id :: word32\n  bi_f_num_nodes :: word32\n  bi_f_num_iopt_levels :: word32\n  bi_f_ipcbuf_vptr :: vspace_ref\n  bi_f_null_caps :: slot_region_t\n  bi_f_sh_frame_caps :: slot_region_t\n  bi_f_ui_frame_caps :: slot_region_t\n  bi_f_ui_pt_caps :: slot_region_t\n  bi_f_ut_obj_caps :: slot_region_t\n  bi_f_ut_obj_paddr_list :: \"paddr list\"\n  bi_f_ut_obj_size_bits_list :: \"word8 list\"\n  bi_f_it_cnode_size_bits :: word8\n  bi_f_num_dev_regs :: word32\n  bi_f_dev_reg_list :: \"bi_dev_reg_t list\"\n\ntype_synonym (* XXX: natural numbers represent components of kernel objects, for those\n              objects that can be subdivided *)\n  component = \"bool list\"", "property": "Boot Info Frame Data: Represents the contents of the boot info frame, including node ID, number of nodes, number of I/O page table levels, IPC buffer virtual pointer, and various capability and object information.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel Init State", "comment": ""}
{"spec": "(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/ARM.hs\n\nend (* context Arch *)\n\nend", "property": "Arch-Specific Ghost Update Functions: Provide functions for updating the ghost state of physical memory, specific to the ARM architecture.", "title": "./spec/design/skel/ARM/ArchPSpace_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "text \\<open>Lifting a normal function into the monad type:\\<close>\ndefinition liftM :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> ('s,'a) nondet_monad \\<Rightarrow> ('s, 'b) nondet_monad\" where\n  \"liftM f m \\<equiv> do x \\<leftarrow> m; return (f x) od\"", "property": "Lifting Function into Monad: Lifts a normal function into the nondeterministic state monad, allowing it to operate on monadic values while preserving the monadic context.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Library of additional Monadic Functions and Combinators", "comment": ""}
{"spec": "definition\n  get_tcb_ep_badge :: \"cdl_tcb \\<Rightarrow> cdl_badge option\"\nwhere\n  \"get_tcb_ep_badge t \\<equiv>\n    case (cdl_tcb_caps t tcb_pending_op_slot) of\n      Some (PendingSyncSendCap _ badge _ _ _ _) \\<Rightarrow> Some badge\n    | _ \\<Rightarrow> None\"", "property": "Retrieve Badge for IPC Send Operation: Obtain the badge used by a thread for its pending IPC send operation, if such an operation exists.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": "\n * Get the badge the given thread object is using to\n * perform its IPC send operation.\n "}
{"spec": "definition set_vm_root :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_vm_root tcb \\<equiv> do\n     thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n     thread_root \\<leftarrow> get_cap thread_root_slot;\n     (case thread_root of\n        ArchObjectCap (PageTableCap pt VSRootPT_T (Some (asid, _))) \\<Rightarrow> doE\n          pt' \\<leftarrow> find_vspace_for_asid asid;\n          whenE (pt \\<noteq> pt') $ throwError InvalidRoot;\n          liftE $ arm_context_switch pt asid\n        odE\n      | _ \\<Rightarrow> throwError InvalidRoot) <catch> (\\<lambda>_. set_global_user_vspace)\n  od\"\n\n\ndefinition delete_asid_pool :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"delete_asid_pool base ptr \\<equiv> do\n     assert (asid_low_bits_of base = 0);\n     asid_table \\<leftarrow> gets asid_table;\n     when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n       pool \\<leftarrow> get_asid_pool ptr;\n       mapM (\\<lambda>offset. when (pool (ucast offset) \\<noteq> None) $ do\n                            invalidate_tlb_by_asid $ base + offset;\n                            invalidate_asid_entry $ base + offset\n                      od) [0  .e.  mask asid_low_bits];\n       asid_table' \\<leftarrow> return $ asid_table (asid_high_bits_of base:= None);\n       modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>);\n       tcb \\<leftarrow> gets cur_thread;\n       set_vm_root tcb\n     od\n   od\"\n\n\ndefinition delete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"delete_asid asid pt \\<equiv> do\n     pool_ptr_op \\<leftarrow> gets (pool_for_asid asid);\n     case pool_ptr_op of\n       None \\<Rightarrow> return ()\n     | Some pool_ptr \\<Rightarrow> do\n         pool \\<leftarrow> get_asid_pool pool_ptr;\n         when (\\<exists>vmid. pool (asid_low_bits_of asid) = Some (ASIDPoolVSpace vmid pt)) $ do\n           invalidate_tlb_by_asid asid;\n           invalidate_asid_entry asid;\n           \\<comment> \\<open>re-read here, because @{text invalidate_asid_entry} changes the ASID pool:\\<close>\n           pool \\<leftarrow> get_asid_pool pool_ptr;\n           pool' \\<leftarrow> return $ pool (asid_low_bits_of asid := None);\n           set_asid_pool pool_ptr pool';\n           tcb \\<leftarrow> gets cur_thread;\n           set_vm_root tcb\n         od\n       od\n   od\"\n\n\ndefinition unmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"unmap_page_table asid vaddr pt \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     (pt_slot, level) \\<leftarrow> pt_lookup_from_level max_pt_level top_level_pt vaddr pt;\n     liftE $ store_pte (level_type level) pt_slot InvalidPTE;\n     liftE $ do_machine_op $ cleanByVA_PoU pt_slot (addrFromPPtr pt_slot);\n     liftE $ invalidate_tlb_by_asid asid\n   odE <catch> (K $ return ())\"", "property": "Address Space Management: Switch into the address space of a given thread or the global address space if none is correctly configured, ensuring that the thread's root page table is valid and properly configured.\n\nSubproperties:\n- Set VM Root: Set the virtual machine root for a given thread, ensuring that the thread's root page table is valid and properly configured.\n- Delete ASID Pool: Delete an ASID pool, invalidating all associated TLB entries and updating the ASID table.\n- Delete ASID: Delete an ASID, invalidating its TLB entry and updating the ASID pool.\n- Unmap Page Table: Unmap a page table from an ASID, invalidating its TLB entry and cleaning the page table's memory.", "title": "./spec/abstract/AARCH64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "\n  Switch into the address space of a given thread or the global address space if none is correctly\n  configured."}
{"spec": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Kernel_Config.maxIRQ\"\n\nend (* context AARCH64 *)\n\nend", "property": "IRQ Configuration: Define the maximum IRQ value based on the Kernel_Config.", "title": "./spec/design/skel/AARCH64/Hardware_H.thy", "chapter": "", "section": "", "comment": " Kernel_Config provides a generic numeral, Haskell expects type irq "}
{"spec": "definition\n  kernel_base :: \"vspace_ref\" where\n  \"kernel_base \\<equiv> 0xe0000000\"\n\ndefinition\n  idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = kernel_base + 0x1000\"\n\nend\n\narch_requalify_consts (A) kernel_base idle_thread_ptr\n\ncontext Arch begin arch_global_naming (A)", "property": "Kernel Window Base Address: The kernel reserves virtual addresses from a fixed base address (0xe0000000) upwards in every virtual address space, ensuring a consistent and protected kernel region. \n\nSubproperty: \nIdle Thread Pointer: The idle thread pointer is offset from the kernel base address by 0x1000, providing a fixed location for the idle thread in the kernel's virtual address space.", "title": "./spec/abstract/ARM_HYP/Machine_A.thy", "chapter": "", "section": "", "comment": "The lowest virtual address in the kernel window. The kernel reserves the\nvirtual addresses from here up in every virtual address space."}
{"spec": "definition arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\" where\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"", "property": "AARCH64 Capability Update: Updating AARCH64-specific capabilities does not modify user-modifiable data, preserving the integrity of capability-based access control.", "title": "./spec/abstract/AARCH64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "No user-modifiable data is stored in AARCH64-specific capabilities."}
{"spec": "chapter \\<open>Handle Hypervisor Fault Events\\<close>\n\ntheory Hypervisor_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"machine_word \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\n  where\n  \"handle_hypervisor_fault thread (ARMVCPUFault hsr) = do\n     fpu_enabled \\<leftarrow> do_machine_op isFpuEnable;\n     if \\<not>fpu_enabled\n     then fail\n     else if hsr = 0x2000000 \\<comment> \\<open>@{text UNKNOWN_FAULT}\\<close>\n          then do\n            esr \\<leftarrow> do_machine_op getESR;\n            handle_fault thread (UserException (esr && mask 32) 0)\n          od\n          else handle_fault thread (ArchFault $ VCPUFault (ucast hsr))\n   od\"\n\nend\nend", "property": "Handle Hypervisor Faults: Process hypervisor fault events by checking if the FPU is enabled, and based on the fault type, either handle a specific user exception or an architectural fault. If the FPU is not enabled, the fault handling fails.", "title": "./spec/abstract/AARCH64/Hypervisor_A.thy", "chapter": "Handle Hypervisor Fault Events", "section": "", "comment": ""}
{"spec": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/ARM.lhs CONTEXT ARM_HYP_H bodies_only ArchInv=ArchRetypeDecls_H.ARM_HYP ArchLabels=ArchInvocationLabels_H.ARM_HYP NOT checkPDAt checkPTAt checkPDASIDMapMembership checkValidMappingSize vptrFromPPtr\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert\n    (\\<lambda>s. 2 ^ pageBitsForSize sz <= gsMaxObjectSize s) []\"\n\nend\nend", "property": "VSpace Lookup and Validation: Ensures that the size of a mapping is valid by checking that it does not exceed the maximum object size allowed in the system.", "title": "./spec/design/skel/ARM_HYP/ArchVSpace_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "definition kdev_base :: \"machine_word\" where\n  \"kdev_base = Platform.AARCH64.kdevBase\"", "property": "Kernel Device Mapping Region: The virtual address for the start of the kernel device mapping region is located in the highest 1GiB of memory.", "title": "./spec/abstract/AARCH64/Machine_A.thy", "chapter": "", "section": "", "comment": "\n  Virtual address for start of kernel device mapping region in highest 1GiB of memory.\n"}
{"spec": "(*\n * Accessor functions for objects and caps.\n *)\n\ntheory KHeap_D\nimports Monads_D\nbegin", "property": "No properties can be extracted from this code snippet as it does not contain any specific functionality or behavior. It appears to be a header or import statement for a theory in a formal verification framework.", "title": "./spec/capDL/KHeap_D.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "lemmas ThreadState_defs = StrictC'_thread_state_defs", "property": "ThreadState Definitions: Consolidates the definitions related to thread states, providing a more usable and accessible name for referencing these definitions.", "title": "./spec/cspec/RISCV64/Kernel_C.thy", "chapter": "", "section": "", "comment": "Add a more usable name for the collection of ThreadState definitions"}
{"spec": "text \\<open>\n  The monad function that always fails. Returns an empty set of results and sets the failure flag.\\<close>\ndefinition fail :: \"('s, 'a) nondet_monad\" where\n  \"fail \\<equiv> \\<lambda>s. ({}, True)\"", "property": "Failure Handling: The monad function `fail` always results in an empty set of outcomes and sets the failure flag, indicating an unsuccessful computation.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": ""}
{"spec": "definition\nperform_pdpt_invocation :: \"pdpt_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_pdpt_invocation iv \\<equiv>\ncase iv of PDPTMap cap ct_slot pml4e pml4_slot vspace \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pml4e pml4_slot pml4e;\n    asid <- case cap of ArchObjectCap (PDPointerTableCap _ (Some (as, _))) \\<Rightarrow> return as\n            | _ \\<Rightarrow> fail;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\n  | PDPTUnmap (ArchObjectCap (PDPointerTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_pdpt asid vaddr p;\n      pdept_bits \\<leftarrow> return word_size_bits;\n      slots \\<leftarrow> return [p, p + (1 << pdept_bits) .e. p + (1 << pdpt_bits) - 1];\n      mapM_x (swp store_pdpte InvalidPDPTE) slots\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"\n\ndefinition\n  port_out :: \"('a word \\<Rightarrow> unit machine_monad) \\<Rightarrow> ('a word) \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"port_out f w = do\n    do_machine_op $ f w;\n    return []\n  od\"\n\ndefinition\n  port_in :: \"(data machine_monad) \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"port_in f = do\n    res \\<leftarrow> do_machine_op f;\n    return [res]\n  od\"\n\ndefinition\n  perform_io_port_invocation :: \"io_port_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_io_port_invocation i \\<equiv> (\n    case i of (IOPortInvocation port port_data) \\<Rightarrow> (\n      case port_data of\n        IOPortIn8 \\<Rightarrow> port_in (in8 port)\n      | IOPortIn16 \\<Rightarrow> port_in (in16 port)\n      | IOPortIn32 \\<Rightarrow> port_in (in32 port)\n      | IOPortOut8 w \\<Rightarrow> port_out (out8 port) w\n      | IOPortOut16 w \\<Rightarrow> port_out (out16 port) w\n      | IOPortOut32 w \\<Rightarrow> port_out (out32 port) w\n    )\n    )\"\n\ndefinition\n  perform_ioport_control_invocation :: \"io_port_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_ioport_control_invocation i \\<equiv>\n    case i of (IOPortControlInvocation f l dest_slot control_slot) \\<Rightarrow> do\n      set_ioport_mask f l True;\n      c \\<leftarrow> return $ ArchObjectCap $ IOPortCap f l;\n      cap_insert (ArchObjectCap (IOPortCap f l)) control_slot dest_slot\n    od\"\n\nabbreviation\n  arch_no_return :: \"(unit, 'z::state_ext) s_monad \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\nwhere\n  \"arch_no_return oper \\<equiv> do oper; return [] od\"", "property": "PageDirectory and I/O Port Management: PageDirectory capabilities allow for mapping and unmapping of page tables, including updating the page table entries and invalidating the page structure cache. I/O port capabilities enable reading from and writing to I/O ports, as well as controlling I/O port access by setting masks and inserting I/O port capabilities into slots.", "title": "./spec/abstract/X64/Arch_A.thy", "chapter": "", "section": "", "comment": "PageDirectory capabilities confer the authority to map and unmap page\ntables."}
{"spec": "type_synonym cdl_raw_usercontext = \"word32 list\"", "property": "TCB Context: Represent the user context of a thread as a list of 32-bit words for operations such as writing to a thread's registers.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " TCB context, for operations such as write to a thread's registers. "}
{"spec": "lemma into_rtrancl [rule_format]:\n  \"(a,b) \\<in> r^* \\<Longrightarrow> (\\<forall>x. (x,b) \\<in> r \\<longrightarrow> x = b) \\<longrightarrow> a = b\"\n  apply (erule converse_rtrancl_induct)\n   apply simp\n  apply clarsimp\n  done\n\nlemma into_rtrancl2 [rule_format]:\n  \" \\<And> B. \\<lbrakk>(a,b) \\<in> r^*; b \\<in> B\\<rbrakk> \\<Longrightarrow> (\\<forall>x.(x,b) \\<in> r \\<longrightarrow> x \\<in> B) \\<longrightarrow> a \\<in> B\"\n  thm rtrancl_induct converse_rtrancl_induct\n  apply (erule converse_rtrancl_induct)\n   apply clarsimp\n  apply clarsimp\n  oops\n\nlemma store_connected_id:\n \"{(0::word32, 0), (1, 1), (1, 2)}\\<^sup>* = {(1, 2)}\\<^sup>* \"\n  apply rule\n   apply clarsimp\n   apply (erule rtranclE)\n    apply simp\n   apply (fastforce dest: into_rtrancl)\n  apply clarsimp\n  apply (erule rtranclE)\n   apply simp\n  apply (fastforce dest: into_rtrancl)\n  done\n\nlemma store_connected_s: \"store_connected s = {(1,2)} \\<union> Id\"\n  apply simp\n  apply (rule equalityI)\n  apply (insert store_connected_direct_s)\n   apply (simp add: store_connected_def)\n   apply clarsimp\n   apply (erule converse_rtranclE)\n    apply simp\n   apply clarsimp\n   apply (erule rtranclE)\n    apply fastforce\n   apply (simp add: store_connected_id)\n   apply (drule rtranclD)\n   apply (safe, simp_all, (erule tranclE, simp, fastforce)+)\n  apply (fastforce simp: store_connected_def)\n  done", "property": "Store Connectedness: The store connected relation is defined as the union of the identity relation and the specific connection between elements 1 and 2. This relation is both reflexive and transitive, ensuring that any element connected to 1 is also connected to 2, and any element connected to itself remains unchanged.", "title": "./spec/take-grant/Example2.thy", "chapter": "", "section": "", "comment": "*******************************"}
{"spec": "definition\nunmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page pgsz asid vptr pptr \\<equiv> doE\n    vspace \\<leftarrow> find_vspace_for_asid asid;\n    case pgsz of\n          X64SmallPage \\<Rightarrow> doE\n            pt_slot \\<leftarrow> lookup_pt_slot vspace vptr;\n            pte \\<leftarrow> liftE $ get_pte pt_slot;\n            unlessE (check_mapping_pptr pptr (VMPTE pte)) $ throwError InvalidRoot;\n            liftE $ store_pte pt_slot InvalidPTE\n          odE\n        | X64LargePage \\<Rightarrow> doE\n            pd_slot \\<leftarrow> lookup_pd_slot vspace vptr;\n            pde \\<leftarrow> liftE $ get_pde pd_slot;\n            unlessE (check_mapping_pptr pptr (VMPDE pde)) $ throwError InvalidRoot;\n            liftE $ store_pde pd_slot InvalidPDE\n          odE\n        | X64HugePage \\<Rightarrow> doE\n            pdpt_slot \\<leftarrow> lookup_pdpt_slot vspace vptr;\n            pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n            unlessE (check_mapping_pptr pptr (VMPDPTE pdpte)) $ throwError InvalidRoot;\n            liftE $ store_pdpte pdpt_slot InvalidPDPTE\n          odE;\n    liftE $ do_machine_op $ invalidateTranslationSingleASID vptr (ucast asid)\nodE <catch> (K $ return ())\"", "property": "Unmap Page: Unmaps a page from the virtual address space if the given mapping details are still current. It checks the page size and corresponding page table entry, and if the physical page pointer matches, it invalidates the page table entry and flushes the translation cache for the specified ASID.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Unmap a mapped page if the given mapping details are still current."}
{"spec": "definition\n  reset_untyped_cap :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"reset_untyped_cap src_slot = doE\n  cap \\<leftarrow> liftE $ get_cap src_slot;\n  sz \\<leftarrow> returnOk $ bits_of cap;\n  base \\<leftarrow> returnOk $ obj_ref_of cap;\n  if free_index_of cap = 0\n    then returnOk ()\n  else doE\n    liftE $ delete_objects base sz;\n  dev \\<leftarrow> returnOk $ is_device_untyped_cap cap;\n\n  if dev \\<or> sz < resetChunkBits\n      then liftE $ do\n        unless dev $ do_machine_op $ clearMemory base (2 ^ sz);\n        set_cap (UntypedCap dev base sz 0) src_slot\n      od\n    else mapME_x (\\<lambda>i. doE\n          liftE $ do_machine_op $ clearMemory (base + (of_nat i << resetChunkBits))\n              (2 ^ resetChunkBits);\n          liftE $ set_cap (UntypedCap dev base sz\n              (i * 2 ^ resetChunkBits)) src_slot;\n          preemption_point\n        odE) (rev [i \\<leftarrow> [0 ..< 2 ^ (sz - resetChunkBits)].\n            i * 2 ^ resetChunkBits < free_index_of cap])\n    odE\n  odE\"", "property": "Reset Untyped Capability: Clear and reset the underlying memory and object level representation of an untyped capability, progressively moving the free region pointer back to the start of the newly cleared region. If the capability is a device or its size is smaller than the reset chunk size, clear the entire memory region at once; otherwise, clear the memory in chunks and update the capability accordingly.", "title": "./spec/abstract/Retype_A.thy", "chapter": "Retyping and Untyped Invocations", "section": "Invoking Untyped Capabilities", "comment": "Untyped capabilities note a currently free region. Sometimes this\nregion is reset during a Retype operation. This progressively clears the\nunderlying memory and also the object level representation, moving the free\nregion pointer back to the start of the newly cleared region each time."}
{"spec": "definition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend", "property": "Canonical Address Assertion: The function `canonicalAddressAssert` always returns true, indicating that the provided machine word is considered to be in a canonical form.", "title": "./spec/design/skel/ARM/ArchRetypeDecls_H.thy", "chapter": "", "section": "", "comment": " Defined differently and/or delayed on different architectures "}
{"spec": "lemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\nend\nend", "property": "Message Alignment: The message alignment value is made visible through the msg_align_bits constant, ensuring proper alignment of messages in memory.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "Make numeric value of @{const msg_align_bits} visible."}
{"spec": "definition\n  ensure_empty :: \"cdl_cap_ref \\<Rightarrow> unit except_monad\"\nwhere\n  \"ensure_empty cap_ref \\<equiv> doE\n     cap \\<leftarrow> liftE $ get_cap cap_ref;\n     unlessE (cap = NullCap) $ throw\n  odE\"", "property": "Ensure Slot Emptiness: Verify that the specified capability slot is empty, and if not, throw an exception.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": " Ensure that the given cap slot is empty. "}
{"spec": "text \\<open>Helper function to handle a signal operation in the case\nwhere a receiver is waiting.\\<close>\ndefinition\n  update_waiting_ntfn :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref option \\<Rightarrow> badge \\<Rightarrow>\n                         (unit,'z::state_ext) s_monad\"\nwhere\n  \"update_waiting_ntfn ntfnptr queue bound_tcb badge \\<equiv> do\n     assert (queue \\<noteq> []);\n     (dest,rest) \\<leftarrow> return $ (hd queue, tl queue);\n     set_notification ntfnptr $ \\<lparr>\n         ntfn_obj = (case rest of [] \\<Rightarrow> IdleNtfn | _ \\<Rightarrow> WaitingNtfn rest),\n         ntfn_bound_tcb = bound_tcb \\<rparr>;\n     set_thread_state dest Running;\n     as_user dest $ setRegister badge_register badge;\n     do_extended_op (possible_switch_to dest)\n\n   od\"", "property": "Asynchronous Message Transfer to Waiting Receiver: When a receiver is waiting for a notification, update the notification object, set the receiver's thread state to running, set the badge register, and potentially switch to the receiver's thread. \n\nUpdate Notification Object: Update the notification object's state to either IdleNtfn or WaitingNtfn, depending on whether there are remaining waiting threads.", "title": "./spec/abstract/Ipc_A.thy", "chapter": "IPC", "section": "Asynchronous Message Transfers", "comment": ""}
{"spec": "definition\n  arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"", "property": "Architectural Capability Update: Updating x64-specific capabilities does not modify user-modifiable data.", "title": "./spec/abstract/X64/ArchVSpace_A.thy", "chapter": "", "section": "", "comment": "No user-modifiable data is stored in x64-specific capabilities."}
{"spec": "definition\nthrow_on_false :: \"'e \\<Rightarrow> (bool,'z::state_ext) s_monad \\<Rightarrow> ('e + unit,'z::state_ext) s_monad\" where\n\"throw_on_false ex f \\<equiv> doE v \\<leftarrow> liftE f; unlessE v $ throwError ex odE\"\n\nend", "property": "Raise Exception on Condition Failure: Throws an exception if a given condition does not hold, ensuring that the system maintains its integrity and handles errors appropriately.", "title": "./spec/abstract/KHeap_A.thy", "chapter": "Accessing the Kernel Heap", "section": "User Context", "comment": "Raise an exception if a property does not hold."}
{"spec": "definition\n  update_cap_data :: \"bool \\<Rightarrow> word32 \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap k_monad\"\nwhere\n  \"update_cap_data preserve data cap \\<equiv>\n    return $ case cap of\n        EndpointCap _ b _ \\<Rightarrow>\n          if b = 0 \\<and> \\<not> preserve then\n            badge_update data cap\n          else\n            NullCap\n      | NotificationCap _ b _ \\<Rightarrow>\n          if b = 0 \\<and> \\<not> preserve then\n            badge_update data cap\n          else\n            NullCap\n      | CNodeCap object guard guard_size sz \\<Rightarrow>\n          let\n            reserved_bits = 3;\n            guard_bits = 18;\n            guard_size_bits = 5;\n\n            new_guard_size = unat ((data >> reserved_bits) && mask guard_size_bits);\n            new_guard = (data >> (reserved_bits + guard_size_bits)) && mask (min (unat ((data >> reserved_bits) && mask guard_size_bits)) guard_bits)\n          in\n            if new_guard_size + sz > word_bits then NullCap else\n            (CNodeCap object new_guard new_guard_size sz)\n      | _ \\<Rightarrow> cap\"", "property": "Capability Update: Transform a capability based on a user request, interpreting the \"data\" word differently for various capability types, and return a set of possible capabilities to accommodate non-deterministic implementations.\n\nSubproperties:\n- Endpoint and Notification Capabilities: Update the badge of the capability if the current badge is zero and the preserve flag is not set; otherwise, return a Null Capability.\n- CNode Capability: Update the guard size and guard of the capability based on the provided data, ensuring that the new guard size does not exceed the word size limit; otherwise, return a Null Capability.\n- Other Capability Types: Return the original capability unchanged.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": "\n * Transform a capability based on a request from the user.\n *\n * The \"data\" word is interpreted differently for different cap types.\n *\n * We return a set of possible caps to allow for non-deterministic\n * implementations, to avoid messy implementation details of the CDT\n * in lower-level models.\n "}
{"spec": "idle_thread \\<leftarrow> gets idle_thread;\n     modify (\\<lambda>s. s\\<lparr> cur_thread := idle_thread \\<rparr>);\n\n     switch_to_thread tcb_pptr;\n\n     cap \\<leftarrow> return $ ThreadCap tcb_pptr;\n     write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_TCB) cap\n   od)\n   odE\"\n\ndefinition\n  create_device_frames :: \"cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_device_frames root_cnode_cap \\<equiv> doE\n     dev_regs \\<leftarrow> do_kernel_op $ do_machine_op getDeviceRegions;\n\n     (swp mapME) dev_regs (\\<lambda>(start,end). doE", "property": "Kernel Initialization: Set up the initial kernel state by switching to the idle thread, setting the current thread, and writing the thread capability to the root CNode. \n\nDevice Frame Creation: Create device frames by retrieving device regions and mapping each region to a device frame.", "title": "./spec/abstract/KernelInit_A.thy", "chapter": "", "section": "Kernel init functions", "comment": " scheduler action not in abstract spec "}
{"spec": "(*\n * Operations on page table objects and frames.\n *)\n\ntheory Asid_D\nimports\n  Invocations_D\n  CSpace_D\n  Untyped_D\nbegin\n\ndefinition\n  decode_asid_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_asid_control_intent \\<Rightarrow> cdl_asid_control_invocation except_monad\"\nwhere\n  \"decode_asid_control_invocation target target_ref caps intent \\<equiv> case intent of\n     AsidControlMakePoolIntent index depth \\<Rightarrow>\n       doE\n         base \\<leftarrow> liftE $ select {x. x < 2 ^ asid_high_bits};\n\n         \\<comment> \\<open>Fetch the untyped item, and ensure it is valid.\\<close>\n         (untyped_cap, untyped_cap_ref) \\<leftarrow> throw_on_none $ get_index caps 0;\n         (case untyped_cap of\n             UntypedCap _ s _ \\<Rightarrow> returnOk ()\n           | _ \\<Rightarrow> throw);\n         ensure_no_children untyped_cap_ref;\n\n         \\<comment> \\<open>Fetch the slot we plan to put the generated cap into.\\<close>\n         (cspace_cap, _) \\<leftarrow> throw_on_none $ get_index caps 1;\n         target_slot \\<leftarrow> lookup_slot_for_cnode_op cspace_cap index (unat depth);\n         ensure_empty target_slot;\n\n         returnOk $ MakePool (set_available_range untyped_cap {}) untyped_cap_ref\n           (cap_objects untyped_cap) target_slot base\n       odE \\<sqinter> throw\"\n\ndefinition\n  decode_asid_pool_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_asid_pool_intent \\<Rightarrow> cdl_asid_pool_invocation except_monad\"\nwhere\n  \"decode_asid_pool_invocation target target_ref caps intent \\<equiv> case intent of\n     AsidPoolAssignIntent \\<Rightarrow>\n       doE\n         (pd_cap, pd_cap_ref) \\<leftarrow> throw_on_none $ get_index caps 0;\n         (case pd_cap of\n             PageDirectoryCap _ _ _ \\<Rightarrow> returnOk ()\n           | _ \\<Rightarrow> throw);\n\n         base \\<leftarrow> (case target of\n             AsidPoolCap p base \\<Rightarrow> returnOk $ base\n           | _ \\<Rightarrow> throw);\n         offset \\<leftarrow> liftE $ select {x. x < 2 ^ asid_low_bits};\n         returnOk $ Assign (base, offset) pd_cap_ref (cap_object target, offset)\n       odE \\<sqinter> throw\"\n\ndefinition\n  invoke_asid_control :: \"cdl_asid_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_asid_control params \\<equiv>\n    case params of\n        MakePool untyped_cap untyped_cap_ref untyped_covers target_slot base \\<Rightarrow>\n          do\n            \\<comment> \\<open>Untype the region. A choice may be made about whether to detype\n               objects with Untyped addresses.\\<close>\n            modify (detype untyped_covers);\n            set_cap untyped_cap_ref untyped_cap;\n            targets \\<leftarrow> generate_object_ids 1 AsidPoolType untyped_covers;\n\n            \\<comment> \\<open>Retype the region.\\<close>\n            retype_region 0 AsidPoolType targets;\n            assert (targets \\<noteq> []);\n\n            \\<comment> \\<open>Insert the cap.\\<close>\n            frame \\<leftarrow> return $ pick (hd targets);\n            insert_cap_child (AsidPoolCap frame base) untyped_cap_ref target_slot;\n\n            \\<comment> \\<open>Update the asid table.\\<close>\n            asid_table \\<leftarrow> gets cdl_asid_table;\n            asid_table' \\<leftarrow> return $ asid_table (base \\<mapsto> AsidPoolCap frame 0);\n            modify (\\<lambda>s. s \\<lparr>cdl_asid_table := asid_table'\\<rparr>)\n\n          od\"\n\ndefinition\n  invoke_asid_pool :: \"cdl_asid_pool_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_asid_pool params \\<equiv>\n     case params of\n       Assign asid pd_cap_ref ap_target_slot \\<Rightarrow> do\n         pd_cap \\<leftarrow> get_cap pd_cap_ref;\n         case pd_cap of\n           PageDirectoryCap pd_id _ _ \\<Rightarrow> do\n             set_cap pd_cap_ref (PageDirectoryCap pd_id Real (Some asid));\n             set_cap ap_target_slot (PageDirectoryCap pd_id Fake None)\n           od\n         | _ \\<Rightarrow> fail\n       od\"\n\nend", "property": "ASID Control and Pool Management: \n- ASID Control Invocation: Decodes and performs ASID control invocations, including making a new ASID pool from an untyped capability, ensuring the untyped item is valid, and inserting the generated cap into the target slot.\n- ASID Pool Invocation: Decodes and performs ASID pool invocations, including assigning a page directory to an ASID pool, updating the page directory capability, and setting the ASID pool capability.\n- ASID Control and Pool Operations: Invokes ASID control and pool operations, including untyping and retyping regions, inserting capabilities, and updating the ASID table.", "title": "./spec/capDL/Asid_D.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "lemma bindE_assoc:\n  \"(m >>=E f) >>=E g = m >>=E (\\<lambda>x. f x >>=E g)\"\n  unfolding bindE_def\n  by (fastforce simp: bind_assoc lift_def throwError_def\n                split: sum.splits\n                intro: arg_cong[where f=\"\\<lambda>x. m >>= x\"])", "property": "Associativity of Bind with Exceptions: The bind operation with exceptions is associative, ensuring that the order in which exceptions are handled does not affect the outcome.", "title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "chapter": "Nondeterministic State Monad with Failure", "section": "Adding Exceptions", "comment": "Associativity of @{const bindE}:"}
{"spec": "definition\n  allActiveTCBs :: \"(obj_ref set,'z::state_ext) s_monad\" where\n  \"allActiveTCBs \\<equiv> do\n    state \\<leftarrow> get;\n    return {x. getActiveTCB x state \\<noteq> None}\n   od\"", "property": "Retrieve All Active Threads: Obtain a set of all threads in the system that are currently schedulable.", "title": "./spec/abstract/Schedule_A.thy", "chapter": "", "section": "", "comment": "Gets all schedulable threads in the system."}
{"spec": "text \\<open>An ASID is simply a word.\\<close>\ntype_synonym asid = \"word32\"\n\ndatatype vm_attribute = ParityEnabled | PageCacheable | Global | XNever\ntype_synonym vm_attributes = \"vm_attribute set\"", "property": "ARM-Specific Data Types: Define architecture-specific data types for the ARM architecture, including the ASID (Application-Specific ID) type as a 32-bit word and VM (Virtual Memory) attributes as a set of flags (ParityEnabled, PageCacheable, Global, XNever).", "title": "./spec/abstract/ARM/Arch_Structs_A.thy", "chapter": "ARM-Specific Data Types", "section": "Architecture-specific capabilities", "comment": ""}
{"spec": "definition\n  getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\nwhere\n  \"getActiveIRQ in_kernel \\<equiv> do\n    is_masked \\<leftarrow> gets $ irq_masks;\n    modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n    active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n    if is_masked active_irq \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n    then return None\n    else return (Some active_irq)\n  od\"\n\ndefinition\n  maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"maskInterrupt m irq \\<equiv>\n  modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition\n  lineStart :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"lineStart addr = (addr >> cacheLineBits) << cacheLineBits\"", "property": "Machine Operations: Manage interrupt handling and masking, ensuring deterministic and efficient interrupt processing. This includes updating the IRQ state, retrieving the active IRQ, and masking interrupts.\n\nSubproperties:\n- IRQ State Update: Increment the IRQ state to reflect the passage of time since the last IRQ retrieval.\n- Active IRQ Retrieval: Get the active IRQ, considering IRQ masking and kernel-mode restrictions.\n- Interrupt Masking: Set or clear the mask for a specific IRQ, controlling its interruptibility.", "title": "./spec/machine/ARM/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": "\n  @{term getActiveIRQ} is now derministic.\n  It 'updates' the irq state to the reflect the passage of\n  time since last the irq was gotten, then it gets the active\n  IRQ (if there is one).\n"}
{"spec": "(*\nFunctions for fault handling.\n*)\n\nchapter \\<open>arch fault related functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n  \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData) od\"\n| \"make_arch_fault_msg (VCPUFault hsr) thread = return (7, [hsr])\"\n| \"make_arch_fault_msg (VPPIEvent irq) thread = return (8, [ucast irq])\"\n| \"make_arch_fault_msg (VGICMaintenance archData) thread = do\n      msg \\<leftarrow> return $ (case archData of None \\<Rightarrow> [-1] | Some idx \\<Rightarrow> [idx]);\n      return (6, msg)\n   od\"\n\ndefinition\n  handle_arch_fault_reply :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_arch_fault_reply af thread x y = return True\"\n\n\nend\n\nend", "property": "Arch Fault Message Generation: Generates a message for different types of architectural faults, including VM faults, VCPU faults, VPPI events, and VGIC maintenance. The message includes specific data relevant to the fault type, such as the restart PC, virtual pointer, and additional fault-specific data.", "title": "./spec/abstract/ARM_HYP/ArchFault_A.thy", "chapter": "arch fault related functions", "section": "", "comment": ""}
{"spec": "definition\n  derive_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap except_monad\"\nwhere\n  \"derive_cap slot cap \\<equiv> case cap of\n     UntypedCap _ _ _ \\<Rightarrow> doE ensure_no_children slot; returnOk cap odE\n   | ReplyCap _ _ \\<Rightarrow> returnOk NullCap\n   | MasterReplyCap oref \\<Rightarrow> returnOk NullCap\n   | IrqControlCap \\<Rightarrow> returnOk NullCap\n   | ZombieCap _ \\<Rightarrow> returnOk NullCap\n   | FrameCap dev p r sz b x \\<Rightarrow> returnOk (FrameCap dev p r sz b None)\n   | PageTableCap _ _ _ \\<Rightarrow> throw \\<sqinter> returnOk cap\n   | PageDirectoryCap _ _ _ \\<Rightarrow> throw \\<sqinter> returnOk cap\n   | _ \\<Rightarrow> returnOk cap\"", "property": "Derive Capabilities: Derives a new capability from an existing one, potentially returning a modified version or `NullCap` for certain types. For `FrameCap`, it clears the badge. For `PageTableCap` and `PageDirectoryCap`, it may throw an exception or return the original capability, reflecting the nondeterminism in their handling. Other capabilities are returned unchanged.", "title": "./spec/capDL/CSpace_D.thy", "chapter": "", "section": "", "comment": "\n * Some caps may not be copied/minted. In this case the following function\n * returns NullCap or throws.\n *\n * PageTable and PageDirectory caps may not be copied if already mapped. This is\n * left out here and modelled by nondeterminism.\n "}
{"spec": "definition\n  create_cap :: \"cdl_object_type \\<Rightarrow> nat \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool \\<Rightarrow> (cdl_cap_ref \\<times> cdl_object_id set) \\<Rightarrow> unit k_monad\"\nwhere\n  \"create_cap new_type sz parent_slot dev \\<equiv> \\<lambda>(dest_slot, obj_refs).\n  do\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_cap dest_slot (default_cap new_type obj_refs sz dev);\n    set_parent dest_slot parent_slot\n  od\"\n\n\ndefinition\n  update_available_range :: \"(cdl_object_id set) => (cdl_object_id list) \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere \"update_available_range orange newids cap_ref cap \\<equiv>\n  do\n     new_range  \\<leftarrow> select {x. x \\<subseteq> orange - set newids};\n     set_cap cap_ref $ set_available_range cap new_range\n  od\"\n\n\ndefinition\n  retype_region :: \"nat \\<Rightarrow> cdl_object_type \\<Rightarrow> (cdl_object_id set list)\n  \\<Rightarrow> ((cdl_object_id set) list) k_monad\"\nwhere\n  \"retype_region target_bits target_type target_object_ids \\<equiv>\n    do\n      \\<comment> \\<open>Get a list of target locations. We are happy with any unused name\n         within the target range.\\<close>\n\n      if (target_type \\<noteq> UntypedType) then\n       do\n         current_domain \\<leftarrow> gets cdl_current_domain;\n         create_objects target_object_ids (default_object target_type target_bits current_domain)\n       od\n      else return ();\n\n      \\<comment> \\<open>Get a list of target locations. We are happy with any unused name\n         within the target range.\\<close>\n      return target_object_ids\n    od\"\n\nprimrec (nonexhaustive)\n  untyped_is_device :: \"cdl_cap \\<Rightarrow> bool\"\nwhere\n    \"untyped_is_device (UntypedCap d _ _) = d\"\n\ndefinition\n  reset_untyped_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"reset_untyped_cap cref \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap cref;\n    whenE (available_range cap \\<noteq> cap_objects cap) $ doE\n      liftE $ modify (detype (cap_objects cap));\n      new_rans \\<leftarrow> liftE $ select {xs. (\\<forall>S \\<in> set xs.\n              S \\<subseteq> cap_objects cap \\<and> available_range cap \\<subset> S)\n          \\<and> xs \\<noteq> [] \\<and> List.last xs = cap_objects cap};\n      mapME_x (\\<lambda>r. doE\n        liftE $ set_cap cref $ set_available_range cap r;\n        returnOk () \\<sqinter> throw\n      odE) new_rans\n    odE\n  odE\"\n\ndefinition\n  invoke_untyped :: \"cdl_untyped_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_untyped params \\<equiv> case params of\n     Retype untyped_ref new_type type_size target_slots has_kids num_objects \\<Rightarrow>\n   doE\n     unlessE has_kids $ reset_untyped_cap untyped_ref;\n       liftE $ do\n         untyped_cap \\<leftarrow> get_cap untyped_ref;\n\n         new_range \\<leftarrow> return $ available_range untyped_cap;\n         new_obj_refs \\<leftarrow> generate_object_ids num_objects new_type new_range;\n\n         update_available_range new_range (map (\\<lambda>s. pick s) new_obj_refs) untyped_ref untyped_cap;\n\n         \\<comment> \\<open>Construct new objects within the covered range.\\<close>\n         retype_region type_size new_type new_obj_refs;\n\n         \\<comment> \\<open>Construct caps for the new objects.\\<close>\n         mapM_x (create_cap new_type type_size untyped_ref (untyped_is_device untyped_cap)) (zip target_slots new_obj_refs);\n\n         \\<comment> \\<open>Ideally, we should return back to the user how many\n            objects were created.\\<close>\n\n         return ()\n       od\n    odE\"\n\nend", "property": "Create and Update Capabilities: Create new capabilities for objects, set their default properties, and update the available range for untyped capabilities. This ensures that new objects are properly initialized and integrated into the system, while maintaining the integrity of the available object ranges.", "title": "./spec/capDL/Untyped_D.thy", "chapter": "", "section": "", "comment": " Insert a cap for a new object in the given location. "}
{"spec": "definition\n  init_tcb_ptr :: word32 where\n  \"init_tcb_ptr = kernel_base + 0x2000\"\n\ndefinition\n  init_irq_node_ptr :: word32 where\n  \"init_irq_node_ptr = kernel_base + 0x8000\"", "property": "Dummy Initial State: Defines the initial state of the kernel with dummy values, ensuring consistency of invariants and refinement relations. \n\nInitialization Constants: Specifies the initial pointers for the thread control block (TCB) and interrupt request (IRQ) node.", "title": "./spec/abstract/ARM/Init_A.thy", "chapter": "", "section": "", "comment": "\n  This is not a specification of true kernel\n  initialisation. This theory describes a dummy initial state only, to\n  show that the invariants and refinement relation are consistent.\n"}
{"spec": "|  TcbConfigureIntent cdl_cptr cdl_raw_capdata cdl_raw_capdata word32", "property": "TCB Configuration: Configure various settings for a target thread, including its fault endpoint, capability space root, virtual space root, and IPC buffer, along with their associated data.", "title": "./spec/capDL/Intents_D.thy", "chapter": "", "section": "", "comment": " Configure: (target), fault_ep, (cspace_root), cspace_root_data, (vspace_root), vspace_root_data, buffer, (bufferFrame) "}
{"spec": "definition non_kernel_IRQs :: \"irq set\"\n  where\n  \"non_kernel_IRQs = {}\"", "property": "Non-Kernel Interrupts: Define the set of interrupts that cannot occur while the kernel is running but can occur from user mode as an empty set.", "title": "./spec/machine/RISCV64/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": "Interrupts that cannot occur while the kernel is running (e.g. at preemption points), but\nthat can occur from user mode. Empty on RISCV64."}
{"spec": "context begin interpretation Arch .\nrequalify_consts NormalPT_T VSRootPT_T\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 10\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]", "property": "Page Table Type Constructors: Define constructors for retype annotations, specifically for normal page tables and virtual space root page tables, to be used globally in the C code.", "title": "./spec/cspec/AARCH64/Kernel_C.thy", "chapter": "", "section": "", "comment": " Also need pt_type constructors for retype annotations. We leave them available globally for C. "}
{"spec": "definition\n  send_ipc :: \"bool \\<Rightarrow> bool \\<Rightarrow> badge \\<Rightarrow> bool \\<Rightarrow> bool\n                \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"send_ipc block call badge can_grant can_grant_reply thread epptr \\<equiv> do\n     ep \\<leftarrow> get_endpoint epptr;\n     case (ep, block) of\n         (IdleEP, True) \\<Rightarrow> do\n               set_thread_state thread (BlockedOnSend epptr\n                                   \\<lparr> sender_badge = badge,\n                                     sender_can_grant = can_grant,\n                                     sender_can_grant_reply = can_grant_reply,\n                                     sender_is_call = call \\<rparr>);\n               set_endpoint epptr $ SendEP [thread]\n             od\n       | (SendEP queue, True) \\<Rightarrow> do\n               set_thread_state thread (BlockedOnSend epptr\n                                   \\<lparr> sender_badge = badge,\n                                     sender_can_grant = can_grant,\n                                     sender_can_grant_reply = can_grant_reply,\n                                     sender_is_call = call\\<rparr>);\n               set_endpoint epptr $ SendEP (queue @ [thread])\n             od\n       | (IdleEP, False) \\<Rightarrow> return ()\n       | (SendEP queue, False) \\<Rightarrow> return ()\n       | (RecvEP (dest # queue), _) \\<Rightarrow> do\n                set_endpoint epptr $ (case queue of [] \\<Rightarrow> IdleEP\n                                                     | _ \\<Rightarrow> RecvEP queue);\n                recv_state \\<leftarrow> get_thread_state dest;\n                reply_can_grant \\<leftarrow> case recv_state\n                  of (BlockedOnReceive x data) \\<Rightarrow> do\n                           do_ipc_transfer thread (Some epptr) badge can_grant dest;\n                           return (receiver_can_grant data)\n                           od\n                  | _ \\<Rightarrow> fail;\n                set_thread_state dest Running;\n                do_extended_op (possible_switch_to dest);\n                when call $\n                  if (can_grant \\<or> can_grant_reply)\n                  then setup_caller_cap thread dest reply_can_grant\n                  else set_thread_state thread Inactive\n                od\n\n       | (RecvEP [], _) \\<Rightarrow> fail\n   od\"", "property": "Synchronous Message Transfer: Handles message send operations on an endpoint by a thread, transferring the message to a waiting receiver if available. If no receiver is waiting and the thread is willing to block, it is placed in the sending queue of the endpoint. If the thread is not willing to block and there is no waiting receiver, the operation does nothing.", "title": "./spec/abstract/Ipc_A.thy", "chapter": "IPC", "section": "Synchronous Message Transfers", "comment": "Handle a message send operation performed on an endpoint by a thread.\nIf a receiver is waiting then transfer the message. If no receiver is available\nand the thread is willing to block waiting to send then put it in the endpoint\nsending queue."}
{"spec": "type_synonym ('a,'z) f_monad = \"(fault + 'a,'z) s_monad\"\n\nterm \"a::(unit,'a) s_monad\"", "property": "Fault Monad: Handles exceptions by potentially throwing a fault, which is typically reported to the current thread's fault handler.", "title": "./spec/abstract/Exceptions_A.thy", "chapter": "", "section": "", "comment": "The fault monad: may throw a @{text fault} exception which\nwill usually be reported to the current thread's fault handler."}
{"spec": "lemma \"LENGTH(pt_index_len) = ptTranslationBits\"\n  by (simp add: ptTranslationBits_def)\n\ntype_synonym asid_pool = \"asid_low_index \\<rightharpoonup> obj_ref\"\ntype_synonym pt = \"pt_index \\<Rightarrow> pte\"", "property": "RISCV64-Specific Data Types: Define architecture-specific object types, including the ASID pool and page table (PT), which are essential for managing memory and address translation in the RISCV64 architecture. \n\n Page Table Index Length: The length of the page table index is equal to the number of translation bits, ensuring proper address translation.", "title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "chapter": "RISCV64-Specific Data Types", "section": "Architecture-specific object types and default objects", "comment": "Sanity check:"}
{"spec": "theory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n  pt_array_len\n  vs_array_len\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . \n\n\nlemma ptTranslationBits_vs_array_len':\n  \"2 ^ ptTranslationBits VSRootPT_T = vs_array_len\"\n  by (simp add: vs_array_len_val ptTranslationBits_vs_index_bits vs_index_bits_def\n                Kernel_Config.config_ARM_PA_SIZE_BITS_40_def)\n\nlemmas ptTranslationBits_vs_array_len = ptTranslationBits_vs_array_len'[unfolded vs_array_len_val]\n\ntype_synonym cghost_state =\n  \"(machine_word \\<rightharpoonup> vmpage_size) \\<times>   \\<comment> \\<open>Frame sizes\\<close>\n   (machine_word \\<rightharpoonup> nat) \\<times>           \\<comment> \\<open>CNode sizes\\<close>\n   (machine_word \\<rightharpoonup> pt_type) \\<times>       \\<comment> \\<open>PT types\\<close>\n   ghost_assertions\"                 \\<comment> \\<open>ASMRefine assertions\\<close>\n\ndefinition gs_clear_region :: \"addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n     (\\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n      \\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x,\n      \\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd (snd gs)) x,\n      snd (snd (snd gs)))\"\n\ndefinition gs_new_frames:: \"vmpage_size \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n     if bits < pageBitsForSize sz then gs\n     else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                    x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n               else fst gs x, snd gs)\"\n\ndefinition gs_new_cnodes:: \"nat \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n     if bits < sz + 4 then gs\n     else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                       then Some sz\n                       else fst (snd gs) x, snd (snd gs))\"\n\ndefinition gs_new_pt_t:: \"pt_type \\<Rightarrow> addr \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_pt_t pt_t ptr \\<equiv>\n     \\<lambda>gs. (fst gs, fst (snd gs), (fst (snd (snd gs))) (ptr \\<mapsto> pt_t), snd (snd (snd gs)))\"\n\nabbreviation gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> machine_word\" where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd \\<circ> snd \\<circ> snd)\"\n\nabbreviation gs_set_assn :: \"int \\<Rightarrow> machine_word \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd \\<circ> apsnd \\<circ> apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend", "property": "Ghost State Management: Manages the ghost state, including frame sizes, CNode sizes, PT types, and assertions. It provides operations to clear regions, add new frames, add new CNodes, and set PT types, ensuring that the ghost state accurately reflects the system's memory and capability configurations.", "title": "./spec/cspec/AARCH64/Kernel_C.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "theory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs Platform=Platform.RISCV64 CONTEXT RISCV64_H NOT plic_complete_claim getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory setHardwareASID wordFromPDE wordFromPTE VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize toPAddr addrFromPPtr ptrFromPAddr sfence physBase paddrBase pptrBase pptrBaseOffset pptrTop pptrUserTop kernelELFBase kernelELFBaseOffset kernelELFPAddrBase addrFromKPPtr ptTranslationBits vmFaultTypeFSR read_stval setVSpaceRoot hwASIDFlush setIRQTrigger\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64_H instanceproofs NOT plic_complete_claim HardwareASID VMFaultType VMPageSize VMPageEntry HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64_H ONLY wordFromPTE", "property": "Hardware Abstraction: Provide a hardware abstraction layer for the RISCV64 architecture, encapsulating low-level operations and hardware-specific details, such as memory management, interrupt handling, and timer configuration, to facilitate platform-agnostic kernel development.\n\nSubproperties:\n- Memory Management: Manage memory regions, kernel devices, and hardware ASIDs, ensuring efficient memory allocation and deallocation.\n- Interrupt Handling: Handle interrupts, including getting active IRQs, acknowledging and masking interrupts, and configuring timers.\n- Low-Level Operations: Perform low-level operations, such as loading and storing words, setting the next PC, and clearing memory.\n- Virtual Memory: Manage virtual memory, including page table translations, VM fault types, and VM page sizes.\n- Hardware-Specific Details: Encapsulate hardware-specific details, such as physical base addresses, page bits, and VM rights.", "title": "./spec/design/skel/RISCV64/Hardware_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "lemma numDomains_not_zero:\n  \"numDomains > 0\"\n  unfolding Kernel_Config.numDomains_def\n  by simp\n\nlemma numDomains_machine_word_safe:\n  \"unat (of_nat numDomains :: machine_word) = numDomains\"\n  unfolding Kernel_Config.numDomains_def by simp\n\nend", "property": "Configuration Constants: Ensure the validity and consistency of architecture-independent configuration constants, specifically the number of domains, to maintain proof resilience across different configurations.\n  - Non-Zero Domain Count: The number of domains is always greater than zero.\n  - Domain Count Machine Word Safety: The number of domains can be safely represented as an unsigned machine word without loss of information.", "title": "./spec/machine/Kernel_Config_Lemmas.thy", "chapter": "", "section": "", "comment": "\n  seL4's build system allows configuration of some architecture-independent constants, such as the\n  number of domains.\n\n  The long-term goal is to make the proofs resilient in the face of changes of these configuration\n  options. To this end this theory contains properties of these constants, to avoid unfolding\n  their values later in the proofs."}
{"spec": "type_synonym ('a,'z) p_monad = \"(unit + 'a,'z) s_monad\"", "property": "Preemption Monad: May throw an interrupt exception, allowing for preemption of the current execution.", "title": "./spec/abstract/Exceptions_A.thy", "chapter": "", "section": "", "comment": "The preemption monad. May throw an interrupt exception."}
{"spec": "definition pptr_from_pte :: \"pte \\<Rightarrow> vspace_ref\" where\n  \"pptr_from_pte pte \\<equiv> ptrFromPAddr (pte_base_addr pte)\"\n\ndefinition pt_slot_offset :: \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\" where\n  \"pt_slot_offset level pt_ptr vptr = pt_ptr + (pt_index level vptr << pte_bits)\"", "property": "Virtual Address Space Management: Provides basic operations for accessing and managing the AARCH64 virtual address space. \n\nAddress Translation: Extract the physical address from a page table entry (PTE).\n\nPage Table Slot Calculation: Calculate the offset of a page table slot for a given virtual address and page table level.", "title": "./spec/abstract/AARCH64/ArchVSpaceAcc_A.thy", "chapter": "Accessing the AARCH64 VSpace", "section": "Basic Operations", "comment": ""}
{"spec": "text \\<open>Clear memory contents to recycle it as user memory. Do not yet flush the cache.\\<close>\ndefinition clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"clearMemory ptr bytelength \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"", "property": "Clear Memory: Clear a specified range of memory by setting each word in the range to zero, preparing it for reuse as user memory without flushing the cache.", "title": "./spec/machine/AARCH64/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": ""}
{"spec": "definition\n  ensure_empty :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"ensure_empty slot \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap slot;\n    whenE (cap \\<noteq> NullCap) (throwError DeleteFirst)\n  odE\"", "property": "Ensure Capability Slot Emptiness: Guarantee that a capability slot is empty by checking if it contains a non-Null capability, and if so, throw an error.", "title": "./spec/abstract/CSpaceAcc_A.thy", "chapter": "Accessing CSpace", "section": "Accessing the capability derivation tree", "comment": "Ensure a capability slot is empty."}
{"spec": "requalify_consts (aliasing)\n  deriveCap finaliseCap postCapDeletion isCapRevocable\n  hasCancelSendRights sameRegionAs isPhysicalCap\n  sameObjectAs updateCapData maskCapRights\n  createObject capUntypedPtr capUntypedSize\n  performInvocation decodeInvocation prepareThreadDelete\n\ncontext begin global_naming global\n\nrequalify_consts (aliasing)\n  RetypeDecls_H.deriveCap RetypeDecls_H.finaliseCap RetypeDecls_H.postCapDeletion\n  RetypeDecls_H.isCapRevocable\n  RetypeDecls_H.hasCancelSendRights RetypeDecls_H.sameRegionAs RetypeDecls_H.isPhysicalCap\n  RetypeDecls_H.sameObjectAs RetypeDecls_H.updateCapData RetypeDecls_H.maskCapRights\n  RetypeDecls_H.createObject RetypeDecls_H.capUntypedPtr RetypeDecls_H.capUntypedSize\n  RetypeDecls_H.performInvocation RetypeDecls_H.decodeInvocation\nend\n\nend\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType.lhs Arch=Arch bodies_only\n\nend", "property": "Namespace Disambiguation: Disambiguates names between architecture-specific and non-architecture-specific constants to prevent naming conflicts.", "title": "./spec/design/skel/Retype_H.thy", "chapter": "", "section": "", "comment": " disambiguate name clash between Arch and non-arch consts with same names "}
{"spec": "chapter \\<open>Architecture-specific TCB functions\\<close>\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\" where\n  \"sanitise_register b r v \\<equiv> case r of\n     SPSR_EL1 \\<Rightarrow> if b \\<and> v && 0x1f \\<in> {0,4,5} then v else v && 0xf0000000 || 0x140\n   | _ \\<Rightarrow> v\"\n\ndefinition arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\" where\n  \"arch_get_sanitise_register_info t \\<equiv> do\n     vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n     return (vcpu \\<noteq> None)\n   od\"\n\ndefinition arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\" where\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend", "property": "Architecture-specific TCB Functions: Sanitize and manage thread control block (TCB) registers based on architecture-specific rules. The sanitization process ensures that specific register values are modified to maintain system integrity, and the post-modification process updates the state accordingly.", "title": "./spec/abstract/AARCH64/ArchTcb_A.thy", "chapter": "Architecture-specific TCB functions", "section": "", "comment": ""}
{"spec": "chapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewPageCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        return $ map (\\<lambda>n. PageCap (PPtr (fromPPtr n)) VMReadWrite VMNoMap pSize dev Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 0 X64SmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev ptTranslationBits X64LargePage\n        | HugePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev (ptTranslationBits + ptTranslationBits) X64HugePage\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        | PageDirectoryObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdBits (makeObject::pde) PageDirectoryCap\n              (\\<lambda>pts. return ())\n        | PDPointerTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdptBits (makeObject::pdpte) PDPointerTableCap\n              (\\<lambda>pts. return ())\n        | PML4Object \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pml4Bits (makeObject::pml4e) PML4Cap\n              (\\<lambda>pms. mapM_x copyGlobalMappings pms)\n        )\"\n\nend\nend\n\nend", "property": "Create New Memory Objects: Generate new memory objects (pages or tables) and their corresponding capabilities based on the specified type, region base, number of objects, and other parameters. The function initializes the memory objects and updates the kernel state to reflect the new mappings, ensuring that the system can manage and access the newly created memory regions effectively.", "title": "./spec/design/skel/X64/ArchIntermediate_H.thy", "chapter": "Intermediate", "section": "", "comment": ""}
{"spec": "(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/X64.hs\n\nend (* context Arch *)\n\nend", "property": "Arch-Specific Ghost Update Functions: Define and implement architecture-specific ghost update functions for managing physical memory. These functions ensure that the memory management operations are correctly reflected in the system's ghost state, maintaining the integrity and consistency of the memory model.", "title": "./spec/design/skel/X64/ArchPSpace_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv=ArchRetypeDecls_H ONLY pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft\n\nfun\n  lookupPTSlotFromLevel :: \"nat => machine_word => machine_word => (nat * machine_word) kernel\"\nwhere\n  \"lookupPTSlotFromLevel 0 ptPtr vPtr =\n     return (ptBitsLeft 0, ptSlotIndex 0 ptPtr vPtr)\"\n| \"lookupPTSlotFromLevel level ptPtr vPtr = do\n     pte <- pteAtIndex level ptPtr vPtr;\n     if isPageTablePTE pte\n     then do\n       checkPTAt NormalPT_T (getPPtrFromPTE pte);\n       lookupPTSlotFromLevel (level - 1) (getPPtrFromPTE pte) vPtr\n     od\n     else return (ptBitsLeft level, ptSlotIndex level ptPtr vPtr)\n   od\"\n\nfun\n  lookupPTFromLevel :: \"nat => machine_word => machine_word => machine_word =>\n    (lookup_failure, machine_word) kernel_f\"\nwhere\n  \"lookupPTFromLevel level ptPtr vPtr targetPtPtr = doE\n    assertE (ptPtr \\<noteq> targetPtPtr);\n    unlessE (0 < level) $ throw InvalidRoot;\n    slot <- returnOk $ ptSlotIndex level ptPtr vPtr;\n    pte <- withoutFailure $ getObject slot;\n    unlessE (isPageTablePTE pte) $ throw InvalidRoot;\n    ptr <- returnOk (getPPtrFromPTE pte);\n    if ptr = targetPtPtr\n        then returnOk slot\n        else doE\n          liftE $ checkPTAt NormalPT_T ptr;\n          lookupPTFromLevel (level - 1) ptr vPtr targetPtPtr\n        odE\n  odE\"\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv=ArchRetypeDecls_H NOT lookupPTSlotFromLevel lookupPTFromLevel pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft checkPTAt checkValidMappingSize\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert (\\<lambda>s. 2 ^ sz <= gsMaxObjectSize s) []\"\n\nend\n\nend", "property": "VSpace Lookup: Recursively traverses the page table hierarchy to find the appropriate slot for a given virtual address, ensuring that each level is a valid page table and stopping at the target level or when a non-page-table PTE is encountered. Subproperties include:\n- **PT Slot Lookup**: Determines the slot index at a specific level of the page table hierarchy.\n- **PT Hierarchy Traversal**: Recursively checks each level of the page table, validating the PTEs and continuing to the next level until the target is found or a non-page-table PTE is encountered.", "title": "./spec/design/skel/AARCH64/ArchVSpace_H.thy", "chapter": "", "section": "", "comment": ""}
{"spec": "context begin interpretation Arch . global_naming vmpage_size\nrequalify_consts X64SmallPage X64LargePage X64HugePage\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 10\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]", "property": "Create Qualified Aliases: Define and qualify constants for different page sizes and calculate the size and offset for the control thread control block (CTCB). This ensures that the system uses consistent and appropriately sized memory allocations for thread control blocks.", "title": "./spec/cspec/X64/Kernel_C.thy", "chapter": "", "section": "", "comment": " create appropriately qualified aliases "}
{"spec": "consts' configureTimer_impl :: \"unit machine_rest_monad\"\nconsts' configureTimer_val :: \"machine_state \\<Rightarrow> irq\"\ndefinition configureTimer :: \"irq machine_monad\"\n  where\n  \"configureTimer \\<equiv> do\n     machine_op_lift configureTimer_impl;\n     gets configureTimer_val\n   od\"\n\nconsts' initTimer_impl :: \"unit machine_rest_monad\"\ndefinition initTimer :: \"unit machine_monad\"\n  where\n  \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts' resetTimer_impl :: \"unit machine_rest_monad\"\ndefinition resetTimer :: \"unit machine_monad\"\n  where\n  \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"", "property": "Timer Operations: Configure, initialize, and reset the timer. These operations allow for the management of the timer's state and behavior within the machine, ensuring proper timing and scheduling functionality.", "title": "./spec/machine/RISCV64/MachineOps.thy", "chapter": "Machine Operations", "section": "The Operations", "comment": ""}
{"spec": "context begin interpretation Arch . global_naming vmpage_size\n\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 8\"\n\ndefinition\n  ctcb_offset :: \"32 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]", "property": "Create Appropriately Qualified Aliases: Define and requalify constants for architecture-specific page sizes and create definitions for the size and offset of the CTCB (C Thread Control Block) data structure.", "title": "./spec/cspec/ARM_HYP/Kernel_C.thy", "chapter": "", "section": "", "comment": " create appropriately qualified aliases "}
{"spec": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Kernel_Config.maxIRQ\"", "property": "IRQ Range Limitation: The maximum IRQ value is defined as a generic numeral in Kernel_Config and is denoted as maxIRQ.", "title": "./spec/design/skel/ARM_HYP/Hardware_H.thy", "chapter": "", "section": "", "comment": " Kernel_Config provides a generic numeral, Haskell expects type irq "}
