[
  {
    "instruction": "Machine State Management: Provides mechanisms to access and update the underlying memory, device state, and interrupt masks, ensuring that the machine state is correctly maintained and modified.",
    "input": "",
    "output": "theory MachineMonad\nimports MachineTypes\nbegin\n\narch_requalify_types\n  machine_state\n  machine_state_rest\n\narch_requalify_consts\n  underlying_memory\n  underlying_memory_update\n  device_state\n  device_state_update\n  irq_masks\n  machine_state_rest\n  machine_state_rest_update",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Monad Operations: Facilitate operations on the machine state, allowing for the manipulation and transformation of the state in a nondeterministic manner. The `machine_rest_lift` function lifts operations from a restricted machine state to the full machine state, ensuring that changes are applied correctly. The `ignore_failure` function handles failures by ignoring them and continuing execution, providing a way to manage errors gracefully.",
    "input": "",
    "output": "type_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\ntranslations\n  (type) \"'c machine_monad\" <= (type) \"machine_state \\<Rightarrow> ('c \\<times> machine_state) set \\<times> bool\"\n\ntype_synonym 'a machine_rest_monad = \"(machine_state_rest, 'a) nondet_monad\"\n\ndefinition\n  machine_rest_lift :: \"'a machine_rest_monad \\<Rightarrow> 'a machine_monad\"\nwhere\n  \"machine_rest_lift f \\<equiv> do\n    mr \\<leftarrow> gets machine_state_rest;\n    (r, mr') \\<leftarrow> select_f (f mr);\n    modify (\\<lambda>s. s \\<lparr> machine_state_rest := mr' \\<rparr>);\n    return r\n  od\"\n\n\ndefinition\n  ignore_failure :: \"('s,unit) nondet_monad \\<Rightarrow> ('s,unit) nondet_monad\"\n  where\n  \"ignore_failure f \\<equiv>\n  \\<lambda>s. if fst (f s) = {} then ({((),s)},False) else (fst (f s), False)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Wrapper Consistency: The wrapper function `ignore_failure` behaves identically to the original function `f` when `f` is guaranteed not to fail and not to return a failure.",
    "input": "",
    "output": "lemma failure_consistent:\n  \"\\<lbrakk> empty_fail f; no_fail \\<top> f \\<rbrakk> \\<Longrightarrow> ignore_failure f = f\"\n  apply (simp add: ignore_failure_def empty_fail_def no_fail_def)\n  apply (rule ext)\n  apply (auto intro: prod_eqI)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Failure Handling and Machine Operations: Ensures that operations wrapped with `ignore_failure` and `machine_rest_lift` do not fail, maintaining the integrity and reliability of the system.",
    "input": "",
    "output": "lemma ef_ignore_failure [simp]:\n  \"empty_fail (ignore_failure f)\"\n  by (simp add: empty_fail_def ignore_failure_def)\n\nlemma no_fail_ignore_failure [simp, intro!]:\n  \"no_fail \\<top> (ignore_failure f)\"\n  by (simp add: no_fail_def ignore_failure_def)\n\n\nlemma ef_machine_rest_lift [simp, intro!]:\n  \"empty_fail f \\<Longrightarrow> empty_fail (machine_rest_lift f)\"\n  apply (clarsimp simp: empty_fail_def machine_rest_lift_def simpler_gets_def\n                        select_f_def bind_def simpler_modify_def return_def)\n  apply force\n  done\n\nlemma no_fail_machine_state_rest [intro!]:\n  \"no_fail P f \\<Longrightarrow> no_fail (P o machine_state_rest) (machine_rest_lift f)\"\n  apply (simp add: no_fail_def machine_rest_lift_def simpler_gets_def\n                        select_f_def bind_def simpler_modify_def return_def)\n  apply force\n  done\n\nlemma no_fail_machine_state_rest_T [simp, intro!]:\n  \"no_fail \\<top> f \\<Longrightarrow> no_fail \\<top> (machine_rest_lift f)\"\n  apply (drule no_fail_machine_state_rest)\n  apply (simp add: o_def)\n  done\n\ndefinition\n  \"machine_op_lift \\<equiv> machine_rest_lift o ignore_failure\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constraints: Ensures that the definitions in Kernel_Config adhere to specific architectural constraints, providing a consistent and reliable foundation for the kernel's behavior across different architectures.",
    "input": "",
    "output": "(* Architecture-independent lemmas constraining Kernel_Config definitions *)\n\ntheory Kernel_Config_Lemmas\nimports \"$L4V_ARCH/Kernel_Config\"\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Configuration Constants Properties: The number of domains is greater than zero and its conversion to a machine word is safe, preserving the original value.",
    "input": "",
    "output": "lemma numDomains_not_zero:\n  \"numDomains > 0\"\n  unfolding Kernel_Config.numDomains_def\n  by simp\n\nlemma numDomains_machine_word_safe:\n  \"unat (of_nat numDomains :: machine_word) = numDomains\"\n  unfolding Kernel_Config.numDomains_def by simp\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Machine Word Consistency: Ensure that the `machine_word` and `machine_word_len word` types are consistent, allowing for seamless type conversion and usage in various architectural operations.",
    "input": "",
    "output": "term \"id :: machine_word \\<Rightarrow> machine_word_len word\"\n\narch_requalify_types\n  vmfault_type\n  hyp_fault_type\n  irq\n  user_monad\n  user_context\n\narch_requalify_consts\n  getActiveIRQ\n  maskInterrupt\n  freeMemory\n  loadWord\n  storeWord\n  storeWordVM\n  setNextPC\n  getRestartPC\n  setRegister\n  getRegister\n  initContext\n  exceptionMessage\n  syscallMessage\n  gpRegisters\n  frameRegisters\n  ackInterrupt\n  resetTimer\n  minIRQ\n  clearMemory\n  non_kernel_IRQs\n  tlsBaseRegister\n  debugPrint\n  configureTimer\n  initL2Cache\n  ptrFromPAddr\n  pageBits",
    "system": "",
    "history": []
  },
  {
    "instruction": "Bitwise and Size Properties: Define relationships between bitwise operations, size constants, and their numerical representations. Specifically, the properties relate the size of a word, the number of bits in a word, and the result of dividing a masked value by the word size.",
    "input": "",
    "output": "lemma Suc_unat_mask_div_obfuscated:\n  \"Suc (unat (mask sz div (word_size::machine_word))) = 2 ^ (min sz word_bits - word_size_bits)\"\n  by (rule Suc_unat_mask_div)\n\nlemma word_size_size_bits_nat:\n  \"2^word_size_bits = (word_size :: nat)\"\n  by (simp add: word_size_bits_def word_size_def)\n\nlemma word_size_size_bits_word:\n  \"2^word_size_bits = (word_size :: 'a :: len word)\"\n  by (simp add: word_size_bits_def word_size_def)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Namespace Management: Defines a locale for architecture-specific definitions, allowing for organized and namespaced management of architectural components. This ensures that architecture-specific entities are clearly delineated and can be selectively qualified or unqualified for use in generic proofs.",
    "input": "",
    "output": "locale Arch\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Perform operations on the underspecified part of the machine state, ensuring that they do not fail and always return a non-empty set of follow-on states. These operations explicitly ignore the failure flag, setting it to False, and treat any case that would result in an empty set of follow-on states as a null operation.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine operations below work on the underspecified\n  part of the machine state @{typ machine_state_rest} and cannot fail.\n  We could express the latter by type (leaving out the failure flag),\n  but if we later wanted to implement them,\n  we'd have to set up a new hoare-logic\n  framework for that type. So instead, we provide a wrapper for these\n  operations that explicitly ignores the fail flag and sets it to\n  False. Similarly, these operations never return an empty set of\n  follow-on states, which would require the operation to fail.\n  So we explicitly make this (non-existing) case a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\n\\<close>\n\ncontext Arch begin global_naming ARM",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Define a set of machine-level operations, including initializing and resetting the timer, writing to the Translation Table Base Register 0 (TTBR0), and setting the hardware Address Space Identifier (ASID). These operations are lifted from lower-level implementations to the machine monad, ensuring they can be executed within the context of the machine state.",
    "input": "",
    "output": "consts'\n  memory_regions :: \"(paddr \\<times> paddr) list\" \n  initTimer_impl :: \"unit machine_rest_monad\"\ndefinition\n  initTimer :: \"unit machine_monad\"\nwhere \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts'\n  resetTimer_impl :: \"unit machine_rest_monad\"\n\ndefinition\n  resetTimer :: \"unit machine_monad\"\nwhere \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"\n\nconsts'\n  writeTTBR0_impl :: \"paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeTTBR0 :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere \"writeTTBR0 pd \\<equiv> machine_op_lift (writeTTBR0_impl pd)\"\n\n\nconsts'\n  setHardwareASID_impl :: \"hardware_asid \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setHardwareASID:: \"hardware_asid \\<Rightarrow> unit machine_monad\"\nwhere \"setHardwareASID a \\<equiv> machine_op_lift (setHardwareASID_impl a)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Barrier Operations: Provide mechanisms to enforce memory ordering and synchronization, including instruction synchronization barriers (ISB), data synchronization barriers (DSB), and data memory barriers (DMB). Additionally, operations are available to invalidate the local Translation Lookaside Buffer (TLB) either for all ASIDs or for a specific ASID, ensuring that memory accesses are coherent and consistent.",
    "input": "",
    "output": "consts'\n  isb_impl :: \"unit machine_rest_monad\"\ndefinition\n  isb :: \"unit machine_monad\"\nwhere \"isb \\<equiv> machine_op_lift isb_impl\"\n\nconsts'\n  dsb_impl :: \"unit machine_rest_monad\"\ndefinition\n  dsb :: \"unit machine_monad\"\nwhere \"dsb \\<equiv> machine_op_lift dsb_impl\"\n\nconsts'\n  dmb_impl :: \"unit machine_rest_monad\"\ndefinition\n  dmb :: \"unit machine_monad\"\nwhere \"dmb \\<equiv> machine_op_lift dmb_impl\"\n\nconsts'\n  invalidateLocalTLB_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB :: \"unit machine_monad\"\nwhere \"invalidateLocalTLB \\<equiv> machine_op_lift invalidateLocalTLB_impl\"\n\n\nconsts'\n  invalidateLocalTLB_ASID_impl :: \"hardware_asid \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB_ASID :: \"hardware_asid \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateLocalTLB_ASID a \\<equiv> machine_op_lift (invalidateLocalTLB_ASID_impl a)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Provide a set of functions to perform various machine-level operations, including cache management, TLB invalidation, branch flushing, interrupt acknowledgment, and debug register access. These operations are lifted from their C implementations to the machine monad, ensuring that they can be safely and effectively used within the kernel's context.",
    "input": "",
    "output": "consts'\n  invalidateLocalTLB_VAASID_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB_VAASID :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateLocalTLB_VAASID w \\<equiv> machine_op_lift (invalidateLocalTLB_VAASID_impl w)\"\n\nconsts'\n  cleanByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanByVA w p \\<equiv> machine_op_lift (cleanByVA_impl w p)\"\n\nconsts'\n  cleanByVA_PoU_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanByVA_PoU :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanByVA_PoU w p \\<equiv> machine_op_lift (cleanByVA_PoU_impl w p)\"\n\nconsts'\n  invalidateByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateByVA w p \\<equiv> machine_op_lift (invalidateByVA_impl w p)\"\n\nconsts'\n  invalidateByVA_I_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateByVA_I :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateByVA_I w p \\<equiv> machine_op_lift (invalidateByVA_I_impl w p)\"\n\nconsts'\n  invalidate_I_PoU_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidate_I_PoU :: \"unit machine_monad\"\nwhere \"invalidate_I_PoU \\<equiv> machine_op_lift invalidate_I_PoU_impl\"\n\nconsts'\n  cleanInvalByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanInvalByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanInvalByVA w p \\<equiv> machine_op_lift (cleanInvalByVA_impl w p)\"\n\nconsts'\n  branchFlush_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  branchFlush :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"branchFlush w p \\<equiv> machine_op_lift (branchFlush_impl w p)\"\n\nconsts'\n  clean_D_PoU_impl :: \"unit machine_rest_monad\"\ndefinition\n  clean_D_PoU :: \"unit machine_monad\"\nwhere \"clean_D_PoU \\<equiv> machine_op_lift clean_D_PoU_impl\"\n\nconsts'\n  cleanInvalidate_D_PoC_impl :: \"unit machine_rest_monad\"\ndefinition\n  cleanInvalidate_D_PoC :: \"unit machine_monad\"\nwhere \"cleanInvalidate_D_PoC \\<equiv> machine_op_lift cleanInvalidate_D_PoC_impl\"\n\nconsts'\n  cleanInvalidateL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanInvalidateL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanInvalidateL2Range w p \\<equiv> machine_op_lift (cleanInvalidateL2Range_impl w p)\"\n\nconsts'\n  invalidateL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateL2Range w p \\<equiv> machine_op_lift (invalidateL2Range_impl w p)\"\n\nconsts'\n  cleanL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanL2Range w p \\<equiv> machine_op_lift (cleanL2Range_impl w p)\"\n\nconsts'\n  initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition\n  initL2Cache :: \"unit machine_monad\"\nwhere \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\ndefinition\n  clearExMonitor :: \"unit machine_monad\"\nwhere \"clearExMonitor \\<equiv> modify (\\<lambda>s. s \\<lparr> exclusive_state := default_exclusive_state \\<rparr>)\"\n\nconsts'\n  flushBTAC_impl :: \"unit machine_rest_monad\"\ndefinition\n  flushBTAC :: \"unit machine_monad\"\nwhere \"flushBTAC \\<equiv> machine_op_lift flushBTAC_impl\"\n\nconsts'\n  initIRQController_impl :: \"unit machine_rest_monad\"\ndefinition\n  initIRQController :: \"unit machine_monad\"\nwhere \"initIRQController \\<equiv> machine_op_lift initIRQController_impl\"\n\ndefinition\n  IRQ :: \"irq \\<Rightarrow> irq\"\nwhere \"IRQ \\<equiv> id\"\n\nconsts'\n  writeContextID_impl :: \"unit machine_rest_monad\"\ndefinition\n  writeContextID :: \"unit machine_monad\"\nwhere \"writeContextID \\<equiv> machine_op_lift writeContextID_impl\"\n\nlemmas cache_machine_op_defs = isb_def dsb_def dmb_def writeContextID_def flushBTAC_def\n                               clearExMonitor_def cleanL2Range_def invalidateL2Range_def\n                               cleanInvalidateL2Range_def cleanInvalidate_D_PoC_def\n                               clean_D_PoU_def branchFlush_def cleanInvalByVA_def\n                               invalidate_I_PoU_def invalidateByVA_I_def invalidateByVA_def\n                               cleanByVA_PoU_def cleanByVA_def invalidateLocalTLB_VAASID_def\n                               invalidateLocalTLB_ASID_def invalidateLocalTLB_def\nconsts'\n  IFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  DFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  FAR_val :: \"machine_state \\<Rightarrow> machine_word\"\n\ndefinition\n  getIFSR :: \"machine_word machine_monad\"\n  where \"getIFSR \\<equiv> gets IFSR_val\"\n\ndefinition\n  getDFSR :: \"machine_word machine_monad\"\n  where \"getDFSR \\<equiv> gets DFSR_val\"\n\ndefinition\n  getFAR :: \"machine_word machine_monad\"\n  where \"getFAR \\<equiv> gets FAR_val\"\n\ndefinition\n  debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\"\nwhere\n  debugPrint_def[simp]:\n \"debugPrint \\<equiv> \\<lambda>message. return ()\"\n\nconsts'\n  ackInterrupt_impl :: \"irq \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ackInterrupt irq \\<equiv> machine_op_lift (ackInterrupt_impl irq)\"\n\n\n\\<comment> \\<open>Interrupt controller operations\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Kernel Interrupts: Defines a set of interrupts that cannot occur while the kernel is running but can occur from user mode. In this case, the set is empty, indicating no such interrupts exist on the specified architecture.",
    "input": "",
    "output": "definition\n  \"non_kernel_IRQs = {}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Active IRQ Retrieval: Retrieves the active interrupt request (IRQ) after updating the IRQ state, considering whether the IRQ is masked or if it is a non-kernel IRQ when in kernel mode. If the IRQ is masked or is a non-kernel IRQ in kernel mode, it returns `None`; otherwise, it returns the active IRQ.",
    "input": "",
    "output": "definition\n  getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\nwhere\n  \"getActiveIRQ in_kernel \\<equiv> do\n    is_masked \\<leftarrow> gets $ irq_masks;\n    modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n    active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n    if is_masked active_irq \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n    then return None\n    else return (Some active_irq)\n  od\"\n\ndefinition\n  maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"maskInterrupt m irq \\<equiv>\n  modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition\n  lineStart :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"lineStart addr = (addr >> cacheLineBits) << cacheLineBits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache Operations: Perform specific cache operations (such as clean, invalidate, and branch flush) on every cache line that intersects the supplied virtual and physical address range. These operations ensure data consistency and coherence across different levels of the cache hierarchy.",
    "input": "",
    "output": "definition\n  cacheRangeOp :: \"(machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad)\n                 \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cacheRangeOp operation vstart vend pstart \\<equiv>\n    let pend = pstart + (vend - vstart);\n        vptrs = [lineStart vstart, lineStart vstart + of_nat cacheLine .e. lineStart vend];\n        pptrs = [lineStart pstart, lineStart pstart + of_nat cacheLine .e. lineStart pend]\n    in mapM_x (\\<lambda>(v, p). operation v p) (zip vptrs pptrs)\"\n\ndefinition\n  cleanCacheRange_PoC :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoC vstart vend pstart \\<equiv> cacheRangeOp cleanByVA vstart vend pstart\"\n\ndefinition\n  cleanInvalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanInvalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanInvalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp cleanInvalByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  cleanCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanL2Range pstart (pstart + (vend - vstart))\n  od\"\n\ndefinition\n  cleanCacheRange_PoU :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoU vstart vend pstart \\<equiv> cacheRangeOp cleanByVA_PoU vstart vend pstart\"\n\ndefinition\n  invalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    when (vstart \\<noteq> lineStart vstart) $\n        cleanCacheRange_RAM vstart vstart pstart;\n    when (vend + 1 \\<noteq> lineStart (vend + 1)) $\n        cleanCacheRange_RAM (lineStart vend) (lineStart vend)\n           (pstart + ((lineStart vend) - vstart));\n    invalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp invalidateByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  invalidateCacheRange_I :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_I vstart vend pstart \\<equiv> cacheRangeOp invalidateByVA_I vstart vend pstart\"\n\ndefinition\n  branchFlushRange :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"branchFlushRange vstart vend pstart \\<equiv> cacheRangeOp branchFlush vstart vend pstart\"\n\ndefinition\n  cleanCaches_PoU :: \"unit machine_monad\"\nwhere\n  \"cleanCaches_PoU \\<equiv> do\n    dsb;\n    clean_D_PoU;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\"\n\ndefinition\n  cleanInvalidateL1Caches :: \"unit machine_monad\"\nwhere\n  \"cleanInvalidateL1Caches \\<equiv> do\n    dsb;\n    cleanInvalidate_D_PoC;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Clearance: Clear the contents of a specified memory region by setting each word to zero, preparing it for reuse as user memory. The operation does not flush the cache.",
    "input": "",
    "output": "text \\<open>Clear memory contents to recycle it as user memory. Do not yet flush the cache.\\<close>\ndefinition\n  clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"clearMemory ptr bytelength \\<equiv>\n    mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"\n\ndefinition\n  clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Initialization: Initialize memory to be used as user memory, ensuring it is cleared and ready for use. This process includes a call to clean the cache range, which is essential for maintaining memory integrity and performance.",
    "input": "",
    "output": "abbreviation (input) \"initMemory == clearMemory\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Clearance: Zero out the memory region starting from the specified pointer and spanning the given number of bits to ensure that the freed memory contains no garbage, allowing for predictable and consistent memory state.",
    "input": "",
    "output": "definition\n  freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"freeMemory ptr bits \\<equiv>\n  mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "User Monad Operations: Provides functions to get and set machine word values for specific registers within a user context, including getting the restart program counter and setting the next program counter. These operations enable manipulation of the user context's register state in a non-deterministic monad.",
    "input": "",
    "output": "type_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ndatatype user_context = UserContext (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\ndefinition getRegister :: \"register \\<Rightarrow> machine_word user_monad\" where\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition modify_registers :: \"(user_regs \\<Rightarrow> user_regs) \\<Rightarrow> user_context \\<Rightarrow> user_context\" where\n  \"modify_registers f uc \\<equiv> UserContext (f (user_regs uc))\"\n\ndefinition setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\" where\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext ((user_regs s) (r := v)))\"\n\ndefinition\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition\n  \"setNextPC \\<equiv> setRegister NextIP\"\n\nend\n\ntranslations\n  (type) \"'a ARM.user_monad\" <= (type) \"(ARM.register \\<Rightarrow> machine_word, 'a) nondet_monad\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Integer Representation: Defines the representation of integer literals and words, specifying that integer literals are 32-bit signed integers and integer words are 32-bit signed words.",
    "input": "",
    "output": "(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define and specify the bit lengths and sizes for IRQs, physical addresses, page colors, and cache lines, ensuring consistent and correct representation of these values in the system.",
    "input": "",
    "output": "context Arch begin global_naming ARM\n\nvalue_type irq_len = Kernel_Config.irqBits (* IRQ_CNODE_SLOT_BITS *)\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = word32\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\ndefinition pageColourBits :: nat where\n  \"pageColourBits \\<equiv> 2\"\n\ndefinition cacheLineBits :: nat where\n  \"cacheLineBits = CONFIG_L1_CACHE_LINE_SIZE_BITS\"\n\ndefinition cacheLine :: nat where\n  \"cacheLine = 2^cacheLineBits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define the base addresses and offsets for the kernel's physical memory window, including the first virtual address, physical address base, and offsets for the kernel ELF. These constants facilitate the conversion between physical and virtual addresses, ensuring correct memory mapping and access within the system.",
    "input": "",
    "output": "definition pptrBase :: word32 where\n  \"pptrBase \\<equiv> 0xe0000000\"\n\nabbreviation (input) \"paddrBase \\<equiv> physBase\"\n\ndefinition pptrBaseOffset :: word32 where\n  \"pptrBaseOffset \\<equiv> pptrBase - paddrBase\"\n\ndefinition kernelELFPAddrBase :: word32 where\n  \"kernelELFPAddrBase \\<equiv> physBase\"\n\ndefinition kernelELFBase :: word32 where\n  \"kernelELFBase \\<equiv> pptrBase + (kernelELFPAddrBase && mask 22)\"\n\ndefinition kernelELFBaseOffset :: word32 where\n  \"kernelELFBaseOffset \\<equiv> kernelELFBase - kernelELFPAddrBase\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> word32\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"word32 \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"word32 \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr kpptr \\<equiv> kpptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constraints: Ensure that the kernel configuration definitions adhere to architectural-specific constraints, maintaining consistency and compatibility with the ARM platform.",
    "input": "",
    "output": "(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming ARM",
    "system": "",
    "history": []
  },
  {
    "instruction": "Physical Base Alignment: The physical base address is aligned to a 24-bit boundary, ensuring proper memory alignment for the system.",
    "input": "",
    "output": "lemma physBase_aligned:\n  \"is_aligned physBase 24\"\n  by (simp add: is_aligned_def Kernel_Config.physBase_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value: The maximum interrupt request (IRQ) value is less than 2 raised to the power of the number of bits allocated for IRQs.",
    "input": "",
    "output": "lemma maxIRQ_less_2p_irqBits:\n  \"(maxIRQ::nat) < 2^irqBits\"\n  by (simp add: Kernel_Config.maxIRQ_def Kernel_Config.irqBits_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Length and Maximum IRQ Value: The length of the `irq_len` is defined to be equal to `irqBits`, and the maximum IRQ value is less than \\(2^{irqBits}\\).",
    "input": "",
    "output": "lemma LENGTH_irq_len_irqBits[simp]: (* [simp] will fire only for simp del: len_of_numeral_defs *)\n  \"LENGTH(irq_len) = irqBits\"\n  using irq_len_def irq_len_val\n  by simp\n\nlemma maxIRQ_less_2p_irq_len:\n  \"(maxIRQ::nat) < 2^LENGTH(irq_len)\"\n  using maxIRQ_less_2p_irqBits\n  by (simp del: len_of_numeral_defs)",
    "system": "",
    "history": []
  },
  {
    "instruction": "MaxIRQ Conversion: The maximum interrupt request number can be converted to a word of any length without loss of information, ensuring consistency in numeric representations.",
    "input": "",
    "output": "lemma of_nat_maxIRQ[simp]:\n  \"of_nat maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma of_int_maxIRQ[simp]:\n  \"of_int maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unat Conversion for maxIRQ: Ensures that the unat conversion of maxIRQ is equal to maxIRQ itself, provided that the length of irq_len is less than or equal to the bit length of the word type. This property guarantees safe simplification and usage of maxIRQ in various contexts without loss of information.",
    "input": "",
    "output": "lemma unat_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> unat (maxIRQ::'a word) = maxIRQ\"\n  by (metis maxIRQ_less_2p_irq_len Word.of_nat_unat of_nat_inverse of_nat_maxIRQ unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Safe Conversion of maxIRQ: Ensures that the conversion of the maximum interrupt request (maxIRQ) to an unsigned integer is safe and retains its value, provided that the length of the interrupt request is less than or equal to the bit width of the target type.",
    "input": "",
    "output": "lemma uint_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> uint (maxIRQ::'a word) = maxIRQ\"\n  by (metis Kernel_Config.maxIRQ_def of_nat_numeral uint_nat unat_maxIRQ)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Conversion Safety: The conversion of `maxIRQ` between different bit lengths is safe and preserves the value, provided that the target bit length is at least as large as the source bit length.",
    "input": "",
    "output": "lemma ucast_maxIRQ[simp]:\n  \"\\<lbrakk> LENGTH(irq_len) \\<le> LENGTH('a::len); LENGTH(irq_len) \\<le> LENGTH('b::len) \\<rbrakk> \\<Longrightarrow>\n   UCAST ('a \\<rightarrow> 'b) maxIRQ = maxIRQ\"\n  by (metis of_nat_maxIRQ ucast_nat_def unat_maxIRQ)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Comparison: Ensures that the comparison of a maximum IRQ value with an upcast IRQ value remains consistent, provided the length of the upcast type is at least as large as the original IRQ type. This guarantees safe and predictable behavior when comparing IRQ values across different word sizes.",
    "input": "",
    "output": "lemma maxIRQ_less_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   (maxIRQ < (ucast irq :: 'a word)) = (maxIRQ < irq)\" for irq::irq\n  by (simp add: word_less_nat_alt unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Upcast Safety: Ensures that upcasting an IRQ to a larger word size does not affect the comparison with the maximum IRQ value, maintaining the safety and correctness of IRQ handling.",
    "input": "",
    "output": "lemma maxIRQ_le_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   ((ucast irq :: 'a word) \\<le> Kernel_Config.maxIRQ) = (irq \\<le> Kernel_Config.maxIRQ)\" for irq::irq\n  by (simp add: word_le_nat_alt unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "MaxIRQ Properties: Define and constrain the maximum interrupt request (IRQ) value, ensuring that it is within the bounds of the system's IRQ length and that conversions between different word types (machine_word, irq, int_word) maintain the integrity of the maxIRQ value. This ensures consistent and predictable behavior in IRQ handling across the system.",
    "input": "",
    "output": "lemma le_maxIRQ_machine_less_irqBits_val[simplified]:\n  \"w \\<le> maxIRQ \\<Longrightarrow> unat w < 2^LENGTH(irq_len)\" for w::machine_word\n  using maxIRQ_less_2p_irq_len\n  by (simp add: word_le_nat_alt)\n\nlemma irq_machine_le_maxIRQ_irq:\n  \"irq \\<le> Kernel_Config.maxIRQ \\<Longrightarrow> (ucast irq::irq) \\<le> maxIRQ\" for irq::machine_word\n  by (simp add: Kernel_Config.maxIRQ_def word_le_nat_alt unat_ucast)\n\nlemma maxIRQ_eq_ucast_irq_32_signed_uint:\n  \"(maxIRQ = (ucast b :: int_word)) = (uint b = maxIRQ)\" for b::irq\n  unfolding Kernel_Config.maxIRQ_def\n  apply uint_arith\n  apply (simp add: uint_up_ucast is_up)\n  done\n\nlemma sint_maxIRQ_32[simp]:\n  \"sint (maxIRQ :: int_word) = maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_machine[simp]:\n  \"scast (maxIRQ :: int_word) = (maxIRQ::machine_word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_irq[simp]:\n  \"scast (maxIRQ :: int_word) = (maxIRQ::irq)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_machine:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = x\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_irq:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = (ucast x :: irq)\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_1_plus_eq_Suc_machine[simp]:\n  \"unat (1 + maxIRQ :: machine_word) = Suc Kernel_Config.maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache Line Bits Sanity: The value of `cacheLineBits` must be within the range of 2 to 10, ensuring it is suitable for use in cache operations and does not conflict with other values.",
    "input": "",
    "output": "lemma cacheLineBits_sanity:\n  \"cacheLineBits \\<in> {2..10}\"\n  by (simp add: cacheLineBits_def Kernel_Config.CONFIG_L1_CACHE_LINE_SIZE_BITS_def)\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Perform operations on the underspecified part of the machine state, ensuring that they do not fail and always return a non-empty set of follow-on states. These operations are wrapped to explicitly set the failure flag to False and handle the non-existing case as a null operation.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine operations below work on the underspecified\n  part of the machine state @{typ machine_state_rest} and cannot fail.\n  We could express the latter by type (leaving out the failure flag),\n  but if we later wanted to implement them,\n  we'd have to set up a new hoare-logic\n  framework for that type. So instead, we provide a wrapper for these\n  operations that explicitly ignores the fail flag and sets it to\n  False. Similarly, these operations never return an empty set of\n  follow-on states, which would require the operation to fail.\n  So we explicitly make this (non-existing) case a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\n\\<close>\n\ncontext Arch begin global_naming X64",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Define and lift machine-level operations such as initializing and resetting the timer, invalidating the TLB, and printing debug messages. These operations ensure that low-level hardware interactions are abstracted and managed within the machine monad, providing a clear interface for system-level tasks.",
    "input": "",
    "output": "consts'\n  memory_regions :: \"(paddr \\<times> paddr) list\" \n  initTimer_impl :: \"unit machine_rest_monad\"\ndefinition\n  initTimer :: \"unit machine_monad\"\nwhere \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts'\n  resetTimer_impl :: \"unit machine_rest_monad\"\n\ndefinition\n  resetTimer :: \"unit machine_monad\"\nwhere \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"\n\nconsts'\n  invalidateTLB_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidateTLB :: \"unit machine_monad\"\nwhere \"invalidateTLB \\<equiv> machine_op_lift invalidateTLB_impl\"\n\nlemmas cache_machine_op_defs = invalidateTLB_def\n\ndefinition\n  debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\"\nwhere\n  debugPrint_def[simp]:\n \"debugPrint \\<equiv> \\<lambda>message. return ()\"\n\n\n\\<comment> \\<open>Interrupt controller operations\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Kernel Interrupts: Defines a set of interrupts that cannot occur while the kernel is running but can occur from user mode. The set is empty for plain x86-64 architectures.",
    "input": "",
    "output": "definition\n  \"non_kernel_IRQs = {}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Active IRQ Determination: Retrieves the active interrupt request (IRQ) by updating the IRQ state to reflect the passage of time, and then checks if the IRQ is masked, invalid, or not allowed in the current kernel state. If any of these conditions are met, it returns `None`; otherwise, it returns the active IRQ. \n\nInterrupt Masking: Modifies the IRQ mask for a specific interrupt, allowing or disallowing its processing based on the provided boolean value.",
    "input": "",
    "output": "definition\n  getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\nwhere\n  \"getActiveIRQ in_kernel \\<equiv> do\n    is_masked \\<leftarrow> gets $ irq_masks;\n    modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n    active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n    if is_masked active_irq \\<or> active_irq = 0xFF \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n    then return None\n    else return ((Some active_irq) :: irq option)\n  od\"\n\ndefinition\n  maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"maskInterrupt m irq \\<equiv>\n  modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Acknowledge Interrupt: The operation acknowledges an interrupt but performs no actual action on the imx31 platform.",
    "input": "",
    "output": "definition\n  ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ackInterrupt \\<equiv> \\<lambda>irq. return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Interrupt Mode: The operation does not perform any action on the imx31 platform, effectively ignoring the specified interrupt mode settings.",
    "input": "",
    "output": "definition\n  setInterruptMode :: \"irq \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setInterruptMode \\<equiv> \\<lambda>irq levelTrigger polarityLow. return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Memory: Clear the contents of a specified memory region by setting each word to zero, preparing it for reuse as user memory.",
    "input": "",
    "output": "text \\<open>Clear memory contents to recycle it as user memory\\<close>\ndefinition\n  clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"clearMemory ptr bytelength \\<equiv> mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"\n\ndefinition\n  clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Initialization: Clear the memory to be used as user memory, ensuring it is properly initialized and ready for use. This process includes a call to cleanCacheRange, which is essential for maintaining memory integrity and performance.",
    "input": "",
    "output": "abbreviation (input) \"initMemory == clearMemory\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Clearance: Zero out the underlying memory region specified by the pointer and size to ensure that no garbage data remains, allowing for a clean state in the specifications.",
    "input": "",
    "output": "definition\n  freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"freeMemory ptr bits \\<equiv>\n  mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "User Monad Operations: Provide a set of operations for managing user context, including getting and setting register values, managing FPU state, and performing I/O operations. These operations enable the manipulation of user-level state and interaction with hardware, ensuring that the system can effectively handle user-level processes and their associated data.",
    "input": "",
    "output": "text \\<open> There are 576 bytes of FPU state. Since there are no operations on this state apart from bulk\nsave/restore, we abstract from names and just say how many bytes there are. \\<close>\ntype_synonym fpu_bytes = 576\ntype_synonym fpu_state = \"fpu_bytes \\<Rightarrow> 8 word\"\n\ntype_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ndatatype user_context = UserContext (fpu_state : fpu_state) (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\ndefinition\n  getRegister :: \"register \\<Rightarrow> machine_word user_monad\"\nwhere\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition\n  \"modify_registers f uc \\<equiv> UserContext (fpu_state uc) (f (user_regs uc))\"\n\ndefinition\n  setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\"\nwhere\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext (fpu_state s) ((user_regs s) (r := v)))\"\n\ndefinition\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition\n  \"setNextPC \\<equiv> setRegister NextIP\"\n\n\ndefinition\n  getFPUState :: \"fpu_state user_monad\"\nwhere\n  \"getFPUState \\<equiv> gets fpu_state\"\n\ndefinition\n  setFPUState :: \"fpu_state \\<Rightarrow> unit user_monad\"\nwhere\n  \"setFPUState fc \\<equiv> modify (\\<lambda>s. UserContext fc (user_regs s))\"\n\n\n\ndefinition\n  hwASIDInvalidate :: \"word64 \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"hwASIDInvalidate \\<equiv> invalidateASID\"\n\nconsts'\n  getFaultAddress_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\ngetFaultAddress :: \"word64 machine_monad\"\nwhere\n\"getFaultAddress \\<equiv> gets getFaultAddress_val\"\n\nconsts'\n  irqIntOffset_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\nirqIntOffset :: \"machine_word\"\nwhere\n\"irqIntOffset \\<equiv> 0x20\"\n\ndefinition\nmaxPCIBus :: \"machine_word\"\nwhere\n\"maxPCIBus \\<equiv> 0xFF\"\n\ndefinition\nmaxPCIDev :: \"machine_word\"\nwhere\n\"maxPCIDev \\<equiv> 31\"\n\ndefinition\nmaxPCIFunc :: \"machine_word\"\nwhere\n\"maxPCIFunc \\<equiv> 7\"\n\ndefinition\nioapicIRQLines :: \"machine_word\"\nwhere\n\"ioapicIRQLines \\<equiv> 24\"\n\nconsts'\n  ioapicMapPinToVector_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow>\n    machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  ioapicMapPinToVector :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow>\n    machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ioapicMapPinToVector ioapic pin level polarity vector \\<equiv>\n    machine_op_lift (ioapicMapPinToVector_impl ioapic pin level polarity vector)\"\n\ndefinition IRQ :: \"word8 \\<Rightarrow> irq\"\nwhere\n  \"IRQ \\<equiv> id\"\n\nconsts'\n  in8_impl :: \"word16 \\<Rightarrow> unit machine_rest_monad\"\n  in8_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  in8 :: \"word16 \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"in8 port \\<equiv> do machine_op_lift $ in8_impl port; gets in8_val od\"\n\nconsts'\n  in16_impl :: \"word16 \\<Rightarrow> unit machine_rest_monad\"\n  in16_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  in16 :: \"word16 \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"in16 port \\<equiv> do machine_op_lift $ in16_impl port; gets in16_val od\"\n\nconsts'\n  in32_impl :: \"word16 \\<Rightarrow> unit machine_rest_monad\"\n  in32_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  in32 :: \"word16 \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"in32 port \\<equiv> do machine_op_lift $ in32_impl port; gets in32_val od\"\n\nconsts'\n  out8_impl :: \"word16 \\<Rightarrow> word8 \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  out8 :: \"word16 \\<Rightarrow> word8 \\<Rightarrow> unit machine_monad\"\nwhere\n  \"out8 port dat \\<equiv> machine_op_lift $ out8_impl port dat\"\n\nconsts'\n  out16_impl :: \"word16 \\<Rightarrow> word16 \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  out16 :: \"word16 \\<Rightarrow> word16 \\<Rightarrow> unit machine_monad\"\nwhere\n  \"out16 port dat \\<equiv> machine_op_lift $ out16_impl port dat\"\n\nconsts'\n  out32_impl :: \"word16 \\<Rightarrow> word32 \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  out32 :: \"word16 \\<Rightarrow> word32 \\<Rightarrow> unit machine_monad\"\nwhere\n  \"out32 port dat \\<equiv> machine_op_lift $ out32_impl port dat\"\n\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Integer Literal Representation: Defines the representation of C integer literals and integer words, using a 32-bit signed format.",
    "input": "",
    "output": "(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define and establish a set of constants and type synonyms for the platform, including physical address ranges, interrupt request (IRQ) limits, and control register (CR3) manipulation functions. These constants and functions ensure consistent and accurate handling of platform-specific details, facilitating proper memory and interrupt management.",
    "input": "",
    "output": "context Arch begin global_naming X64\n\ntype_synonym irq_len = 8\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = word64\n\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\ndefinition\n  pptrBase :: word64 where\n  \"pptrBase = 0xffffff8000000000\"\n\ndefinition\n  kernelELFBaseOffset :: word64 where\n  \"kernelELFBaseOffset = 0xffffffff80000000\"\n\ndefinition\n  pptrUserTop :: word64 where\n  \"pptrUserTop = 0x00007fffffffffff\"\n\ndefinition\n  ptrFromPAddr :: \"paddr \\<Rightarrow> word64\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBase\"\n\ndefinition\n  addrFromPPtr :: \"word64 \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBase\"\n\ndefinition\n  addrFromKPPtr :: \"word64 \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr pptr \\<equiv> pptr - kernelELFBaseOffset\"\n\ndefinition\n  pageColourBits :: \"nat\" where\n  \"pageColourBits \\<equiv> undefined\"\n\ndefinition\n  minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition\n  maxIRQ :: \"irq\" where\n  \"maxIRQ \\<equiv> 125\"\n\ndefinition\n  minUserIRQ :: \"irq\" where\n  \"minUserIRQ \\<equiv> 16\"\n\ndefinition\n  maxUserIRQ :: \"irq\" where\n  \"maxUserIRQ \\<equiv> 123\"\n\ndatatype cr3 = X64CR3 (CR3BaseAddress: word64) (cr3pcid: word64)\n\nprimrec cr3BaseAddress_update :: \"(word64 \\<Rightarrow> word64) \\<Rightarrow> cr3 \\<Rightarrow> cr3\"\nwhere\n  \"cr3BaseAddress_update f (X64CR3 v0 v1) = (X64CR3 (f v0) v1)\"\n\nprimrec cr3pcid_update :: \"(word64 \\<Rightarrow> word64) \\<Rightarrow> cr3 \\<Rightarrow> cr3\"\nwhere\n  \"cr3pcid_update f (X64CR3 v0 v1) = (X64CR3 v0 (f v1))\"\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constraints: Define and enforce architectural-specific constraints on kernel configurations, ensuring that the system adheres to the requirements and limitations of the X64 platform.",
    "input": "",
    "output": "(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming X64\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Perform operations on the underspecified part of the machine state, ensuring that they do not fail and always return a non-empty set of follow-on states. These operations explicitly ignore the failure flag and set it to False, and handle the non-existing case as a null operation to avoid the need for additional axioms.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine operations below work on the underspecified part of the machine state @{typ\n  machine_state_rest} and cannot fail. We could express the latter by type (leaving out the failure\n  flag), but if we later wanted to implement them, we'd have to set up a new Hoare logic framework\n  for that type. So instead, we provide a wrapper for these operations that explicitly ignores the\n  fail flag and sets it to False. Similarly, these operations never return an empty set of follow-on\n  states, which would require the operation to fail. So we explicitly make this (non-existing) case\n  a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\n\\<close>\n\ncontext Arch begin global_naming RISCV64",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Operations: Load and store 64-bit words in the machine's memory, ensuring that the memory addresses are properly aligned. Additionally, retrieve the list of memory regions defined in the system.",
    "input": "",
    "output": "definition loadWord :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\n  where\n  \"loadWord p \\<equiv> do\n     m \\<leftarrow> gets underlying_memory;\n     assert (p && mask 3 = 0);\n     return (word_rcat (map (\\<lambda>i. m (p + (7 - of_int i))) [0 .. 7]))\n   od\"\n\ndefinition storeWord :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"storeWord p w \\<equiv> do\n     assert (p && mask 3 = 0);\n     modify (underlying_memory_update\n              (fold (\\<lambda>i m. m((p + (of_int i)) := word_rsplit w ! (7 - nat i))) [0 .. 7]))\n   od\"\n\nlemma upto0_7_def:\n  \"[0..7] = [0,1,2,3,4,5,6,7]\" by eval\n\nlemma loadWord_storeWord_is_return:\n  \"p && mask 3 = 0 \\<Longrightarrow> (do w \\<leftarrow> loadWord p; storeWord p w od) = return ()\"\n  by (auto simp: loadWord_def storeWord_def bind_def assert_def return_def word_rsplit_rcat_size\n                 modify_def gets_def get_def eval_nat_numeral put_def upto0_7_def word_size)\n\nconsts' memory_regions :: \"(paddr \\<times> paddr) list\"\ndefinition getMemoryRegions :: \"(paddr * paddr) list machine_monad\"\n  where\n  \"getMemoryRegions \\<equiv> return memory_regions\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Store Word in Virtual Machine: This operation is a placeholder for storing a machine word at a specified address in the virtual machine, used exclusively in the simulator.",
    "input": "",
    "output": "definition storeWordVM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"storeWordVM w p \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Timer Operations: Configure, initialize, and reset the timer. These operations allow for the management of the timer's state and behavior within the machine, ensuring proper timing and scheduling functionality.",
    "input": "",
    "output": "consts' configureTimer_impl :: \"unit machine_rest_monad\"\nconsts' configureTimer_val :: \"machine_state \\<Rightarrow> irq\"\ndefinition configureTimer :: \"irq machine_monad\"\n  where\n  \"configureTimer \\<equiv> do\n     machine_op_lift configureTimer_impl;\n     gets configureTimer_val\n   od\"\n\nconsts' initTimer_impl :: \"unit machine_rest_monad\"\ndefinition initTimer :: \"unit machine_monad\"\n  where\n  \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts' resetTimer_impl :: \"unit machine_rest_monad\"\ndefinition resetTimer :: \"unit machine_monad\"\n  where\n  \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Debug Print: Outputs a debug message, which is currently a no-op that returns immediately without any side effects.",
    "input": "",
    "output": "definition debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\"\n  where\n  debugPrint_def[simp]:\n  \"debugPrint \\<equiv> \\<lambda>message. return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Controller Operations: Manage interrupt requests by setting the trigger mode for a specific interrupt and completing the claim for an interrupt. These operations ensure that interrupts are handled correctly and efficiently by the system.",
    "input": "",
    "output": "definition\n  IRQ :: \"irq \\<Rightarrow> irq\"\nwhere \"IRQ \\<equiv> id\"\n\nconsts'\n  setIRQTrigger_impl :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  setIRQTrigger :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setIRQTrigger irq trigger \\<equiv> machine_op_lift (setIRQTrigger_impl irq trigger)\"\n\nconsts'\n  plic_complete_claim_impl :: \"irq \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  plic_complete_claim :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"plic_complete_claim irq \\<equiv> machine_op_lift (plic_complete_claim_impl irq)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Kernel Interrupts: Defines a set of interrupts that cannot occur while the kernel is running but can occur from user mode. In this case, the set is empty, indicating no such interrupts exist on the RISCV64 architecture.",
    "input": "",
    "output": "definition non_kernel_IRQs :: \"irq set\"\n  where\n  \"non_kernel_IRQs = {}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Handling:\n- Get Active IRQ: Retrieves the active interrupt request, updating the IRQ state and checking if the IRQ is masked, invalid, or not allowed in the current kernel state.\n- Mask Interrupt: Updates the mask status of a specific IRQ, allowing or disallowing its processing.\n- Acknowledge Interrupt: Acknowledges an interrupt, though it currently performs no action.\n- Set Interrupt Mode: Sets the trigger level and polarity for a specific IRQ, though it currently performs no action.",
    "input": "",
    "output": "definition getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\n  where\n  \"getActiveIRQ in_kernel \\<equiv> do\n     is_masked \\<leftarrow> gets $ irq_masks;\n     modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n     active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n     if is_masked active_irq \\<or> active_irq = 0xFF \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n     then return None\n     else return ((Some active_irq) :: irq option)\n   od\"\n\ndefinition maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\n  where\n  \"maskInterrupt m irq \\<equiv> modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\n  where\n  \"ackInterrupt \\<equiv> \\<lambda>irq. return ()\"\n\ndefinition setInterruptMode :: \"irq \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\"\n  where\n  \"setInterruptMode \\<equiv> \\<lambda>irq levelTrigger polarityLow. return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Memory: Clear a specified range of memory by setting each word in the range to zero, preparing it for reuse as user memory.",
    "input": "",
    "output": "text \\<open>Clear memory contents to recycle it as user memory\\<close>\ndefinition clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemory ptr bytelength \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Memory: Clears a specified number of bits starting from a given memory address.",
    "input": "",
    "output": "definition clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Initialization: Clear and initialize memory to be used as user memory, ensuring it is properly prepared for use. This includes a call to cleanCacheRange to maintain consistency between the memory and the cache.",
    "input": "",
    "output": "abbreviation (input) \"initMemory == clearMemory\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Memory: Zero out the memory region specified by the pointer and size to ensure that it contains no garbage, allowing for a clean state in the specifications.",
    "input": "",
    "output": "definition freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"freeMemory ptr bits \\<equiv>\n   mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "User-Level Register Operations: Allow manipulation of user-level registers, including getting and setting register values, modifying multiple registers, and managing the program counter for restart and next execution.",
    "input": "",
    "output": "type_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ndatatype user_context = UserContext (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\n\ndefinition getRegister :: \"register \\<Rightarrow> machine_word user_monad\"\n  where\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition modify_registers :: \"(user_regs \\<Rightarrow> user_regs) \\<Rightarrow> user_context \\<Rightarrow> user_context\"\n  where\n  \"modify_registers f uc \\<equiv> UserContext (f (user_regs uc))\"\n\ndefinition setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\"\n  where\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext ((user_regs s) (r := v)))\"\n\ndefinition getRestartPC :: \"machine_word user_monad\"\n  where\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition setNextPC :: \"machine_word \\<Rightarrow> unit user_monad\"\n  where\n  \"setNextPC \\<equiv> setRegister NextIP\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache and Barrier Operations: Initialize the L2 cache, flush the hardware ASID, and perform a store fence (sfence) to ensure memory ordering and coherence.",
    "input": "",
    "output": "consts' initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition initL2Cache :: \"unit machine_monad\"\n  where\n  \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\nconsts' hwASIDFlush_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition hwASIDFlush :: \"machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"hwASIDFlush asid \\<equiv> machine_op_lift (hwASIDFlush_impl asid)\"\n\nconsts' sfence_impl :: \"unit machine_rest_monad\"\ndefinition sfence :: \"unit machine_monad\"\n  where\n  \"sfence \\<equiv> machine_op_lift sfence_impl\"\n\nlemmas cache_machine_op_defs = sfence_def hwASIDFlush_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Read Fault Status Value: Retrieve the fault status value from the machine state.",
    "input": "",
    "output": "consts' stval_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition read_stval :: \"machine_word machine_monad\"\n  where\n  \"read_stval = gets stval_val\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Virtual Space Root: Configures the virtual memory space by setting the root page table and the associated address space identifier.",
    "input": "",
    "output": "consts' setVSpaceRoot_impl :: \"paddr \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition setVSpaceRoot :: \"paddr \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"setVSpaceRoot pt asid \\<equiv> machine_op_lift $ setVSpaceRoot_impl pt asid\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Integer Representation: Defines the representation of integer literals and words in the system, using a 32-bit signed format.",
    "input": "",
    "output": "(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define the length of IRQ identifiers and establish type synonyms for IRQ and physical addresses, ensuring consistent and clear representation of these fundamental platform-specific values.",
    "input": "",
    "output": "context Arch begin global_naming RISCV64\n\nvalue_type irq_len = Kernel_Config.irqBits (* IRQ_CNODE_SLOT_BITS *)\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = machine_word\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants Definition: Defines a set of constants for platform-specific memory addresses, offsets, and boundaries, ensuring consistent and accurate memory management and address translation. These constants include base addresses, top addresses, and offsets for kernel and user space, as well as interrupt request (IRQ) ranges, facilitating the alignment and mapping of physical and virtual addresses.",
    "input": "",
    "output": "definition canonical_bit :: nat\n  where\n  \"canonical_bit = 38\"\n\ndefinition kdevBase :: machine_word\n  where\n  \"kdevBase = - (1 << 30)\" (* 2^64 - 1 GiB *)\n\nlemma \"kdevBase = 0xFFFFFFFFC0000000\" (* Sanity check with C *)\n  by (simp add: kdevBase_def)\n\ndefinition kernelELFPAddrBase :: machine_word\n  where\n  \"kernelELFPAddrBase = physBase + 0x4000000\"\n\ndefinition pptrTop :: machine_word\n  where\n  \"pptrTop \\<equiv> - (1 << 31)\"\n\ndefinition kernelELFBase :: machine_word\n  where\n  \"kernelELFBase = pptrTop + (kernelELFPAddrBase && mask 30)\" (* 2^64 - 2 GiB + ... *)\n\ndefinition kernelELFBaseOffset :: machine_word\n  where\n  \"kernelELFBaseOffset = kernelELFBase - kernelELFPAddrBase\"\n\ndefinition pptrBase :: machine_word\n  where\n  \"pptrBase = - (1 << canonical_bit)\"\n\nlemma \"pptrBase = 0xFFFFFFC000000000\" (* Sanity check with C *)\n  by (simp add: pptrBase_def canonical_bit_def)\n\ndefinition pptrUserTop :: machine_word\n  where\n  \"pptrUserTop \\<equiv> mask canonical_bit && ~~mask 12\" (* for page boundary alignment *)\n\nlemma \"pptrUserTop = 0x0000003ffffff000\" (* Sanity check with C *)\n  by (simp add: pptrUserTop_def canonical_bit_def mask_def)\n\nschematic_goal pptrUserTop_def': (* direct constant definition *)\n  \"RISCV64.pptrUserTop = numeral ?x\"\n  by (simp add: RISCV64.pptrUserTop_def canonical_bit_def mask_def del: word_eq_numeral_iff_iszero)\n\ndefinition paddrBase :: machine_word\n  where\n  \"paddrBase \\<equiv> 0\"\n\ndefinition pptrBaseOffset :: machine_word\n  where\n  \"pptrBaseOffset = pptrBase - paddrBase\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> machine_word\"\n  where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"machine_word \\<Rightarrow> paddr\"\n  where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"machine_word \\<Rightarrow> paddr\"\n  where\n  \"addrFromKPPtr pptr \\<equiv> pptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\"\n  where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition maxIRQ :: \"irq\"\n  where\n  \"maxIRQ \\<equiv> 54\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reserved IRQ Value: Defines a constant `irqInvalid` with a value of 0 to represent an invalid or non-existent interrupt request. \n\nPage Coloring: Defines a constant `pageColourBits` which is currently undefined, indicating that page coloring is not implemented on this platform.",
    "input": "",
    "output": "definition irqInvalid :: \"irq\"\n  where\n  \"irqInvalid \\<equiv> 0\"\n\ndefinition pageColourBits :: nat\n  where\n  \"pageColourBits \\<equiv> undefined\" \\<comment> \\<open>not implemented on this platform\\<close>\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Physical Pointer Base and Kernel ELF Base Relationship: The physical pointer base is less than the kernel ELF base, ensuring that the memory regions for physical pointers and the kernel ELF are properly separated.",
    "input": "",
    "output": "(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming RISCV64\n\nlemma pptrBase_kernelELFBase:\n  \"pptrBase < kernelELFBase\"\n  by (simp add: pptrBase_def canonical_bit_def kernelELFBase_def kernelELFPAddrBase_def pptrTop_def\n                Kernel_Config.physBase_def mask_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Physical Base Alignment: The physical base address is aligned to a 12-bit boundary, ensuring proper memory alignment for the system.",
    "input": "",
    "output": "lemma is_page_aligned_physBase:\n  \"is_aligned physBase 12\"\n  by (simp add: Kernel_Config.physBase_def is_aligned_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Window Sizing: Ensures that the kernel's memory window is sufficiently large, with the base address of the kernel ELF plus 2^22 being less than or equal to the kernel ELF base, and the kernel ELF base plus at least one page (2^12) being less than or equal to the device base. This guarantees that the kernel and its associated data fit within the allocated memory regions without overlap.",
    "input": "",
    "output": "lemma kernel_window_sufficient:\n  \"pptrBase + (1 << 22) \\<le> kernelELFBase\"\n  unfolding pptrBase_def canonical_bit_def kernelELFBase_def kernelELFPAddrBase_def pptrTop_def\n  by (simp add: mask_def Kernel_Config.physBase_def)\n\nlemma kernel_elf_window_at_least_page:\n  \"kernelELFBase + 2 ^ 12 \\<le> kdevBase\"\n  unfolding kernelELFBase_def kernelELFPAddrBase_def kdevBase_def pptrTop_def\n  by (simp add: mask_def Kernel_Config.physBase_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel ELF Base Address: The base address of the kernel ELF is less than the base address plus 2^12, ensuring that the address space does not overflow.",
    "input": "",
    "output": "lemma kernelELFBase_no_overflow:\n  \"kernelELFBase < kernelELFBase + 2 ^ 12\"\n  unfolding kernelELFBase_def kernelELFPAddrBase_def pptrTop_def\n  by (simp add: mask_def Kernel_Config.physBase_def)\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Perform operations on the underspecified part of the machine state, ensuring that they do not fail and always return a non-empty set of follow-on states. These operations are designed to avoid the need for additional axioms by explicitly setting the failure flag to False and handling the non-existing case as a null operation.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine operations below work on the underspecified part of the machine state @{typ\n  machine_state_rest} and cannot fail. We could express the latter by type (leaving out the failure\n  flag), but if we later wanted to implement them, we'd have to set up a new Hoare logic framework\n  for that type. So instead, we provide a wrapper for these operations that explicitly ignores the\n  fail flag and sets it to False. Similarly, these operations never return an empty set of follow-on\n  states, which would require the operation to fail. So we explicitly make this (non-existing) case\n  a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\\<close>\n\ncontext Arch begin global_naming AARCH64",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Operations: Enable the loading and storing of machine words in memory, ensuring that the memory addresses are properly aligned. Additionally, provide a mechanism to retrieve the defined memory regions.",
    "input": "",
    "output": "definition loadWord :: \"machine_word \\<Rightarrow> machine_word machine_monad\" where\n  \"loadWord p \\<equiv> do\n     m \\<leftarrow> gets underlying_memory;\n     assert (p && mask 3 = 0);\n     return (word_rcat (map (\\<lambda>i. m (p + (7 - of_int i))) [0 .. 7]))\n   od\"\n\ndefinition storeWord :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"storeWord p w \\<equiv> do\n     assert (p && mask 3 = 0);\n     modify (underlying_memory_update\n              (fold (\\<lambda>i m. m((p + (of_int i)) := word_rsplit w ! (7 - nat i))) [0 .. 7]))\n   od\"\n\nlemma upto0_7_def:\n  \"[0..7] = [0,1,2,3,4,5,6,7]\" by eval\n\nlemma loadWord_storeWord_is_return:\n  \"p && mask 3 = 0 \\<Longrightarrow> (do w \\<leftarrow> loadWord p; storeWord p w od) = return ()\"\n  by (auto simp: loadWord_def storeWord_def bind_def assert_def return_def word_rsplit_rcat_size\n                 modify_def gets_def get_def eval_nat_numeral put_def upto0_7_def word_size)\n\nconsts' memory_regions :: \"(paddr \\<times> paddr) list\"\ndefinition getMemoryRegions :: \"(paddr * paddr) list machine_monad\" where\n  \"getMemoryRegions \\<equiv> return memory_regions\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Store Word in Virtual Machine: The operation is defined to store a machine word at a specified address in the virtual machine, but it is currently a no-op and does nothing.",
    "input": "",
    "output": "definition storeWordVM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"storeWordVM w p \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Timer Operations: Configure, initialize, and reset the timer. These operations allow for the setup, initialization, and resetting of the timer, ensuring that the system can manage time-based events and interrupts effectively.",
    "input": "",
    "output": "consts' configureTimer_impl :: \"unit machine_rest_monad\"\nconsts' configureTimer_val :: \"machine_state \\<Rightarrow> irq\"\ndefinition configureTimer :: \"irq machine_monad\" where\n  \"configureTimer \\<equiv> do\n     machine_op_lift configureTimer_impl;\n     gets configureTimer_val\n   od\"\n\nconsts' initTimer_impl :: \"unit machine_rest_monad\"\ndefinition initTimer :: \"unit machine_monad\" where\n  \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts' resetTimer_impl :: \"unit machine_rest_monad\"\ndefinition resetTimer :: \"unit machine_monad\" where\n  \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Debug Print: Outputs a debug message, which is defined to have no effect in the machine monad.",
    "input": "",
    "output": "definition debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\" where\n  debugPrint_def[simp]:\n  \"debugPrint \\<equiv> \\<lambda>message. return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Controller Operations: Manage interrupt requests by setting the trigger mode for a specific interrupt and completing the claim for an interrupt. These operations ensure that interrupts are handled correctly and efficiently, maintaining the system's responsiveness and reliability.",
    "input": "",
    "output": "definition IRQ :: \"irq \\<Rightarrow> irq\" where\n  \"IRQ \\<equiv> id\"\n\nconsts' setIRQTrigger_impl :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_rest_monad\"\ndefinition setIRQTrigger :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\" where\n  \"setIRQTrigger irq trigger \\<equiv> machine_op_lift (setIRQTrigger_impl irq trigger)\"\n\nconsts' plic_complete_claim_impl :: \"irq \\<Rightarrow> unit machine_rest_monad\"\ndefinition plic_complete_claim :: \"irq \\<Rightarrow> unit machine_monad\" where\n  \"plic_complete_claim irq \\<equiv> machine_op_lift (plic_complete_claim_impl irq)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Kernel Interrupts: Defines a set of interrupts that can occur in user mode but not while the kernel is running, specifically including maintenance and timer event interrupts.",
    "input": "",
    "output": "definition non_kernel_IRQs :: \"irq set\" where\n  \"non_kernel_IRQs = {irqVGICMaintenance, irqVTimerEvent}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Handling:\n- Get Active IRQ: Determines the active interrupt request (IRQ) by updating the IRQ state and checking if the IRQ is masked or if it is a non-kernel IRQ while in kernel mode. If the IRQ is valid, it returns the active IRQ; otherwise, it returns None.\n- Mask Interrupt: Updates the masking status of a specific IRQ, allowing or preventing its processing.\n- Acknowledge Interrupt: Acknowledges an interrupt, indicating that it has been processed.\n- Set Interrupt Mode: Configures the triggering mode and polarity for a specific IRQ.",
    "input": "",
    "output": "definition getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\" where\n  \"getActiveIRQ in_kernel \\<equiv> do\n     is_masked \\<leftarrow> gets $ irq_masks;\n     modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n     active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n     if is_masked active_irq \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n     then return None\n     else return (Some active_irq)\n   od\"\n\ndefinition maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\" where\n  \"maskInterrupt m irq \\<equiv> modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\" where\n  \"ackInterrupt \\<equiv> \\<lambda>irq. return ()\"\n\ndefinition setInterruptMode :: \"irq \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\" where\n  \"setInterruptMode \\<equiv> \\<lambda>irq levelTrigger polarityLow. return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "User-Level Register Management: Provides a type alias for a function that maps registers to machine words, enabling the manipulation and access of user-level registers within the system.",
    "input": "",
    "output": "type_synonym user_regs = \"register \\<Rightarrow> machine_word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "FPU Register Management: The system manages 64 general FPU registers, ensuring that floating-point operations are supported and state is maintained effectively.",
    "input": "",
    "output": "type_synonym fpu_regs = 64",
    "system": "",
    "history": []
  },
  {
    "instruction": "User Monad and Register Operations: Provides functions to get and set the values of user registers, including the ability to modify multiple registers at once and to specifically handle the program counter for restart and next instructions.",
    "input": "",
    "output": "datatype fpu_state = FPUState (fpuRegs : \"fpu_regs \\<Rightarrow> 64 word\")\n                              (fpuSr : \"32 word\")\n                              (fpuCr : \"32 word\")\n\ndatatype user_context = UserContext (fpu_state : fpu_state) (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\ndefinition getRegister :: \"register \\<Rightarrow> machine_word user_monad\" where\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition modify_registers :: \"(user_regs \\<Rightarrow> user_regs) \\<Rightarrow> user_context \\<Rightarrow> user_context\" where\n  \"modify_registers f uc \\<equiv> UserContext (fpu_state uc) (f (user_regs uc))\"\n\ndefinition setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\" where\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext (fpu_state s) ((user_regs s) (r := v)))\"\n\ndefinition getRestartPC :: \"machine_word user_monad\" where\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition setNextPC :: \"machine_word \\<Rightarrow> unit user_monad\" where\n  \"setNextPC \\<equiv> setRegister NextIP\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "FPU Management: Enables, retrieves, and sets the FPU state, checks if a native thread is using the FPU, switches the FPU owner, and performs cleanup operations for FPU-related resources.",
    "input": "",
    "output": "consts' enableFpuEL01_impl :: \"unit machine_rest_monad\"\ndefinition enableFpuEL01 :: \"unit machine_monad\" where\n  \"enableFpuEL01 \\<equiv> machine_op_lift enableFpuEL01_impl\"\n\ndefinition getFPUState :: \"fpu_state user_monad\" where\n  \"getFPUState \\<equiv> gets fpu_state\"\n\ndefinition setFPUState :: \"fpu_state \\<Rightarrow> unit user_monad\" where\n  \"setFPUState fc \\<equiv> modify (\\<lambda>s. UserContext fc (user_regs s))\"\n\nconsts' nativeThreadUsingFPU_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\nconsts' nativeThreadUsingFPU_val :: \"machine_state \\<Rightarrow> bool\"\ndefinition nativeThreadUsingFPU :: \"machine_word \\<Rightarrow> bool machine_monad\" where\n  \"nativeThreadUsingFPU thread_ptr \\<equiv> do\n       machine_op_lift (nativeThreadUsingFPU_impl thread_ptr);\n       gets nativeThreadUsingFPU_val\n  od\"\n\nconsts' switchFpuOwner_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition switchFpuOwner :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"switchFpuOwner new_owner cpu \\<equiv> machine_op_lift (switchFpuOwner_impl new_owner cpu)\"\n\n\nconsts' fpuThreadDeleteOp_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition fpuThreadDeleteOp :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"fpuThreadDeleteOp thread_ptr \\<equiv> machine_op_lift (fpuThreadDeleteOp_impl thread_ptr)\"\n\n\ndefinition isFpuEnable :: \"bool machine_monad\" where\n  \"isFpuEnable \\<equiv> return True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Register Access: Retrieve the values of fault-related registers (FAR, DFSR, IFSR) from the machine state.",
    "input": "",
    "output": "consts' FAR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getFAR :: \"machine_word machine_monad\" where\n  \"getFAR \\<equiv> gets FAR_val\"\n\nconsts' DFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getDFSR :: \"machine_word machine_monad\" where\n  \"getDFSR \\<equiv> gets DFSR_val\"\n\nconsts' IFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getIFSR :: \"machine_word machine_monad\" where\n  \"getIFSR \\<equiv> gets IFSR_val\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Control Register Operations: Provide mechanisms to get and set the values of hardware control registers such as HSR, ESR, and SCTLR. Additionally, support address translation for stage 1, allowing the retrieval of translated addresses.",
    "input": "",
    "output": "consts' HSR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getHSR :: \"machine_word machine_monad\" where\n  \"getHSR \\<equiv> gets HSR_val\"\n\nconsts' ESR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getESR :: \"machine_word machine_monad\" where\n  \"getESR \\<equiv> gets ESR_val\"\n\nconsts' SCTLR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getSCTLR :: \"machine_word machine_monad\" where\n  \"getSCTLR \\<equiv> gets SCTLR_val\"\n\nconsts' setHCR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition setHCR :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"setHCR w \\<equiv> machine_op_lift (setHCR_impl w)\"\n\nconsts' setSCTLR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition setSCTLR :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"setSCTLR w \\<equiv> machine_op_lift (setSCTLR_impl w)\"\n\nconsts' addressTranslateS1_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\nconsts' addressTranslateS1_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition addressTranslateS1 :: \"machine_word \\<Rightarrow> machine_word machine_monad\" where\n  \"addressTranslateS1 w \\<equiv> do\n    machine_op_lift (addressTranslateS1_impl w);\n    gets (addressTranslateS1_val w)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "GIC vCPU Control Interface: Provides operations to get and set various control registers (HCR, VMCR, APR, VTR, MISR, EISR0, EISR1, and LR) for the GIC vCPU interface. These operations allow for the manipulation and retrieval of 32-bit values from the machine state, enabling precise control over the virtual CPU's interrupt handling and configuration.",
    "input": "",
    "output": "consts' gic_vcpu_ctrl_hcr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_hcr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_hcr \\<equiv> gets gic_vcpu_ctrl_hcr_val\"\n\nconsts' set_gic_vcpu_ctrl_hcr_impl :: \"32 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_hcr :: \"32 word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_hcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_hcr_impl w)\"\n\nconsts' gic_vcpu_ctrl_vmcr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_vmcr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_vmcr \\<equiv> gets gic_vcpu_ctrl_vmcr_val\"\n\nconsts' set_gic_vcpu_ctrl_vmcr_impl :: \"32 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_vmcr :: \"32 word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_vmcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vmcr_impl w)\"\n\nconsts' gic_vcpu_ctrl_apr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_apr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_apr \\<equiv> gets gic_vcpu_ctrl_apr_val\"\n\nconsts' set_gic_vcpu_ctrl_apr_impl :: \"32 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_apr :: \"32 word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_apr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_apr_impl w)\"\n\nconsts' gic_vcpu_ctrl_vtr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_vtr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_vtr \\<equiv> gets gic_vcpu_ctrl_vtr_val\"\n\nconsts' set_gic_vcpu_ctrl_vtr_impl :: \"32 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_vtr :: \"32 word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_vtr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vtr_impl w)\"\n\nconsts' gic_vcpu_ctrl_misr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_misr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_misr \\<equiv> gets gic_vcpu_ctrl_misr_val\"\n\nconsts' gic_vcpu_ctrl_eisr0_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_eisr0 :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_eisr0 \\<equiv> gets gic_vcpu_ctrl_eisr0_val\"\n\nconsts' gic_vcpu_ctrl_eisr1_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_eisr1 :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_eisr1 \\<equiv> gets gic_vcpu_ctrl_eisr1_val\"\n\nconsts' get_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\nconsts' gic_vcpu_ctrl_lr_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition get_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word machine_monad\" where\n  \"get_gic_vcpu_ctrl_lr n \\<equiv> do\n     machine_op_lift (get_gic_vcpu_ctrl_lr_impl n);\n     gets (gic_vcpu_ctrl_lr_val n)\n   od\"\n\nconsts' set_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_lr n w  \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_lr_impl n w)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Timer Interface: Provides operations to check the export of architectural timer and read the value of the virtual timer counter.",
    "input": "",
    "output": "consts' check_export_arch_timer_impl :: \"unit machine_rest_monad\"\ndefinition check_export_arch_timer :: \"unit machine_monad\" where\n  \"check_export_arch_timer \\<equiv> machine_op_lift check_export_arch_timer_impl\"\n\nconsts' read_cntpct_val :: \"machine_state \\<Rightarrow> 64 word\"\ndefinition read_cntpct :: \"64 word machine_monad\" where\n  \"read_cntpct \\<equiv> gets read_cntpct_val\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Banked Registers Access: Provides mechanisms to read and write the values of VCPU hardware registers. The `readVCPUHardwareReg` function retrieves the value of a specified VCPU register, while the `writeVCPUHardwareReg` function updates the value of a specified VCPU register.",
    "input": "",
    "output": "consts' vcpuHardwareReg_val :: \"vcpureg \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition readVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word machine_monad\" where\n  \"readVCPUHardwareReg reg \\<equiv> gets (vcpuHardwareReg_val reg)\"\n\nconsts' writeVCPUHardwareReg_impl :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition writeVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"writeVCPUHardwareReg reg val \\<equiv> machine_op_lift (writeVCPUHardwareReg_impl reg val)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache and Barrier Operations: Provide mechanisms to initialize the L2 cache, perform instruction and data synchronization barriers, and manage cache coherence through various operations such as invalidating translations, cleaning, and invalidating cache ranges. These operations ensure that the memory and cache states are consistent and synchronized, maintaining the integrity and performance of the system.",
    "input": "",
    "output": "consts' initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition initL2Cache :: \"unit machine_monad\" where\n  \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\nconsts' isb_impl :: \"unit machine_rest_monad\"\ndefinition isb :: \"unit machine_monad\" where\n  \"isb \\<equiv> machine_op_lift isb_impl\"\n\nconsts' dsb_impl :: \"unit machine_rest_monad\"\ndefinition dsb :: \"unit machine_monad\" where\n  \"dsb \\<equiv> machine_op_lift dsb_impl\"\n\nconsts' invalidateTranslationASID_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition invalidateTranslationASID :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"invalidateTranslationASID asid \\<equiv> machine_op_lift (invalidateTranslationASID_impl asid)\"\n\nconsts' invalidateTranslationSingle_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition invalidateTranslationSingle :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"invalidateTranslationSingle r \\<equiv> machine_op_lift (invalidateTranslationSingle_impl r)\"\n\nconsts' cleanByVA_PoU_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition cleanByVA_PoU :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"cleanByVA_PoU vaddr paddr = machine_op_lift (cleanByVA_PoU_impl vaddr paddr)\"\n\nconsts' cleanInvalidateCacheRange_RAM_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition cleanInvalidateCacheRange_RAM ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"cleanInvalidateCacheRange_RAM vstart vend pstart =\n     machine_op_lift (cleanInvalidateCacheRange_RAM_impl vstart vend pstart)\"\n\nconsts' cleanCacheRange_RAM_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition cleanCacheRange_RAM ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"cleanCacheRange_RAM vstart vend pstart =\n     machine_op_lift (cleanCacheRange_RAM_impl vstart vend pstart)\"\n\nconsts' cleanCacheRange_PoU_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition cleanCacheRange_PoU ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"cleanCacheRange_PoU vstart vend pstart =\n     machine_op_lift (cleanCacheRange_PoU_impl vstart vend pstart)\"\n\nconsts' invalidateCacheRange_RAM_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition invalidateCacheRange_RAM ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"invalidateCacheRange_RAM vstart vend pstart =\n     machine_op_lift (invalidateCacheRange_RAM_impl vstart vend pstart)\"\n\nconsts' invalidateCacheRange_I_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition invalidateCacheRange_I ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"invalidateCacheRange_I vstart vend pstart =\n     machine_op_lift (invalidateCacheRange_I_impl vstart vend pstart)\"\n\nconsts' branchFlushRange_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition branchFlushRange ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"branchFlushRange vstart vend pstart = machine_op_lift (branchFlushRange_impl vstart vend pstart)\"\n\nlemmas cache_machine_op_defs =\n  invalidateTranslationASID_def\n  invalidateTranslationSingle_def\n  cleanByVA_PoU_def\n  cleanInvalidateCacheRange_RAM_def\n  cleanCacheRange_RAM_def\n  cleanCacheRange_PoU_def\n  invalidateCacheRange_RAM_def\n  invalidateCacheRange_I_def\n  branchFlushRange_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Memory: Clear a specified range of memory by setting each word in the range to zero, preparing it for reuse as user memory without flushing the cache.",
    "input": "",
    "output": "text \\<open>Clear memory contents to recycle it as user memory. Do not yet flush the cache.\\<close>\ndefinition clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"clearMemory ptr bytelength \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Memory: Clears a specified number of bits starting from a given memory address.",
    "input": "",
    "output": "definition clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Initialization: Clear and initialize memory to be used as user memory, ensuring it is properly prepared for subsequent operations.",
    "input": "",
    "output": "abbreviation (input) \"initMemory == clearMemory\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Memory: Zero out the memory region specified by the pointer and size to avoid garbage, ensuring that the memory content is predictable and consistent in the specifications.",
    "input": "",
    "output": "definition freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"freeMemory ptr bits \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Virtual Space Root: Configures the virtual memory space by setting the root page table and associated address space identifier.",
    "input": "",
    "output": "consts' setVSpaceRoot_impl :: \"paddr \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition setVSpaceRoot :: \"paddr \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"setVSpaceRoot pt asid \\<equiv> machine_op_lift $ setVSpaceRoot_impl pt asid\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Integer Literal Representation: Defines the representation of C integer literals as 32-bit signed integers, providing a standardized format for integer values in the system.",
    "input": "",
    "output": "(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define and initialize various platform-specific constants, including base addresses, offsets, top addresses, and interrupt request (IRQ) values. These constants are used to manage memory addresses and IRQs, ensuring consistent and predictable behavior across the system.",
    "input": "",
    "output": "context Arch begin global_naming AARCH64\n\nvalue_type irq_len = Kernel_Config.irqBits \n\n\n\ndefinition paddrBase :: machine_word where\n  \"paddrBase \\<equiv> 0\"\n\ndefinition pptrBaseOffset :: machine_word where\n  \"pptrBaseOffset = pptrBase - paddrBase\"\n\ndefinition paddrTop :: machine_word where\n  \"paddrTop = pptrTop - pptrBaseOffset\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> machine_word\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"machine_word \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"machine_word \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr pptr \\<equiv> pptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition irqVGICMaintenance :: irq where\n  \"irqVGICMaintenance \\<equiv> 25\"\n\ndefinition irqVTimerEvent :: irq where\n  \"irqVTimerEvent \\<equiv> 27\"\n\ndefinition pageColourBits :: nat where\n  \"pageColourBits \\<equiv> undefined\" \\<comment> \\<open>not implemented on this platform\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Sizes: The number of bits used for the virtual space index in the page table is determined by the configuration, specifically whether the physical address size is 40 bits, in which case 10 bits are used, or 9 bits otherwise.",
    "input": "",
    "output": "definition vs_index_bits :: nat where\n  \"vs_index_bits \\<equiv> if config_ARM_PA_SIZE_BITS_40 then 10 else (9::nat)\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Space Index Bits: The number of bits used for the virtual space index is greater than zero, ensuring a valid and non-zero size for page table entries.",
    "input": "",
    "output": "declare AARCH64.vs_index_bits_def[code]\n\ncontext Arch begin global_naming AARCH64\n\nlemma vs_index_bits_ge0[simp, intro!]: \"0 < vs_index_bits\"\n  by (simp add: vs_index_bits_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Index Sizes: Define the size of virtual space index and page table index types, ensuring that the virtual space index length is less than a symbolic value (vs_index_bits) and the page table index length is fixed at 9 bits. This allows for flexible and precise management of memory addressing and page table structures.",
    "input": "",
    "output": "typedef vs_index_len = \"{n :: nat. n < vs_index_bits}\" by auto\n\nend\n\ninstantiation AARCH64.vs_index_len :: len0\nbegin\n  interpretation Arch .\n  definition len_of_vs_index_len: \"len_of (x::vs_index_len itself) \\<equiv> CARD(vs_index_len)\"\n  instance ..\nend\n\ninstantiation AARCH64.vs_index_len :: len\nbegin\n  interpretation Arch .\n  instance\n  proof\n   show \"0 < LENGTH(vs_index_len)\"\n     by (simp add: len_of_vs_index_len type_definition.card[OF type_definition_vs_index_len])\n  qed\nend\n\ncontext Arch begin global_naming AARCH64\n\ntype_synonym vs_index = \"vs_index_len word\"\n\ntype_synonym pt_index_len = 9\ntype_synonym pt_index = \"pt_index_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Length of vs_index_len: The length of the `vs_index_len` is equal to the number of bits in `vs_index_bits`, ensuring consistency and correctness in the page table size definitions.",
    "input": "",
    "output": "lemma length_vs_index_len[simp]:\n  \"LENGTH(vs_index_len) = vs_index_bits\"\n  by (simp add: len_of_vs_index_len type_definition.card[OF type_definition_vs_index_len])",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Array Sizes: Define the sizes of C arrays for page tables and virtual space, where `pt_array_len` is calculated as 2 raised to the power of `LENGTH(pt_index_len)`, and `vs_array_len` is calculated as 2 raised to the power of `vs_index_bits`.",
    "input": "",
    "output": "value_type pt_array_len = \"(2::nat) ^ LENGTH(pt_index_len)\"\nvalue_type vs_array_len = \"(2::nat) ^ vs_index_bits\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constraints: Define and enforce constraints specific to the AARCH64 architecture, ensuring that the kernel configuration adheres to the architectural requirements and limitations.",
    "input": "",
    "output": "(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming AARCH64",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Constraints: The maximum interrupt request (IRQ) number is less than \\(2^{irqBits}\\), and the virtual timer event IRQ is less than or equal to the maximum IRQ.",
    "input": "",
    "output": "lemma irqVTimerEvent_le_maxIRQ[simp, intro!]:\n  \"irqVTimerEvent \\<le> maxIRQ\"\n  by (simp add: irqVTimerEvent_def Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_less_2p_irqBits:\n  \"(maxIRQ::nat) < 2^irqBits\"\n  by (simp add: Kernel_Config.maxIRQ_def Kernel_Config.irqBits_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Length and Maximum IRQ Value: The length of the IRQ representation is defined by `irqBits`, and the maximum IRQ value is less than \\(2^{irqBits}\\).",
    "input": "",
    "output": "lemma LENGTH_irq_len_irqBits[simp]: (* [simp] will fire only for simp del: len_of_numeral_defs *)\n  \"LENGTH(irq_len) = irqBits\"\n  using irq_len_def irq_len_val\n  by simp\n\nlemma maxIRQ_less_2p_irq_len:\n  \"(maxIRQ::nat) < 2^LENGTH(irq_len)\"\n  using maxIRQ_less_2p_irqBits\n  by (simp del: len_of_numeral_defs)",
    "system": "",
    "history": []
  },
  {
    "instruction": "MaxIRQ Representation: The maximum interrupt request (maxIRQ) is represented as a generic numeral, allowing for rules about type casts, unat, and uint operations without explicitly mentioning specific numbers.",
    "input": "",
    "output": "lemma of_nat_maxIRQ[simp]:\n  \"of_nat maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma of_int_maxIRQ[simp]:\n  \"of_int maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unat Conversion for maxIRQ: Ensures that the conversion of `maxIRQ` to its natural number representation using `unat` is safe and maintains the value, provided that the length of `irq_len` is less than or equal to the length of the word type.",
    "input": "",
    "output": "lemma unat_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> unat (maxIRQ::'a word) = maxIRQ\"\n  by (metis maxIRQ_less_2p_irq_len Word.of_nat_unat of_nat_inverse of_nat_maxIRQ unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Uint Conversion for maxIRQ: Ensures that the conversion of the maximum interrupt request (maxIRQ) to an unsigned integer is safe and retains its value, provided the length of the interrupt request does not exceed the word length.",
    "input": "",
    "output": "lemma uint_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> uint (maxIRQ::'a word) = maxIRQ\"\n  by (metis Kernel_Config.maxIRQ_def of_nat_numeral uint_nat unat_maxIRQ)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Property: Ucast Preservation of maxIRQ: The value of `maxIRQ` is preserved when cast between types of equal or greater length, ensuring that the maximum interrupt request number remains consistent across different type representations.",
    "input": "",
    "output": "lemma ucast_maxIRQ[simp]:\n  \"\\<lbrakk> LENGTH(irq_len) \\<le> LENGTH('a::len); LENGTH(irq_len) \\<le> LENGTH('b::len) \\<rbrakk> \\<Longrightarrow>\n   UCAST ('a \\<rightarrow> 'b) maxIRQ = maxIRQ\"\n  by (metis of_nat_maxIRQ ucast_nat_def unat_maxIRQ)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Property: Maximum IRQ Comparison: Ensures that the comparison between the maximum IRQ and an upcasted IRQ value remains consistent, provided the target word length is not less than the source IRQ length. This property guarantees the safety and correctness of IRQ comparisons across different word sizes.",
    "input": "",
    "output": "lemma maxIRQ_less_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   (maxIRQ < (ucast irq :: 'a word)) = (maxIRQ < irq)\" for irq::irq\n  by (simp add: word_less_nat_alt unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Property: \nMax IRQ Value Preservation: Ensures that the upcast of an IRQ value to a larger word size does not exceed the maximum IRQ value, maintaining the integrity of the IRQ range.",
    "input": "",
    "output": "lemma maxIRQ_le_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   ((ucast irq :: 'a word) \\<le> Kernel_Config.maxIRQ) = (irq \\<le> Kernel_Config.maxIRQ)\" for irq::irq\n  by (simp add: word_le_nat_alt unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value Properties: The maximum IRQ value (`maxIRQ`) is constrained and related to the bit length of the IRQ, ensuring that any word less than or equal to `maxIRQ` has a natural number representation less than \\(2^{LENGTH(irq\\_len)}\\). Additionally, the `maxIRQ` value can be cast and manipulated between different word types (signed, unsigned, and machine words) while preserving its value and properties.",
    "input": "",
    "output": "lemma le_maxIRQ_machine_less_irqBits_val[simplified]:\n  \"w \\<le> maxIRQ \\<Longrightarrow> unat w < 2^LENGTH(irq_len)\" for w::machine_word\n  using maxIRQ_less_2p_irq_len\n  by (simp add: word_le_nat_alt)\n\nlemma irq_machine_le_maxIRQ_irq:\n  \"irq \\<le> Kernel_Config.maxIRQ \\<Longrightarrow> (ucast irq::irq) \\<le> maxIRQ\" for irq::machine_word\n  by (simp add: Kernel_Config.maxIRQ_def word_le_nat_alt unat_ucast)\n\nlemma maxIRQ_eq_ucast_irq_32_signed_uint:\n  \"(maxIRQ = (ucast b :: 32 signed word)) = (uint b = maxIRQ)\" for b::irq\n  unfolding Kernel_Config.maxIRQ_def\n  apply uint_arith\n  apply (simp add: uint_up_ucast is_up)\n  done\n\nlemma sint_maxIRQ_32[simp]:\n  \"sint (maxIRQ :: 32 signed word) = maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_machine[simp]:\n  \"scast (maxIRQ::32 signed word) = (maxIRQ::machine_word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_irq[simp]:\n  \"scast (maxIRQ :: 32 signed word) = (maxIRQ::irq)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_machine:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = x\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_irq:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = (ucast x :: irq)\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_1_plus_eq_Suc_machine[simp]:\n  \"unat (1 + Kernel_Config.maxIRQ :: machine_word) = Suc Kernel_Config.maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache Line Bits Sanity: The value of `cacheLineBits` must be within the range of 2 to 12, ensuring it is suitable for use in cache operations without conflicting with other values.",
    "input": "",
    "output": "lemma cacheLineBits_sanity:\n  \"cacheLineBits \\<in> {2..12}\"\n  by (simp add: cacheLineBits_def Kernel_Config.CONFIG_L1_CACHE_LINE_SIZE_BITS_def)\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Perform operations on the underspecified part of the machine state, ensuring that they do not fail and always return a non-empty set of follow-on states. These operations are wrapped to explicitly ignore the failure flag and set it to False, maintaining consistency and predictability in the system's behavior.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine operations below work on the underspecified\n  part of the machine state @{typ machine_state_rest} and cannot fail.\n  We could express the latter by type (leaving out the failure flag),\n  but if we later wanted to implement them,\n  we'd have to set up a new hoare-logic\n  framework for that type. So instead, we provide a wrapper for these\n  operations that explicitly ignores the fail flag and sets it to\n  False. Similarly, these operations never return an empty set of\n  follow-on states, which would require the operation to fail.\n  So we explicitly make this (non-existing) case a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\n\\<close>\n\ncontext Arch begin global_naming ARM_HYP",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Provide a set of machine-level operations, including initializing and resetting the timer, writing to the Translation Table Base Register 0 (TTBR0), and setting the hardware ASID. These operations are lifted to the machine monad for execution in the machine context, ensuring that they interact correctly with the underlying hardware.",
    "input": "",
    "output": "consts'\n  memory_regions :: \"(paddr \\<times> paddr) list\" \n  initTimer_impl :: \"unit machine_rest_monad\"\ndefinition\n  initTimer :: \"unit machine_monad\"\nwhere \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts'\n  resetTimer_impl :: \"unit machine_rest_monad\"\n\ndefinition\n  resetTimer :: \"unit machine_monad\"\nwhere \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"\n\nconsts'\n  writeTTBR0_impl :: \"paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeTTBR0 :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere \"writeTTBR0 pd \\<equiv> machine_op_lift (writeTTBR0_impl pd)\"\n\n\nconsts'\n  setHardwareASID_impl :: \"hardware_asid \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setHardwareASID:: \"hardware_asid \\<Rightarrow> unit machine_monad\"\nwhere \"setHardwareASID a \\<equiv> machine_op_lift (setHardwareASID_impl a)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Barrier Operations: Provide mechanisms to enforce memory ordering and synchronization, including instruction stream barriers (ISB), data synchronization barriers (DSB), and data memory barriers (DMB). Additionally, operations are defined to set the current page directory pointer for level 2 translation (PDPL2) and to invalidate local translation lookaside buffer (TLB) entries, either globally or for a specific address space identifier (ASID).",
    "input": "",
    "output": "consts'\n  isb_impl :: \"unit machine_rest_monad\"\ndefinition\n  isb :: \"unit machine_monad\"\nwhere \"isb \\<equiv> machine_op_lift isb_impl\"\n\nconsts'\n  dsb_impl :: \"unit machine_rest_monad\"\ndefinition\n  dsb :: \"unit machine_monad\"\nwhere \"dsb \\<equiv> machine_op_lift dsb_impl\"\n\nconsts'\n  dmb_impl :: \"unit machine_rest_monad\"\ndefinition\n  dmb :: \"unit machine_monad\"\nwhere \"dmb \\<equiv> machine_op_lift dmb_impl\"\n\nconsts'\n  setCurrentPDPL2_impl :: \"paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setCurrentPDPL2 :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere \"setCurrentPDPL2 pd \\<equiv> machine_op_lift (setCurrentPDPL2_impl pd)\"\n\nconsts'\n  invalidateLocalTLB_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB :: \"unit machine_monad\"\nwhere \"invalidateLocalTLB \\<equiv> machine_op_lift invalidateLocalTLB_impl\"\n\n\nconsts'\n  invalidateLocalTLB_ASID_impl :: \"hardware_asid \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB_ASID :: \"hardware_asid \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateLocalTLB_ASID a \\<equiv> machine_op_lift (invalidateLocalTLB_ASID_impl a)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Provide a set of functions to manage and control various aspects of the machine, including cache operations (cleaning, invalidating, and initializing), TLB operations, branch flushing, interrupt handling, and system register access. These operations ensure that the machine state is maintained correctly and efficiently, supporting the overall stability and performance of the system.",
    "input": "",
    "output": "consts'\n  invalidateLocalTLB_VAASID_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB_VAASID :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateLocalTLB_VAASID w \\<equiv> machine_op_lift (invalidateLocalTLB_VAASID_impl w)\"\n\nconsts'\n  cleanByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanByVA w p \\<equiv> machine_op_lift (cleanByVA_impl w p)\"\n\nconsts'\n  cleanByVA_PoU_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanByVA_PoU :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanByVA_PoU w p \\<equiv> machine_op_lift (cleanByVA_PoU_impl w p)\"\n\nconsts'\n  invalidateByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateByVA w p \\<equiv> machine_op_lift (invalidateByVA_impl w p)\"\n\nconsts'\n  invalidateByVA_I_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateByVA_I :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateByVA_I w p \\<equiv> machine_op_lift (invalidateByVA_I_impl w p)\"\n\nconsts'\n  invalidate_I_PoU_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidate_I_PoU :: \"unit machine_monad\"\nwhere \"invalidate_I_PoU \\<equiv> machine_op_lift invalidate_I_PoU_impl\"\n\nconsts'\n  cleanInvalByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanInvalByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanInvalByVA w p \\<equiv> machine_op_lift (cleanInvalByVA_impl w p)\"\n\nconsts'\n  branchFlush_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  branchFlush :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"branchFlush w p \\<equiv> machine_op_lift (branchFlush_impl w p)\"\n\nconsts'\n  clean_D_PoU_impl :: \"unit machine_rest_monad\"\ndefinition\n  clean_D_PoU :: \"unit machine_monad\"\nwhere \"clean_D_PoU \\<equiv> machine_op_lift clean_D_PoU_impl\"\n\nconsts'\n  cleanInvalidate_D_PoC_impl :: \"unit machine_rest_monad\"\ndefinition\n  cleanInvalidate_D_PoC :: \"unit machine_monad\"\nwhere \"cleanInvalidate_D_PoC \\<equiv> machine_op_lift cleanInvalidate_D_PoC_impl\"\n\nconsts'\n  cleanInvalidateL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanInvalidateL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanInvalidateL2Range w p \\<equiv> machine_op_lift (cleanInvalidateL2Range_impl w p)\"\n\nconsts'\n  invalidateL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateL2Range w p \\<equiv> machine_op_lift (invalidateL2Range_impl w p)\"\n\nconsts'\n  cleanL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanL2Range w p \\<equiv> machine_op_lift (cleanL2Range_impl w p)\"\n\nconsts'\n  initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition\n  initL2Cache :: \"unit machine_monad\"\nwhere \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\ndefinition\n  clearExMonitor :: \"unit machine_monad\"\nwhere \"clearExMonitor \\<equiv> modify (\\<lambda>s. s \\<lparr> exclusive_state := default_exclusive_state \\<rparr>)\"\n\nconsts'\n  flushBTAC_impl :: \"unit machine_rest_monad\"\ndefinition\n  flushBTAC :: \"unit machine_monad\"\nwhere \"flushBTAC \\<equiv> machine_op_lift flushBTAC_impl\"\n\nconsts'\n  initIRQController_impl :: \"unit machine_rest_monad\"\ndefinition\n  initIRQController :: \"unit machine_monad\"\nwhere \"initIRQController \\<equiv> machine_op_lift initIRQController_impl\"\n\ndefinition\n  IRQ :: \"irq \\<Rightarrow> irq\"\nwhere \"IRQ \\<equiv> id\"\n\nconsts'\n  writeContextID_impl :: \"unit machine_rest_monad\"\ndefinition\n  writeContextID :: \"unit machine_monad\"\nwhere \"writeContextID \\<equiv> machine_op_lift writeContextID_impl\"\n\nlemmas cache_machine_op_defs = isb_def dsb_def dmb_def writeContextID_def flushBTAC_def\n                               clearExMonitor_def cleanL2Range_def invalidateL2Range_def\n                               cleanInvalidateL2Range_def cleanInvalidate_D_PoC_def\n                               clean_D_PoU_def branchFlush_def cleanInvalByVA_def\n                               invalidate_I_PoU_def invalidateByVA_I_def invalidateByVA_def\n                               cleanByVA_PoU_def cleanByVA_def invalidateLocalTLB_VAASID_def\n                               invalidateLocalTLB_ASID_def invalidateLocalTLB_def\nconsts'\n  IFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  DFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  FAR_val :: \"machine_state \\<Rightarrow> machine_word\"\n\ndefinition\n  getIFSR :: \"machine_word machine_monad\"\n  where \"getIFSR \\<equiv> gets IFSR_val\"\n\ndefinition\n  getDFSR :: \"machine_word machine_monad\"\n  where \"getDFSR \\<equiv> gets DFSR_val\"\n\ndefinition\n  getFAR :: \"machine_word machine_monad\"\n  where \"getFAR \\<equiv> gets FAR_val\"\n\ndefinition\n  debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\"\nwhere\n  debugPrint_def[simp]:\n \"debugPrint \\<equiv> \\<lambda>message. return ()\"\n\nconsts'\n  ackInterrupt_impl :: \"irq \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ackInterrupt irq \\<equiv> machine_op_lift (ackInterrupt_impl irq)\"\n\nconsts'\n  TPIDRURO_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  getTPIDRURO :: \"machine_word machine_monad\"\nwhere \"getTPIDRURO \\<equiv> gets TPIDRURO_val\"\n\nconsts'\n  setTPIDRURO_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setTPIDRURO :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setTPIDRURO w \\<equiv> machine_op_lift (setTPIDRURO_impl w)\"\n\n\\<comment> \\<open>Interrupt controller operations\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Kernel Interrupts: Defines a set of interrupts that are not allowed to occur while the kernel is running but can occur during user mode.",
    "input": "",
    "output": "definition\n  \"non_kernel_IRQs = {irqVGICMaintenance, irqVTimerEvent}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Active IRQ Retrieval: Determines the active interrupt request (IRQ) by updating the IRQ state to reflect the passage of time and checking if the IRQ is masked or in a non-kernel state. If the IRQ is not masked and is in a valid state, it returns the active IRQ; otherwise, it returns None.",
    "input": "",
    "output": "definition\n  getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\nwhere\n  \"getActiveIRQ in_kernel \\<equiv> do\n    is_masked \\<leftarrow> gets $ irq_masks;\n    modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n    active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n    if is_masked active_irq \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n    then return None\n    else return (Some active_irq)\n  od\"\n\ndefinition\n  maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"maskInterrupt m irq \\<equiv>\n  modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition\n  lineStart :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"lineStart addr = (addr >> cacheLineBits) << cacheLineBits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache Operations: Perform operations on cache lines that intersect a specified virtual and physical address range. These operations include cleaning, invalidating, or both, and may involve multiple steps such as cleaning by virtual address, data synchronization barriers (DSB), and L2 cache operations to ensure the coherence and consistency of the cache.",
    "input": "",
    "output": "definition\n  cacheRangeOp :: \"(machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad)\n                 \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cacheRangeOp operation vstart vend pstart \\<equiv>\n    let pend = pstart + (vend - vstart);\n        vptrs = [lineStart vstart, lineStart vstart + of_nat cacheLine .e. lineStart vend];\n        pptrs = [lineStart pstart, lineStart pstart + of_nat cacheLine .e. lineStart pend]\n    in mapM_x (\\<lambda>(v, p). operation v p) (zip vptrs pptrs)\"\n\ndefinition\n  cleanCacheRange_PoC :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoC vstart vend pstart \\<equiv> cacheRangeOp cleanByVA vstart vend pstart\"\n\ndefinition\n  cleanInvalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanInvalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanInvalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp cleanInvalByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  cleanCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanL2Range pstart (pstart + (vend - vstart))\n  od\"\n\ndefinition\n  cleanCacheRange_PoU :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoU vstart vend pstart \\<equiv> cacheRangeOp cleanByVA_PoU vstart vend pstart\"\n\ndefinition\n  invalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    when (vstart \\<noteq> lineStart vstart) $\n        cleanCacheRange_RAM vstart vstart pstart;\n    when (vend + 1 \\<noteq> lineStart (vend + 1)) $\n        cleanCacheRange_RAM (lineStart vend) (lineStart vend)\n           (pstart + ((lineStart vend) - vstart));\n    invalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp invalidateByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  invalidateCacheRange_I :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_I vstart vend pstart \\<equiv> invalidate_I_PoU\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache Management: Perform cache operations to maintain data and instruction coherence. These include flushing specific ranges of the branch cache, cleaning and invalidating data and instruction caches, and ensuring memory barriers (DSB) between operations to synchronize the processor's view of memory.",
    "input": "",
    "output": "definition\n  branchFlushRange :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"branchFlushRange vstart vend pstart \\<equiv> cacheRangeOp branchFlush vstart vend pstart\"\n\ndefinition\n  cleanCaches_PoU :: \"unit machine_monad\"\nwhere\n  \"cleanCaches_PoU \\<equiv> do\n    dsb;\n    clean_D_PoU;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\"\n\ndefinition\n  cleanInvalidateL1Caches :: \"unit machine_monad\"\nwhere\n  \"cleanInvalidateL1Caches \\<equiv> do\n    dsb;\n    cleanInvalidate_D_PoC;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Clearance: Clear the contents of a specified memory region by setting each word to zero, preparing it for reuse as user memory. The operation does not flush the cache.",
    "input": "",
    "output": "text \\<open>Clear memory contents to recycle it as user memory. Do not yet flush the cache.\\<close>\ndefinition\n  clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"clearMemory ptr bytelength \\<equiv>\n    mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"\n\ndefinition\n  clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Initialization: Clear the memory to be used as user memory, ensuring it is properly initialized and ready for use. This includes a call to cleanCacheRange to maintain consistency between the cache and the memory.",
    "input": "",
    "output": "abbreviation (input) \"initMemory == clearMemory\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Clearance: Zero out the memory region specified by the pointer and the number of bits, ensuring that the freed memory contains no garbage and can be safely reused.",
    "input": "",
    "output": "definition\n  freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"freeMemory ptr bits \\<equiv>\n  mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operations: Provides a set of operations to manage and interact with the machine state, including reading and writing various control registers (HSR, HDFAR, SCTLR, HCR, and GIC vCPU control registers), performing address translations, and handling interrupts. These operations ensure that the system can effectively manage hardware resources and maintain the correct state for virtualization and interrupt handling.",
    "input": "",
    "output": "consts'\n  writeContextIDAndPD_impl :: \"hardware_asid \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeContextIDAndPD :: \"hardware_asid \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere \"writeContextIDAndPD a b \\<equiv> machine_op_lift (writeContextIDAndPD_impl a b)\"\n\nconsts'\n  HSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  HDFAR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  SCTLR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  ACTLR_val :: \"machine_state \\<Rightarrow> machine_word\"\n\ndefinition\n  getHSR :: \"machine_word machine_monad\"\nwhere \"getHSR \\<equiv> gets HSR_val\"\n\ndefinition\n  getHDFAR :: \"machine_word machine_monad\"\nwhere \"getHDFAR \\<equiv> gets HDFAR_val\"\n\nconsts'\n  setHCR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setHCR :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setHCR w \\<equiv> machine_op_lift (setHCR_impl w)\"\n\nconsts'\n  addressTranslateS1_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\n  addressTranslateS1_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  addressTranslateS1 :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"addressTranslateS1 w \\<equiv> do\n    machine_op_lift (addressTranslateS1_impl w);\n    gets (addressTranslateS1_val w)\n  od\"\n\ndefinition\n  getSCTLR :: \"machine_word machine_monad\"\nwhere \"getSCTLR \\<equiv> gets SCTLR_val\"\n\nconsts'\n  setSCTLR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setSCTLR :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setSCTLR w \\<equiv> machine_op_lift (setSCTLR_impl w)\"\n\ndefinition\n  vgic_irq_active :: \"machine_word\"\nwhere\n  \"vgic_irq_active \\<equiv> 2 << 28\"\n\ndefinition\n  vgic_irq_mask :: \"machine_word\"\nwhere\n  \"vgic_irq_mask \\<equiv> 3 << 28\"\n\nconsts'\n  gic_vcpu_ctrl_hcr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_hcr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_hcr \\<equiv> gets gic_vcpu_ctrl_hcr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_hcr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_hcr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_hcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_hcr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_vmcr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_vmcr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_vmcr \\<equiv> gets gic_vcpu_ctrl_vmcr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_vmcr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_vmcr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_vmcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vmcr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_apr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_apr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_apr \\<equiv> gets gic_vcpu_ctrl_apr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_apr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_apr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_apr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_apr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_vtr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_vtr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_vtr \\<equiv> gets gic_vcpu_ctrl_vtr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_vtr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_vtr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_vtr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vtr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_misr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_misr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_misr \\<equiv> gets gic_vcpu_ctrl_misr_val\"\n\nconsts'\n  gic_vcpu_ctrl_eisr0_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_eisr0 :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_eisr0 \\<equiv> gets gic_vcpu_ctrl_eisr0_val\"\n\nconsts'\n  gic_vcpu_ctrl_eisr1_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_eisr1 :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_eisr1 \\<equiv> gets gic_vcpu_ctrl_eisr1_val\"\n\nconsts'\n  get_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\n  gic_vcpu_ctrl_lr_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_lr n \\<equiv> do\n      machine_op_lift (get_gic_vcpu_ctrl_lr_impl n);\n      gets (gic_vcpu_ctrl_lr_val n)\n    od\"\n\nconsts'\n  set_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_lr n w  \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_lr_impl n w)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Banked Registers Access: Provides operations to get and set the values of hypervisor banked registers, including `cntv_cval_64`, `cntv_off_64`, and `read_cntpct`. These operations allow for the retrieval and modification of specific 64-bit register values in the machine state.",
    "input": "",
    "output": "consts'\n  cntv_cval_64_val :: \"machine_state \\<Rightarrow> 64 word\"\ndefinition\n  get_cntv_cval_64 :: \"64 word machine_monad\"\nwhere\n  \"get_cntv_cval_64 \\<equiv> gets cntv_cval_64_val\"\n\nconsts'\n  set_cntv_cval_64_impl :: \"64 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_cntv_cval_64 :: \"64 word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_cntv_cval_64 w \\<equiv> machine_op_lift (set_cntv_cval_64_impl w)\"\n\nconsts'\n  cntv_off_64_val :: \"machine_state \\<Rightarrow> 64 word\"\ndefinition\n  get_cntv_off_64 :: \"64 word machine_monad\"\nwhere\n  \"get_cntv_off_64 \\<equiv> gets cntv_off_64_val\"\n\nconsts'\n  set_cntv_off_64_impl :: \"64 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_cntv_off_64 :: \"64 word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_cntv_off_64 w \\<equiv> machine_op_lift (set_cntv_off_64_impl w)\"\n\nconsts'\n  read_cntpct_val :: \"machine_state \\<Rightarrow> 64 word\"\ndefinition\n  read_cntpct :: \"64 word machine_monad\"\nwhere\n  \"read_cntpct \\<equiv> gets read_cntpct_val\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Banked Registers Access: Provides mechanisms to read and write hardware registers specific to a virtual CPU (vCPU) in the machine state. Reading a vCPU hardware register retrieves its current value, while writing updates the register with a new value.",
    "input": "",
    "output": "consts'\n  vcpuHardwareReg_val :: \"vcpureg \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  readVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"readVCPUHardwareReg reg \\<equiv> gets (vcpuHardwareReg_val reg)\"\n\nconsts'\n  writeVCPUHardwareReg_impl :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"writeVCPUHardwareReg reg val \\<equiv> machine_op_lift (writeVCPUHardwareReg_impl reg val)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "User Register Management: Provides operations to get and set the values of user-level registers, including getting the restart program counter and setting the next program counter, allowing for the manipulation and control of the user context.",
    "input": "",
    "output": "type_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ndatatype user_context = UserContext (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\ndefinition getRegister :: \"register \\<Rightarrow> machine_word user_monad\" where\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition modify_registers :: \"(user_regs \\<Rightarrow> user_regs) \\<Rightarrow> user_context \\<Rightarrow> user_context\" where\n  \"modify_registers f uc \\<equiv> UserContext (f (user_regs uc))\"\n\ndefinition setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\" where\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext ((user_regs s) (r := v)))\"\n\ndefinition\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition\n  \"setNextPC \\<equiv> setRegister NextIP\"\n\nend\n\ntranslations\n  (type) \"'a ARM_HYP.user_monad\" <= (type) \"(ARM_HYP.register \\<Rightarrow> machine_word, 'a) nondet_monad\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Integer Literal Representation: Defines the representation of C integer literals as 32-bit signed words.",
    "input": "",
    "output": "(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define and specify the bit lengths and sizes for IRQs, physical addresses, page colors, and cache lines. These constants ensure consistent and predictable behavior of the platform-specific hardware features.",
    "input": "",
    "output": "context Arch begin global_naming ARM_HYP\n\nvalue_type irq_len = Kernel_Config.irqBits (* IRQ_CNODE_SLOT_BITS *)\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = word32\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\ndefinition pageColourBits :: nat where\n  \"pageColourBits \\<equiv> 2\"\n\ndefinition cacheLineBits :: nat where\n  \"cacheLineBits = CONFIG_L1_CACHE_LINE_SIZE_BITS\"\n\ndefinition cacheLine :: nat where\n  \"cacheLine = 2^cacheLineBits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define the base and top addresses for physical and virtual memory, as well as offsets and conversions between them. Additionally, specify specific IRQ values for system interrupts.",
    "input": "",
    "output": "definition pptrBase :: word32 where\n  \"pptrBase \\<equiv> 0xe0000000\"\n\nabbreviation (input) \"paddrBase \\<equiv> physBase\"\n\ndefinition pptrBaseOffset :: machine_word where\n  \"pptrBaseOffset = pptrBase - paddrBase\"\n\ndefinition pptrTop :: \"32 word\" where\n  \"pptrTop \\<equiv> 0xfff00000\"\n\ndefinition paddrTop :: \"32 word\" where\n  \"paddrTop \\<equiv> pptrTop - pptrBaseOffset\"\n\ndefinition kernelELFPAddrBase :: word32 where\n  \"kernelELFPAddrBase \\<equiv> physBase\"\n\ndefinition kernelELFBase :: word32 where\n  \"kernelELFBase \\<equiv> pptrBase + (kernelELFPAddrBase && mask 22)\"\n\ndefinition kernelELFBaseOffset :: word32 where\n  \"kernelELFBaseOffset \\<equiv> kernelELFBase - kernelELFPAddrBase\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> word32\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"word32 \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"word32 \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr kpptr \\<equiv> kpptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition irqVGICMaintenance :: \"irq\" where\n  \"irqVGICMaintenance \\<equiv> 25\"\n\ndefinition irqVTimerEvent :: \"irq\" where\n  \"irqVTimerEvent  \\<equiv> 27\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constraints: Define and enforce architectural-specific constraints on kernel configurations, ensuring that the system adheres to the requirements and limitations of the ARM_HYP architecture.",
    "input": "",
    "output": "(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming ARM_HYP",
    "system": "",
    "history": []
  },
  {
    "instruction": "Physical Base Alignment: The physical base address is aligned to a 25-bit boundary, ensuring proper alignment for memory operations.",
    "input": "",
    "output": "lemma physBase_aligned:\n  \"is_aligned physBase 25\"\n  by (simp add: is_aligned_def Kernel_Config.physBase_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value: The maximum IRQ value is less than \\(2^{irqBits}\\), ensuring that the system can handle a defined range of interrupts without exceeding the allocated bits for IRQ representation. Additionally, the virtual timer event IRQ is guaranteed to be within the range of the maximum IRQ value.",
    "input": "",
    "output": "lemma irqVTimerEvent_le_maxIRQ[simp, intro!]:\n  \"irqVTimerEvent \\<le> maxIRQ\"\n  by (simp add: irqVTimerEvent_def Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_less_2p_irqBits:\n  \"(maxIRQ::nat) < 2^irqBits\"\n  by (simp add: Kernel_Config.maxIRQ_def Kernel_Config.irqBits_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Length and Maximum IRQ Value: The length of the IRQ representation is defined by `irqBits`, and the maximum IRQ value is less than \\(2^{irqBits}\\). Additionally, the unsigned integer representation of \\(2^{irqBits}\\) as a machine word is equal to \\(2^{irqBits}\\).",
    "input": "",
    "output": "lemma LENGTH_irq_len_irqBits[simp]: (* [simp] will fire only for simp del: len_of_numeral_defs *)\n  \"LENGTH(irq_len) = irqBits\"\n  using irq_len_def irq_len_val\n  by simp\n\nlemma maxIRQ_less_2p_irq_len:\n  \"(maxIRQ::nat) < 2^LENGTH(irq_len)\"\n  using maxIRQ_less_2p_irqBits\n  by (simp del: len_of_numeral_defs)\n\nlemma unat_2p_irqBits_machine[simp]:\n  \"unat (2 ^ irqBits :: machine_word) = 2 ^ irqBits\"\n  by (simp add: Kernel_Config.irqBits_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value Conversion: The maximum interrupt request (IRQ) value can be converted to a word of any length without loss of information, ensuring consistency in numeric representations.",
    "input": "",
    "output": "lemma of_nat_maxIRQ[simp]:\n  \"of_nat maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma of_int_maxIRQ[simp]:\n  \"of_int maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unat Conversion for maxIRQ: Ensures that the conversion of `maxIRQ` to its natural number representation using `unat` is safe and equivalent to `maxIRQ` itself, provided that the length of `irq_len` is less than or equal to the bit length of the word type.",
    "input": "",
    "output": "lemma unat_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> unat (maxIRQ::'a word) = maxIRQ\"\n  by (metis maxIRQ_less_2p_irq_len Word.of_nat_unat of_nat_inverse of_nat_maxIRQ unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Uint Conversion for maxIRQ: Ensures that the conversion of `maxIRQ` to its unsigned integer representation is safe and retains the original value, provided that the length of `irq_len` does not exceed the bit width of the word type.",
    "input": "",
    "output": "lemma uint_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> uint (maxIRQ::'a word) = maxIRQ\"\n  by (metis Kernel_Config.maxIRQ_def of_nat_numeral uint_nat unat_maxIRQ)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Property: Ucast Preservation of maxIRQ: The value of `maxIRQ` is preserved under unsigned casting between types, provided the target type has a bit length greater than or equal to the bit length of `irq_len`.",
    "input": "",
    "output": "lemma ucast_maxIRQ[simp]:\n  \"\\<lbrakk> LENGTH(irq_len) \\<le> LENGTH('a::len); LENGTH(irq_len) \\<le> LENGTH('b::len) \\<rbrakk> \\<Longrightarrow>\n   UCAST ('a \\<rightarrow> 'b) maxIRQ = maxIRQ\"\n  by (metis of_nat_maxIRQ ucast_nat_def unat_maxIRQ)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Comparison: Ensures that the comparison between the maximum IRQ value and an upcasted IRQ value remains consistent, provided the length of the upcasted word is greater than or equal to the length of the original IRQ type.",
    "input": "",
    "output": "lemma maxIRQ_less_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   (maxIRQ < (ucast irq :: 'a word)) = (maxIRQ < irq)\" for irq::irq\n  by (simp add: word_less_nat_alt unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Property: \nIRQ Upcasting Safety: Ensures that upcasting an IRQ to a larger word size does not change the comparison result with the maximum IRQ value, maintaining the safety and correctness of IRQ handling.",
    "input": "",
    "output": "lemma maxIRQ_le_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   ((ucast irq :: 'a word) \\<le> Kernel_Config.maxIRQ) = (irq \\<le> Kernel_Config.maxIRQ)\" for irq::irq\n  by (simp add: word_le_nat_alt unat_ucast_up_simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ and Machine Word Properties: These lemmas establish relationships and constraints between the maximum IRQ value, machine words, and their representations. They ensure that values within the defined range for IRQs are correctly cast, compared, and manipulated, maintaining consistency and correctness in the system's handling of interrupts and related operations.",
    "input": "",
    "output": "lemma le_maxIRQ_machine_less_irqBits_val[simplified]:\n  \"w \\<le> maxIRQ \\<Longrightarrow> unat w < 2^LENGTH(irq_len)\" for w::machine_word\n  using maxIRQ_less_2p_irq_len\n  by (simp add: word_le_nat_alt)\n\nlemma irq_machine_le_maxIRQ_irq:\n  \"irq \\<le> Kernel_Config.maxIRQ \\<Longrightarrow> (ucast irq::irq) \\<le> maxIRQ\" for irq::machine_word\n  by (simp add: Kernel_Config.maxIRQ_def word_le_nat_alt unat_ucast)\n\nlemma maxIRQ_eq_ucast_irq_32_signed_uint:\n  \"(maxIRQ = (ucast b :: 32 signed word)) = (uint b = maxIRQ)\" for b::irq\n  unfolding Kernel_Config.maxIRQ_def\n  apply uint_arith\n  apply (simp add: uint_up_ucast is_up)\n  done\n\nlemma sint_maxIRQ_32[simp]:\n  \"sint (maxIRQ :: 32 signed word) = maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_machine[simp]:\n  \"scast (maxIRQ::32 signed word) = (maxIRQ::machine_word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_irq[simp]:\n  \"scast (maxIRQ :: 32 signed word) = (maxIRQ::irq)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_machine:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = x\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_irq:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = (ucast x :: irq)\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_1_plus_eq_Suc_machine[simp]:\n  \"unat (1 + maxIRQ :: machine_word) = Suc Kernel_Config.maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_le_mask_irq_len:\n  \"x \\<le> maxIRQ \\<longrightarrow> x \\<le> mask irq_len\" for x :: machine_word\n  using le_maxIRQ_machine_less_irqBits_val\n  by (fastforce simp add: word_le_nat_alt word_less_nat_alt irq_len_val mask_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cache Line Bits Sanity: The value of `cacheLineBits` must be within the range of 2 to 12, ensuring it is suitable for use in cache operations and does not conflict with other values.",
    "input": "",
    "output": "lemma cacheLineBits_sanity:\n  \"cacheLineBits \\<in> {2..12}\"\n  by (simp add: cacheLineBits_def Kernel_Config.CONFIG_L1_CACHE_LINE_SIZE_BITS_def)\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Direct Caps Update: The direct capabilities of a state are updated by replacing the capabilities associated with a specific entity. If the entity is `None`, the capabilities are set to an empty set; if the entity is `Some (Entity c)`, the capabilities are set to `c`. This ensures that the direct capabilities reflect the current state of entities accurately.",
    "input": "",
    "output": "theory Example2\nimports Isolation_S\nbegin\n\nlemma direct_caps_of_update [simp]:\n  \"direct_caps_of (s(x := y)) =\n  (direct_caps_of s)(x:= case y of None \\<Rightarrow> {} | Some (Entity c) \\<Rightarrow> c)\"\n  by (rule ext, simp add: direct_caps_of_def split:option.splits)\n\nlemma direct_caps_of_empty [simp]:\n  \"direct_caps_of Map.empty = ( \\<lambda> x. {})\"\n  by (simp add: direct_caps_of_def fun_eq_iff)\n\ndefinition \"id\\<^sub>0 \\<equiv> 0\"\ndefinition \"id\\<^sub>1 \\<equiv> 1\"\ndefinition \"id\\<^sub>2 \\<equiv> 2\"\ndefinition \"id\\<^sub>3 \\<equiv> 3\"\ndefinition \"id\\<^sub>4 \\<equiv> 4\"\ndefinition \"id\\<^sub>5 \\<equiv> 5\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity and Capability Management: The system allows the creation, granting, revoking, and removal of capabilities for entities. Entity 0 (e0) initially has full rights to itself and the ability to create capabilities for all of memory. Through a series of operations, the system can manage and modify the capabilities of different entities, ensuring that each entity has the appropriate set of rights and permissions.",
    "input": "",
    "output": "definition\n  e0_caps :: \"cap set\"\nwhere\n  \"e0_caps \\<equiv> range create_cap \\<union> {full_cap 0}\"\n\ndefinition\n  s0  :: \"state\"\nwhere\n  \"s0  \\<equiv> [0 \\<mapsto> Entity e0_caps]\"\n\ndefinition\n  s1  :: \"state\"\nwhere\n  \"s1  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> null_entity]\"\n\ndefinition\n  s2  :: \"state\" where\n  \"s2  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> Entity {create_cap 2}]\"\n\ndefinition\n  s3  :: \"state\" where\n  \"s3  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>}]\"\n\ndefinition\n  s4  :: \"state\" where\n  \"s4  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity]\"\n\ndefinition\n  s5  :: \"state\" where\n  \"s5  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1, write_cap 2}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity]\"\n\ndefinition\n  s6  :: \"state\" where\n  \"s6  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1, write_cap 2}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2, read_cap 2},\n          2 \\<mapsto> null_entity]\"\n\ndefinition\n  s7  :: \"state\" where \"s7  \\<equiv> s4\"\n\ndefinition\n  s8  :: \"state\" where\n  \"s8  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1, full_cap 3}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity,\n          3 \\<mapsto> null_entity]\"\n\ndefinition\n  s9  :: \"state\" where\n  \"s9  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity,\n          3 \\<mapsto> null_entity]\"\n\ndefinition\n  s10 :: \"state\" where \"s10 \\<equiv> s4\"\n\ndefinition\n  s   :: \"state\" where\n  \"s   \\<equiv> [0 \\<mapsto> Entity (e0_caps - {create_cap 1, create_cap 2}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity]\"\n\ndefinition\n  op0  :: \"sysOPs\" where\n  \"op0  \\<equiv> SysCreate  0 (full_cap 0) (create_cap 1)\"\ndefinition\n  op1  :: \"sysOPs\" where\n  \"op1  \\<equiv> SysGrant   0 (full_cap 1) (create_cap 2) UNIV\"\ndefinition\n  op2  :: \"sysOPs\" where\n  \"op2  \\<equiv> SysGrant   0 (full_cap 1) (full_cap   1) {Write, Store}\"\ndefinition\n  op3  :: \"sysOPs\" where\n  \"op3  \\<equiv> SysCreate  1 \\<lparr>target = 1, rights = {Write, Store}\\<rparr> (create_cap 2)\"\ndefinition\n  op4  :: \"sysOPs\" where\n  \"op4  \\<equiv> SysTake    0 (full_cap 1) (full_cap   2) {Write}\"\ndefinition\n  op5  :: \"sysOPs\" where\n  \"op5  \\<equiv> SysCopy    1 \\<lparr>target = 1, rights = {Write, Store}\\<rparr> (full_cap   2) {Read}\"\ndefinition\n  op6  :: \"sysOPs\" where\n  \"op6  \\<equiv> SysRevoke  0 (write_cap 2)\"\ndefinition\n  op7  :: \"sysOPs\" where\n  \"op7  \\<equiv> SysCreate  0 (full_cap 0) (create_cap 3)\"\ndefinition\n  op8  :: \"sysOPs\" where\n  \"op8  \\<equiv> SysRemove  0 (full_cap 0) (full_cap 3)\"\ndefinition\n  op9  :: \"sysOPs\" where\n  \"op9  \\<equiv> SysDestroy  0 (create_cap 3)\"\ndefinition\n  op10 :: \"sysOPs\" where\n  \"op10 \\<equiv> SysRemoveSet 0 (full_cap 0) {full_cap 1, create_cap 1, create_cap 2}\"\n\ndefinition ops :: \"sysOPs list\" where",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Sequence: Define a sequence of operations, excluding op6 and op5, to be used in the system.",
    "input": "",
    "output": "\"ops \\<equiv> [op10, op9, op8, op7, op3, op2, op1, op0]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity Existence: The lemmas define the existence of entities in different states, where certain states contain specific entities and others do not. For each state \\( s_i \\), the lemmas specify whether an entity \\( e_j \\) exists or not.",
    "input": "",
    "output": "lemma is_entity_s0_e0 [simp]:\n  \"is_entity s0 0\"\n  by (simp add: is_entity_def s0_def)\n\nlemma is_entity_s1_e0 [simp]:\n  \"is_entity s1 0\"\n  by (simp add: is_entity_def s1_def)\n\nlemma is_entity_s2_e0 [simp]:\n  \"is_entity s2 0\"\n  by (simp add: is_entity_def s2_def)\n\nlemma is_entity_s3_e0 [simp]:\n  \"is_entity s3 0\"\n  by (simp add: is_entity_def s3_def)\n\nlemma is_entity_s4_e0 [simp]:\n  \"is_entity s4 0\"\n  by (simp add: is_entity_def s4_def)\n\nlemma is_entity_s5_e0 [simp]:\n  \"is_entity s5 0\"\n  by (simp add: is_entity_def s5_def)\n\nlemma is_entity_s6_e0 [simp]:\n  \"is_entity s6 0\"\n  by (simp add: is_entity_def s6_def)\n\nlemma is_entity_s8_e0 [simp]:\n  \"is_entity s8 0\"\n  by (simp add: is_entity_def s8_def)\n\nlemma is_entity_s9_e0 [simp]:\n  \"is_entity s9 0\"\n  by (simp add: is_entity_def s9_def)\n\nlemma is_entity_s_e0 [simp]:\n  \"is_entity s 0\"\n  by (simp add: is_entity_def s_def)\n\n\nlemma is_entity_s0_e1 [simp]:\n  \"\\<not> is_entity s0 1\"\n  by (simp add: is_entity_def s0_def)\n\nlemma is_entity_s1_e1 [simp]:\n  \"is_entity s1 1\"\n  by (simp add: is_entity_def s1_def)\n\nlemma is_entity_s2_e1 [simp]:\n  \"is_entity s2 1\"\n  by (simp add: is_entity_def s2_def)\n\nlemma is_entity_s3_e1 [simp]:\n  \"is_entity s3 1\"\n  by (simp add: is_entity_def s3_def)\n\nlemma is_entity_s4_e1 [simp]:\n  \"is_entity s4 1\"\n  by (simp add: is_entity_def s4_def)\n\nlemma is_entity_s5_e1 [simp]:\n  \"is_entity s5 1\"\n  by (simp add: is_entity_def s5_def)\n\n\nlemma is_entity_s3_e2 [simp]:\n  \"\\<not> is_entity s3 2\"\n  by (simp add: is_entity_def s3_def)\n\nlemma is_entity_s4_e3 [simp]:\n  \"\\<not> is_entity s4 3\"\n  by (simp add: is_entity_def s4_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Direct and Indirect Capabilities: The lemmas define the direct and indirect capabilities associated with different states (s0, s1, s2, etc.) and their respective indices. Each state has a specific set of capabilities, which may include full, create, and write/store rights, and these capabilities are combined or extended in subsequent states.",
    "input": "",
    "output": "lemma direct_caps_of_s0_e0_caps [simp]:\n  \"direct_caps_of s0 0 = e0_caps\"\n  by (simp add: direct_caps_of_def s0_def e0_caps_def)\n\nlemma direct_caps_of_s1_e0_caps [simp]:\n  \"direct_caps_of s1 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s1_def e0_caps_def)\n\nlemma direct_caps_of_s2_e0_caps [simp]:\n  \"direct_caps_of s2 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s2_def e0_caps_def)\n\nlemma direct_caps_of_s4_e0_caps [simp]:\n  \"direct_caps_of s4 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s4_def e0_caps_def)\n\nlemma direct_caps_of_s5_e0_caps [simp]:\n  \"direct_caps_of s5 0 = e0_caps \\<union> {full_cap 1, write_cap 2}\"\n  by (simp add: direct_caps_of_def s5_def e0_caps_def)\n\nlemma direct_caps_of_s6_e0_caps [simp]:\n  \"direct_caps_of s6 0 = e0_caps \\<union> {full_cap 1, write_cap 2}\"\n  by (simp add: direct_caps_of_def s6_def e0_caps_def)\n\nlemma direct_caps_of_s8_e0_caps [simp]:\n  \"direct_caps_of s8 0 = e0_caps \\<union> {full_cap 1, full_cap 3}\"\n  by (simp add: direct_caps_of_def s8_def e0_caps_def)\n\nlemma direct_caps_of_s9_e0_caps [simp]:\n  \"direct_caps_of s9 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s9_def e0_caps_def)\n\n\nlemma direct_caps_of_s2_e1 [simp]:\n  \"direct_caps_of s2 1 = {create_cap 2}\"\n  by (simp add: direct_caps_of_def s2_def)\n\nlemma direct_caps_of_s3_e1 [simp]:\n  \"direct_caps_of s3 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>}\"\n  by (simp add: direct_caps_of_def s3_def)\n\nlemma direct_caps_of_s4_e1 [simp]:\n  \"direct_caps_of s4 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s4_def)\n\nlemma direct_caps_of_s6_e1 [simp]:\n  \"direct_caps_of s5 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s5_def)\n\nlemma direct_caps_of_s9_e1 [simp]:\n  \"direct_caps_of s9 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s9_def)\n\n\nlemma full_cap_e0_caps_in_caps_of_s0_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s0 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e1_in_caps_of_s1_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s1 0\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e1_in_caps_of_s2_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s2 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e0_caps_in_caps_of_s4_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e1_in_caps_of_s4_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e2_in_caps_of_s4_e1 [simp]:\n  \"full_cap 2 \\<in> caps_of s4 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e1_in_caps_of_s5_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s5 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e2_in_caps_of_s5_e0_caps [simp]:\n  \"full_cap 2 \\<in> caps_of s5 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e0_caps_in_caps_of_s8_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s8 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s0_e0_caps [simp]:\n  \"create_cap i \\<in> caps_of s0 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s1_e0_caps [simp]:\n  \"create_cap i \\<in> caps_of s1 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s2_e1 [simp]:\n  \"create_cap 2 \\<in> caps_of s2 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma create_cap_in_caps_of_s3_e1 [simp]:\n  \"create_cap 2 \\<in> caps_of s3 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma create_cap_in_caps_of_s4_e3 [simp]:\n  \"create_cap 3 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s9_e3 [simp]:\n  \"create_cap 3 \\<in> caps_of s9 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma write_store_e1_in_caps_of_s3_e1 [simp]:\n  \"\\<lparr>target = 1, rights = {Write, Store}\\<rparr>  \\<in> caps_of s3 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma write_store_e1_in_caps_of_s5_e1 [simp]:\n  \"\\<lparr>target = 1, rights = {Write, Store}\\<rparr> \\<in> caps_of s5 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma write_cap_e2_in_caps_of_s6_e0_caps [simp]:\n  \"write_cap 2 \\<in> caps_of s6 0\"\n  by (rule direct_cap_in_cap, simp)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Execution: The operation `op0` is legal and its execution from state `s0` results in either the original state `s0` or a new state `s1`.",
    "input": "",
    "output": "lemma op0_legal:\n  \"legal op0 s0\"\n  by  (clarsimp simp: op0_def all_rights_def)\n\nlemma execute_op0_safe:\n  \"step op0 s0 \\<subseteq> ({s0, s1})\"\n  by (fastforce simp: op0_def step_def createOperation_def s0_def s1_def\n                 split: if_split_asm)\n\nlemma execute_op0_live:\n  \"step op0 s0 \\<supseteq> ({s0, s1})\"\n  apply clarsimp\n  apply (rule conjI)\n   apply (simp add: step_def)\n  apply (simp add: step_def op0_legal)\n  apply (rule disjI2)\n  apply (clarsimp simp: op0_def createOperation_def)\n  apply (rule ext)\n  apply (clarsimp simp: s0_def s1_def)\n  done\n\nlemma execute_op0:\n  \"step op0 s0 = ({s0, s1})\"\n  apply rule\n   apply (rule execute_op0_safe)\n  apply (rule execute_op0_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Execution: The operation `op1` is legal and its execution from state `s1` results in a state transition to either `s1` or `s2`. This ensures that the operation is both safe and live, maintaining the integrity and consistency of the system states.",
    "input": "",
    "output": "lemma op1_legal:\n  \"legal op1 s1\"\n  by  (clarsimp simp: op1_def all_rights_def)\n\nlemma execute_op1_safe:\n  \"step op1 s1 \\<subseteq> ({s1, s2})\"\n  by (clarsimp simp: op1_def step_def grantOperation_def diminish_def\n                     s1_def s2_def create_cap_def null_entity_def\n              split: if_split_asm)\n\nlemma execute_op1_live:\n  \"step op1 s1 \\<supseteq> ({s1, s2})\"\n  apply clarsimp\n  apply (rule conjI)\n   apply (simp add: step_def)\n  apply (simp add: step_def op1_legal)\n  apply (rule disjI2)\n  apply (clarsimp simp: op1_def grantOperation_def)\n  apply (rule ext)\n  apply (clarsimp simp: s1_def s2_def null_entity_def)\n  done\n\nlemma execute_op1:\n  \"step op1 s1 = ({s1, s2})\"\n  apply rule\n   apply (rule execute_op1_safe)\n  apply (rule execute_op1_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Execution Safety and Liveness: The operation `op2` is legal and its execution from state `s2` results in a transition to either state `s2` or state `s3`, ensuring both safety and liveness.",
    "input": "",
    "output": "lemma op2_legal:\n  \"legal op2 s2\"\n  by  (clarsimp simp: op2_def all_rights_def)\n\nlemma execute_op2_safe:\n  \"step op2 s2 \\<subseteq> ({s2, s3})\"\n  apply clarsimp\n  apply (rule ext)\n  apply (auto simp: op2_def step_def grantOperation_def diminish_def s2_def s3_def full_cap_def all_rights_def\n             split: if_split_asm)\n  done\n\nlemma execute_op2_live:\n  \"step op2 s2 \\<supseteq> ({s2, s3})\"\n  apply clarsimp\n  apply (simp add: step_def op2_legal)\n  apply (rule disjI2)\n  apply (simp add: op2_def)\n  apply (rule ext)\n  apply (fastforce simp: s2_def s3_def grantOperation_def diminish_def all_rights_def full_cap_def)\n  done\n\nlemma execute_op2:\n  \"step op2 s2 = ({s2, s3})\"\n  apply rule\n   apply (rule execute_op2_safe)\n  apply (rule execute_op2_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Execution: The operation `op3` is legal and its execution from state `s3` results in a transition to either state `s3` or state `s4`. This ensures that the operation is both safe and live, maintaining the integrity and predictability of the system's state transitions.",
    "input": "",
    "output": "lemma op3_legal:\n  \"legal op3 s3\"\n  by  (clarsimp simp: op3_def all_rights_def)\n\nlemma execute_op3_safe:\n  \"step op3 s3 \\<subseteq> ({s3, s4})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: op3_def step_def createOperation_def s3_def s4_def\n             split: if_split_asm)\n  done\n\nlemma execute_op3_live:\n  \"step op3 s3 \\<supseteq> ({s3, s4})\"\n  apply clarsimp\n  apply (simp add: step_def op3_legal)\n  apply (rule disjI2)\n  apply (clarsimp simp: op3_def createOperation_def)\n  apply (rule ext)\n  apply (fastforce simp: s3_def s4_def)\n  done\n\nlemma execute_op3:\n  \"step op3 s3 = ({s3, s4})\"\n  apply rule\n   apply (rule execute_op3_safe)\n  apply (rule execute_op3_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "SysTake Operation: The operation `op4` is legal and its execution transitions the system state from `s4` to either `s4` or `s5`, ensuring that the system remains in a valid state.",
    "input": "",
    "output": "lemma op4_legal:\n  \"legal op4 s4\"\n  by  (clarsimp simp: op4_def all_rights_def)\n\nlemma execute_op4_safe:\n  \"step op4 s4 \\<subseteq> ({s4, s5})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s4_def s5_def op4_def step_def takeOperation_def\n                    diminish_def all_rights_def write_cap_def\n             split: if_split_asm)\n  done\n\nlemma execute_op4_live:\n  \"step op4 s4 \\<supseteq> ({s4, s5})\"\n  apply clarsimp\n  apply (simp add: op4_legal step_def)\n  apply (rule disjI2)\n  apply (simp add: op4_def)\n  apply (rule ext)\n  apply (fastforce simp: s4_def s5_def takeOperation_def diminish_def all_rights_def write_cap_def)\n  done\n\nlemma execute_op4:\n  \"step op4 s4 = ({s4, s5})\"\n  apply rule\n   apply (rule execute_op4_safe)\n  apply (rule execute_op4_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "SysCopy Operation: The operation `op5` is legal and, when executed, transitions the system state from `s5` to either `s5` or `s6`. This ensures that the system remains in a valid state after the copy operation, maintaining the integrity and consistency of the system.",
    "input": "",
    "output": "lemma op5_legal:\n  \"legal op5 s5\"\n  by  (clarsimp simp: op5_def all_rights_def)\n\nlemma execute_op5_safe:\n  \"step op5 s5 \\<subseteq> ({s5, s6})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s5_def s6_def op5_def step_def copyOperation_def diminish_def all_rights_def read_cap_def\n             split: if_split_asm)\n  done\n\nlemma execute_op5_live:\n  \"step op5 s5 \\<supseteq> ({s5, s6})\"\n  apply clarsimp\n  apply (simp add: step_def op5_legal)\n  apply (rule disjI2)\n  apply (simp add: op5_def)\n  apply (rule ext)\n  apply (fastforce simp: s5_def s6_def copyOperation_def diminish_def all_rights_def read_cap_def)\n  done\n\nlemma execute_op5:\n  \"step op5 s5 = ({s5, s6})\"\n  apply rule\n   apply (rule execute_op5_safe)\n  apply (rule execute_op5_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "SysRevoke Operation: The operation `op6` is legal and, when executed, transitions the system state from `s6` to a set of states that includes `s6` and `s7`. This ensures that the revocation of a capability is performed safely and maintains the integrity of the system.",
    "input": "",
    "output": "lemma op6_legal:\n  \"legal op6 s6\"\n  by  (clarsimp simp: op6_def all_rights_def)\n\nlemma execute_op6_safe:\n  \"step op6 s6 \\<subseteq> ({s6, s7})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s6_def s7_def s4_def op7_def step_def revokeOperation_def\n          split: if_split_asm)\n  oops\n\nlemma execute_op6_live:\n  \"step op6 s6 \\<supseteq> ({s6, s7})\"\n  apply (insert op6_legal)\n  oops (*\n  apply (auto simp: step_def op6_legal op6_def s6_def s7_def s4_def revokeOperation_def fun_eq_iff)\n  done*)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Step Execution: The execution of operation `op6` from state `s6` results in a transition to a set of possible states, including `s6` and `s7`.",
    "input": "",
    "output": "lemma execute_op6_live:\n  \"s7 \\<in> step op6 s6\"\n  oops\n\nlemma execute_op6:\n  \"step op6 s6 = ({s6, s7})\"\n  oops",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Execution: The execution of operation `op7` in state `s7` results in either the original state `s7` or a new state `s8`. This ensures that the operation is both safe and live, maintaining the integrity and consistency of the system.",
    "input": "",
    "output": "lemma op7_legal:\n  \"legal op7 s7\"\n  by  (clarsimp simp: s7_def op7_def all_rights_def)\n\nlemma execute_op7_safe:\n  \"step op7 s7 \\<subseteq> ({s7, s8})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s7_def s8_def s4_def op7_def step_def createOperation_def\n             split: if_split_asm)\n  done\n\nlemma execute_op7_live:\n  \"step op7 s7 \\<supseteq> ({s7, s8})\"\n  apply clarsimp\n  apply (simp add: step_def op7_legal)\n  apply (rule disjI2)\n  apply (simp add: op7_def)\n  apply (rule ext)\n  apply (fastforce simp: s7_def s8_def s4_def createOperation_def)\n  done\n\nlemma execute_op7:\n  \"step op7 s7 = ({s7, s8})\"\n  apply rule\n   apply (rule execute_op7_safe)\n  apply (rule execute_op7_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Execution: The operation `op8` is legal and its execution on state `s8` results in a transition to either state `s8` or state `s9`.",
    "input": "",
    "output": "lemma op8_legal:\n  \"legal op8 s8\"\n  by  (clarsimp simp: op8_def)\n\nlemma execute_op8_safe:\n  \"step op8 s8 \\<subseteq> ({s8, s9})\"\n  apply clarsimp\n  apply (rule ext)\n  apply (insert op8_legal)\n  apply (fastforce simp: step_def op8_def s8_def s9_def removeOperation_def\n                        full_cap_def create_cap_def all_rights_def e0_caps_def)\n  done\n\nlemma execute_op8_live:\n  \"step op8 s8 \\<supseteq> ({s8, s9})\"\n  apply (simp add: step_def op8_legal op8_def)\n  apply (rule disjI2)\n  apply (rule ext)\n  apply (clarsimp simp: removeOperation_def)\n  apply (fastforce simp: s8_def s9_def full_cap_def create_cap_def all_rights_def e0_caps_def)\n  done\n\nlemma execute_op8:\n  \"step op8 s8 = ({s8, s9})\"\n  apply rule\n   apply (rule execute_op8_safe)\n  apply (rule execute_op8_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Safety and Liveness: The operation `op9` is legal and its execution from state `s9` results in a transition to either state `s9` or `s10`, ensuring both safety and liveness.",
    "input": "",
    "output": "lemma op9_legal:\n  \"legal op9 s9\"\n  apply (simp add: op9_def)\n  apply (fastforce simp: s9_def e0_caps_def null_entity_def split:if_split_asm)\n  done\n\nlemma execute_op9_safe:\n  \"step op9 s9 \\<subseteq> ({s9, s10})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s9_def s10_def s4_def op9_def step_def destroyOperation_def\n             split: if_split_asm)\n  done\n\nlemma execute_op9_live:\n  \"step op9 s9 \\<supseteq> ({s9, s10})\"\n  apply (simp add: step_def op9_legal)\n  apply (rule disjI2)\n  apply (simp add: op9_def)\n  apply (rule ext)\n  apply (clarsimp simp: destroyOperation_def step_def op9_def s9_def s10_def s4_def)\n  done\n\nlemma execute_op9:\n  \"step op9 s9 = ({s9, s10})\"\n  apply rule\n   apply (rule execute_op9_safe)\n  apply (rule execute_op9_live)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Operation Safety and Liveness: The operation `op10` is legal and its execution from state `s10` results in a transition to either the same state `s10` or a new state `s`. This ensures that the system maintains safety and liveness, guaranteeing that the operation does not lead to an undefined or inconsistent state.",
    "input": "",
    "output": "lemma op10_legal:\n  \"legal op10 s10\"\n  by  (clarsimp simp: s10_def op10_def all_rights_def)\n\nlemma e0_caps_diminished [simp]:\n  \"e0_caps - {full_cap 1, create_cap 1, create_cap 2} = e0_caps - {create_cap 1, create_cap 2}\"\n  by (fastforce simp: e0_caps_def create_cap_def full_cap_def all_rights_def)\n\n\nlemma execute_op10_safe:\n  \"step op10 s10 \\<subseteq> ({s10, s})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s10_def op10_def step_def removeSetOperation_def s4_def s_def\n              split: if_split_asm)\n  done\n\nlemma execute_op10_live:\n  \"step op10 s10 \\<supseteq> ({s10, s})\"\n  apply clarsimp\n  apply (rule conjI)\n   apply (simp add: step_def)\n  apply (simp add: step_def op10_legal)\n  apply (rule disjI2)\n  apply (clarsimp simp: s10_def op10_def removeSetOperation_def)\n  apply (rule ext)\n  apply (fastforce simp: s4_def s_def)\n  done\n\nlemma execute_op10:\n  \"step op10 s10 = ({s10, s})\"\n  apply rule\n   apply (rule execute_op10_safe)\n  apply (rule execute_op10_live)\n  done\n\n\nlemma execute_ops:\n  \"s \\<in> execute ops s0\"\n  apply (clarsimp simp: ops_def)\n  apply (insert execute_op0_live execute_op1_live execute_op2_live execute_op3_live\n                execute_op4_live execute_op5_live                  execute_op7_live\n                execute_op8_live execute_op9_live execute_op10_live)\n  apply (simp add: s7_def)\n  apply fastforce\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Store Exclusion in Capabilities: The `create_cap` function does not include the `Store` right in the created capability. If a capability includes the `Store` right, it cannot be the result of the `create_cap` function.",
    "input": "",
    "output": "lemma store_not_in_create_cap [simp]:\n  \"Store \\<notin> rights (create_cap i)\"\n  by (simp add: create_cap_def)\n\nlemma store_not_in_create_cap2 [simp]:\n  \"Store \\<in> rights c \\<Longrightarrow> c \\<noteq> create_cap i\"\n  by (clarsimp simp: create_cap_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Store Connected Direct: The store-connected relationship is defined for specific capability configurations, where the set of store-connected pairs is {(0,0), (1,1), (1,2)}. This ensures that the store operations are restricted to these specific target and source pairs, maintaining the integrity and security of the system.",
    "input": "",
    "output": "lemma store_connected_direct_s_helper1:\n  \"{c'.(c' = \\<lparr>target = 0, rights = UNIV\\<rparr> \\<or> c' \\<in> range create_cap) \\<and>\n        c' \\<noteq> \\<lparr>target = 1, rights = {Create}\\<rparr> \\<and> c' \\<noteq> \\<lparr>target = 2, rights = {Create}\\<rparr> \\<and>\n        Store \\<in> rights c'} = {full_cap 0}\"\n by (auto simp: create_cap_def full_cap_def all_rights_def e0_caps_def)\n\nlemma store_connected_direct_s_helper2:\n  \"{c'. (c' = \\<lparr>target = 2, rights = {Create}\\<rparr> \\<or> c' = \\<lparr>target = 1, rights = {Write, Store}\\<rparr> \\<or>\n         c' = \\<lparr>target = 2, rights = UNIV\\<rparr>)    \\<and>  Store \\<in> rights c'}\n   = {\\<lparr>target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (auto simp: create_cap_def full_cap_def all_rights_def e0_caps_def)\n\n\nlemma store_connected_direct_s:\n  \"store_connected_direct s = {(0,0), (1,1), (1,2)}\"\n  by (fastforce simp: store_connected_direct_def s_def e0_caps_def\n                      full_cap_def all_rights_def create_cap_def null_entity_def\n                      store_connected_direct_s_helper1 store_connected_direct_s_helper2\n               split: if_split_asm)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reflexive Transitive Closure Properties: The lemmas establish properties of the reflexive transitive closure of a relation, including conditions under which elements in the closure are equal and conditions for membership in a set. Specifically, they show that if a pair is in the reflexive transitive closure and certain conditions on the relation hold, then the elements of the pair must be equal or belong to a specific set. Additionally, the lemmas demonstrate the equivalence of certain sets under the reflexive transitive closure.",
    "input": "",
    "output": "lemma into_rtrancl [rule_format]:\n  \"(a,b) \\<in> r^* \\<Longrightarrow> (\\<forall>x. (x,b) \\<in> r \\<longrightarrow> x = b) \\<longrightarrow> a = b\"\n  apply (erule converse_rtrancl_induct)\n   apply simp\n  apply clarsimp\n  done\n\nlemma into_rtrancl2 [rule_format]:\n  \" \\<And> B. \\<lbrakk>(a,b) \\<in> r^*; b \\<in> B\\<rbrakk> \\<Longrightarrow> (\\<forall>x.(x,b) \\<in> r \\<longrightarrow> x \\<in> B) \\<longrightarrow> a \\<in> B\"\n  thm rtrancl_induct converse_rtrancl_induct\n  apply (erule converse_rtrancl_induct)\n   apply clarsimp\n  apply clarsimp\n  oops\n\nlemma store_connected_id:\n \"{(0::word32, 0), (1, 1), (1, 2)}\\<^sup>* = {(1, 2)}\\<^sup>* \"\n  apply rule\n   apply clarsimp\n   apply (erule rtranclE)\n    apply simp\n   apply (fastforce dest: into_rtrancl)\n  apply clarsimp\n  apply (erule rtranclE)\n   apply simp\n  apply (fastforce dest: into_rtrancl)\n  done\n\nlemma store_connected_s: \"store_connected s = {(1,2)} \\<union> Id\"\n  apply simp\n  apply (rule equalityI)\n  apply (insert store_connected_direct_s)\n   apply (simp add: store_connected_def)\n   apply clarsimp\n   apply (erule converse_rtranclE)\n    apply simp\n   apply clarsimp\n   apply (erule rtranclE)\n    apply fastforce\n   apply (simp add: store_connected_id)\n   apply (drule rtranclD)\n   apply (safe, simp_all, (erule tranclE, simp, fastforce)+)\n  apply (fastforce simp: store_connected_def)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Caps of State: The capabilities associated with each entity in the state `s` are defined as follows:\n- Entity 0 has all initial capabilities except for `create_cap 1` and `create_cap 2`.\n- Entity 1 has specific capabilities including `create_cap 2`, a capability with target 1 and rights {Write, Store}, and `full_cap 2`.\n- Entities 2 and any other entities (except 0 and 1) have no capabilities.",
    "input": "",
    "output": "lemma caps_of_s_e0_caps: \"caps_of s 0 = e0_caps - {create_cap 1, create_cap 2}\"\n  apply (clarsimp simp: caps_of_def store_connected_s Collect_disj_eq)\n  apply (simp add: s_def)\n  done\n\nlemma caps_of_s_e0_caps_2: \"caps_of s 0 = {full_cap 0} \\<union> ( range create_cap - {create_cap 1, create_cap 2})\"\n  by (fastforce simp: caps_of_s_e0_caps e0_caps_def full_cap_def create_cap_def)\n\n\nlemma caps_of_s_e1: \"caps_of s 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  apply (clarsimp simp: caps_of_def store_connected_s Collect_disj_eq)\n  apply (simp add: s_def null_entity_def)\n  done\n\nlemma caps_of_s_e2: \"caps_of s 2 = {}\"\n  apply (simp add: caps_of_def store_connected_s)\n  apply (simp add: s_def null_entity_def)\n  done\n\nlemma caps_of_s_e3: \"\\<lbrakk>e \\<noteq> 0; e \\<noteq> 1\\<rbrakk> \\<Longrightarrow> caps_of s e = {}\"\n  apply (simp add: caps_of_def store_connected_s)\n  apply (simp add: s_def null_entity_def)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Extra Rights Preservation: The extra rights of a capability are preserved when creating, taking, or granting the capability. Specifically, the extra rights of a created, taken, or granted capability are identical to the original capability, and the extra rights of capabilities in a specific range of created capabilities map to a corresponding range of full capabilities, excluding certain specific cases.",
    "input": "",
    "output": "lemma extra_rights_create_cap:\n  \"extra_rights (create_cap i) = full_cap i\"\n  by (simp add: create_cap_def full_cap_def extra_rights_def)\n\n\nlemma extra_rights_full_cap:\n  \"extra_rights (full_cap i) = full_cap i\"\n  by (simp add: full_cap_def extra_rights_def)\n\nlemma extra_rights_take_cap:\n  \"extra_rights (take_cap i) = take_cap i\"\n  by (simp add: take_cap_def extra_rights_def)\n\nlemma extra_rights_grant_cap:\n  \"extra_rights (grant_cap i) = grant_cap i\"\n  by (simp add: take_cap_def extra_rights_def)\n\nlemma caps_of'_s_e0_caps_helper:\n  \"extra_rights ` (range create_cap - {create_cap 1, create_cap 2}) =\n  range full_cap - {full_cap 1, full_cap 2}\"\n  apply rule\n   apply (fastforce simp: create_cap_def extra_rights_def all_rights_def full_cap_def)\n  apply rule\n  apply (erule DiffE)\n  apply clarsimp\n  apply (rule image_eqI)\n   apply (rule extra_rights_create_cap [THEN sym])\n  apply (simp add: full_cap_def create_cap_def)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Rights and Connections:\n- Extra rights of a capability include all the original rights, ensuring that the new capability has at least the same permissions as the original.\n- The system enforces specific connectivity rules between different entities (e0, e1, e2), where e0 is connected to any other entity except e1 and e2, and e1 is connected to e2, but e0 is not connected to either e1 or e2. This ensures controlled and secure communication and access within the system.",
    "input": "",
    "output": "lemma extra_rights_increases_rights:\n  \"rights c \\<subseteq> rights (extra_rights c)\"\n  by (simp add: extra_rights_def all_rights_def)\n\nlemma cap_in_caps_take_cap:\n  \"\\<lbrakk>create_cap x \\<in> caps_of s y\\<rbrakk> \\<Longrightarrow> take_cap x \\<in>cap caps_of s y\"\n  apply (auto simp: cap_in_caps_def caps_of_def extra_rights_take_cap)\n  apply (rule exI, rule conjI, assumption)\n  apply (rule rev_bexI, simp)\n  apply (rule conjI)\n   apply (subgoal_tac \"target (full_cap x) = x\", simp+)\n  apply (simp add: extra_rights_create_cap all_rights_def)\n  done\n\n\nlemma e0_connected_to:\n  \"\\<lbrakk>x \\<noteq> 1; x \\<noteq> 2\\<rbrakk> \\<Longrightarrow> s \\<turnstile> 0 \\<leftrightarrow> x\"\n  apply (rule directly_tgs_connected_comm)\n  apply (simp add: directly_tgs_connected_def4)\n  apply (rule disjI1)\n  apply (rule cap_in_caps_take_cap)\n  apply (simp add: caps_of_s_e0_caps e0_caps_def create_cap_def)\n  done\n\nlemma e1_connected_to_e2:\n  \"s \\<turnstile> 1 \\<leftrightarrow> 2\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (rule disjI2)+\n  apply (simp add: shares_caps_def)\n  apply (simp add: store_connected_s)\n  done\n\nlemma e0_caps_not_connected_to_e1:\n  \"\\<not> (s \\<turnstile> 0 \\<leftrightarrow> 1)\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (rule conjI)\n   apply (simp add: cap_in_caps_def caps_of_s_e1)\n  apply (rule conjI)\n   apply (clarsimp simp add: cap_in_caps_def caps_of_s_e0_caps e0_caps_def)\n   apply (erule disjE)\n    apply (simp add: full_cap_def)\n   apply clarsimp\n  apply (rule conjI)\n     apply (clarsimp simp add: cap_in_caps_def caps_of_s_e0_caps e0_caps_def)\n   apply (erule disjE)\n    apply (simp add: full_cap_def)\n   apply clarsimp\n  apply (rule conjI)\n   apply (simp add: cap_in_caps_def caps_of_s_e1)\n  apply (simp add: shares_caps_def)\n  apply (simp add: store_connected_s)\n  done\n\nlemma e0_caps_not_connected_to_e2:\n  \"\\<not> (s \\<turnstile> 0 \\<leftrightarrow> 2)\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (rule conjI)\n   apply (simp add: cap_in_caps_def caps_of_s_e2)\n  apply (rule conjI)\n   apply (clarsimp simp add: cap_in_caps_def caps_of_s_e0_caps e0_caps_def)\n   apply (erule disjE)\n    apply (simp add: full_cap_def)\n   apply clarsimp\n  apply (rule conjI)\n     apply (clarsimp simp add: cap_in_caps_def caps_of_s_e0_caps e0_caps_def)\n   apply (erule disjE)\n    apply (simp add: full_cap_def)\n   apply clarsimp\n  apply (rule conjI)\n   apply (simp add: cap_in_caps_def caps_of_s_e2)\n  apply (simp add: shares_caps_def)\n  apply (simp add: store_connected_s)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "TGS Connectedness and Leakage: The system ensures that the connectedness between entities 1 and 2 is preserved, and any entity connected to 1 or 2 must be either 1 or 2. Additionally, it guarantees that there is no leakage from entity 0 to entity 1, maintaining the integrity of the security properties.",
    "input": "",
    "output": "lemma e1_connected_trans_to_e2:\n  \"s \\<turnstile> 1 \\<leftrightarrow>* 2\"\n  apply (insert e1_connected_to_e2)\n  apply (simp add: tgs_connected_def)\n  done\n\n\nlemma caps_of_to_e1:\n  \"\\<lbrakk>c \\<in> caps_of s x; target c = 1\\<rbrakk> \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (case_tac \"x = 0\")\n   apply (fastforce simp: caps_of_s_e0_caps_2)\n  apply (case_tac \"x = 1\")\n   apply (fastforce simp: caps_of_s_e1)\n  apply (fastforce simp: caps_of_s_e3)\n  done\n\nlemma caps_of_to_e2:\n  \"\\<lbrakk>c \\<in> caps_of s x; target c = 2\\<rbrakk> \\<Longrightarrow> x = 1\"\n  apply (case_tac \"x = 0\")\n   apply (fastforce simp: caps_of_s_e0_caps_2)\n  apply (case_tac \"x = 1\")\n   apply (fastforce simp: caps_of_s_e1)\n  apply (fastforce simp: caps_of_s_e3)\n  done\n\nlemma cap_in_caps_caps_of_e1:\n  \"c \\<in>cap caps_of s 1 \\<Longrightarrow> target c = 1 \\<or> target c = 2\"\n  by (clarsimp simp: cap_in_caps_def caps_of_s_e1)\n\nlemma cap_in_caps_caps_of_e2:\n  \"c \\<in>cap caps_of s 2 \\<Longrightarrow> False\"\n  by (clarsimp simp: cap_in_caps_def caps_of_s_e2)\n\nlemma cap_in_caps_caps_of_to_e1:\n  \"\\<lbrakk>c \\<in>cap caps_of s x; target c = 1\\<rbrakk> \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (drule (1) caps_of_to_e1, simp)\n  done\n\nlemma cap_in_caps_caps_of_to_e2:\n  \"\\<lbrakk>c \\<in>cap caps_of s x; target c = 2\\<rbrakk> \\<Longrightarrow> x = 1\"\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (erule (1) caps_of_to_e2)\n  done\n\nlemma e1_connected_to:\n  \"s \\<turnstile> 1 \\<leftrightarrow> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (erule disjE)\n   apply (erule cap_in_caps_caps_of_to_e1, simp)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, simp)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, simp)\n  apply (erule disjE)\n   apply (erule cap_in_caps_caps_of_to_e1, simp)\n  apply (fastforce simp: shares_caps_def store_connected_s)\n  done\n\n\nlemma e2_connected_to:\n  \"s \\<turnstile> 2 \\<leftrightarrow> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (erule disjE, rule disjI1)\n   apply (erule cap_in_caps_caps_of_to_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (drule cap_in_caps_caps_of_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (drule cap_in_caps_caps_of_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (erule cap_in_caps_caps_of_to_e2, simp)\n  apply (clarsimp simp: shares_caps_def store_connected_s)\n  done\n\n\nlemma directly_tgs_connected_in_inv_image:\n  \"(directly_tgs_connected s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  by (fastforce simp: inv_image_def\n              dest!: e1_connected_to e1_connected_to [OF directly_tgs_connected_comm]\n                     e2_connected_to e2_connected_to [OF directly_tgs_connected_comm])\n\nlemma connected_inv_image_trans:\n  \"trans (inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\"\n  by (rule trans_inv_image [OF trans_Id])\n\nlemma eq_inv_image_connected:\n  \"(inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\\<^sup>= = inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  by (fastforce simp: inv_image_def)\n\nlemma rtrancl_inv_image_connected:\n  \"(inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\\<^sup>* = inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  apply (subst trancl_reflcl [symmetric])\n  apply (subst eq_inv_image_connected)\n  apply (rule trancl_id)\n  apply (rule connected_inv_image_trans)\n  done\n\nlemma tgs_connected_in_inv_image:\n  \"(tgs_connected s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  apply (simp add: tgs_connected_def)\n  apply (subst rtrancl_inv_image_connected [symmetric])\n  apply (rule rtrancl_mono)\n  apply (rule directly_tgs_connected_in_inv_image)\n  done\n\nlemma e0_not_connected_trans_e1:\n  \"\\<not> s \\<turnstile> 0 \\<leftrightarrow>* 1\"\n  apply clarsimp\n  apply (drule set_mp [OF tgs_connected_in_inv_image])\n  apply (simp add: inv_image_def)\n  done\n\nlemma e0_not_ever_connected_trans_e1:\n  \"s' \\<in> execute cmds s \\<Longrightarrow> \\<not> s' \\<turnstile> 0 \\<leftrightarrow>* 1\"\n  apply clarsimp\n  apply (drule (1) tgs_connected_preserved)\n  apply (simp add: e0_not_connected_trans_e1)\n  done\n\n\nlemma e0_e1_leakage:\n  \"s' \\<in> execute cmds s \\<Longrightarrow> \\<not> leak s' 0 1\"\n  apply (insert e0_not_connected_trans_e1)\n  apply (drule (2) leakage_rule)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Island Formation: The island function defines the set of elements connected to a given element in the system. Specifically, elements 1 and 2 form an isolated island, while all other elements (excluding 1 and 2) form a separate island. This ensures that the connectivity and isolation properties are maintained within the system.",
    "input": "",
    "output": "lemma island_e0:\n  \"island s 0 = {i. i \\<noteq> 1 \\<and> i \\<noteq> 2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (drule (1) e0_connected_to)\n  apply (drule directly_tgs_connected_comm)\n  by (metis directly_tgs_connected_def2 tgs_connected_comm leakImplyConnectedTrans)\n\nlemma island_e1:\n  \"island s 1 = {1,2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (rule e1_connected_trans_to_e2)\n  done\n\nlemma island_e2:\n  \"island s 2 = {1,2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (rule e1_connected_trans_to_e2  [THEN tgs_connected_comm])\n  done\n\nlemma island_e3:\n  \"\\<lbrakk>x \\<noteq> 1; x \\<noteq> 2\\<rbrakk> \\<Longrightarrow> island s x =  {i. i \\<noteq> 1 \\<and> i \\<noteq> 2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (frule_tac x=x  in e0_connected_to, simp)\n  apply (frule_tac x=xa in e0_connected_to, simp)\n  apply (drule_tac x=0 and y=xa in directly_tgs_connected_comm)\n  apply (rule tgs_connected_comm)\n  apply (simp add: tgs_connected_def)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Information Flow Constraints: The flow and transitive flow relations are constrained such that only states 1 and 2 can flow to or from each other, ensuring that states 0 and 1, as well as states 1 and 0, are isolated in terms of information flow.",
    "input": "",
    "output": "lemma e1_flow_to:\n  \"s \\<turnstile> 1 \\<leadsto> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (rule ccontr)\n  apply (clarsimp simp: flow_def set_flow_def island_e1 island_e3)\n  apply (erule disjE, clarsimp)\n   apply (erule disjE)\n    apply (drule cap_in_caps_caps_of_to_e1, clarsimp+)\n   apply (drule cap_in_caps_caps_of_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_to_e2, clarsimp+)\n  apply (drule cap_in_caps_caps_of_e2, clarsimp+)\n  done\n\nlemma e2_flow_to:\n  \"s \\<turnstile> 2 \\<leadsto> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (rule ccontr)\n  apply (clarsimp simp: flow_def set_flow_def island_e2 island_e3)\n  apply (erule disjE, clarsimp)\n   apply (erule disjE)\n    apply (drule cap_in_caps_caps_of_to_e1, clarsimp+)\n   apply (drule cap_in_caps_caps_of_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_to_e2, clarsimp+)\n  apply (drule cap_in_caps_caps_of_e2, clarsimp+)\n  done\n\nlemma flow_to_e1:\n  \"s \\<turnstile> x \\<leadsto> 1 \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (rule ccontr)\n  apply (clarsimp simp: flow_def set_flow_def island_e1 island_e3)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_to_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e2, clarsimp+)\n  apply (drule cap_in_caps_caps_of_to_e2, clarsimp+)\n  done\n\nlemma flow_to_e2:\n  \"s \\<turnstile> x \\<leadsto> 2 \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (rule ccontr)\n  apply (clarsimp simp: flow_def set_flow_def island_e2 island_e3)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_to_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e2, clarsimp+)\n  apply (drule cap_in_caps_caps_of_to_e2, clarsimp+)\n  done\n\n\nlemma flow_in_inv_image:\n  \"(flow s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  by (fastforce simp: inv_image_def\n              dest!: e1_flow_to flow_to_e1\n                     e2_flow_to flow_to_e2)\n\n\nlemma flow_trans_in_inv_image:\n  \"(flow_trans s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  apply (simp add: flow_trans_def)\n  apply (subst rtrancl_inv_image_connected [symmetric])\n  apply (rule rtrancl_mono)\n  apply (rule flow_in_inv_image)\n  done\n\nlemma e0_not_flow_trans_e1:\n  \"\\<not> s \\<turnstile> 0 \\<leadsto>* 1\"\n  apply clarsimp\n  apply (drule set_mp [OF flow_trans_in_inv_image])\n  apply (simp add: inv_image_def)\n  done\n\nlemma e1_not_flow_trans_e0:\n  \"\\<not> s \\<turnstile> 1 \\<leadsto>* 0\"\n  apply clarsimp\n  apply (drule set_mp [OF flow_trans_in_inv_image])\n  apply (simp add: inv_image_def)\n  done\n\nlemma e0_e1_isolated:\n  \"s' \\<in> execute cmds s \\<Longrightarrow> \\<not> s' \\<turnstile> 0 \\<leadsto>* 1 \\<and> \\<not> s' \\<turnstile> 1 \\<leadsto>* 0\"\n  apply (rule conjI)\n   apply (erule information_flow)\n   apply (rule e0_not_flow_trans_e1)\n  apply (erule information_flow)\n  apply (rule e1_not_flow_trans_e0)\n  done\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Confinement Proof: Ensures that the system adheres to the security model by preventing unauthorized access and information flow, maintaining the integrity and confidentiality of the system.",
    "input": "",
    "output": "(* Title:   Confinement_S\n * Description: confinement proof of the security model\n *)\n\ntheory Confine_S\nimports System_S\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Extra Rights Translation: If a capability includes the `Create` right, it is translated to have all possible rights; otherwise, the capability remains unchanged.",
    "input": "",
    "output": "definition\n  extra_rights :: \"cap \\<Rightarrow> cap\" where\n  \"extra_rights c \\<equiv>\n  if (Create \\<in> rights c)\n  then c\\<lparr>rights := all_rights\\<rparr>\n  else c\"\n\n\nlemma extra_rights_idem [simp]:\n  \"(extra_rights (extra_rights c)) = (extra_rights c)\"\n  apply (clarsimp simp add: extra_rights_def)\n  done\n\nlemma extra_rights_image_idem [simp]:\n  \"(extra_rights ` (extra_rights ` S)) = (extra_rights ` S)\"\n  by (rule set_eqI) (simp add: image_iff)\n\nlemma extra_rights_empty_rights_ident [simp]:\n   \"extra_rights \\<lparr> target = e, rights = {} \\<rparr> = \\<lparr> target = e, rights = {} \\<rparr>\"\n  by (simp add: extra_rights_def)\n\nlemma entity_extra_rights [simp]:\n  \"target (extra_rights c) = target c\"\n  by (simp add: extra_rights_def)\n\nlemma rights_extra_rights:\n  \"rights (extra_rights c) =\n   (if Create \\<in> (rights c)\n    then all_rights\n    else rights c)\"\n  by (simp add: extra_rights_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Membership: A capability is considered to be in a set of capabilities if there exists a capability in the set with the same target and at least the same or more access rights.",
    "input": "",
    "output": "definition\n  cap_in_caps :: \"cap \\<Rightarrow> cap set \\<Rightarrow> bool\" (infix \"\\<in>cap\" 50) where\n  \"c \\<in>cap C \\<equiv> \\<exists>c' \\<in> C. target c = target c' \\<and> rights (extra_rights c) \\<subseteq> rights (extra_rights c')\"\n\nabbreviation not_cap_in_caps where\n  \"not_cap_in_caps x A \\<equiv> ~ (x \\<in>cap A)\" \\<comment> \\<open>non-membership\\<close>\n\nnotation (input) cap_in_caps (infix \":cap\" 50)\nnotation (latex output)  cap_in_caps (infix \"\\<in>\\<^sub>c\\<^sub>a\\<^sub>p\" 50)\n\nnotation\n  not_cap_in_caps  (\"(\\<notin>cap)\") and\n  not_cap_in_caps  (\"(_/ \\<notin>cap _)\" [51, 51] 50)\n\nnotation (latex output)\n  not_cap_in_caps  (\"(\\<notin>\\<^sub>c\\<^sub>a\\<^sub>p)\") and\n  not_cap_in_caps  (infix \"\\<notin>\\<^sub>c\\<^sub>a\\<^sub>p\" 50)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Dominance and Sharing: A set of capabilities is considered dominated by another capability if each capability in the set has equal or fewer rights to the target entity. Entities are connected through shared capabilities, and a leak exists between two entities if one can take or grant a capability from or to the other, or if they share a common store. The transitive closure of these direct connections defines the overall connectivity between entities.",
    "input": "",
    "output": "definition\n  caps_dominated_by :: \"cap set \\<Rightarrow> cap \\<Rightarrow> bool\" (infix \"\\<le>cap\" 50) where\n  \"caps \\<le>cap cap \\<equiv> \\<forall>cap' \\<in> caps. target cap' = target cap \\<longrightarrow> rights (extra_rights cap') \\<subseteq> rights (extra_rights cap)\"\n\nnotation (input) caps_dominated_by (infix \"<=cap\" 50)\nnotation (latex output) caps_dominated_by (infix \"\\<unlhd>\\<^sub>c\\<^sub>a\\<^sub>p\" 50)\n\ndefinition\n  shares_caps :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" where\n  \"shares_caps s e\\<^sub>x e\\<^sub>y \\<equiv> \\<exists>e\\<^sub>i . (e\\<^sub>x, e\\<^sub>i) \\<in> store_connected s \\<and> (e\\<^sub>y, e\\<^sub>i) \\<in> store_connected s\"\n\ndefinition\n  leak :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<rightarrow> _\") where\n  \"leak s e\\<^sub>x e\\<^sub>y \\<equiv> take_cap e\\<^sub>x \\<in>cap caps_of s e\\<^sub>y \\<or> grant_cap e\\<^sub>y \\<in>cap caps_of s e\\<^sub>x \\<or> shares_caps s e\\<^sub>x e\\<^sub>y\"\n\n\ndefinition\n  directly_tgs_connected :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"directly_tgs_connected s \\<equiv> {(e\\<^sub>x, e\\<^sub>y). leak s e\\<^sub>x e\\<^sub>y \\<or> leak s e\\<^sub>y e\\<^sub>x}\"\n\nlemma directly_tgs_connected_def2:\n  \"(e\\<^sub>x, e\\<^sub>y) \\<in> directly_tgs_connected s = (leak s e\\<^sub>x e\\<^sub>y \\<or> leak s e\\<^sub>y e\\<^sub>x)\"\n  by (simp add: directly_tgs_connected_def)\n\nabbreviation\n  in_directly_tgs_connected :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<leftrightarrow> _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x \\<leftrightarrow> y \\<equiv> (x,y) \\<in> directly_tgs_connected s\"\n\ndefinition\n  tgs_connected :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"tgs_connected s \\<equiv> (directly_tgs_connected s)\\<^sup>*\"\n\nabbreviation\n  in_tgs_connected :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<leftrightarrow>* _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x \\<leftrightarrow>* y == (x,y) \\<in> tgs_connected s\"\n\nnotation (latex output)\n  in_tgs_connected (\"_ \\<turnstile> _ \\<leftrightarrow>\\<^sup>* _\" [60,0,60] 61)\n\ntranslations\n  \"\\<not> (s \\<turnstile> x \\<leftrightarrow> y)\" <= \"(x,y) \\<notin> CONST directly_tgs_connected s\"\n  \"\\<not> (s \\<turnstile> x \\<leftrightarrow>* y)\" <= \"(x,y) \\<notin> CONST tgs_connected s\"\n\nlemma shares_caps_sym [simp]:\n \"shares_caps s y x = shares_caps s x y\"\n  by (auto simp: shares_caps_def)\n\nlemma directly_tgs_connected_def4:\n  \"s \\<turnstile> e\\<^sub>x \\<leftrightarrow> e\\<^sub>y = (take_cap e\\<^sub>x \\<in>cap caps_of s e\\<^sub>y \\<or> take_cap e\\<^sub>y \\<in>cap caps_of s e\\<^sub>x \\<or>\n                  grant_cap e\\<^sub>y \\<in>cap caps_of s e\\<^sub>x \\<or> grant_cap e\\<^sub>x \\<in>cap caps_of s e\\<^sub>y \\<or>\n                  shares_caps s e\\<^sub>x e\\<^sub>y)\"\n  by (auto simp: directly_tgs_connected_def leak_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity and Capability Management: Allows the creation, modification, and transfer of capabilities between entities. The operations ensure that the rights and direct capabilities of entities are updated correctly, maintaining the integrity and security of the system. Subproperties include:\n- **Create Operation**: Creates a new entity with full rights based on a given capability.\n- **Take Operation**: Transfers a subset of rights from one entity to another.\n- **Grant Operation**: Grants a subset of rights from one entity to another.\n- **Copy Operation**: Copies a subset of rights from one entity to another.",
    "input": "",
    "output": "definition\n  generalOperation ::\n  \"entity_id \\<Rightarrow> entity_id \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"generalOperation e\\<^sub>0 e\\<^sub>1 c r s \\<equiv>\n  s (e\\<^sub>1 \\<mapsto> Entity ( insert (diminish r (extra_rights c)) (direct_caps_of s e\\<^sub>1) ))\"\n\nlemma is_entity_general [simp]:\n  \"is_entity s e\\<^sub>1 \\<Longrightarrow> is_entity (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) e' = is_entity s e'\"\n  by (simp add: is_entity_def generalOperation_def)\n\ndefinition\n  make_entity :: \"entity_id \\<Rightarrow> modify_state\" where\n  \"make_entity n s \\<equiv>\n  s (n \\<mapsto> null_entity)\"\n\nlemma direct_caps_of_store_connected_eq:\n  \"\\<forall> e. direct_caps_of s e = direct_caps_of s' e\n  \\<Longrightarrow> store_connected s = store_connected s'\"\n  by (simp add: store_connected_def store_connected_direct_def\n                direct_caps_of_def)\n\nlemma direct_caps_of_caps_of_eq:\n  \"\\<forall> e. direct_caps_of s e = direct_caps_of s' e \\<Longrightarrow> caps_of s e = caps_of s' e\"\n  by (simp add: caps_of_def store_connected_def store_connected_direct_def\n                direct_caps_of_def)\n\nlemma direct_caps_of_caps_of_eq2:\n  \"\\<lbrakk>\\<forall> e. direct_caps_of s e = direct_caps_of s' e; c \\<in>cap caps_of s e\\<rbrakk> \\<Longrightarrow> c \\<in>cap caps_of s' e\"\n  apply (drule direct_caps_of_caps_of_eq)\n  apply (simp add: cap_in_caps_def)\n  by auto\n\nlemma direct_caps_of_directly_tgs_connected_eq:\n  \"\\<forall> e. direct_caps_of s e = direct_caps_of s' e \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y = s' \\<turnstile> x \\<leftrightarrow> y\"\n  apply (simp add: directly_tgs_connected_def4 shares_caps_def)\n  apply rule\n   apply (erule disjE, drule (1) direct_caps_of_caps_of_eq2, clarsimp)+\n   apply (drule direct_caps_of_store_connected_eq, clarsimp)\n  apply (erule disjE, drule direct_caps_of_caps_of_eq2 [rotated, where s=s' and s'=s], simp+)+\n  apply (drule direct_caps_of_store_connected_eq, simp)\n  done\n\nlemma direct_caps_of_make_entity:\n  \"\\<not> is_entity s n \\<Longrightarrow> direct_caps_of (make_entity n s) e = direct_caps_of s e\"\n  by (simp add: direct_caps_of_def make_entity_def is_entity_def\n                null_entity_def)\n\nlemma caps_of_make_entity:\n  \"\\<not> is_entity s n \\<Longrightarrow> caps_of (make_entity n s) e = caps_of s e\"\n  apply (rule direct_caps_of_caps_of_eq)\n  apply clarsimp\n  apply (erule direct_caps_of_make_entity)\n  done\n\nlemma caps_of_make_entity2:\n  \"\\<lbrakk>\\<not> is_entity s n; c \\<in> caps_of (make_entity n s) e\\<rbrakk> \\<Longrightarrow> c \\<in> caps_of s e\"\n  apply (drule caps_of_make_entity)\n  apply fastforce\n  done\n\nlemma directly_tgs_connected_make_entity:\n \"\\<not> is_entity s n \\<Longrightarrow> make_entity n s \\<turnstile> x \\<leftrightarrow> y = s \\<turnstile> x \\<leftrightarrow> y\"\n  apply (rule direct_caps_of_directly_tgs_connected_eq)\n  apply clarsimp\n  apply (drule (1) direct_caps_of_make_entity)\n  done\n\nlemma directly_tgs_connected_make_entity2:\n \"\\<lbrakk>\\<not> is_entity s n; make_entity n s \\<turnstile> x \\<leftrightarrow> y\\<rbrakk> \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y\"\n  apply (drule directly_tgs_connected_make_entity)\n  apply fastforce\n  done\n\nlemma diminish_extra_rights [simp]:\n  \"diminish (rights c) (extra_rights c) = c\"\n  by (simp add: diminish_def all_rights_def rights_extra_rights)\n\nlemma diminish_extra_rights2 [simp]:\n  \"diminish (r \\<inter> rights c) (extra_rights c) = diminish r c\"\n  apply (simp add: diminish_def extra_rights_def all_rights_def)\n  apply (simp add: Int_commute)\n  apply (subgoal_tac \"rights c \\<inter> (r \\<inter> rights c) = r \\<inter> rights c\")\n   apply simp\n  apply fastforce\n  done\n\nlemma create_general_helper:\n  \"Create \\<in> rights c\\<^sub>2 \\<Longrightarrow>\n   \\<lparr>target = target c\\<^sub>2, rights = UNIV\\<rparr> = c\\<^sub>2\\<lparr>rights := UNIV\\<rparr>\"\n  by auto\n\nlemma extra_rights_full_cap [simp]:\n  \"extra_rights (full_cap e) = full_cap e\"\n  by (simp add: extra_rights_def)\n\nlemma create_general_alt:\n  \"createOperation e c\\<^sub>1 c\\<^sub>2 s =\n   make_entity (target c\\<^sub>2)\n               (generalOperation  e (target c\\<^sub>1) (full_cap (target c\\<^sub>2)) (all_rights) s)\"\n  by (simp add: createOperation_def generalOperation_def make_entity_def)\n\nlemma create_general:\n  \"Create \\<in> rights c\\<^sub>2 \\<Longrightarrow> createOperation e c\\<^sub>1 c\\<^sub>2 s =\n   make_entity (target c\\<^sub>2)\n               (generalOperation  e (target c\\<^sub>1) c\\<^sub>2 (all_rights) s)\"\n  by (simp add: createOperation_def generalOperation_def make_entity_def\n                full_cap_def all_rights_def diminish_def\n                extra_rights_def create_general_helper null_entity_def)\n\nlemma take_general:\n  \"takeOperation e c\\<^sub>1 c\\<^sub>2 r s =\n   generalOperation (target c\\<^sub>1) e c\\<^sub>2 (r \\<inter> rights c\\<^sub>2) s\"\n  by (simp add: takeOperation_def generalOperation_def)\n\nlemma grant_general:\n  \"grantOperation e c\\<^sub>1 c\\<^sub>2 r s =\n   generalOperation e (target c\\<^sub>1) c\\<^sub>2 (r \\<inter> rights c\\<^sub>2) s\"\n  by (simp add: grantOperation_def generalOperation_def)\n\nlemma copy_general:\n  \"copyOperation e c\\<^sub>1 c\\<^sub>2 r s =\n   generalOperation e (target c\\<^sub>1) c\\<^sub>2 (r \\<inter> rights c\\<^sub>2) s\"\n  by (simp add: copyOperation_def generalOperation_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Directly TGS Connected and TGS Connected Properties: The directly_tgs_connected and tgs_connected relations are symmetric and reflexive, and tgs_connected is transitive. Additionally, certain capabilities (Take, Grant, Create) and store connections imply a directly_tgs_connected relationship.",
    "input": "",
    "output": "lemma directly_tgs_connected_comm:\n  \"s \\<turnstile> x \\<leftrightarrow> y \\<Longrightarrow> s \\<turnstile> y \\<leftrightarrow> x\"\n  by(auto simp: directly_tgs_connected_def)\n\nlemma tgs_connected_refl [simp]:\n  \"s \\<turnstile> x \\<leftrightarrow>* x\"\n  by (metis tgs_connected_def rtrancl.rtrancl_refl)\n\nlemma tgs_connected_comm:\n  \"s \\<turnstile> x \\<leftrightarrow>* y \\<Longrightarrow> s \\<turnstile> y \\<leftrightarrow>* x\"\n  apply(simp add: tgs_connected_def)\n  apply(erule rtrancl_induct, simp)\n  apply(case_tac \"s \\<turnstile> z \\<leftrightarrow> y\")\n   apply(simp add: directly_tgs_connected_comm)\n  apply(simp add: directly_tgs_connected_comm)\n  done\n\nlemma tgs_connected_comm_eq:\n  \"s \\<turnstile> x \\<leftrightarrow>* y = s \\<turnstile> y \\<leftrightarrow>* x\"\n  by (metis tgs_connected_comm)\n\nlemmas tgs_connected_trans =\n       rtrancl_trans [where r=\"directly_tgs_connected s\"  for s, simplified tgs_connected_def[symmetric]]\n\nlemmas directly_tgs_connected_rtrancl_into_rtrancl =\n       rtrancl_into_rtrancl [where r=\"directly_tgs_connected s\" for s, simplified tgs_connected_def[symmetric]]\n\nlemma take_caps_directly_tgs_connected:\n  \"\\<lbrakk>c \\<in> caps_of s e; Take \\<in> rights c\\<rbrakk> \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\"\n  by (auto simp: directly_tgs_connected_def leak_def take_cap_def cap_in_caps_def extra_rights_def all_rights_def)\n\nlemma grant_caps_directly_tgs_connected:\n  \"\\<lbrakk>c \\<in> caps_of s e; Grant \\<in> rights c\\<rbrakk> \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\"\n  by (auto simp: directly_tgs_connected_def leak_def grant_cap_def cap_in_caps_def extra_rights_def all_rights_def)\n\nlemma create_caps_directly_tgs_connected:\n  \"\\<lbrakk>c \\<in> caps_of s e; Create \\<in> rights c\\<rbrakk> \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\"\n  by (auto simp: directly_tgs_connected_def leak_def cap_in_caps_def rights_extra_rights all_rights_def)\n\nlemma store_connected_directly_tgs_connected:\n  \"(x, y) \\<in> store_connected s \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y\"\n  by (auto simp: directly_tgs_connected_def leak_def shares_caps_def store_connected_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Rights and Insertion Properties: \n- A capability is in the set after insertion if it either matches the target and has a subset of the extra rights of the inserted capability, or it was already in the original set.\n- A capability is in a singleton set if it matches the target and its extra rights are a subset of the extra rights of the singleton capability.\n- The empty set is always dominated by any capability.\n- Diminishing a capability's rights results in a set of rights that is a subset of the original capability's rights.",
    "input": "",
    "output": "lemma cap_in_caps_insert [simp]:\n  \"c \\<in>cap insert c' S = (target c = target c' \\<and>\n  rights (extra_rights c) \\<subseteq> rights (extra_rights c') \\<or> c \\<in>cap S)\"\n  by (simp add: cap_in_caps_def)\n\nlemma cap_in_caps_singleton [simp]:\n  \"c \\<in>cap {c'} = (target c = target c' \\<and> rights (extra_rights c) \\<subseteq> rights (extra_rights c'))\"\n  by (simp add: cap_in_caps_def)\n\nlemma not_in [simp]:\n  \"{} \\<le>cap c\"\n  by(simp add: caps_dominated_by_def)\n\nlemma extra_rights_diminish:\n  \"x \\<in> rights (extra_rights (diminish r c))\n   \\<Longrightarrow> x \\<in> rights (extra_rights c)\"\n  by (auto simp: rights_extra_rights all_rights_def split:if_split_asm)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Store Connection: Determines if two entities are connected in the system's store.",
    "input": "",
    "output": "definition\n  in_store_connected :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" where\n  \"in_store_connected s x y \\<equiv> (x, y) \\<in> store_connected s\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "General Operation Impact on Capabilities and Store Connections: The general operation modifies the direct capabilities and store connections in a way that preserves the integrity of the system. Specifically, it updates the direct capabilities for a given endpoint, and ensures that any new store connections are consistent with the existing ones, maintaining the overall structure and security of the capability and store relationships.",
    "input": "",
    "output": "lemma direct_caps_of_generalOp:\n  \"direct_caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) e =\n  (if e = e\\<^sub>1\n   then insert (diminish r (extra_rights c)) (direct_caps_of s (e\\<^sub>1))\n   else direct_caps_of s e)\"\n  by (clarsimp simp: generalOperation_def direct_caps_of_def split:option.splits)\n\nlemma direct_caps_of_generalOp2:\n  \"\\<lbrakk>c' \\<in> direct_caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x\\<rbrakk> \\<Longrightarrow>\n   c' \\<in> direct_caps_of s x \\<or> (c' \\<in>cap {c} \\<and> x = e\\<^sub>1)\"\n  apply (clarsimp simp: direct_caps_of_generalOp extra_rights_diminish\n           split:if_split_asm)\n  apply (drule extra_rights_diminish)\n  by simp\n\nlemma store_connected_direct_generalOp:\n  \"\\<lbrakk>(x, y) \\<in> store_connected_direct (generalOperation e\\<^sub>0 e\\<^sub>1 c r s)\\<rbrakk> \\<Longrightarrow>\n   (x, y) \\<in> store_connected_direct s \\<or>\n   (x = e\\<^sub>1 \\<and> y = target c \\<and> Store \\<in> rights (extra_rights c))\"\n  by (auto simp: store_connected_direct_def direct_caps_of_generalOp all_rights_def\n          split: if_split_asm)\n\nlemma store_connected_generalOp:\n  \"\\<lbrakk>(x, y) \\<in> store_connected (generalOperation e\\<^sub>0 e\\<^sub>1 c r s)\\<rbrakk> \\<Longrightarrow>\n   (x, y) \\<in> store_connected s \\<or>\n   ((x, e\\<^sub>1) \\<in> store_connected s \\<and>\n   (e\\<^sub>1, target c) \\<in> store_connected_direct (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) \\<and>\n   (target c, y) \\<in> store_connected s)\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl_induct)\n   apply clarsimp\n  apply (clarsimp)\n  apply (fold store_connected_def)\n  apply (subgoal_tac \"(y, z) \\<in> store_connected_direct s\")\n   apply (clarsimp simp: store_connected_def)\n   apply (erule disjE)\n    apply fastforce\n   apply clarsimp\n   apply (erule notE)\n   apply fastforce\n  apply (frule store_connected_direct_generalOp)\n  apply (clarsimp simp: store_connected_def)\n  done\n\n\nlemma store_connected_generalOp_not_new:\n  \"\\<lbrakk>(e\\<^sub>1, target c) \\<in> store_connected_direct (generalOperation e\\<^sub>0 e\\<^sub>1 c r s);\n   c \\<in> caps_of s e\\<^sub>0\\<rbrakk> \\<Longrightarrow>\n   (e\\<^sub>1, target c) \\<in> store_connected_direct s \\<or>\n   (e\\<^sub>0, target c) \\<in> store_connected s \\<or>\n   Create \\<in> rights c\"\n  apply (drule store_connected_direct_generalOp)\n  apply (clarsimp simp: rights_extra_rights split:if_split_asm)\n   apply (drule (1) store_caps_store_connected, simp)\n  done\n\nlemma store_connected_generalOp2:\n  \"\\<lbrakk>(x, y) \\<in> store_connected (generalOperation e\\<^sub>0 e\\<^sub>1 c r s);\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk> \\<Longrightarrow>\n   s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (drule store_connected_generalOp)\n  apply (erule disjE)\n   apply (simp add: tgs_connected_def)\n   apply (drule store_connected_directly_tgs_connected, simp)\n  apply clarsimp\n  apply (drule store_connected_directly_tgs_connected [where x=x and y=e\\<^sub>1])\n  apply (drule store_connected_directly_tgs_connected [where x=\"target c\" and y=y])\n  apply (drule (1) store_connected_generalOp_not_new)\n  apply (erule disjE)\n   apply (drule store_connected_direct_in_store_connected)\n   apply (drule store_connected_directly_tgs_connected [where x=e\\<^sub>1 and y=\"target c\"])\n   apply (simp add: tgs_connected_def)\n  apply (drule directly_tgs_connected_comm [where x=\"e\\<^sub>0\" and y=\"e\\<^sub>1\"])\n  apply (erule disjE)\n   apply (drule store_connected_directly_tgs_connected [where x=e\\<^sub>0 and y=\"target c\"])\n   apply (simp add: tgs_connected_def)\n  apply (drule (1) create_caps_directly_tgs_connected)\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma shares_caps_of_generalOp:\n  \"\\<lbrakk>shares_caps (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x y;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (clarsimp simp: shares_caps_def)\n  apply (frule (2) store_connected_generalOp2 [where x=x])\n  apply (drule (2) store_connected_generalOp2 [where x=y])\n  apply (drule tgs_connected_comm [where x=y])\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma caps_of_generalOp:\n  \"\\<lbrakk>c' \\<in> caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (simp add: caps_of_def[where e=x])\n  apply clarsimp\n  apply (frule (2) store_connected_generalOp2)\n  apply (drule direct_caps_of_generalOp2)\n  apply (erule disjE)\n   apply (drule direct_cap_in_cap)\n   apply (fastforce simp: cap_in_caps_def)\n  apply (subgoal_tac \"s \\<turnstile> x \\<leftrightarrow>* e\\<^sub>0\")\n   apply (subgoal_tac \"c' \\<in>cap caps_of s e\\<^sub>0\")\n    apply fastforce\n   apply (fastforce simp: cap_in_caps_def)\n  apply clarsimp\n  apply (drule directly_tgs_connected_comm [where x=\"e\\<^sub>0\" and y=\"e\\<^sub>1\"])\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma take_cap_generalOp:\n  \"\\<lbrakk>take_cap y \\<in>cap caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z.  s \\<turnstile> x \\<leftrightarrow>* z \\<and> take_cap y \\<in>cap caps_of s z\"\n  apply (simp add: cap_in_caps_def)\n  apply clarsimp\n  apply (drule (2) caps_of_generalOp)\n  apply (fastforce simp: cap_in_caps_def)\n  done\n\nlemma grant_cap_generalOp:\n  \"\\<lbrakk>grant_cap y \\<in>cap caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z.  s \\<turnstile> x \\<leftrightarrow>* z \\<and> grant_cap y \\<in>cap caps_of s z\"\n  apply (simp add: cap_in_caps_def)\n  apply clarsimp\n  apply (drule (2) caps_of_generalOp)\n  apply (fastforce simp: cap_in_caps_def)\n  done\n\nlemma take_cap_generalOp2:\n  \"\\<lbrakk>take_cap y \\<in>cap caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply (drule (2) take_cap_generalOp)\n  apply clarsimp\n  apply (subgoal_tac \"s \\<turnstile> z \\<leftrightarrow> y\")\n   apply (simp add: tgs_connected_def)\n  apply (simp add: directly_tgs_connected_def leak_def)\n  done\n\nlemma grant_cap_generalOp2:\n  \"\\<lbrakk>grant_cap y \\<in>cap caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply (drule (2) grant_cap_generalOp)\n  apply clarsimp\n  apply (subgoal_tac \"s \\<turnstile> z \\<leftrightarrow> y\")\n   apply (simp add: tgs_connected_def)\n  apply (simp add: directly_tgs_connected_def leak_def)\n  done\n\nlemma generalOp_directly_tgs_connected:\n \"\\<lbrakk>generalOperation e\\<^sub>0 e\\<^sub>1 c r s \\<turnstile> x \\<leftrightarrow> y;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (simp add: directly_tgs_connected_def [where s=\"generalOperation e\\<^sub>0 e\\<^sub>1 c r s\"] leak_def)\n  apply safe\n       apply (rule tgs_connected_comm)\n       apply (drule (3) take_cap_generalOp2)\n      apply (drule (3) grant_cap_generalOp2)\n     apply (erule (2) shares_caps_of_generalOp)\n    apply (drule (3) take_cap_generalOp2)\n   apply (rule tgs_connected_comm)\n   apply (drule (3) grant_cap_generalOp2)\n  apply (erule (2) shares_caps_of_generalOp)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Operations and TGS Connectedness: Ensures that if a system operation (create, take, grant, or copy) is legal, the target and endpoint remain directly TGS connected. Additionally, if the operation results in a new state where two entities are directly TGS connected, they were already TGS connected in the previous state. This property maintains the integrity and consistency of the TGS connections during system operations.",
    "input": "",
    "output": "lemma create_legal_directly_tgs_connected:\n  \"legal (SysCreate e c\\<^sub>1 c\\<^sub>2) s \\<Longrightarrow> s  \\<turnstile> target c\\<^sub>1 \\<leftrightarrow> e\"\n  apply clarsimp\n  apply (rule directly_tgs_connected_comm)\n  apply (drule (1) create_caps_directly_tgs_connected)\n  apply (drule (1) store_caps_store_connected)\n  apply (drule (1) store_connected_directly_tgs_connected)\n  done\n\nlemma take_legal_directly_tgs_connected:\n  \"legal (SysTake e c\\<^sub>1 c\\<^sub>2 r) s \\<Longrightarrow> s  \\<turnstile> target c\\<^sub>1 \\<leftrightarrow> e\"\n  apply clarsimp\n  apply (rule directly_tgs_connected_comm)\n  apply (drule (2) take_caps_directly_tgs_connected)\n  done\n\nlemma grant_legal_directly_tgs_connected:\n  \"legal (SysGrant e c\\<^sub>1 c\\<^sub>2 r) s \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\\<^sub>1\"\n  apply clarsimp\n  apply (drule (2) grant_caps_directly_tgs_connected)\n  done\n\nlemma copy_legal_directly_tgs_connected:\n  \"legal (SysCopy e c\\<^sub>1 c\\<^sub>2 r) s \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\\<^sub>1\"\n  apply clarsimp\n  apply (drule (1) store_caps_store_connected)\n  apply (drule (1) store_connected_directly_tgs_connected)\n  done\n\nlemma caps_of_create:\n  \"\\<lbrakk>c' \\<in> caps_of (createOperation e c\\<^sub>1 c\\<^sub>2 s) x; legal (SysCreate e c\\<^sub>1 c\\<^sub>2) s\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (frule create_legal_directly_tgs_connected)\n  apply (clarsimp simp: create_general)\n  apply (drule caps_of_make_entity2 [rotated], clarsimp)\n  apply (drule (1) caps_of_generalOp)\n   apply (drule (2) directly_tgs_connected_comm)\n  done\n\nlemma caps_of_take:\n  \"\\<lbrakk>c' \\<in> caps_of (takeOperation e c\\<^sub>1 c\\<^sub>2 r s) x; legal (SysTake e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (frule take_legal_directly_tgs_connected)\n  apply (clarsimp simp: take_general)\n  apply (drule (2) caps_of_generalOp)\n   apply (drule (1) directly_tgs_connected_comm)\n  done\n\nlemma caps_of_grant:\n  \"\\<lbrakk>c' \\<in> caps_of (grantOperation e c\\<^sub>1 c\\<^sub>2 r s) x; legal (SysGrant e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (frule grant_legal_directly_tgs_connected)\n  apply (clarsimp simp: grant_general)\n  apply (drule (2) caps_of_generalOp)\n   apply (drule (1) directly_tgs_connected_comm)\n  done\n\nlemma caps_of_copy:\n  \"\\<lbrakk>c' \\<in> caps_of (copyOperation e c\\<^sub>1 c\\<^sub>2 r s) x; legal (SysCopy e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (frule copy_legal_directly_tgs_connected)\n  apply (clarsimp simp: copy_general)\n  apply (drule (2) caps_of_generalOp)\n   apply (drule (1) directly_tgs_connected_comm)\n  done\n\nlemma create_directly_tgs_connected:\n \"\\<lbrakk>createOperation e c\\<^sub>1 c\\<^sub>2 s \\<turnstile> x \\<leftrightarrow> y; legal (SysCreate e c\\<^sub>1 c\\<^sub>2) s\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (frule create_legal_directly_tgs_connected)\n  apply (clarsimp simp: create_general)\n  apply (drule directly_tgs_connected_make_entity2 [rotated], clarsimp)\n  apply (drule (1) generalOp_directly_tgs_connected)\n   apply (drule (2) directly_tgs_connected_comm)\n  done\n\nlemma take_directly_tgs_connected:\n \"\\<lbrakk>takeOperation e c\\<^sub>1 c\\<^sub>2 r s \\<turnstile> x \\<leftrightarrow> y; legal (SysTake e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (frule take_legal_directly_tgs_connected)\n  apply (clarsimp simp: take_general)\n  apply (drule (3) generalOp_directly_tgs_connected)\n  done\n\nlemma grant_directly_tgs_connected:\n \"\\<lbrakk>grantOperation e c\\<^sub>1 c\\<^sub>2 r s \\<turnstile> x \\<leftrightarrow> y; legal (SysGrant e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (frule grant_legal_directly_tgs_connected)\n  apply (clarsimp simp: grant_general)\n  apply (drule (3) generalOp_directly_tgs_connected)\n  done\n\nlemma copy_directly_tgs_connected:\n \"\\<lbrakk>copyOperation e c\\<^sub>1 c\\<^sub>2 r s \\<turnstile> x \\<leftrightarrow> y; legal (SysCopy e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (frule copy_legal_directly_tgs_connected)\n  apply (clarsimp simp: copy_general)\n  apply (drule (3) generalOp_directly_tgs_connected)\n  done\n\n\n\nlemma create_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysCreate e c\\<^sub>1 c\\<^sub>2)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n   apply (erule disjE, fastforce simp: tgs_connected_def, clarsimp)\n   apply (drule create_directly_tgs_connected, clarsimp, assumption)\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma take_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysTake e c\\<^sub>1 c\\<^sub>2 r)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n   apply (erule disjE, fastforce simp: tgs_connected_def, clarsimp)\n   apply (drule take_directly_tgs_connected, clarsimp, assumption)\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma grant_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysGrant e c\\<^sub>1 c\\<^sub>2 r)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n   apply (erule disjE, fastforce simp: tgs_connected_def, clarsimp)\n   apply (drule grant_directly_tgs_connected, clarsimp, assumption)\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma copy_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysCopy e c\\<^sub>1 c\\<^sub>2 r)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n   apply (erule disjE, fastforce simp: tgs_connected_def, clarsimp)\n   apply (drule copy_directly_tgs_connected, clarsimp, assumption)\n  apply (simp add: tgs_connected_def)\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Destroy Operation Preservation: The destroy operation preserves the relationships and properties of capabilities, ensuring that direct capability connections, store connections, shared capabilities, and directly TGS-connected pairs in the system state remain intact after the operation.",
    "input": "",
    "output": "lemma direct_caps_of_destroy:\n  \"c \\<in> direct_caps_of (s(e := None)) x \\<Longrightarrow> c \\<in> direct_caps_of s x\"\n  by (simp add: direct_caps_of_def split: option.splits split: if_split_asm)\n\nlemma store_connected_destroy:\n \"(x, y) \\<in> store_connected (s(e := None)) \\<Longrightarrow> (x, y) \\<in> store_connected s\"\n  apply (simp add: store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply (fold store_connected_def)\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (fastforce simp: store_connected_def)\n  apply (simp add: store_connected_direct_def)\n  apply clarsimp\n  by (metis direct_caps_of_destroy)\n\nlemma shares_caps_destroy:\n  \"shares_caps (destroyOperation e c s) x y\n  \\<Longrightarrow> shares_caps s x y\"\n  apply (clarsimp simp: shares_caps_def destroyOperation_def)\n  apply (frule store_connected_destroy [where x=x])\n  apply (drule store_connected_destroy [where x=y])\n  by auto\n\nlemma caps_of_destroy:\n  \"c \\<in> caps_of (destroyOperation e' c' s) e \\<Longrightarrow>\n  c \\<in> caps_of s e\"\n  apply (clarsimp simp add: destroyOperation_def caps_of_def)\n  apply (rule_tac x=x in exI)\n  apply (drule direct_caps_of_destroy)\n  apply simp\n  apply (erule store_connected_destroy)\n  done\n\nlemma destroy_directly_tgs_connected:\n  \"\\<lbrakk>s' \\<in> step (SysDestroy e c) s; (x, y) \\<in> directly_tgs_connected s'\\<rbrakk> \\<Longrightarrow>\n  (x, y) \\<in> directly_tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n  apply(erule disjE, simp)\n  apply(simp add: directly_tgs_connected_def leak_def)\n  apply (erule disjE)\n   apply(fastforce simp add: cap_in_caps_def dest!: caps_of_destroy)\n  apply (erule disjE)\n   apply(fastforce simp add: cap_in_caps_def dest!: caps_of_destroy)\n  apply (erule disjE)\n   apply (drule shares_caps_destroy, simp)\n  apply (erule disjE)\n   apply(fastforce simp add: cap_in_caps_def dest!: caps_of_destroy)\n  apply (erule disjE)\n   apply(fastforce simp add: cap_in_caps_def dest!: caps_of_destroy)\n  apply (drule shares_caps_destroy, simp)\n  done\n\nlemma destroy_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysDestroy e c)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in>  directly_tgs_connected s\"\n  by(auto dest!: destroy_directly_tgs_connected)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Remove Operation Effects on Capabilities: The removal of a capability through the `removeOperation` function affects the direct and overall capabilities associated with an entity. Specifically, the direct capabilities of the target entity are updated by removing the specified capability, while the overall set of capabilities remains a subset of the original, ensuring that no new capabilities are introduced and existing ones are appropriately adjusted.",
    "input": "",
    "output": "lemma direct_caps_of_remove:\n  \"c \\<in> direct_caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x \\<Longrightarrow>\n  c \\<in> direct_caps_of s x\"\n  by (clarsimp simp: removeOperation_simpler direct_caps_of_def\n              split: option.splits if_split_asm)\n\nlemma direct_caps_of_remove_eq:\n  \"direct_caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x =\n  ( if   is_entity s (target c\\<^sub>1) \\<and> x = target c\\<^sub>1\n   then  direct_caps_of s (target c\\<^sub>1) - {c\\<^sub>2}\n   else  direct_caps_of s x )\"\n  by(simp add: direct_caps_of_def is_entity_def removeOperation_def)\n\nlemma store_connected_remove [rule_format]:\n  \"(x, y) \\<in> store_connected (s(e \\<mapsto> Entity C')) \\<Longrightarrow>\n  s e = Some (Entity C) \\<longrightarrow> C' \\<subseteq> C \\<longrightarrow> (x, y) \\<in> store_connected s\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply clarsimp\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (erule rtrancl_trans)\n   apply fastforce\n  apply (fold store_connected_def)\n  apply (clarsimp simp add: store_connected_direct_def)\n  apply (fastforce simp: direct_caps_of_def\n                  split: option.splits if_split_asm)\n  done\n\nlemma caps_of_remove:\n  \"c \\<in> caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x \\<Longrightarrow>\n  c \\<in> caps_of s x\"\n  apply (clarsimp simp: caps_of_def)\n  apply (rule_tac x=xa in exI)\n  apply (drule direct_caps_of_remove)\n  apply (simp add: removeOperation_simpler\n            split: option.splits)\n  apply (erule (1) store_connected_remove)\n  apply blast\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Removal and Connection Preservation: The removal of capabilities (either individually or in a set) from the system state does not introduce new connections between entities. It ensures that any direct or shared capability connections present in the modified state were also present in the original state, preserving the integrity of the system's capability structure.",
    "input": "",
    "output": "lemma caps_of_remove2:\n  \"caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x \\<subseteq> caps_of s x\"\n  apply(simp add: caps_of_def is_entity_def removeOperation_def direct_caps_of_def)\n  apply (clarsimp split: if_split_asm)\n   apply (auto dest!: store_connected_remove)\n  done\n\nlemma shares_caps_remove:\n  \"shares_caps (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x y\n  \\<Longrightarrow> shares_caps s x y\"\n  apply (clarsimp simp: shares_caps_def removeOperation_simpler\n                 split:option.splits)\n  apply (frule (1) store_connected_remove [where x=x], clarsimp)\n  apply (drule (1) store_connected_remove [where x=y], clarsimp)\n  by auto\n\nlemma remove_directly_tgs_connected:\n  \"\\<lbrakk>s' \\<in> step (SysRemove e c\\<^sub>1 c\\<^sub>2) s; (x, y) \\<in> directly_tgs_connected s'\\<rbrakk> \\<Longrightarrow>\n  (x, y) \\<in> directly_tgs_connected s\"\n  apply(simp add: step_def split: if_split_asm)\n  apply(erule disjE, simp)\n  apply(simp add: directly_tgs_connected_def leak_def)\n  apply(simp add: cap_in_caps_def)\n  apply(clarsimp)\n  apply safe\n     prefer 3\n     apply (drule shares_caps_remove, simp)\n    prefer 5\n    apply (drule shares_caps_remove, simp)\n   apply(auto dest!: caps_of_remove)\n  done\n\nlemma remove_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysRemove e c\\<^sub>1 c\\<^sub>2)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in>  directly_tgs_connected s\"\n  by(auto dest!: remove_directly_tgs_connected)\n\nlemma direct_caps_of_removeSet:\n  \"c' \\<in> direct_caps_of (removeSetOperation e c C s) x \\<Longrightarrow>\n  c' \\<in> direct_caps_of s x\"\n  by (clarsimp simp: removeSetOperation_simpler direct_caps_of_def\n              split: option.splits if_split_asm)\n\nlemma caps_of_removeSet:\n  \"c' \\<in> caps_of (removeSetOperation e c C s) x \\<Longrightarrow>\n  c' \\<in> caps_of s x\"\n  apply (clarsimp simp: caps_of_def)\n  apply (rule_tac x=xa in exI)\n  apply (drule direct_caps_of_removeSet)\n  apply (simp add: removeSetOperation_simpler split: option.splits)\n  apply (erule (1) store_connected_remove)\n  apply blast\n  done\n\nlemma shares_caps_removeSet:\n  \"shares_caps (removeSetOperation e c C s) x y\n  \\<Longrightarrow> shares_caps s x y\"\n  apply (clarsimp simp: shares_caps_def removeSetOperation_simpler split:option.splits)\n  apply (frule (1) store_connected_remove [where x=x], clarsimp)\n  apply (drule (1) store_connected_remove [where x=y], clarsimp)\n  by auto\n\nlemma removeSet_connected:\n  \" \\<lbrakk>s' \\<in> step (SysRemoveSet e c C) s; s' \\<turnstile> x \\<leftrightarrow> y\\<rbrakk> \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y\"\n  apply(simp add: step_def split: if_split_asm)\n  apply(erule disjE, simp)\n  apply(simp add: directly_tgs_connected_def leak_def)\n  apply(simp add: cap_in_caps_def)\n  apply(clarsimp)\n  apply safe\n     prefer 3\n     apply (drule shares_caps_removeSet, simp)\n    prefer 5\n    apply (drule shares_caps_removeSet, simp)\n   apply (auto dest!: caps_of_removeSet)\n  done\n\nlemma removeSet_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; s' \\<turnstile> x \\<leftrightarrow> y; cmd = (SysRemoveSet n c C)\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y\"\n  by(auto dest!: removeSet_connected)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Revoke Operation Properties: The revoke operation ensures that the capabilities and connectivity in the system are preserved. Specifically, it maintains the direct and indirect capabilities, store connectivity, and shared capabilities between entities. Additionally, it preserves the entity identifiers and the directly connected entities in the system, ensuring that the system's integrity and structure are maintained after a capability is revoked.",
    "input": "",
    "output": "lemma direct_caps_of_removeSetOfCaps:\n  \"c' \\<in> direct_caps_of (removeSetOfCaps cap_map s) x \\<Longrightarrow>\n  c' \\<in> direct_caps_of s x\"\n  by (clarsimp simp: removeSetOfCaps_def direct_caps_of_def\n              split: option.splits if_split_asm)\nthm store_connected_remove\n\nlemma store_connected_removeSetOfCaps:\n  \"(x, y) \\<in> store_connected (\\<lambda>e. if is_entity s e\n                                 then Some (Entity (direct_caps_of s e - cap_map e))\n                                 else None) \\<Longrightarrow>\n    (x, y) \\<in> store_connected s\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (erule rtrancl_trans)\n   apply fastforce\n  apply (fold store_connected_def)\n  apply (clarsimp simp add: store_connected_direct_def)\n  apply (fastforce simp: direct_caps_of_def\n                  split: option.splits if_split_asm)\n  done\n\nlemma caps_of_removeSetOfCaps:\n  \"c' \\<in> caps_of (removeSetOfCaps cap_map s) x \\<Longrightarrow>\n  c' \\<in> caps_of s x\"\n  apply (clarsimp simp: caps_of_def)\n  apply (rule_tac x=xa in exI)\n  apply (drule direct_caps_of_removeSetOfCaps)\n  apply (simp add: removeSetOfCaps_def split: option.splits)\n  apply (erule store_connected_removeSetOfCaps)\n  done\n\nlemma caps_of_revoke:\n  \"\\<lbrakk>s' \\<in> revokeOperation sub c\\<^sub>1 s ;  c \\<in> caps_of s' e \\<rbrakk>\n  \\<Longrightarrow> c \\<in> caps_of s e\"\n  apply (clarsimp simp: revokeOperation_def\n                 split: if_split_asm)\n  apply (drule (1) caps_of_removeSetOfCaps)\n  done\n\nlemma direct_caps_of_revoke:\n  \"\\<lbrakk>s' \\<in> revokeOperation e c s; c' \\<in> direct_caps_of s' x\\<rbrakk>\n   \\<Longrightarrow> c' \\<in> direct_caps_of s x\"\n  apply (clarsimp simp: revokeOperation_def\n                 split: if_split_asm)\n  apply (drule (1) direct_caps_of_removeSetOfCaps)\n  done\n\nlemma store_connected_revoke:\n \"\\<lbrakk>(x, y) \\<in> store_connected s'; s' \\<in> revokeOperation e c s\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> store_connected s\"\n  apply (simp add: store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply (fold store_connected_def)\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (fastforce simp: store_connected_def)\n  apply (clarsimp simp: store_connected_direct_def)\n  apply (metis direct_caps_of_revoke)\n  done\n\nlemma shares_caps_revoke:\n  \"\\<lbrakk>shares_caps s' x y; s' \\<in> revokeOperation e c s\\<rbrakk>\n  \\<Longrightarrow> shares_caps s x y\"\n  apply (clarsimp simp: shares_caps_def)\n  apply (frule (1) store_connected_revoke [where x=x])\n  apply (drule (1) store_connected_revoke [where x=y])\n  by auto\n\nlemma removeOperation_entity_ids [simp]:\n  \"is_entity (removeOperation e c c' s) e' = is_entity s e'\"\n  by (simp add: is_entity_def removeOperation_def)\n\nlemma removeSetOfCaps_entity_ids [simp]:\n  \"is_entity (removeSetOfCaps cap_map s) e' = is_entity s e'\"\n  by (simp add: is_entity_def removeSetOfCaps_def)\n\nlemma revoke_entities:\n  \"s' \\<in> revokeOperation sub c\\<^sub>1 s \\<Longrightarrow> is_entity s' e = is_entity s e\"\n  by (clarsimp simp: revokeOperation_def split: if_split_asm)\n\nlemma revoke_directly_tgs_connected:\n  \"\\<lbrakk>s' \\<in> step (SysRevoke n c\\<^sub>1) s; (x, y) \\<in> directly_tgs_connected s'\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in>  directly_tgs_connected s\"\n  apply (simp add: step_def split: if_split_asm)\n  apply (erule disjE, simp)\n  apply (simp add: directly_tgs_connected_def leak_def)\n  apply (erule disjE)\n   apply(auto simp add: cap_in_caps_def dest!: caps_of_revoke)[1]\n  apply (erule disjE)\n   apply(auto simp add: cap_in_caps_def dest!: caps_of_revoke)[1]\n  apply (erule disjE)\n   apply (drule (1) shares_caps_revoke, simp)\n  apply (erule disjE)\n   apply(auto simp add: cap_in_caps_def dest!: caps_of_revoke)[1]\n  apply (erule disjE)\n   apply(auto simp add: cap_in_caps_def dest!: caps_of_revoke)[1]\n  apply (drule (1) shares_caps_revoke, simp)\n  done\n\nlemma revoke_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysRevoke n c\\<^sub>1)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in>  directly_tgs_connected s\"\n  by(auto dest!: revoke_directly_tgs_connected)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity Preservation: The grant and destroy operations maintain the entity status of other entities in the system, ensuring that the existence of an entity is not affected by these operations.",
    "input": "",
    "output": "lemma is_entity_grant [simp]:\n  \"is_entity s (target c\\<^sub>1) \\<Longrightarrow>\n  is_entity (grantOperation e c\\<^sub>1 c\\<^sub>2 r s) e' = is_entity s e'\"\n  by (simp add: is_entity_def grantOperation_def)\n\nlemma is_entity_destroy:\n  \"is_entity (destroyOperation e' c s) e \\<Longrightarrow> is_entity s e\"\n  by (simp add: destroyOperation_def is_entity_def split: if_split_asm)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Transitive Connectedness Preservation: The transitive connectedness between entities is preserved through the execution of commands. If two entities are transitively connected in a state after command execution, they were also transitively connected in the initial state.",
    "input": "",
    "output": "lemma connected_tgs_connected:\n  \"\\<lbrakk>s' \\<in> step cmd s; (e\\<^sub>x, e\\<^sub>y) \\<in> directly_tgs_connected s'\\<rbrakk> \\<Longrightarrow>\n  (e\\<^sub>x, e\\<^sub>y) \\<in> tgs_connected s\"\n  apply(case_tac \"(e\\<^sub>x, e\\<^sub>y) \\<in> directly_tgs_connected s\")\n   apply(simp add: tgs_connected_def)\n   apply(case_tac cmd)\n         apply(rule create_conTrans, fastforce+)\n        apply(rule take_conTrans, fastforce+)\n       apply(rule grant_conTrans, fastforce+)\n      apply(frule copy_conTrans, fastforce+)\n     apply(frule remove_conTrans, fastforce+)\n    apply(frule removeSet_conTrans, fastforce+)\n   apply(frule revoke_conTrans, fastforce+)\n  apply(frule destroy_conTrans, fastforce+)\n  done\n\nlemma tgs_connected_preserved_step:\n  \"\\<lbrakk>s' \\<in> step cmd s; s' \\<turnstile> x \\<leftrightarrow>* z\\<rbrakk> \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* z\"\n  thm rtrancl_induct [where r=\"directly_tgs_connected s'\" and a=x and b=z and P=\"\\<lambda>z. (x, z) \\<in> (directly_tgs_connected s)\\<^sup>*\", simplified,\n                      simplified tgs_connected_def [symmetric]]\n  apply(erule rtrancl_induct [where r=\"directly_tgs_connected s'\",\n                              simplified tgs_connected_def [symmetric]], simp)\n  apply(case_tac \"s \\<turnstile> y \\<leftrightarrow>* z\")\n   apply (erule (1) tgs_connected_trans)\n  apply (simp add: connected_tgs_connected)\n  done\n\nlemma leakImplyConnected:\n  \"leak s\\<^sub>i e\\<^sub>x e\\<^sub>i \\<Longrightarrow> (e\\<^sub>x, e\\<^sub>i) \\<in> directly_tgs_connected s\\<^sub>i\"\n by(simp add: directly_tgs_connected_def)\n\nlemma leakImplyConnectedTrans:\n  \"leak s\\<^sub>i e\\<^sub>x e\\<^sub>i \\<Longrightarrow> (e\\<^sub>x, e\\<^sub>i) \\<in> tgs_connected s\\<^sub>i\"\n  by(simp add: tgs_connected_def, frule leakImplyConnected, auto)\n\n\nlemma tgs_connected_preserved [rule_format]:\n  \"\\<forall>s'. s' \\<in> execute cmds s \\<longrightarrow>\n    s' \\<turnstile> x \\<leftrightarrow>* y \\<longrightarrow>\n    s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply(induct_tac cmds, simp)\n  apply clarsimp\n  apply(rename_tac cmd cmds s'' s')\n  apply(erule_tac x=s' in allE)\n  apply(simp add: tgs_connected_preserved_step)\n  done\n\nlemma leak_conTrans [rule_format]:\n  \"\\<lbrakk>s \\<in> execute cmds s\\<^sub>0; leak s x y\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\\<^sub>0\"\n  by (auto intro: leakImplyConnectedTrans tgs_connected_preserved)\n\nlemma leakage_rule:\n  \"\\<lbrakk>s' \\<in> execute cmds s; \\<not> s \\<turnstile> x \\<leftrightarrow>* y\\<rbrakk> \\<Longrightarrow> \\<not> (s' \\<turnstile> x \\<rightarrow> y)\"\n  by(auto simp add: leak_conTrans)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Authority Confinement: Ensures that the capabilities of an entity in the system remain within a specified limit after executing a series of commands. This property maintains the integrity and security of the system by confining the authority of entities, preventing them from gaining more capabilities than initially allowed.",
    "input": "",
    "output": "lemma caps_of_op:\n  \"\\<lbrakk>s' \\<in> step cmd s; c' \\<in> caps_of s' x\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. s \\<turnstile> x \\<leftrightarrow>* z \\<and> c' \\<in>cap caps_of s z\"\n  apply (simp add: step_def split:if_split_asm)\n   prefer 2\n   apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n  apply (erule disjE)\n   apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n  apply (case_tac cmd)\n         apply (simp add: caps_of_create)\n        apply (simp add: caps_of_take)\n       apply (simp add: caps_of_grant)\n      apply (simp add: caps_of_copy)\n     apply (clarsimp, drule caps_of_remove)\n     apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n    apply (clarsimp, drule caps_of_removeSet)\n    apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n   apply (clarsimp, drule (1) caps_of_revoke)\n   apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n  apply (clarsimp, drule caps_of_destroy)\n  apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n  done\n\nlemma authority_confinement_induct_step:\n  \"\\<lbrakk>s' \\<in> step cmd s;\n    \\<forall>e\\<^sub>i. s \\<turnstile> e\\<^sub>x \\<leftrightarrow>* e\\<^sub>i \\<longrightarrow> caps_of s e\\<^sub>i \\<le>cap c\\<rbrakk>\n  \\<Longrightarrow> caps_of s' e\\<^sub>x \\<le>cap c\"\n  apply (clarsimp simp: caps_dominated_by_def)\n  apply (drule (1) caps_of_op)\n  apply (fastforce simp: cap_in_caps_def)\n  done\n\nlemma authority_confinement_helper:\n  \"s' \\<in> execute cmds s \\<longrightarrow>\n   (\\<forall>e\\<^sub>i. s \\<turnstile> e\\<^sub>x \\<leftrightarrow>* e\\<^sub>i \\<longrightarrow> caps_of s e\\<^sub>i \\<le>cap c) \\<longrightarrow>\n   (\\<forall>e\\<^sub>i. s' \\<turnstile> e\\<^sub>x \\<leftrightarrow>* e\\<^sub>i \\<longrightarrow> caps_of s' e\\<^sub>i \\<le>cap c)\"\nproof (induct cmds arbitrary: s')\ncase Nil\n  show ?case by clarsimp\nnext\ncase (Cons cmd cmds s')\nshow ?case\n  apply clarsimp\n  apply (rule authority_confinement_induct_step, assumption)\n  apply clarsimp\n  apply (rule Cons.hyps[rule_format], simp_all)\n  apply (drule(1) tgs_connected_preserved_step)\n  apply (simp add: tgs_connected_def)\n  done\nqed\n\nlemma authority_confinement:\n  \"\\<lbrakk>s' \\<in> execute cmds s;\n    \\<forall>e\\<^sub>i. s \\<turnstile> e\\<^sub>x \\<leftrightarrow>* e\\<^sub>i \\<longrightarrow> caps_of s e\\<^sub>i \\<le>cap c\\<rbrakk>\n  \\<Longrightarrow> caps_of s' e\\<^sub>x \\<le>cap c\"\n  by (erule authority_confinement_helper [rule_format, where e\\<^sub>x=e\\<^sub>x], simp_all)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "High-Level Security Model: Defines the security policies and mechanisms that govern the behavior of the kernel, ensuring that the system's integrity, confidentiality, and availability are maintained.",
    "input": "",
    "output": "(* Title:   System_S\n * Description: High-level security model of the kernel.\n *)",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Entity Rights and Capabilities: Defines system entities with unique identifiers and a set of rights that include read, write, take, grant, create, and store. Each capability is associated with a target entity and a set of these rights, allowing for fine-grained control over the actions that can be performed on or by the entities.",
    "input": "",
    "output": "type_synonym entity_id = word32 (* kernel objects - identified by a UID *)\n\ndatatype\n  right = Read      (* Authorise reading of information *)\n         | Write    (* Authorise writing of information *)\n         | Take     (* Having sufficient authority to take a capability from another entity *)\n         | Grant    (* Having sufficient authority to propagate a capability to another entity *)\n         | Create   (* Confers the authority to create new entities *)\n         | Store    (* Simulates CNodeCap - get caps of said entity *)\n\nrecord cap =\n  target :: entity_id      (* The entity over which it has control *)\n  rights :: \"right set\"    (* The control it has over that entity  *)\n\ndatatype entity = Entity \"cap set\"\ndeclare entity.splits [split]\n\ntype_synonym state = \"entity_id \\<Rightarrow> entity option\"\n\ntype_synonym modify_state   = \"state \\<Rightarrow> state\"\ntype_synonym modify_state_n = \"state \\<Rightarrow> state set\"\ntype_synonym mask = \"right set\"\n\ndefinition\n  null_entity :: \"entity\" where\n  \"null_entity \\<equiv> Entity {}\"\n\ndefinition\n  all_rights :: \"right set\" where\n  \"all_rights \\<equiv> UNIV\"\n\nlemma all_rights_def2:\n  \"all_rights = {Read, Write, Take, Grant, Create, Store}\"\n  apply (clarsimp simp: all_rights_def, rule, simp_all, rule, simp)\n  apply (metis right.exhaust)\n  done\n\ndefinition\n  entity_ids :: \"state \\<Rightarrow> entity_id set\" where\n  \"entity_ids s \\<equiv> dom s\"\n\ndefinition\n  is_entity :: \"state \\<Rightarrow> entity_id \\<Rightarrow> bool\" where\n  \"is_entity s e \\<equiv> s e \\<noteq> None\"\n\ndefinition\n  exist :: \"state \\<Rightarrow> cap \\<Rightarrow> bool\" where\n  \"exist s c \\<equiv> is_entity s (target c)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity Capabilities and Store Connections: Defines the direct capabilities associated with an entity and determines the store-connected relationships between entities based on their capabilities. The store-connected relationship is transitive, capturing all indirect connections through a series of store capabilities.",
    "input": "",
    "output": "definition\n  direct_caps :: \"entity \\<Rightarrow> cap set\"\nwhere\n  \"direct_caps e \\<equiv> case e of (Entity c) \\<Rightarrow> c\"\n\ndefinition\n  direct_caps_of :: \"state \\<Rightarrow> entity_id \\<Rightarrow> cap set\"\nwhere\n  \"direct_caps_of s p \\<equiv>\n  case s p of\n    None \\<Rightarrow> {}\n  | Some (Entity e) \\<Rightarrow> e\"\n\ndefinition\n  store_connected_direct :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"store_connected_direct s \\<equiv> {(e\\<^sub>x, e\\<^sub>y). \\<exists>cap. cap \\<in> direct_caps_of s e\\<^sub>x \\<and>\n                                               Store \\<in> rights cap \\<and>\n                                               target cap = e\\<^sub>y}\"\n\ndefinition\n  store_connected :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"store_connected s \\<equiv> (store_connected_direct s)^*\"\n\ndefinition",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity Capabilities: Returns the set of all capabilities an entity has access to, either directly or through store connections. This ensures a comprehensive view of the entity's permissions and access rights within the system.",
    "input": "",
    "output": "caps_of :: \"state \\<Rightarrow> entity_id \\<Rightarrow> cap set\" where\n  \"caps_of s e  \\<equiv> \\<Union>(direct_caps_of s ` {e' . (e,e') \\<in> store_connected s})\"\n\nlemma caps_rel:\n  \"caps_of s e = \\<Union>(direct_caps_of s ` store_connected s `` {e})\"\n  by (simp add: caps_of_def Image_def)\n\ndefinition  (* All the different capabilities of the system *)\n  all_caps_of :: \"state \\<Rightarrow> cap set\" where\n  \"all_caps_of s \\<equiv> \\<Union>e. direct_caps_of s e\"\n\ndefinition\n  read_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"read_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Read}\\<rparr>\"\n\ndefinition\n  write_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"write_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Write}\\<rparr>\"\n\ndefinition\n  take_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"take_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Take}\\<rparr>\"\n\ndefinition\n  grant_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"grant_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Grant}\\<rparr>\"\n\ndefinition\n  create_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"create_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Create}\\<rparr>\"\n\ndefinition\n  store_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"store_cap e \\<equiv> \\<lparr>target = e, rights = {Store}\\<rparr>\"\n\ndefinition\n  full_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"full_cap e \\<equiv> \\<lparr>target = e, rights = all_rights \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Operations: Define a set of primitive kernel operations for managing entities and their capabilities, including creating, taking, granting, copying, removing, revoking, and destroying capabilities, as well as handling sets of capabilities. These operations ensure the proper management and control of system resources and permissions.",
    "input": "",
    "output": "datatype sysOPs =\n    SysCreate entity_id cap cap\n  | SysTake   entity_id cap cap mask\n  | SysGrant  entity_id cap cap mask\n  | SysCopy   entity_id cap cap mask\n  | SysRemove entity_id cap cap\n  | SysRemoveSet entity_id cap \"cap set\"\n  | SysRevoke entity_id cap\n  | SysDestroy entity_id cap",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operation Legality: Determines if a system operation is allowed based on the current state, ensuring that the involved entities and capabilities meet specific conditions, such as existence, ownership, and required rights.",
    "input": "",
    "output": "primrec\n  legal :: \"sysOPs \\<Rightarrow> state \\<Rightarrow> bool\"\nwhere\n  \"legal (SysCreate e c\\<^sub>1 c\\<^sub>2) s = (is_entity s e \\<and> is_entity s (target c\\<^sub>1) \\<and> \\<not> (is_entity s (target c\\<^sub>2)) \\<and>\n                                   {c\\<^sub>1, c\\<^sub>2} \\<subseteq> caps_of s e \\<and>\n                                   Write \\<in> rights c\\<^sub>1 \\<and> Store \\<in> rights c\\<^sub>1 \\<and> Create \\<in> rights c\\<^sub>2)\"\n\n| \"legal (SysTake  e c\\<^sub>1 c\\<^sub>2 r) s = (is_entity s e \\<and>  is_entity s (target c\\<^sub>1) \\<and>\n                                  c\\<^sub>1 \\<in> caps_of s e \\<and> c\\<^sub>2 \\<in> caps_of s (target c\\<^sub>1) \\<and> Take \\<in> rights c\\<^sub>1)\"\n\n| \"legal (SysGrant e c\\<^sub>1 c\\<^sub>2 r) s = (is_entity s e \\<and>  is_entity s (target c\\<^sub>1) \\<and>\n                                  {c\\<^sub>1,c\\<^sub>2} \\<subseteq> caps_of s e \\<and> Grant \\<in> rights c\\<^sub>1)\"\n\n| \"legal (SysCopy  e c\\<^sub>1 c\\<^sub>2 r) s   = (is_entity s e \\<and>  is_entity s (target c\\<^sub>1) \\<and>\n                                  {c\\<^sub>1,c\\<^sub>2} \\<subseteq> caps_of s e \\<and> Store \\<in> rights c\\<^sub>1)\"\n\n| \"legal (SysRemove e c\\<^sub>1 c\\<^sub>2) s = (is_entity s e \\<and> c\\<^sub>1 \\<in> caps_of s e)\"\n\n| \"legal (SysRemoveSet e c C) s = (is_entity s e \\<and> c \\<in> caps_of s e)\"\n\n| \"legal (SysRevoke e c) s = (is_entity s e \\<and> c \\<in> caps_of s e)\"\n\n| \"legal (SysDestroy e c) s = (is_entity s e \\<and> c \\<in> caps_of s e \\<and> {Create} = rights c \\<and>\n                              target c \\<notin> target ` (all_caps_of s - {c}))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Operations on Capabilities: These operations modify the system state by creating, diminishing, granting, copying, and removing capabilities. Specifically, they manage the rights and direct capabilities of entities, ensuring that the system's security and integrity are maintained through controlled access and modification of capabilities.",
    "input": "",
    "output": "definition\n  diminish :: \"right set \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"diminish R cap \\<equiv> cap \\<lparr> rights := rights cap \\<inter> R \\<rparr>\"\n\ndefinition\n  createOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"createOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (full_cap (target c\\<^sub>2))\n                                (direct_caps_of s (target c\\<^sub>1))),\n     target c\\<^sub>2 \\<mapsto> null_entity)\"\n\nlemma createOperation_def2:\n  \"createOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  let new_cap = \\<lparr> target = target c\\<^sub>2, rights = all_rights \\<rparr>;\n      newTarget = ({new_cap} \\<union> direct_caps_of s (target c\\<^sub>1) )\n  in\n  s (target c\\<^sub>1 \\<mapsto> Entity newTarget, target c\\<^sub>2 \\<mapsto> null_entity)\"\n  by (simp add: createOperation_def Let_def full_cap_def null_entity_def)\n\ndefinition\n  takeOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"takeOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (e \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s e)))\"\n\nlemma takeOperation_def2:\n  \"takeOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (e \\<mapsto> Entity ({diminish R c\\<^sub>2} \\<union> direct_caps_of s e))\"\n  by (clarsimp simp: takeOperation_def caps_of_def)\n\ndefinition\n  grantOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"grantOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s (target c\\<^sub>1)) )) \"\n\nlemma grantOperation_def2:\n  \"grantOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity ( {diminish R c\\<^sub>2} \\<union> direct_caps_of s (target c\\<^sub>1)))\"\n  by (clarsimp simp: grantOperation_def caps_of_def)\n\ndefinition\n  copyOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"copyOperation sRef c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s (target c\\<^sub>1)))) \"\n\ndefinition\n  removeOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"removeOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  if is_entity s (target c\\<^sub>1)\n  then\n     s ((target c\\<^sub>1) \\<mapsto> Entity ((direct_caps_of s (target c\\<^sub>1)) - {c\\<^sub>2} ))\n  else\n     s\"\n\nlemma removeOperation_simpler:\n  \"removeOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  (case s (target c\\<^sub>1) of\n    None \\<Rightarrow> s\n  | Some (Entity caps) \\<Rightarrow> s (target c\\<^sub>1 \\<mapsto> Entity (caps - {c\\<^sub>2})))\"\n  by (rule eq_reflection, simp add: removeOperation_def is_entity_def direct_caps_of_def\n                             split: if_split_asm option.splits)\n\ndefinition\n  removeSetOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap set \\<Rightarrow> modify_state\" where\n  \"removeSetOperation e c C s \\<equiv>\n  if is_entity s (target c) then\n   s ((target c) \\<mapsto> Entity ((direct_caps_of s (target c)) - C ))\n  else\n   s\"\n\nlemma removeSetOperation_simpler:\n  \"removeSetOperation e c caps s \\<equiv>\n  (case s (target c) of\n    None \\<Rightarrow> s\n  | Some (Entity caps') \\<Rightarrow> s (target c \\<mapsto> Entity (caps' - caps)))\"\n  by (auto simp: removeSetOperation_def is_entity_def direct_caps_of_def\n         intro!: eq_reflection\n          split: if_split_asm option.splits)\n\nlemma removeSetOperation_fold_removeOperation:\n  \"removeSetOperation e c (set caps) s = fold (removeOperation e c) caps s\"\n  apply (subst foldr_fold [symmetric])\n   apply (fastforce simp: removeOperation_def direct_caps_of_def is_entity_def)\n  apply (rule sym)\n  apply (induct caps)\n   apply (fastforce simp: removeSetOperation_def removeOperation_def direct_caps_of_def is_entity_def)\n  apply (fastforce simp: removeSetOperation_def removeOperation_def direct_caps_of_def is_entity_def)\n  done\n\ndefinition\n  removeSetOfCaps :: \"(entity_id \\<Rightarrow> cap set) \\<Rightarrow> modify_state\"\nwhere\n  \"removeSetOfCaps cap_map s \\<equiv> \\<lambda>e.\n     if is_entity s e\n     then Some (Entity ((direct_caps_of s e) - cap_map e ))\n     else None\"\n\ndefinition\n  caps_to_entity :: \"entity_id \\<Rightarrow> entity_id \\<Rightarrow> state \\<Rightarrow> cap set\"\nwhere\n  \"caps_to_entity e e' s \\<equiv> {cap. cap \\<in> direct_caps_of s e' \\<and> target cap = e}\"\n\ndefinition\n  revokeOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> modify_state_n\" where\n  \"revokeOperation e c s \\<equiv>\n    {s'. \\<exists>cap_map. \\<forall>e'. cap_map e' \\<subseteq> caps_to_entity (target c) e' s \\<and>\n         s' = removeSetOfCaps cap_map s}\"\n\ndefinition\n  destroyOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"destroyOperation e c s \\<equiv> s(target c := None)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-deterministic System Call Execution: Execute a single system operation non-deterministically, where each operation (create, take, grant, copy, remove, remove set, revoke, destroy) is performed based on the provided parameters and the current state.",
    "input": "",
    "output": "primrec\n  step' :: \"sysOPs \\<Rightarrow> modify_state_n\"\nwhere\n  \"step' (SysCreate    e c\\<^sub>1 c\\<^sub>2) s   = {createOperation e c\\<^sub>1 c\\<^sub>2 s}\"\n| \"step' (SysTake      e c\\<^sub>1 c\\<^sub>2 R) s = {takeOperation  e c\\<^sub>1 c\\<^sub>2 R s}\"\n| \"step' (SysGrant     e c\\<^sub>1 c\\<^sub>2 R) s = {grantOperation  e c\\<^sub>1 c\\<^sub>2 R s}\"\n| \"step' (SysCopy      e c\\<^sub>1 c\\<^sub>2 R) s = {copyOperation e c\\<^sub>1 c\\<^sub>2 R s}\"\n| \"step' (SysRemove    e c\\<^sub>1 c\\<^sub>2)   s = {removeOperation e c\\<^sub>1 c\\<^sub>2 s}\"\n| \"step' (SysRemoveSet e c C)    s = {removeSetOperation e c C s}\"\n| \"step' (SysRevoke    e c) s      =  revokeOperation e c s\"\n| \"step' (SysDestroy   e c) s      = {destroyOperation e c s}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Operation Step: Execute a system operation only if it is legal in the current state. If the operation is legal, update the state accordingly; otherwise, the state remains unchanged.",
    "input": "",
    "output": "definition\n  step :: \"sysOPs \\<Rightarrow> modify_state_n\" where\n  \"step cmd s \\<equiv> if legal cmd s then (step' cmd s) \\<union> {s} else {s}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Execution of Command List: Execute a list of commands in reverse order, where each command transitions the system state, and the final state set is the union of all possible states resulting from the execution of each command.",
    "input": "",
    "output": "primrec\n  execute :: \"sysOPs list \\<Rightarrow> state \\<Rightarrow> state set\"\nwhere\n  \"execute [] s = {s}\"\n| \"execute (cmd#cmds) s = \\<Union> (step cmd ` ( execute cmds s ))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Properties of the Model:\n\n- **Entity and Store Relationships**: Defines relationships and properties between entities and the store, including entity existence, connectedness, and capability ownership. Ensures that if an entity is in the store, it is not `None`, and if an entity has no direct capabilities, it also has no indirect capabilities.\n\n- **Capability Rights and Diminishment**: Establishes that the intersection of any capability with all rights remains the same, and the diminish operation on a set of capabilities with all rights does not change the set. Also, the order of applying diminish operations is associative.\n\n- **Execution Properties**: Ensures that the execution of a sequence of operations on a state is non-empty, and the result of executing a concatenated sequence of operations is equivalent to executing each sequence in succession.",
    "input": "",
    "output": "lemma Int_all_rights [simp]: \"c \\<inter> all_rights = c\"\n  by (simp add: all_rights_def)\n\nlemma is_entity_dom: \"is_entity s e = (e \\<in> dom s)\"\n  by (simp add: is_entity_def dom_def)\n\nlemma is_entity_imp_not_None:\n  \"is_entity s e \\<Longrightarrow> s e \\<noteq> None\"\n  by (simp add: is_entity_def)\n\nlemma store_connected_refl [simp]:\n  \"(e, e) \\<in> store_connected s\"\n  by (simp add: store_connected_def)\n\nlemma no_caps_of_imp_not_connected [rule_format]:\n  \"\\<lbrakk>(e, x) \\<in> store_connected s\\<rbrakk>\n  \\<Longrightarrow> direct_caps_of s e = {} \\<longrightarrow> x = e\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl.induct)\n   apply simp\n  apply (clarsimp simp: store_connected_direct_def direct_caps_of_def)\n  done\n\nlemma no_direct_caps_of_no_caps_of:\n  \"(direct_caps_of s e = {}) = (caps_of s e = {})\"\n  apply (rule iffI)\n   apply (clarsimp simp add: caps_of_def)\n   apply (drule (1) no_caps_of_imp_not_connected)\n   apply simp\n  apply (clarsimp simp add: caps_of_def store_connected_def)\n  done\n\nlemma no_direct_caps_of_imp_no_caps_of:\n  \"direct_caps_of s e = {} \\<Longrightarrow> caps_of s e = {}\"\n  by (rule no_direct_caps_of_no_caps_of [THEN iffD1])\n\nlemma no_caps_of_imp_no_direct_caps_of:\n  \"caps_of s e = {} \\<Longrightarrow> direct_caps_of s e = {}\"\n  by (rule no_direct_caps_of_no_caps_of [THEN iffD2])\n\nlemma store_connected_direct_in_store_connected:\n  \"(x, y) \\<in> store_connected_direct s \\<Longrightarrow> (x, y) \\<in> store_connected s\"\n  by (simp add: store_connected_def)\n\nlemma no_diminish [simp]:\n  \"diminish all_rights c = c\"\n  by (simp add: diminish_def)\n\nlemma no_diminish_image [simp]:\n  \"diminish all_rights ` C = C\"\n  by (fastforce)\n\nlemma diminish_diminish [simp]:\n  \"diminish dimR2 (diminish dimR1 sc) = diminish (dimR1 \\<inter> dimR2) sc\"\n  by (clarsimp simp add: diminish_def Int_assoc)\n\nlemma diminish_range_diminish [simp]:\n  \"diminish dimR2 ` diminish dimR1 ` ssc = diminish (dimR1 \\<inter> dimR2) ` ssc\"\n  apply (rule set_eqI)\n  apply (rule iffI)\n   apply (clarsimp)\n  apply (clarsimp simp del: diminish_diminish simp add: diminish_diminish [symmetric])\n  done\n\nlemma execute_not_empty:\n  \"execute ops s \\<noteq> {}\"\n  apply (induct ops)\n   apply (simp)\n  apply (simp add: step_def del: if_image_distrib, fast)\n  done\n\nlemma execute_append [intro]:\n  \"\\<And> s s' s'' opsA. \\<lbrakk> s'' \\<in> execute opsA s; s' \\<in> execute opsB s'' \\<rbrakk> \\<Longrightarrow> s' \\<in> execute (opsB @ opsA) s\"\n  apply (induct opsB)\n   apply (simp)\n  apply (atomize)\n  apply (clarsimp)\n  apply (rule bexI)\n   apply (assumption)\n  by (drule spec | drule(1) mp)+",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Rights and Target Consistency: The target of a capability remains consistent across various operations, and the rights associated with each capability are defined and maintained according to the operation performed. Subproperties include:\n- The target of read, write, take, grant, create, store, and full capabilities is the same as the entity they reference.\n- The rights of read, write, take, grant, create, and store capabilities are restricted to specific sets of rights (e.g., {Read}, {Write}, {Take}, {Grant}, {Create}, {Store}).\n- The full capability includes all possible rights.\n- Diminishing a capability's rights results in the intersection of the original rights and the specified set of rights, while the target remains unchanged.",
    "input": "",
    "output": "lemma heapAdd_read_cap [simp]:\n  \"target (read_cap e) = e\"\n  by (simp add: read_cap_def)\n\nlemma rights_read_cap [simp]:\n  \"rights (read_cap e) = {Read}\"\n  by (simp add: read_cap_def)\n\nlemma heapAdd_write_cap [simp]:\n  \"target (write_cap e) = e\"\n  by (simp add: write_cap_def)\n\nlemma rights_write_cap [simp]:\n  \"rights (write_cap e) = {Write}\"\n  by (simp add: write_cap_def)\n\nlemma heapAdd_take_cap [simp]:\n  \"target (take_cap e) = e\"\n  by (simp add: take_cap_def)\n\nlemma rights_take_cap [simp]:\n  \"rights (take_cap e) = {Take}\"\n  by (simp add: take_cap_def)\n\nlemma heapAdd_grant_cap [simp]:\n  \"target (grant_cap e) = e\"\n  by (simp add: grant_cap_def)\n\nlemma rights_grant_cap [simp]:\n  \"rights (grant_cap e) = {Grant}\"\n  by (simp add: grant_cap_def)\n\nlemma heapAdd_create_cap [simp]:\n  \"target (create_cap e) = e\"\n  by (simp add: create_cap_def)\n\nlemma rights_create_cap [simp]:\n  \"rights (create_cap e) = {Create}\"\n  by (simp add: create_cap_def)\n\nlemma heapAdd_store_cap [simp]:\n  \"target (store_cap e) = e\"\n  by (simp add: store_cap_def)\n\nlemma rights_store_cap [simp]:\n  \"rights (store_cap e) = {Store}\"\n  by (simp add: store_cap_def)\n\nlemma heapAdd_full_cap [simp]:\n  \"target (full_cap e) = e\"\n  by (simp add: full_cap_def)\n\nlemma rights_full_cap [simp]:\n  \"rights (full_cap e) = all_rights\"\n  by (simp add: full_cap_def)\n\nlemma entity_diminish [simp]:\n  \"target (diminish R c) = target c\"\n  by (simp add: diminish_def)\n\nlemma rights_diminish [simp]:\n  \"rights (diminish R c) = rights c \\<inter> R\"\n  by (simp add: diminish_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Relationships: Establishes the relationship between capabilities in `caps_of` and `direct_caps_of`, ensuring that any capability in `caps_of` is also present in `direct_caps_of` for some endpoint, and vice versa. Additionally, it defines the conditions under which a capability is included in `all_caps_of`.",
    "input": "",
    "output": "lemma caps_of_imp_some_direct_cap:\n  \"c \\<in> caps_of s e \\<Longrightarrow> \\<exists>e'. c \\<in> direct_caps_of s e'\"\n  by (auto simp: caps_of_def)\n\nlemma caps_of_imp_some_store_connected_direct_cap:\n  \"c \\<in> caps_of s e \\<Longrightarrow> \\<exists>e'. (e, e') \\<in> store_connected s \\<and> c \\<in> direct_caps_of s e'\"\n  by (auto simp: caps_of_def)\n\nlemma direct_cap_in_cap:\n  \"c \\<in> direct_caps_of s e \\<Longrightarrow> c \\<in> caps_of s e\"\n  by (auto simp: caps_of_def store_connected_def)\n\nlemma all_caps_ofE [elim!]:\n  \"\\<lbrakk> c \\<in> all_caps_of s; \\<And>e'. c \\<in> direct_caps_of s e' \\<Longrightarrow> P \\<rbrakk> \\<Longrightarrow> P\"\n  by (fastforce simp add: all_caps_of_def)\n\nlemma all_caps_ofI [intro]:\n  \"c \\<in> direct_caps_of s e' \\<Longrightarrow> c \\<in> all_caps_of s\"\n  by (fastforce simp add: all_caps_of_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity and Capability Relationships: Ensures that only entities can have associated capabilities, and non-entities do not possess any direct or indirect capabilities.",
    "input": "",
    "output": "lemma entity_not_not_entity:\n  \"\\<lbrakk>is_entity s e\\<^sub>1; \\<not> is_entity s e\\<^sub>2\\<rbrakk> \\<Longrightarrow> e\\<^sub>1 \\<noteq> e\\<^sub>2\"\n  by (auto simp: is_entity_def)\n\nlemma no_direct_caps_of_in_nonEntity:\n  \"\\<not> is_entity s e \\<Longrightarrow> direct_caps_of s e = {}\"\n  by (auto simp: direct_caps_of_def is_entity_def split:option.splits)\n\nlemma not_is_entity_imp_no_direct_caps_of:\n  \"\\<not> is_entity s e \\<Longrightarrow> caps_of s e = {}\"\n  by (drule no_direct_caps_of_in_nonEntity, erule no_direct_caps_of_imp_no_caps_of)\n\nlemma direct_caps_of_imp_is_entity:\n  \"c \\<in> direct_caps_of s e \\<Longrightarrow> is_entity s e\"\n  by (auto intro: classical dest: no_direct_caps_of_in_nonEntity)\n\nlemma caps_of_imp_is_entity:\n  \"c \\<in> caps_of s e \\<Longrightarrow> is_entity s e\"\n  by (auto intro: classical dest: not_is_entity_imp_no_direct_caps_of)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Store-Connected Relationship: If a capability with store rights is present in the direct or overall caps of a source endpoint, then the source and the target of the capability are store-connected.",
    "input": "",
    "output": "lemma store_caps_of_store_connected_direct:\n  \"\\<lbrakk>c \\<in> direct_caps_of s e; Store \\<in> rights c\\<rbrakk>\n  \\<Longrightarrow> (e, target c) \\<in> store_connected_direct s\"\n  by (fastforce simp: store_connected_direct_def)\n\nlemma store_caps_store_connected:\n  \"\\<lbrakk>c \\<in> caps_of s e; Store \\<in> rights c\\<rbrakk> \\<Longrightarrow> (e, target c) \\<in> store_connected s\"\n  apply (clarsimp simp: store_connected_def caps_of_def)\n  by (frule (1) store_caps_of_store_connected_direct, simp)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Authority Confinement in Islands: Ensures that the capabilities within an island remain confined and dominated by a specified capability after executing a set of commands. This property maintains the integrity and security of the system by preventing unauthorized access or modification of capabilities within the island.",
    "input": "",
    "output": "(* Title:   Confinement_S\n * Description: Rephrasing of the confinement proof using the concept of islands.\n *)\n\ntheory Islands_S\nimports Confine_S\nbegin\n\ndefinition\n  island :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id set\" where\n  \"island s x \\<equiv> {e\\<^sub>i. s \\<turnstile> x \\<leftrightarrow>* e\\<^sub>i}\"\n\ndefinition\n  island_caps :: \"state \\<Rightarrow> entity_id \\<Rightarrow> cap set\" where\n  \"island_caps s x \\<equiv> \\<Union>(caps_of s ` island s x)\"\n\nlemma island_caps_def2:\n  \"island_caps s x \\<equiv> \\<Union> e \\<in> island s x. caps_of s e\"\n  by(simp add: island_caps_def)\n\nlemma island_caps_def3:\n  \"island_caps s x =  \\<Union>(direct_caps_of s ` island s x)\"\n  apply (clarsimp simp: island_caps_def)\n  apply rule\n   apply (clarsimp simp: island_def caps_of_def)\n   apply (drule store_connected_directly_tgs_connected)\n   apply (metis directly_tgs_connected_rtrancl_into_rtrancl)\n  apply (fastforce simp: caps_of_def store_connected_def)\n  done\n\nlemma island_caps_dom:\n  \"island_caps s e\\<^sub>x \\<le>cap c =\n  (\\<forall>e\\<^sub>i. (e\\<^sub>x, e\\<^sub>i) \\<in> tgs_connected s \\<longrightarrow> caps_of s e\\<^sub>i \\<le>cap c)\"\n  by (auto simp add: island_caps_def caps_dominated_by_def island_def)\n\nlemma authority_confinement_islands:\n  \"\\<lbrakk>s' \\<in> execute cmds s;\n    island_caps s x \\<le>cap c\\<rbrakk>\n  \\<Longrightarrow> island_caps s' x \\<le>cap c\"\n  apply (simp add: island_caps_dom)\n  apply clarsimp\n  apply (frule (1) tgs_connected_preserved)\n  apply (subst (asm) tgs_connected_comm_eq)\n  apply (erule authority_confinement)\n  apply clarsimp\n  apply (erule_tac x=e\\<^sub>i' in allE)\n  apply (erule impE)\n  apply (metis (opaque_lifting, no_types) tgs_connected_comm_eq tgs_connected_def rtrancl_trans)\n  apply clarsimp\n  done\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flow and Transitive Flow: Define the flow and transitive flow relationships between entities in a state, where an entity can read or write to another if it has the corresponding capability. The flow relationship is based on the capabilities of the entities, and the transitive flow extends this to include indirect flows through intermediate entities.",
    "input": "",
    "output": "theory Isolation_S\nimports Islands_S\nbegin\n\ndefinition\n  set_flow :: \"state \\<Rightarrow> (entity_id set \\<times> entity_id set) set\" where\n  \"set_flow s \\<equiv> {(X,Y). \\<exists>x \\<in> X. \\<exists>y \\<in> Y.\n                        (read_cap x \\<in>cap caps_of s y \\<or>\n                        write_cap y \\<in>cap caps_of s x)}\"\n\nlemma set_flow_def2:\n  \"(X, Y) \\<in> set_flow s = (\\<exists>x \\<in> X. \\<exists>y \\<in> Y.\n                        (read_cap x \\<in>cap caps_of s y \\<or>\n                        write_cap y \\<in>cap caps_of s x))\"\n  by (simp add: set_flow_def)\n\ndefinition\n  flow :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"flow s \\<equiv>  {(x,y). (island s x, island s y) \\<in> set_flow s}\"\n\nlemma flow_def2:\n  \"(x, y) \\<in> flow s = ((island s x, island s y) \\<in> set_flow s)\"\n  by (simp add: flow_def)\n\n\nabbreviation\n  in_flow :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<leadsto> _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x \\<leadsto> y \\<equiv> (x,y) \\<in> flow s\"\n\ndefinition\n  flow_trans :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" (\"flow\\<^sup>*\") where\n  \"flow_trans s \\<equiv> (flow s)\\<^sup>*\"\n\nabbreviation\n  in_flow_trans :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<leadsto>* _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x \\<leadsto>* y == (x,y) \\<in> flow_trans s\"\n\nnotation (latex output)\n  in_flow_trans (\"_ \\<turnstile> _ \\<leadsto>\\<^sup>* _\" [60,0,60] 61)\n\ntranslations\n  \"\\<not> (s \\<turnstile> x \\<leadsto> y)\" <= \"(x,y) \\<notin> CONST flow s\"\n  \"\\<not> (s \\<turnstile> x \\<leadsto>* y)\" <= \"(x,y) \\<notin> CONST flow_trans s\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Information Flow Preservation: Ensures that if there is no information flow from \\( x \\) to \\( y \\) in the initial state \\( s \\), then there will be no information flow from \\( x \\) to \\( y \\) in any state \\( s' \\) resulting from the execution of a sequence of commands.",
    "input": "",
    "output": "lemma rights_extra_rights_read_cap [simp]:\n  \"rights (extra_rights (read_cap e)) = {Read}\"\n  by (simp add: rights_extra_rights)\n\nlemma rights_extra_rights_write_cap [simp]:\n  \"rights (extra_rights (write_cap e)) = {Write}\"\n  by (simp add: rights_extra_rights)\n\nlemma flow_trans_refl [simp]:\n  \"s \\<turnstile> x \\<leadsto>* x\"\n  by (metis flow_trans_def rtrancl.rtrancl_refl)\n\nlemma flow_connected_step:\n  \"\\<lbrakk>s' \\<turnstile> x \\<leadsto>* y; s' \\<in> step cmd s\\<rbrakk> \\<Longrightarrow>\n    s \\<turnstile> x \\<leadsto>* y\"\n  apply (erule rtrancl_induct [where r=\"flow s'\",\n                              simplified flow_trans_def[symmetric]])\n   apply simp\n  apply (subgoal_tac \"s \\<turnstile> y \\<leadsto> z\")\n   apply (fastforce simp: flow_trans_def rtrancl.rtrancl_into_rtrancl)\n  apply (clarsimp simp: flow_def island_def set_flow_def)\n  apply (frule_tac x=y in tgs_connected_preserved_step, simp)\n  apply (frule_tac x=z in tgs_connected_preserved_step, simp)\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (erule disjE)\n   apply clarsimp\n   apply (drule (1) caps_of_op)\n   apply (clarsimp simp: cap_in_caps_def)\n   apply (metis (no_types) tgs_connected_trans subsetD)\n  apply clarsimp\n  apply (drule (1) caps_of_op)\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (metis (no_types) tgs_connected_trans subsetD)\n  done\n\nlemma flow_connected [rule_format]:\n  \"\\<forall>s'.  s' \\<in> execute cmds s \\<longrightarrow>\n    s' \\<turnstile> x \\<leadsto>* y \\<longrightarrow>\n    s \\<turnstile> x \\<leadsto>* y\"\n  apply (induct_tac cmds, simp)\n  apply clarsimp\n  apply (drule (1) flow_connected_step)\n  apply auto\n  done\n\nlemma information_flow:\n  \"\\<lbrakk>s' \\<in> execute cmds s;\n  \\<not> s \\<turnstile> x \\<leadsto>* y\\<rbrakk> \\<Longrightarrow>\n  \\<not> s' \\<turnstile> x \\<leadsto>* y\"\n  by (auto simp: flow_connected)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entity Capabilities and Store-Connected Relations: Defines the capabilities and store-connected relations for entities in the example state. Each entity has a set of direct capabilities, and the store-connected relation determines the transitive closure of store rights, allowing the identification of all entities that can be reached through a chain of store rights.",
    "input": "",
    "output": "theory Example\nimports System_S\nbegin\n\ndefinition \"id0 \\<equiv> 0\"\ndefinition  \"id1 \\<equiv> 1\"\ndefinition  \"id2 \\<equiv> 2\"\n\ndefinition \"e0 \\<equiv> Entity {\\<lparr> target = id1, rights = {Store}\\<rparr>}\"\ndefinition \"e1 \\<equiv> Entity {\\<lparr> target = id2, rights = {Grant}\\<rparr>}\"\ndefinition \"e2 \\<equiv> Entity {}\"\n\nlemmas id_defs = id0_def id1_def id2_def\nlemmas entity_defs = e0_def e1_def e2_def\n\ndefinition example_state :: \"state\" where\n\"example_state \\<equiv> [0 \\<mapsto> e0, 1 \\<mapsto> e1, 2 \\<mapsto> e2] \"\n\nlemma de0:\n  \"direct_caps_of example_state id0 =\n   {\\<lparr> target = id1, rights = {Store}\\<rparr>}\"\n  by (simp add: direct_caps_of_def example_state_def\n                id_defs entity_defs\n         split: option.splits)\n\nlemma de1:\n  \"direct_caps_of example_state id1 =\n   {\\<lparr> target = id2, rights = {Grant}\\<rparr>}\"\n  by (simp add: direct_caps_of_def example_state_def\n                id_defs entity_defs\n         split: option.splits)\n\nlemma de2: \"direct_caps_of example_state id2 = {}\"\n  by (simp add: direct_caps_of_def example_state_def\n                id_defs entity_defs\n         split: option.splits)\n\n\nlemma scd:\n  \"store_connected_direct example_state = {(id0,id1)}\"\n  by (auto simp: store_connected_direct_def direct_caps_of_def\n                 example_state_def id_defs entity_defs\n          split: if_split_asm option.splits\n           cong: conj_cong)\n\nlemma sc:\n  \"store_connected example_state = {(id0,id1)} \\<union> Id\"\n  apply simp\n  apply (rule equalityI)\n  apply (insert scd)\n   apply (simp add: store_connected_def)\n   apply clarsimp\n   apply (erule converse_rtranclE)\n    apply simp\n   apply clarsimp\n   apply (erule rtranclE)\n    apply simp\n   apply clarsimp\n  apply (fastforce simp: store_connected_def)\n  done\n\nlemma sc': \"store_connected example_state = Id \\<union> {(0,1)}\"\n  by (clarsimp simp: sc id_defs)\n\nlemma ce0:\n  \"caps_of example_state id0 =\n   {\\<lparr>target = id1, rights = {Store}\\<rparr>,\n    \\<lparr>target = id2, rights = {Grant}\\<rparr>}\"\n  by (fastforce simp: caps_of_def sc Collect_disj_eq de0 de1)\n\nlemma ce1:\n  \"caps_of example_state id1 =\n   {\\<lparr> target = id2, rights = {Grant}\\<rparr>}\"\n  apply (clarsimp simp: caps_of_def sc Collect_disj_eq de0 de1)\n  apply (simp add: id0_def id1_def)\n  done\n\nlemma ce2: \"caps_of example_state id2 = {}\"\n  apply (simp add: caps_of_def sc)\n  apply (rule allI)\n  apply (rule conjI)\n   apply (simp add: id0_def id2_def)\n  apply (simp add: de2)\n  done\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Storable Object Instances: Defines the instances of pspace_storable objects, including endpoints, notifications, CTEs, user data, user data devices, and TCBs. Each instance provides methods for projecting and injecting kernel objects, and specifies the object type, ensuring that these objects can be managed and manipulated within the kernel's physical space.",
    "input": "",
    "output": "(*\n    Defines the instances of pspace_storable objects.\n*)\n\nchapter \"Storable Object Instances\"\n\ntheory ObjectInstances_H\nimports\n  Structures_H\n  State_H\n  PSpaceStorable_H\n  Config_H\nbegin\n\narch_requalify_consts (H)\n  VPtr\n  newContext\n\nlemma projectKO_eq2:\n  \"((obj,s') \\<in> fst (projectKO ko s)) = (projectKO_opt ko = Some obj \\<and> s' = s)\"\n  by (auto simp: projectKO_def fail_def return_def split: option.splits)\n\n\n\\<comment> \\<open>-----------------------------------\\<close>\n\ninstantiation endpoint :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_ep:\n  \"projectKO_opt e \\<equiv> case e of KOEndpoint e \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_ep [simp]:\n  \"injectKO e \\<equiv> KOEndpoint e\"\n\ndefinition\n  koType_ep [simp]:\n  \"koType (t::endpoint itself) \\<equiv> EndpointT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_ep split: kernel_object.splits)\n\nend\n\ninstantiation notification :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_ntfn:\n  \"projectKO_opt e \\<equiv> case e of KONotification e \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_ntfn [simp]:\n  \"injectKO e \\<equiv> KONotification e\"\n\ndefinition\n  koType_ntfn [simp]:\n  \"koType (t::notification itself) \\<equiv> NotificationT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_ntfn split: kernel_object.splits)\n\nend\n\n\ninstantiation cte :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_cte:\n  \"projectKO_opt e \\<equiv> case e of KOCTE e \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_cte [simp]:\n  \"injectKO c \\<equiv> KOCTE c\"\n\ndefinition\n  koType_cte [simp]:\n  \"koType (t::cte itself) \\<equiv> CTET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_cte split: kernel_object.splits)\n\nend\n\ninstantiation user_data_device :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_user_data_device:\n  \"projectKO_opt e \\<equiv> case e of KOUserDataDevice \\<Rightarrow> Some UserDataDevice | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_user_data_device [simp]:\n  \"injectKO (t :: user_data_device) \\<equiv> KOUserDataDevice\"\n\ndefinition\n  koType_user_data_device [simp]:\n  \"koType (t::user_data_device itself) \\<equiv> UserDataDeviceT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_user_data_device split: kernel_object.splits)\nend\n\ninstantiation user_data :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_user_data:\n  \"projectKO_opt e \\<equiv> case e of KOUserData \\<Rightarrow> Some UserData | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_user_data [simp]:\n  \"injectKO (t :: user_data) \\<equiv> KOUserData\"\n\ndefinition\n  koType_user_data [simp]:\n  \"koType (t::user_data itself) \\<equiv> UserDataT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_user_data split: kernel_object.splits)\n\nend\n\n\ninstantiation tcb :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_tcb:\n  \"projectKO_opt e \\<equiv> case e of KOTCB e \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_tcb [simp]:\n  \"injectKO t \\<equiv> KOTCB t\"\n\ndefinition\n  koType_tcb [simp]:\n  \"koType (t::tcb itself) \\<equiv> TCBT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_tcb split: kernel_object.splits)\n\nend\n\n\nlemmas projectKO_opts_defs =\n  projectKO_opt_tcb projectKO_opt_cte projectKO_opt_ntfn projectKO_opt_ep\n  projectKO_opt_user_data projectKO_opt_user_data_device\n\nlemmas injectKO_defs =\n  injectKO_tcb injectKO_cte injectKO_ntfn injectKO_ep injectKO_user_data injectKO_user_data_device\n\nlemmas koType_defs =\n  koType_tcb koType_cte koType_ntfn koType_ep koType_user_data koType_user_data_device\n\n\\<comment> \\<open>-----------------------------------\\<close>\n\ninstantiation endpoint :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY Endpoint\n\ninstance\n  apply (intro_classes)\n  apply simp\n  apply (case_tac ko, auto simp: projectKO_opt_ep updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\ninstantiation notification :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY Notification\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_ntfn updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\ninstantiation cte :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY CTE\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_cte updateObject_cte\n                                 in_monad projectKO_eq2 typeError_def alignError_def\n                           split: kernel_object.splits if_split_asm)\n  done\n\nend\n\n\ninstantiation user_data :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY UserData\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_user_data updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\ninstantiation user_data_device :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY UserDataDevice\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_user_data_device updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\ninstantiation tcb :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY TCB\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_tcb updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Enumeration: Defines a comprehensive list of all system call labels, providing a clear and structured reference for invoking various kernel operations.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/InvocationLabels.lhs ArchLabels= ONLY GenInvocationLabels InvocationLabel\n#INCLUDE_HASKELL SEL4/API/InvocationLabels.lhs instanceproofs\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Pspace Storable Objects: Defines a framework for managing kernel objects in memory, including loading and updating objects while ensuring type and alignment constraints. The framework ensures that the type of an object remains consistent after updates and that objects are correctly aligned and do not overlap with adjacent objects in memory.",
    "input": "",
    "output": "theory PSpaceStorable_H\nimports\n  Structures_H\n  KernelStateData_H\n  \"Lib.DataMap\"\nbegin\n\narch_requalify_types (H)\n  arch_kernel_object_type\n\narch_requalify_consts (H)\n  archTypeOf\n\nlemma UserData_singleton [simp]:\n  \"(v = UserData) = True\" \"(UserData = v) = True\"\n  by (cases v, simp)+\n\nlemma UserDataDevice_singleton [simp]:\n  \"(v = UserDataDevice) = True\" \"(UserDataDevice = v) = True\"\n  by (cases v, simp)+\n\ndatatype\n  kernel_object_type =\n    EndpointT\n  | NotificationT\n  | CTET\n  | TCBT\n  | UserDataT\n  | UserDataDeviceT\n  | KernelDataT\n  | ArchT arch_kernel_object_type\n\nprimrec\n  koTypeOf :: \"kernel_object \\<Rightarrow> kernel_object_type\"\nwhere\n  \"koTypeOf (KOEndpoint e) = EndpointT\"\n| \"koTypeOf (KONotification e) = NotificationT\"\n| \"koTypeOf (KOCTE e) = CTET\"\n| \"koTypeOf (KOTCB e) = TCBT\"\n| \"koTypeOf (KOUserData) = UserDataT\"\n| \"koTypeOf (KOUserDataDevice) = UserDataDeviceT\"\n| \"koTypeOf (KOKernelData) = KernelDataT\"\n| \"koTypeOf (KOArch e) = ArchT (archTypeOf e)\"\n\ndefinition\n  typeError :: \"unit list \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\" where\n  \"typeError t1 t2 \\<equiv> fail\"\n\ndefinition\n  alignError :: \"nat \\<Rightarrow> 'a kernel\" where\n  \"alignError n \\<equiv> fail\"\n\ndefinition\n  alignCheck :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit kernel\" where\n  \"alignCheck x n \\<equiv> unless ((x && mask n) = 0) $ alignError n\"\n\ndefinition\n  magnitudeCheck :: \"machine_word \\<Rightarrow> machine_word option \\<Rightarrow> nat \\<Rightarrow> unit kernel\"\nwhere\n \"magnitudeCheck x y n \\<equiv> case y of None \\<Rightarrow> return ()\n               | Some z \\<Rightarrow> when (z - x < 1 << n) fail\"\n\nclass pre_storable =\n  fixes injectKO :: \"'a \\<Rightarrow> kernel_object\"\n  fixes projectKO_opt :: \"kernel_object \\<Rightarrow> 'a option\"\n  fixes koType :: \"'a itself \\<Rightarrow> kernel_object_type\"\n\n  assumes project_inject: \"(projectKO_opt ko = Some v) = (injectKO v = ko)\"\n  assumes project_koType: \"(\\<exists>v. projectKO_opt ko = Some (v::'a)) = (koTypeOf ko = koType TYPE('a))\"\nbegin\n\ndefinition\n  projectKO :: \"kernel_object \\<Rightarrow> 'a kernel\"\nwhere\n  \"projectKO e \\<equiv>\n  case projectKO_opt e of None \\<Rightarrow> fail | Some k \\<Rightarrow> return k\"\n\ndefinition\n  objBits :: \"'a \\<Rightarrow> nat\"\nwhere\n  \"objBits v \\<equiv> objBitsKO (injectKO v)\"\n\ndefinition\n  loadObject_default :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\"\nwhere\n  \"loadObject_default ptr ptr' next obj \\<equiv> do\n     assert (ptr = ptr');\n     val \\<leftarrow> projectKO obj;\n     alignCheck ptr (objBits val);\n     magnitudeCheck ptr next (objBits val);\n     return val\n  od\"\n\ndefinition\n  updateObject_default :: \"'a \\<Rightarrow> kernel_object \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object kernel\"\nwhere\n  \"updateObject_default val oldObj ptr ptr' next \\<equiv> do\n     assert (ptr = ptr');\n     (_ :: 'a) \\<leftarrow> projectKO oldObj;\n     alignCheck ptr (objBits val);\n     magnitudeCheck ptr next (objBits val);\n     return (injectKO val)\n  od\"\n\nend\n\nclass pspace_storable = pre_storable +\n  fixes makeObject :: 'a\n\n  \\<comment>\\<open>\n    `loadObject` is only used in the generic definition of `getObject`. It\n    describes how to extract a value of type `'a` from memory.\n\n    If `(obj, _) \\<in> loadObjext p before after ko` within `getObject`, then:\n      - @{term \"p :: machine_word\"} is the addres that we want to read an\n        instance of `'a` from.\n      - @{term \"before :: machine_word\"} is the address of the nearest\n        object at or before `p`.\n      - @{term \"after :: machine_word option\"} is the address of the nearest\n        object after `p`, if any (for checking overlap).\n      - @{term \"ko :: kernel_object\"} is the object currently at `before`.\n      - @{term \"obj :: 'a\"} is the value extracted from `ko`.\n\n    Graphically, the \"memory\" looks like this:\n\n    before  p              after\n    |-------|--+-----+-----|---|\n    |       +~~+ <---+---------- The span of obj, the object we want to extract.\n    +~~~~~~~~~~~~~~~~+ <-------- The span of ko, the existing object that spans obj.\n\n                           +~~~+ The span of whatever object comes after obj.\n                                 We don't care about this beyond making sure\n                                 it doesn't overlap with ko.\n\n    In almost every case, the object in memory (ko) is the same type of object\n    as the one being loaded (obj). For example, for a reply object our parameters\n    look like this:\n\n    p, before\n    |-----------|\n    +~~~~~~~~~~~+ <- The span of two objects:\n                     - ko, the existing object (which should be a reply object).\n                     - obj, the object that we want to load from memory. This will\n                       just be ko projected through @{term projectKO}.\n\n    In these simple cases, @{term loadObject_default} is a good specification\n    for how to load an instance of `'a` from memory.\n\n    The only interesting case is when we're loading a CTE, which might be\n    inside a TCB. Then memory looks like this:\n\n    before  p\n    |-------|--+-----+\n    |       +~~+ <---+---- The span of obj, i.e. the CTE which we're reading from\n    |                |     memory.\n    +~~~~~~~~~~~~~~~~+ <-- The span of ko, i.e. the TCB surrounding and containing\n                           obj.\n\n    In this case, the process for extracting the CTE from the surrounding TCB\n    is more involved. See `loadObject_cte` in `ObjectInstances_H`.\n  \\<close>\n  fixes loadObject :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\"\n\n  \\<comment>\\<open>\n    `updateObject` is only used in the generic definition of `setObject`,\n    but it shows up in a few lemma statements as well. It describes how to update\n    the kernel object contents of memory depending on what's already in that\n    memory.\n\n    If `(ko', _) \\<in> updateObject v ko p before after s` within `setObject`, then:\n      - @{term \"v :: 'a\"} is the new object you want to write at pointer\n        @{term \"p :: machine_word\"}.\n      - @{term \"before :: machine_word\"} is the address of the nearest\n        object at or before `p`.\n      - @{term \"ko :: kernel_object\"} is the object currently at `before`.\n      - @{term \"after :: machine_word option\"} should be the address of the nearest\n        object after `p`, if any (for checking overlap).\n      - The returned value @{term \"ko' :: kernel_object\"} is the old object `ko`,\n        updated as required by `v`. This value gets inserted by `setObject` into\n        memory at the address `before`.\n\n    Graphically, the \"memory\" looks like this:\n\n    before  p              after\n    |-------|--+-----+-----|---|\n    |       +~~+ <---+---------- The span of v, the object we want to insert.\n    +~~~~~~~~~~~~~~~~+ <-------- The span of ko, the existing object that spans v.\n                                 This is also the span of ko', which will be what\n                                 gets put into memory after the update.\n\n                           +~~~+ The span of whatever object comes after ko.\n                                 We don't care about this beyond making sure\n                                 it doesn't overlap with ko before or after it\n                                 gets updated with v.\n\n    In almost every case, the object in memory (ko) is the same type of object\n    as the one being inserted (v). For example, for a reply object our parameters\n    look like this:\n\n    p, before\n    |-----------|\n    +~~~~~~~~~~~+ <- The span of three objects:\n                     - v, the new reply object we want to insert.\n                     - ko, the existing object (which should be a reply object).\n                     - ko', the new object (which should be a reply object if\n                       the previous one was).\n\n    In these simple cases, @{term updateObject_default} is a good specification\n    for how to update the existing kernel object.\n\n    The only interesting case is when we're updating a CTE, which might be\n    inside a TCB. Then memory looks like this:\n\n    before  p\n    |-------|--+-----+\n    |       +~~+ <---+---- The span of v, i.e. the CTE which we're inserting into\n    |                |     memory.\n    +~~~~~~~~~~~~~~~~+ <-- The span of ko, i.e. the TCB surrounding and containing v.\n                           This is also the span of ko', which is \"just\" a copy\n                           of ko with the relevant CTE updated.\n\n    In this case, the process for updating the surrounding TCB is more involved.\n    See `updateObject_cte` in `ObjectInstances_H`.\n  \\<close>\n  fixes updateObject :: \"'a \\<Rightarrow> kernel_object \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow>\n                              machine_word option \\<Rightarrow> kernel_object kernel\"\n\n  \\<comment>\\<open>\n    If updating an object succeeds, then the type of the updated object (ko')\n    should be the same as the original object (ko).\n  \\<close>\n  assumes updateObject_type:\n  \"(ko', s') \\<in> fst (updateObject v ko p p' p'' s) \\<Longrightarrow> koTypeOf ko' = koTypeOf ko\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Operations: Provides functions to manage capabilities within CNodes, including revoking a capability at a specified location. This ensures that the system can dynamically modify and control the capabilities stored in CNodes, maintaining the integrity and security of the capability space.",
    "input": "",
    "output": "chapter \"CNodes\"\n\ntheory CNode_H\nimports\n  FaultMonad_H\n  ThreadDecls_H\n  RetypeDecls_H\n  TCBDecls_H\n  CSpaceDecls_H\n  EndpointDecls_H\n  PSpaceFuns_H\nbegin\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs decls_only NOT cteRevoke\n\nfunction\n  cteRevoke :: \"machine_word \\<Rightarrow> unit kernel_p\"\nwhere\n \"cteRevoke p s =\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteRevoke\n\n  p s\"\nby auto\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs bodies_only NOT finaliseSlot cteRevoke cteDeleteOne noReplyCapsFor\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Declarations: Define the structures and declarations for interrupt objects, including their properties and methods, to manage and handle interrupts within the system.",
    "input": "",
    "output": "theory InterruptDecls_H\nimports\n  RetypeDecls_H\n  KI_Decls_H\nbegin\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n#INCLUDE_HASKELL SEL4/Object/Interrupt.lhs Arch=ArchInterrupt_H decls_only NOT deletedIRQHandler\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Resolve Address Bits: The function resolves the address bits of a capability based on the provided cptr and bit count, returning the corresponding machine word and bit count. This ensures that the capability's address is correctly interpreted within the CSpace.",
    "input": "",
    "output": "chapter \"CSpace\"\n\ntheory CSpace_H\nimports CSpaceDecls_H Object_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/CSpace.lhs bodies_only NOT resolveAddressBits\n\n\nfunction\n  resolveAddressBits ::\n  \"capability \\<Rightarrow> cptr \\<Rightarrow> nat \\<Rightarrow>\n   (lookup_failure, (machine_word * nat)) kernel_f\"\nwhere\n \"resolveAddressBits a b c =\n#INCLUDE_HASKELL SEL4/Kernel/CSpace.lhs BODY resolveAddressBits\na b c\"\n  by auto\n\ntermination\n  apply (relation \"measure (snd o snd)\")\n  apply (auto simp add: in_monad split: if_split_asm)\n  done\n\ndefs\n  resolveAddressBits_decl_def:\n  \"CSpaceDecls_H.resolveAddressBits \\<equiv> resolveAddressBits\"\ndeclare resolveAddressBits_decl_def[simp]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Convert Pointer to Bit List: The function `ptrBits` converts a pointer into its bit representation, returning the result as a list of bits.",
    "input": "",
    "output": "definition\n  ptrBits_def[simp]:\n \"ptrBits \\<equiv> to_bl\"\n\n#INCLUDE_HASKELL SEL4/Model/PSpace.lhs ONLY ptrBitsForSize",
    "system": "",
    "history": []
  },
  {
    "instruction": "Physical Memory Management: Manages the allocation, deallocation, and organization of physical memory, ensuring efficient and secure memory usage.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Model/PSpace.lhs Data.Map=DataMap ONLY PSpace\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for Threads: Defines the necessary function declarations for thread management, including structures, fault handling, kernel initialization, and architecture-specific thread operations.",
    "input": "",
    "output": "chapter \"Function Declarations for Threads\"\n\ntheory ThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\n  ArchThreadDecls_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs decls_only NOT transferCapsToSlots\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Structures: Define and handle different types of faults, including architecture-specific faults, to ensure the system can properly identify, report, and manage errors and exceptions.",
    "input": "",
    "output": "(*\n    The fault datatype.\n*)\n\nchapter \"Fault Structures\"\n\ntheory Fault_H\nimports ArchFault_H\nbegin\n\narch_requalify_types (H)\n  arch_fault\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Types.lhs\n#INCLUDE_HASKELL SEL4/API/Failures.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Failures.lhs bodies_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Retyping Function Declarations: Define the necessary functions and data structures for redefining object types, including handling interrupts and managing object types.",
    "input": "",
    "output": "chapter \"Function Declarations for Retyping Objects\"\n\ntheory RetypeDecls_H\nimports\n  ArchRetypeDecls_H\n  Structures_H\n  FaultMonad_H\n  Invocations_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType.lhs decls_only\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt.lhs decls_only ONLY deletedIRQHandler\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Collection of SEL4 Model Modules: Aggregates and organizes the various SEL4 model modules into a cohesive framework for system specification and verification.",
    "input": "",
    "output": "end",
    "system": "",
    "history": []
  },
  {
    "instruction": "Activate Idle Thread: Enables the activation of an idle thread, ensuring that the system can efficiently manage resources and maintain optimal performance when no other threads are ready to run.",
    "input": "",
    "output": "requalify_consts\n  activateIdleThread",
    "system": "",
    "history": []
  },
  {
    "instruction": "Namespace Disambiguation: Resolve naming conflicts between architecture-specific and non-architecture-specific constants by requalifying them with their respective namespaces.",
    "input": "",
    "output": "requalify_consts (aliasing)\n  configureIdleThread\n  switchToIdleThread\n  switchToThread\n\ncontext begin global_naming global\n\nrequalify_consts (aliasing)\n  ThreadDecls_H.configureIdleThread\n  ThreadDecls_H.switchToIdleThread\n  ThreadDecls_H.switchToThread\n\nend\nend\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs Arch=Arch bodies_only NOT doNormalTransfer doIPCTransfer doReplyTransfer doNormalTransfer transferCaps transferCapsToSlots\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs Arch=Arch ONLY transferCapsToSlots\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs Arch=Arch bodies_only ONLY doNormalTransfer doIPCTransfer doReplyTransfer doNormalTransfer transferCaps\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Notification Function Declarations: Define the necessary functions for managing notifications, including creating, binding, and unbinding notification objects, as well as handling notification events.",
    "input": "",
    "output": "chapter \"Function Declarations for Notifications\"\n\ntheory NotificationDecls_H imports    \"FaultMonad_H\"\n begin\n\n#INCLUDE_HASKELL SEL4/Object/Notification.lhs decls_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Deletion: Deletes a capability from a CNode, handling various types of capabilities including CNodeCap, ThreadCap, and Zombie. The deletion process involves finalizing the slot, reducing zombies, and managing related IRQ handlers, IPC cancellations, and thread suspensions to ensure the system's integrity and consistency.",
    "input": "",
    "output": "chapter \"Deleting Capabilities\"\n\ntheory Delete_H\nimports\n  CNode_H\n  Interrupt_H\n  Endpoint_H\n  Thread_H\nbegin\n\ndefinition\n  slotsPointed :: \"capability \\<Rightarrow> machine_word set\"\nwhere\n \"slotsPointed cap \\<equiv> case cap of\n   CNodeCap ptr a b c   \\<Rightarrow> {ptr}\n | ThreadCap ptr        \\<Rightarrow> {ptr}\n | Zombie ptr bits num  \\<Rightarrow> {ptr}\n | _                    \\<Rightarrow> {}\"\n\nprimrec\n  sethelper :: \"bool \\<Rightarrow> 'a set \\<Rightarrow> 'a set\"\nwhere\n  \"sethelper True  s = {}\"\n| \"sethelper False s = s\"\n\nfunction\n  finaliseSlot' :: \"machine_word \\<Rightarrow> bool \\<Rightarrow> (bool * capability) kernel_p\"\nwhere\n \"finaliseSlot' x b s =\n(\\<lambda> finaliseSlot.\n(\\<lambda> cteDelete.\n(\\<lambda> reduceZombie.\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY finaliseSlot\n)\n(\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY reduceZombie\n)\n)\n(\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteDelete\n)\n)\nfinaliseSlot' x b s\"\n\n  by auto\n\ndefs\n  finaliseSlot_def:\n \"finaliseSlot \\<equiv> finaliseSlot'\"\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n\nfunction\n  cteDeleteOne' :: \"machine_word \\<Rightarrow> unit kernel\"\nwhere\n \"cteDeleteOne' x s =\n(\\<lambda> cteDeleteOne.\n(\\<lambda> deletingIRQHandler.\n(\\<lambda> cancelIPC.\n(\\<lambda> suspend.\n(\\<lambda> finaliseCap.\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteDeleteOne\n)\n(\n#INCLUDE_HASKELL SEL4/Object/ObjectType.lhs Arch=Arch BODY finaliseCap\n)\n)\n(\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs BODY suspend\n)\n)\n(\n#INCLUDE_HASKELL SEL4/Object/Endpoint.lhs BODY cancelIPC\n)\n)\n(\n#INCLUDE_HASKELL SEL4/Object/Interrupt.lhs BODY deletingIRQHandler\n)\n)\ncteDeleteOne' x s\"\n\n  by auto\n\ndefs\n  cteDeleteOne_def1:\n \"cteDeleteOne \\<equiv> cteDeleteOne'\"\n\ntermination cteDeleteOne'\n  by (rule cteDeleteOne'.termination[OF wf_empty], simp+)\n\nlemma cteDeleteOne_def:\n \"cteDeleteOne =\n(\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteDeleteOne\n)\"\n  apply (rule ext)+\n  apply (subst cteDeleteOne_def1)\n  apply (subst cteDeleteOne'.simps)\n  apply (unfold finaliseCap_def suspend_def cancelIPC_def\n                deletingIRQHandler_def cteDeleteOne_def1)\n  apply (rule refl)\n  done\n\nlemma card_reduce:\n  \"(s :: ('a :: finite) set) \\<inter> s' = {} \\<Longrightarrow> card (UNIV - (s \\<union> s')) < card (UNIV - s) = (s' \\<noteq> {})\"\n  apply (case_tac \"s' \\<subseteq> s\")\n   apply (simp add: Un_absorb2)\n   apply (simp add: Int_absorb1)\n  apply (clarsimp simp: subset_iff)\n  apply (subst psubset_card_mono)\n    apply simp\n   apply blast\n  apply blast\n  done\n\nlemma isCapDs:\n  \"isUntypedCap cap \\<Longrightarrow> \\<exists>dev ptr size freeIndex. cap = UntypedCap dev ptr size freeIndex\"\n  \"isEndpointCap cap \\<Longrightarrow> \\<exists>ptr bdg cans canr cang cangr. cap = EndpointCap ptr bdg cans canr cang cangr\"\n  \"isNotificationCap cap \\<Longrightarrow> \\<exists>ptr bdg cans canr. cap = NotificationCap ptr bdg cans canr\"\n  \"isCNodeCap cap \\<Longrightarrow> \\<exists>ptr bits grd gsize. cap = CNodeCap ptr bits grd gsize\"\n  \"isThreadCap cap \\<Longrightarrow> \\<exists>ptr. cap = ThreadCap ptr\"\n  \"isArchObjectCap cap \\<Longrightarrow> \\<exists>archcap. cap = ArchObjectCap archcap\"\n  \"isZombie cap \\<Longrightarrow> \\<exists>ptr bits num. cap = Zombie ptr bits num\"\n  apply (case_tac cap, simp_all add: isUntypedCap_def)\n  apply (case_tac cap, simp_all add: isEndpointCap_def)\n  apply (case_tac cap, simp_all add: isNotificationCap_def)\n  apply (case_tac cap, simp_all add: isCNodeCap_def)\n  apply (case_tac cap, simp_all add: isThreadCap_def)\n  apply (case_tac cap, simp_all add: isArchObjectCap_def)\n  apply (case_tac cap, simp_all add: isZombie_def)\n  done\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Fault Handling: Manages and processes hypervisor faults, ensuring the system can respond appropriately to exceptions and errors at the hypervisor level.",
    "input": "",
    "output": "(*\n    Hypervisor code.\n*)\n\ntheory Hypervisor_H\nimports\n  CNode_H\n  ArchHypervisor_H\n  KernelInitMonad_H\nbegin\n\narch_requalify_consts (H)\n  handleHypervisorFault\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Prefixed Invocation Types: Define and requalify types for invocation structures, including `copy_register_sets` and `irqcontrol_invocation`, with an `Arch` prefix to ensure compatibility and proper scoping within the architecture-specific context.",
    "input": "",
    "output": "requalify_types (in Arch)\n  copy_register_sets irqcontrol_invocation\n  invocation\n\n#INCLUDE_HASKELL SEL4/API/Invocation.lhs Arch=Arch NOT GenInvocationLabels InvocationLabel\n#INCLUDE_HASKELL SEL4/API/InvocationLabels.lhs ONLY invocationType genInvocationType",
    "system": "",
    "history": []
  },
  {
    "instruction": "Disambiguation of Names: Ensures that naming conflicts between architecture-specific and non-architecture-specific constants with the same names are resolved, maintaining clarity and preventing ambiguity in the code.",
    "input": "",
    "output": "context Arch begin\ncontext begin global_naming global\nrequalify_types (aliasing)\n  Invocations_H.invocation\nend\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "API-Visible Types: Define and requalify a set of types, constants, and facts that are visible and usable in the API, ensuring consistent and accessible data representations and operations for system components.",
    "input": "",
    "output": "(*\n   Types visible in the API.\n*)\n\nchapter \"Types visible in the API\"\n\ntheory Types_H\nimports\n  MachineExports\n  ArchTypes_H\nbegin\n\narch_requalify_types (H)\n  object_type\n  paddr\n  vptr\n\narch_requalify_consts (H)\n  getObjectSize\n  fromAPIType\n  toAPIType\n  isFrameType\n  pageType\n  tcbBlockSizeBits\n\narch_requalify_facts (H)\n  tcbBlockSizeBits_def\n\n#INCLUDE_HASKELL SEL4/API/Types.lhs all_bits NOT wordsFromBootInfo messageInfoFromWord wordFromMessageInfo ObjectType getObjectSize fromAPIType toAPIType isFrameType pageType\n#INCLUDE_HASKELL SEL4/API/Types.lhs all_bits ONLY wordsFromBootInfo messageInfoFromWord wordFromMessageInfo\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization State Management: Manages the initialization state by encapsulating it within a monad, allowing for operations to be performed on the kernel state during initialization. It ensures that the kernel state is updated and maintained correctly, handling potential initialization failures.",
    "input": "",
    "output": "record init_data =\n  initFreeMemory   :: \"region list\"\n  initSlotPosCur :: \"machine_word\"\n  initSlotPosMax   :: \"machine_word\"\n  initBootInfo    :: \"biframe_data\"\n  initBootInfoFrame       :: paddr\n  initKernelState :: kernel_state\n\ntype_synonym 'a kernel_init_state = \"(init_data, 'a) nondet_monad\"\n\ntranslations\n  (type) \"'c kernel_init_state\" <= (type) \"(init_data, 'c) nondet_monad\"\n\ntype_synonym 'a kernel_init = \"(init_failure + 'a) kernel_init_state\"\n\ntranslations\n  (type) \"'a kernel_init\" <= (type) \"(init_failure + 'a) kernel_init\"\n\ndefinition\n  noInitFailure :: \"'a kernel_init_state \\<Rightarrow> 'a kernel_init\"\nwhere\n  noInitFailure_def[simp]:\n  \"noInitFailure \\<equiv> liftE\"\n\n\n\ndefinition\n  doKernelOp :: \"'a kernel \\<Rightarrow> 'a kernel_init\"\nwhere\n \"doKernelOp kop \\<equiv> doE\n    ms \\<leftarrow> liftE $ gets initKernelState;\n    (r, ms') \\<leftarrow> liftE $ select_f (kop ms);\n    liftE $ modify (\\<lambda>ks. ks \\<lparr> initKernelState := ms' \\<rparr>);\n    returnOk r\n  odE\"\n\nconsts\n  itASID :: asid\n  biCapNull :: machine_word\n  biCapITTCB :: machine_word\n  biCapITCNode :: machine_word\n  biCapITPD :: machine_word\n  biCapIRQControl :: machine_word\n  biCapASIDControl :: machine_word\n  biCapITASIDPool :: machine_word\n  biCapIOPort :: machine_word\n  biCapIOSpace :: machine_word\n  biCapBIFrame :: machine_word\n  biCapITIPCBuf :: machine_word\n  biCapDynStart :: machine_word\n  biFrameSizeBits :: nat\n  nopBIFrameData :: biframe_data\n\ndefinition\n  runInit :: \"machine_word \\<Rightarrow> 'a kernel_init \\<Rightarrow> 'b kernel\"\nwhere\n  \"runInit initOffset doInit \\<equiv> do\n    ks \\<leftarrow> get;\n    initData \\<leftarrow> return \\<lparr> initFreeMemory = [],\n                   initSlotPosCur = 0,\n                   initSlotPosMax = bit (pageBits),\n                   initBootInfo = nopBIFrameData,\n                   initBootInfoFrame = 0,\n                   initKernelState = ks \\<rparr>;\n    (ret, initData') \\<leftarrow> select_f (doInit initData);\n    (case ret of\n      Inr a \\<Rightarrow> fail\n    | Inl _ \\<Rightarrow> fail)\n  od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "DataMap Range Deletion: Remove a range of entries from a DataMap based on a specified pointer and bit size, ensuring that only the entries within the specified range are deleted.",
    "input": "",
    "output": "requalify_consts (in Arch)\n  deleteGhost\n\ndefinition deleteRange :: \"( machine_word , 'a ) DataMap.map \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> ( machine_word , 'a ) DataMap.map\"\nwhere \"deleteRange m ptr bits \\<equiv>\n        let inRange = (\\<lambda> x. x && ((- mask bits) - 1) = fromPPtr ptr) in\n        data_map_filterWithKey (\\<lambda> x _. Not (inRange x)) m\"\n\n#INCLUDE_HASKELL SEL4/Model/PSpace.lhs decls_only Data.Map=DataMap NOT PSpace ptrBits ptrBitsForSize lookupAround maybeToMonad lookupAround2 typeError alignError alignCheck sizeCheck objBits deleteRange\n\nconsts\nlookupAround2 :: \"('k :: {linorder,finite}) \\<Rightarrow> ( 'k , 'a ) DataMap.map \\<Rightarrow> (('k * 'a) option * 'k option)\"\n\n#INCLUDE_HASKELL SEL4/Model/PSpace.lhs bodies_only Data.Map=DataMap NOT PSpace ptrBits ptrBitsForSize lookupAround maybeToMonad typeError alignError alignCheck sizeCheck objBits deletionIsSafe deletionIsSafe_delete_locale cNodePartialOverlap pointerInUserData ksASIDMapSafe deleteRange\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object and Capability Creation: Create and initialize new objects and their corresponding capabilities, ensuring proper allocation and configuration in the system. This includes creating TCBs, endpoints, notifications, CNodes, untyped memory, and architecture-specific objects, and setting up their initial states and capabilities.",
    "input": "",
    "output": "consts\ninsertNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> machine_word list \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> unit kernel\"\n\nconsts\ncreateObjects :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> Structures_H.kernel_object \\<Rightarrow> nat \\<Rightarrow> machine_word list kernel\"\n\nconsts\ncreateObjects' :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> kernel_object \\<Rightarrow> nat \\<Rightarrow> unit kernel\"\n\nconsts\ncreateNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> capability list kernel\"\n\nconsts\nArch_createNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_capability list kernel\"\n\ndefs insertNewCaps_def:\n\"insertNewCaps newType srcSlot destSlots regionBase magnitudeBits dev \\<equiv> (do\n    caps \\<leftarrow> createNewCaps newType regionBase (length destSlots) magnitudeBits dev;\n    zipWithM_x (insertNewCap srcSlot) destSlots caps\n  od)\"\n\ndefs createNewCaps_def:\n\"createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    (case toAPIType t of\n          Some TCBObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::tcb)) 0;\n            curdom \\<leftarrow> curDomain;\n            mapM_x (\\<lambda>tptr. threadSet (tcbDomain_update (\\<lambda>_. curdom)) tptr) addrs;\n            return $ map (\\<lambda> addr. ThreadCap addr) addrs\n          od)\n        | Some EndpointObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::endpoint)) 0;\n            return $ map (\\<lambda> addr. EndpointCap addr 0 True True True True) addrs\n          od)\n        | Some NotificationObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::notification)) 0;\n            return $ map (\\<lambda> addr. NotificationCap addr 0 True True) addrs\n          od)\n        | Some ArchTypes_H.CapTableObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::cte)) userSize;\n            modify (\\<lambda> ks. ks \\<lparr> gsCNodes := (\\<lambda> addr.\n              if addr `~elem~` map fromPPtr addrs then Just userSize\n              else gsCNodes ks addr)\\<rparr>);\n            return $ map (\\<lambda> addr. CNodeCap addr userSize 0 0) addrs\n          od)\n        | Some ArchTypes_H.Untyped \\<Rightarrow>\n            return $ map\n                (\\<lambda> n. UntypedCap dev (regionBase + n * 2 ^ (fromIntegral userSize)) userSize 0)\n                [0  .e.  (fromIntegral numObjects) - 1]\n        | None \\<Rightarrow>   (do\n            archCaps \\<leftarrow> Arch_createNewCaps t regionBase numObjects userSize dev;\n            return $ map ArchObjectCap archCaps\n          od)\n        )\"\n\ndefs createObjects_def:\n\"createObjects ptr numObjects val gSize \\<equiv> (do\n        oBits \\<leftarrow> return ( objBitsKO val);\n        gBits \\<leftarrow> return ( oBits + gSize);\n        createObjects' ptr numObjects val gSize;\n        return (map (\\<lambda> n. (ptr + n `~shiftL~` gBits))\n                [0  .e.  (of_nat numObjects) - 1])\n  od)\"\n\ndefs createObjects'_def:\n\"createObjects' ptr numObjects val gSize\\<equiv> (do\n        oBits \\<leftarrow> return ( objBitsKO val);\n        gBits \\<leftarrow> return ( oBits + gSize);\n        unless (fromPPtr ptr && mask gBits = 0) $\n            alignError gBits;\n        ps \\<leftarrow> gets ksPSpace;\n        end \\<leftarrow> return ( fromPPtr ptr + fromIntegral ((numObjects `~shiftL~` gBits) - 1));\n        (before, _) \\<leftarrow> return ( lookupAround2 end (psMap ps));\n        (case before of\n              None \\<Rightarrow>   return ()\n            | Some (x, _) \\<Rightarrow>   haskell_assert (x < fromPPtr ptr)\n                []\n            );\n        addresses \\<leftarrow> return ( map\n                (\\<lambda> n. fromPPtr ptr + n `~shiftL~` oBits)\n                [0  .e.  (fromIntegral numObjects `~shiftL~` gSize) - 1]);\n        map' \\<leftarrow> return ( foldR\n               (\\<lambda> addr map. data_map_insert addr val map)\n               (psMap ps) addresses);\n        ps' \\<leftarrow> return ( ps \\<lparr> psMap := map' \\<rparr>);\n        modify (\\<lambda> ks. ks \\<lparr> ksPSpace := ps'\\<rparr>)\nod)\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Data Structures: Define and requalify various kernel data structures, including capabilities, kernel objects, ASIDs, and TCBs, to ensure they are properly typed and initialized for use within the kernel.",
    "input": "",
    "output": "(*\n   datatypes/records for the various kernel data structures.\n*)\n\nchapter \"Kernel Data Structures\"\n\ntheory Structures_H\nimports\n  Config_H\n  State_H\n  Fault_H\n  Types_H\n  ArchStructures_H\nbegin\n\narch_requalify_types (H)\n  arch_capability\n  arch_kernel_object\n  asid\n  arch_tcb\n\narch_requalify_consts (H)\n  archObjSize\n  nullPointer\n  newArchTCB\n  fromPPtr\n  PPtr\n  atcbContextGet\n  atcbContextSet\n\n#INCLUDE_HASKELL SEL4/Object/Structures.lhs decls_only NOT isNullCap isUntypedCap isIRQControlCap isReplyCap isDomainCap isNotificationCap\n#INCLUDE_HASKELL SEL4/Object/Structures.lhs bodies_only NOT kernelObjectTypeName isNullCap isUntypedCap isIRQControlCap isReplyCap isDomainCap isNotificationCap\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Handling: Provides mechanisms for handling and propagating failures in kernel operations, including lifting kernel functions to handle failures, throwing errors, catching and rethrowing failures, and providing default values (such as `NullCap`, empty lists, or `Nothing`) when a failure occurs.",
    "input": "",
    "output": "definition\n  withoutFailure :: \"'a kernel \\<Rightarrow> ('f, 'a) kernel_f\"\nwhere\n  withoutFailure_def[simp]:\n  \"withoutFailure \\<equiv> liftE\"\n\ndefinition\n  throw :: \"'f \\<Rightarrow> ('f, 'a) kernel_f\"\nwhere\n  throw_def[simp]:\n  \"throw \\<equiv> throwError\"\n\ndefinition\n  catchFailure :: \"('f, 'a) kernel_f \\<Rightarrow> ('f \\<Rightarrow> 'a kernel) \\<Rightarrow> 'a kernel\"\nwhere\n  catchFailure_def[simp]:\n \"catchFailure \\<equiv> catch\"\n\ndefinition\n  rethrowFailure :: \"('f1 \\<Rightarrow> 'f2) \\<Rightarrow> ('f1, 'a) kernel_f \\<Rightarrow> ('f2, 'a) kernel_f\"\nwhere\n \"rethrowFailure f m \\<equiv> m <handle2> (throwError \\<circ> f)\"\n\ndefinition\n  ignoreFailure :: \"( 'f , unit ) kernel_f \\<Rightarrow> unit kernel\"\nwhere\n  \"ignoreFailure x \\<equiv> (catchFailure x (const (return ())))\"\n\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures.lhs\n#INCLUDE_HASKELL SEL4/Model/Failures.lhs NOT KernelF withoutFailure catchFailure throw rethrowFailure nullCapOnFailure nothingOnFailure ignoreFailure emptyOnFailure\n\ndefinition\n  nullCapOnFailure :: \"('f, capability) kernel_f \\<Rightarrow> capability kernel\"\nwhere\n \"nullCapOnFailure m \\<equiv> m <catch> (\\<lambda>x. return NullCap)\"\n\ndefinition\n  emptyOnFailure :: \"('f, 'a list) kernel_f \\<Rightarrow> 'a list kernel\"\nwhere\n \"emptyOnFailure m \\<equiv> m <catch> (\\<lambda>x. return [])\"\n\ndefinition\n  nothingOnFailure :: \"('f, 'a option) kernel_f \\<Rightarrow> 'a option kernel\"\nwhere\n \"nothingOnFailure m \\<equiv> m <catch> (\\<lambda>x. return Nothing)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Preemption Control: Manages preemption by incrementing the work units, checking against a limit, and potentially triggering a preemption if the limit is reached. This ensures that the system remains responsive and fair in scheduling.",
    "input": "",
    "output": "type_synonym 'a kernel_p = \"(irq + 'a) kernel\"\n\ntranslations\n  (type) \"'a kernel_p\" <= (type) \"(irq + 'a) kernel\"\n\ndefinition\n  withoutPreemption :: \"'a kernel \\<Rightarrow> 'a kernel_p\"\nwhere\n  withoutPreemption_def[simp]:\n \"withoutPreemption \\<equiv> liftE\"\n\ndefinition\n  workUnitsLimit :: machine_word\nwhere\n  \"workUnitsLimit \\<equiv> 0x64\"\n\ndefinition\n  preemptionPoint :: \"unit kernel_p\"\nwhere\n  \"preemptionPoint \\<equiv> doE\n     liftE $ modifyWorkUnits (\\<lambda>u. u + 1);\n     workUnits <- liftE $ getWorkUnits;\n     whenE (workUnitsLimit <= workUnits) $ doE\n       liftE $ setWorkUnits 0;\n       preempt <- liftE $ doMachineOp (getActiveIRQ True);\n       case preempt of\n           Some irq => throwError irq\n           | None => returnOk ()\n     odE\n   odE\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Notifications: Enable threads to manage and interact with notifications, including binding and unbinding notification pointers, and handling badge registers for communication.",
    "input": "",
    "output": "chapter \"Notifications\"\n\ntheory Notification_H imports    \"NotificationDecls_H\"\n    \"TCB_H\"\n  TCB_H\n  ThreadDecls_H\n  CSpaceDecls_H\n  ObjectInstances_H\nbegin\n\narch_requalify_consts (H)\n  badgeRegister\n\n#INCLUDE_HASKELL SEL4/Object/Notification.lhs bodies_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Endpoint Management: Enables the creation, manipulation, and communication through endpoints, facilitating inter-thread messaging and synchronization.",
    "input": "",
    "output": "chapter \"Endpoints\"\n\ntheory Endpoint_H\nimports\n  EndpointDecls_H\n  TCB_H\n  ThreadDecls_H\n  CSpaceDecls_H\n  FaultHandlerDecls_H\n  Notification_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Endpoint.lhs bodies_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for CSpace: Defines the necessary functions for managing capabilities within the CSpace, providing the foundational operations required for capability manipulation and interaction.",
    "input": "",
    "output": "chapter \"Function Declarations for CSpace\"\n\ntheory CSpaceDecls_H\nimports FaultMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/CSpace.lhs decls_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Requalification of Constants: Requalifies abstract specification constants with design-specific versions, ensuring that the constants used in the architecture-specific code are consistent and correctly mapped to their design counterparts.",
    "input": "",
    "output": "arch_requalify_consts (aliasing, H)\n  gpRegisters\n  frameRegisters\n  tlsBaseRegister\n\nabbreviation \"mapMaybe \\<equiv> option_map\"\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= bodies_only NOT liftFnMaybe assertDerived archThreadGet archThreadSet asUser sanitiseRegister getSanitiseRegisterInfo\n\ndefs asUser_def:\n\"asUser tptr f\\<equiv> (do\n        uc \\<leftarrow> threadGet  (atcbContextGet o tcbArch) tptr;\n        (a, uc') \\<leftarrow> select_f (f uc);\n        threadSet (\\<lambda> tcb. tcb \\<lparr> tcbArch := atcbContextSet uc' (tcbArch tcb)\\<rparr>) tptr;\n        return a\nod)\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constants: Define and requalify constants for CTE (Capability Table Entry) rights and guard bits, ensuring consistent and correct usage across the architecture.",
    "input": "",
    "output": "requalify_consts\n  cteRightsBits cteGuardBits",
    "system": "",
    "history": []
  },
  {
    "instruction": "Namespace Disambiguation: Disambiguates names between architecture-specific and non-architecture-specific constants to prevent naming conflicts.",
    "input": "",
    "output": "requalify_consts (aliasing)\n  deriveCap finaliseCap postCapDeletion isCapRevocable\n  hasCancelSendRights sameRegionAs isPhysicalCap\n  sameObjectAs updateCapData maskCapRights\n  createObject capUntypedPtr capUntypedSize\n  performInvocation decodeInvocation prepareThreadDelete\n\ncontext begin global_naming global\n\nrequalify_consts (aliasing)\n  RetypeDecls_H.deriveCap RetypeDecls_H.finaliseCap RetypeDecls_H.postCapDeletion\n  RetypeDecls_H.isCapRevocable\n  RetypeDecls_H.hasCancelSendRights RetypeDecls_H.sameRegionAs RetypeDecls_H.isPhysicalCap\n  RetypeDecls_H.sameObjectAs RetypeDecls_H.updateCapData RetypeDecls_H.maskCapRights\n  RetypeDecls_H.createObject RetypeDecls_H.capUntypedPtr RetypeDecls_H.capUntypedSize\n  RetypeDecls_H.performInvocation RetypeDecls_H.decodeInvocation\nend\n\nend\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType.lhs Arch=Arch bodies_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Initialization and Management: Initialize and manage the virtual space, including creating and activating the global virtual space, initializing the IRQ controller, creating and managing frames for IPC buffers, device frames, and other regions, and handling VM faults. This ensures that the virtual memory is properly set up and maintained for efficient and secure operation.",
    "input": "",
    "output": "(*\n    VSpace lookup code.\n*)\n\ntheory VSpace_H\nimports\n  CNode_H\n  ArchVSpace_H\n  KernelInitMonad_H\nbegin\n\narch_requalify_consts (H)\n  mapKernelWindow\n  activateGlobalVSpace\n  initIRQController\n  createIPCBufferFrame\n  createBIFrame\n  createFramesOfRegion\n  createITPDPTs\n  writeITPDPTs\n  createITASIDPool\n  writeITASIDPool\n  createDeviceFrames\n  handleVMFault\n  isValidVTableRoot\n  checkValidIPCBuffer\n  lookupIPCBuffer\n  vptrFromPPtr\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace.lhs Arch= ONLY initKernelVM initPlatform initCPU\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Management: Ensures proper handling and masking of interrupts, including checking and managing reserved IRQs.",
    "input": "",
    "output": "requalify_consts\n  checkIRQ\n  handleReservedIRQ\n  maskIrqSignal",
    "system": "",
    "history": []
  },
  {
    "instruction": "Disambiguate Constants: Resolve name clashes between architecture-specific and non-architecture-specific constants by requalifying them with their respective namespaces.",
    "input": "",
    "output": "requalify_consts (aliasing)\n  decodeIRQControlInvocation\n  invokeIRQHandler\n  performIRQControl\n  initInterruptController\n\ncontext begin global_naming global\nrequalify_consts (aliasing)\n  InterruptDecls_H.decodeIRQControlInvocation\n  InterruptDecls_H.invokeIRQHandler\n  InterruptDecls_H.performIRQControl\n  InterruptDecls_H.initInterruptController\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Override Configuration Constants: Requalify and constrain kernel configuration constants, such as `maxIRQ`, using definitions from the hardware abstraction layer (H). This ensures that the constants are consistent with the hardware specifications.",
    "input": "",
    "output": "arch_requalify_consts (aliasing, H)\n  maxIRQ\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n#INCLUDE_HASKELL SEL4/Object/Interrupt.lhs bodies_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Event Handling: The kernel reacts to both user-level and machine-generated events, processing them through system calls to manage and respond to various conditions and requests.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/Syscall.lhs ONLY Event Syscall\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Configuration Parameters: Define and import configuration parameters for the system, such as the number of domains, time slice duration, reset chunk bits, and retype fan-out limit. These parameters are essential for configuring the system's behavior and resource management.",
    "input": "",
    "output": "theory Config_H\nimports Types_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Config.lhs NOT numDomains timeSlice resetChunkBits retypeFanOutLimit\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Calls: Define and implement the interface for system calls, allowing user-level applications to request services from the kernel. This includes handling various operations such as process management, memory management, and I/O operations, ensuring that the kernel can securely and efficiently manage system resources and provide necessary services to user-space applications.",
    "input": "",
    "output": "chapter \"System Calls\"\n\ntheory Syscall_H\nimports Kernel_H Event_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Model/Syscall.lhs\n#INCLUDE_HASKELL SEL4/API/Syscall.lhs decls_only NOT Event Syscall\n#INCLUDE_HASKELL SEL4/API/Syscall.lhs bodies_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ready Queue Definition: Defines a ready queue as a type synonym for a thread control block (TCB) queue, facilitating the management and scheduling of threads in the kernel.",
    "input": "",
    "output": "type_synonym ready_queue = tcb_queue",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel State and Monad Structure: The kernel state encapsulates various components including physical space, user pages, CNodes, untyped zero ranges, maximum object size, domain scheduling information, current and idle threads, scheduler actions, interrupt state, work units completed, and architecture-specific and machine states. This structure allows for the management and manipulation of the kernel's operational environment within a nondeterministic monad, facilitating state transitions and computations.",
    "input": "",
    "output": "record kernel_state =\n  ksPSpace             :: pspace\n  gsUserPages          :: \"machine_word \\<Rightarrow> vmpage_size option\"\n  gsCNodes             :: \"machine_word \\<Rightarrow> nat option\"\n  gsUntypedZeroRanges  :: \"(machine_word \\<times> machine_word) set\"\n  gsMaxObjectSize      :: nat\n  ksDomScheduleIdx     :: nat\n  ksDomSchedule        :: \"(domain \\<times> machine_word) list\"\n  ksCurDomain          :: domain\n  ksDomainTime         :: machine_word\n  ksReadyQueues        :: \"domain \\<times> priority \\<Rightarrow> ready_queue\"\n  ksReadyQueuesL1Bitmap :: \"domain \\<Rightarrow> machine_word\"\n  ksReadyQueuesL2Bitmap :: \"domain \\<times> nat \\<Rightarrow> machine_word\"\n  ksCurThread          :: machine_word\n  ksIdleThread         :: machine_word\n  ksSchedulerAction    :: scheduler_action\n  ksInterruptState     :: interrupt_state\n  ksWorkUnitsCompleted :: machine_word\n  ksArchState          :: Arch.kernel_state\n  ksMachineState       :: machine_state\n\ncontext Arch begin\ncontext begin global_naming global\nrequalify_types KernelStateData_H.kernel_state\nend\nend\n\ntype_synonym 'a kernel = \"(kernel_state, 'a) nondet_monad\"\n\ntranslations\n  (type) \"'c kernel\" <= (type) \"(kernel_state, 'c) nondet_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Execute Machine Operations: Perform a machine operation within the kernel, updating the machine state and returning the result. This ensures that the kernel's machine state is correctly modified and maintained.",
    "input": "",
    "output": "definition\n  doMachineOp :: \"(machine_state, 'a) nondet_monad  \\<Rightarrow> 'a kernel\"\nwhere\n \"doMachineOp mop \\<equiv> do\n    ms \\<leftarrow> gets ksMachineState;\n    (r, ms') \\<leftarrow> select_f (mop ms);\n    modify (\\<lambda>ks. ks \\<lparr> ksMachineState := ms' \\<rparr>);\n    return r\n  od\"\n\n#INCLUDE_HASKELL SEL4/Model/StateData.lhs decls_only ONLY capHasProperty ksReadyQueues_asrt ready_qs_runnable idleThreadNotQueued\n#INCLUDE_HASKELL SEL4/Model/StateData.lhs NOT doMachineOp KernelState ReadyQueue Kernel assert stateAssert findM funArray newKernelState capHasProperty ksReadyQueues_asrt ready_qs_runnable idleThreadNotQueued\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for TCBs: Defines the function declarations related to thread control blocks (TCBs) without including architecture-specific functions such as `archThreadGet`, `archThreadSet`, `sanitiseRegister`, and `getSanitiseRegisterInfo`.",
    "input": "",
    "output": "chapter \"Function Declarations for TCBs\"\n\ntheory TCBDecls_H\nimports FaultMonad_H Invocations_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs decls_only \\\n  NOT archThreadGet archThreadSet sanitiseRegister getSanitiseRegisterInfo\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Integration: Integrates various kernel components including initialization, thread management, fault handling, capability space management, and hypervisor functionalities to form a cohesive system.",
    "input": "",
    "output": "chapter \"Kernel\"\n\ntheory Kernel_H\nimports\n  KernelInit_H\n  Thread_H\n  FaultHandler_H\n  CSpace_H\n  Hypervisor_H\nbegin\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Endpoint Function Declarations: Define the necessary functions for managing and interacting with endpoints, facilitating communication and synchronization between threads.",
    "input": "",
    "output": "chapter \"Function Declarations for Endpoints\"\n\ntheory EndpointDecls_H\nimports FaultMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Endpoint.lhs decls_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clobber Constants: Requalify previously defined abstract specification constants with design-specific versions, ensuring that the system uses the updated constants for fault handling and system calls.",
    "input": "",
    "output": "arch_requalify_consts (aliasing, H)\n  syscallMessage\n  exceptionMessage\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures.lhs\n\n#INCLUDE_HASKELL SEL4/Kernel/FaultHandler.lhs bodies_only\n#INCLUDE_HASKELL SEL4/API/Faults.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults.lhs bodies_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for Fault Handlers: Defines the necessary function declarations to handle faults within the kernel, providing a structured interface for fault management and ensuring that fault handling mechanisms are properly integrated into the system.",
    "input": "",
    "output": "(*\n    Declarations from SEL4.Kernel.FaultHandler\n*)\n\nchapter \"Function Declarations for Fault Handlers\"\n\ntheory FaultHandlerDecls_H\nimports Structures_H FaultMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/FaultHandler.lhs decls_only\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "API Module Collection: Aggregates all API modules, providing a comprehensive set of functions and declarations for the system.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4.lhs decls_only NOT callKernel\n\n#INCLUDE_HASKELL SEL4.lhs NOT kernelExitAssertions fastpathKernelAssertions\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Initialization: Initializes the kernel state and sets up the necessary data structures and configurations to prepare the system for operation.",
    "input": "",
    "output": "chapter \"Initialisation\"\n\ntheory KI_Decls_H\nimports\n  ThreadDecls_H\n  KernelInitMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/Init.lhs decls_only NOT isAligned funArray newKernelState distinct rangesBy doKernelOp runInit\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Untyped Objects: Define and manage untyped memory regions with specified size constraints, ensuring that these regions do not overlap with critical system structures.",
    "input": "",
    "output": "chapter \"Untyped Objects\"\n\ntheory Untyped_H\nimports\n  RetypeDecls_H\n  CSpaceDecls_H\n  CNode_H\n  Invocations_H\n  InvocationLabels_H\n  Config_H\nbegin\n\narch_requalify_consts (H)\n  minUntypedSizeBits\n  maxUntypedSizeBits\n\nconsts\n  cNodeOverlap :: \"(machine_word \\<Rightarrow> nat option) \\<Rightarrow> (machine_word \\<Rightarrow> bool) \\<Rightarrow> bool\"\n\n#INCLUDE_HASKELL SEL4/Object/Untyped.lhs decls_only ONLY archOverlap\n\n#INCLUDE_HASKELL SEL4/Object/Untyped.lhs NOT cNodeOverlap canonicalAddressAssert archOverlap\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Disambiguation of Constants: Resolve name clashes between architecture-specific and non-architecture-specific constants by requalifying and aliasing them, ensuring clear and unambiguous references in the code.",
    "input": "",
    "output": "context Arch begin\nrequalify_facts (aliasing)\n   newKernelState_def\nrequalify_consts (aliasing)\n   newKernelState\n\ncontext begin global_naming global\nrequalify_facts (aliasing)\n   KernelInit_H.newKernelState_def\nrequalify_consts (aliasing)\n   KernelInit_H.newKernelState\nend\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Physical Memory Management: Provides arch-specific ghost update functions for managing physical memory, ensuring that the memory state is correctly maintained and updated according to the architectural requirements.",
    "input": "",
    "output": "(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/ARM.hs\n\nend (* context Arch *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for Threads: Defines the necessary function declarations for thread management in the ARM architecture, providing the structural and operational foundations for thread-related functionalities within the kernel.",
    "input": "",
    "output": "(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT Arch decls_only\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Type Enumeration: Defines the enumeration of object types, including both API object types and ARM-specific object types such as PageDirectory, SmallPage, LargePage, Section, SuperSection, and PageTable. Ensures that the object types are exhaustively covered and distinct, supporting comprehensive type handling and validation.",
    "input": "",
    "output": "qualify ARM_H (in Arch)\ninstantiation ARM_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [PageDirectoryObject,\n      SmallPageObject,\n      LargePageObject,\n      SectionObject,\n      SuperSectionObject,\n      PageTableObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation ARM_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation ARM_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Kernel State and Monads: Defines the architecture-specific kernel state and monads, incorporating necessary imports and context for the ARM architecture. This ensures that the kernel state and monads are tailored to the specific requirements and structures of the ARM architecture, providing a foundation for the rest of the system.",
    "input": "",
    "output": "(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_H NOT ArmVSpaceRegionUse\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup: Provides mechanisms for handling and translating virtual memory faults, ensuring that the system can properly manage and respond to memory access errors.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/API/Failures/ARM.lhs CONTEXT ARM_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/ARM.lhs CONTEXT ARM_H bodies_only\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Management: The ASID pool is represented as a fixed-size array of `Nothing` values, ensuring a safe and consistent structure for managing ASID mappings. The loading and updating of the ASID pool object are handled using default methods, maintaining the integrity and consistency of the ASID pool within the kernel.",
    "input": "",
    "output": "instantiation ARM_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pde updateObject_pde\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Common, Architecture-Specific Data Types: Define and share architecture-specific data types between the specification and abstract models, ensuring consistency and reusability across different parts of the system.",
    "input": "",
    "output": "(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Main Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_H ONLY ArmVSpaceRegionUse\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup and Validation: Ensures that the size of a mapping is valid by checking that the size does not exceed the maximum object size supported by the system.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  Untyped_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/ARM.lhs CONTEXT ARM_H bodies_only ArchInv=ArchRetypeDecls_H.ARM ArchLabels=ArchInvocationLabels_H.ARM NOT checkPDAt checkPTAt checkPDASIDMapMembership checkValidMappingSize vptrFromPPtr\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert\n    (\\<lambda>s. 2 ^ pageBitsForSize sz <= gsMaxObjectSize s) []\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Thread Management: Provides functions for getting and setting thread-specific architectural state, ensuring that the thread's state is correctly managed and updated according to the architecture-specific requirements.",
    "input": "",
    "output": "theory ArchTCB_H\nimports TCBDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/ARM.lhs RegisterSet= CONTEXT ARM_H\n\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retyping Objects: Allows the redefinition of an object's type within the system, enabling the transformation of one type of object into another. This ensures flexibility and dynamic resource management in the kernel.",
    "input": "",
    "output": "chapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT ARM_H\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/ARM.lhs CONTEXT ARM_H decls_only ArchInv=\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Canonical Address Assertion: The function `canonicalAddressAssert` always returns true, indicating that the provided machine word is considered to be in a canonical form.",
    "input": "",
    "output": "definition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific System Call Labels: Define an enumeration of architecture-specific system call labels, providing a structured and standardized way to reference and invoke system calls within the ARM architecture.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_H ONLY ArchInvocationLabel\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Invocation Label Requalification: The code requalifies arch-specific invocation labels within the Arch context, ensuring that the enum instance proofs are correctly handled outside of the Arch locale.",
    "input": "",
    "output": "arch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Definition of New User Context: Defines a new user context with all registers initialized to zero.",
    "input": "",
    "output": "chapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext ((K 0) aLU initContext)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Handling: Defines the structure and behavior of fault handlers specific to the ARM architecture, including the declaration and implementation of fault types and their corresponding handling mechanisms.",
    "input": "",
    "output": "chapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/ARM.lhs\n\n#INCLUDE_HASKELL SEL4/API/Faults/ARM.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/ARM.lhs bodies_only\n\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Kernel Object Types: Defines three types of architectural kernel objects—PDET, PTET, and ASIDPoolT—each representing different components of the memory management system. The `archTypeOf` function determines the type of a given architectural kernel object, enabling the system to manage and manipulate these objects based on their specific roles in the architecture.",
    "input": "",
    "output": "theory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_H decls_only\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_H instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_H bodies_only\n\ndatatype arch_kernel_object_type =\n    PDET\n  | PTET\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPDE e) = PDET\"\n| \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constants and Definitions: Define and requalify architectural constants and functions, including word bits, pointer conversions, and null pointer representation, to ensure consistency and compatibility across different architectures.",
    "input": "",
    "output": "arch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=ARM CONTEXT ARM_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Handling: Defines the handling and management of interrupts specific to the ARM architecture, including operations such as enabling, disabling, and configuring interrupts. This ensures that the system can efficiently manage hardware interrupts and maintain the integrity of the interrupt handling mechanisms.",
    "input": "",
    "output": "theory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/ARM.lhs Arch= CONTEXT ARM_H bodies_only ArchInv=\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retyping Objects: Allows the redefinition of object types in the system, enabling the transformation of one type of object into another while preserving the underlying memory and maintaining the integrity of the system.",
    "input": "",
    "output": "chapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/ARM.lhs CONTEXT ARM_H Arch.Types= ArchInv= bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs bodies_only CONTEXT ARM_H NOT isPDFlushLabel isPageFlushLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create New Memory Objects: Generate new memory objects (pages or tables) and their corresponding capabilities based on the specified type, region base, number of objects, and device status. The function initializes the mappings, updates the user pages, and performs cache cleaning as necessary.",
    "input": "",
    "output": "chapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewPageCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        when (\\<not>dev) $\n          mapM_x (\\<lambda>addr. doMachineOp $\n                            cleanCacheRange_RAM addr\n                                                (addr + mask (pageBitsForSize pSize))\n                                                (addrFromPPtr addr)) addrs;\n        return $ map (\\<lambda>n. PageCap dev (PPtr (fromPPtr n)) VMReadWrite pSize Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      mapM_x (\\<lambda>addr. doMachineOp $\n                       cleanCacheRange_PoU addr (addr + mask tableBits) (addrFromPPtr addr)) addrs;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 0 ARMSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 4 ARMLargePage\n        | SectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 8 ARMSection\n        | SuperSectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 12 ARMSuperSection\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        | PageDirectoryObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdBits (makeObject::pde) PageDirectoryCap\n              (\\<lambda>pds. do objSize \\<leftarrow> return (((1::nat) `~shiftL~` pdBits));\n                        mapM_x copyGlobalMappings pds\n                     od)\n        )\"\n\nend\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Management: Defines the architecture-specific thread management and operations, including thread creation, scheduling, and context switching, ensuring that threads are managed efficiently and in accordance with the architectural requirements.",
    "input": "",
    "output": "chapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT ARM_H ARMHardware=ARM bodies_only\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Invocation Labels: Define and handle architecture-specific invocation labels for operations such as page directory and page flushes, ensuring that the system can perform these operations in a manner consistent with the underlying architecture.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs CONTEXT ARM_H ONLY isPDFlushLabel isPageFlushLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Stub for ARM: Provides the necessary declarations and implementations for hypervisor functionality specific to the ARM architecture, ensuring that the hypervisor can manage and interact with ARM-specific hardware features.",
    "input": "",
    "output": "(*\n  Hypervisor stub for ARM\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_H bodies_only ArchInv= ArchLabels=\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Declarations: Define and declare interrupt-related objects and their properties for the ARM architecture, ensuring proper handling and management of interrupts within the system.",
    "input": "",
    "output": "theory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/ARM.lhs CONTEXT ARM_H decls_only ArchInv=\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware Operations: Provides a set of hardware-specific operations for managing memory, interrupts, and cache on ARM architecture, including memory initialization, interrupt handling, and cache management. These operations ensure efficient and secure manipulation of the hardware resources.",
    "input": "",
    "output": "theory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs Platform=Platform.ARM CONTEXT ARM_H NOT getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory writeTTBR0 setGlobalPD  setTTBCR setHardwareASID invalidateLocalTLB invalidateLocalTLB_ASID invalidateLocalTLB_VAASID cleanByVA cleanByVA_PoU invalidateByVA invalidateByVA_I invalidate_I_PoU cleanInvalByVA branchFlush clean_D_PoU cleanInvalidate_D_PoC cleanInvalidate_D_PoU cleanInvalidateL2Range invalidateL2Range cleanL2Range isb dsb dmb getIFSR getDFSR getFAR HardwareASID wordFromPDE wordFromPTE VMFaultType VMPageSize HypFaultType pageBits pageBitsForSize toPAddr cacheLineBits cacheLine lineStart cacheRangeOp cleanCacheRange_PoC cleanInvalidateCacheRange_RAM cleanCacheRange_RAM cleanCacheRange_PoU invalidateCacheRange_RAM invalidateCacheRange_I branchFlushRange cleanCaches_PoU cleanInvalidateL1Caches addrFromPPtr ptrFromPAddr initIRQController setIRQTrigger MachineData paddrBase pptrBase pptrTop paddrTop kernelELFPAddrBase kernelELFBase kernelELFBaseOffset pptrBaseOffset addrFromKPPtr\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_H instanceproofs NOT HardwareASID VMFaultType VMPageSize HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_H ONLY wordFromPDE wordFromPTE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value: Defines the maximum value for an interrupt request (IRQ) in the system, which is provided by the Kernel_Config.",
    "input": "",
    "output": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ == Kernel_Config.maxIRQ\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IRQ Controller: Provides the ARM/ARM_HYP machine operation for initializing the IRQ controller, ensuring that the system can handle interrupts effectively.",
    "input": "",
    "output": "abbreviation (input) initIRQController where\n  \"initIRQController \\<equiv> ARM.initIRQController\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Ghost Update Functions: Define and implement architecture-specific ghost update functions for managing physical memory. These functions ensure that the memory management operations are correctly reflected in the system's ghost state, maintaining the integrity and consistency of the memory model.",
    "input": "",
    "output": "(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/X64.hs\n\nend (* context Arch *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for Threads: Defines the necessary function declarations for thread management and operations specific to the X64 architecture, providing the foundational structure for thread-related functionalities in the kernel.",
    "input": "",
    "output": "(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/X64.lhs CONTEXT X64_H decls_only\n\nend (* context X64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Type Enumeration: Defines the enumeration of object types, including specific types such as PDPointerTableObject, PML4Object, HugePageObject, SmallPageObject, LargePageObject, PageTableObject, and PageDirectoryObject. Ensures that the enumeration is complete and distinct, supporting both standard and alternative enumeration methods.",
    "input": "",
    "output": "qualify X64_H (in Arch)\ninstantiation X64_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [PDPointerTableObject,\n      PML4Object,\n      HugePageObject,\n      SmallPageObject,\n      LargePageObject,\n      PageTableObject,\n      PageDirectoryObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation X64_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation X64_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ArchHook Definitions: Defines entry and exit hooks for architectural operations, which are currently implemented as no-ops. These hooks can be used to insert custom behavior at the beginning and end of architectural operations.",
    "input": "",
    "output": "chapter \"ArchHook\"\n\ntheory ArchHook_H\nimports KernelStateData_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  cEntryHook :: \"unit kernel\"\nwhere\n  \"cEntryHook\\<equiv> return ()\"\n\ndefinition\n  cExitHook :: \"unit kernel\"\nwhere\n  \"cExitHook\\<equiv> return ()\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Kernel State and Monads: Defines the architecture-specific kernel state and monads, incorporating necessary imports and context for the X64 architecture. This ensures that the kernel's state and operations are tailored to the specific requirements and capabilities of the X64 architecture.",
    "input": "",
    "output": "(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/X64.lhs CONTEXT X64_H NOT X64VSpaceRegionUse\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup: Provides the mechanisms for looking up virtual memory space, enabling the system to manage and access memory regions effectively.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Failures/X64.lhs CONTEXT X64_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/X64.lhs CONTEXT X64_H bodies_only\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Management: The ASID pool is initialized with a function array of `Nothing` values, and the loading and updating of the ASID pool object are handled by default methods. This ensures that the ASID pool is consistently managed and updated within the kernel.",
    "input": "",
    "output": "instantiation X64_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pte updateObject_pte\n  loadObject_pde updateObject_pde\n  loadObject_pdpte updateObject_pdpte\n  loadObject_pml4e updateObject_pml4e\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Data Types: Define and share architecture-specific data types between the specification and abstract layers, ensuring consistency and compatibility across different architectural contexts.",
    "input": "",
    "output": "(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Main Setup_Locale\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/X64.lhs CONTEXT X64_H ONLY X64VSpaceRegionUse\n\nend (* context X64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup and Validation: Ensures that the mapping size for a virtual space is valid by checking that the size is within the allowed maximum object size.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  Untyped_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/X64.lhs CONTEXT X64_H bodies_only ArchInv=ArchRetypeDecls_H NOT checkPML4At checkPDPTAt checkPDAt checkPTAt checkValidMappingSize\n#INCLUDE_HASKELL SEL4/Object/IOPort/X64.lhs CONTEXT X64_H bodies_only ArchInv=ArchRetypeDecls_H\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert\n    (\\<lambda>s. 2 ^ pageBitsForSize sz <= gsMaxObjectSize s) []\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural TCB Operations: Define and implement architecture-specific operations for thread control blocks, including getting and setting thread state, tailored for the x64 architecture.",
    "input": "",
    "output": "theory ArchTCB_H\nimports TCBDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/X64.lhs RegisterSet= CONTEXT X64_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retyping Objects: Define and manage the reconfiguration of objects within the system, including structures, invocation labels, and virtual space operations, to ensure they meet the required architectural specifications.",
    "input": "",
    "output": "chapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT X64_H\n#INCLUDE_HASKELL_PREPARSE SEL4/API/InvocationLabels/X64.lhs CONTEXT X64\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/X64.lhs CONTEXT X64_H decls_only ArchInv=\n#INCLUDE_HASKELL SEL4/Object/IOPort/X64.lhs CONTEXT X64_H decls_only ArchInv=\n\nend (* context X64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Canonical Address Assertion: Ensures that a given machine word is considered canonical, which may be defined or delayed differently across various architectures.",
    "input": "",
    "output": "definition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific System Call Labels: Define a set of labels for architecture-specific system calls, providing a standardized way to identify and invoke these operations within the system.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/InvocationLabels/X64.lhs CONTEXT X64_H ONLY ArchInvocationLabel\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Invocation Label Requalification: Ensures that the invocation labels specific to the architecture are requalified and properly integrated within the architectural context, facilitating the correct handling of architecture-specific operations.",
    "input": "",
    "output": "arch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/X64.lhs CONTEXT X64_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Register Set Initialization: Defines a new user context with an initial state, setting the floating-point unit (FPU) to a null state and initializing the general-purpose registers.",
    "input": "",
    "output": "chapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext FPUNullState ((K 0) aLU initContext)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Handling: Defines the architecture-specific fault handling mechanisms, including the declaration and implementation of fault types and their corresponding failure handling logic.",
    "input": "",
    "output": "chapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/X64.lhs\n\n#INCLUDE_HASKELL SEL4/API/Faults/X64.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/X64.lhs bodies_only\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Kernel Object Types: Defines a set of arch kernel object types, including PDET, PTET, PDPTET, PML4ET, and ASIDPoolT, and provides a function to determine the type of a given arch kernel object.",
    "input": "",
    "output": "theory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/X64.lhs CONTEXT X64_H decls_only\n#INCLUDE_HASKELL SEL4/Object/Structures/X64.lhs CONTEXT X64_H instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/X64.lhs CONTEXT X64_H bodies_only\n\ndatatype arch_kernel_object_type =\n    PDET\n  | PTET\n  | PDPTET\n  | PML4ET\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPDE e) = PDET\"\n| \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOPDPTE e) = PDPTET\"\n| \"archTypeOf (KOPML4E e) = PML4ET\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constants and Register Set Definitions: Define and requalify architectural constants and register set operations for the X64 architecture, including definitions for pointer conversion and null pointer.",
    "input": "",
    "output": "arch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=X64 CONTEXT X64_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Handling: Defines the architecture-specific interrupt handling mechanisms, including declarations and configurations for interrupts on the x64 platform. This ensures that the system can manage and respond to hardware interrupts effectively, maintaining the stability and responsiveness of the operating system.",
    "input": "",
    "output": "theory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/X64.lhs CONTEXT X64_H bodies_only ArchInv= Arch=\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retyping Objects: Define and manage the reconfiguration of object types, allowing for the transformation of one type of object into another within the system. This ensures flexibility and adaptability in the use of system resources.",
    "input": "",
    "output": "chapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/X64.lhs CONTEXT X64_H Arch.Types=ArchTypes_H ArchInv=ArchRetypeDecls_H NOT bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/X64.lhs CONTEXT X64_H bodies_only\n\nend (* context X64 *)\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create New Memory Objects: Generate new memory objects (pages or tables) and their corresponding capabilities based on the specified type, region base, number of objects, and other parameters. The function initializes the memory objects and updates the kernel state to reflect the new mappings, ensuring that the system can manage and access the newly created memory regions effectively.",
    "input": "",
    "output": "chapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewPageCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        return $ map (\\<lambda>n. PageCap (PPtr (fromPPtr n)) VMReadWrite VMNoMap pSize dev Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 0 X64SmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev ptTranslationBits X64LargePage\n        | HugePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev (ptTranslationBits + ptTranslationBits) X64HugePage\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        | PageDirectoryObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdBits (makeObject::pde) PageDirectoryCap\n              (\\<lambda>pts. return ())\n        | PDPointerTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdptBits (makeObject::pdpte) PDPointerTableCap\n              (\\<lambda>pts. return ())\n        | PML4Object \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pml4Bits (makeObject::pml4e) PML4Cap\n              (\\<lambda>pms. mapM_x copyGlobalMappings pms)\n        )\"\n\nend\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Architecture: Defines the architecture-specific thread operations and structures for the x64 platform, including thread control block (TCB) declarations and virtual space management.",
    "input": "",
    "output": "chapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\nbegin\n\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/X64.lhs CONTEXT X64_H Arch=MachineOps ArchReg=MachineTypes bodies_only\n\nend (* context X64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "No specific code or comments are provided for the x64 section, so there is no property to summarize.",
    "input": "",
    "output": "end",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Stub for X64: Provides the necessary declarations and implementations for hypervisor functionalities specific to the X64 architecture, ensuring that the hypervisor can manage and interact with virtualized resources effectively.",
    "input": "",
    "output": "(*\n  Hypervisor stub for X64\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/X64.lhs Arch= CONTEXT X64_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/X64.lhs Arch= CONTEXT X64_H bodies_only ArchInv= ArchLabels=\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Declarations: Define and declare the necessary components and operations for handling interrupts in the x64 architecture, ensuring that the system can manage and respond to hardware interrupts effectively.",
    "input": "",
    "output": "theory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/X64.lhs CONTEXT X64_H decls_only ArchInv= Arch=MachineOps\n\nend (* context X64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware Abstraction and Memory Management: Provides a comprehensive set of functions for hardware-level operations, including memory management, interrupt handling, timer configuration, and I/O operations. These functions ensure that the system can interact with the underlying hardware efficiently and safely, supporting critical tasks such as memory initialization, page table manipulation, and interrupt management.",
    "input": "",
    "output": "theory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs Platform=Platform.X64 CONTEXT X64_H NOT getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory wordFromPDE wordFromPTE VMFaultType HypFaultType VMMapType VMPageSize pageBits pageBitsForSize paddrBase pptrBase pptrTop pptrBaseOffset kernelELFBaseOffset kernelELFPAddrBase kernelELFBase toPAddr addrFromPPtr ptrFromPAddr addrFromKPPtr setCurrentUserCR3 getCurrentUserCR3 invalidateTLB invalidateTLBEntry mfence wordFromPML4E wordFromPDPTE firstValidIODomain numIODomainIDBits hwASIDInvalidate getFaultAddress irqIntOffset maxPCIBus maxPCIDev maxPCIFunc ioapicIRQLines ioapicMapPinToVector irqStateIRQIOAPICNew irqStateIRQMSINew updateIRQState in8 out8 in16 out16 in32 out32 invalidatePageStructureCache writeCR3 invalidateASID invalidateTranslationSingleASID invalidateLocalPageStructureCacheASID ptTranslationBits nativeThreadUsingFPU switchFpuOwner\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64_H instanceproofs NOT VMFaultType VMPageSize VMPageEntry VMMapType HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64_H ONLY wordFromPDE wordFromPTE wordFromPML4E wordFromPDPTE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Maximum IRQ Definition: The maximum interrupt request (IRQ) number is defined based on the platform-specific value for x64 architectures.",
    "input": "",
    "output": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Platform.X64.maxIRQ\"\n\nend (* context X64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific Ghost Update Functions: Define and implement architecture-specific ghost update functions for managing physical memory in the RISC-V64 architecture.",
    "input": "",
    "output": "(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/RISCV64.hs\n\nend (* context Arch *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for Threads: Defines the necessary function declarations and context setup for thread management in the RISCV64 architecture, ensuring that the kernel has the required functions to handle thread operations.",
    "input": "",
    "output": "(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/RISCV64.hs CONTEXT RISCV64_H decls_only\n\nend (* context RISCV64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Type Enumeration: Defines the enumeration of object types for the RISCV64_H architecture, including API object types and specific memory objects such as HugePage, SmallPage, LargePage, and PageTable. Ensures that all possible object types are covered and can be uniquely identified.",
    "input": "",
    "output": "qualify RISCV64_H (in Arch)\ninstantiation RISCV64_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [HugePageObject,\n      SmallPageObject,\n      LargePageObject,\n      PageTableObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation RISCV64_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation RISCV64_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Kernel State and Monads: Defines the architecture-specific kernel state and monads, incorporating necessary imports and context for the RISCV64 architecture. This ensures that the kernel's state and operations are tailored to the specific requirements and capabilities of the RISCV64 architecture.",
    "input": "",
    "output": "(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/RISCV64.hs CONTEXT RISCV64_H NOT RISCVVSpaceRegionUse\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup: Provides the necessary definitions and context for handling architecture-specific failures in the RISCV64 architecture, ensuring that the system can properly manage and respond to various fault conditions.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Failures/RISCV64.hs CONTEXT RISCV64_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/RISCV64.hs CONTEXT RISCV64_H bodies_only\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Initialization and Management: The ASID pool is initialized with a function array where each entry is set to `Nothing`. The loading and updating of the ASID pool object are handled by default methods, ensuring that the ASID pool can be managed within the kernel's memory space.",
    "input": "",
    "output": "instantiation RISCV64_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Data Types: Define and share common, architecture-specific data types between the specification and abstract models, ensuring consistency and reusability across different components of the system.",
    "input": "",
    "output": "(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Setup_Locale\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/RISCV64.hs CONTEXT RISCV64_H ONLY RISCVVSpaceRegionUse\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup: Recursively traverses the page table hierarchy to find the appropriate slot or pointer based on the given virtual address and level, ensuring that the page table entries are valid and correctly point to the next level of the hierarchy.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  Untyped_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/RISCV64.hs CONTEXT RISCV64_H bodies_only ArchInv=ArchRetypeDecls_H ONLY pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft\n\nfun\n  lookupPTSlotFromLevel :: \"nat => machine_word => machine_word => (nat * machine_word) kernel\"\nwhere\n  \"lookupPTSlotFromLevel 0 ptPtr vPtr =\n     return (ptBitsLeft 0, ptSlotIndex 0 ptPtr vPtr)\"\n| \"lookupPTSlotFromLevel level ptPtr vPtr = do\n     pte <- pteAtIndex level ptPtr vPtr;\n     if isPageTablePTE pte\n     then do\n       checkPTAt (getPPtrFromHWPTE pte);\n       lookupPTSlotFromLevel (level - 1) (getPPtrFromHWPTE pte) vPtr\n     od\n     else return (ptBitsLeft level, ptSlotIndex level ptPtr vPtr)\n   od\"\n\nfun\n  lookupPTFromLevel :: \"nat => machine_word => machine_word => machine_word =>\n    (lookup_failure, machine_word) kernel_f\"\nwhere\n  \"lookupPTFromLevel level ptPtr vPtr targetPtPtr = doE\n    assertE (ptPtr \\<noteq> targetPtPtr);\n    unlessE (0 < level) $ throw InvalidRoot;\n    slot <- returnOk $ ptSlotIndex level ptPtr vPtr;\n    pte <- withoutFailure $ getObject slot;\n    unlessE (isPageTablePTE pte) $ throw InvalidRoot;\n    ptr <- returnOk (getPPtrFromHWPTE pte);\n    if ptr = targetPtPtr\n        then returnOk slot\n        else doE\n          liftE $ checkPTAt ptr;\n          lookupPTFromLevel (level - 1) ptr vPtr targetPtPtr\n        odE\n  odE\"\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/RISCV64.hs CONTEXT RISCV64_H bodies_only ArchInv=ArchRetypeDecls_H NOT lookupPTSlotFromLevel lookupPTFromLevel pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft checkPTAt\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural TCB Operations: Provides functions for getting and setting thread control block (TCB) architectural state, allowing for the manipulation of register sets and other architecture-specific properties.",
    "input": "",
    "output": "theory ArchTCB_H\nimports TCBDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/RISCV64.hs RegisterSet= CONTEXT RISCV64_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Retyping: Allows the redefinition of an object's type and structure, enabling the transformation of one type of object into another. This process ensures that the system can dynamically adapt and manage memory and resources efficiently.",
    "input": "",
    "output": "chapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT RISCV64_H\n#INCLUDE_HASKELL_PREPARSE SEL4/API/InvocationLabels/RISCV64.hs CONTEXT RISCV64\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/RISCV64.hs CONTEXT RISCV64_H decls_only ArchInv= NOT lookupPTSlotFromLevel lookupPTFromLevel\n\nend (* context RISCV64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Canonical Address Assertion: Ensures that a given machine word represents a canonical address, which may be defined or delayed differently across various architectures.",
    "input": "",
    "output": "consts canonicalAddressAssert :: \"machine_word => bool\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific System Call Labels: Define a set of architecture-specific labels for system calls, providing a standardized way to identify and handle different types of system calls in the RISCV64 architecture.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/InvocationLabels/RISCV64.hs CONTEXT RISCV64_H ONLY ArchInvocationLabel\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Invocation Label Requalification: Requalifies the `arch_invocation_label` type within the Arch context, ensuring that it adheres to the specific requirements and constraints of the RISCV64 architecture.",
    "input": "",
    "output": "arch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/RISCV64.hs CONTEXT RISCV64_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Register Set Initialization: Define a new user context with all registers initialized to zero. This ensures that the initial state of the user context is well-defined and consistent, providing a clean starting point for thread execution.",
    "input": "",
    "output": "chapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext ((K 0) aLU initContext)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Handling: Defines the fault handling mechanisms and associated failures for the RISC-V64 architecture, ensuring that the system can properly manage and respond to various types of faults.",
    "input": "",
    "output": "chapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/RISCV64.hs\n\n#INCLUDE_HASKELL SEL4/API/Faults/RISCV64.hs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/RISCV64.hs bodies_only\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Kernel Object Types: Defines two types of architectural kernel objects, Page Table Entry (PTE) and ASID Pool, and provides a function to determine the type of a given architectural kernel object.",
    "input": "",
    "output": "theory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H decls_only\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H bodies_only\n\ndatatype arch_kernel_object_type =\n    PTET\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Requalification and Import of Word and Register Set Definitions: Requalifies and imports word and register set definitions for the RISCV64 architecture, ensuring that these definitions are available in the current context. Defines pointer conversion functions and a null pointer value, facilitating machine word operations and register manipulations specific to the RISCV64 architecture.",
    "input": "",
    "output": "arch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=RISCV64 CONTEXT RISCV64_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Handling: Defines the handling and management of interrupts specific to the RISCV64 architecture, including operations for claiming and completing interrupt requests.",
    "input": "",
    "output": "theory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/RISCV64.hs CONTEXT RISCV64_H bodies_only ArchInv= Arch= NOT plic_complete_claim\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retyping Objects: Allows the transformation of an object's type, enabling the modification of its structure and capabilities to fit different roles or requirements within the system.",
    "input": "",
    "output": "chapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/RISCV64.hs CONTEXT RISCV64_H Arch.Types=ArchTypes_H ArchInv=ArchRetypeDecls_H NOT bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/RISCV64.hs CONTEXT RISCV64_H bodies_only\n\nend (* context RISCV64 *)\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create New Capabilities: Generate new capabilities for different types of objects (frames or tables) based on the specified region, number of objects, and object type. For frame objects, it creates user data or device data frames with specified sizes and sets their permissions. For table objects, it initializes mappings and generates corresponding capabilities.",
    "input": "",
    "output": "chapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewFrameCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        return $ map (\\<lambda>n. FrameCap  (PPtr (fromPPtr n)) VMReadWrite pSize dev Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev 0 RISCVSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev ptTranslationBits RISCVLargePage\n        | HugePageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev (ptTranslationBits + ptTranslationBits) RISCVHugePage\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        )\"\n\nend\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Management: Defines the architecture-specific thread management operations and data structures for the RISCV64 architecture, ensuring proper handling of thread states and behaviors within the kernel.",
    "input": "",
    "output": "chapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/RISCV64.hs CONTEXT RISCV64_H Arch=MachineOps ArchReg=MachineTypes bodies_only\n\nend (* context RISCV64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "No specific property can be derived from the provided code snippet, as it only contains an `end` statement and no functional or behavioral definitions.",
    "input": "",
    "output": "end",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Stub for RISCV64: Provides the necessary declarations and implementations for hypervisor functionality specific to the RISCV64 architecture, ensuring that the hypervisor can manage and interact with virtual machines effectively.",
    "input": "",
    "output": "(*\n  Hypervisor stub for RISCV64\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/RISCV64.hs Arch= CONTEXT RISCV64_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/RISCV64.hs Arch= CONTEXT RISCV64_H bodies_only ArchInv= ArchLabels=\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Declarations: Define the declarations and operations for handling interrupts in the RISCV64 architecture, including the necessary context and global naming conventions.",
    "input": "",
    "output": "theory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/RISCV64.hs CONTEXT RISCV64_H decls_only ArchInv= Arch=MachineOps NOT plic_complete_claim\n\nend (* context RISCV64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware Abstraction: Provides a set of hardware-specific operations and constants for the RISCV64 architecture, including memory management, interrupt handling, timer configuration, and virtual memory operations. These functions and values enable the operating system to interact with the underlying hardware effectively, ensuring proper resource management and system stability.",
    "input": "",
    "output": "theory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs Platform=Platform.RISCV64 CONTEXT RISCV64_H NOT plic_complete_claim getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory setHardwareASID wordFromPDE wordFromPTE VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize toPAddr addrFromPPtr ptrFromPAddr sfence physBase paddrBase pptrBase pptrBaseOffset pptrTop pptrUserTop kernelELFBase kernelELFBaseOffset kernelELFPAddrBase addrFromKPPtr ptTranslationBits vmFaultTypeFSR read_stval setVSpaceRoot hwASIDFlush setIRQTrigger\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64_H instanceproofs NOT plic_complete_claim HardwareASID VMFaultType VMPageSize VMPageEntry HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64_H ONLY wordFromPTE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Definition: The maximum interrupt request (IRQ) number is defined according to the platform-specific definitions for the RISCV64 architecture.",
    "input": "",
    "output": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Platform.RISCV64.maxIRQ\"\n\nend (* context RISCV64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Management: Provides functionalities for managing virtual CPUs, including enabling, disabling, saving, restoring, and switching VCPUs, as well as handling virtual interrupts and maintaining VCPU state.",
    "input": "",
    "output": "chapter \"VCPU\"\n\ntheory VCPU_H\nimports\n  Hardware_H\n  Structures_H\n  Invocations_H\n  TCB_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT AARCH64_H\n#INCLUDE_HASKELL SEL4/Object/VCPU/AARCH64.hs CONTEXT AARCH64_H ArchInv=Arch \\\n  NOT vcpuUpdate vgicUpdate vgicUpdateLR vcpuSaveReg vcpuRestoreReg \\\n    vcpuSaveRegRange vcpuRestoreRegRange vcpuWriteReg vcpuReadReg saveVirtTimer \\\n    restoreVirtTimer vcpuDisable vcpuEnable vcpuRestore vcpuSave vcpuSwitch \\\n    vcpuInvalidateActive vcpuCleanInvalidateActive countTrailingZeros virqType \\\n    virqSetEOIIRQEN vgicMaintenance vppiEvent irqVPPIEventIndex armvVCPUSave \\\n    curVCPUActive\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Physical Memory Management: Provides functions for managing physical memory, including handling page table partial overlaps, ensuring that memory is correctly allocated and managed according to the architecture's specifications.",
    "input": "",
    "output": "(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/AARCH64.hs decls_only ONLY pTablePartialOverlap\n#INCLUDE_HASKELL SEL4/Model/PSpace/AARCH64.hs NOT pTablePartialOverlap\n\nend (* context Arch *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for Threads: Defines the necessary function declarations and context for thread management in an AARCH64 architecture, ensuring that the kernel can handle thread-related operations effectively.",
    "input": "",
    "output": "(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/AARCH64.hs CONTEXT AARCH64_H decls_only\n\nend (* context AARCH64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Type Enumeration: Defines the enumeration of object types for the AARCH64 architecture, including specific types such as HugePageObject, VSpaceObject, SmallPageObject, LargePageObject, PageTableObject, and VCPUObject. Ensures that all and any properties over the object types are correctly defined and that the enumeration is distinct and complete.",
    "input": "",
    "output": "qualify AARCH64_H (in Arch)\ninstantiation AARCH64_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [HugePageObject,\n      VSpaceObject,\n      SmallPageObject,\n      LargePageObject,\n      PageTableObject,\n      VCPUObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation AARCH64_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation AARCH64_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Kernel State and Monads: Defines the architecture-specific kernel state and monads, incorporating the necessary components from various architectural structures and types to support the SEL4 model.",
    "input": "",
    "output": "(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/AARCH64.hs CONTEXT AARCH64_H NOT ArmVSpaceRegionUse\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup: Provides mechanisms for handling and translating virtual memory faults in the AARCH64 architecture, ensuring that the system can respond appropriately to memory access errors.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Failures/AARCH64.hs CONTEXT AARCH64_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/AARCH64.hs CONTEXT AARCH64_H bodies_only\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Management: The ASID pool is represented as a fixed-size array of `Nothing` values, ensuring a safe and consistent structure for managing ASID mappings. The load and update operations for the ASID pool are defined to use default implementations, maintaining the integrity and simplicity of the ASID pool's state.",
    "input": "",
    "output": "instantiation AARCH64_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Common, Architecture-Specific Data Types: Define and share architecture-specific data types, such as ArmVSpaceRegionUse and FlushType, between the specification and abstract layers to ensure consistent representation and handling of architecture-specific concepts.",
    "input": "",
    "output": "(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Setup_Locale\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/AARCH64.hs CONTEXT AARCH64_H ONLY ArmVSpaceRegionUse\n\n#INCLUDE_HASKELL SEL4/API/Invocation/AARCH64.hs CONTEXT AARCH64_H ONLY FlushType\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup: Recursively traverses the page table hierarchy to find the appropriate slot for a given virtual address, ensuring that each level is a valid page table and stopping at the target level or when a non-page-table PTE is encountered. Subproperties include:\n- **PT Slot Lookup**: Determines the slot index at a specific level of the page table hierarchy.\n- **PT Hierarchy Traversal**: Recursively checks each level of the page table, validating the PTEs and continuing to the next level until the target is found or a non-page-table PTE is encountered.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv=ArchRetypeDecls_H ONLY pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft\n\nfun\n  lookupPTSlotFromLevel :: \"nat => machine_word => machine_word => (nat * machine_word) kernel\"\nwhere\n  \"lookupPTSlotFromLevel 0 ptPtr vPtr =\n     return (ptBitsLeft 0, ptSlotIndex 0 ptPtr vPtr)\"\n| \"lookupPTSlotFromLevel level ptPtr vPtr = do\n     pte <- pteAtIndex level ptPtr vPtr;\n     if isPageTablePTE pte\n     then do\n       checkPTAt NormalPT_T (getPPtrFromPTE pte);\n       lookupPTSlotFromLevel (level - 1) (getPPtrFromPTE pte) vPtr\n     od\n     else return (ptBitsLeft level, ptSlotIndex level ptPtr vPtr)\n   od\"\n\nfun\n  lookupPTFromLevel :: \"nat => machine_word => machine_word => machine_word =>\n    (lookup_failure, machine_word) kernel_f\"\nwhere\n  \"lookupPTFromLevel level ptPtr vPtr targetPtPtr = doE\n    assertE (ptPtr \\<noteq> targetPtPtr);\n    unlessE (0 < level) $ throw InvalidRoot;\n    slot <- returnOk $ ptSlotIndex level ptPtr vPtr;\n    pte <- withoutFailure $ getObject slot;\n    unlessE (isPageTablePTE pte) $ throw InvalidRoot;\n    ptr <- returnOk (getPPtrFromPTE pte);\n    if ptr = targetPtPtr\n        then returnOk slot\n        else doE\n          liftE $ checkPTAt NormalPT_T ptr;\n          lookupPTFromLevel (level - 1) ptr vPtr targetPtPtr\n        odE\n  odE\"\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv=ArchRetypeDecls_H NOT lookupPTSlotFromLevel lookupPTFromLevel pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft checkPTAt checkValidMappingSize\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert (\\<lambda>s. 2 ^ sz <= gsMaxObjectSize s) []\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Thread Management: Provides functions for getting and setting architectural-specific thread states, including register sets, ensuring that the thread's state is correctly managed and updated according to the architecture's requirements.",
    "input": "",
    "output": "theory ArchTCB_H\nimports TCBDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/AARCH64.hs RegisterSet= CONTEXT AARCH64_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Base Calculation: Compute the base address of a page given a word and an offset, ensuring that the result is within the constraints of the specified word length.",
    "input": "",
    "output": "consts'\npageBase :: \"('a :: len word) \\<Rightarrow> nat \\<Rightarrow> 'a word\"\n\nend (* context AARCH64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Canonical Address Assertion: Ensures that a given machine word represents a canonical address, with the definition and validation potentially varying across different architectures.",
    "input": "",
    "output": "consts canonicalAddressAssert :: \"machine_word => bool\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific System Call Labels: Enumerate labels for architecture-specific system calls, providing a structured way to identify and handle different types of system calls in the AARCH64 architecture.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/InvocationLabels/AARCH64.hs CONTEXT AARCH64_H ONLY ArchInvocationLabel\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Invocation Label Requalification: The code requalifies arch-specific invocation labels within the Arch context, ensuring that the enum instances are correctly defined and used outside of the generic Arch locale.",
    "input": "",
    "output": "arch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/AARCH64.hs CONTEXT AARCH64_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Register Initialization: Defines the initial state for the FPU and user context, setting all registers to a default value of 0. This ensures that the system starts in a known and consistent state.",
    "input": "",
    "output": "chapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition newFPUState :: \"fpu_state\" where\n  \"newFPUState \\<equiv> FPUState (K 0) 0 0 \"\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext newFPUState ((K 0) aLU initContext)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Handling: Define and manage fault handlers for the AARCH64 architecture, ensuring that the system can appropriately respond to and handle various types of faults.",
    "input": "",
    "output": "chapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/AARCH64.hs\n\n#INCLUDE_HASKELL SEL4/API/Faults/AARCH64.hs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/AARCH64.hs bodies_only\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Structures: Define and initialize the architectural-specific structures and objects for the AARCH64 architecture, including ASID pools and TCBs, while excluding VPPIEventIRQ and VirtTimer.",
    "input": "",
    "output": "theory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64_H decls_only \\\n  NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64_H instanceproofs \\\n  NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64_H bodies_only \\\n  NOT makeVCPUObject",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create VCPU Object: Defines the creation of a VCPU object with specific initial values for its components, including an empty TCB pointer, a VGIC interface with default settings, a set of registers initialized to zero with specific exceptions, a VPPIMasked function that always returns false, and a virtual timer initialized to zero.",
    "input": "",
    "output": "defs makeVCPUObject_def:\n\"makeVCPUObject \\<equiv>\n    VCPUObj_ \\<lparr>\n          vcpuTCBPtr= Nothing\n        , vcpuVGIC= VGICInterface_ \\<lparr>\n                          vgicHCR= vgicHCREN\n                        , vgicVMCR= 0\n                        , vgicAPR= 0\n                        , vgicLR= (\\<lambda>_. 0)\n                        \\<rparr>\n        , vcpuRegs= funArray (const 0)  aLU  [(VCPURegSCTLR, sctlrEL1VM)]\n        , vcpuVPPIMasked= (\\<lambda>_. False)\n        , vcpuVTimer= VirtTimer 0\n        \\<rparr>\"\n\ndatatype arch_kernel_object_type =\n    PTET\n  | VCPUT\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOVCPU e) = VCPUT\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Requalification: The requalification of types is architecture-specific, allowing for the handling of unique architectural features such as vCPU. This ensures that the system can adapt to the specific requirements and capabilities of different architectures.",
    "input": "",
    "output": "arch_requalify_types (H)\n  vcpu\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constants and Utilities: Defines and requalifies architectural constants, including word bits, and provides utility functions for pointer manipulation, such as converting to and from physical pointers and defining a null pointer.",
    "input": "",
    "output": "arch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=AARCH64 CONTEXT AARCH64_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Handling: Defines the architecture-specific interrupt handling mechanisms for AARCH64, including declarations and configurations for interrupt objects and hypervisor interactions.",
    "input": "",
    "output": "theory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv= Arch= NOT plic_complete_claim\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retyping Objects: Allows the reclassification and reinitialization of objects in the system, enabling the transformation of one type of object into another while preserving the system's integrity and security.",
    "input": "",
    "output": "chapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\n  VCPU_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/AARCH64.hs CONTEXT AARCH64_H Arch.Types=ArchTypes_H ArchInv=ArchRetypeDecls_H NOT bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/AARCH64.hs CONTEXT AARCH64_H bodies_only \\\n  NOT isVSpaceFlushLabel isPageFlushLabel\n\nend (* context AARCH64 *)\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create New Capabilities: Generates new capabilities based on the specified type, region base, and number of objects. This includes creating frame or table capabilities, updating kernel state, and performing necessary cache operations to ensure the integrity and readiness of the newly created memory regions.",
    "input": "",
    "output": "chapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewFrameCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        when (\\<not>dev) $\n          mapM_x (\\<lambda>addr. doMachineOp $\n                            cleanCacheRange_RAM addr\n                                                (addr + mask (pageBitsForSize pSize))\n                                                (addrFromPPtr addr)) addrs;\n        return $ map (\\<lambda>n. FrameCap  (PPtr (fromPPtr n)) VMReadWrite pSize dev Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects ptType objectProto cap initialiseMappings \\<equiv> (do\n      tableBits \\<leftarrow> return (ptBits ptType);\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      modify (\\<lambda>ks. ks \\<lparr>ksArchState :=\n                         ksArchState ks \\<lparr>gsPTTypes := (\\<lambda>addr.\n                                           if addr `~elem~` map fromPPtr addrs then Just ptType\n                                           else gsPTTypes (ksArchState ks) addr)\\<rparr>\\<rparr>);\n      initialiseMappings pts;\n      mapM_x (\\<lambda>addr. doMachineOp $\n                       cleanCacheRange_PoU addr (addr + mask tableBits) (addrFromPPtr addr)) addrs;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev 0 ARMSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev (ptTranslationBits NormalPT_T) ARMLargePage\n        | HugePageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev (2 * ptTranslationBits NormalPT_T) ARMHugePage\n        | VSpaceObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects VSRootPT_T (makeObject::pte)\n              (\\<lambda>base addr. PageTableCap base VSRootPT_T addr)\n              (\\<lambda>pts. return ())\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects NormalPT_T (makeObject::pte)\n              (\\<lambda>base addr. PageTableCap base NormalPT_T addr)\n              (\\<lambda>pts. return ())\n        | VCPUObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject :: vcpu)) 0;\n            return $ map (\\<lambda>addr. VCPUCap addr) addrs\n            od)\n        )\"\n\nend\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Management: Defines the architecture-specific operations and data structures for managing threads, including thread control block (TCB) declarations, virtual space management, and hypervisor interactions.",
    "input": "",
    "output": "chapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/AARCH64.hs CONTEXT AARCH64_H Arch=MachineOps ArchReg=MachineTypes bodies_only\n\nend (* context AARCH64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific Invocation Labels: Determine if an invocation label corresponds to a virtual space flush or a page flush, enabling the system to handle architecture-specific memory management operations.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/Invocation/AARCH64.hs CONTEXT AARCH64_H \\\n  ONLY isVSpaceFlushLabel isPageFlushLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hypervisor Functions for AARCH64: Provides a set of functions to manage virtual CPUs, including updating, saving, restoring, enabling, and disabling vCPUs, as well as handling virtual interrupts and timer operations. These functions ensure the proper state management and control of virtual CPUs in the hypervisor environment.",
    "input": "",
    "output": "(*\n  Hypervisor function definitions for AARCH64\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  FaultHandlerDecls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/VCPU/AARCH64.hs CONTEXT AARCH64_H decls_only \\\n  ONLY countTrailingZeros irqVPPIEventIndex\n#INCLUDE_HASKELL SEL4/Object/VCPU/AARCH64.hs CONTEXT AARCH64_H bodies_only \\\n  ONLY countTrailingZeros irqVPPIEventIndex\n#INCLUDE_HASKELL SEL4/Object/VCPU/AARCH64.hs CONTEXT AARCH64_H ArchInv=Arch \\\n  ONLY vcpuUpdate vgicUpdate vgicUpdateLR vcpuSaveReg vcpuRestoreReg \\\n    vcpuSaveRegRange vcpuRestoreRegRange vcpuWriteReg vcpuReadReg saveVirtTimer \\\n    restoreVirtTimer vcpuDisable vcpuEnable vcpuRestore armvVCPUSave \\\n    vcpuSave vcpuSwitch vcpuInvalidateActive vcpuCleanInvalidateActive \\\n    virqType virqSetEOIIRQEN vgicMaintenance vppiEvent curVCPUActive\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/AARCH64.hs Arch= CONTEXT AARCH64_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/AARCH64.hs Arch= CONTEXT AARCH64_H bodies_only ArchInv= ArchLabels=\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Declarations: Define the declarations and operations for managing interrupts on the AARCH64 architecture, ensuring that the system can handle and process interrupts effectively.",
    "input": "",
    "output": "theory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/AARCH64.hs CONTEXT AARCH64_H decls_only ArchInv= Arch=MachineOps NOT plic_complete_claim\n\nend (* context AARCH64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware Abstraction: Provides a comprehensive set of functions and constants for managing AARCH64 hardware, including memory operations, interrupt handling, timer configuration, and cache management. These abstractions enable the operating system to interact with the underlying hardware effectively, ensuring proper resource management and system stability.",
    "input": "",
    "output": "theory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs Platform=Platform.AARCH64 CONTEXT AARCH64_H \\\n  NOT PT_Type plic_complete_claim getMemoryRegions getDeviceRegions getKernelDevices \\\n  loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt \\\n  configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory \\\n  clearMemoryVM initMemory freeMemory setHardwareASID wordFromPDE wordFromPTE \\\n  VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize toPAddr \\\n  addrFromPPtr ptrFromPAddr sfence physBase paddrBase pptrBase pptrBaseOffset \\\n  pptrUserTop kernelELFBase kernelELFBaseOffset kernelELFPAddrBase \\\n  addrFromKPPtr ptTranslationBits vmFaultTypeFSR setVSpaceRoot \\\n  setIRQTrigger \\\n  config_ARM_PA_SIZE_BITS_40 fpuThreadDeleteOp isFpuEnable \\\n  hcrVCPU hcrNative sctlrDefault vgicHCREN gicVCPUMaxNumLR sctlrEL1VM \\\n  get_gic_vcpu_ctrl_hcr set_gic_vcpu_ctrl_hcr get_gic_vcpu_ctrl_vmcr \\\n  set_gic_vcpu_ctrl_vmcr get_gic_vcpu_ctrl_apr set_gic_vcpu_ctrl_apr \\\n  get_gic_vcpu_ctrl_vtr get_gic_vcpu_ctrl_eisr0 get_gic_vcpu_ctrl_eisr1 \\\n  get_gic_vcpu_ctrl_misr get_gic_vcpu_ctrl_lr set_gic_vcpu_ctrl_lr read_cntpct \\\n  check_export_arch_timer \\\n  isb dsb dmb \\\n  invalidateTranslationASID invalidateTranslationSingle \\\n  cleanByVA_PoU cleanInvalidateCacheRange_RAM cleanCacheRange_RAM cleanCacheRange_PoU \\\n  invalidateCacheRange_RAM invalidateCacheRange_I branchFlushRange \\\n  enableFpuEL01 \\\n  getFAR getDFSR getIFSR getHSR setHCR getESR  getSCTLR setSCTLR \\\n  addressTranslateS1 \\\n  readVCPUHardwareReg writeVCPUHardwareReg vcpuBits\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs CONTEXT AARCH64_H instanceproofs NOT plic_complete_claim HardwareASID VMFaultType VMPageSize VMPageEntry HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs CONTEXT AARCH64_H ONLY wordFromPTE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value: Defines the maximum value for an interrupt request (IRQ) in the system, ensuring that the kernel can handle and manage interrupts within a specified range.",
    "input": "",
    "output": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Kernel_Config.maxIRQ\"\n\nend (* context AARCH64 *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Management: Provides functions for managing virtual CPUs, including enabling, disabling, saving, restoring, and switching VCPUs, as well as handling virtual interrupts and maintaining the state of the virtual CPU.",
    "input": "",
    "output": "chapter \"VCPU\"\n\ntheory VCPU_H\nimports\n  Hardware_H\n  Structures_H\n  Invocations_H\n  TCB_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT ARM_HYP_H\n#INCLUDE_HASKELL SEL4/Object/VCPU/ARM.lhs CONTEXT ARM_HYP_H ArchInv=Arch NOT vcpuUpdate vgicUpdate vgicUpdateLR vcpuSaveReg vcpuRestoreReg vcpuSaveRegRange vcpuRestoreRegRange vcpuWriteReg vcpuReadReg saveVirtTimer restoreVirtTimer vcpuDisable vcpuEnable vcpuRestore vcpuSave vcpuSwitch vcpuInvalidateActive vcpuCleanInvalidateActive countTrailingZeros virqSetEOIIRQEN vgicMaintenance vppiEvent irqVPPIEventIndex armvVCPUSave\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Ghost Update Functions: Define and implement architecture-specific ghost update functions for managing physical memory, ensuring that the model accurately reflects the state and behavior of the system's memory.",
    "input": "",
    "output": "(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/ARM.hs\n\nend (* context Arch *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Function Declarations for Threads: Provides the necessary function declarations for thread management in the ARM architecture, ensuring that the system can handle thread-related operations effectively.",
    "input": "",
    "output": "(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT Arch decls_only\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Type Enumeration: Defines the enumeration of object types, including API object types and specific ARM hypervisor object types such as PageDirectory, SmallPage, LargePage, Section, SuperSection, PageTable, and VCPU. Ensures that all possible object types are covered and can be checked for properties using `enum_all` and `enum_ex`.",
    "input": "",
    "output": "qualify ARM_HYP_H (in Arch)\ninstantiation ARM_HYP_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [PageDirectoryObject,\n      SmallPageObject,\n      LargePageObject,\n      SectionObject,\n      SuperSectionObject,\n      PageTableObject,\n      VCPUObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation ARM_HYP_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation ARM_HYP_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Kernel State and Monads: Defines the architecture-specific kernel state and monads, incorporating necessary imports and context for the ARM architecture. This ensures that the kernel is tailored to the specific requirements and capabilities of the ARM architecture, providing a foundation for architecture-specific operations and state management.",
    "input": "",
    "output": "(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_HYP_H NOT ArmVSpaceRegionUse\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup: Provides mechanisms for handling and translating virtual memory faults, ensuring that the system can respond appropriately to memory access violations and maintain the integrity of the virtual address space.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/API/Failures/ARM.lhs CONTEXT ARM_HYP_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/ARM.lhs CONTEXT ARM_HYP_H bodies_only\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Initialization and Management: The ASID pool is initialized with a function array where each element is set to `Nothing`, and the loading and updating of the ASID pool object are handled using default methods. This ensures that the ASID pool is consistently managed and updated in the kernel.",
    "input": "",
    "output": "instantiation ARM_HYP_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pde updateObject_pde\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Define and Share Architecture-Specific Data Types: Establish common, architecture-specific data types that are utilized across both the specification and the abstract model, ensuring consistency and reusability in the system's formalization.",
    "input": "",
    "output": "(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Main Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_HYP_H ONLY ArmVSpaceRegionUse\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup and Validation: Ensures that the size of a mapping is valid by checking that it does not exceed the maximum object size allowed in the system.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/ARM.lhs CONTEXT ARM_HYP_H bodies_only ArchInv=ArchRetypeDecls_H.ARM_HYP ArchLabels=ArchInvocationLabels_H.ARM_HYP NOT checkPDAt checkPTAt checkPDASIDMapMembership checkValidMappingSize vptrFromPPtr\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert\n    (\\<lambda>s. 2 ^ pageBitsForSize sz <= gsMaxObjectSize s) []\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural TCB Operations: Define and implement architecture-specific operations for managing thread control blocks, including getting and setting thread state, ensuring that the TCB is correctly managed according to the architectural requirements.",
    "input": "",
    "output": "theory ArchTCB_H\nimports TCBDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/ARM.lhs RegisterSet= CONTEXT ARM_HYP_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Base Calculation: Compute the base address of a page given a word and a virtual memory page size, ensuring that the calculation adheres to more constrained specifications.",
    "input": "",
    "output": "consts'\npageBase :: \"('a :: len word) \\<Rightarrow> vmpage_size \\<Rightarrow> 'a word\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Canonical Address Assertion: Ensures that a given machine word is considered a valid canonical address, with the assertion always evaluating to true.",
    "input": "",
    "output": "definition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Canonical Address Assertion: The canonical address assertion is always true, indicating that the address is considered valid or canonical on all architectures.",
    "input": "",
    "output": "definition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific System Call Labels: Define a set of labels for architecture-specific system calls, providing a standardized way to identify and handle different types of system calls in the ARM architecture.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_HYP_H ONLY ArchInvocationLabel\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Invocation Label Requalification: Ensures that the invocation labels are requalified within the architecture-specific context, maintaining consistency and correctness for architecture-dependent operations.",
    "input": "",
    "output": "arch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_HYP_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Register Set Initialization: Defines a new user context with all registers initialized to zero.",
    "input": "",
    "output": "chapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext ((K 0) aLU initContext)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Handling: Defines the structure and behavior of fault handlers for the ARM architecture, including the declaration and implementation of fault-related functions and data structures. This ensures that the system can effectively manage and respond to various types of faults, maintaining system stability and reliability.",
    "input": "",
    "output": "chapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/ARM.lhs\n\n#INCLUDE_HASKELL SEL4/API/Faults/ARM.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/ARM.lhs bodies_only\n\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Structures: Define and instantiate the architectural-specific structures and objects for the ARM hypervisor, including ASID pools and TCBs, to support the execution and management of virtualized environments.",
    "input": "",
    "output": "theory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H decls_only NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H instanceproofs NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H bodies_only NOT makeVCPUObject",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create VCPU Object: Defines the creation of a VCPU object with default values for its components, including an uninitialized TCB pointer, a VGIC interface with specific register values, a set of initial CPU registers, a function indicating that no VPPIMasked bits are set, and a virtual timer initialized to zero.",
    "input": "",
    "output": "defs makeVCPUObject_def:\n\"makeVCPUObject \\<equiv>\n    VCPUObj_ \\<lparr>\n          vcpuTCBPtr= Nothing\n        , vcpuVGIC= VGICInterface_ \\<lparr>\n                          vgicHCR= vgicHCREN\n                        , vgicVMCR= 0\n                        , vgicAPR= 0\n                        , vgicLR= (\\<lambda>_. 0)\n                        \\<rparr>\n        , vcpuRegs= funArray (const 0)  aLU  [(VCPURegSCTLR, sctlrDefault)\n                                             ,(VCPURegACTLR, actlrDefault)]\n        , vcpuVPPIMasked= (\\<lambda>_. False)\n        , vcpuVTimer= VirtTimer 0\n        \\<rparr>\"\n\ndatatype arch_kernel_object_type =\n    PDET\n  | PTET\n  | VCPUT\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPDE e) = PDET\"\n| \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOVCPU e) = VCPUT\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Requalification of vCPU: The system requalifies the vCPU type, ensuring that it meets the necessary architectural requirements. This process is specific to certain architectures and cannot be generalized due to variations in vCPU implementations across different architectures.",
    "input": "",
    "output": "arch_requalify_types (H)\n  vcpu\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Constants and Type Definitions: Defines architectural constants, type conversions, and a null pointer for machine words, ensuring consistency and proper handling of memory addresses and pointers in the system.",
    "input": "",
    "output": "arch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=ARM_HYP CONTEXT ARM_HYP_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Interrupt Controller: Set the IRQ state to reserved for the maintenance of the virtual generic interrupt controller (VGIC).",
    "input": "",
    "output": "theory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/ARM.lhs Arch= CONTEXT ARM_HYP_H bodies_only ArchInv= NOT initInterruptController\n\ndefinition initInterruptController :: \"unit kernel\"\n  where \"initInterruptController \\<equiv> (do\n    setIRQState IRQReserved $ irqVGICMaintenance;\n    return ()\nod)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retyping Objects: Allows the transformation of an object's type, enabling the modification of its structure and capabilities to fit different roles or requirements within the system.",
    "input": "",
    "output": "chapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  VCPU_H\n  KI_Decls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/ARM.lhs CONTEXT ARM_HYP_H Arch.Types= ArchInv= bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs bodies_only CONTEXT ARM_HYP_H NOT isPDFlushLabel isPageFlushLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create New Capabilities: Generate new capabilities for different types of objects such as pages, tables, directories, and VCPUs. The process involves creating the objects, updating the kernel state to reflect the new objects, cleaning the cache, and initializing mappings if necessary. This ensures that the system can manage and utilize these new capabilities effectively.",
    "input": "",
    "output": "chapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewPageCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        when (\\<not>dev) $\n          mapM_x (\\<lambda>addr. doMachineOp $\n                            cleanCacheRange_RAM addr\n                                                (addr + mask (pageBitsForSize pSize))\n                                                (addrFromPPtr addr)) addrs;\n        return $ map (\\<lambda>n. PageCap dev (PPtr (fromPPtr n)) VMReadWrite pSize Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      mapM_x (\\<lambda>addr. doMachineOp $\n                       cleanCacheRange_PoU addr (addr + mask tableBits) (addrFromPPtr addr)) addrs;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 0 ARMSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 4 ARMLargePage\n        | SectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 9 ARMSection\n        | SuperSectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 13 ARMSuperSection\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        | PageDirectoryObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdBits (makeObject::pde) PageDirectoryCap\n              (\\<lambda>pds. do objSize \\<leftarrow> return (((1::nat) `~shiftL~` pdBits));\n                        mapM_x copyGlobalMappings pds\n                     od)\n        | VCPUObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject :: vcpu)) 0;\n            return $ map (\\<lambda>addr. VCPUCap addr) addrs\n            od)\n        )\"\n\nend\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Management: Defines the architecture-specific thread management for ARM, including thread creation, scheduling, and state transitions, ensuring that threads are managed efficiently and in compliance with the ARM architecture.",
    "input": "",
    "output": "chapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT ARM_HYP_H ARMHardware=ARM_HYP bodies_only\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Invocation Labels: Define and identify specific invocation labels for architecture-specific operations, such as page directory flush and page flush, to ensure proper handling and execution of these operations within the ARM architecture.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs CONTEXT ARM_HYP_H ONLY isPDFlushLabel isPageFlushLabel\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace and VCPU Management: Provides functions for managing virtual CPUs, including updating, saving, restoring, enabling, and disabling VCPU states, as well as handling virtual interrupts and timer operations. These functions ensure that the VCPU state is correctly maintained and managed, supporting efficient and reliable virtualization.",
    "input": "",
    "output": "(*\n  VSpace lookup code.\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  FaultHandlerDecls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/VCPU/ARM.lhs CONTEXT ARM_HYP_H decls_only ONLY countTrailingZeros irqVPPIEventIndex\n#INCLUDE_HASKELL SEL4/Object/VCPU/ARM.lhs CONTEXT ARM_HYP_H bodies_only ONLY countTrailingZeros irqVPPIEventIndex\n\n#INCLUDE_HASKELL SEL4/Object/VCPU/ARM.lhs CONTEXT ARM_HYP_H ArchInv=Arch ONLY vcpuUpdate vgicUpdate vgicUpdateLR vcpuSaveReg vcpuRestoreReg vcpuSaveRegRange vcpuRestoreRegRange vcpuWriteReg vcpuReadReg saveVirtTimer restoreVirtTimer vcpuDisable vcpuEnable vcpuRestore armvVCPUSave vcpuSave vcpuSwitch vcpuInvalidateActive vcpuCleanInvalidateActive virqSetEOIIRQEN vgicMaintenance vppiEvent\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_HYP_H decls_only\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_HYP_H bodies_only\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Interrupt Declarations: Define and import architectural-specific interrupt handling declarations for the ARM architecture, ensuring that the system can manage and respond to interrupts according to the ARM architecture's requirements.",
    "input": "",
    "output": "theory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/ARM.lhs CONTEXT Arch decls_only ArchInv=\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware Abstraction: Provides a comprehensive set of hardware-specific operations and configurations for ARM architecture, including memory management, interrupt handling, timer configuration, cache operations, and virtualization support. These operations ensure efficient and secure interaction with the underlying hardware, facilitating tasks such as memory manipulation, interrupt control, and virtual machine management.",
    "input": "",
    "output": "theory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs Platform=Platform.ARM_HYP CONTEXT ARM_HYP_H NOT getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory writeTTBR0 setGlobalPD  setTTBCR setHardwareASID invalidateLocalTLB invalidateLocalTLB_ASID invalidateLocalTLB_VAASID cleanByVA cleanByVA_PoU invalidateByVA invalidateByVA_I invalidate_I_PoU cleanInvalByVA branchFlush clean_D_PoU cleanInvalidate_D_PoC cleanInvalidate_D_PoU cleanInvalidateL2Range invalidateL2Range cleanL2Range isb dsb dmb getIFSR getDFSR getFAR HardwareASID wordFromPDE wordFromPTE VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize toPAddr paddrBase pptrBase pptrTop paddrTop kernelELFPAddrBase kernelELFBase kernelELFBaseOffset pptrBaseOffset cacheLineBits cacheLine lineStart cacheRangeOp cleanCacheRange_PoC cleanInvalidateCacheRange_RAM cleanCacheRange_RAM cleanCacheRange_PoU invalidateCacheRange_RAM invalidateCacheRange_I branchFlushRange cleanCaches_PoU cleanInvalidateL1Caches addrFromPPtr ptrFromPAddr addrFromKPPtr initIRQController MachineData hapFromVMRights wordsFromPDE wordsFromPTE writeContextIDAndPD hcrVCPU hcrNative vgicHCREN sctlrDefault actlrDefault gicVCPUMaxNumLR getHSR setHCR getHDFAR addressTranslateS1 getSCTLR setSCTLR getACTLR setACTLR get_gic_vcpu_ctrl_hcr set_gic_vcpu_ctrl_hcr get_gic_vcpu_ctrl_vmcr set_gic_vcpu_ctrl_vmcr get_gic_vcpu_ctrl_apr set_gic_vcpu_ctrl_apr get_gic_vcpu_ctrl_vtr get_gic_vcpu_ctrl_eisr0 get_gic_vcpu_ctrl_eisr1 get_gic_vcpu_ctrl_misr get_gic_vcpu_ctrl_lr set_gic_vcpu_ctrl_lr setCurrentPDPL2 readVCPUHardwareReg setIRQTrigger writeVCPUHardwareReg getTPIDRURO setTPIDRURO get_cntv_cval_64 set_cntv_cval_64 set_cntv_off_64 get_cntv_off_64 read_cntpct\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_HYP_H instanceproofs NOT HardwareASID VMFaultType HypFaultType VMPageSize\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_HYP_H ONLY hapFromVMRights wordsFromPDE wordsFromPTE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Value: Defines the maximum value for an interrupt request (IRQ) in the system, which is specified by the Kernel_Config.",
    "input": "",
    "output": "abbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Kernel_Config.maxIRQ\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IRQ Controller: The system initializes the IRQ controller using the ARM/ARM_HYP machine operation, ensuring proper setup and configuration for interrupt handling.",
    "input": "",
    "output": "abbreviation (input) initIRQController where\n  \"initIRQController \\<equiv> ARM_HYP.initIRQController\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Management: Defines the structure and operations for managing the ARM machine state, including the ability to get and set register values, and create new context states.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM decls_only NOT UserContext UserMonad Word getRegister setRegister newContext",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State: Defines the architecture-specific state, including register sets for the ARM architecture, ensuring that the system maintains and manages the necessary hardware state information.",
    "input": "",
    "output": "end\n\narch_requalify_types register\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM instanceproofs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Representation: Defines the structure and contents of the ARM machine state, including the register set, to provide a formal model for the state of the ARM architecture within the system.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM bodies_only NOT getRegister setRegister newContext",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Abstraction: The machine state is left underspecified, with only the existence and some interface functions declared, without detailing the transformations or effects on the machine.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exclusive Monitors State: The state of exclusive monitors is represented as a combination of a list of boolean values indexed by 32-bit words and a function that maps a pair of a 32-bit word and a natural number to a boolean value, making it observable in user mode.",
    "input": "",
    "output": "type_synonym exclusive_monitors = \"(word32 \\<Rightarrow> bool) list \\<times> (word32 \\<times> nat \\<Rightarrow> bool)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State: The machine state includes observable and underspecified components. Observable parts consist of the interrupt controller's IRQ masking status, the machine's memory, and the device state. The memory is further divided into kernel memory, which is maintained in a more abstract datatype, and user memory, which is reflected in the underlying machine memory. Additionally, the state includes exclusive monitors and other unspecified aspects encapsulated in the machine state rest.",
    "input": "",
    "output": "end\n\nqualify ARM (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"ARM.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  device_state :: \"word32 \\<Rightarrow> word8 option\"\n  exclusive_state :: ARM.exclusive_monitors\n  machine_state_rest :: ARM.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> ARM.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall> n. irq_oracle n <= Kernel_Config.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Monad: Defines a monad for operations on the machine state, enabling nondeterministic actions and transformations within the context of the ARM architecture.",
    "input": "",
    "output": "type_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c ARM.machine_monad\" <= (type) \"(ARM.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Masking: After kernel initialization, all IRQs are masked to prevent interruptions.",
    "input": "",
    "output": "definition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Memory State: The user-visible memory is initialized with all contents set to 0.",
    "input": "",
    "output": "definition\n  init_underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Exclusive State: The initial state of the exclusive monitors is set to a constant value, which is the same as the default value used by clearExMonitor.",
    "input": "",
    "output": "consts' default_exclusive_state :: exclusive_monitors",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Machine State: Defines the initial state of the machine, including interrupt masks, interrupt state, underlying memory, device state, and exclusive state, while leaving the unspecified parts of the machine state undefined.",
    "input": "",
    "output": "definition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         exclusive_state = default_exclusive_state,\n                         machine_state_rest = undefined \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definitions: Define and requalify types for hardware ASID, virtual machine fault types, virtual machine page sizes, and hypervisor fault types. These definitions ensure that the system can accurately represent and manage hardware-specific attributes and fault conditions in the ARM architecture.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM ONLY HardwareASID VMFaultType VMPageSize HypFaultType pageBits pageBitsForSize\n\nend\n\narch_requalify_types vmpage_size\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM instanceproofs ONLY HardwareASID VMFaultType VMPageSize HypFaultType\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Management: Defines the structure and manipulation of the x86-64 machine state, including the ability to get and set register values, and create new context states. This ensures that the system can effectively manage and interact with the hardware registers and contexts, maintaining the integrity and performance of the machine operations.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/X64.lhs CONTEXT X64 decls_only NOT UserContext UserMonad Word getRegister setRegister newContext",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State: Defines the architecture-specific machine state, including registers and GDT slots, for the x86-64 platform. This ensures that the system maintains the correct state and context for executing and managing processes on x86-64 hardware.",
    "input": "",
    "output": "end\n\narch_requalify_types register gdtslot\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/X64.lhs CONTEXT X64 instanceproofs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definition: Defines the structure and management of the x86-64 machine state, including the register set and context, to ensure proper handling and manipulation of the CPU state.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/X64.lhs CONTEXT X64 bodies_only NOT getRegister setRegister newContext",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definition: Defines the machine state with components including IRQ masks, IRQ state, underlying memory, and device state, along with an underspecified rest of the machine state. This structure allows for the declaration of interface functions without detailing the transformations or effects on the machine.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\nend\n\nqualify X64 (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"X64.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"word64 \\<Rightarrow> word8\"\n  device_state :: \"word64 \\<Rightarrow> word8 option\"\n  machine_state_rest :: X64.machine_state_rest\n\nconsts irq_oracle :: \"nat \\<Rightarrow> word8\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Monad Operations: Define operations on the machine state using a monad that allows for non-deterministic computations, enabling flexible and robust handling of system-level operations.",
    "input": "",
    "output": "type_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c X64.machine_monad\" <= (type) \"(X64.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Masking: After kernel initialization, all IRQs are masked to prevent interruptions during the initial setup phase.",
    "input": "",
    "output": "definition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Memory State: The user-visible memory is initialized to 0, ensuring a known and consistent starting state for the system.",
    "input": "",
    "output": "definition\n  init_underlying_memory :: \"word64 \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Machine State: The machine state is initialized with specific values for interrupt masks, interrupt state, underlying memory, and an empty device state. The remaining part of the machine state is left undefined, allowing for flexibility in specifying additional details as needed.",
    "input": "",
    "output": "definition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         machine_state_rest = undefined \\<rparr>\"\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64 ONLY VMFaultType HypFaultType VMPageSize VMMapType pageBits ptTranslationBits pageBitsForSize\n\nend\n\narch_requalify_types vmpage_size vmmap_type\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64 instanceproofs ONLY VMFaultType HypFaultType VMPageSize VMMapType\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Management: Defines the structure and manipulation of the RISCV64 machine state, including the ability to get and set register values, and create new contexts. This ensures that the machine state is correctly maintained and updated, supporting the execution and management of threads in the system.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/RISCV64.hs CONTEXT RISCV64 decls_only NOT UserContext UserMonad Word getRegister setRegister newContext",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV 64-bit Machine State: Defines the architecture-specific machine state, including the register set, for the RISCV64 architecture, ensuring that the system can correctly manage and manipulate the processor's state.",
    "input": "",
    "output": "end\n\narch_requalify_types register\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/RISCV64.hs CONTEXT RISCV64 instanceproofs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definition: Defines the structure and management of the RISCV64 machine state, including the register set and context, to ensure proper handling and manipulation of processor state.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/RISCV64.hs CONTEXT RISCV64 bodies_only NOT getRegister setRegister newContext",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definition: The machine state includes IRQ masks, IRQ state, underlying memory, and device state, along with additional unspecified machine state. The IRQ masks indicate which interrupts are enabled or disabled, the IRQ state holds the current interrupt state, the underlying memory maps addresses to byte values, and the device state maps addresses to optional byte values. The `irq_oracle` function provides a mapping from natural numbers to IRQ identifiers, ensuring that the generated IRQ does not exceed the maximum IRQ value.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\nend\n\nqualify RISCV64 (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"RISCV64.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"machine_word \\<Rightarrow> word8\"\n  device_state :: \"machine_word \\<Rightarrow> word8 option\"\n  machine_state_rest :: RISCV64.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> RISCV64.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall>n. irq_oracle n <= RISCV64.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Monad: Defines a monad for performing operations on the machine state, enabling nondeterministic computations and state transformations within the RISCV64 architecture.",
    "input": "",
    "output": "type_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c RISCV64.machine_monad\" <= (type) \"(RISCV64.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Masking: After kernel initialization, all interrupts (IRQs) are masked to prevent them from being processed until the system is fully set up.",
    "input": "",
    "output": "definition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Memory State: The user-visible memory is initialized to 0 for all addresses.",
    "input": "",
    "output": "definition\n  init_underlying_memory :: \"machine_word \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Machine State: Defines the initial state of the machine, including IRQ masks, IRQ state, underlying memory, and an empty device state. The remaining parts of the machine state are left unspecified.",
    "input": "",
    "output": "definition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         machine_state_rest = undefined \\<rparr>\"\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64 ONLY VMFaultType HypFaultType vmFaultTypeFSR VMPageSize pageBits ptTranslationBits pageBitsForSize\n\nend\n\narch_requalify_types vmpage_size\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64 instanceproofs ONLY VMFaultType HypFaultType VMPageSize\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Management: Defines the structure and operations for managing the AARCH64 machine state, including handling virtual performance monitoring interrupts (VPPI) and virtual timers. This ensures that the system can effectively manage and interact with hardware-specific features, maintaining the integrity and performance of the system.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/AARCH64.hs CONTEXT AARCH64 decls_only NOT UserContext UserMonad Word getRegister setRegister newContext FPUState newFPUState\n\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64 ONLY VPPIEventIRQ VirtTimer",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definitions: Define and requalify types for AARCH64 architecture, including registers, virtual CPU registers, virtual PPI event IRQs, and virtual timers. This ensures that the machine state is accurately represented and manipulated within the AARCH64 context.",
    "input": "",
    "output": "end\n\narch_requalify_types register vcpureg vppievent_irq virt_timer\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/AARCH64.hs CONTEXT AARCH64 instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64 instanceproofs ONLY VPPIEventIRQ VirtTimer",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Management: Defines the structure and operations for managing the AARCH64 machine state, including the register set and FPU state, ensuring that the system can correctly handle and manipulate the state of the processor.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/AARCH64.hs CONTEXT AARCH64 bodies_only NOT getRegister setRegister newContext newFPUState",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definition: Defines the machine state with components including IRQ masks, IRQ state, underlying memory, device state, and an underspecified rest of the machine state. The IRQ oracle function maps natural numbers to IRQ identifiers, ensuring that the mapped IRQs do not exceed the maximum IRQ value.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\nend\n\nqualify AARCH64 (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"AARCH64.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"machine_word \\<Rightarrow> word8\"\n  device_state :: \"machine_word \\<Rightarrow> word8 option\"\n  machine_state_rest :: AARCH64.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> AARCH64.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall>n. irq_oracle n <= Kernel_Config.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Monad: Represents operations on the machine state, encapsulating non-deterministic behaviors and effects on the system's hardware state.",
    "input": "",
    "output": "type_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c AARCH64.machine_monad\" <= (type) \"(AARCH64.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IRQ Masks: After kernel initialization, all IRQs are masked to prevent any interruptions until the system is fully set up.",
    "input": "",
    "output": "definition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Memory State: The user-visible memory is initialized with all contents set to 0.",
    "input": "",
    "output": "definition\n  init_underlying_memory :: \"machine_word \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Machine State: The machine state is initialized with specific values for IRQ masks, IRQ state, underlying memory, and an empty device state, while the remaining part of the machine state is left undefined.",
    "input": "",
    "output": "definition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         machine_state_rest = undefined \\<rparr>\"\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs CONTEXT AARCH64 ONLY \\\n  PT_Type \\\n  VMFaultType HypFaultType vmFaultTypeFSR VMPageSize pageBits ptTranslationBits \\\n  pageBitsForSize \\\n  hcrCommon hcrTWE hcrTWI \\\n  hcrVCPU hcrNative vgicHCREN sctlrDefault sctlrEL1VM actlrDefault gicVCPUMaxNumLR \\\n  vcpuBits\n\nend\n\narch_requalify_types vmpage_size\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs CONTEXT AARCH64 instanceproofs ONLY VMFaultType HypFaultType VMPageSize\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Management: Defines and manages the machine state for ARM_HYP, including handling virtual timer and VPP event IRQs, as well as providing operations to get and set registers in the context of the ARM_HYP architecture.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP decls_only NOT UserContext UserMonad Word getRegister setRegister newContext\n\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP ONLY VPPIEventIRQ VirtTimer",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definitions: Define and requalify types for machine state components such as registers, virtual CPU registers, virtual PPI event IRQs, and virtual timers, ensuring proper handling and management of these components in the ARM_HYP architecture.",
    "input": "",
    "output": "end\n\narch_requalify_types register vcpureg vppievent_irq virt_timer\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP instanceproofs ONLY VPPIEventIRQ VirtTimer",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Management: Define and manage the machine state for ARM_HYP, including the register set, to ensure proper handling and manipulation of the processor's state.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP bodies_only NOT getRegister setRegister newContext",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Underspecification: The machine state is largely underspecified, with only the existence of certain interface functions declared, without detailing the state transformations or their effects on the machine.",
    "input": "",
    "output": "text \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exclusive Monitors State: The state of exclusive monitors is represented as a combination of a list of functions that map word32 to boolean values and a function that maps a pair of word32 and natural number to a boolean value. This state is observable in user mode, allowing for the tracking and management of exclusive monitor operations.",
    "input": "",
    "output": "type_synonym exclusive_monitors = \"(word32 \\<Rightarrow> bool) list \\<times> (word32 \\<times> nat \\<Rightarrow> bool)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Composition: The machine state consists of observable and underspecified components. Observable parts include the interrupt controller's IRQ masking, the machine's memory, and device state, while the underspecified part encompasses the remaining state. The memory is further divided into kernel memory, which is maintained in a more abstract datatype, and user memory, which is reflected in the underlying machine memory.",
    "input": "",
    "output": "end\n\nqualify ARM_HYP (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"ARM_HYP.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  device_state :: \"word32 \\<Rightarrow> word8 option\"\n  exclusive_state :: ARM_HYP.exclusive_monitors\n  machine_state_rest :: ARM_HYP.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> ARM_HYP.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall> n. irq_oracle n <= Kernel_Config.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Monad Operations: Define a monad for performing operations on the machine state, allowing for nondeterministic computations and state transformations.",
    "input": "",
    "output": "type_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c ARM_HYP.machine_monad\" <= (type) \"(ARM_HYP.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Mask Initialization: After kernel initialization, all IRQs are masked to prevent interruptions.",
    "input": "",
    "output": "definition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Memory State: The user-visible memory is initialized to 0, ensuring a known and consistent starting state for the system.",
    "input": "",
    "output": "definition\n  init_underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Exclusive State: The initial state of the exclusive monitors is set to a constant value, which is the same value used by the clearExMonitor function.",
    "input": "",
    "output": "consts' default_exclusive_state :: exclusive_monitors",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Machine State: The machine state is initialized with predefined values for interrupt masks, interrupt state, underlying memory, and device state, while leaving the remaining unspecified parts of the machine state undefined.",
    "input": "",
    "output": "definition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         exclusive_state = default_exclusive_state,\n                         machine_state_rest = undefined \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Definitions: Define and requalify types related to hardware ASIDs, VM fault types, hypervisor fault types, VM page sizes, and other hardware-specific configurations. These definitions ensure that the system can accurately represent and manage the state of ARM_HYP machine hardware.",
    "input": "",
    "output": "#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_HYP ONLY HardwareASID VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize hcrCommon hcrTWE hcrTWI hcrVCPU hcrNative vgicHCREN sctlrDefault actlrDefault gicVCPUMaxNumLR\n\nend\n\narch_requalify_types vmpage_size\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_HYP instanceproofs ONLY HardwareASID VMFaultType HypFaultType VMPageSize\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Intent Extraction: Extract specific types of intents from a generic intent, such as CNode, TCB, IRQ control, IRQ handler, ASID pool, ASID control, page, page table, page directory, untyped, and domain intents. This allows for the precise handling and processing of different intent types in the system.",
    "input": "",
    "output": "theory Decode_D\nimports\n  Asid_D\n  CNode_D\n  Interrupt_D\n  PageTable_D\n  Tcb_D\n  Untyped_D\nbegin\n\ndefinition\n  get_cnode_intent :: \"cdl_intent \\<Rightarrow> cdl_cnode_intent option\"\nwhere\n  \"get_cnode_intent intent \\<equiv>\n    case intent of\n        CNodeIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_tcb_intent :: \"cdl_intent \\<Rightarrow> cdl_tcb_intent option\"\nwhere\n  \"get_tcb_intent intent \\<equiv>\n    case intent of\n        TcbIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_irq_control_intent :: \"cdl_intent \\<Rightarrow> cdl_irq_control_intent option\"\nwhere\n  \"get_irq_control_intent intent \\<equiv>\n    case intent of\n        IrqControlIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_irq_handler_intent :: \"cdl_intent \\<Rightarrow> cdl_irq_handler_intent option\"\nwhere\n  \"get_irq_handler_intent intent \\<equiv>\n    case intent of\n        IrqHandlerIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_asid_pool_intent :: \"cdl_intent \\<Rightarrow> cdl_asid_pool_intent option\"\nwhere\n  \"get_asid_pool_intent intent \\<equiv>\n    case intent of\n        AsidPoolIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\n\ndefinition\n  get_asid_control_intent :: \"cdl_intent \\<Rightarrow> cdl_asid_control_intent option\"\nwhere\n  \"get_asid_control_intent intent \\<equiv>\n    case intent of\n        AsidControlIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_page_intent :: \"cdl_intent \\<Rightarrow> cdl_page_intent option\"\nwhere\n  \"get_page_intent intent \\<equiv>\n    case intent of\n        PageIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_page_table_intent :: \"cdl_intent \\<Rightarrow> cdl_page_table_intent option\"\nwhere\n  \"get_page_table_intent intent \\<equiv>\n    case intent of\n        PageTableIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_page_directory_intent :: \"cdl_intent \\<Rightarrow> cdl_page_directory_intent option\"\nwhere\n  \"get_page_directory_intent intent \\<equiv>\n    case intent of\n        PageDirectoryIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_untyped_intent :: \"cdl_intent \\<Rightarrow> cdl_untyped_intent option\"\nwhere\n  \"get_untyped_intent intent \\<equiv>\n    case intent of\n        UntypedIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_domain_intent :: \"cdl_intent \\<Rightarrow> cdl_domain_intent option\"\nwhere\n  \"get_domain_intent intent \\<equiv>\n     case intent of\n         DomainIntent x \\<Rightarrow> Some x\n       | _ \\<Rightarrow> None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode and Validate Intent: Decode the given intent into an appropriate invocation based on the type of capability. For endpoint-like capabilities, perform a specific operation regardless of the user's intent. For other capabilities, validate that the user's intent matches the capability type before proceeding with the corresponding invocation. If the intent does not match or the capability type is unsupported, the operation is aborted.",
    "input": "",
    "output": "definition\n  decode_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_intent \\<Rightarrow> cdl_invocation except_monad\"\nwhere\n  \"decode_invocation invoked_cap invoked_cap_ref caps intent \\<equiv>\n    case invoked_cap of\n       \\<comment> \\<open>For endpoint-like caps, we always perform an operation,\n          regardless of the user's actual intent.\\<close>\n         EndpointCap o_id badge rights \\<Rightarrow>\n           (if Write \\<in> rights then\n             returnOk $ InvokeEndpoint (SyncMessage badge (Grant \\<in> rights) (GrantReply \\<in> rights) o_id)\n           else\n             throw)\n       | NotificationCap o_id badge rights \\<Rightarrow>\n           (if Write \\<in> rights then\n             returnOk $ InvokeNotification (Signal badge o_id)\n           else\n             throw)\n       | ReplyCap o_id rights \\<Rightarrow>\n           returnOk $ InvokeReply (ReplyMessage o_id invoked_cap_ref (Grant \\<in> rights))\n\n       \\<comment> \\<open>\n         For other operations, we only perform the user's intent\n         if it matches up with the cap.\n        \n         Note that this does not currently match the current\n         implementation: instead, the user's message will be\n         decoded into a new (undefined) intent for what the\n         cap happened to be. I propose modifying labels used to\n         avoid overlaps between different items so that we can\n         recognise when the user is invoking the wrong item.\n       \\<close>\n       | CNodeCap _ _ _ _ \\<Rightarrow>\n           doE\n             cnode_intent \\<leftarrow> throw_opt undefined $ get_cnode_intent intent;\n             liftME InvokeCNode $ decode_cnode_invocation invoked_cap invoked_cap_ref caps cnode_intent\n           odE\n       | TcbCap _ \\<Rightarrow>\n           doE\n             tcb_intent \\<leftarrow> throw_opt undefined $ get_tcb_intent intent;\n             liftME InvokeTcb $ decode_tcb_invocation invoked_cap invoked_cap_ref caps tcb_intent\n           odE\n       | IrqControlCap \\<Rightarrow>\n           doE\n             irq_control_intent \\<leftarrow> throw_opt undefined $ get_irq_control_intent intent;\n             liftME InvokeIrqControl $ decode_irq_control_invocation\n                 invoked_cap invoked_cap_ref caps irq_control_intent\n           odE\n       | IrqHandlerCap _ \\<Rightarrow>\n           doE\n             irq_handler_intent \\<leftarrow> throw_opt undefined $ get_irq_handler_intent intent;\n             liftME InvokeIrqHandler $ decode_irq_handler_invocation\n                 invoked_cap invoked_cap_ref caps irq_handler_intent\n           odE\n       | AsidPoolCap _ _\\<Rightarrow>\n           doE\n             asid_pool_intent \\<leftarrow> throw_opt undefined $ get_asid_pool_intent intent;\n             liftME InvokeAsidPool $ decode_asid_pool_invocation\n                 invoked_cap invoked_cap_ref caps asid_pool_intent\n           odE\n       | AsidControlCap \\<Rightarrow>\n           doE\n             asid_control_intent \\<leftarrow> throw_opt undefined $ get_asid_control_intent intent;\n             liftME InvokeAsidControl $ decode_asid_control_invocation\n                 invoked_cap invoked_cap_ref caps asid_control_intent\n           odE\n       | UntypedCap _ _ _ \\<Rightarrow>\n           doE\n             untyped_intent \\<leftarrow> throw_opt undefined $ get_untyped_intent intent;\n             liftME InvokeUntyped $ decode_untyped_invocation\n                 invoked_cap invoked_cap_ref caps untyped_intent\n           odE\n       | FrameCap _ _ _ _ _ _ \\<Rightarrow>\n           doE\n             page_intent \\<leftarrow> throw_opt undefined $ get_page_intent intent;\n             liftME InvokePage $ decode_page_invocation\n                 invoked_cap invoked_cap_ref caps page_intent\n           odE\n       | PageTableCap _ _ _ \\<Rightarrow>\n           doE\n             page_table_intent \\<leftarrow> throw_opt undefined $ get_page_table_intent intent;\n             liftME InvokePageTable $ decode_page_table_invocation\n                 invoked_cap invoked_cap_ref caps page_table_intent\n           odE\n       | PageDirectoryCap _ _ _ \\<Rightarrow>\n          doE\n             page_directory_intent \\<leftarrow> throw_opt undefined $ get_page_directory_intent intent;\n             liftME InvokePageDirectory $ decode_page_directory_invocation\n                 invoked_cap invoked_cap_ref caps page_directory_intent\n           odE\n       | DomainCap \\<Rightarrow>\n          doE\n            domain_intent \\<leftarrow> throw_opt undefined $ get_domain_intent intent;\n            liftME InvokeDomain $ decode_domain_invocation caps domain_intent\n          odE\n\n       \\<comment> \\<open>Don't support operations on other types of caps.\\<close>\n       | _ \\<Rightarrow> throw\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Control and Pool Management: Manage ASID pools and their assignments, including creating new ASID pools from untyped memory regions and assigning page directories to ASID pools. Ensures that the ASID table is updated and the appropriate capabilities are inserted and modified, maintaining the integrity of the address space and memory management.",
    "input": "",
    "output": "(*\n * Operations on page table objects and frames.\n *)\n\ntheory Asid_D\nimports\n  Invocations_D\n  CSpace_D\n  Untyped_D\nbegin\n\ndefinition\n  decode_asid_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_asid_control_intent \\<Rightarrow> cdl_asid_control_invocation except_monad\"\nwhere\n  \"decode_asid_control_invocation target target_ref caps intent \\<equiv> case intent of\n     AsidControlMakePoolIntent index depth \\<Rightarrow>\n       doE\n         base \\<leftarrow> liftE $ select {x. x < 2 ^ asid_high_bits};\n\n         \\<comment> \\<open>Fetch the untyped item, and ensure it is valid.\\<close>\n         (untyped_cap, untyped_cap_ref) \\<leftarrow> throw_on_none $ get_index caps 0;\n         (case untyped_cap of\n             UntypedCap _ s _ \\<Rightarrow> returnOk ()\n           | _ \\<Rightarrow> throw);\n         ensure_no_children untyped_cap_ref;\n\n         \\<comment> \\<open>Fetch the slot we plan to put the generated cap into.\\<close>\n         (cspace_cap, _) \\<leftarrow> throw_on_none $ get_index caps 1;\n         target_slot \\<leftarrow> lookup_slot_for_cnode_op cspace_cap index (unat depth);\n         ensure_empty target_slot;\n\n         returnOk $ MakePool (set_available_range untyped_cap {}) untyped_cap_ref\n           (cap_objects untyped_cap) target_slot base\n       odE \\<sqinter> throw\"\n\ndefinition\n  decode_asid_pool_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_asid_pool_intent \\<Rightarrow> cdl_asid_pool_invocation except_monad\"\nwhere\n  \"decode_asid_pool_invocation target target_ref caps intent \\<equiv> case intent of\n     AsidPoolAssignIntent \\<Rightarrow>\n       doE\n         (pd_cap, pd_cap_ref) \\<leftarrow> throw_on_none $ get_index caps 0;\n         (case pd_cap of\n             PageDirectoryCap _ _ _ \\<Rightarrow> returnOk ()\n           | _ \\<Rightarrow> throw);\n\n         base \\<leftarrow> (case target of\n             AsidPoolCap p base \\<Rightarrow> returnOk $ base\n           | _ \\<Rightarrow> throw);\n         offset \\<leftarrow> liftE $ select {x. x < 2 ^ asid_low_bits};\n         returnOk $ Assign (base, offset) pd_cap_ref (cap_object target, offset)\n       odE \\<sqinter> throw\"\n\ndefinition\n  invoke_asid_control :: \"cdl_asid_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_asid_control params \\<equiv>\n    case params of\n        MakePool untyped_cap untyped_cap_ref untyped_covers target_slot base \\<Rightarrow>\n          do\n            \\<comment> \\<open>Untype the region. A choice may be made about whether to detype\n               objects with Untyped addresses.\\<close>\n            modify (detype untyped_covers);\n            set_cap untyped_cap_ref untyped_cap;\n            targets \\<leftarrow> generate_object_ids 1 AsidPoolType untyped_covers;\n\n            \\<comment> \\<open>Retype the region.\\<close>\n            retype_region 0 AsidPoolType targets;\n            assert (targets \\<noteq> []);\n\n            \\<comment> \\<open>Insert the cap.\\<close>\n            frame \\<leftarrow> return $ pick (hd targets);\n            insert_cap_child (AsidPoolCap frame base) untyped_cap_ref target_slot;\n\n            \\<comment> \\<open>Update the asid table.\\<close>\n            asid_table \\<leftarrow> gets cdl_asid_table;\n            asid_table' \\<leftarrow> return $ asid_table (base \\<mapsto> AsidPoolCap frame 0);\n            modify (\\<lambda>s. s \\<lparr>cdl_asid_table := asid_table'\\<rparr>)\n\n          od\"\n\ndefinition\n  invoke_asid_pool :: \"cdl_asid_pool_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_asid_pool params \\<equiv>\n     case params of\n       Assign asid pd_cap_ref ap_target_slot \\<Rightarrow> do\n         pd_cap \\<leftarrow> get_cap pd_cap_ref;\n         case pd_cap of\n           PageDirectoryCap pd_id _ _ \\<Rightarrow> do\n             set_cap pd_cap_ref (PageDirectoryCap pd_id Real (Some asid));\n             set_cap ap_target_slot (PageDirectoryCap pd_id Fake None)\n           od\n         | _ \\<Rightarrow> fail\n       od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Untyped Memory Object Operations: Decode untyped memory object invocations to retype the untyped memory into a specified type and size, ensuring that the target slots are available and empty. The operation checks if the target is a CNode cap and determines the available names based on whether the untyped memory has children.",
    "input": "",
    "output": "(*\n * Operations on untyped memory objects.\n *)\n\ntheory Untyped_D\nimports Invocations_D CSpace_D\nbegin\n\ndefinition\n  decode_untyped_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_untyped_intent \\<Rightarrow> cdl_untyped_invocation except_monad\"\nwhere\n  \"decode_untyped_invocation untyped_cap untyped_ref caps intent \\<equiv> case intent of\n     UntypedRetypeIntent type size_bits node_index node_depth node_offset node_window \\<Rightarrow>\n       doE\n         (root_cap, root_slot) \\<leftarrow> throw_on_none $ get_index caps 0;\n\n         \\<comment> \\<open>Lookup the destination slots.\\<close>\n         target_node \\<leftarrow> if node_depth = 0 then\n             returnOk root_cap\n           else\n             doE\n               target_slot \\<leftarrow> lookup_slot_for_cnode_op root_cap node_index (unat node_depth);\n               liftE $ get_cap target_slot\n             odE;\n\n         \\<comment> \\<open>Ensure it is a CNode cap.\\<close>\n         unlessE (is_cnode_cap target_node) throw;\n\n         \\<comment> \\<open>Find our target slots.\\<close>\n         slots \\<leftarrow> returnOk $ map (\\<lambda>n. (cap_object target_node, n))\n               [unat node_offset ..< unat node_offset + unat node_window];\n         mapME_x ensure_empty slots;\n\n         \\<comment> \\<open>Work out what names are available. If we haven't haven't already been typed into something we can reuse our names.\\<close>\n         s \\<leftarrow> liftE $ get;\n         has_kids \\<leftarrow> returnOk $ has_children untyped_ref s;\n\n         returnOk $ Retype untyped_ref type (unat size_bits) slots has_kids (unat node_window)\n       odE \\<sqinter> throw\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Zero Out Addresses: Set a specified set of addresses to an untyped state, effectively zeroing out the corresponding objects in the system.",
    "input": "",
    "output": "definition\n  detype :: \"cdl_object_id set \\<Rightarrow> cdl_state \\<Rightarrow> cdl_state\"\nwhere\n  \"detype detype_set s \\<equiv>\n     (s\\<lparr> cdl_objects :=\n         (\\<lambda>x. if x \\<in> detype_set then\n           Some Untyped\n         else cdl_objects s x)\\<rparr>)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Generate and Create Objects: Generate a list of unique object IDs within a specified range, ensuring that the IDs are distinct and do not overlap. If the target object type is not Untyped, each set in the list is converted to a single object ID. The generated IDs are then used to create new objects of the specified type, updating the system state with the new objects.",
    "input": "",
    "output": "definition\n  generate_object_ids :: \"nat \\<Rightarrow> cdl_object_type \\<Rightarrow> cdl_object_id set \\<Rightarrow>  ((cdl_object_id set) list) k_monad\"\n  where \"generate_object_ids num_objects type object_range\n  \\<equiv> do\n    s \\<leftarrow> get;\n    available_names \\<leftarrow> return $ (cdl_objects s) -` {Some Untyped};\n    setlist \\<leftarrow> select {x. distinct  x \\<and> (\\<forall>a\\<in> set x. \\<forall>b \\<in> set x. a \\<noteq> b \\<longrightarrow> a \\<inter> b = {})\n           \\<and> (\\<forall>y \\<in> set x. y \\<noteq> {} \\<and> y \\<subseteq> object_range \\<inter> available_names)\n           \\<and> (num_objects = (size x)) };\n    if (type \\<noteq> UntypedType) then (return $ map (\\<lambda>x. {pick x}) setlist)\n    else return setlist\n    od\"\n\ndefinition create_objects :: \"(cdl_object_id set) list \\<Rightarrow> cdl_object option \\<Rightarrow> unit k_monad\"\nwhere\n  \"create_objects target_object_ids object \\<equiv>\n    (modify (\\<lambda>s. s\\<lparr>cdl_objects := (\\<lambda>x.\n     if {x} \\<in> set target_object_ids then\n      object\n     else\n      cdl_objects s x)\\<rparr>))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create and Update Capabilities: Create new capabilities for objects, set their default properties, and update the available range for untyped capabilities. This ensures that new objects are properly initialized and integrated into the system, while maintaining the integrity of the available object ranges.",
    "input": "",
    "output": "definition\n  create_cap :: \"cdl_object_type \\<Rightarrow> nat \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool \\<Rightarrow> (cdl_cap_ref \\<times> cdl_object_id set) \\<Rightarrow> unit k_monad\"\nwhere\n  \"create_cap new_type sz parent_slot dev \\<equiv> \\<lambda>(dest_slot, obj_refs).\n  do\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_cap dest_slot (default_cap new_type obj_refs sz dev);\n    set_parent dest_slot parent_slot\n  od\"\n\n\ndefinition\n  update_available_range :: \"(cdl_object_id set) => (cdl_object_id list) \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere \"update_available_range orange newids cap_ref cap \\<equiv>\n  do\n     new_range  \\<leftarrow> select {x. x \\<subseteq> orange - set newids};\n     set_cap cap_ref $ set_available_range cap new_range\n  od\"\n\n\ndefinition\n  retype_region :: \"nat \\<Rightarrow> cdl_object_type \\<Rightarrow> (cdl_object_id set list)\n  \\<Rightarrow> ((cdl_object_id set) list) k_monad\"\nwhere\n  \"retype_region target_bits target_type target_object_ids \\<equiv>\n    do\n      \\<comment> \\<open>Get a list of target locations. We are happy with any unused name\n         within the target range.\\<close>\n\n      if (target_type \\<noteq> UntypedType) then\n       do\n         current_domain \\<leftarrow> gets cdl_current_domain;\n         create_objects target_object_ids (default_object target_type target_bits current_domain)\n       od\n      else return ();\n\n      \\<comment> \\<open>Get a list of target locations. We are happy with any unused name\n         within the target range.\\<close>\n      return target_object_ids\n    od\"\n\nprimrec (nonexhaustive)\n  untyped_is_device :: \"cdl_cap \\<Rightarrow> bool\"\nwhere\n    \"untyped_is_device (UntypedCap d _ _) = d\"\n\ndefinition\n  reset_untyped_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"reset_untyped_cap cref \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap cref;\n    whenE (available_range cap \\<noteq> cap_objects cap) $ doE\n      liftE $ modify (detype (cap_objects cap));\n      new_rans \\<leftarrow> liftE $ select {xs. (\\<forall>S \\<in> set xs.\n              S \\<subseteq> cap_objects cap \\<and> available_range cap \\<subset> S)\n          \\<and> xs \\<noteq> [] \\<and> List.last xs = cap_objects cap};\n      mapME_x (\\<lambda>r. doE\n        liftE $ set_cap cref $ set_available_range cap r;\n        returnOk () \\<sqinter> throw\n      odE) new_rans\n    odE\n  odE\"\n\ndefinition\n  invoke_untyped :: \"cdl_untyped_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_untyped params \\<equiv> case params of\n     Retype untyped_ref new_type type_size target_slots has_kids num_objects \\<Rightarrow>\n   doE\n     unlessE has_kids $ reset_untyped_cap untyped_ref;\n       liftE $ do\n         untyped_cap \\<leftarrow> get_cap untyped_ref;\n\n         new_range \\<leftarrow> return $ available_range untyped_cap;\n         new_obj_refs \\<leftarrow> generate_object_ids num_objects new_type new_range;\n\n         update_available_range new_range (map (\\<lambda>s. pick s) new_obj_refs) untyped_ref untyped_cap;\n\n         \\<comment> \\<open>Construct new objects within the covered range.\\<close>\n         retype_region type_size new_type new_obj_refs;\n\n         \\<comment> \\<open>Construct caps for the new objects.\\<close>\n         mapM_x (create_cap new_type type_size untyped_ref (untyped_is_device untyped_cap)) (zip target_slots new_obj_refs);\n\n         \\<comment> \\<open>Ideally, we should return back to the user how many\n            objects were created.\\<close>\n\n         return ()\n       od\n    odE\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "User Intents: Define the semantics of operations that users aim to perform, abstracting away the specific encoding in message registers. These intents correspond one-to-one with user-space invocations and are used to separate the data part of an invocation from the capabilities required for the operation.",
    "input": "",
    "output": "(*\n * This file contains user \"intents\".\n *\n * Such intents attempt to capture the semantics of an operation the\n * user is attempting to perform, without having to worry about how the\n * operation is actually encoded within their message registers.\n *\n * There is a one-to-one mapping between the following intents and the\n * invocations made available to userspace. There is not quite\n * a one-to-one mapping between these intents and the invocations listed\n * in Invocations_D, as some of these intents are multiplexed onto\n * a single invocation when being validated.\n *\n * Caps required by the intents are not stored in the intent themselves,\n * but passed seperately in when required. In some sense, the Intent\n * is the \"data\" part of an invocation, but not the \"caps\" part of it.\n *)\n\ntheory Intents_D\nimports\n  \"ASpec.CapRights_A\"\n  ExecSpec.Platform\nbegin\n\ncontext begin interpretation Arch .\nrequalify_types irq\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Entities have specific rights to kernel objects, which determine the permissible interactions and operations they can perform on those objects.",
    "input": "",
    "output": "type_synonym cdl_right = rights",
    "system": "",
    "history": []
  },
  {
    "instruction": "User Capability Pointer: Defines a 32-bit word as a user capability pointer (cdl_cptr) and establishes abbreviations for different rights, including Read, Write, Grant, and GrantReply, to simplify the specification of access permissions.",
    "input": "",
    "output": "type_synonym cdl_cptr = word32\n\nabbreviation (input) Read ::rights\n  where \"Read \\<equiv> AllowRead\"\n\nabbreviation (input) Write::rights\n  where \"Write \\<equiv> AllowWrite\"\n\nabbreviation (input) Grant::rights\n  where \"Grant \\<equiv> AllowGrant\"\n\nabbreviation (input) GrantReply::rights\n  where \"GrantReply \\<equiv> AllowGrantReply\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Data Representation: Represents capability data, such as guard information, using a 32-bit word.",
    "input": "",
    "output": "type_synonym cdl_raw_capdata = word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "VM Attributes Definition: Defines VM attributes, such as page cache attributes, using a 32-bit word.",
    "input": "",
    "output": "type_synonym cdl_raw_vmattrs = word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Register Operations: Allow writing to a thread's registers using a list of 32-bit words, enabling the modification of the thread's execution context.",
    "input": "",
    "output": "type_synonym cdl_raw_usercontext = \"word32 list\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Object Types: Defines a set of distinct object types within the kernel, including endpoints, notifications, threads (TCBs), capability nodes, interrupt request nodes, untyped memory, address space identifier pools, page tables, page directories, and frames with specified sizes.",
    "input": "",
    "output": "datatype cdl_object_type =\n    EndpointType\n  | NotificationType\n  | TcbType\n  | CNodeType\n  | IRQNodeType\n  | UntypedType\n  | AsidPoolType\n  | PageTableType\n  | PageDirectoryType\n  | FrameType nat (* size in bits of desired page *)\n\ndatatype cdl_cnode_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Copy CNode Capabilities: Copy capabilities from a source CNode to a destination CNode, specifying the target, destination index, destination depth, source root, source index, and source depth, along with the rights to be applied to the copied capabilities.",
    "input": "",
    "output": "CNodeCopyIntent word32 word32 word32 word32 \"cdl_right set\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Mint Intent: Specifies the intent to mint a new capability in a CNode, including details such as the target CNode, destination index and depth, source root, source index and depth, rights, and badge. This ensures that the new capability is correctly created and placed within the specified CNode, with the appropriate permissions and metadata.",
    "input": "",
    "output": "|  CNodeMintIntent word32 word32 word32 word32 \"cdl_right set\" cdl_raw_capdata",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Move Intent: Specifies the movement of a capability within or between CNodes, defined by the target CNode, destination index and depth, source root CNode, and source index and depth.",
    "input": "",
    "output": "|  CNodeMoveIntent word32 word32 word32 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Mutation: Allows modification of a capability within a CNode by specifying the target, destination index, and depth, as well as the source root, source index, and depth, along with a badge. This ensures that capabilities can be updated or moved within the CNode structure, maintaining the integrity and flexibility of the capability system.",
    "input": "",
    "output": "|  CNodeMutateIntent word32 word32 word32 word32 cdl_raw_capdata",
    "system": "",
    "history": []
  },
  {
    "instruction": "Revoke Capability: Revokes a capability at a specified index and depth within a CNode, ensuring that the targeted capability is removed and no longer accessible.",
    "input": "",
    "output": "|  CNodeRevokeIntent word32 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Deletion: Allows the deletion of a capability at a specified index and depth within a CNode, ensuring that the targeted capability is removed from the system.",
    "input": "",
    "output": "|  CNodeDeleteIntent word32 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Save Caller Intent: Store the caller's intent in a CNode, specified by the target, index, and depth. This ensures that the caller's context is preserved for later retrieval or use.",
    "input": "",
    "output": "|  CNodeSaveCallerIntent word32 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel Badged Sends: Allows the cancellation of sends to a specific CNode based on a badge, index, and depth. This ensures that any pending badged sends to the specified CNode are invalidated, maintaining the integrity and security of the communication channels.",
    "input": "",
    "output": "|  CNodeCancelBadgedSendsIntent word32 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Rotation: Allows the rotation of capabilities within a CNode, specifying the target, destination index and depth, pivot root with its index and depth, and source root with its index and depth. This operation facilitates the reorganization of capabilities within the CNode structure, ensuring that the system can dynamically adjust to changing requirements while maintaining the integrity of the capability hierarchy.",
    "input": "",
    "output": "|  CNodeRotateIntent word32 word32 word32 word32 cdl_raw_capdata word32 word32 cdl_raw_capdata\n\ndatatype cdl_tcb_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Read Thread Registers: Retrieve a specified number of register values from the target thread, optionally suspending the source thread before reading. The operation respects architectural flags and ensures the integrity of the register data.",
    "input": "",
    "output": "TcbReadRegistersIntent bool word8 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "WriteRegisters: Allows writing a specified number of register values to the target thread's context, with an option to resume the target thread after the operation. The operation ensures that the register values are correctly set and sanitized, and it triggers a reschedule if the target thread is the current thread.",
    "input": "",
    "output": "|  TcbWriteRegistersIntent bool word8 word32 cdl_raw_usercontext",
    "system": "",
    "history": []
  },
  {
    "instruction": "CopyRegisters Intent: Defines the intent for copying registers between threads, including options to suspend the source thread, resume the target thread, and specify which sets of registers (frame or integer) to transfer.",
    "input": "",
    "output": "|  TcbCopyRegistersIntent bool bool bool bool word8",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Suspension: Allows a thread to request the suspension of another specified target thread.",
    "input": "",
    "output": "|  TcbSuspendIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "Resume Intent: Allows a thread to express the intention to resume another specified thread, enabling the resumption of the target thread's execution.",
    "input": "",
    "output": "|  TcbResumeIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Configuration: Allows the configuration of a target thread by updating its fault endpoint, CSpace root, VSpace root, and IPC buffer. The configuration ensures that the thread's capabilities and memory spaces are properly set up, enhancing the thread's operational integrity and security.",
    "input": "",
    "output": "|  TcbConfigureIntent cdl_cptr cdl_raw_capdata cdl_raw_capdata word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Thread Maximum Priority: Allows setting the maximum priority of a thread. This ensures that the thread's scheduling priority is appropriately managed, maintaining system stability and performance.",
    "input": "",
    "output": "|  TcbSetMCPriorityIntent word8",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Thread Priority: Adjust the priority of a specified thread. This action updates the thread's scheduling priority, ensuring that the thread's execution is managed according to the new priority level.",
    "input": "",
    "output": "|  TcbSetPriorityIntent word8",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Scheduling Parameters: Allows setting the scheduling parameters, including maximum priority and current priority, for a target thread. This ensures that the thread's scheduling behavior is updated according to the specified parameters, maintaining the integrity and efficiency of the system's scheduling.",
    "input": "",
    "output": "|  TcbSetSchedParamsIntent word8 word8",
    "system": "",
    "history": []
  },
  {
    "instruction": "SetIPCBuffer: Allows setting the IPC buffer for a thread, optionally including a buffer frame. This ensures that the thread can correctly handle IPC messages with associated data and capabilities.",
    "input": "",
    "output": "|  TcbSetIPCBufferIntent word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Space Configuration: Allows the configuration of a thread's control space (CSpace) and virtual space (VSpace) roots, along with a fault endpoint. This ensures that the thread's memory and capability management structures are properly set up, enabling effective resource handling and error management.",
    "input": "",
    "output": "|  TcbSetSpaceIntent word32 cdl_raw_capdata cdl_raw_capdata",
    "system": "",
    "history": []
  },
  {
    "instruction": "Bind Notification: Associates a thread with a notification, allowing the thread to receive notifications.",
    "input": "",
    "output": "|  TcbBindNTFNIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unbind Notification: Unbinds a notification from the target thread, removing the association between the thread and the notification.",
    "input": "",
    "output": "|  TcbUnbindNTFNIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set TLS Base: Allows setting the Thread Local Storage (TLS) base for a specified thread, ensuring that the thread's TLS base register is updated. If the thread being updated is the current thread, a reschedule is required to apply the changes.",
    "input": "",
    "output": "|  TcbSetTLSBaseIntent\n\ndatatype cdl_untyped_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retype Intent: Specifies the intent to retype an untyped object, including the target object, reset action, type of the new object, size in bits, root CNode, node index, node depth, node offset, node window, and whether it has children.",
    "input": "",
    "output": "UntypedRetypeIntent cdl_object_type word32 word32 word32 word32 word32\n\ndatatype cdl_irq_handler_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Acknowledge Interrupt Handler: The system acknowledges the handling of an interrupt, indicating that the specified interrupt handler has completed its execution.",
    "input": "",
    "output": "IrqHandlerAckIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Endpoint: Assigns a specified endpoint to a target, establishing the target's association with the endpoint for interrupt handling.",
    "input": "",
    "output": "|  IrqHandlerSetEndpointIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Interrupt Handler Intent: Clears the intent associated with an interrupt handler, ensuring that any pending or specified actions are removed or reset.",
    "input": "",
    "output": "|  IrqHandlerClearIntent\n\ndatatype cdl_arch_irq_control_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "ArchIssueIrqHandler: Configures an interrupt handler for a specified target, IRQ, and root, with the given index and depth, allowing for precise control over interrupt handling.",
    "input": "",
    "output": "ARMIrqControlIssueIrqHandlerIntent irq word32 word32\n\ndatatype cdl_irq_control_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Issue IRQ Handler: Configures an interrupt request (IRQ) handler for a specified target, setting the root, index, and depth parameters to manage the IRQ handling process.",
    "input": "",
    "output": "IrqControlIssueIrqHandlerIntent irq word32 word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Control: Manage the issuance of interrupt handler intents, allowing for the configuration and control of interrupt handling mechanisms within the system.",
    "input": "",
    "output": "|  ArchIrqControlIssueIrqHandlerIntent cdl_arch_irq_control_intent\n\ndatatype cdl_page_table_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Intent: Represents the intention to map or unmap a page in the page table, specifying the target, page directory, virtual address, and attributes for mapping, or the intent to unmap a page.",
    "input": "",
    "output": "PageTableMapIntent word32 cdl_raw_vmattrs\n |  PageTableUnmapIntent\n\ndatatype cdl_page_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Map Page Intent: Defines the intent to map a page with specified rights and attributes at a given virtual address, using the provided target and page directory.",
    "input": "",
    "output": "PageMapIntent word32 \"cdl_right set\" cdl_raw_vmattrs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page: Remove a page from the specified target's address space, ensuring that the memory is no longer accessible and freeing up the associated resources.",
    "input": "",
    "output": "|  PageUnmapIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "FlushCaches: Initiates a cache flush operation for the specified target, ensuring that the data in the cache is synchronized with the main memory.",
    "input": "",
    "output": "|  PageFlushCachesIntent",
    "system": "",
    "history": []
  },
  {
    "instruction": "GetAddress: Retrieves the address associated with a specific page or page directory, based on the intent provided.",
    "input": "",
    "output": "| PageGetAddressIntent\n\n\ndatatype cdl_page_directory_intent =\n   PageDirectoryFlushIntent\n | PageDirectoryNothingIntent\n\ndatatype cdl_asid_control_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create ASID Pool: Generate an ASID pool with specified parameters, including target, untyped memory, root, index, and depth, to manage address space identifiers effectively.",
    "input": "",
    "output": "AsidControlMakePoolIntent word32 word32\n\ndatatype cdl_asid_pool_intent =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Assign ASID Pool and VRoot: Allows the assignment of an ASID pool and a virtual root to a target, enabling the management and configuration of memory and virtual address spaces for the target.",
    "input": "",
    "output": "AsidPoolAssignIntent\n\ndatatype cdl_notification_intent =\n    SendSignalIntent word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "Intent Representation: Defines a structured representation for various types of system intents, including operations on CNodes, TCBS, untyped objects, IRQ handlers and controls, page tables, pages, page directories, ASID controls, ASID pools, notifications, endpoints, and domains. Each intent can optionally include an error flag, a capability pointer, extra capability pointers, and a receive slot. This structure allows for the encapsulation of complex operations and their associated data, facilitating the management and execution of system-level actions.",
    "input": "",
    "output": "datatype cdl_endpoint_intent =\n    SendMessageIntent \"cdl_cptr list\"\n\ndatatype cdl_domain_intent = DomainSetIntent word8\n\ndatatype cdl_intent =\n    CNodeIntent cdl_cnode_intent\n  | TcbIntent cdl_tcb_intent\n  | UntypedIntent cdl_untyped_intent\n  | IrqHandlerIntent cdl_irq_handler_intent\n  | IrqControlIntent cdl_irq_control_intent\n  | PageTableIntent cdl_page_table_intent\n  | PageIntent cdl_page_intent\n  | PageDirectoryIntent cdl_page_directory_intent\n  | AsidControlIntent cdl_asid_control_intent\n  | AsidPoolIntent cdl_asid_pool_intent\n  | NotificationIntent cdl_notification_intent\n  | EndpointIntent cdl_endpoint_intent\n  | DomainIntent cdl_domain_intent\n\nrecord cdl_full_intent =\n  cdl_intent_op        :: \"cdl_intent option\"\n  cdl_intent_error     :: bool\n  cdl_intent_cap       :: cdl_cptr\n  cdl_intent_extras    :: \"cdl_cptr list\"\n  cdl_intent_recv_slot :: \"(cdl_cptr \\<times> word32 \\<times> nat) option\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Control Block Invocations: Allows for various operations on thread control blocks, including reading and writing registers, suspending and resuming threads, copying registers between threads, configuring thread settings (fault endpoints, cspace and vspace roots, IPC buffers), modifying thread priorities, and managing notifications and TLS base. These operations ensure that threads can be effectively managed and controlled, maintaining the system's integrity and performance.",
    "input": "",
    "output": "(*\n * Operations on thread control blocks.\n *)\n\ntheory Tcb_D\nimports Invocations_D CSpace_D\nbegin\n\ndefinition cdl_update_cnode_cap_data :: \"cdl_cap \\<Rightarrow> word32 \\<Rightarrow> cdl_cap\"\nwhere \"cdl_update_cnode_cap_data cap data  \\<equiv>\n  case cap of cdl_cap.CNodeCap oid _ _ sz \\<Rightarrow> if data\\<noteq>0 then\n    (let reserved_bits = 3; guard_bits = 18; guard_size_bits = 5; new_guard_size = unat ((data >> reserved_bits) && mask guard_size_bits);\n        new_guard =\n          (data >> reserved_bits + guard_size_bits) && mask (min (unat ((data >> reserved_bits) && mask guard_size_bits)) guard_bits)\n    in CNodeCap oid new_guard new_guard_size sz)\n    else cap\n  | _ \\<Rightarrow> cap\"\n\ndefinition cdl_same_arch_obj_as :: \"cdl_cap \\<Rightarrow> cdl_cap \\<Rightarrow> bool\"\nwhere \"cdl_same_arch_obj_as capa capb \\<equiv>\n  case capa of AsidPoolCap x _ \\<Rightarrow> (\n        case capb of AsidPoolCap y _ \\<Rightarrow>  y = x\n        | _ \\<Rightarrow> False)\n  | AsidControlCap \\<Rightarrow> (\n       case capb of AsidControlCap \\<Rightarrow> True\n        | _ \\<Rightarrow> False)\n  | FrameCap dev ra _ sa _ _ \\<Rightarrow> (\n       case capb of FrameCap dev' rb _ sb _ _ \\<Rightarrow> rb = ra \\<and> sb = sa \\<and> dev = dev'\n        | _ \\<Rightarrow> False)\n  | cdl_cap.PageTableCap a _ _ \\<Rightarrow> (\n       case capb of cdl_cap.PageTableCap b _ _ \\<Rightarrow> b = a\n        | _ \\<Rightarrow> False)\n  | cdl_cap.PageDirectoryCap a _ _ \\<Rightarrow> (\n       case capb of cdl_cap.PageDirectoryCap b _ _ \\<Rightarrow> b = a\n        | _ \\<Rightarrow> False)\n  | _ \\<Rightarrow> False\"\n\ndefinition\n  decode_tcb_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_tcb_intent \\<Rightarrow> cdl_tcb_invocation except_monad\"\nwhere\n  \"decode_tcb_invocation target slot caps intent \\<equiv> case intent of\n       \\<comment> \\<open>Read another thread's registers.\\<close>\n       TcbReadRegistersIntent suspend flags count \\<Rightarrow>\n         returnOk (ReadRegisters (cap_object target) suspend 0 0) \\<sqinter> throw\n\n       \\<comment> \\<open>Write another thread's registers.\\<close>\n     | TcbWriteRegistersIntent resume flags count regs \\<Rightarrow>\n         returnOk (WriteRegisters (cap_object target) resume [0] 0) \\<sqinter> throw\n\n       \\<comment> \\<open>Copy registers from one thread to another.\\<close>\n     | TcbCopyRegistersIntent suspend_source resume_target f1 f2 f3 \\<Rightarrow>\n         doE\n           (source_cap, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           source_tcb \\<leftarrow> (\n              case source_cap of\n                  TcbCap x \\<Rightarrow> returnOk x\n                | _ \\<Rightarrow> throw);\n           target_tcb \\<leftarrow> returnOk $ cap_object target;\n           returnOk (CopyRegisters target_tcb source_tcb suspend_source resume_target f1 f2 0)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Suspend the target thread.\\<close>\n     | TcbSuspendIntent \\<Rightarrow>\n         returnOk (Suspend (cap_object target)) \\<sqinter> throw\n\n       \\<comment> \\<open>Resume the target thread.\\<close>\n     | TcbResumeIntent \\<Rightarrow>\n         returnOk (Resume (cap_object target)) \\<sqinter> throw\n\n       \\<comment> \\<open>Configure: target, fault_ep, mcp, priority, cspace_root_data, vspace_root_data, buffer\\<close>\n     | TcbConfigureIntent fault_ep cspace_root_data vspace_root_data buffer \\<Rightarrow>\n         doE\n           cspace_root \\<leftarrow> throw_on_none $ get_index caps 0;\n           vspace_root \\<leftarrow> throw_on_none $ get_index caps 1;\n           buffer_frame \\<leftarrow> throw_on_none $ get_index caps 2;\n           cspace_root_cap_ref \\<leftarrow> returnOk $ (cdl_update_cnode_cap_data (fst cspace_root) cspace_root_data,snd cspace_root);\n           vspace_root_cap_ref \\<leftarrow> returnOk $ vspace_root;\n           buffer_frame_opt \\<leftarrow> returnOk $ (if (buffer \\<noteq> 0) then Some (reset_mem_mapping (fst buffer_frame), snd buffer_frame) else None);\n           returnOk (ThreadControl (cap_object target) slot (Some fault_ep)\n               (Some cspace_root_cap_ref) (Some vspace_root_cap_ref) (buffer_frame_opt))\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Modify a thread's maximum control priority.\\<close>\n     | TcbSetMCPriorityIntent mcp \\<Rightarrow>\n         doE\n           auth_cap \\<leftarrow> throw_on_none $ get_index caps 0;\n           returnOk (ThreadControl (cap_object target) slot None None None None)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Modify a thread's priority.\\<close>\n     | TcbSetPriorityIntent priority \\<Rightarrow>\n         doE\n           auth_cap \\<leftarrow> throw_on_none $ get_index caps 0;\n           returnOk (ThreadControl (cap_object target) slot None None None None)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Modify a thread's mcp and priority at the same time.\\<close>\n     | TcbSetSchedParamsIntent mcp priority \\<Rightarrow>\n         doE\n           auth_cap \\<leftarrow> throw_on_none $ get_index caps 0;\n           returnOk (ThreadControl (cap_object target) slot None None None None)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Modify a thread's IPC buffer.\\<close>\n     | TcbSetIPCBufferIntent buffer \\<Rightarrow>\n         doE\n           buffer_frame \\<leftarrow> throw_on_none $ get_index caps 0;\n           buffer_frame_opt \\<leftarrow> returnOk $ (if (buffer \\<noteq> 0) then Some (reset_mem_mapping (fst buffer_frame), snd buffer_frame) else None);\n           returnOk (ThreadControl (cap_object target) slot None None None buffer_frame_opt)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Update the various spaces (CSpace/VSpace) of a thread.\\<close>\n     | TcbSetSpaceIntent fault_ep cspace_root_data vspace_root_data \\<Rightarrow>\n         doE\n           cspace_root \\<leftarrow> throw_on_none $ get_index caps 0;\n           vspace_root \\<leftarrow> throw_on_none $ get_index caps 1;\n           cspace_root_cap_ref \\<leftarrow> returnOk $ (cdl_update_cnode_cap_data (fst cspace_root) cspace_root_data,snd cspace_root);\n           vspace_root_cap_ref \\<leftarrow> returnOk $ vspace_root;\n           returnOk (ThreadControl (cap_object target) slot (Some fault_ep)\n               (Some cspace_root_cap_ref) (Some vspace_root_cap_ref) None)\n        odE \\<sqinter> throw\n     | TcbBindNTFNIntent \\<Rightarrow> doE\n           (ntfn_cap, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           returnOk (NotificationControl (cap_object target) (Some (cap_object ntfn_cap)))\n         odE \\<sqinter> throw\n     | TcbUnbindNTFNIntent \\<Rightarrow> returnOk (NotificationControl (cap_object target) None) \\<sqinter> throw\n     | TCBSetTLSBaseIntent \\<Rightarrow> returnOk (SetTLSBase (cap_object target)) \\<sqinter> throw\n  \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Empty TCB Slot: Deletes the specified slot of a TCB if it is not a null capability, ensuring that the slot is cleared and the associated resources are freed.",
    "input": "",
    "output": "definition\n  tcb_empty_thread_slot :: \"cdl_object_id \\<Rightarrow> cdl_cnode_index \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_empty_thread_slot target_tcb target_slot \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap (target_tcb,target_slot);\n    whenE (cap \\<noteq> NullCap) $\n      delete_cap  (target_tcb, target_slot)\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update TCB Slot: Update a specified slot of a TCB with a new capability, and delete the previous capability in that slot. This ensures that the TCB's capabilities are correctly managed and updated.",
    "input": "",
    "output": "definition\n  tcb_update_thread_slot :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cnode_index \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_thread_slot target_tcb tcb_cap_slot target_slot pcap \\<equiv>\n         liftE (do\n           thread_cap \\<leftarrow> get_cap tcb_cap_slot;\n           when (thread_cap = TcbCap target_tcb)\n           (insert_cap_child (fst pcap) (snd pcap) (target_tcb, target_slot)\n            \\<sqinter> insert_cap_sibling (fst pcap) (snd pcap) (target_tcb,target_slot))\n         od)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update CSpace Root: Update a thread's CSpace root by emptying the existing CSpace slot and, if the new capability is a valid CNode, inserting the new CSpace root into the thread's CSpace slot.",
    "input": "",
    "output": "definition\n  tcb_update_cspace_root :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap \\<times> cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_cspace_root target_tcb tcb_cap_ref croot \\<equiv>\n  doE\n     tcb_empty_thread_slot target_tcb tcb_cspace_slot;\n     src_cap \\<leftarrow> liftE $ get_cap (snd croot);\n     whenE (is_cnode_cap src_cap \\<and> (cap_object src_cap = cap_object (fst croot)))\n       $ tcb_update_thread_slot target_tcb tcb_cap_ref tcb_cspace_slot croot\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update VSpace Root: Updates the virtual space root of a target thread by first emptying the existing VSpace slot, then retrieving and validating the new VSpace capability, and finally updating the thread's VSpace slot with the new capability.",
    "input": "",
    "output": "definition\n  tcb_update_vspace_root :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_vspace_root target_tcb tcb_cap_ref vroot \\<equiv>\n  doE\n     tcb_empty_thread_slot target_tcb tcb_vspace_slot;\n     src_cap \\<leftarrow> liftE $ get_cap (snd vroot);\n     whenE (cdl_same_arch_obj_as (fst vroot) src_cap)\n       $ tcb_update_thread_slot target_tcb tcb_cap_ref tcb_vspace_slot vroot\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Modify TCB Intent Error: Update the TCB's intent to indicate whether an error occurred during decode. This ensures that the TCB's state accurately reflects the outcome of the decoding process.",
    "input": "",
    "output": "definition\n  mark_tcb_intent_error :: \"cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"mark_tcb_intent_error target_tcb has_error \\<equiv>\n      update_thread target_tcb (\\<lambda>t. (t\\<lparr>cdl_tcb_intent := (cdl_tcb_intent t)\\<lparr>cdl_intent_error := has_error\\<rparr>\\<rparr>))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update IPC Buffer: Updates a thread's IPC buffer by first emptying the existing slot, corrupting the TCB intent, and then updating the thread slot with the new IPC buffer if the source capability is from the same architectural object.",
    "input": "",
    "output": "definition\n  tcb_update_ipc_buffer :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_ipc_buffer target_tcb tcb_cap_ref ipc_buffer \\<equiv>\n     doE\n       tcb_empty_thread_slot target_tcb tcb_ipcbuffer_slot;\n       liftE $ corrupt_tcb_intent target_tcb;\n       src_cap \\<leftarrow> liftE $ get_cap (snd ipc_buffer);\n       whenE (cdl_same_arch_obj_as (fst ipc_buffer) src_cap)\n         $ tcb_update_thread_slot target_tcb tcb_cap_ref tcb_ipcbuffer_slot ipc_buffer\n     odE\n\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Restart: Resumes a thread, aborts any pending operations, and revokes any incoming reply capabilities. If the thread is not already in a restart or running state, it cancels the current IPC operation, sets the reply capability to a master reply capability, and updates the pending operation to a restart state.",
    "input": "",
    "output": "definition\n  restart :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"restart target_tcb \\<equiv>\n  do\n     cap \\<leftarrow> KHeap_D.get_cap (target_tcb,tcb_pending_op_slot);\n     when (cap \\<noteq> RestartCap \\<and> cap\\<noteq> RunningCap)\n     (do\n       CSpace_D.cancel_ipc target_tcb;\n       KHeap_D.set_cap (target_tcb,tcb_replycap_slot) (cdl_cap.MasterReplyCap target_tcb);\n       KHeap_D.set_cap (target_tcb,tcb_pending_op_slot) (cdl_cap.RestartCap)\n      od)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread and Domain Management: Allows threads to be suspended, resumed, and have their state and capabilities modified. Suspend operations abort any pending operations and revoke incoming reply capabilities, while resume operations restart the thread. Thread control operations can update fault endpoints, CSpace, VSpace, and IPC buffers. Additionally, domain management allows setting the domain of a thread, updating its scheduling and execution context.",
    "input": "",
    "output": "definition\n  suspend :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"suspend target_tcb \\<equiv> CSpace_D.cancel_ipc target_tcb >>= K (KHeap_D.set_cap (target_tcb,tcb_pending_op_slot) cdl_cap.NullCap)\"\n\ndefinition\n  bind_notification :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"bind_notification tcb_id ntfn_id \\<equiv> set_cap (tcb_id, tcb_boundntfn_slot) (BoundNotificationCap ntfn_id)\"\n\ndefinition\n  invoke_tcb :: \"cdl_tcb_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_tcb params \\<equiv> case params of\n    \\<comment> \\<open>Modify a thread's registers.\\<close>\n      WriteRegisters target_tcb resume _ _ \\<Rightarrow>\n        liftE $\n        do\n          corrupt_tcb_intent target_tcb;\n          when resume $ restart target_tcb\n        od\n\n    \\<comment> \\<open>Read a thread's registers.\\<close>\n    | ReadRegisters src_tcb _ _ _ \\<Rightarrow>\n        liftE $ suspend src_tcb \\<sqinter> return ()\n\n    \\<comment> \\<open>Copy registers from one thread to another\\<close>\n    | CopyRegisters target_tcb source_tcb _ _ _ _ _ \\<Rightarrow>\n        liftE $\n        do\n          suspend source_tcb \\<sqinter> return ();\n          restart target_tcb \\<sqinter> return ();\n          corrupt_tcb_intent target_tcb\n       od\n\n    \\<comment> \\<open>Suspend this thread.\\<close>\n    | Suspend target_tcb \\<Rightarrow>\n        liftE $ suspend target_tcb \\<sqinter> return ()\n\n    \\<comment> \\<open>Resume this thread.\\<close>\n    | Resume target_tcb \\<Rightarrow>\n        liftE $ restart target_tcb\n\n    \\<comment> \\<open>Update a thread's options.\\<close>\n    | ThreadControl target_tcb tcb_cap_slot faultep croot vroot ipc_buffer \\<Rightarrow>\n        doE\n          case faultep of\n              Some x \\<Rightarrow> liftE $ update_thread target_tcb (\\<lambda>tcb. tcb\\<lparr>cdl_tcb_fault_endpoint := x\\<rparr>)\n            | None \\<Rightarrow> returnOk ();\n\n          \\<comment> \\<open>Possibly update CSpace\\<close>\n          case croot of\n              Some x \\<Rightarrow> tcb_update_cspace_root target_tcb tcb_cap_slot x\n            | None \\<Rightarrow> returnOk ();\n\n          \\<comment> \\<open>Possibly update VSpace\\<close>\n          case vroot of\n              Some x \\<Rightarrow> tcb_update_vspace_root target_tcb tcb_cap_slot x\n            | None \\<Rightarrow> returnOk ();\n\n          \\<comment> \\<open>Possibly update Ipc Buffer\\<close>\n          case ipc_buffer of\n              Some x \\<Rightarrow> tcb_update_ipc_buffer target_tcb tcb_cap_slot x\n            | None \\<Rightarrow> (returnOk () \\<sqinter> (doE tcb_empty_thread_slot target_tcb tcb_ipcbuffer_slot;\n                 liftE $ corrupt_tcb_intent target_tcb odE))\n        odE\n    | NotificationControl tcb ntfn \\<Rightarrow>\n          liftE $ (case ntfn of\n             Some ntfn_id \\<Rightarrow> bind_notification tcb ntfn_id\n           | None \\<Rightarrow> unbind_notification tcb)\n    | SetTLSBase tcb \\<Rightarrow> liftE $ corrupt_tcb_intent tcb\"\n\n\ndefinition\n  decode_domain_invocation :: \"(cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_domain_intent \\<Rightarrow> cdl_domain_invocation except_monad\"\nwhere\n  \"decode_domain_invocation caps intent \\<equiv> case intent of\n     DomainSetIntent d \\<Rightarrow> returnOk (SetDomain (cap_object (fst (hd caps))) d) \\<sqinter> throw\"\n\ndefinition\n  set_domain :: \"cdl_object_id \\<Rightarrow> word8 \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_domain tcb d \\<equiv> update_thread tcb (\\<lambda>t. (t\\<lparr>cdl_tcb_domain := d \\<rparr>))\"\n\ndefinition\n  invoke_domain :: \"cdl_domain_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_domain params \\<equiv> case params of\n     SetDomain tcb d \\<Rightarrow> liftE $ set_domain tcb d\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Endpoint Operations: Manage and manipulate endpoints, enabling communication and synchronization between threads.",
    "input": "",
    "output": "(*\n * Operations on endpoints.\n *)\n\ntheory Endpoint_D\nimports Invocations_D CSpace_D Tcb_D\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Inject Reply Capability: Inject a reply capability into the target TCB, setting the pending operation and inserting the reply capability with specified permissions.",
    "input": "",
    "output": "definition\n  inject_reply_cap :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"inject_reply_cap src_tcb_id dst_tcb_id can_grant \\<equiv> do\n     set_cap (src_tcb_id, tcb_pending_op_slot) $\n         cdl_cap.PendingSyncRecvCap src_tcb_id True False;\n     insert_cap_child (ReplyCap src_tcb_id (if can_grant then {Grant, Write} else {Write}))\n                      (src_tcb_id, tcb_replycap_slot)\n                      (dst_tcb_id, tcb_caller_slot);\n     return ()\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Determine Receive Slot: Identify and validate the slot for an incoming capability for a specific thread. If the thread's IPC buffer has the necessary read and write permissions, the function locates the appropriate slot in the cspace, ensuring it is empty before returning it.",
    "input": "",
    "output": "definition\n  get_receive_slot :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref option k_monad\"\nwhere\n  \"get_receive_slot thread \\<equiv>\n    do\n      tcb \\<leftarrow> get_thread thread;\n      recv_slot \\<leftarrow> (case (cdl_tcb_caps tcb tcb_ipcbuffer_slot) of (Some (FrameCap _ _ rights _ _ _)) \\<Rightarrow>\n        if (Read \\<in> rights \\<and> Write \\<in> rights)\n          then return (cdl_intent_recv_slot (cdl_tcb_intent tcb))\n        else\n          return None\n      | _ \\<Rightarrow> return None);\n      case ( recv_slot ) of\n          None \\<Rightarrow>\n            return None\n        | Some (croot, index, depth) \\<Rightarrow>\n            doE\n              \\<comment> \\<open>Lookup the slot.\\<close>\n              cspace_root \\<leftarrow> unify_failure $ lookup_cap thread croot;\n              result \\<leftarrow> unify_failure $ lookup_slot_for_cnode_op cspace_root index depth;\n\n              \\<comment> \\<open>Ensure nothing is already in it.\\<close>\n              cap \\<leftarrow> liftE $ get_cap result;\n              whenE (cap \\<noteq> NullCap) throw;\n\n              returnOk $ Some result\n            odE <catch> (\\<lambda>_. return None)\n    od\n  \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve and Validate IPC Buffer: Obtain the IPC buffer for a given thread, ensuring it has the necessary read and write permissions based on the operation context. If the buffer is valid, return its address; otherwise, return none.\n\nCorrupt IPC Buffer or TCB Intent: Depending on the validity and permissions of the IPC buffer, either corrupt the frame associated with the buffer or the TCB intent of the thread. This ensures that the integrity of the IPC mechanism is maintained by invalidating the data in case of an error.",
    "input": "",
    "output": "definition\n  get_send_slots :: \"cdl_object_id \\<Rightarrow> cdl_cptr list k_monad\"\nwhere\n  \"get_send_slots thread \\<equiv>\n    do\n      tcb \\<leftarrow> get_thread thread;\n      return $ cdl_intent_extras (cdl_tcb_intent tcb)\n    od\n  \"\n\ndefinition\n  get_ipc_buffer :: \"cdl_object_id \\<Rightarrow> bool \\<Rightarrow> cdl_object_id option k_monad\"\nwhere\n  \"get_ipc_buffer oid in_receive \\<equiv> do\n    frame_cap \\<leftarrow> get_cap (oid,tcb_ipcbuffer_slot);\n    (case frame_cap of\n        Types_D.FrameCap _ a rights _ _ _ \\<Rightarrow> if (Write \\<in> rights \\<and> Read \\<in> rights) \\<or> (Read\\<in> rights \\<and> \\<not> in_receive)\n          then return (Some a)\n          else return None\n        | _ \\<Rightarrow> return None)\n   od\"\n\ndefinition\n  corrupt_ipc_buffer :: \"cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\n  where\n  \"corrupt_ipc_buffer oid in_receive \\<equiv> do\n    buffer \\<leftarrow> get_ipc_buffer oid in_receive;\n    (case buffer of\n        Some a \\<Rightarrow> corrupt_frame a\n      | None \\<Rightarrow> corrupt_tcb_intent oid)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Transfer Cap and Badges: Transfers at most one capability and a number of endpoint badges. If the capability to be transferred is to the endpoint used in the transfer, it transfers the badge; otherwise, it transfers the capability while updating its rights and inserting it into the destination slot.",
    "input": "",
    "output": "fun\n  transfer_caps_loop :: \"cdl_object_id option \\<Rightarrow> cdl_object_id \\<Rightarrow>\n                         (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_cap_ref option\n                         \\<Rightarrow> unit k_monad\"\nwhere\n  \"transfer_caps_loop ep receiver [] dest = return ()\"\n| \"transfer_caps_loop ep receiver ((cap,slot)#caps) dest =\n      \\<comment> \\<open>Transfer badge, transfer cap, or abort early if more than\n         one cap to transfer\\<close>\n      (if is_ep_cap cap \\<and> ep = Some (cap_object cap)\n      then do\n        \\<comment> \\<open>transfer badge\\<close>\n        corrupt_ipc_buffer receiver True;\n        \\<comment> \\<open>transfer rest of badges or cap\\<close>\n        transfer_caps_loop ep receiver caps dest\n      od\n      else if dest \\<noteq> None then doE\n        new_cap \\<leftarrow> returnOk (update_cap_rights (cap_rights cap - {Write}) cap) \\<sqinter>\n                  returnOk cap;\n\n        \\<comment> \\<open>Target cap is derived. This may abort transfer early.\\<close>\n        target_cap \\<leftarrow> derive_cap slot new_cap;\n        whenE (target_cap = NullCap) throw;\n\n        \\<comment> \\<open>Copy the cap across as either a child or sibling.\\<close>\n        liftE (insert_cap_child target_cap slot (the dest)\n               \\<sqinter> insert_cap_sibling target_cap slot (the dest));\n\n        \\<comment> \\<open>Transfer rest of badges\\<close>\n        liftE $ transfer_caps_loop ep receiver caps None\n      odE <catch> (\\<lambda>_. return ())\n      else\n        return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Transfer: Transfer capabilities from the source to the destination thread, with the actual behavior depending on the specific implementation details. The transfer process may involve nondeterministic outcomes, such as caps not being sent but still consuming the receive slot, or the transfer stopping midway due to faults. Only one destination cap slot is supported, and the new cap may be a sibling or child of the source cap.",
    "input": "",
    "output": "definition\n  transfer_caps :: \"cdl_object_id option \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n                    cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"transfer_caps ep caps sender receiver \\<equiv>\n    do\n      dest_slot \\<leftarrow> get_receive_slot receiver \\<sqinter> return None;\n      transfer_caps_loop ep receiver caps dest_slot\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Notification Reception Waiters: Retrieve the set of threads that are waiting to receive a notification on the specified target. These threads have a pending operation slot indicating they are awaiting a notification from the given target.",
    "input": "",
    "output": "definition\n  get_waiting_ntfn_recv_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_waiting_ntfn_recv_threads target state \\<equiv>\n     {x. \\<exists>a. (cdl_objects state) x = Some (Tcb a) \\<and>\n         (((cdl_tcb_caps a) tcb_pending_op_slot) = Some (PendingNtfnRecvCap target)) }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Waiting Sync Receive Threads: Identify the set of threads that are waiting to receive on a specified synchronization endpoint. This involves checking the state of each thread and determining if it has a pending synchronous receive operation on the given endpoint.",
    "input": "",
    "output": "definition\n  get_waiting_sync_recv_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_waiting_sync_recv_threads target state \\<equiv>\n     {x. \\<exists>a. (cdl_objects state) x = Some (Tcb a) \\<and>\n         (\\<exists>can_grant. (cdl_tcb_caps a) tcb_pending_op_slot = Some (PendingSyncRecvCap target False can_grant)) }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Waiting Sync Send Threads: Identify the set of threads that are waiting to send to a specified synchronization endpoint. These threads have a pending synchronous send operation associated with the target endpoint.",
    "input": "",
    "output": "definition\n  get_waiting_sync_send_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_waiting_sync_send_threads target state \\<equiv>\n     {t. \\<exists>fault a b. (cdl_objects state) t = Some (Tcb a) \\<and>\n         (\\<exists>call can_grant can_grant_reply. (cdl_tcb_caps a) tcb_pending_op_slot =\n                    Some (PendingSyncSendCap target b call can_grant can_grant_reply fault)) }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Identify Synchronous Bound Notification Threads: Retrieve the set of threads that are both bound to a specific notification and waiting for synchronous IPC. This ensures that only relevant threads, which are in the correct state and associated with the given notification, are selected.",
    "input": "",
    "output": "definition\n  get_waiting_sync_bound_ntfn_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_waiting_sync_bound_ntfn_threads ntfn_id state \\<equiv>\n     {x. \\<exists>a ep_id. (cdl_objects state) x = Some (Tcb a) \\<and>\n         (\\<exists>can_grant. (cdl_tcb_caps a) tcb_pending_op_slot = Some (PendingSyncRecvCap ep_id False can_grant)) \\<and>\n         ((cdl_tcb_caps a) tcb_boundntfn_slot = Some (BoundNotificationCap ntfn_id))}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread IPC Blocking: When a thread blocks on an IPC, it is assigned a new \"send once\" or \"receive once\" capability. This ensures that the IPC transfer can proceed even if the original capability used to initiate the send or receive operation is revoked.",
    "input": "",
    "output": "definition\n  block_thread_on_ipc :: \"cdl_object_id \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere\n  \"block_thread_on_ipc tcb cap \\<equiv> set_cap (tcb, tcb_pending_op_slot) cap\" (* Might need to do some check here *)\n\ndefinition\n  lookup_extra_caps :: \"cdl_object_id \\<Rightarrow> cdl_cptr list \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list fault_monad\"\nwhere\n  \"lookup_extra_caps thread cptrs \\<equiv>\n     mapME (\\<lambda>cptr. lookup_cap_and_slot thread cptr) cptrs\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IPC Transfer: Transfers a message from the sender to the receiver, optionally copying capabilities. If the receiver has a pending fault, the fault is sent instead of the message. The transfer process includes looking up and transferring capabilities, corrupting the IPC buffer, and setting the message information.",
    "input": "",
    "output": "definition\n  do_ipc_transfer :: \"cdl_object_id option \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"do_ipc_transfer ep_id sender_id receiver_id can_grant \\<equiv> do\n      \\<comment> \\<open>look up cap transfer\\<close>\n      src_slots \\<leftarrow> get_send_slots sender_id;\n      do \\<comment> \\<open>do normal transfer\\<close>\n        caps \\<leftarrow> if can_grant then\n                lookup_extra_caps sender_id src_slots <catch> (\\<lambda>_. return [])\n              else\n                return [];\n        \\<comment> \\<open>copy registers, transfer message or fault\\<close>\n        corrupt_ipc_buffer receiver_id True;\n        \\<comment> \\<open>transfer caps if no fault occured\\<close>\n        transfer_caps ep_id caps sender_id receiver_id\n      od  \\<sqinter>  \\<comment> \\<open>fault transfer\\<close>\n      corrupt_ipc_buffer receiver_id True;\n      \\<comment> \\<open>set message info\\<close>\n      corrupt_tcb_intent receiver_id\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Message Reply Transfer: Transfers a message from the sender to the receiver using a reply capability, with the option for the sender to grant capabilities over the channel. If the receiver has a pending fault, the fault is transferred and the receiver's intent is corrupted. The reply capability is deleted after the transfer, and the receiver's pending operation slot is updated based on the presence of a fault.",
    "input": "",
    "output": "definition\n  do_reply_transfer :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"do_reply_transfer sender_id receiver_id reply_cap_slot can_grant \\<equiv>\n    do\n      has_fault \\<leftarrow> get_thread_fault receiver_id;\n      when (\\<not> has_fault) $ do_ipc_transfer None sender_id receiver_id can_grant;\n      \\<comment> \\<open>Clear out any pending operation caps.\\<close>\n      delete_cap_simple reply_cap_slot;\n      when (has_fault) $ (do corrupt_tcb_intent receiver_id;\n        update_thread_fault receiver_id (\\<lambda>_. False) od );\n      if ( \\<not> has_fault) then set_cap (receiver_id, tcb_pending_op_slot) RunningCap\n      else\n         (set_cap (receiver_id,tcb_pending_op_slot) NullCap\n        \\<sqinter> set_cap (receiver_id,tcb_pending_op_slot) RestartCap)\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Wake-up Thread on Notification: Wake up a thread that is waiting on a notification by setting the capability of the receiver's pending operation slot to RunningCap and corrupting the TCB intent.",
    "input": "",
    "output": "definition\n  do_notification_transfer :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"do_notification_transfer receiver_id \\<equiv> do\n      set_cap (receiver_id,tcb_pending_op_slot) RunningCap;\n      corrupt_tcb_intent receiver_id\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Signal Notification: Sends a signal to a notification, waking up a thread if one is blocked on the notification. If no threads are waiting, the operation has no effect.",
    "input": "",
    "output": "definition\n  send_signal_bound :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"send_signal_bound ntfn_id \\<equiv> do\n      bound_tcbs \\<leftarrow> gets $ get_waiting_sync_bound_ntfn_threads ntfn_id;\n      if (bound_tcbs \\<noteq> {}) then do\n          t \\<leftarrow> select bound_tcbs;\n          set_cap (t, tcb_pending_op_slot) NullCap;\n          do_notification_transfer t\n        od\n      else return ()\n    od\"\n\ndefinition\n  send_signal :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"send_signal ep_id \\<equiv>\n    (do waiters \\<leftarrow> gets $ get_waiting_ntfn_recv_threads ep_id;\n          t \\<leftarrow> option_select waiters;\n          case t of\n              None \\<Rightarrow> return ()\n            | Some receiver \\<Rightarrow> do_notification_transfer receiver\n     od)\n            \\<sqinter> send_signal_bound ep_id\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Receive Signal: A thread can receive a signal from a notification, either by receiving the data or blocking until the data is available. This ensures that the thread's state is updated to reflect the pending reception and any associated intent is corrupted.",
    "input": "",
    "output": "definition\n  recv_signal :: \"cdl_object_id \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere\n  \"recv_signal tcb_id_receiver ep_cap  \\<equiv> do\n     ep_id \\<leftarrow> return $ cap_object ep_cap;\n     block_thread_on_ipc tcb_id_receiver (PendingNtfnRecvCap ep_id) \\<sqinter> corrupt_tcb_intent tcb_id_receiver\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IPC Synchronization: Sends an IPC to a specified endpoint. If there is a waiting receiver, it wakes up the receiver and performs the IPC transfer, including capability grants if allowed. If no receiver is waiting and blocking is enabled, the sender is put to sleep; otherwise, the operation returns immediately.",
    "input": "",
    "output": "definition\n  send_ipc :: \"bool \\<Rightarrow> bool \\<Rightarrow> cdl_badge \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"send_ipc block call badge can_grant can_grant_reply tcb_id_sender ep_id \\<equiv>\n    do\n      waiters \\<leftarrow> gets $ get_waiting_sync_recv_threads ep_id;\n      t \\<leftarrow> option_select waiters;\n      case t of\n          None \\<Rightarrow>\n            if block then\n              block_thread_on_ipc tcb_id_sender\n                  (PendingSyncSendCap ep_id badge call can_grant can_grant_reply False)\n            else\n              return ()\n        | Some tcb_id_receiver \\<Rightarrow> do\n             \\<comment> \\<open>liftM instead of bind+return avoids early unfolding in send_ipc_corres\\<close>\n             recv_state \\<leftarrow> liftM (\\<lambda>tcb. the (cdl_tcb_caps tcb tcb_pending_op_slot)) $\n                              get_thread tcb_id_receiver;\n             reply_can_grant \\<leftarrow>\n               (case recv_state of\n                    PendingSyncRecvCap target False receiver_grant \\<Rightarrow> do\n                      do_ipc_transfer (Some ep_id) tcb_id_sender tcb_id_receiver can_grant;\n                      return receiver_grant od\n                  | _ \\<Rightarrow> fail);\n             set_cap (tcb_id_receiver,tcb_pending_op_slot) RunningCap;\n             (when (can_grant \\<or> can_grant_reply) $\n                  (inject_reply_cap tcb_id_sender tcb_id_receiver reply_can_grant))\n               \\<sqinter> set_cap (tcb_id_sender,tcb_pending_op_slot) NullCap \\<sqinter> return ()\n          od\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Receive Synchronous IPC: Handle synchronous IPC reception from a specified endpoint. If there are waiting senders, wake one up and perform the IPC transfer, including capability grants if allowed. If no senders are waiting, block the receiver on the endpoint and mark its intent as corrupted.",
    "input": "",
    "output": "definition\n  receive_sync :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"receive_sync thread ep_id receiver_can_grant \\<equiv> do\n    waiters \\<leftarrow> gets $ get_waiting_sync_send_threads ep_id;\n      waiter \\<leftarrow> option_select waiters;\n      (case waiter of\n          None \\<Rightarrow>\n            block_thread_on_ipc thread (PendingSyncRecvCap ep_id False receiver_can_grant)\n             \\<sqinter> corrupt_tcb_intent thread\n        | Some tcb_id_sender \\<Rightarrow> (do\n            tcb \\<leftarrow> get_thread tcb_id_sender;\n            case ((cdl_tcb_caps tcb) tcb_pending_op_slot) of\n              Some (PendingSyncSendCap target _ call can_grant can_grant_reply fault) \\<Rightarrow> (do\n                 do_ipc_transfer (Some ep_id) tcb_id_sender thread can_grant;\n                 (when (can_grant \\<or> can_grant_reply) $\n                    (inject_reply_cap tcb_id_sender thread receiver_can_grant)) \\<sqinter>\n                 set_cap (tcb_id_sender, tcb_pending_op_slot) RunningCap \\<sqinter>\n                 set_cap (tcb_id_sender, tcb_pending_op_slot) NullCap\n              od)\n        od)\n      )\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IPC and Notification Handling: Enables threads to send and receive IPC messages, signals, and reply messages. The system supports synchronous message passing, signal sending, and reply message transfers, allowing for inter-thread communication and coordination.",
    "input": "",
    "output": "definition\n  receive_ipc :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"receive_ipc thread ep_id can_grant \\<equiv> corrupt_tcb_intent thread \\<sqinter> receive_sync thread ep_id can_grant\"\n\ndefinition\n  invoke_endpoint :: \"bool \\<Rightarrow> bool \\<Rightarrow> cdl_endpoint_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_endpoint is_call can_block params \\<equiv> case params of\n    SyncMessage badge can_grant can_grant_reply ep_id \\<Rightarrow> do\n      thread \\<leftarrow> gets_the cdl_current_thread;\n      send_ipc can_block is_call badge can_grant can_grant_reply thread ep_id\n    od\"\n\ndefinition\n  invoke_notification :: \"cdl_notification_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_notification params \\<equiv> case params of\n    Signal badge ep_id \\<Rightarrow>\n      send_signal ep_id\"\n\ndefinition\n  invoke_reply :: \"cdl_reply_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_reply params \\<equiv> case params of\n    ReplyMessage recv reply_cap_ref rights \\<Rightarrow> do\n      send \\<leftarrow> gets_the cdl_current_thread;\n      do_reply_transfer send recv reply_cap_ref rights\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Send Fault IPC: Send a fault IPC to the specified thread's fault handler, provided the handler has the necessary rights (Write and either Grant or GrantReply). If the handler does not have the required rights, the operation fails.",
    "input": "",
    "output": "definition\n  send_fault_ipc :: \"cdl_object_id \\<Rightarrow> unit fault_monad\"\n  where\n  \"send_fault_ipc tcb_id \\<equiv>\n    doE\n      \\<comment> \\<open>Lookup where we should send the fault IPC to.\\<close>\n      tcb \\<leftarrow> liftE $ get_thread tcb_id;\n      target_ep_cptr \\<leftarrow> returnOk $ cdl_tcb_fault_endpoint tcb;\n      handler_cap \\<leftarrow> lookup_cap tcb_id target_ep_cptr;\n      (case handler_cap of\n          EndpointCap ref badge rights \\<Rightarrow>\n            if Write \\<in> rights \\<and> (Grant \\<in> rights \\<or> GrantReply \\<in> rights) then\n              liftE $ do\n                update_thread_fault tcb_id (\\<lambda>_. True);\n                send_ipc True True badge (Grant \\<in> rights) True tcb_id ref\n              od\n            else\n               throw\n        | _ \\<Rightarrow> throw)\n    odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Fault: Manage a fault caused by the current thread. If sending a fault IPC fails, set the capability in the current thread's pending operation slot to null.",
    "input": "",
    "output": "definition\n  handle_fault :: \"unit k_monad\"\nwhere\n  \"handle_fault \\<equiv> do\n    tcb_id \\<leftarrow> gets_the cdl_current_thread;\n    (send_fault_ipc tcb_id\n      <catch> (\\<lambda>_. KHeap_D.set_cap (tcb_id,tcb_pending_op_slot) cdl_cap.NullCap))\n  od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Operations: Perform various operations on capabilities within CNodes, including copying, moving, revoking, deleting, and rotating capabilities. These operations ensure the integrity and management of capabilities, allowing for the modification of rights and data, and the atomic movement of capabilities between slots.",
    "input": "",
    "output": "(*\n * Operations on CNodes.\n *)\n\ntheory CNode_D\nimports Invocations_D CSpace_D\nbegin\n\ndefinition\n  has_cancel_send_rights :: \"cdl_cap \\<Rightarrow> bool\" where\n  \"has_cancel_send_rights cap \\<equiv> case cap of\n   EndpointCap _ _ R \\<Rightarrow> R = UNIV\n   | _ \\<Rightarrow> False\"\n\ndefinition\n  decode_cnode_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_cnode_intent \\<Rightarrow> cdl_cnode_invocation except_monad\"\nwhere\n  \"decode_cnode_invocation target target_ref caps intent \\<equiv> case intent of\n       \\<comment> \\<open>Copy a cap to anther capslot, without modifying the cap.\\<close>\n       CNodeCopyIntent dest_index dest_depth src_index src_depth rights \\<Rightarrow>\n         doE\n           (src_root, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op target dest_index (unat dest_depth);\n           ensure_empty dest_slot;\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n           new_cap \\<leftarrow> returnOk $ update_cap_rights (cap_rights src_cap \\<inter> rights) src_cap;\n           cap \\<leftarrow> derive_cap src_slot new_cap;\n           whenE (cap = cdl_cap.NullCap) throw;\n\n           returnOk $ InsertCall cap src_slot dest_slot\n         odE\n\n     \\<comment> \\<open>Copy a cap to another capslot, possibly modifying the cap.\\<close>\n     | CNodeMintIntent dest_index dest_depth src_index src_depth rights badge \\<Rightarrow>\n         doE\n           (src_root, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op target dest_index (unat dest_depth);\n           ensure_empty dest_slot;\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n\n           \\<comment> \\<open>Munge the caps rights/data.\\<close>\n           new_cap \\<leftarrow> returnOk $ update_cap_rights (cap_rights src_cap \\<inter> rights) src_cap;\n           new_cap' \\<leftarrow> liftE $ update_cap_data False badge new_cap;\n\n           cap \\<leftarrow> derive_cap src_slot new_cap';\n           whenE (cap = cdl_cap.NullCap) throw;\n\n           returnOk $ InsertCall cap src_slot dest_slot\n         odE\n\n     \\<comment> \\<open>Move a cap to another capslot, without modifying the cap.\\<close>\n     | CNodeMoveIntent dest_index dest_depth src_index src_depth \\<Rightarrow>\n         doE\n           (src_root, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op target dest_index (unat dest_depth);\n           ensure_empty dest_slot;\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n           whenE (src_cap = NullCap) throw;\n           returnOk $ MoveCall src_cap src_slot dest_slot\n         odE\n\n     \\<comment> \\<open>Move a cap to another capslot, possibly modifying the cap.\\<close>\n     | CNodeMutateIntent dest_index dest_depth src_index src_depth badge \\<Rightarrow>\n         doE\n           (src_root, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op target dest_index (unat dest_depth);\n           ensure_empty dest_slot;\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n\n           \\<comment> \\<open>Munge the caps rights/data.\\<close>\n           cap \\<leftarrow> liftE $ update_cap_data True badge src_cap;\n           whenE (cap = NullCap) throw;\n\n           returnOk $ MoveCall cap src_slot dest_slot\n         odE\n\n     \\<comment> \\<open>Revoke all CDT children of the given cap.\\<close>\n     | CNodeRevokeIntent index depth \\<Rightarrow>\n         doE\n           target_slot \\<leftarrow> lookup_slot_for_cnode_op target index (unat depth);\n           returnOk $ RevokeCall target_slot\n         odE\n\n     \\<comment> \\<open>Delete the given cap, but not its children.\\<close>\n     | CNodeDeleteIntent index depth \\<Rightarrow>\n         doE\n           target_slot \\<leftarrow> lookup_slot_for_cnode_op target index (unat depth);\n           returnOk $ DeleteCall target_slot\n         odE\n\n     \\<comment> \\<open>Save the current thread's reply cap into the target slot.\\<close>\n     | CNodeSaveCallerIntent index depth \\<Rightarrow>\n         doE\n           target_slot \\<leftarrow> lookup_slot_for_cnode_op target index (unat depth);\n           ensure_empty target_slot;\n           returnOk $ SaveCall target_slot\n         odE\n\n     \\<comment> \\<open>Recycle the target cap.\\<close>\n     | CNodeCancelBadgedSendsIntent index depth \\<Rightarrow>\n         doE\n           target_slot \\<leftarrow> lookup_slot_for_cnode_op target index (unat depth);\n           cap \\<leftarrow> liftE $ get_cap target_slot;\n           unlessE (has_cancel_send_rights cap) throw;\n           returnOk $ CancelBadgedSendsCall cap\n         odE\n\n     \\<comment> \\<open>Atomically move several caps.\\<close>\n     | CNodeRotateIntent dest_index dest_depth pivot_index pivot_depth pivot_badge src_index src_depth src_badge \\<Rightarrow>\n         doE\n           pivot_root \\<leftarrow> throw_on_none $ get_index caps 0;\n           src_root \\<leftarrow> throw_on_none $ get_index caps 1;\n\n           dest_root \\<leftarrow> returnOk $ target;\n           pivot_root \\<leftarrow> returnOk $ fst pivot_root;\n           src_root \\<leftarrow> returnOk $ fst src_root;\n\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op dest_root dest_index (unat dest_depth);\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           pivot_slot \\<leftarrow> lookup_slot_for_cnode_op pivot_root pivot_index (unat pivot_depth);\n\n           whenE (pivot_slot = src_slot \\<or> pivot_slot = dest_slot) throw;\n\n           unlessE (src_slot = dest_slot) $ ensure_empty dest_slot;\n\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n           whenE (src_cap = NullCap) throw;\n\n           pivot_cap \\<leftarrow> liftE $ get_cap pivot_slot;\n           whenE (pivot_cap = NullCap) throw;\n\n           \\<comment> \\<open>Munge caps.\\<close>\n           new_src \\<leftarrow> liftE $ update_cap_data True src_badge src_cap;\n           new_pivot \\<leftarrow> liftE $ update_cap_data True pivot_badge pivot_cap;\n\n           whenE (new_src = NullCap) throw;\n           whenE (new_pivot = NullCap) throw;\n\n           returnOk $ RotateCall new_src new_pivot src_slot pivot_slot dest_slot\n         odE\n   \"\n\ndefinition\n  invoke_cnode :: \"cdl_cnode_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_cnode params \\<equiv> case params of\n    \\<comment> \\<open>Insert a new cap.\\<close>\n      InsertCall cap src_slot dest_slot \\<Rightarrow>\n        liftE $\n          insert_cap_sibling cap src_slot dest_slot\n          \\<sqinter>\n          insert_cap_child cap src_slot dest_slot\n\n    \\<comment> \\<open>Move a cap, possibly modifying it in the process.\\<close>\n    | MoveCall cap src_slot dest_slot \\<Rightarrow>\n        liftE $ move_cap cap src_slot dest_slot\n\n    \\<comment> \\<open>Revoke a cap.\\<close>\n    | RevokeCall src_slot \\<Rightarrow>\n        revoke_cap src_slot\n\n    \\<comment> \\<open>Delete a cap.\\<close>\n    | DeleteCall src_slot \\<Rightarrow>\n        delete_cap src_slot\n\n    \\<comment> \\<open>Atomically move two capabilities.\\<close>\n    | RotateCall cap1 cap2 slot1 slot2 slot3 \\<Rightarrow>\n        liftE $ if slot1 = slot3 then\n          swap_cap cap1 slot1 cap2 slot2\n        else\n          do\n            move_cap cap2 slot2 slot3;\n            move_cap cap1 slot1 slot2\n          od\n\n    \\<comment> \\<open>Save a reply cap from the caller's TCB into this CNode.\\<close>\n    | SaveCall dest_slot \\<Rightarrow>\n        liftE $ do\n          current \\<leftarrow> gets_the cdl_current_thread;\n          replycap \\<leftarrow> get_cap (current, tcb_caller_slot);\n          when (replycap \\<noteq> NullCap)\n            $ move_cap replycap (current, tcb_caller_slot) dest_slot\n        od\n\n    \\<comment> \\<open>Reset an object into its original state.\\<close>\n    | CancelBadgedSendsCall (EndpointCap ep b _) \\<Rightarrow> liftE $ when (b \\<noteq> 0) $ cancel_badged_sends ep b\n    | CancelBadgedSendsCall _ \\<Rightarrow> fail\n  \"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Frame Operations: Manage and manipulate page table objects and frames, ensuring proper memory allocation, deallocation, and configuration within the system.",
    "input": "",
    "output": "(*\n * Operations on page table objects and frames.\n *)\n\ntheory PageTable_D\nimports Invocations_D CSpace_D\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Free PD Slots: Identify and return the set of free slots in the given page directory, where each slot contains a NullCap.",
    "input": "",
    "output": "definition\n  free_pd_slots :: \"cdl_object \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n  \"free_pd_slots pd pd_id state \\<equiv> {(pd_id, y). (object_slots pd) y = Some NullCap}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve All PD/PT Slots: Collect all the slots in the given page directory (PD) and its associated page tables (PTs). The set includes both the slots within the PD and the slots of the PTs referenced by the PD, ensuring a comprehensive mapping of the memory structure.",
    "input": "",
    "output": "definition\n  all_pd_pt_slots :: \"cdl_object \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n  \"all_pd_pt_slots pd pd_id state \\<equiv> {(pd_id, y). y \\<in> dom (object_slots pd)}\n     \\<union> {(x, y). \\<exists> a b c. (object_slots pd) a = Some (PageTableCap x b c) \\<and> x \\<in> dom (cdl_objects state)}\"\n\ndefinition\n  \"cdl_get_pt_mapped_addr cap \\<equiv>\n    case cap of PageTableCap pid ctype maddr \\<Rightarrow>  maddr\n    | _ \\<Rightarrow> None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Invocation Decoding: Decode a page table intent into a specific invocation, supporting mapping and unmapping operations. For mapping, it ensures the page table is not already mapped, retrieves the page directory and ASID, and sets up the necessary mappings. For unmapping, it validates the target as a page table and performs the unmap operation.",
    "input": "",
    "output": "definition\n  decode_page_table_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_page_table_intent \\<Rightarrow> cdl_page_table_invocation except_monad\"\nwhere\n  \"decode_page_table_invocation target target_ref caps intent \\<equiv> case intent of\n    \\<comment> \\<open>\n      Map the given PageTable into the given PageDirectory at the given\n      virtual address.\n\n      The concrete implementation only allows a PageTable to be mapped\n      once at any point in time, but we don't enforce that here.\n     \\<close>\n    PageTableMapIntent vaddr attr \\<Rightarrow>\n      doE\n        case cdl_get_pt_mapped_addr target of Some a \\<Rightarrow> throw\n        | None \\<Rightarrow> returnOk ();\n        \\<comment> \\<open>Ensure that a PD was passed in.\\<close>\n        pd \\<leftarrow> throw_on_none $ get_index caps 0;\n        (pd_object_id, asid) \\<leftarrow>\n          case (fst pd) of\n              PageDirectoryCap x _ (Some asid) \\<Rightarrow> returnOk (x, asid)\n            | _ \\<Rightarrow> throw;\n\n        target_slot \\<leftarrow> returnOk $ cdl_lookup_pd_slot pd_object_id vaddr;\n\n        returnOk $ PageTableMap (PageTableCap (cap_object target) Real (Some (asid,vaddr && ~~ mask 20)))\n          (PageTableCap (cap_object target) Fake None) target_ref target_slot\n      odE \\<sqinter> throw\n    \\<comment> \\<open>Unmap this PageTable.\\<close>\n    | PageTableUnmapIntent \\<Rightarrow> (\n        case target of PageTableCap pid ctype maddr \\<Rightarrow>\n        (returnOk $ PageTableUnmap maddr pid target_ref)\n        | _ \\<Rightarrow> throw\n      ) \\<sqinter> throw\n  \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode Page Directory Intent: Interpret a page directory intent into a corresponding page directory invocation, which can include various flush operations (Unify, Clean, CleanInvalidate, Invalidate) or no operation.",
    "input": "",
    "output": "definition\n  decode_page_directory_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_page_directory_intent \\<Rightarrow> cdl_page_directory_invocation except_monad\"\nwhere\n  \"decode_page_directory_invocation target target_ref caps intent \\<equiv>\n      (returnOk $ PageDirectoryNothing) \\<sqinter>\n      (returnOk $ PageDirectoryFlush Unify)  \\<sqinter>  (returnOk $ PageDirectoryFlush Clean)  \\<sqinter>\n      (returnOk $ PageDirectoryFlush CleanInvalidate )  \\<sqinter> (returnOk $ PageDirectoryFlush Invalidate)\n      \\<sqinter> throw \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Invocation Decoding: Decode a page intent into a specific page invocation, supporting actions such as mapping a page into a page directory or table, unmapping a page, flushing caches, and retrieving the page address. Each action ensures that the appropriate capabilities and parameters are validated and used to construct the corresponding page invocation.",
    "input": "",
    "output": "definition\n  decode_page_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_page_intent \\<Rightarrow> cdl_page_invocation except_monad\"\nwhere\n  \"decode_page_invocation target target_ref caps intent \\<equiv> case intent of\n      \\<comment> \\<open>\n        Map the given Page into the given PageDirectory or PageTable at\n        the given virtual address.\n\n        The concrete implementation only allows a Page to be mapped\n        once at any point in time, but we don't enforce that here.\n       \\<close>\n      PageMapIntent vaddr rights attr \\<Rightarrow>\n        doE\n          \\<comment> \\<open>Ensure that a PD was passed in.\\<close>\n          pd \\<leftarrow> throw_on_none $ get_index caps 0;\n          (pd_object_id, asid) \\<leftarrow>\n            case (fst pd) of\n                PageDirectoryCap x _ (Some asid) \\<Rightarrow> returnOk (x, asid)\n              | _ \\<Rightarrow> throw;\n\n          \\<comment> \\<open>Collect mapping from target cap.\\<close>\n          (frame,sz,dev) \\<leftarrow> returnOk $ (case target of FrameCap dev p R sz m mp \\<Rightarrow> (p,sz,dev));\n\n          target_slots \\<leftarrow> cdl_page_mapping_entries vaddr sz pd_object_id;\n\n          \\<comment> \\<open>Calculate rights.\\<close>\n          new_rights \\<leftarrow> returnOk $ validate_vm_rights $ cap_rights target \\<inter> rights;\n\n          \\<comment> \\<open>Return the map intent.\\<close>\n          returnOk $ PageMap (FrameCap dev frame (cap_rights target) sz Real (Some (asid,vaddr)))\n            (FrameCap False frame new_rights sz Fake None) target_ref target_slots\n        odE \\<sqinter> throw\n\n    \\<comment> \\<open>Unmap this PageTable.\\<close>\n    | PageUnmapIntent \\<Rightarrow> doE\n        (frame, asid, sz) \\<leftarrow> (case target of\n           FrameCap _ p R sz m mp \\<Rightarrow> returnOk (p, mp , sz)\n        | _ \\<Rightarrow> throw);\n      (returnOk $ PageUnmap asid frame target_ref sz) \\<sqinter> throw\n      odE\n\n    \\<comment> \\<open>Flush the caches associated with this page.\\<close>\n    | PageFlushCachesIntent \\<Rightarrow>\n       (returnOk $ PageFlushCaches Unify)  \\<sqinter>  (returnOk $ PageFlushCaches Clean)  \\<sqinter>\n      (returnOk $ PageFlushCaches CleanInvalidate )  \\<sqinter> (returnOk $ PageFlushCaches Invalidate)\n      \\<sqinter> throw\n\n    | PageGetAddressIntent \\<Rightarrow> returnOk PageGetAddress\n\n  \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Directory Invocation: Handles page directory operations, including flushing the page directory or performing no action. This ensures that the page directory can be updated or left unchanged as required.",
    "input": "",
    "output": "definition\n  invoke_page_directory :: \"cdl_page_directory_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_page_directory params \\<equiv> case params of\n      PageDirectoryFlush flush  => return ()\n    | PageDirectoryNothing => return ()\n  \"\n\ndefinition \"option_exec f \\<equiv> \\<lambda>x. case x of Some a \\<Rightarrow> f a | None \\<Rightarrow> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Invocation: Manages the mapping and unmapping of page tables. It sets or updates the capability for a page table, installs the page table into a page directory, and unmaps the page table from a specified address, clearing its capabilities if necessary.",
    "input": "",
    "output": "definition\n  invoke_page_table :: \"cdl_page_table_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_page_table params \\<equiv> case params of\n      PageTableMap real_pt_cap pt_cap pt_cap_ref pd_target_slot \\<Rightarrow>\n        do set_cap pt_cap_ref real_pt_cap;\n           \\<comment> \\<open>\n             We install the Page Table into the Page Directory.  The\n             concrete kernel uses hardware-defined PDEs (Page Directory\n             Entries). Our abstract spec just uses caps.\n            \\<close>\n           insert_cap_orphan pt_cap pd_target_slot\n        od\n    | PageTableUnmap mapped_addr pt_id pt_cap_ref \\<Rightarrow> do\n        (case mapped_addr of Some maddr \\<Rightarrow> do\n                 unmap_page_table maddr pt_id;\n                 clear_object_caps pt_id \\<sqinter> return ()\n               od\n          | _ \\<Rightarrow> return ());\n        cap \\<leftarrow> get_cap pt_cap_ref;\n        set_cap pt_cap_ref (reset_mem_mapping cap)\n        od\n\n  \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Invocation: Manages page operations including mapping, unmapping, flushing caches, and retrieving the address of a page. It ensures that frame capabilities are correctly set or reset, target slots are updated, and cache operations are performed as specified.",
    "input": "",
    "output": "definition\n  invoke_page :: \"cdl_page_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_page params \\<equiv> case params of\n      PageMap frame_cap pseudo_frame_cap frame_cap_ref target_slots \\<Rightarrow>\n          \\<comment> \\<open>Clear out the target slots.\\<close>\n        do\n          set_cap frame_cap_ref frame_cap;\n          mapM_x (swp set_cap pseudo_frame_cap) target_slots\n        od\n\n    | PageUnmap mapped_addr frame_id frame_cap_ref pgsz \\<Rightarrow> do\n        (case mapped_addr of\n          Some maddr \\<Rightarrow> unmap_page maddr frame_id pgsz\n        | _ \\<Rightarrow> return ());\n        cap \\<leftarrow> get_cap frame_cap_ref;\n        set_cap frame_cap_ref (reset_mem_mapping cap)\n      od\n\n    | PageFlushCaches flush \\<Rightarrow> return ()\n\n    | PageGetAddress \\<Rightarrow> return ()\n\n  \"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Interface: Defines the interface for system calls, enabling user-level applications to request services from the kernel. This ensures that the kernel can securely and efficiently handle requests, providing necessary functionalities while maintaining system integrity and stability.",
    "input": "",
    "output": "(*\n * System calls\n *)\n\ntheory Syscall_D\nimports\n  Schedule_D\n  Decode_D\n  \"ExecSpec.Event_H\"\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Handling: System calls are processed in three stages—capability validation, argument validation, and execution. The system call function takes five user-provided functions for these stages, including error handlers, and executes the system call, handling any potential preemption by interrupts. \n\n- **Capability Validation**: Ensures that all capabilities passed into the system call are valid.\n- **Argument Validation**: Ensures that the requested operation is valid and permitted.\n- **Execution**: Carries out the actual operation, with the ability to handle preemption by interrupts.",
    "input": "",
    "output": "definition\nsyscall :: \"\n  ('a fault_monad) \\<Rightarrow> (unit k_monad) \\<Rightarrow>\n  ('a \\<Rightarrow> 'b except_monad) \\<Rightarrow> (unit k_monad) \\<Rightarrow>\n  ('b \\<Rightarrow> unit preempt_monad) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"syscall\n      cap_decoder_fn decode_error_handler_fn\n      arg_decode_fn arg_error_handler_fn\n      perform_syscall_fn \\<equiv>\n    cap_decoder_fn\n    <handle>\n      (\\<lambda> _. liftE $ decode_error_handler_fn)\n    <else>\n      (\\<lambda> a. ((arg_decode_fn a)\n        <handle>\n          (\\<lambda> _. liftE $ arg_error_handler_fn)\n        <else>\n          perform_syscall_fn))\n  \"\n\nfun\n  perform_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> cdl_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n    \"perform_invocation is_call can_block (InvokeUntyped untyped_params) = (invoke_untyped untyped_params)\"\n  | \"perform_invocation is_call can_block (InvokeEndpoint endpoint_params) = liftE (invoke_endpoint is_call can_block endpoint_params)\"\n  | \"perform_invocation is_call can_block (InvokeNotification ntfn_params) = liftE (invoke_notification ntfn_params)\"\n  | \"perform_invocation is_call can_block (InvokeReply reply_params) = liftE (invoke_reply reply_params)\"\n  | \"perform_invocation is_call can_block (InvokeTcb tcb_params) = (invoke_tcb tcb_params)\"\n  | \"perform_invocation is_call can_block (InvokeDomain domain_params) = (invoke_domain domain_params)\"\n  | \"perform_invocation is_call can_block (InvokeCNode cnode_params) = invoke_cnode cnode_params\"\n  | \"perform_invocation is_call can_block (InvokeIrqControl irq_params) = liftE (invoke_irq_control irq_params)\"\n  | \"perform_invocation is_call can_block (InvokeIrqHandler handler_params) = liftE (invoke_irq_handler handler_params)\"\n  | \"perform_invocation is_call can_block (InvokePageTable page_table_params) = liftE (invoke_page_table page_table_params)\"\n  | \"perform_invocation is_call can_block (InvokePage page_params) = liftE (invoke_page page_params)\"\n  | \"perform_invocation is_call can_block (InvokeAsidControl asid_control_params) = liftE (invoke_asid_control asid_control_params)\"\n  | \"perform_invocation is_call can_block (InvokeAsidPool asid_pool_params) = liftE (invoke_asid_pool asid_pool_params)\"\n  | \"perform_invocation is_call can_block (InvokePageDirectory page_dir_params) = liftE (invoke_page_directory page_dir_params) \"\n\ndefinition ep_related_cap :: \"cdl_cap \\<Rightarrow> bool\"\nwhere \"ep_related_cap cap \\<equiv> case cap of\n cdl_cap.EndpointCap o_id badge rights \\<Rightarrow> True\n| cdl_cap.NotificationCap o_id badge rights \\<Rightarrow> True\n| cdl_cap.ReplyCap o_id rights \\<Rightarrow> True\n| _ \\<Rightarrow> False\"\n\ndefinition \"has_restart_cap \\<equiv> \\<lambda>tcb_id. do\n  t \\<leftarrow> get_thread tcb_id;\n  return ((cdl_tcb_caps t) tcb_pending_op_slot = Some cdl_cap.RestartCap)\n  od\"\n\ndefinition\n  handle_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"handle_invocation is_call can_block \\<equiv>\n    doE\n      thread_ptr \\<leftarrow> liftE $ gets_the cdl_current_thread;\n      thread \\<leftarrow> liftE $ get_thread thread_ptr;\n      full_intent \\<leftarrow> returnOk $ cdl_tcb_intent thread;\n\n      intent \\<leftarrow> returnOk $ cdl_intent_op full_intent;\n      invoked_cptr \\<leftarrow> returnOk $ cdl_intent_cap full_intent;\n      extra_cap_cptrs \\<leftarrow> returnOk $ cdl_intent_extras full_intent;\n\n      syscall\n        \\<comment> \\<open>Lookup all caps presented.\\<close>\n        (doE\n          (cap, cap_ref) \\<leftarrow> lookup_cap_and_slot thread_ptr invoked_cptr;\n          extra_caps \\<leftarrow> lookup_extra_caps thread_ptr extra_cap_cptrs;\n          returnOk (cap, cap_ref, extra_caps)\n        odE)\n        \\<comment> \\<open>If that failed, send off a fault IPC (if we did a blocking operation).\\<close>\n        (when can_block $ handle_fault)\n\n        \\<comment> \\<open>Decode the user's intent.\\<close>\n        (\\<lambda> (cap, cap_ref, extra_caps).\n          case intent of\n              None \\<Rightarrow> (if ep_related_cap cap then\n                decode_invocation cap cap_ref extra_caps undefined\n                else throw)\n            | Some intent' \\<Rightarrow>\n                decode_invocation cap cap_ref extra_caps intent')\n\n        \\<comment> \\<open>If that stuffed up, we do nothing more than corrupt the frames.\\<close>\n        (do corrupt_ipc_buffer thread_ptr True;\n            when is_call (mark_tcb_intent_error thread_ptr True)\n         od)\n\n        \\<comment> \\<open>Invoke the system call.\\<close>\n        (\\<lambda> inv. doE\n            liftE $ set_cap (thread_ptr,tcb_pending_op_slot) RestartCap;\n            perform_invocation is_call can_block inv;\n            restart \\<leftarrow> liftE $ has_restart_cap thread_ptr;\n            whenE restart $ liftE (do\n                       corrupt_ipc_buffer thread_ptr True;\n                       when (is_call) (mark_tcb_intent_error thread_ptr False);\n                       set_cap (thread_ptr,tcb_pending_op_slot) RunningCap\n            od)\n            odE)\n  odE\n  \"\n\ndefinition\n  handle_recv :: \"unit k_monad\"\nwhere\n  \"handle_recv \\<equiv>\n    do\n      \\<comment> \\<open>Get the current thread.\\<close>\n      tcb_id \\<leftarrow> gets_the cdl_current_thread;\n      tcb \\<leftarrow> get_thread tcb_id;\n      \\<comment> \\<open>Get the endpoint it is trying to receive from.\\<close>\n      (doE\n        ep_cptr \\<leftarrow> returnOk $ cdl_intent_cap (cdl_tcb_intent tcb);\n        ep_cap \\<leftarrow> lookup_cap tcb_id ep_cptr;\n        (case ep_cap of\n          EndpointCap o_id badge rights \\<Rightarrow>\n            if Read \\<in> rights then\n              (liftE $ do\n                   delete_cap_simple (tcb_id, tcb_caller_slot);\n                   receive_ipc tcb_id (cap_object ep_cap) (Grant \\<in> rights)\n                od) \\<sqinter> throw\n            else\n              throw\n        | NotificationCap o_id badge rights \\<Rightarrow>\n            if Read \\<in> rights then\n              (liftE $ recv_signal tcb_id ep_cap) \\<sqinter> throw\n            else\n              throw\n        | _ \\<Rightarrow>\n            throw)\n      odE)\n      <catch>\n        (\\<lambda> _. handle_fault)\n    od\n  \"\n\ndefinition\n  handle_reply :: \"unit k_monad\"\nwhere\n  \"handle_reply \\<equiv>\n    do\n      tcb_id \\<leftarrow> gets_the cdl_current_thread;\n      caller_cap \\<leftarrow> get_cap (tcb_id, tcb_caller_slot);\n\n      case caller_cap of\n          ReplyCap target rights \\<Rightarrow> do_reply_transfer tcb_id target (tcb_id, tcb_caller_slot) (Grant \\<in> rights)\n        | NullCap \\<Rightarrow> return ()\n        | _ \\<Rightarrow> fail\n    od\n  \"\n\ndefinition handle_hypervisor_fault :: \"unit k_monad\"\nwhere \"handle_hypervisor_fault \\<equiv> return ()\"\n\ndefinition\n  handle_syscall :: \"syscall \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"handle_syscall sys \\<equiv>\n    case sys of\n      SysSend  \\<Rightarrow> handle_invocation False True\n    | SysNBSend \\<Rightarrow> handle_invocation False False\n    | SysCall \\<Rightarrow> handle_invocation True True\n    | SysRecv \\<Rightarrow> liftE $ handle_recv\n    | SysYield \\<Rightarrow> returnOk ()\n    | SysReply \\<Rightarrow> liftE $ handle_reply\n    | SysReplyRecv \\<Rightarrow> liftE $ do\n        handle_reply;\n        handle_recv\n      od\n    | SysNBRecv \\<Rightarrow> liftE $ handle_recv\"\n\ndefinition\n  handle_event :: \"event \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"handle_event ev \\<equiv> case ev of\n      SyscallEvent sys \\<Rightarrow> handle_syscall sys\n    | UnknownSyscall n \\<Rightarrow> liftE $ handle_fault\n    | UserLevelFault a b \\<Rightarrow> liftE $ handle_fault\n    | VMFaultEvent c \\<Rightarrow> liftE $ handle_fault\n    | Interrupt \\<Rightarrow> liftE $ handle_pending_interrupts\n    | HypervisorEvent w \\<Rightarrow> liftE $ handle_hypervisor_fault\n    \"\n\ndefinition\n  call_kernel :: \"event \\<Rightarrow> unit k_monad\"\nwhere\n  \"call_kernel ev \\<equiv>\n    do\n      \\<comment> \\<open>Deal with the event.\\<close>\n      handle_event ev\n        <handle> (\\<lambda> _. liftE handle_pending_interrupts);\n      schedule;\n      t \\<leftarrow> gets cdl_current_thread;\n      case t of Some thread \\<Rightarrow> do\n       restart \\<leftarrow> has_restart_cap thread;\n       when restart $ set_cap (thread, tcb_pending_op_slot) RunningCap\n      od | None \\<Rightarrow> return ()\n    od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page and Cap Management: Enables the management of page tables, including unmapping pages, revoking and finalizing capabilities, and canceling IPC operations. It supports operations to unbind notifications, check if a thread is blocked on an endpoint, and determine if a capability can be fast-finalized. Additionally, it provides mechanisms to clear and manage capability slots, ensuring that entities are correctly deleted or retained based on their cap counts and finality.",
    "input": "",
    "output": "(*\n * Unmapping pages and page tables and what is needed for it:\n * short cut delete, revoke and finale of caps, ipc cancelling.\n *)\n\ntheory PageTableUnmap_D\nimports\n  Invocations_D\n  KHeap_D\nbegin\n\n\\<comment> \\<open>Return all slots in the system containing a cap with the given property.\\<close>\ndefinition\n  slots_with :: \"(cdl_cap \\<Rightarrow> bool) \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n  \"slots_with P s \\<equiv> {(obj, slot). \\<exists>x c. cdl_objects s obj = Some x \\<and>\n                                        has_slots x \\<and>\n                                        object_slots x slot = Some c \\<and> P c}\"\n\n\n\\<comment> \\<open>Remove a pending operation from the given TCB.\\<close>\ndefinition\n  remove_pending_operation :: \"cdl_tcb \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_tcb\"\nwhere\n  \"remove_pending_operation t cap \\<equiv> t\\<lparr>cdl_tcb_caps := (cdl_tcb_caps t)(tcb_pending_op_slot \\<mapsto> cap)\\<rparr>\"\n\n\n\\<comment> \\<open>Is the given thread pending on the given endpoint?\\<close>\ndefinition\n  is_thread_blocked_on_endpoint :: \"cdl_tcb \\<Rightarrow> cdl_object_id \\<Rightarrow> bool\"\nwhere\n  \"is_thread_blocked_on_endpoint t ep \\<equiv>\n    case (cdl_tcb_caps t tcb_pending_op_slot) of\n        Some (PendingSyncSendCap p _ _ _ _ _) \\<Rightarrow> p = ep\n      | Some (PendingSyncRecvCap p is_reply _) \\<Rightarrow> p = ep \\<and> \\<not> is_reply\n      | Some (PendingNtfnRecvCap p) \\<Rightarrow> p = ep\n      | _ \\<Rightarrow> False\"\n\n\n\\<comment> \\<open>Cancel all pending IPCs currently blocked on this endpoint.\\<close>\ndefinition\n  cancel_all_ipc :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"cancel_all_ipc ep \\<equiv>\n    modify (\\<lambda>s. s\\<lparr>cdl_objects :=  map_option\n        (\\<lambda>obj. case obj of\n            Tcb t \\<Rightarrow>\n              if (is_thread_blocked_on_endpoint t ep) then\n                Tcb (remove_pending_operation t RestartCap)\n              else\n                Tcb t\n           | _ \\<Rightarrow> obj)\n          \\<circ> (cdl_objects s)\\<rparr>)\"\n\n\\<comment> \\<open>Is the given thread bound to the given ntfn?\\<close>\ndefinition\n  is_thread_bound_to_ntfn :: \"cdl_tcb \\<Rightarrow> cdl_object_id \\<Rightarrow> bool\"\nwhere\n  \"is_thread_bound_to_ntfn t ntfn \\<equiv>\n    case (cdl_tcb_caps t tcb_boundntfn_slot) of\n        Some (BoundNotificationCap a) \\<Rightarrow> a = ntfn\n      | _ \\<Rightarrow> False\"\n\n\\<comment> \\<open>find all tcbs that are bound to a given ntfn\\<close>\ndefinition\n  get_bound_notification_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_bound_notification_threads ntfn_id state \\<equiv>\n     {x. \\<exists>a. (cdl_objects state) x = Some (Tcb a) \\<and>\n         (((cdl_tcb_caps a) tcb_boundntfn_slot) = Some (BoundNotificationCap ntfn_id))}\"\n\ndefinition\n  modify_bound_ntfn :: \"cdl_tcb \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_tcb\"\nwhere\n  \"modify_bound_ntfn t cap \\<equiv> t \\<lparr> cdl_tcb_caps := (cdl_tcb_caps t)(tcb_boundntfn_slot \\<mapsto> cap)\\<rparr>\"\n\n\nabbreviation\n  do_unbind_notification :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"do_unbind_notification tcb \\<equiv> set_cap (tcb, tcb_boundntfn_slot) NullCap\"\n\ndefinition\n  unbind_notification :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"unbind_notification tcb \\<equiv> do\n     cap \\<leftarrow> KHeap_D.get_cap (tcb, tcb_boundntfn_slot);\n     (case cap of\n      BoundNotificationCap _ \\<Rightarrow> do_unbind_notification tcb\n    | _ \\<Rightarrow> return ())\n   od\"\n\ndefinition\n  unbind_maybe_notification :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"unbind_maybe_notification ntfn_id \\<equiv> do\n     bound_tcbs \\<leftarrow> gets $ get_bound_notification_threads ntfn_id;\n     t \\<leftarrow> option_select bound_tcbs;\n     (case t of\n       None \\<Rightarrow> return ()\n     | Some tcb \\<Rightarrow> do_unbind_notification tcb)\n  od\"\n\ndefinition\n  can_fast_finalise :: \"cdl_cap \\<Rightarrow> bool\" where\n \"can_fast_finalise cap \\<equiv> case cap of ReplyCap r R \\<Rightarrow> True\n                       | MasterReplyCap r \\<Rightarrow> True\n                       | EndpointCap r b R \\<Rightarrow> True\n                       | NotificationCap r b R \\<Rightarrow> True\n                       | NullCap \\<Rightarrow> True\n                       | RestartCap \\<Rightarrow> True\n                       | RunningCap \\<Rightarrow> True\n                       | PendingSyncSendCap r _ _ _ _ _ \\<Rightarrow> True\n                       | PendingSyncRecvCap r _ _ \\<Rightarrow> True\n                       | PendingNtfnRecvCap r \\<Rightarrow> True\n                       | DomainCap \\<Rightarrow> True\n                       | PageDirectoryCap _ x _ \\<Rightarrow> \\<not>(x = Real)\n                       | PageTableCap _ x _ \\<Rightarrow> \\<not>(x = Real)\n                       | FrameCap _ _ _ _ x _ \\<Rightarrow> \\<not>(x = Real)\n                       | _ \\<Rightarrow> False\"\n\ncontext\nnotes [[function_internals =true]]\nbegin\n\nfun\n  fast_finalise :: \"cdl_cap \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"fast_finalise NullCap                  final = return ()\"\n| \"fast_finalise (RestartCap)             final = return ()\"\n| \"fast_finalise (RunningCap)             final = return ()\"\n| \"fast_finalise (ReplyCap r R)           final = return ()\"\n| \"fast_finalise (MasterReplyCap r)       final = return ()\"\n| \"fast_finalise (EndpointCap r b R)      final =\n      (when final $ cancel_all_ipc r)\"\n| \"fast_finalise (NotificationCap r b R) final =\n      (when final $ do\n            unbind_maybe_notification r;\n            cancel_all_ipc r\n          od)\"\n| \"fast_finalise (PendingSyncSendCap r _ _ _ _ _) final = return()\"\n| \"fast_finalise (PendingSyncRecvCap r _ _) final = return()\"\n| \"fast_finalise  (PendingNtfnRecvCap r) final = return()\"\n| \"fast_finalise DomainCap final = return ()\"\n| \"fast_finalise (PageDirectoryCap _ x _) _ = (if x = Real then fail else return())\"\n| \"fast_finalise (PageTableCap _ x _) _ = (if x = Real then fail else return())\"\n| \"fast_finalise (FrameCap _ _ _ _ x _) _ = (if x = Real then fail else return())\"\n| \"fast_finalise _ _ = fail\"\n\nend\n\n\\<comment> \\<open>These caps don't count when determining if an entity should be deleted or not\\<close>\ndefinition\n  cap_counts :: \"cdl_cap \\<Rightarrow> bool\" where\n \"cap_counts cap \\<equiv> (case cap of\n    cdl_cap.NullCap \\<Rightarrow> False\n  | UntypedCap _ _ _ \\<Rightarrow> False\n  | ReplyCap _ _ \\<Rightarrow> False\n  | MasterReplyCap _ \\<Rightarrow> False\n  | RestartCap \\<Rightarrow> False\n  | RunningCap \\<Rightarrow> False\n  | PendingSyncSendCap _ _ _ _ _ _ \\<Rightarrow> False\n  | PendingSyncRecvCap _ _ _ \\<Rightarrow> False\n  | PendingNtfnRecvCap _ \\<Rightarrow> False\n  | DomainCap \\<Rightarrow> False\n  | BoundNotificationCap _ \\<Rightarrow> False\n  | IrqControlCap  \\<Rightarrow> False\n  | AsidControlCap \\<Rightarrow> False\n  | IOSpaceMasterCap \\<Rightarrow> False\n  | FrameCap _ _ _ _ c _ \\<Rightarrow> c = Real\n  | PageTableCap _ c _ \\<Rightarrow> c = Real\n  | PageDirectoryCap _ c _ \\<Rightarrow> c = Real\n  | _ \\<Rightarrow> True)\"\n\ndefinition\n  cdl_cap_irq :: \"cdl_cap \\<Rightarrow> cdl_irq option\" where\n \"cdl_cap_irq cap \\<equiv> (case cap of IrqHandlerCap irq \\<Rightarrow> Some irq | _ \\<Rightarrow> None)\"\n\n\\<comment> \\<open>Some caps don't count when determining if an entity should be deleted or not\\<close>\ndefinition\n  is_final_cap' :: \"cdl_cap \\<Rightarrow> cdl_state \\<Rightarrow> bool\" where\n \"is_final_cap' cap s \\<equiv> ((cap_counts cap) \\<and>\n  (\\<exists>cref. {cref. \\<exists>cap'. opt_cap cref s = Some cap'\n                       \\<and> (cap_object cap = cap_object cap'\n                             \\<and> cdl_cap_irq cap = cdl_cap_irq cap')\n                       \\<and> cap_counts cap'}\n         = {cref}))\"\n\n\ndefinition\n  is_final_cap :: \"cdl_cap \\<Rightarrow> bool k_monad\" where\n  \"is_final_cap cap \\<equiv> gets (is_final_cap' cap)\"\n\n\ndefinition\n  always_empty_slot :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n \"always_empty_slot slot = do\n    remove_parent slot;\n    set_cap slot NullCap\n  od\"\n\ndefinition\n  empty_slot :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n \"empty_slot slot = do\n  cap \\<leftarrow> get_cap slot;\n  if cap = NullCap then\n    return ()\n  else do\n    remove_parent slot;\n    set_cap slot NullCap\n    od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Preemptable Cap Deletion: Ensures the deletion of a capability without causing preemption, suitable for capabilities that exist at the CapDL level but not at lower levels. The operation checks if the capability is not null, determines if it is a final capability, and then finalizes and empties the slot.",
    "input": "",
    "output": "definition\n  delete_cap_simple :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"delete_cap_simple cap_ref \\<equiv> do\n    cap \\<leftarrow> get_cap cap_ref;\n    unless (cap = NullCap) $ do\n      final \\<leftarrow> is_final_cap cap;\n      fast_finalise cap final;\n      always_empty_slot cap_ref\n    od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Preemptable Revocation: Ensures that a capability and its non-null descendants are revoked in a non-preemptable manner, suitable for bounded revokes. The process involves recursively deleting non-null descendant capabilities until all relevant capabilities are removed.",
    "input": "",
    "output": "function\n  revoke_cap_simple :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"revoke_cap_simple victim s = (do\n    descendants \\<leftarrow> gets $ KHeap_D.descendants_of victim;\n    assert (finite descendants);\n    non_null \\<leftarrow> gets (\\<lambda>s. {slot. opt_cap slot s \\<noteq> Some NullCap \\<and> opt_cap slot s \\<noteq> None});\n    non_null_descendants \\<leftarrow> return (descendants \\<inter> non_null);\n    if (non_null_descendants \\<noteq> {}) then do\n      a \\<leftarrow> select non_null_descendants;\n      delete_cap_simple a;\n      revoke_cap_simple victim\n    od else return ()\n  od) s\"\n  by auto\n\n\ndefinition cdl_get_pde :: \"(word32 \\<times> nat)\\<Rightarrow> cdl_cap k_monad\"\nwhere \"cdl_get_pde ptr \\<equiv>\n  KHeap_D.get_cap ptr\"\n\ndefinition cdl_lookup_pd_slot :: \"word32 \\<Rightarrow> word32 \\<Rightarrow> word32 \\<times> nat \"\n  where \"cdl_lookup_pd_slot pd vptr \\<equiv> (pd, unat (vptr >> 20))\"\n\ndefinition cdl_lookup_pt_slot :: \"word32 \\<Rightarrow> word32 \\<Rightarrow> (word32 \\<times> nat) except_monad\"\n  where \"cdl_lookup_pt_slot pd vptr \\<equiv>\n    doE pd_slot \\<leftarrow> returnOk (cdl_lookup_pd_slot pd vptr);\n        pdcap \\<leftarrow> liftE $ cdl_get_pde pd_slot;\n        (case pdcap of cdl_cap.PageTableCap ref Fake None\n         \\<Rightarrow> ( doE pt \\<leftarrow> returnOk ref;\n              pt_index \\<leftarrow> returnOk ((vptr >> 12) && 0xFF);\n              returnOk (pt,unat pt_index)\n         odE)\n        | _ \\<Rightarrow> Monads_D.throw)\n    odE\"\n\ndefinition\n  cdl_find_pd_for_asid :: \"cdl_mapped_addr \\<Rightarrow> cdl_object_id except_monad\"\nwhere\n  \"cdl_find_pd_for_asid maddr \\<equiv> doE\n     asid_table \\<leftarrow> liftE $ gets cdl_asid_table;\n     asid_pool \\<leftarrow> returnOk $ asid_table (fst (fst maddr));\n     pd_cap_ref \\<leftarrow> (case asid_pool of Some (AsidPoolCap ptr _) \\<Rightarrow> returnOk (ptr, (snd \\<circ> fst) maddr)\n              | _ \\<Rightarrow> throw );\n     pd_cap \\<leftarrow> liftE $ get_cap pd_cap_ref;\n     case pd_cap of (PageDirectoryCap pd _ _) \\<Rightarrow> returnOk pd\n     | _ \\<Rightarrow> throw\n   odE \"\n\ndefinition cdl_page_mapping_entries :: \"32 word \\<Rightarrow> nat \\<Rightarrow> 32 word\n                                       \\<Rightarrow> ((32 word \\<times> nat) list) except_monad\"\n  where \"cdl_page_mapping_entries vptr pgsz pd \\<equiv>\n  if pgsz = 12 then doE\n    p \\<leftarrow> cdl_lookup_pt_slot pd vptr;\n         returnOk [p]\n    odE\n\n  else if pgsz = 16 then doE\n    p \\<leftarrow> cdl_lookup_pt_slot pd vptr;\n         returnOk [p]\n    odE\n  else if pgsz = 20 then doE\n    p \\<leftarrow> returnOk $ (cdl_lookup_pd_slot pd vptr);\n         returnOk [p]\n    odE\n  else if pgsz = 24 then doE\n    p \\<leftarrow> returnOk $ (cdl_lookup_pd_slot pd vptr);\n         returnOk [p]\n    odE\n  else throw\"\n\ndefinition\n  cdl_page_table_mapped :: \"cdl_mapped_addr \\<Rightarrow> cdl_object_id \\<Rightarrow> (cdl_cap_ref option) k_monad\"\nwhere\n  \"cdl_page_table_mapped maddr pt_id \\<equiv> doE\n     pd \\<leftarrow> cdl_find_pd_for_asid maddr;\n     pd_slot \\<leftarrow> returnOk (cdl_lookup_pd_slot pd (snd maddr));\n     pdcap \\<leftarrow> liftE $ cdl_get_pde pd_slot;\n     (case pdcap of\n       cdl_cap.PageTableCap ref Fake None \\<Rightarrow>\n         (returnOk $ if ref = pt_id then Some pd_slot else None)\n     | _ \\<Rightarrow> returnOk None )\n   odE <catch> (K (return None))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Frame: Unmaps a specified frame from the given address, removing its associated page table entries. The operation involves finding the appropriate page directory, identifying the relevant page table slots, and deleting the capabilities in those slots.",
    "input": "",
    "output": "definition\n \"might_throw \\<equiv> (returnOk ()) \\<sqinter> throw\"\n\ndefinition\n  unmap_page :: \"cdl_mapped_addr  \\<Rightarrow> cdl_object_id \\<Rightarrow> nat \\<Rightarrow> unit k_monad\"\nwhere\n  \"unmap_page maddr frame_id pgsz \\<equiv>\n    doE\n      pd \\<leftarrow> cdl_find_pd_for_asid maddr;\n      pslots \\<leftarrow> cdl_page_mapping_entries (snd maddr) pgsz pd;\n      might_throw;\n      liftE $ mapM_x delete_cap_simple pslots;\n      returnOk ()\n    odE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page Table: Unmaps a specified page table from a given memory address. If the page table is found, it is removed; otherwise, no action is taken.",
    "input": "",
    "output": "definition\n  unmap_page_table  :: \"cdl_mapped_addr \\<Rightarrow> cdl_object_id  \\<Rightarrow> unit k_monad\"\nwhere\n  \"unmap_page_table maddr pt_id\\<equiv>\n    do\n      pt_slot \\<leftarrow> cdl_page_table_mapped maddr pt_id;\n      case pt_slot of (Some slot) \\<Rightarrow> delete_cap_simple slot\n      | None \\<Rightarrow> return ()\n    od\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "High-Level Type Definitions: Introduces the fundamental types and structures used in the CapDL specification, providing a foundation for defining and manipulating system components and their interactions.",
    "input": "",
    "output": "(*\n * CapDL Types\n *\n * This file introduces many of the high-level types used in this\n * specification.\n *)\n\ntheory Types_D\nimports\n  \"ASpec.VMRights_A\"\n  Intents_D\n  \"Lib.Lib\"\n  \"Lib.SplitRule\"\n  \"HOL-Combinatorics.Transposition\" (* for Fun.swap *)\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware IRQ Number: Represents a hardware interrupt request number, used to identify specific hardware interrupts in the system.",
    "input": "",
    "output": "type_synonym cdl_irq = irq",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Naming: Objects within the kernel are named using 32-bit words, which may correspond to the memory addresses of the objects.",
    "input": "",
    "output": "type_synonym cdl_object_id = word32\n\ntype_synonym cdl_object_set = \"(cdl_object_id set)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Endpoint Badge: Represents a 32-bit value used to identify or tag an endpoint, enabling unique identification and management within the system.",
    "input": "",
    "output": "type_synonym cdl_badge = word32",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Cap Guard: Defines a guard for a CNode capability, represented as a 32-bit word, and specifies the number of bits used by the guard.",
    "input": "",
    "output": "type_synonym cdl_cap_guard = word32\ntype_synonym cdl_cap_guard_size = nat",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Size Representation: Represents the size of objects using natural numbers.",
    "input": "",
    "output": "type_synonym cdl_size_bits = nat",
    "system": "",
    "history": []
  },
  {
    "instruction": "IA32 IO Port: Represents a single IO port in the IA32 architecture, identified by a natural number.",
    "input": "",
    "output": "type_synonym cdl_io_port = nat",
    "system": "",
    "history": []
  },
  {
    "instruction": "Pagetable Depth: Defines the depth of an IA32 pagetable, representing the number of levels in the pagetable structure.",
    "input": "",
    "output": "type_synonym cdl_io_pagetable_level = nat",
    "system": "",
    "history": []
  },
  {
    "instruction": "Index for Kernel Object Capabilities: A natural number used as an index to reference capabilities within a CNode, TCB, or other kernel objects.",
    "input": "",
    "output": "type_synonym cdl_cnode_index = nat",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Slot Reference: Represents a reference to a specific capability slot, identified by an object ID and a CNode index.",
    "input": "",
    "output": "type_synonym cdl_cap_ref = \"cdl_object_id \\<times> cdl_cnode_index\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual ASID Representation: A virtual ASID is represented as a pair of CDL cnode indices, allowing for the identification and management of address spaces within the system.",
    "input": "",
    "output": "type_synonym cdl_asid = \"cdl_cnode_index \\<times> cdl_cnode_index\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Mapped Address: Represents a mapped address in the system, consisting of an ASID (Address Space Identifier) and a 32-bit word. This allows for the identification and management of memory mappings within the context of a specific address space.",
    "input": "",
    "output": "type_synonym cdl_mapped_addr = \"(cdl_asid \\<times> word32)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Badge Bit Count: Defines the number of bits available for a badge, which is 28 bits.",
    "input": "",
    "output": "definition\n  badge_bits :: nat\nwhere\n  \"badge_bits \\<equiv> 28\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Frame and Page Table Capabilities: Frame, page table, and page directory capabilities can be either real or fake. Real capabilities are installed in CNodes, while fake capabilities represent a page table mapping.",
    "input": "",
    "output": "datatype cdl_frame_cap_type = Real | Fake",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Capabilities: Define the structure of capabilities, which include attributes such as the object they point to, the rights they confer to the holder, and the allowed interactions with the target object.",
    "input": "",
    "output": "datatype cdl_cap =\n    NullCap",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Object Capabilities: Define various types of capabilities that grant permissions and access rights to different kernel objects, including untyped memory, endpoints, notifications, reply slots, CNodes, TCBs, and domains. These capabilities ensure controlled and secure access to the underlying resources.",
    "input": "",
    "output": "| UntypedCap bool cdl_object_set cdl_object_set\n  | EndpointCap cdl_object_id cdl_badge \"cdl_right set\"\n  | NotificationCap cdl_object_id cdl_badge \"cdl_right set\"\n  | ReplyCap cdl_object_id \"cdl_right set\" (* The id of the tcb of the target thread *)\n  | MasterReplyCap cdl_object_id\n  | CNodeCap cdl_object_id cdl_cap_guard cdl_cap_guard_size cdl_size_bits\n  | TcbCap cdl_object_id\n  | DomainCap",
    "system": "",
    "history": []
  },
  {
    "instruction": "Pending Synchronous Send Capability: Represents a pending synchronous send operation with associated properties including the object ID, badge, and flags indicating whether it is a call, can grant, can grant reply, and if it is a fault IPC.",
    "input": "",
    "output": "| PendingSyncSendCap cdl_object_id cdl_badge bool bool bool bool",
    "system": "",
    "history": []
  },
  {
    "instruction": "Pending Synchronization and Notification Capabilities: A thread can be in a state where it is waiting for a reply, during which it can grant synchronization or notification capabilities.",
    "input": "",
    "output": "| PendingSyncRecvCap cdl_object_id bool bool\n  | PendingNtfnRecvCap cdl_object_id",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread State Indication: The thread is marked as ready for rescheduling, indicating that it is either in a state to restart or is currently running.",
    "input": "",
    "output": "| RestartCap\n  | RunningCap",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Capabilities: Define two types of interrupt capabilities, `IrqControlCap` for controlling interrupts and `IrqHandlerCap` for handling specific interrupts identified by `cdl_irq`.",
    "input": "",
    "output": "| IrqControlCap\n  | IrqHandlerCap cdl_irq",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Memory Capabilities: Define various types of capabilities for managing virtual memory, including frame, page table, and page directory capabilities, each with specific attributes such as object IDs, rights, and mapped addresses. Additionally, include control capabilities for ASID and ASID pools, which manage address space identifiers and their associated cnode indices.",
    "input": "",
    "output": "| FrameCap bool cdl_object_id \"cdl_right set\" nat cdl_frame_cap_type \"cdl_mapped_addr option\"\n  | PageTableCap cdl_object_id cdl_frame_cap_type \"cdl_mapped_addr option\"\n  | PageDirectoryCap cdl_object_id cdl_frame_cap_type \"cdl_asid option\"\n  | AsidControlCap\n  | AsidPoolCap cdl_object_id \"cdl_cnode_index\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "X86-Specific Capabilities: Define capabilities specific to the x86 architecture, including I/O port sets, I/O space master, I/O space, and I/O page table. These capabilities enable fine-grained control over I/O operations and memory management in the x86 environment.",
    "input": "",
    "output": "| IOPortsCap cdl_object_id \"cdl_io_port set\"\n  | IOSpaceMasterCap\n  | IOSpaceCap cdl_object_id\n  | IOPageTableCap cdl_object_id",
    "system": "",
    "history": []
  },
  {
    "instruction": "Zombie Capabilities: Represent objects that are in the process of being deleted, maintaining a reference to the object ID to ensure proper cleanup and resource management.",
    "input": "",
    "output": "| ZombieCap cdl_object_id",
    "system": "",
    "history": []
  },
  {
    "instruction": "Bound Notification Capability: Represents a capability that signifies a TCB is bound to a notification, allowing the TCB to receive and handle notifications.",
    "input": "",
    "output": "| BoundNotificationCap cdl_object_id",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Mapping: Provides a mapping from capability identifiers to their corresponding capabilities, allowing for efficient lookup and management of capabilities within the system.",
    "input": "",
    "output": "type_synonym cdl_cap_map = \"cdl_cnode_index \\<Rightarrow> cdl_cap option\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Derivation Tree (CDT): Records the derivation relationships between capabilities, where each capability may have a parent capability. This structure is crucial for managing capability revocation, as revoking a parent capability automatically revokes all its derived (child) capabilities.",
    "input": "",
    "output": "type_synonym cdl_cdt = \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref option\"\n\ntranslations\n  (type) \"cdl_cap_map\" <=(type) \"nat \\<Rightarrow> cdl_cap option\"\n  (type) \"cdl_cap_ref\" <=(type) \"cdl_object_id \\<times> nat\"\n  (type) \"cdl_cap_ref\" <=(type) \"word32 \\<times> nat\"\n  (type) \"cdl_cdt\"     <=(type) \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref option\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Object Structures: Define the structure of various kernel objects, each containing a capability map and additional specific attributes. These structures include TCBs with fault handling and domain information, CNodes with size bits, ASID pools, page tables, page directories, frames with size bits, and IRQ nodes.",
    "input": "",
    "output": "record cdl_tcb =\n  cdl_tcb_caps           :: cdl_cap_map\n  cdl_tcb_fault_endpoint :: cdl_cptr\n  cdl_tcb_intent         :: cdl_full_intent\n  cdl_tcb_has_fault      :: bool\n  cdl_tcb_domain         :: word8\n\nrecord cdl_cnode =\n  cdl_cnode_caps :: cdl_cap_map\n  cdl_cnode_size_bits :: cdl_size_bits\n\nrecord cdl_asid_pool =\n  cdl_asid_pool_caps :: cdl_cap_map\n\nrecord cdl_page_table =\n  cdl_page_table_caps :: cdl_cap_map\n\nrecord cdl_page_directory =\n  cdl_page_directory_caps :: cdl_cap_map\n\nrecord cdl_frame =\n  cdl_frame_size_bits :: cdl_size_bits\n\nrecord cdl_irq_node =\n  cdl_irq_node_caps :: cdl_cap_map",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Objects: Define a set of in-memory objects that can be created or deleted by users, including endpoints, notifications, threads (TCBs), capability nodes (CNodes), ASID pools, page tables, page directories, frames, untyped memory, and IRQ nodes.",
    "input": "",
    "output": "datatype cdl_object =\n    Endpoint\n  | Notification\n  | Tcb cdl_tcb\n  | CNode cdl_cnode\n  | AsidPool cdl_asid_pool\n  | PageTable cdl_page_table\n  | PageDirectory cdl_page_directory\n  | Frame cdl_frame\n  | Untyped\n  | IRQNode cdl_irq_node",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture Definition: Specifies the supported architectures, including IA32 and ARM11, for the system model.",
    "input": "",
    "output": "datatype cdl_arch = IA32 | ARM11",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Object Mapping: Represents a mapping of object identifiers to their corresponding objects within the system, allowing for the tracking and management of all objects present in the system.",
    "input": "",
    "output": "type_synonym cdl_heap = \"cdl_object_id \\<Rightarrow> cdl_object option\"\n\ntranslations\n  (type) \"cdl_heap\" <=(type) \"32 word \\<Rightarrow> cdl_object option\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "System State Representation: The system state is represented by a record that includes the architecture, existing objects, capability derivation tree, current thread, IRQ to notification mappings, ASID table, and current domain. This comprehensive state record ensures that all essential information about the system's configuration and runtime status is accessible and manageable.",
    "input": "",
    "output": "record cdl_state =\n  cdl_arch           :: cdl_arch\n  cdl_objects        :: cdl_heap\n  cdl_cdt            :: cdl_cdt\n  cdl_current_thread :: \"cdl_object_id option\"\n  cdl_irq_node       :: \"cdl_irq \\<Rightarrow> cdl_object_id\"\n  cdl_asid_table     :: cdl_cap_map\n  cdl_current_domain :: word8",
    "system": "",
    "history": []
  },
  {
    "instruction": "Determine Object Type: Identify the type of a given object, such as Untyped, Endpoint, Notification, TCB, CNode, IRQNode, AsidPool, PageTable, PageDirectory, or Frame, based on its definition.",
    "input": "",
    "output": "definition\n  object_type :: \"cdl_object \\<Rightarrow> cdl_object_type\"\nwhere\n  \"object_type x \\<equiv>\n    case x of\n        Untyped \\<Rightarrow> UntypedType\n      | Endpoint \\<Rightarrow> EndpointType\n      | Notification \\<Rightarrow> NotificationType\n      | Tcb _ \\<Rightarrow> TcbType\n      | CNode _ \\<Rightarrow> CNodeType\n      | IRQNode _ \\<Rightarrow> IRQNodeType\n      | AsidPool _ \\<Rightarrow> AsidPoolType\n      | PageTable _ \\<Rightarrow> PageTableType\n      | PageDirectory _ \\<Rightarrow> PageDirectoryType\n      | Frame f \\<Rightarrow> FrameType (cdl_frame_size_bits f)\"\n\nlemmas object_type_simps = object_type_def[split_simps cdl_object.split]\n\ndefinition\n  asid_high_bits :: nat where\n  \"asid_high_bits \\<equiv> 7\"\ndefinition\n  asid_low_bits :: nat where\n  \"asid_low_bits \\<equiv> 10 :: nat\"\ndefinition\n  asid_bits :: nat where\n  \"asid_bits \\<equiv> 17 :: nat\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "TCB Cap Slot Definitions: Each TCB contains a set of cap slots, each with a specific purpose, such as cspace, vspace, reply cap, caller cap, IPC buffer, pending operation, and bound notification. These slots are defined by constants and organized in a list to ensure consistent and predictable behavior in the system.",
    "input": "",
    "output": "definition \"tcb_cspace_slot     = (0 :: cdl_cnode_index)\"\ndefinition \"tcb_vspace_slot     = (1 :: cdl_cnode_index)\"\ndefinition \"tcb_replycap_slot   = (2 :: cdl_cnode_index)\"\ndefinition \"tcb_caller_slot     = (3 :: cdl_cnode_index)\"\ndefinition \"tcb_ipcbuffer_slot  = (4 :: cdl_cnode_index)\"\ndefinition \"tcb_pending_op_slot = (5 :: cdl_cnode_index)\"\ndefinition \"tcb_boundntfn_slot  = (8 :: cdl_cnode_index)\"\n\ndefinition \"tcb_slots_list \\<equiv> [0..<tcb_pending_op_slot + 1] @ [tcb_boundntfn_slot]\"\nabbreviation \"tcb_slots \\<equiv> set tcb_slots_list\"\nlemmas tcb_slots_def = tcb_slots_list_def\n\nlemmas tcb_slot_defs =\n  tcb_cspace_slot_def\n  tcb_vspace_slot_def\n  tcb_replycap_slot_def\n  tcb_caller_slot_def\n  tcb_ipcbuffer_slot_def\n  tcb_pending_op_slot_def\n  tcb_boundntfn_slot_def\n  tcb_slots_list_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Management: Defines and manipulates various attributes of capabilities, including the associated objects, badges, rights, and guards. It allows for updating these attributes, ensuring that capabilities are correctly configured and managed within the system.",
    "input": "",
    "output": "primrec (nonexhaustive)\n  cap_objects :: \"cdl_cap \\<Rightarrow> cdl_object_id set\"\nwhere\n    \"cap_objects (IOPageTableCap x) = {x}\"\n  | \"cap_objects (IOSpaceCap x) = {x}\"\n  | \"cap_objects (IOPortsCap x _) = {x}\"\n  | \"cap_objects (AsidPoolCap x _) = {x}\"\n  | \"cap_objects (PageDirectoryCap x _ _) = {x}\"\n  | \"cap_objects (PageTableCap x _ _) = {x}\"\n  | \"cap_objects (FrameCap _ x _ _ _ _) = {x}\"\n  | \"cap_objects (TcbCap x) = {x}\"\n  | \"cap_objects (CNodeCap x _ _ _) = {x}\"\n  | \"cap_objects (MasterReplyCap x) = {x}\"\n  | \"cap_objects (ReplyCap x _) = {x}\"\n  | \"cap_objects (NotificationCap x _ _) = {x}\"\n  | \"cap_objects (EndpointCap x _ _) = {x}\"\n  | \"cap_objects (UntypedCap _ x a) = x\"\n  | \"cap_objects (ZombieCap x) = {x}\"\n  | \"cap_objects (PendingSyncSendCap x _ _ _ _ _) = {x}\"\n  | \"cap_objects (PendingSyncRecvCap x _ _) = {x}\"\n  | \"cap_objects (PendingNtfnRecvCap x) = {x}\"\n  | \"cap_objects (BoundNotificationCap x) = {x}\"\n\ndefinition\n  cap_has_object :: \"cdl_cap \\<Rightarrow> bool\"\nwhere\n  \"cap_has_object cap \\<equiv> case cap of\n     NullCap          \\<Rightarrow> False\n  | IrqControlCap    \\<Rightarrow> False\n  | IrqHandlerCap _  \\<Rightarrow> False\n  | AsidControlCap   \\<Rightarrow> False\n  | IOSpaceMasterCap \\<Rightarrow> False\n  | RestartCap       \\<Rightarrow> False\n  | RunningCap       \\<Rightarrow> False\n  | DomainCap        \\<Rightarrow> False\n  | _                \\<Rightarrow> True\"\n\ndefinition\n  cap_object :: \"cdl_cap \\<Rightarrow> cdl_object_id\"\nwhere\n  \"cap_object cap \\<equiv>\n     if cap_has_object cap\n     then (THE c. c \\<in> cap_objects cap)\n     else undefined\"\n\nlemma cap_object_simps[simp]:\n  \"cap_object (IOPageTableCap x) = x\"\n  \"cap_object (IOSpaceCap x) = x\"\n  \"cap_object (IOPortsCap x a) = x\"\n  \"cap_object (AsidPoolCap x b) = x\"\n  \"cap_object (PageDirectoryCap x c d) = x\"\n  \"cap_object (PageTableCap x e f) = x\"\n  \"cap_object (FrameCap dev x g h i j) = x\"\n  \"cap_object (TcbCap x) = x\"\n  \"cap_object (CNodeCap x k l sz) = x\"\n  \"cap_object (MasterReplyCap x) = x\"\n  \"cap_object (ReplyCap x q) = x\"\n  \"cap_object (NotificationCap x m n) = x\"\n  \"cap_object (EndpointCap x p q) = x\"\n  \"cap_object (ZombieCap x) = x\"\n  \"cap_object (PendingSyncSendCap x s t u v w) = x\"\n  \"cap_object (PendingSyncRecvCap x t u) = x\"\n  \"cap_object (PendingNtfnRecvCap x) = x\"\n  \"cap_object (BoundNotificationCap x) = x\"\n  by (simp_all add:cap_object_def Nitpick.The_psimp cap_has_object_def)\n\nprimrec (nonexhaustive) cap_badge :: \"cdl_cap \\<Rightarrow> cdl_badge\"\nwhere\n    \"cap_badge (NotificationCap _ x _) = x\"\n  | \"cap_badge (EndpointCap _ x _) = x\"\n\ndefinition\n  update_cap_badge :: \"cdl_badge \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"update_cap_badge x c \\<equiv> case c of\n      NotificationCap f1 _ f3 \\<Rightarrow> NotificationCap f1 x f3\n    | EndpointCap f1 _ f3      \\<Rightarrow> EndpointCap f1 x f3\n    | _ \\<Rightarrow> c\"\n\ndefinition all_cdl_rights :: \"cdl_right set\" where\n  \"all_cdl_rights = {Read, Write, Grant, GrantReply}\"\n\ndefinition\n  cap_rights :: \"cdl_cap \\<Rightarrow> cdl_right set\"\nwhere\n  \"cap_rights c \\<equiv> case c of\n      FrameCap _ _ x _ _ _ \\<Rightarrow> x\n    | NotificationCap _ _ x \\<Rightarrow> x\n    | EndpointCap _ _ x \\<Rightarrow> x\n    | ReplyCap _ x \\<Rightarrow> x\n    | _ \\<Rightarrow> all_cdl_rights\"\n\ndefinition\n  update_cap_rights :: \"cdl_right set \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"update_cap_rights r c \\<equiv> case c of\n      FrameCap dev f1 _ f2 f3 f4 \\<Rightarrow> FrameCap dev f1 (validate_vm_rights r) f2 f3 f4\n    | NotificationCap f1 f2 _ \\<Rightarrow> NotificationCap f1 f2 (r - {Grant, GrantReply})\n    | EndpointCap f1 f2 _ \\<Rightarrow> EndpointCap f1 f2 r\n    | ReplyCap f1 _ \\<Rightarrow> ReplyCap f1 (r - {Read, GrantReply} \\<union> {Write})\n    | _ \\<Rightarrow> c\"\n\ndefinition\n  update_mapping_cap_status :: \"cdl_frame_cap_type \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n \"update_mapping_cap_status r c \\<equiv> case c of\n      FrameCap dev f1 f2 f3 _ f4 \\<Rightarrow> FrameCap dev f1 f2 f3 r f4\n    | PageTableCap pt1 _ pt2 \\<Rightarrow> PageTableCap pt1 r pt2\n    | _ \\<Rightarrow> c\"\n\nprimrec (nonexhaustive) cap_guard :: \"cdl_cap \\<Rightarrow> cdl_cap_guard\"\nwhere\n  \"cap_guard (CNodeCap _ x _ _) = x\"\n\ndefinition\n  update_cap_guard :: \"cdl_cap_guard \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"update_cap_guard x c \\<equiv> case c of\n      CNodeCap f1 _ f3 f4 \\<Rightarrow> CNodeCap f1 x f3 f4\n    | _ \\<Rightarrow> c\"\n\nprimrec (nonexhaustive) cap_guard_size :: \"cdl_cap \\<Rightarrow> cdl_cap_guard_size\"\nwhere\n  \"cap_guard_size (CNodeCap _ _ x _ ) = x\"\n\ndefinition\n  cnode_cap_size :: \"cdl_cap \\<Rightarrow> cdl_size_bits\"\nwhere\n  \"cnode_cap_size cap \\<equiv> case cap of\n      CNodeCap _ _ _ x \\<Rightarrow> x\n    | _ \\<Rightarrow> 0\"\n\ndefinition\n  update_cap_guard_size :: \"cdl_cap_guard_size \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"update_cap_guard_size x c \\<equiv> case c of\n      CNodeCap f1 f2 _ f3 \\<Rightarrow> CNodeCap f1 f2 x f3\n    | _ \\<Rightarrow> c\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Object Management: Provides functions to get, update, and check the capability slots of different kernel objects, as well as manage free IDs and IRQs associated with capabilities. This ensures that the kernel can effectively manage and manipulate the capabilities and resources of various objects, maintaining system integrity and resource allocation.",
    "input": "",
    "output": "definition\n  object_slots :: \"cdl_object \\<Rightarrow> cdl_cap_map\"\nwhere\n  \"object_slots obj \\<equiv> case obj of\n    PageDirectory x \\<Rightarrow> cdl_page_directory_caps x\n  | PageTable x \\<Rightarrow> cdl_page_table_caps x\n  | AsidPool x \\<Rightarrow> cdl_asid_pool_caps x\n  | CNode x \\<Rightarrow> cdl_cnode_caps x\n  | Tcb x \\<Rightarrow> cdl_tcb_caps x\n  | IRQNode x \\<Rightarrow> cdl_irq_node_caps x\n  | _ \\<Rightarrow> Map.empty\"\n\ndefinition\n  update_slots :: \"cdl_cap_map \\<Rightarrow> cdl_object \\<Rightarrow> cdl_object\"\nwhere\n  \"update_slots new_val obj \\<equiv> case obj of\n    PageDirectory x \\<Rightarrow> PageDirectory (x\\<lparr>cdl_page_directory_caps := new_val\\<rparr>)\n  | PageTable x \\<Rightarrow> PageTable (x\\<lparr>cdl_page_table_caps := new_val\\<rparr>)\n  | AsidPool x \\<Rightarrow> AsidPool (x\\<lparr>cdl_asid_pool_caps := new_val\\<rparr>)\n  | CNode x \\<Rightarrow> CNode (x\\<lparr>cdl_cnode_caps := new_val\\<rparr>)\n  | Tcb x \\<Rightarrow> Tcb (x\\<lparr>cdl_tcb_caps := new_val\\<rparr>)\n  | IRQNode x \\<Rightarrow> IRQNode (x\\<lparr>cdl_irq_node_caps := new_val\\<rparr>)\n  | _ \\<Rightarrow> obj\"\n\ndefinition\n  has_slots :: \"cdl_object \\<Rightarrow> bool\"\nwhere\n  \"has_slots obj \\<equiv> case obj of\n    PageDirectory _ \\<Rightarrow> True\n  | PageTable _ \\<Rightarrow> True\n  | AsidPool _ \\<Rightarrow> True\n  | CNode _ \\<Rightarrow> True\n  | Tcb _ \\<Rightarrow> True\n  | IRQNode _ \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"\n\n\ndefinition\n  cap_free_ids :: \"cdl_cap \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"cap_free_ids cap \\<equiv> (case cap of\n     UntypedCap _ _ free_ids \\<Rightarrow> free_ids\n   | _ \\<Rightarrow> {})\"\n\ndefinition\n  remove_free_ids :: \"cdl_cap \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_cap\"\nwhere\n  \"remove_free_ids cap obj_ids \\<equiv> case cap of\n     UntypedCap dev c a \\<Rightarrow> UntypedCap dev c (a - obj_ids)\n   | _ \\<Rightarrow> cap\"\n\ndefinition cap_irq :: \"cdl_cap \\<Rightarrow> cdl_irq\"\nwhere\n  \"cap_irq cap \\<equiv> case cap of\n      IrqHandlerCap x \\<Rightarrow> x\n    | _ \\<Rightarrow> undefined\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Type Classification: Categorizes different types of capabilities, such as Untyped, Endpoint, Notification, TCB, CNode, ASID Pool, Page Table, Page Directory, Frame, and IRQ Node, based on their specific attributes. Each capability type is uniquely identified, and the type remains unchanged under certain updates like badge, rights, mapping status, and guard. Additionally, it identifies pending capabilities, which include PendingSyncRecv, PendingNtfnRecv, and PendingSyncSend.",
    "input": "",
    "output": "definition cap_type :: \"cdl_cap \\<Rightarrow> cdl_object_type option\"\nwhere\n  \"cap_type x \\<equiv> case x of\n    UntypedCap _ _ _         \\<Rightarrow> Some UntypedType\n  | EndpointCap _ _ _      \\<Rightarrow> Some EndpointType\n  | NotificationCap _ _ _ \\<Rightarrow> Some NotificationType\n  | TcbCap _               \\<Rightarrow> Some TcbType\n  | CNodeCap _ _ _ _       \\<Rightarrow> Some CNodeType\n  | AsidPoolCap _ _        \\<Rightarrow> Some AsidPoolType\n  | PageTableCap _ _ _     \\<Rightarrow> Some PageTableType\n  | PageDirectoryCap _ _ _ \\<Rightarrow> Some PageDirectoryType\n  | FrameCap _ _ _ f _ _     \\<Rightarrow> Some (FrameType f)\n  | IrqHandlerCap _        \\<Rightarrow> Some IRQNodeType\n  | _                      \\<Rightarrow> None \"\n\nabbreviation \"is_untyped_cap cap    \\<equiv> (cap_type cap = Some UntypedType)\"\nabbreviation \"is_ep_cap cap         \\<equiv> (cap_type cap = Some EndpointType)\"\nabbreviation \"is_ntfn_cap cap        \\<equiv> (cap_type cap = Some NotificationType)\"\nabbreviation \"is_tcb_cap cap        \\<equiv> (cap_type cap = Some TcbType)\"\nabbreviation \"is_cnode_cap cap      \\<equiv> (cap_type cap = Some CNodeType)\"\nabbreviation \"is_asidpool_cap cap   \\<equiv> (cap_type cap = Some AsidPoolType)\"\nabbreviation \"is_pt_cap cap         \\<equiv> (cap_type cap = Some PageTableType)\"\nabbreviation \"is_pd_cap cap         \\<equiv> (cap_type cap = Some PageDirectoryType)\"\nabbreviation \"is_frame_cap cap      \\<equiv> (\\<exists>sz. cap_type cap = Some (FrameType sz))\"\nabbreviation \"is_irqhandler_cap cap \\<equiv> (cap_type cap = Some IRQNodeType)\"\ndefinition   \"is_irqcontrol_cap cap \\<equiv> (cap = IrqControlCap)\"\n\nlemma cap_type_simps [simp]:\n  \"is_untyped_cap    (UntypedCap dev a a')\"\n  \"is_ep_cap         (EndpointCap b c d)\"\n  \"is_ntfn_cap        (NotificationCap e f g)\"\n  \"is_tcb_cap        (TcbCap h)\"\n  \"is_cnode_cap      (CNodeCap j k l m)\"\n  \"is_asidpool_cap   (AsidPoolCap n p)\"\n  \"is_pd_cap         (PageDirectoryCap r s t)\"\n  \"is_pt_cap         (PageTableCap u v w)\"\n  \"is_frame_cap      (FrameCap dev a1 a2 a3 a4 a5)\"\n  \"is_irqhandler_cap (IrqHandlerCap a6)\"\n  \"cap_type (FrameCap dev obj_id rights sz rs asid) = Some (FrameType sz)\"\n  by (clarsimp simp: cap_type_def)+\n\nabbreviation \"cap_has_type cap \\<equiv> (\\<exists>type. cap_type cap = Some type)\"\n\nlemma cap_type_update_cap_badge [simp]:\n  \"cap_type (update_cap_badge x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_badge_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_cap_rights [simp]:\n  \"cap_type (update_cap_rights x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_rights_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_mapping_cap_status [simp]:\n  \"cap_type (update_mapping_cap_status x cap) = cap_type cap\"\n  by (clarsimp simp: update_mapping_cap_status_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_cap_guard [simp]:\n  \"cap_type (update_cap_guard x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_guard_def cap_type_def split: cdl_cap.splits)\n\nlemma update_cap_guard_size [simp]:\n  \"cap_type (update_cap_guard_size x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_guard_size_def cap_type_def split: cdl_cap.splits)\n\n\n\ndefinition is_pending_cap :: \"cdl_cap \\<Rightarrow> bool\"\nwhere \"is_pending_cap c \\<equiv> case c of\n  PendingSyncRecvCap _ _ _ \\<Rightarrow> True\n  | PendingNtfnRecvCap _ \\<Rightarrow> True\n  | PendingSyncSendCap _ _ _ _ _ _ \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create an Empty Capability Map: Generate a capability map of a specified size, where all entries are initialized to NullCap.",
    "input": "",
    "output": "definition\n  empty_cap_map :: \"nat \\<Rightarrow> cdl_cap_map\"\nwhere\n  \"empty_cap_map sz \\<equiv> (\\<lambda>a. if a < 2^sz then (Some NullCap) else None)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Empty Node: Initialize an empty CNode or IRQ node with a specified size, where the CNode contains an empty capability map and the size in bits, and the IRQ node contains an empty capability map.",
    "input": "",
    "output": "definition\n  empty_cnode :: \"nat \\<Rightarrow> cdl_cnode\"\nwhere\n  \"empty_cnode sz = \\<lparr> cdl_cnode_caps = empty_cap_map sz, cdl_cnode_size_bits = sz \\<rparr>\"\n\ndefinition\n  empty_irq_node :: cdl_irq_node\nwhere\n  \"empty_irq_node \\<equiv> \\<lparr> cdl_irq_node_caps = empty_cap_map 0 \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Default TCB Initialization: Initialize a TCB with default values, including setting all capability slots to `NullCap`, fault endpoint to 0, intent fields to default values, and the domain to the specified current domain. This ensures that a newly created TCB is in a known, safe state.",
    "input": "",
    "output": "definition\n  default_tcb :: \"word8 \\<Rightarrow> cdl_tcb\"\nwhere\n  \"default_tcb current_domain = \\<lparr>\n    cdl_tcb_caps = \\<lambda>n. if n \\<in> tcb_slots then Some NullCap else None,\n    cdl_tcb_fault_endpoint = 0,\n    cdl_tcb_intent = \\<lparr>\n      cdl_intent_op = None,\n      cdl_intent_error = False,\n      cdl_intent_cap = 0,\n      cdl_intent_extras = [],\n      cdl_intent_recv_slot = None\n      \\<rparr>,\n    cdl_tcb_has_fault = False,\n    cdl_tcb_domain = current_domain\n    \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Default Object Construction: Construct a new object of the specified type with default properties, including setting up empty structures or specific default values as required by the object type.",
    "input": "",
    "output": "definition\n  default_object :: \"cdl_object_type \\<Rightarrow> nat \\<Rightarrow> word8 \\<Rightarrow> cdl_object option\"\nwhere\n  \"default_object x y current_domain \\<equiv>\n    case x of\n        UntypedType \\<Rightarrow> Some Untyped\n      | EndpointType \\<Rightarrow> Some Endpoint\n      | NotificationType \\<Rightarrow> Some Notification\n      | TcbType \\<Rightarrow> Some (Tcb (default_tcb current_domain))\n      | CNodeType \\<Rightarrow> Some (CNode (empty_cnode y))\n      | AsidPoolType \\<Rightarrow> Some (AsidPool \\<lparr> cdl_asid_pool_caps = empty_cap_map asid_low_bits \\<rparr>)\n      | PageTableType \\<Rightarrow> Some (PageTable \\<lparr> cdl_page_table_caps = empty_cap_map 8 \\<rparr>)\n      | PageDirectoryType \\<Rightarrow> Some (PageDirectory \\<lparr> cdl_page_directory_caps = empty_cap_map 12 \\<rparr>)\n      | FrameType sz \\<Rightarrow> Some (Frame \\<lparr> cdl_frame_size_bits = sz \\<rparr>)\n      | IRQNodeType \\<Rightarrow> Some (IRQNode empty_irq_node)\"\n\nabbreviation \"pick a \\<equiv> SOME x. x\\<in> a\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Default Capability Construction: Generate a default capability for a new object based on its type, a set of available object IDs, size in bits, and a device flag. The generated capability is tailored to the specific object type, ensuring it is correctly configured with the appropriate permissions and attributes.",
    "input": "",
    "output": "definition\n  default_cap :: \"cdl_object_type \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_size_bits \\<Rightarrow> bool \\<Rightarrow> cdl_cap\"\nwhere\n  \"default_cap t id_set sz dev \\<equiv>\n    case t of\n        EndpointType \\<Rightarrow> EndpointCap (pick id_set) 0 UNIV\n      | NotificationType \\<Rightarrow> NotificationCap (THE i. i \\<in> id_set) 0 {Read,Write}\n      | TcbType \\<Rightarrow> TcbCap (pick id_set)\n      | CNodeType \\<Rightarrow> CNodeCap (pick id_set) 0 0 sz\n      | IRQNodeType \\<Rightarrow> IrqHandlerCap undefined\n      | UntypedType \\<Rightarrow> UntypedCap dev id_set id_set\n      | AsidPoolType \\<Rightarrow> AsidPoolCap (pick id_set) 0\n      | PageTableType \\<Rightarrow> PageTableCap (pick id_set) Real None\n      | PageDirectoryType \\<Rightarrow> PageDirectoryCap (pick id_set) Real None\n      | FrameType frame_size \\<Rightarrow> FrameCap dev (pick id_set) {Read, Write} frame_size Real None\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Collect Runnable Threads: Identify and collect the set of all active threads in the system that are either running or ready to restart. Additionally, filter these threads based on their scheduling domain.",
    "input": "",
    "output": "definition\n  all_active_tcbs :: \"cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"all_active_tcbs state \\<equiv> {x \\<in> dom (cdl_objects state).\n      \\<exists> a. (cdl_objects state) x = Some (Tcb a)\n          \\<and> ( ((cdl_tcb_caps a) tcb_pending_op_slot) = (Some RunningCap) \\<or> ((cdl_tcb_caps a) tcb_pending_op_slot) = (Some RestartCap))}\"\n\ndefinition\n  active_tcbs_in_domain :: \"word8 \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"active_tcbs_in_domain domain state  = {x \\<in> dom (cdl_objects state).\n      \\<exists> a. (cdl_objects state) x = Some (Tcb a)\n          \\<and> ( ((cdl_tcb_caps a) tcb_pending_op_slot) = (Some RunningCap) \\<or> ((cdl_tcb_caps a) tcb_pending_op_slot) = (Some RestartCap))\n          \\<and> cdl_tcb_domain a = domain }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Switching: Switch the current thread to a specified target, updating the system state to reflect the new current thread.\n\nDomain Change: Randomly select a new domain and update the system state to set this as the current domain.",
    "input": "",
    "output": "definition\n  switch_to_thread :: \"cdl_object_id option \\<Rightarrow> unit k_monad\"\nwhere\n  \"switch_to_thread target \\<equiv>\n     modify (\\<lambda> t. t\\<lparr> cdl_current_thread := target \\<rparr>)\"\n\ndefinition\n  change_current_domain :: \"unit k_monad\"\nwhere\n  \"change_current_domain = do\n     next_domain \\<leftarrow> select UNIV;\n     modify      (\\<lambda>s. s\\<lparr> cdl_current_domain := next_domain \\<rparr>)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Scheduling Nondeterminism: The scheduling process is fully nondeterministic, allowing for the selection of any active thread within the current domain or switching to an idle state.",
    "input": "",
    "output": "definition\n  schedule :: \"unit k_monad\"\nwhere\n  \"schedule \\<equiv> do\n     change_current_domain;\n     next_domain \\<leftarrow> gets cdl_current_domain;\n     threads     \\<leftarrow> gets (active_tcbs_in_domain next_domain);\n     next_thread \\<leftarrow> select threads;\n     switch_to_thread (Some next_thread)\n   od \\<sqinter> do\n     change_current_domain;\n     switch_to_thread None\n   od\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "CSpace Operations: Define and manage the operations related to the capability space, ensuring the proper allocation, manipulation, and deallocation of capabilities within the system.",
    "input": "",
    "output": "(*\n * Operations on CSpace\n *)\n\ntheory CSpace_D\nimports\n  PageTableUnmap_D\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Has Children: Determines whether a given capability has any children by checking if there exists a child capability in the capability derivation table (CDT) that is associated with the parent.",
    "input": "",
    "output": "definition\n  has_children :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> bool\"\nwhere\n  \"has_children parent s = (\\<exists>child. is_cdt_parent s parent child)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure No Children: Verify that the given capability does not have any children in the CDT. If it does, an exception is thrown.",
    "input": "",
    "output": "definition\n  ensure_no_children :: \"cdl_cap_ref \\<Rightarrow> unit except_monad\"\nwhere\n  \"ensure_no_children x \\<equiv> doE\n     c \\<leftarrow> liftE $ gets (has_children x);\n     whenE c $ throw\n   odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure Slot Emptiness: Verify that the specified capability slot is empty, and if not, throw an exception.",
    "input": "",
    "output": "definition\n  ensure_empty :: \"cdl_cap_ref \\<Rightarrow> unit except_monad\"\nwhere\n  \"ensure_empty cap_ref \\<equiv> doE\n     cap \\<leftarrow> liftE $ get_cap cap_ref;\n     unlessE (cap = NullCap) $ throw\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Insert Orphan Capability: Insert a new capability into a specified slot, ensuring that the destination slot is empty (contains a NullCap) before the insertion. This guarantees that the new capability is added without a parent and does not overwrite an existing capability.",
    "input": "",
    "output": "definition\n  insert_cap_orphan :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"insert_cap_orphan new_cap dest_slot \\<equiv> do\n     old_cap \\<leftarrow> get_cap dest_slot;\n     assert (old_cap = NullCap);\n     set_cap dest_slot new_cap\n   od\"\n\n\n\nprimrec (nonexhaustive)\n  available_range :: \"cdl_cap \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"available_range (UntypedCap _ r available) = available\"\n\ndefinition\n  set_available_range :: \"cdl_cap \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_cap\"\nwhere\n  \"set_available_range cap nrange \\<equiv>\n    case cap of UntypedCap d r available \\<Rightarrow> UntypedCap d r nrange | _ \\<Rightarrow> cap\"\n\nlemmas set_avaiable_range_simps[simp] = set_available_range_def[split_simps cdl_cap.split]\n\ndefinition\n  set_untyped_cap_as_full :: \"cdl_cap \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_untyped_cap_as_full src_cap new_cap src_slot \\<equiv>\n  if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n     \\<and> cap_objects src_cap = cap_objects new_cap) then\n     (set_cap src_slot (set_available_range src_cap {}))\n     else return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Insert Cap Sibling: Insert a new capability as a sibling to an existing slot. The operation ensures that the destination slot is initially empty, updates the source and destination slots with the new capability, and sets the parent of the destination slot if it exists.",
    "input": "",
    "output": "definition\n  insert_cap_sibling :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"insert_cap_sibling new_cap src_slot dest_slot \\<equiv> do\n    src_cap \\<leftarrow> get_cap src_slot;\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_untyped_cap_as_full src_cap new_cap src_slot;\n    set_cap dest_slot new_cap;\n    p \\<leftarrow> gets $ opt_parent src_slot;\n    case p of\n      None \\<Rightarrow> return ()\n    | Some parent \\<Rightarrow> set_parent dest_slot parent\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Insert New Capability as Child: Insert a new capability into an object as a child, ensuring the destination slot is initially empty. The source capability is updated to reflect the new capability, and the parent-child relationship is established between the source and destination slots.",
    "input": "",
    "output": "definition\n  insert_cap_child :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"insert_cap_child new_cap src_slot dest_slot \\<equiv> do\n    src_cap \\<leftarrow> get_cap src_slot;\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_untyped_cap_as_full src_cap new_cap src_slot;\n    set_cap dest_slot new_cap;\n    set_parent dest_slot src_slot\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Delete ASID Pool: Remove the specified ASID pool from the ASID table, setting its entry to NullCap. This ensures that the ASID pool is no longer referenced and can be safely deallocated.",
    "input": "",
    "output": "definition\n  delete_asid_pool :: \"cdl_cnode_index \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"delete_asid_pool base ptr \\<equiv> do\n    asid_table \\<leftarrow> gets cdl_asid_table;\n    asid_table' \\<leftarrow> return $ asid_table (base \\<mapsto> NullCap);\n    modify (\\<lambda>s. s \\<lparr>cdl_asid_table := asid_table'\\<rparr>)\n  od \\<sqinter> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Delete ASID: Remove a specified ASID from the ASID table, deactivating the associated page directory in the process. If the ASID is found, it is replaced with a null capability; otherwise, the operation fails.",
    "input": "",
    "output": "definition\n  delete_asid :: \"cdl_asid \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"delete_asid asid pd \\<equiv> do\n    asid_table \\<leftarrow> gets cdl_asid_table;\n    case asid_table (fst asid) of\n       Some NullCap \\<Rightarrow> return ()\n     | Some (AsidPoolCap p _) \\<Rightarrow> set_cap (p, (snd asid)) NullCap\n     | _ \\<Rightarrow> fail\n  od \\<sqinter> return ()\"\n\ndefinition\n  get_irq_slot :: \"cdl_irq \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref\"\nwhere\n  \"get_irq_slot irq s \\<equiv> (cdl_irq_node s irq, 0)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Handler Deletion: Upon deleting an IRQ handler capability, the corresponding slot is cleared. Additionally, for a thread, any pending IPC operations are canceled by revoking related capabilities and setting the pending operation slot to `NullCap`. This ensures that the system maintains a consistent state after the deletion of an IRQ handler.",
    "input": "",
    "output": "definition\n  deleting_irq_handler :: \"cdl_irq \\<Rightarrow> unit k_monad\"\nwhere\n \"deleting_irq_handler irq \\<equiv>\n    gets (get_irq_slot irq) >>= delete_cap_simple\"\n\ndefinition\n  cancel_ipc ::\"cdl_object_id \\<Rightarrow> unit k_monad\"\n  where \"cancel_ipc ptr \\<equiv>\n  do cap \\<leftarrow> KHeap_D.get_cap (ptr,tcb_pending_op_slot);\n   (case cap of\n    PendingSyncRecvCap _ is_reply _ \\<Rightarrow> ( do\n     when is_reply $ update_thread_fault ptr (\\<lambda>x. False);\n     revoke_cap_simple (ptr,tcb_replycap_slot);\n     when (\\<not> is_reply) $ set_cap (ptr,tcb_pending_op_slot) NullCap\n     od )\n   | PendingSyncSendCap _ _ _ _ _ _ \\<Rightarrow> (do\n     revoke_cap_simple (ptr,tcb_replycap_slot);\n     set_cap (ptr,tcb_pending_op_slot) NullCap\n     od)\n   | PendingNtfnRecvCap _ \\<Rightarrow> (do\n     revoke_cap_simple (ptr,tcb_replycap_slot);\n     set_cap (ptr, tcb_pending_op_slot) NullCap\n     od)\n   | _ \\<Rightarrow> return ())\n  od\"\n\ndefinition\n  prepare_thread_delete ::\"cdl_object_id \\<Rightarrow> unit k_monad\"\n  where \"prepare_thread_delete ptr \\<equiv> return ()\" (* for ARM it does nothing *)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Finalization: Perform necessary actions when a capability is deleted, such as canceling IPC, unbinding notifications, and clearing IRQs. If the deletion requires a long-running operation, return a Zombie capability.",
    "input": "",
    "output": "fun\n  finalise_cap :: \"cdl_cap \\<Rightarrow> bool \\<Rightarrow> (cdl_cap \\<times> cdl_cap) k_monad\"\nwhere\n  \"finalise_cap NullCap                  final = return (NullCap, NullCap)\"\n| \"finalise_cap RestartCap               final = return (NullCap, NullCap)\"\n| \"finalise_cap (UntypedCap dev r a)           final = return (NullCap, NullCap)\"\n| \"finalise_cap (EndpointCap r b R)      final =\n      (liftM (K (NullCap, NullCap)) $ when  final $ cancel_all_ipc r)\"\n| \"finalise_cap (NotificationCap r b R) final =\n      (liftM (K (NullCap, NullCap)) $ when  final $\n       do\n         unbind_maybe_notification r;\n         cancel_all_ipc r\n       od)\"\n| \"finalise_cap (ReplyCap r R)           final = return (NullCap, NullCap)\"\n| \"finalise_cap (MasterReplyCap r)       final = return (NullCap, NullCap)\"\n| \"finalise_cap (CNodeCap r bits g sz)   final =\n      (return (if final then ZombieCap r else NullCap, NullCap))\"\n| \"finalise_cap (TcbCap r)               final =\n      (do\n         when final $ (do unbind_notification r;\n         cancel_ipc r;\n         KHeap_D.set_cap (r, tcb_pending_op_slot) cdl_cap.NullCap;\n         prepare_thread_delete r od);\n         return (if final then (ZombieCap r) else NullCap, NullCap)\n       od)\"\n| \"finalise_cap (PendingSyncSendCap r _ _ _ _ _) final = return (NullCap, NullCap)\"\n| \"finalise_cap (PendingSyncRecvCap r _ _) final = return (NullCap, NullCap)\"\n| \"finalise_cap (PendingNtfnRecvCap r)  final = return (NullCap, NullCap)\"\n| \"finalise_cap IrqControlCap            final = return (NullCap, NullCap)\"\n| \"finalise_cap (IrqHandlerCap irq)      final = (\n       if final then do\n         deleting_irq_handler irq;\n         return (NullCap, (IrqHandlerCap irq))\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (ZombieCap r)            final =\n      (do assert final; return (ZombieCap r, NullCap) od)\"\n| \"finalise_cap (AsidPoolCap ptr asid)        final = (\n       if final then do\n         delete_asid_pool asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap AsidControlCap           final = return (NullCap,NullCap)\"\n| \"finalise_cap (PageDirectoryCap ptr x (Some asid))   final = (\n       if final \\<and> x = Real then do\n         delete_asid asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (PageTableCap ptr x (Some asid))     final = (\n       if (final \\<and> x = Real) then do\n         unmap_page_table asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (FrameCap dev ptr _ s x (Some asid))       final = (\n       if x = Real then do\n         unmap_page asid ptr s;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap _ final = return (NullCap, NullCap)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fast Finalize Operation: Ensures that a capability is deleted when it is known that a long-running operation is impossible, by asserting the capability can be fast finalized and verifying the result of the finalization is a null capability.",
    "input": "",
    "output": "lemma fast_finalise_def2:\n  \"fast_finalise cap final = do\n     assert (can_fast_finalise cap);\n     result \\<leftarrow> finalise_cap cap final;\n     assert (result = (NullCap, NullCap))\n   od\"\n  unfolding can_fast_finalise_def\n  by (rule finalise_cap.cases[of \"(cap,final)\"]; simp add: assert_def liftM_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Atomic Cap Swap: Atomically swap the contents of two capability slots, ensuring that the operation is performed in a single, indivisible step to maintain system integrity.",
    "input": "",
    "output": "definition\n  swap_cap :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"swap_cap cap1 slot1 cap2 slot2 \\<equiv> do\n     set_cap slot1 cap2;\n     set_cap slot2 cap1;\n     swap_parents slot1 slot2\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Movement and Finalization: Enables the movement of a capability from one location to another, potentially modifying it in the process. It also supports the finalization and deletion of capabilities, ensuring that they are properly removed and their resources are freed, while handling zombie capabilities and maintaining system integrity.",
    "input": "",
    "output": "definition\n  move_cap :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"move_cap cap src_slot dest_slot \\<equiv> do\n     insert_cap_orphan cap dest_slot;\n     set_cap src_slot NullCap;\n     swap_parents src_slot dest_slot\n  od\"\n\ndefinition\n  monadic_rel_optionation_form :: \"('a \\<Rightarrow> ('s, 'b) nondet_monad)\n      \\<Rightarrow> (('a \\<times> 's) option \\<times> ('b \\<times> 's) option) set\"\nwhere\n \"monadic_rel_optionation_form f =\n    {(x, y). (x \\<noteq> None \\<and> y \\<noteq> None \\<and> the y \\<in> fst (case_prod f (the x)))\n           \\<or> (x \\<noteq> None \\<and> y = None \\<and> snd (case_prod f (the x)))\n           \\<or> (x = None \\<and> y = None)}\"\n\ndefinition\n  monadic_option_dest :: \"('a \\<times> 's) option set \\<Rightarrow> (('a \\<times> 's) set \\<times> bool)\"\nwhere\n \"monadic_option_dest S = (Some -` S, None \\<in> S)\"\n\nlemma use_option_form:\n  \"f x = (\\<lambda>s. monadic_option_dest  (monadic_rel_optionation_form f `` {Some (x, s)}))\"\n  by (simp add: monadic_rel_optionation_form_def monadic_option_dest_def)\n\nlemma ex_option: \" (\\<exists>x. P x) = ((\\<exists>y. P (Some y)) \\<or> P None)\"\n  apply safe\n  apply (case_tac x, auto)\n  done\n\nlemma use_option_form_bind:\n  \"f x >>= g = (\\<lambda>s. monadic_option_dest\n       ((monadic_rel_optionation_form f O monadic_rel_optionation_form g) `` {Some (x, s)}))\"\n  apply (rule ext)\n  apply (simp add: monadic_rel_optionation_form_def monadic_option_dest_def\n                   bind_def split_def)\n  apply (simp add: relcomp_unfold ex_option image_def prod_eq_iff Bex_def)\n  apply fastforce\n  done\n\ndefinition\n  monadic_trancl :: \"('a \\<Rightarrow> ('s, 'a) nondet_monad)\n       \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad\"\nwhere\n \"monadic_trancl f x = (\\<lambda>s. monadic_option_dest ((monadic_rel_optionation_form f)\\<^sup>* `` {Some (x, s)}))\"\n\ndefinition\n  monadic_trancl_preemptible ::\n     \"('a \\<Rightarrow> ('s, 'e + 'a) nondet_monad)\n         \\<Rightarrow> ('a \\<Rightarrow> ('s, 'e + 'a) nondet_monad)\"\nwhere\n \"monadic_trancl_preemptible f x\n    = monadic_trancl (lift f) (Inr x)\"\n\ndefinition\n  cap_removeable :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> bool\"\nwhere\n \"cap_removeable cap slot s =\n   (cap = NullCap\n      \\<or> (\\<exists>p. cap = ZombieCap p \\<and> swp opt_cap s ` (({p} \\<times> UNIV) - {slot})\n              \\<subseteq> {Some NullCap, None}))\"\n\ndefinition\n  finalise_slot_inner1 :: \"cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> bool) k_monad\"\nwhere\n \"finalise_slot_inner1 victim = do\n    cap \\<leftarrow> get_cap victim;\n    final \\<leftarrow> is_final_cap cap;\n    (cap', irqopt) \\<leftarrow> finalise_cap cap final;\n    removeable \\<leftarrow> gets $ cap_removeable cap' victim;\n    when (\\<not> removeable) (set_cap victim cap')\n        \\<sqinter> set_cap victim cap';\n    return (cap', removeable)\n  od\"\n\ndefinition\n  get_zombie_range :: \"cdl_cap \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n \"get_zombie_range cap =\n    (\\<lambda>s. case cap of ZombieCap p \\<Rightarrow> dom (swp opt_cap s) \\<inter> ({p} \\<times> UNIV)\n               | _ \\<Rightarrow> {})\"\n\ndefinition\n  swap_for_delete :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n \"swap_for_delete ptr1 ptr2 = do\n    cap1 \\<leftarrow> get_cap ptr1;\n    cap2 \\<leftarrow> get_cap ptr2;\n    swap_cap cap1 ptr1 cap2 ptr2\n  od\"\n\ndefinition\n \"finalise_slot_inner2 =\n      (\\<lambda>(region, finalised).\n        liftE (do (victim', remove) \\<leftarrow> select region;\n          (cap', removeable) \\<leftarrow> finalise_slot_inner1 victim';\n          region' \\<leftarrow> gets $ get_zombie_range cap';\n          return (region \\<union> (region' \\<times> {True}), if removeable then {(victim', remove)} else {})\n        od) \\<sqinter>\n        liftE (do (slot, slot') \\<leftarrow> select {(x, y). (x, True) \\<in> region \\<and> (y, True) \\<in> region \\<and> x \\<noteq> y};\n          swap_for_delete slot slot';\n          return (region, {})\n        od) \\<sqinter>\n        liftE (do victim' \\<leftarrow> select {x. (x, True) \\<in> finalised};\n          empty_slot victim';\n          return (region, {})\n        od) \\<sqinter>\n        throw\n      )\"\n\ndefinition\n  finalise_slot :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n \"finalise_slot victim = doE\n    (region, finalised) \\<leftarrow>\n      monadic_trancl_preemptible finalise_slot_inner2\n        ({(victim, False)}, {});\n    whenE (victim \\<notin> fst ` finalised) throw\n  odE\"\n\ndefinition\n  delete_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n \"delete_cap victim = doE\n    finalise_slot victim;\n    liftE $ empty_slot victim\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Revoke Cap and Descendants: Recursively revokes the given capability and all its descendants. If the capability being revoked is encountered during the process, an exception is thrown. This ensures that the capability and its entire lineage are removed from the system, maintaining the integrity of the capability hierarchy.",
    "input": "",
    "output": "definition\n  revoke_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"revoke_cap victim = doE\n     fin \\<leftarrow> monadic_trancl_preemptible (K (doE\n          S \\<leftarrow> liftE $ gets $ descendants_of victim;\n          if S = {} then returnOk True\n          else doE\n            child \\<leftarrow> liftE $ select S;\n            cap \\<leftarrow> liftE $ get_cap child;\n            assertE (cap \\<noteq> NullCap);\n            delete_cap child;\n            Monads_D.throw \\<sqinter> returnOk False\n          odE\n       odE)) False;\n     unlessE fin throw\n   odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Badge for IPC Send Operation: Obtain the badge used by a thread for its pending IPC send operation, if such an operation exists.",
    "input": "",
    "output": "definition\n  get_tcb_ep_badge :: \"cdl_tcb \\<Rightarrow> cdl_badge option\"\nwhere\n  \"get_tcb_ep_badge t \\<equiv>\n    case (cdl_tcb_caps t tcb_pending_op_slot) of\n      Some (PendingSyncSendCap _ badge _ _ _ _) \\<Rightarrow> Some badge\n    | _ \\<Rightarrow> None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel Badged Sends: Cancels all pending send operations to a specified endpoint that are using a specific badge. This ensures that any blocked threads associated with the given endpoint and badge are unblocked and their pending operations are removed.",
    "input": "",
    "output": "definition\n  cancel_badged_sends :: \"cdl_object_id \\<Rightarrow> cdl_badge \\<Rightarrow> unit k_monad\"\nwhere\n  \"cancel_badged_sends ep badge \\<equiv>\n    modify (\\<lambda>s. s\\<lparr>cdl_objects := map_option\n        (\\<lambda>obj. case obj of\n            Tcb t \\<Rightarrow>\n              if (is_thread_blocked_on_endpoint t ep\n                  \\<and> get_tcb_ep_badge t = Some badge) then\n                    Tcb (remove_pending_operation t cdl_cap.RestartCap)\n              else\n                Tcb t\n          | _ \\<Rightarrow> obj) \\<circ> (cdl_objects s)\\<rparr>)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Recycle and Reset: The target object is reset to its initial state, with any children capabilities first being revoked. The process involves clearing the object's capabilities, resetting memory mappings, and merging the object with a default template to restore its initial configuration.",
    "input": "",
    "output": "definition\n  clear_object_caps :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n \"clear_object_caps ptr = do\n    ptrs \\<leftarrow> gets (\\<lambda>s. {cptr. fst cptr = ptr \\<and> opt_cap cptr s \\<noteq> None});\n    ptrlist \\<leftarrow> select {xs. set xs = ptrs \\<and> distinct xs};\n    mapM_x empty_slot ptrlist\n  od\"\n\ndefinition cdl_default_tcb :: \"cdl_object\"\nwhere \"cdl_default_tcb \\<equiv>  Tcb \\<lparr>cdl_tcb_caps =\n           [tcb_cspace_slot \\<mapsto> cdl_cap.NullCap, tcb_vspace_slot \\<mapsto> cdl_cap.NullCap, tcb_replycap_slot \\<mapsto>\n            cdl_cap.NullCap, tcb_caller_slot \\<mapsto> cdl_cap.NullCap, tcb_ipcbuffer_slot \\<mapsto> cdl_cap.NullCap,\n            tcb_pending_op_slot \\<mapsto> cdl_cap.NullCap, tcb_boundntfn_slot \\<mapsto> cdl_cap.NullCap],\n           cdl_tcb_fault_endpoint = 0,\n           cdl_tcb_intent =\n             \\<lparr>cdl_intent_op = None, cdl_intent_error = False,cdl_intent_cap = 0, cdl_intent_extras = [],\n                cdl_intent_recv_slot = None\\<rparr>, cdl_tcb_has_fault = False, cdl_tcb_domain = minBound\\<rparr>\"\n\ndefinition obj_tcb :: \"cdl_object \\<Rightarrow> cdl_tcb\"\nwhere \"obj_tcb obj \\<equiv> case obj of Tcb tcb \\<Rightarrow> tcb\"\n\ndefinition tcb_caps_merge :: \"cdl_tcb \\<Rightarrow> cdl_tcb \\<Rightarrow> cdl_tcb\"\n  where \"tcb_caps_merge regtcb captcb \\<equiv> regtcb\\<lparr>cdl_tcb_caps\n  := (cdl_tcb_caps captcb)(tcb_pending_op_slot \\<mapsto> the (cdl_tcb_caps regtcb tcb_pending_op_slot), tcb_boundntfn_slot \\<mapsto> the (cdl_tcb_caps regtcb tcb_boundntfn_slot))\\<rparr>\"\n\ndefinition merge_with_dft_tcb :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere \"merge_with_dft_tcb o_id \\<equiv>\n do\n  new_intent \\<leftarrow> select UNIV;\n  KHeap_D.update_thread o_id (cdl_tcb_intent_update (\\<lambda>x. new_intent) \\<circ> (tcb_caps_merge (obj_tcb cdl_default_tcb)))\n od\"\n\nfun\n  reset_mem_mapping :: \"cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"reset_mem_mapping (FrameCap dev p rts sz b mp) = FrameCap dev p rts sz b None\"\n| \"reset_mem_mapping (PageTableCap ptr b mp) = PageTableCap ptr b None\"\n| \"reset_mem_mapping (PageDirectoryCap ptr b ma) = PageDirectoryCap ptr b None\"\n| \"reset_mem_mapping cap = cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Address Resolution: Resolve a user's capability pointer (CPTR) into a corresponding capability slot by walking through the CSpace, ensuring that the guard and remaining bits are correctly matched at each level. This process validates the CPTR and retrieves the final cap slot, ensuring the integrity and correctness of the capability lookup.",
    "input": "",
    "output": "function\n  resolve_address_bits ::\n  \"cdl_cap \\<Rightarrow> cdl_cptr \\<Rightarrow> nat \\<Rightarrow> (cdl_cap_ref \\<times> nat) fault_monad\"\nwhere\n  \"resolve_address_bits cnode_cap cap_ptr remaining_size = doE\n    unlessE (is_cnode_cap cnode_cap) $ throw;\n\n    \\<comment> \\<open>Fetch the next level CNode.\\<close>\n    cnode \\<leftarrow> liftE $ get_cnode $ cap_object cnode_cap;\n    radix_size \\<leftarrow> returnOk $ cdl_cnode_size_bits cnode;\n    guard_size \\<leftarrow> returnOk $ cap_guard_size cnode_cap;\n    cap_guard  \\<leftarrow> returnOk $ cap_guard cnode_cap;\n    level_size \\<leftarrow> returnOk (radix_size + guard_size);\n    assertE (level_size \\<noteq> 0);\n\n    \\<comment> \\<open>Ensure the guard matches up.\\<close>\n    guard \\<leftarrow> returnOk $ (cap_ptr >> (remaining_size-guard_size)) && (mask guard_size);\n    unlessE (guard_size \\<le> remaining_size \\<and> guard = cap_guard) $ throw;\n\n    \\<comment> \\<open>Ensure we still enough unresolved bits left in our CPTR.\\<close>\n    whenE (level_size > remaining_size) $ throw;\n\n    \\<comment> \\<open>Find the next slot.\\<close>\n    offset \\<leftarrow> returnOk $ (cap_ptr >> (remaining_size-level_size)) && (mask radix_size);\n    slot \\<leftarrow> returnOk (cap_object cnode_cap, unat offset);\n    size_left \\<leftarrow> returnOk (remaining_size - level_size);\n    if (size_left = 0) then\n      returnOk (slot, 0)\n    else\n      doE\n        next_cap \\<leftarrow> liftE $ get_cap (slot);\n        if is_cnode_cap next_cap then\n          resolve_address_bits next_cap cap_ptr size_left\n        else\n          returnOk (slot, size_left)\n      odE\n  odE\"\n  by fastforce+\n\ntermination resolve_address_bits\n  apply (relation \"measure (\\<lambda>(a,b,c). c)\")\n  apply (auto simp: in_monad)\n  done\n\ndefinition\n  lookup_slot :: \"cdl_object_id \\<Rightarrow> cdl_cptr \\<Rightarrow> cdl_cap_ref fault_monad\"\nwhere\n  \"lookup_slot thread cptr \\<equiv>\n    doE\n      cspace_root \\<leftarrow> liftE $ get_cap (thread, tcb_cspace_slot);\n      (slot, _) \\<leftarrow> resolve_address_bits cspace_root cptr word_bits;\n      returnOk slot\n    odE\"\n\ndefinition\n  lookup_cap :: \"cdl_object_id \\<Rightarrow> cdl_cptr \\<Rightarrow> cdl_cap fault_monad\"\nwhere\n  \"lookup_cap thread cptr \\<equiv>\n    doE\n      slot \\<leftarrow> lookup_slot thread cptr;\n      liftE $ get_cap slot\n    odE\"\n\ndefinition\n  lookup_cap_and_slot :: \"cdl_object_id \\<Rightarrow> cdl_cptr \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) fault_monad\"\nwhere\n  \"lookup_cap_and_slot thread cptr \\<equiv>\n    doE\n      slot \\<leftarrow> lookup_slot thread cptr;\n      cap \\<leftarrow> liftE $ get_cap slot;\n      returnOk (cap, slot)\n    odE\"\n\ndefinition\n  lookup_slot_for_cnode_op :: \"cdl_cap \\<Rightarrow> cdl_cptr \\<Rightarrow> nat \\<Rightarrow> cdl_cap_ref except_monad\"\nwhere\n  \"lookup_slot_for_cnode_op croot cptr depth \\<equiv>\n    doE\n      whenE (depth < 1 \\<or> depth > word_bits) throw;\n      (slot, rem) \\<leftarrow> fault_to_except $ resolve_address_bits croot cptr depth;\n      if rem = 0 then returnOk slot else throw\n    odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Cap Badge: Modify the badge of a capability by applying a mask to the provided data, ensuring that only the bits that can be stored by the lower specifications are updated.",
    "input": "",
    "output": "definition\n  badge_update :: \"word32 \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"badge_update data cap \\<equiv> update_cap_badge (data && mask badge_bits) cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Capability Data: Transform a capability based on user request, interpreting the \"data\" word differently for various cap types. For Endpoint and Notification caps, update the badge if the current badge is 0 and preservation is not required. For CNode caps, update the guard and guard size based on the data, ensuring the new guard size does not exceed the word bits. Other cap types remain unchanged.",
    "input": "",
    "output": "definition\n  update_cap_data :: \"bool \\<Rightarrow> word32 \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap k_monad\"\nwhere\n  \"update_cap_data preserve data cap \\<equiv>\n    return $ case cap of\n        EndpointCap _ b _ \\<Rightarrow>\n          if b = 0 \\<and> \\<not> preserve then\n            badge_update data cap\n          else\n            NullCap\n      | NotificationCap _ b _ \\<Rightarrow>\n          if b = 0 \\<and> \\<not> preserve then\n            badge_update data cap\n          else\n            NullCap\n      | CNodeCap object guard guard_size sz \\<Rightarrow>\n          let\n            reserved_bits = 3;\n            guard_bits = 18;\n            guard_size_bits = 5;\n\n            new_guard_size = unat ((data >> reserved_bits) && mask guard_size_bits);\n            new_guard = (data >> (reserved_bits + guard_size_bits)) && mask (min (unat ((data >> reserved_bits) && mask guard_size_bits)) guard_bits)\n          in\n            if new_guard_size + sz > word_bits then NullCap else\n            (CNodeCap object new_guard new_guard_size sz)\n      | _ \\<Rightarrow> cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Derive Capabilities: Derives a new capability from an existing one, potentially returning a modified version or `NullCap` for certain types. For `FrameCap`, it clears the badge. For `PageTableCap` and `PageDirectoryCap`, it may throw an exception or return the original capability, reflecting the nondeterminism in their handling. Other capabilities are returned unchanged.",
    "input": "",
    "output": "definition\n  derive_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap except_monad\"\nwhere\n  \"derive_cap slot cap \\<equiv> case cap of\n     UntypedCap _ _ _ \\<Rightarrow> doE ensure_no_children slot; returnOk cap odE\n   | ReplyCap _ _ \\<Rightarrow> returnOk NullCap\n   | MasterReplyCap oref \\<Rightarrow> returnOk NullCap\n   | IrqControlCap \\<Rightarrow> returnOk NullCap\n   | ZombieCap _ \\<Rightarrow> returnOk NullCap\n   | FrameCap dev p r sz b x \\<Rightarrow> returnOk (FrameCap dev p r sz b None)\n   | PageTableCap _ _ _ \\<Rightarrow> throw \\<sqinter> returnOk cap\n   | PageDirectoryCap _ _ _ \\<Rightarrow> throw \\<sqinter> returnOk cap\n   | _ \\<Rightarrow> returnOk cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arbitrary TCB Corruption: Allows the modification of a TCB's IPC buffer or registers to an arbitrary new state, ensuring that the TCB's intent can be altered as needed.",
    "input": "",
    "output": "definition\n  corrupt_tcb_intent :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"corrupt_tcb_intent target_tcb \\<equiv>\n    do\n      new_intent \\<leftarrow> select UNIV;\n      update_thread target_tcb (\\<lambda>t. t\\<lparr>cdl_tcb_intent := new_intent\\<rparr>)\n    od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Basic Monads for capDL: Defines the fundamental monadic structures used in the capDL system, providing a foundation for handling non-determinism and verification conditions within the system.",
    "input": "",
    "output": "(*\n * The basic monads used in capDL\n *)\n\ntheory Monads_D\nimports\n  Types_D\n  Monads.Nondet_In_Monad\n  Monads.Nondet_VCG\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel State Monad: Represents a monadic computation in the kernel state, which can handle non-deterministic operations and specific error types including exceptions, preemptions, and faults.",
    "input": "",
    "output": "type_synonym 'a k_monad = \"(cdl_state, 'a) nondet_monad\"\n\ndatatype cdl_except_error = ExceptError\ndatatype cdl_preempt_error = PreemptError\ndatatype cdl_fault_error = FaultError",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling: Manages operations that may result in exceptions, providing a mechanism to handle errors without additional exception information.",
    "input": "",
    "output": "type_synonym 'a except_monad = \"(cdl_state, cdl_except_error + 'a) nondet_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling in Preemption: The preemption monad encapsulates operations that may result in a preemption error, providing a structured way to handle exceptions without additional error information.",
    "input": "",
    "output": "type_synonym 'a preempt_monad = \"(cdl_state, cdl_preempt_error + 'a) nondet_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling: The fault monad allows for the throwing of exceptions, where `throw` is used to signal an error by returning an undefined value. This mechanism ensures that errors can be propagated and handled within the system.",
    "input": "",
    "output": "type_synonym 'a fault_monad =  \"(cdl_state, cdl_fault_error + 'a) nondet_monad\"\n\nabbreviation\n  throw :: \"(cdl_state, 'a + 'b) nondet_monad\" where\n  \"throw == throwError undefined\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Preemption Point: Allow the system to preempt the current thread at a specified point, enabling the scheduler to potentially switch to a different thread.",
    "input": "",
    "output": "definition\n  preemption_point :: \"unit preempt_monad\" where\n \"preemption_point \\<equiv> throw \\<sqinter> returnOk ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unify Failure: Convert an exception monad with an arbitrary type into a new exception monad with a unit type, handling any failure by throwing a unit error.",
    "input": "",
    "output": "definition\n  unify_failure :: \"('f + 'a) k_monad \\<Rightarrow> (unit + 'a) k_monad\" where\n \"unify_failure m \\<equiv> handleE' m (\\<lambda>x. throwError ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Convert Fault Monad to Exception Monad: Transforms a fault monad into an exception monad by handling faults and throwing exceptions.",
    "input": "",
    "output": "definition\n  fault_to_except :: \"'a fault_monad \\<Rightarrow> 'a except_monad\"\nwhere\n  \"fault_to_except m \\<equiv> handleE' m (\\<lambda>x. throw)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-deterministic Selection: Select an item from a given set non-deterministically. If the set is empty, return `None`.",
    "input": "",
    "output": "definition\n  option_select :: \"'a set \\<Rightarrow> ('s, 'a option) nondet_monad\"\nwhere\n  \"option_select S \\<equiv>\n    if S = {} then\n      return None\n    else\n      select S >>= (\\<lambda>a. return (Some a))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Error Handling for Optional Values: Ensures that if the given object is 'None', an error is thrown; otherwise, the object is returned successfully.",
    "input": "",
    "output": "definition\n  throw_on_none :: \"'a option \\<Rightarrow> ('e + 'a) k_monad\"\nwhere\n  \"throw_on_none x \\<equiv>\n    case x of\n        None \\<Rightarrow> throw\n      | Some y \\<Rightarrow> returnOk y\"\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Invocation: Supports operations on capabilities within a CNode, including inserting, moving, revoking, deleting, rotating, saving, and canceling badged sends. These operations allow for the dynamic management of capabilities, ensuring flexibility and security in capability-based systems.\n\nUntyped Invocation: Enables re-typing of untyped memory regions into typed objects, specifying the type, size, and target locations. This allows for the creation and allocation of various object types from untyped memory, providing a flexible memory management system.\n\nTCB Invocation: Allows threads to perform actions such as suspending and resuming other threads, controlling thread settings, copying and reading/writing registers, and managing notifications. These actions ensure that threads can manage their state and capabilities effectively, maintaining the integrity and performance of the system.\n\nIRQ Control Invocation: Manages IRQ handlers by issuing, setting, and clearing them, with support for architecture-specific IRQ handling. This ensures that interrupt requests are handled efficiently and securely, allowing for proper system response to hardware events.\n\nIRQ Handler Invocation: Provides mechanisms to acknowledge, set, and clear IRQ handlers, ensuring that interrupts are managed correctly and the system can respond to hardware events in a timely and controlled manner.",
    "input": "",
    "output": "theory Invocations_D\nimports Types_D\nbegin\n\ndatatype cdl_cnode_invocation =\n    InsertCall cdl_cap cdl_cap_ref cdl_cap_ref\n  | MoveCall cdl_cap cdl_cap_ref cdl_cap_ref\n  | RevokeCall cdl_cap_ref\n  | DeleteCall cdl_cap_ref\n  | RotateCall cdl_cap cdl_cap cdl_cap_ref cdl_cap_ref cdl_cap_ref\n  | SaveCall cdl_cap_ref\n  | CancelBadgedSendsCall cdl_cap\n\ndatatype cdl_untyped_invocation =\n    Retype cdl_cap_ref\n        cdl_object_type cdl_size_bits \"cdl_cap_ref list\" bool nat\n\ndatatype cdl_tcb_invocation =\n    WriteRegisters cdl_object_id bool \"word32 list\" nat\n  | ReadRegisters cdl_object_id bool word32 nat\n  | CopyRegisters cdl_object_id cdl_object_id bool bool bool bool nat\n  | ThreadControl cdl_object_id cdl_cap_ref\n        \"cdl_cptr option\"\n        \"(cdl_cap \\<times> cdl_cap_ref) option\"\n        \"(cdl_cap \\<times> cdl_cap_ref) option\"\n        \"(cdl_cap \\<times> cdl_cap_ref) option\"\n  | Suspend cdl_object_id\n  | Resume cdl_object_id\n  | NotificationControl cdl_object_id \"cdl_object_id option\"\n  | SetTLSBase cdl_object_id\n\ndatatype arch_cdl_irq_control_invocation =\n    ARMIssueIrqHandler cdl_irq cdl_cap_ref cdl_cap_ref bool\n\ndatatype cdl_irq_control_invocation =\n    IssueIrqHandler cdl_irq cdl_cap_ref cdl_cap_ref\n  | ArchIssueIrqHandler arch_cdl_irq_control_invocation\n\ndatatype cdl_irq_handler_invocation =\n    AckIrq cdl_irq\n  | SetIrqHandler cdl_irq cdl_cap cdl_cap_ref\n  | ClearIrqHandler cdl_irq\n\ndatatype cdl_endpoint_invocation =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Notification Invocation: Allows the management of notifications, including setting a badge, granting, and replying to notifications. This ensures that threads can communicate and coordinate effectively through notification mechanisms.",
    "input": "",
    "output": "SyncMessage cdl_badge bool bool cdl_object_id\n\ndatatype cdl_notification_invocation =",
    "system": "",
    "history": []
  },
  {
    "instruction": "Signal Notification: A signal is associated with a badge (notification word) and a notification object, allowing for the delivery of notifications to specific objects with designated badges.",
    "input": "",
    "output": "Signal cdl_badge cdl_object_id\n\ndatatype cdl_reply_invocation =\n    ReplyMessage cdl_object_id cdl_cap_ref bool (* can grant *)\n\ndatatype cdl_page_table_invocation =",
    "system": "",
    "history": []
  },
  {
    "instruction": "PageTable Mapping: Establishes a mapping between a real page table capability and a target page directory slot, ensuring that the page table is correctly referenced and accessible within the memory hierarchy.",
    "input": "",
    "output": "PageTableMap cdl_cap cdl_cap cdl_cap_ref cdl_cap_ref",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Unmap Operation: Unmaps a page from the specified address in the page table, identified by the provided object ID and capability reference. This operation ensures that the page is no longer accessible through the given address, maintaining the integrity of the memory mapping.",
    "input": "",
    "output": "| PageTableUnmap \"cdl_mapped_addr option\"  cdl_object_id cdl_cap_ref\n\ndatatype cdl_asid_control_invocation =\n    MakePool cdl_cap cdl_cap_ref \"cdl_object_id set\" cdl_cap_ref nat\n\ndatatype cdl_asid_pool_invocation =\n    Assign cdl_asid cdl_cap_ref cdl_cap_ref\n\ndatatype flush =\n   Clean | Invalidate | CleanInvalidate | Unify\n\ndatatype cdl_page_invocation =\n    PageMap cdl_cap cdl_cap cdl_cap_ref \"cdl_cap_ref list\"\n  | PageUnmap \"cdl_mapped_addr option\" cdl_object_id \"cdl_cap_ref\" nat\n  | PageFlushCaches flush\n  | PageGetAddress\n\n\ndatatype cdl_page_directory_invocation =\n   PageDirectoryFlush  flush\n | PageDirectoryNothing\n\n\ndatatype cdl_domain_invocation =\n  SetDomain cdl_object_id word8\n\ndatatype cdl_invocation =\n    InvokeUntyped cdl_untyped_invocation\n  | InvokeEndpoint cdl_endpoint_invocation\n  | InvokeNotification cdl_notification_invocation\n  | InvokeReply cdl_reply_invocation\n  | InvokeTcb cdl_tcb_invocation\n  | InvokeDomain cdl_domain_invocation\n  | InvokeCNode cdl_cnode_invocation\n  | InvokeIrqControl cdl_irq_control_invocation\n  | InvokeIrqHandler cdl_irq_handler_invocation\n  | InvokePageTable cdl_page_table_invocation\n  | InvokePage cdl_page_invocation\n  | InvokePageDirectory cdl_page_directory_invocation\n  | InvokeAsidControl cdl_asid_control_invocation\n  | InvokeAsidPool cdl_asid_pool_invocation\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Accessor Functions for Objects and Caps: Provide methods to access and manipulate objects and capabilities within the kernel heap, ensuring that the system can effectively manage and interact with these entities.",
    "input": "",
    "output": "(*\n * Accessor functions for objects and caps.\n *)\n\ntheory KHeap_D\nimports Monads_D\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Object: Fetch an object from the heap based on its ID. The operation fails if the specified object does not exist.",
    "input": "",
    "output": "abbreviation\n  get_object :: \"cdl_object_id \\<Rightarrow> cdl_object k_monad\"\nwhere\n  \"get_object p \\<equiv> gets_the (\\<lambda>s. cdl_objects s p)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Heap Object Update: Set the value of a specified object in the heap to a given new object, updating the heap's state to reflect this change.",
    "input": "",
    "output": "definition\n  set_object :: \"cdl_object_id \\<Rightarrow> cdl_object \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_object p obj \\<equiv>\n    modify (\\<lambda>s. s \\<lparr> cdl_objects := (cdl_objects s) (p \\<mapsto> obj) \\<rparr> )\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Thread: Obtain the thread control block (TCB) from a given object pointer, ensuring that the object is indeed a TCB.",
    "input": "",
    "output": "definition\n  get_thread :: \"cdl_object_id \\<Rightarrow> cdl_tcb k_monad\"\nwhere\n  \"get_thread p \\<equiv>\n    do\n      t \\<leftarrow> get_object p;\n      case t of\n          Tcb tcb \\<Rightarrow> return tcb\n        | _ \\<Rightarrow> fail\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Thread Fault Status: Obtain the fault status of a thread from the given pointer, returning whether the thread has a fault.",
    "input": "",
    "output": "definition\n  get_thread_fault :: \"cdl_object_id \\<Rightarrow> bool k_monad\"\nwhere\n  \"get_thread_fault p \\<equiv>\n    do\n      t \\<leftarrow> get_object p;\n      case t of\n          Tcb tcb \\<Rightarrow> return (cdl_tcb_has_fault tcb)\n        | _ \\<Rightarrow> fail\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Update: Modify a thread's state on the heap by applying a function to its current state. This ensures that the thread's properties can be updated dynamically while maintaining the integrity of the system.",
    "input": "",
    "output": "definition\n  update_thread :: \"cdl_object_id \\<Rightarrow> (cdl_tcb \\<Rightarrow> cdl_tcb) \\<Rightarrow> unit k_monad\"\nwhere\n  \"update_thread p f \\<equiv>\n     do\n       t \\<leftarrow> get_object p;\n       case t of\n          Tcb tcb \\<Rightarrow> set_object p (Tcb (f tcb))\n       | _ \\<Rightarrow> fail\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Thread Fault: Modify the fault status of a thread by updating the `cdl_tcb_has_fault` field in the thread control block. This ensures that the thread's fault status is accurately reflected in the system.",
    "input": "",
    "output": "definition\n  update_thread_fault :: \"cdl_object_id \\<Rightarrow> (bool\\<Rightarrow>bool) \\<Rightarrow> unit k_monad\"\nwhere\n  \"update_thread_fault p f \\<equiv>\n     do\n       t \\<leftarrow> get_object p;\n       case t of\n          Tcb tcb \\<Rightarrow> set_object p (Tcb (tcb\\<lparr>cdl_tcb_has_fault := f (cdl_tcb_has_fault tcb)\\<rparr>))\n       | _ \\<Rightarrow> fail\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve CNode: Obtain a CNode from the given object pointer. If the object is not a CNode, the operation fails.",
    "input": "",
    "output": "definition\n  get_cnode :: \"cdl_object_id \\<Rightarrow> cdl_cnode k_monad\"\nwhere\n  \"get_cnode p \\<equiv>\n    do\n      t \\<leftarrow> get_object p;\n      case t of\n          CNode cnode \\<Rightarrow> return cnode\n        | _ \\<Rightarrow> fail\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Element by Index: Obtain an element from a list at a specified index, returning `None` if the index is out of bounds.",
    "input": "",
    "output": "definition\n  get_index :: \"'a list \\<Rightarrow> nat \\<Rightarrow> 'a option\"\nwhere\n  \"get_index a b \\<equiv>\n     if b < length a then\n       Some (a ! b)\n     else\n       None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Object Slots: Returns the slots of an object as a capability map. If the object does not exist or does not have any capabilities, it returns an empty map.",
    "input": "",
    "output": "definition\n  slots_of :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_map\"\nwhere\n  \"slots_of obj_id \\<equiv> \\<lambda>s.\n  case cdl_objects s obj_id of\n    None \\<Rightarrow> Map.empty\n  | Some obj \\<Rightarrow> object_slots obj\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Cap Option: Obtain the capability at the specified reference, returning `None` if the object or capability does not exist.",
    "input": "",
    "output": "definition\n  opt_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap option\"\nwhere\n  \"opt_cap \\<equiv> \\<lambda>(obj_id, slot) s. slots_of obj_id s slot\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve the Capability: Obtain the capability associated with a given capability reference.",
    "input": "",
    "output": "abbreviation\n  get_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_cap k_monad\" where\n  \"get_cap p \\<equiv> gets_the (opt_cap p)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Capability: Assign a capability to a specific slot in an object. The object must exist and have the necessary slots. If the object is a TCB and the slot being updated is the IPC buffer, the TCB's intent is reset if the capability changes.",
    "input": "",
    "output": "definition\n  set_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_cap \\<equiv> \\<lambda>(obj_id, slot) cap. do\n    obj \\<leftarrow> get_object obj_id;\n    assert (has_slots obj);\n    slots \\<leftarrow> return $ object_slots obj;\n    obj' \\<leftarrow> return $ update_slots (slots (slot \\<mapsto> cap)) obj;\n    obj'' \\<leftarrow> case obj' of\n              Tcb t \\<Rightarrow> if slot = tcb_ipcbuffer_slot \\<and> slots slot \\<noteq> Some cap then do\n                   intent' \\<leftarrow> select UNIV;\n                   return $ Tcb (t \\<lparr> cdl_tcb_intent := intent' \\<rparr>)\n                 od\n                 else return obj'\n             | _ \\<Rightarrow> return obj';\n    set_object obj_id obj''\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Parent Lookup: Retrieve the parent of a given capability reference from the capability descriptor table (CDT).",
    "input": "",
    "output": "definition\n  opt_parent :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref option\" where\n  \"opt_parent p \\<equiv> \\<lambda>s. cdl_cdt s p\"\n\nabbreviation\n  get_parent :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref k_monad\" where\n  \"get_parent p \\<equiv> gets_the (opt_parent p)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Cap Derivation: Establish a parent-child relationship for a capability reference, ensuring that the child does not already have a parent and updating the capability derivation table to reflect the new relationship.",
    "input": "",
    "output": "definition\n  set_parent :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\" where\n  \"set_parent child parent \\<equiv> do\n    cdt \\<leftarrow> gets cdl_cdt;\n    assert (cdt child = None);\n    modify (\\<lambda>s. s \\<lparr> cdl_cdt := (cdl_cdt s) (child \\<mapsto> parent) \\<rparr> )\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Remove Parent Slot: Removes a specified cap slot from the capability descriptor table (CDT) and updates all its children to point to their grandparent, ensuring the integrity of the CDT structure.",
    "input": "",
    "output": "definition\n  remove_parent :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\" where\n  \"remove_parent parent \\<equiv>\n   modify (\\<lambda>s. s \\<lparr>cdl_cdt := (\\<lambda> x. if x = parent\n                                 then None\n                                 else (if cdl_cdt s x = Some parent\n                                     then cdl_cdt s parent\n                                     else cdl_cdt s x )) \\<rparr>)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Parent Swapping: Exchanges the parent-child relationships between two capability references, ensuring that the children of each reference are reassigned to the other parent. This operation maintains the integrity of the capability tree by updating the parent-child relationships accordingly.",
    "input": "",
    "output": "definition\n  swap_parents :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\" where\n  \"swap_parents p p' = modify (cdl_cdt_update\n     (\\<lambda>cd. Fun.swap p p'\n          (\\<lambda>x. if cd x = Some p then Some p' else\n              if cd x = Some p' then Some p else cd x)))\"\n\ndefinition\n  is_cdt_parent :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\" where\n  \"is_cdt_parent s p c \\<equiv> cdl_cdt s c = Some p\"\n\ndefinition\n  cdt_parent_rel :: \"cdl_state \\<Rightarrow> (cdl_cap_ref \\<times> cdl_cap_ref) set\" where\n  \"cdt_parent_rel \\<equiv> \\<lambda>s. {(p,c). is_cdt_parent s p c}\"\n\nabbreviation\n  parent_of :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> p cdt_parent_of c \\<equiv> (p,c) \\<in> cdt_parent_rel s\"\n\nabbreviation\n  parent_of_trancl :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>+ _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x cdt_parent_of\\<^sup>+ y \\<equiv> (x, y) \\<in> (cdt_parent_rel s)\\<^sup>+\"\n\nabbreviation\n  parent_of_rtrancl :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>* _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x cdt_parent_of\\<^sup>* y \\<equiv> (x, y) \\<in> (cdt_parent_rel s)\\<^sup>*\"\n\n\\<comment> \\<open>descendants of a slot\\<close>\ndefinition\n  descendants_of :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\" where\n  \"descendants_of p s \\<equiv> {q. (p,q) \\<in> (cdt_parent_rel s)\\<^sup>+}\"\n\n\n\ndefinition\n  tcb_ipcframe_id :: \"cdl_tcb \\<Rightarrow> cdl_object_id option\"\nwhere\n  \"tcb_ipcframe_id tcb \\<equiv> case (cdl_tcb_caps tcb tcb_ipcbuffer_slot) of\n                              Some (FrameCap _ oid _ _ _ _) \\<Rightarrow> Some oid\n                              | _                       \\<Rightarrow> None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Corrupt Intents: Modify the intent of a TCB based on a given function if the TCB's IPC frame ID matches a specified buffer. This ensures that the intents in the TCB are updated to reflect potential changes in the message registers or other relevant locations, affecting how intents are interpreted.",
    "input": "",
    "output": "definition\n  corrupt_intents ::\"(word32 \\<Rightarrow> cdl_full_intent) \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_state\"\nwhere\n  \"corrupt_intents f bufp s \\<equiv>\n  let changed = (\\<lambda>ptr. case cdl_objects s ptr of\n    Some (Tcb tcb)\n      \\<Rightarrow> if tcb_ipcframe_id tcb = Some bufp then Some (Tcb (tcb\\<lparr> cdl_tcb_intent := f ptr \\<rparr> ) ) else None\n  | _ \\<Rightarrow> None)\n  in\n  s\\<lparr>cdl_objects := cdl_objects s ++ changed\\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Frame Corruption: When a memory frame is identified as corrupted, the intents of all TCBs whose IPC buffers are located within that frame are modified to reflect the corruption.",
    "input": "",
    "output": "definition\n  corrupt_frame :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\n  where\n  \"corrupt_frame bufp \\<equiv> do\n      f \\<leftarrow> select UNIV;\n      modify (corrupt_intents f bufp)\n    od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Operations on Interrupt Objects: Define and manage operations related to interrupt objects, ensuring proper handling and processing of interrupts within the system.",
    "input": "",
    "output": "(*\n * Operations on interrupt objects.\n *)\n\ntheory Interrupt_D\nimports Endpoint_D \"ExecSpec.Platform\"\nbegin\n\ncontext begin interpretation Arch .\nrequalify_types\n  irq\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Management: Enables the creation, acknowledgment, and modification of IRQ handlers. It supports creating new IRQ handler capabilities, acknowledging and unmasking IRQs, setting endpoints for IRQs, and clearing IRQ handlers. These operations ensure that IRQs are managed effectively, allowing for proper handling and dispatching of interrupts in the system.",
    "input": "",
    "output": "definition\n  get_active_irq :: \"(cdl_irq option) k_monad\"\nwhere\n  \"get_active_irq \\<equiv>\n    do\n      irq \\<leftarrow> select UNIV;\n      return $ Some irq\n    od \\<sqinter> (return None)\n  \"\n\ndefinition\n  arch_decode_irq_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_arch_irq_control_intent \\<Rightarrow> cdl_irq_control_invocation except_monad\"\nwhere\n  \"arch_decode_irq_control_invocation target target_ref caps intent \\<equiv> case intent of\n      ARMIrqControlIssueIrqHandlerIntent irq index depth \\<Rightarrow>\n        doE\n          root \\<leftarrow> throw_on_none $ get_index caps 0;\n          cnode_cap \\<leftarrow> returnOk $ fst root;\n          dest_slot_cap_ref \\<leftarrow> lookup_slot_for_cnode_op cnode_cap index (unat depth);\n          returnOk $ IssueIrqHandler irq target_ref dest_slot_cap_ref\n        odE \\<sqinter> throw\"\n\ndefinition\n  decode_irq_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_irq_control_intent \\<Rightarrow> cdl_irq_control_invocation except_monad\"\nwhere\n  \"decode_irq_control_invocation target target_ref caps intent \\<equiv> case intent of\n      \\<comment> \\<open>Create an IRQ handler cap for the given IRQ, placing it\n         in the specified CNode slot.\\<close>\n      IrqControlIssueIrqHandlerIntent irq index depth \\<Rightarrow>\n        doE\n          root \\<leftarrow> throw_on_none $ get_index caps 0;\n          cnode_cap \\<leftarrow> returnOk $ fst root;\n          dest_slot_cap_ref \\<leftarrow> lookup_slot_for_cnode_op cnode_cap index (unat depth);\n          returnOk $ IssueIrqHandler irq target_ref dest_slot_cap_ref\n        odE \\<sqinter> throw\n    | ArchIrqControlIssueIrqHandlerIntent arch_intent \\<Rightarrow> arch_decode_irq_control_invocation target target_ref caps arch_intent\"\n\ndefinition\n  decode_irq_handler_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_irq_handler_intent \\<Rightarrow> cdl_irq_handler_invocation except_monad\"\nwhere\n  \"decode_irq_handler_invocation target target_ref caps intent \\<equiv> case intent of\n    \\<comment> \\<open>Acknowledge an IRQ.\\<close>\n    IrqHandlerAckIntent \\<Rightarrow>\n      doE\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        returnOk $ AckIrq irq\n      odE \\<sqinter> throw\n\n    \\<comment> \\<open>Modify the IRQ so that it no longer sends to an endpoint.\\<close>\n    | IrqHandlerClearIntent \\<Rightarrow>\n      doE\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        returnOk $ ClearIrqHandler irq\n      odE \\<sqinter> throw\n\n    \\<comment> \\<open>Setup an IRQ to cause an endpoint to be sent to.\\<close>\n    | IrqHandlerSetEndpointIntent \\<Rightarrow>\n      doE\n        endpoint \\<leftarrow> throw_on_none $ get_index caps 0;\n        endpoint_cap \\<leftarrow> returnOk $ fst endpoint;\n        endpoint_cap_ref \\<leftarrow> returnOk $ snd endpoint;\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        case endpoint_cap of\n              NotificationCap x _ _ \\<Rightarrow> returnOk ()\n              | _                    \\<Rightarrow> throw;\n        returnOk $ SetIrqHandler irq endpoint_cap endpoint_cap_ref\n      odE \\<sqinter> throw\n  \"\n\ndefinition\n  arch_invoke_irq_control :: \"arch_cdl_irq_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"arch_invoke_irq_control params \\<equiv> case params of\n      \\<comment> \\<open>Create a new IRQ handler cap.\\<close>\n      ARMIssueIrqHandler irq control_slot dest_slot trigger \\<Rightarrow>\n        insert_cap_child (IrqHandlerCap irq) control_slot dest_slot\n  \"\n\ndefinition\n  invoke_irq_control :: \"cdl_irq_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_irq_control params \\<equiv> case params of\n      \\<comment> \\<open>Create a new IRQ handler cap.\\<close>\n      IssueIrqHandler irq control_slot dest_slot \\<Rightarrow>\n        insert_cap_child (IrqHandlerCap irq) control_slot dest_slot\n    | ArchIssueIrqHandler arch_inv \\<Rightarrow>\n        arch_invoke_irq_control arch_inv\"\n\ndefinition\n  invoke_irq_handler :: \"cdl_irq_handler_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_irq_handler params \\<equiv> case params of\n      \\<comment> \\<open>Acknowledge and unmask an IRQ.\\<close>\n      AckIrq irq \\<Rightarrow> return ()\n\n      \\<comment> \\<open>Attach an IRQ handler to write to an endpoint.\\<close>\n    | SetIrqHandler irq cap slot \\<Rightarrow>\n        do\n          irqslot \\<leftarrow> gets (get_irq_slot irq);\n          delete_cap_simple irqslot;\n          insert_cap_child cap slot irqslot \\<sqinter> insert_cap_sibling cap slot irqslot\n        od\n\n      \\<comment> \\<open>Deassociate this handler with all endpoints.\\<close>\n    | ClearIrqHandler irq \\<Rightarrow>\n        do\n          irqslot \\<leftarrow> gets (get_irq_slot irq);\n          delete_cap_simple irqslot\n        od\n  \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interrupt Handling: Process interrupts by checking the corresponding IRQ slot and, if a notification capability with write rights is found, send a signal to the associated object. If no valid capability or no active interrupt is present, the handling process returns without action.",
    "input": "",
    "output": "definition\n  handle_interrupt :: \"cdl_irq \\<Rightarrow> unit k_monad\"\nwhere\n  \"handle_interrupt irq \\<equiv> if irq > maxIRQ then return () else\n    do\n      irq_slot \\<leftarrow> gets $ get_irq_slot irq;\n      c \\<leftarrow> gets $ opt_cap irq_slot;\n      case c of\n          None \\<Rightarrow> return ()\n        | Some cap \\<Rightarrow> (\n            case cap of\n              (NotificationCap obj _ rights) \\<Rightarrow>\n                  if (Write \\<in> rights) then send_signal obj else return ()\n              | _ \\<Rightarrow> return ()\n          )\n    od\n  \"\n\ndefinition\n  handle_pending_interrupts :: \"unit k_monad\"\nwhere\n  \"handle_pending_interrupts \\<equiv>\n    do\n      active \\<leftarrow> get_active_irq;\n      case active of\n          Some irq \\<Rightarrow> handle_interrupt irq\n        | None \\<Rightarrow> return ()\n    od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Definitions for System Components: Define types for component pointers and regions, including a capability slot pointer, a slot region, and a device register. These types facilitate the representation and manipulation of system components in the kernel.",
    "input": "",
    "output": "translations\n  (type) \"cslot_ptr\" <= (type) \"word32 \\<times> bool list\"\n\ntype_synonym slot_ptr = \"cslot_ptr\"\ntype_synonym slot_region_t = \"nat \\<times> nat\"\ntype_synonym bi_dev_reg_t = \"paddr \\<times> word32 \\<times> slot_region_t\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Select from State: Select an element from a non-empty state set S, and throw an exception if the set is empty.",
    "input": "",
    "output": "definition\n  \"throw_select S ex \\<equiv> doE\n     whenE (S = {}) (throwError ex);\n     liftE (select S)\n   odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization State: Defines the initial state of the kernel, including the boot end address, ARM vector table, ARM kernel stack, and the start of the idle thread. These constants ensure that the kernel has a well-defined starting point for its execution and resource management.",
    "input": "",
    "output": "consts\n  ki_boot_end :: paddr\n  arm_vector_table :: obj_ref\n  arm_kernel_stack :: obj_ref\n  idle_thread_start :: vspace_ref (* &idle_thread *)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Boot Information: The boot information frame contains essential data for initializing the kernel, including node identifiers, the number of nodes, I/O port levels, virtual space references, and various capability and object lists. This data is crucial for setting up the initial state and configuration of the kernel.",
    "input": "",
    "output": "text \\<open>Ghost state representing the contents of the boot info frame\\<close>\nrecord bi_frame_data =\n  bi_f_node_id :: word32\n  bi_f_num_nodes :: word32\n  bi_f_num_iopt_levels :: word32\n  bi_f_ipcbuf_vptr :: vspace_ref\n  bi_f_null_caps :: slot_region_t\n  bi_f_sh_frame_caps :: slot_region_t\n  bi_f_ui_frame_caps :: slot_region_t\n  bi_f_ui_pt_caps :: slot_region_t\n  bi_f_ut_obj_caps :: slot_region_t\n  bi_f_ut_obj_paddr_list :: \"paddr list\"\n  bi_f_ut_obj_size_bits_list :: \"word8 list\"\n  bi_f_it_cnode_size_bits :: word8\n  bi_f_num_dev_regs :: word32\n  bi_f_dev_reg_list :: \"bi_dev_reg_t list\"\n\ntype_synonym (* XXX: natural numbers represent components of kernel objects, for those\n              objects that can be subdivided *)\n  component = \"bool list\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization State: Manages the initial state of the kernel, including the basic kernel state, free memory, available memory, boot information, and a components map. The free memory and available memory sets track unallocated and allocated but not yet retyped memory, respectively. The components map specifies which parts of objects in the heap can be accessed, enabling fine-grained permission management.",
    "input": "",
    "output": "record ('z) ki_state =\n  ki_kernel_state    :: \"'z state\"\n  ki_free_mem        :: \"obj_ref set\" (* ndks_boot.freemem representative? *)\n  ki_available_mem   :: \"obj_ref set\" (* ghost state *)\n  ki_bootinfo        :: bi_frame_data (* ghost state *)\n  ki_components      :: \"paddr \\<Rightarrow> component set\"\n  ndks_boot_slot_pos_cur :: nat\n  ndks_boot_slot_pos_max :: nat\n  ndks_boot_bi_frame :: paddr",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization Monad: The kernel initialization monad can fail, with the failure value being largely irrelevant. It is designed to prevent assertion failures without a valid reason.",
    "input": "",
    "output": "text \\<open>\n  The kernel init monad can fail. The actual value of the failure is largely\n  irrelevant, just so long as we don't have assertion failures for no reason.\n\\<close>\n\ndatatype ki_failure = InitFailure\ntype_synonym ('a,'z) ki_monad = \"('z ki_state, ki_failure + 'a) nondet_monad\"\ntranslations\n  (type) \"'a ki_monad\" <=\n    (type) \"((ki_failure + 'a) \\<times> ki_state \\<Rightarrow> bool) \\<times> bool\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lift Kernel State Monad Operations: Elevate operations from the kernel state monad to the kernel init monad, ensuring that the kernel state is properly updated and the result is returned.",
    "input": "",
    "output": "definition\n  do_kernel_op :: \"('a,'z::state_ext) s_monad \\<Rightarrow> ('a,'z) ki_monad\" where\n \"do_kernel_op kop \\<equiv> liftE $ do\n    ms \\<leftarrow> gets ki_kernel_state;\n    (r, ms') \\<leftarrow> select_f (kop ms);\n    modify (\\<lambda>ks. ks \\<lparr> ki_kernel_state := ms' \\<rparr>);\n    return r\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Minimum Untyped Object Size: The minimum number of 4K untyped objects is defined as 12.  \nMaximum Free Memory Regions: The maximum number of free memory regions is defined as 2.",
    "input": "",
    "output": "definition \"MIN_NUM_4K_UNTYPED_OBJ \\<equiv> 12 :: nat\"\ndefinition \"MAX_NUM_FREEMEM_REG \\<equiv> 2 :: nat\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fixed Cap Positions in Root CNode: Define specific, fixed positions for various capabilities in the root CNode, including TCB, CNode, PD, IRQ controller, ASID controller, ASID pool, I/O port, I/O space, bootinfo frame, IPC buffer, and dynamic start. These fixed positions ensure consistent and predictable access to critical system resources.",
    "input": "",
    "output": "definition \"BI_CAP_NULL         \\<equiv>  0 :: nat\"\ndefinition \"BI_CAP_IT_TCB       \\<equiv>  1 :: nat\"\ndefinition \"BI_CAP_IT_CNODE     \\<equiv>  2 :: nat\"\ndefinition \"BI_CAP_IT_PD        \\<equiv>  3 :: nat\"\ndefinition \"BI_CAP_IRQ_CTRL     \\<equiv>  4 :: nat\"\ndefinition \"BI_CAP_ASID_CTRL    \\<equiv>  5 :: nat\"\ndefinition \"BI_CAP_IT_ASID_POOL \\<equiv>  6 :: nat\"\ndefinition \"BI_CAP_IO_PORT      \\<equiv>  7 :: nat\"\ndefinition \"BI_CAP_IO_SPACE     \\<equiv>  8 :: nat\"\ndefinition \"BI_CAP_BI_FRAME     \\<equiv>  9 :: nat\"\ndefinition \"BI_CAP_IT_IPCBUF    \\<equiv> 10 :: nat\"\ndefinition \"BI_CAP_DYN_START    \\<equiv> 11 :: nat\"\n\ndefinition \"BI_FRAME_SIZE_BITS \\<equiv> pageBits\"\ndefinition \"ROOT_CNODE_SIZE_BITS \\<equiv> 12 :: nat\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory and ASID Constants: Define specific memory addresses for the vector table, globals page, and kernel stack, as well as constants for ASID and bit sizes for word, ASID pool, and CTE. These constants ensure consistent and predictable memory and ASID management in the system.",
    "input": "",
    "output": "definition \"PPTR_VECTOR_TABLE \\<equiv> 0xffff0000 :: word32\"\ndefinition \"PPTR_GLOBALS_PAGE \\<equiv> 0xffffc000 :: word32\"\ndefinition \"PPTR_KERNEL_STACK \\<equiv> 0xfffff000 :: word32\"\n\ndefinition \"IT_ASID     \\<equiv> 1 :: asid\" (* initial thread ASID *)\n\ndefinition \"WORD_SIZE_BITS \\<equiv> 2 :: nat\"\ndefinition \"ASID_POOL_BITS \\<equiv> asid_low_bits :: nat\"\ndefinition \"ASID_POOL_SIZE_BITS \\<equiv> ASID_POOL_BITS + WORD_SIZE_BITS\"\n\ndefinition \"CTE_SIZE_BITS \\<equiv> 4 :: nat\" (* from ARM structures.h *)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Page Directory Bit Sizes: Define the bit sizes for page directories (PD_BITS), page tables (PT_BITS), page directory entries (PDE_SIZE_BITS), and page table entries (PTE_SIZE_BITS).",
    "input": "",
    "output": "definition \"PD_BITS \\<equiv> 12 :: nat\"\ndefinition \"PT_BITS \\<equiv> 8 :: nat\"\n\ndefinition \"PDE_SIZE_BITS \\<equiv> 2 :: nat\"\ndefinition \"PTE_SIZE_BITS \\<equiv> 2 :: nat\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Page Directory Size Bits: Define the size bits for page directories and page tables by summing the base bits with the corresponding entry size bits.",
    "input": "",
    "output": "definition \"PD_SIZE_BITS \\<equiv> PD_BITS + PDE_SIZE_BITS\"\ndefinition \"PT_SIZE_BITS \\<equiv> PT_BITS + PTE_SIZE_BITS\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Interrupt Constants: Define specific interrupt values for the iMX31 platform, including an invalid IRQ value and specific interrupts for PMU and EPIT1, with the kernel timer interrupt mapped to EPIT1.",
    "input": "",
    "output": "definition \"irqInvalid       \\<equiv> 255 :: irq\"\ndefinition \"INTERRUPT_PMU    \\<equiv> 23 :: irq\"\ndefinition \"INTERRUPT_EPIT1  \\<equiv> 28 :: irq\"\ndefinition \"KERNEL_TIMER_IRQ \\<equiv> INTERRUPT_EPIT1\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Platform Constants: Define physical and pseudo-physical addresses for various kernel devices, including EPIT, AVIC, L2CC, and UART, to facilitate memory-mapped I/O operations.",
    "input": "",
    "output": "definition \"EPIT_PADDR \\<equiv> 0x53f94000 :: word32\"\ndefinition \"EPIT_PPTR  \\<equiv> 0xfff00000 :: word32\"\ndefinition \"AVIC_PADDR \\<equiv> 0x68000000 :: word32\"\ndefinition \"AVIC_PPTR  \\<equiv> 0xfff01000 :: word32\"\ndefinition \"L2CC_PADDR \\<equiv> 0x30000000 :: word32\"\ndefinition \"L2CC_PPTR  \\<equiv> 0xfff02000 :: word32\"\ndefinition \"UART_PADDR \\<equiv> 0x43f90000 :: word32\"\ndefinition \"UART_PPTR  \\<equiv> 0xfff03000 :: word32\"\n\ndefinition \"BASE_OFFSET = pptrBaseOffset\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Local Capability Management: Manage capabilities within CNodes and TCBs without enforcing well-formedness checks. Capabilities can be retrieved, set, and inserted, with specific rules for updating and transferring capabilities between slots, ensuring that the integrity of the capability system is maintained.",
    "input": "",
    "output": "text \\<open>\n  These shadow the normal functions, but do not force a well-formedness\n  check for the cnodes, as wellformed\\_cnode\\_sz is non-local with respect\n  to individual caps, and so get\\_cap and set\\_cap are also.\\<close>\n\ndefinition\n  get_cap_local :: \"cslot_ptr \\<Rightarrow> (cap,'z::state_ext) s_monad\"\nwhere\n  \"get_cap_local \\<equiv> \\<lambda>(oref, cref). do\n     obj \\<leftarrow> get_object oref;\n     caps \\<leftarrow> case obj of\n             CNode sz cnode \\<Rightarrow> return cnode\n           | TCB tcb     \\<Rightarrow> return (tcb_cnode_map tcb)\n           | _ \\<Rightarrow> fail;\n     assert_opt (caps cref)\n   od\"\n\ndefinition\n  set_cap_local :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_cap_local cap \\<equiv> \\<lambda>(oref, cref). do\n     obj \\<leftarrow> get_object oref;\n     obj' \\<leftarrow> case obj of\n               CNode sz cn \\<Rightarrow> if cref \\<in> dom cn\n                                then return $ CNode sz $ cn (cref \\<mapsto> cap)\n                                else fail\n             | TCB tcb \\<Rightarrow>\n                   if cref = tcb_cnode_index 0 then\n                       return $ TCB $ tcb \\<lparr> tcb_ctable := cap \\<rparr>\n                   else if cref = tcb_cnode_index 1 then\n                       return $ TCB $ tcb \\<lparr> tcb_vtable := cap \\<rparr>\n                   else if cref = tcb_cnode_index 2 then\n                       return $ TCB $ tcb \\<lparr> tcb_reply := cap \\<rparr>\n                   else if cref = tcb_cnode_index 3 then\n                       return $ TCB $ tcb \\<lparr> tcb_caller := cap \\<rparr>\n                   else if cref = tcb_cnode_index 4 then\n                       return $ TCB $ tcb \\<lparr> tcb_ipcframe := cap \\<rparr>\n                   else\n                       fail\n             | _ \\<Rightarrow> fail;\n     set_object oref obj'\n  od\"\n\ndefinition\n  set_untyped_cap_as_full_local :: \"cap \\<Rightarrow> cap \\<Rightarrow> word32 \\<times> bool list\\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_untyped_cap_as_full_local src_cap new_cap src_slot \\<equiv>\n   if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n       \\<and> obj_ref_of src_cap = obj_ref_of new_cap \\<and> cap_bits_untyped src_cap = cap_bits_untyped new_cap)\n       then set_cap_local (max_free_index_update src_cap) src_slot else return ()\"\n\ndefinition\n  cap_insert_local :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"cap_insert_local new_cap src_slot dest_slot \\<equiv> do\n    src_cap \\<leftarrow> get_cap_local src_slot;\n\n    dest_original \\<leftarrow> return (if is_ep_cap new_cap then\n                                cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n                             else if is_ntfn_cap new_cap then\n                                cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n                             else if \\<exists>irq. new_cap = IRQHandlerCap irq then\n                                src_cap = IRQControlCap\n                             else is_untyped_cap new_cap);\n    old_cap \\<leftarrow> get_cap_local dest_slot;\n    assert (old_cap = NullCap);\n    set_untyped_cap_as_full_local src_cap new_cap src_slot;\n    set_cap_local new_cap dest_slot;\n\n    is_original \\<leftarrow> gets is_original_cap;\n    src_parent \\<leftarrow> return $\n       should_be_parent_of src_cap (is_original src_slot) new_cap dest_original;\n    src_p \\<leftarrow> gets (\\<lambda>s. cdt s src_slot);\n    dest_p \\<leftarrow> gets (\\<lambda>s. cdt s dest_slot);\n    update_cdt (\\<lambda>cdt. cdt (dest_slot := if src_parent\n                                        then Some src_slot\n                                        else cdt src_slot));\n    do_extended_op (cap_insert_ext src_parent src_slot dest_slot src_p dest_p);\n    set_original dest_slot dest_original\n  od\"\n\ndefinition\n  \"setup_reply_master_local thread \\<equiv> do\n     old_cap <- get_cap_local (thread, tcb_cnode_index 2);\n     when (old_cap = NullCap) $ do\n         set_original (thread, tcb_cnode_index 2) True;\n         set_cap_local (ReplyCap thread True) (thread, tcb_cnode_index 2)\n     od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Initializes the kernel by creating essential components, including an idle thread and root capability node. The idle thread is created and configured, while the root capability node is set up with a specified size and its slot position is updated. This ensures that the kernel has the necessary structures in place for proper operation.",
    "input": "",
    "output": "consts \n  sync_bootinfo_frame :: \"paddr \\<Rightarrow> (unit,'z::state_ext) ki_monad\"\n\ndefinition \n      returnOk pptr\n   odE\"\n\ndefinition\n  create_idle_thread :: \"(unit,'z::state_ext) ki_monad\" where\n  \"create_idle_thread \\<equiv> doE\n     pptr \\<leftarrow> create_objects (obj_bits $ TCB undefined)\n                           (obj_bits $ TCB undefined) TCBObject;\n     do_kernel_op $ do\n       modify (\\<lambda>s. s \\<lparr> idle_thread := pptr \\<rparr>);\n       configure_idle_thread pptr\n     od\n   odE\"\n\ndefinition\n  create_root_cnode :: \"(cap,'z::state_ext) ki_monad\" where\n  \"create_root_cnode \\<equiv>\n   let sz = (ROOT_CNODE_SIZE_BITS + CTE_SIZE_BITS) in\n   doE\n     liftE $ modify\n               (\\<lambda>s. s \\<lparr> ndks_boot_slot_pos_max := 2 ^ ROOT_CNODE_SIZE_BITS \\<rparr>);\n\n     pptr \\<leftarrow> create_objects sz sz CapTableObject;\n\n     let cap = CNodeCap pptr ROOT_CNODE_SIZE_BITS\n                             (replicate (32 - ROOT_CNODE_SIZE_BITS) False)\n     in (doE\n           do_kernel_op $ write_slot (cap_slot_pptr cap BI_CAP_IT_CNODE) cap;\n           returnOk cap\n         odE)\n   odE\"\n\ndefinition\n  create_irq_cnode :: \"(unit,'z::state_ext) ki_monad\" where\n  \"create_irq_cnode \\<equiv> doE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create CNode Page: Initialize a page with a specified number of CTEs, each occupying the space defined by CTE_SIZE_BITS, to form a CapTableObject.",
    "input": "",
    "output": "pptr \\<leftarrow> create_objects pageBits CTE_SIZE_BITS CapTableObject;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Initialize kernel structures by associating each cnode with an IRQ, creating and configuring frame capabilities for IPC buffers, and allocating and setting up memory regions for various kernel objects. This ensures that the kernel is properly configured with the necessary resources and mappings to support inter-process communication and other critical functionalities.",
    "input": "",
    "output": "do_kernel_op $ modify\n               (\\<lambda>s. s \\<lparr> interrupt_irq_node :=\n                        (\\<lambda>irq. pptr + ucast irq * of_nat CTE_SIZE_BITS) \\<rparr>)\n   odE\"\n\ndefinition\n  create_it_frame_cap :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> asid option \\<Rightarrow> bool \\<Rightarrow> (cap,'z::state_ext) ki_monad\"\n  where\n  \"create_it_frame_cap pptr vptr asid use_large \\<equiv>\n   let sz = if use_large then ARMLargePage else ARMSmallPage in\n     returnOk $ ArchObjectCap $ PageCap pptr {AllowRead,AllowWrite}\n                                        sz (map_option (\\<lambda>a. (a, vptr)) asid)\"\n\ndefinition\n  create_ipcbuf_frame :: \"cap \\<Rightarrow> (vspace_ref \\<times> vspace_ref)\n                          \\<Rightarrow> (cap \\<times> vspace_ref,'z::state_ext) ki_monad\" where\n  \"create_ipcbuf_frame root_cnode_cap ui_v_reg \\<equiv>\n   let vptr = snd ui_v_reg (* ui_v_reg.end *)\n   in\n   doE\n     pptr \\<leftarrow> alloc_region pageBits;\n     do_kernel_op $ do_machine_op $ clearMemory pptr pageBits;\n\n     cap \\<leftarrow> create_it_frame_cap pptr vptr (Some IT_ASID) False;\n\n     do_kernel_op $\n       write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_IPCBUF) cap;\n\n     returnOk (cap, vptr)\n   odE\"\n\ndefinition\n  create_bi_frame :: \"cap \\<Rightarrow> (vspace_ref \\<times> vspace_ref) \\<Rightarrow> vspace_ref \\<Rightarrow> word32\n                      \\<Rightarrow> word32 \\<Rightarrow> (vspace_ref,'z::state_ext) ki_monad\" where\n  \"create_bi_frame root_cnode_cap ui_v_reg ipcbuf_vptr node_id num_nodes \\<equiv>\n   let vptr = ipcbuf_vptr + of_nat (2 ^ pageBits)\n   in\n   doE\n     pptr \\<leftarrow> alloc_region BI_FRAME_SIZE_BITS;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Boot Info: Modify the abstract representation of the boot information frame, updating fields such as node ID, number of nodes, IPC buffer virtual pointer, and root CNode size bits.",
    "input": "",
    "output": "liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_node_id := node_id,\n       bi_f_num_nodes := num_nodes,\n       bi_f_num_iopt_levels := 0,\n       bi_f_ipcbuf_vptr := ipcbuf_vptr,\n       bi_f_it_cnode_size_bits := of_nat ROOT_CNODE_SIZE_BITS \\<rparr>\\<rparr>);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Synchronize the abstract boot information with the boot information frame, update the kernel state to reflect the new boot information frame pointer and the current slot position, create an initial translation frame capability, and write this capability to the specified slot in the root CNode. This ensures that the kernel's initial memory setup is correctly configured for subsequent operations.",
    "input": "",
    "output": "sync_bootinfo_frame pptr;\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ndks_boot_bi_frame := pptr,\n                             ndks_boot_slot_pos_cur := BI_CAP_DYN_START \\<rparr> );\n\n     cap \\<leftarrow> create_it_frame_cap pptr vptr (Some IT_ASID) False;\n     do_kernel_op $\n       write_slot (cap_slot_pptr root_cnode_cap BI_CAP_BI_FRAME) cap;\n\n     returnOk vptr\n   odE\"\n\ndefinition\n  create_it_asid_pool :: \"cap \\<Rightarrow> (cap,'z::state_ext) ki_monad\" where\n  \"create_it_asid_pool root_cnode_cap \\<equiv> doE",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Initialization: Create an ASID pool and initialize it with a specified size, then generate a capability for the ASID pool and write this capability into the root CNode.",
    "input": "",
    "output": "ap_pptr \\<leftarrow> create_objects ASID_POOL_SIZE_BITS\n                              ASID_POOL_SIZE_BITS (ArchObject ASIDPoolObj);\n\n     ap_cap \\<leftarrow> returnOk $ ArchObjectCap $\n                 ASIDPoolCap ap_pptr (IT_ASID >> asid_low_bits);\n\n     do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap\n                                BI_CAP_IT_ASID_POOL) ap_cap;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization Functions: Initialize and configure kernel resources, including creating ASID control capabilities, generating frame capabilities for a specified region, writing ASID pool mappings, and mapping page table capabilities. These functions ensure that the kernel's memory management and address space isolation are properly set up, facilitating secure and efficient operation.",
    "input": "",
    "output": "do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap BI_CAP_ASID_CTRL)\n                               (ArchObjectCap ASIDControlCap);\n\n     returnOk ap_cap\n   odE\"\n\ndefinition\n  create_frames_of_region :: \"cap \\<Rightarrow> (paddr \\<times> paddr) \\<Rightarrow> bool \\<Rightarrow> word32\n                              \\<Rightarrow> (nat \\<times> nat,'z::state_ext) ki_monad\" where\n  \"create_frames_of_region root_cnode_cap reg do_map pv_offset \\<equiv> doE\n\n     slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     (swp mapME)\n       [(fst reg),(fst reg + of_nat (2 ^ pageBits)) .e. (snd reg - 1)]\n       (\\<lambda>f. doE\n              frame_cap \\<leftarrow> (if do_map\n                           then create_it_frame_cap f\n                                  (f - BASE_OFFSET - pv_offset) (Some IT_ASID) False\n                           else create_it_frame_cap f 0 None False);\n              provide_cap root_cnode_cap frame_cap\n            odE);\n\n     slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     returnOk (slot_pos_before, slot_pos_after)\n   odE\"\n\ndefinition\n  write_it_asid_pool :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"write_it_asid_pool it_ap_cap it_pd_cap \\<equiv>\n   let ap_ptr = obj_ref_of it_ap_cap;\n       pd_ptr = obj_ref_of it_pd_cap;\n       asid_idx = ucast (IT_ASID >> asid_low_bits)\n   in\n   do\n     ap \\<leftarrow> get_asid_pool ap_ptr;\n     ap' \\<leftarrow> return (ap (ucast IT_ASID \\<mapsto> pd_ptr));\n     set_asid_pool ap_ptr ap';\n\n     asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n     asid_table' \\<leftarrow> return (asid_table(asid_idx \\<mapsto> ap_ptr));\n     modify (\\<lambda>s. s \\<lparr> arch_state :=\n                      arch_state s \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>)\n\n   od\"\n\ndefinition\n  map_it_pt_cap :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"map_it_pt_cap pd_cap pt_cap \\<equiv> do\n\n     pd \\<leftarrow> return $ obj_ref_of pd_cap; (* C uses specific PD version *)\n\n     (pt,vptr) \\<leftarrow> return $ case the_arch_cap pt_cap\n                            of PageTableCap ref (Some (_, vref)) \\<Rightarrow> (ref,vref);\n\n     slot \\<leftarrow> return $ vptr >> pageBitsForSize ARMSection;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization and Memory Mapping: Initialize the kernel by setting up page directories and page tables, including enabling parity for error correction. Map frame capabilities to specific virtual addresses in the page table, ensuring that memory is correctly configured and accessible.",
    "input": "",
    "output": "pde \\<leftarrow> return $ PageTablePDE (addrFromPPtr pt) {ParityEnabled} 0;\n\n     pd_obj \\<leftarrow> get_object pd;\n     pd_obj' \\<leftarrow> return (case pd_obj\n                         of ArchObj (PageDirectory table)\n                            \\<Rightarrow> ArchObj (PageDirectory $ table(ucast slot := pde)\n                       ));\n     set_object pd pd_obj'\n   od\"\n\ndefinition\n  map_it_frame_cap :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"map_it_frame_cap pd_cap frame_cap \\<equiv> do\n\n     pd \\<leftarrow> return $ obj_ref_of pd_cap;\n\n     (frame, vptr) \\<leftarrow> return $ case the_arch_cap frame_cap\n                       of PageCap ref _ _ (Some (_, vptr)) \\<Rightarrow> (ref, vptr);\n\n     pd_obj \\<leftarrow> get_object pd;\n     pde \\<leftarrow> return $ case pd_obj\n                      of ArchObj (PageDirectory table)\n                         \\<Rightarrow> table (ucast (vptr >> pageBitsForSize ARMSection));\n\n     pt \\<leftarrow> return (case pde of PageTablePDE ref _ _ \\<Rightarrow> ptrFromPAddr ref);\n\n     slot \\<leftarrow> return $ (vptr && mask (pageBitsForSize ARMSection))\n                              >> pageBitsForSize ARMSmallPage;\n\n     pte \\<leftarrow> return $ SmallPagePTE (addrFromPPtr frame) {PageCacheable}\n                                 vm_read_write;\n     pt_obj \\<leftarrow> get_object pt;\n     pt_obj' \\<leftarrow> return (case pt_obj\n                         of ArchObj (PageTable table)\n                            \\<Rightarrow> ArchObj (PageTable $ table(ucast slot := pte)));\n     set_object pt pt_obj'\n   od\"\n\ndefinition\n  write_it_pd_pts :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"write_it_pd_pts root_cnode_cap it_pd_cap \\<equiv> doE\n\n     do_kernel_op $ copy_global_mappings $ obj_ref_of it_pd_cap;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Map Page Table Capabilities: Map the page table capabilities into the page directory. This involves iterating over a range of positions, retrieving the capability at each position, and mapping it into the page directory to establish the necessary memory mappings.",
    "input": "",
    "output": "(start, end) \\<leftarrow> liftE $ gets (bi_f_ui_pt_caps \\<circ> ki_bootinfo);\n\n     do_kernel_op $\n       (swp mapM)\n          [start..<end]\n          (\\<lambda>pos. do\n                   cap \\<leftarrow> get_cap_local $ cap_slot_pptr root_cnode_cap pos;\n                   map_it_pt_cap it_pd_cap cap\n                 od);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Map Frames into Page Tables: Maps frames into page tables by iterating over a range of frame capabilities, retrieving each capability, and mapping it. Additionally, specific capabilities for the IPC buffer and bootinfo frame are also mapped to ensure proper initialization and accessibility of these critical resources.",
    "input": "",
    "output": "(start, end) \\<leftarrow> liftE $ gets (bi_f_ui_frame_caps \\<circ> ki_bootinfo);\n\n     do_kernel_op (do\n       (swp mapM)\n          [start..<end]\n          (\\<lambda>pos. do\n                   cap \\<leftarrow> get_cap_local $ cap_slot_pptr root_cnode_cap pos;\n                   map_it_frame_cap it_pd_cap cap\n                 od);\n\n       cap \\<leftarrow> get_cap_local $ cap_slot_pptr root_cnode_cap BI_CAP_IT_IPCBUF;\n       map_it_frame_cap it_pd_cap cap;\n       cap \\<leftarrow> get_cap_local $ cap_slot_pptr root_cnode_cap BI_CAP_BI_FRAME;\n       map_it_frame_cap it_pd_cap cap\n     od)\n   odE\"\n\ndefinition\n  bi_finalise :: \"(unit,'z::state_ext) ki_monad\" where\n  \"bi_finalise \\<equiv> doE\n     slot_pos_start \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n     slot_pos_end \\<leftarrow> liftE $ gets ndks_boot_slot_pos_max;\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_null_caps := (of_nat slot_pos_start, of_nat slot_pos_end) \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame\n   odE\"\n\ndefinition\n  create_it_pd_pts :: \"cap \\<Rightarrow> (vspace_ref \\<times> vspace_ref) \\<Rightarrow> vspace_ref\n                       \\<Rightarrow> vspace_ref \\<Rightarrow> (cap,'z::state_ext) ki_monad\" where\n  \"create_it_pd_pts root_cnode_cap ui_v_reg ipcbuf_vptr bi_frame_vptr \\<equiv> doE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create and Initialize Page Directory: Create a page directory object and its corresponding capability, then write the capability to the specified slot in the root CNode. This ensures that the page directory is properly set up and accessible for memory management operations.",
    "input": "",
    "output": "pd_pptr \\<leftarrow> create_objects PD_SIZE_BITS PD_SIZE_BITS\n                              (ArchObject PageDirectoryObj);\n     pd_cap \\<leftarrow> returnOk $ ArchObjectCap $\n                           PageDirectoryCap pd_pptr (Some IT_ASID);\n     do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_PD)\n                               pd_cap;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Userland Image: Include the IPC buffer and bootinfo frames in the userland image, setting the virtual register start and end addresses accordingly.",
    "input": "",
    "output": "(ui_v_reg_start, ui_v_reg_end) \\<leftarrow>\n         returnOk (fst ui_v_reg, bi_frame_vptr + 2 ^ BI_FRAME_SIZE_BITS);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Initial Thread and Page Tables: Initialize the kernel by creating all necessary page table objects and capabilities to cover the userland image. This includes allocating and typing page tables, providing corresponding capabilities, and updating the boot information with the positions of the created capabilities.",
    "input": "",
    "output": "slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     start \\<leftarrow> returnOk $ round_down ui_v_reg_start (PD_BITS + pageBits);\n     next \\<leftarrow> returnOk $ start + (2 ^ (PT_BITS + pageBits));\n\n     (swp mapME) [start,next .e. ui_v_reg_end] (\\<lambda>pt_vptr. doE\n\n       pt_pptr \\<leftarrow> alloc_region PT_SIZE_BITS;\n       do_kernel_op $ retype_region pt_pptr 1 PT_SIZE_BITS\n                                            (ArchObject PageTableObj);\n\n       provide_cap root_cnode_cap $\n         ArchObjectCap $ PageTableCap pt_pptr (Some (IT_ASID, pt_vptr))\n     odE);\n\n     slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_ui_pt_caps := (of_nat slot_pos_before, of_nat slot_pos_after) \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame;\n\n     returnOk pd_cap\n   odE\"\n\ndefinition\n  create_initial_thread :: \"cap \\<Rightarrow> cap \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref\n                            \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_initial_thread root_cnode_cap it_pd_cap ui_v_entry bi_frame_vptr\n                         ipcbuf_vptr ipcbuf_cap \\<equiv>\n   let tcb_bits = obj_bits $ TCB undefined\n   in\n   doE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Allocate TCB: Creates and initializes a new TCB object with the specified number of bits, ensuring that the TCB is properly set up for thread management.",
    "input": "",
    "output": "tcb_pptr \\<leftarrow> create_objects tcb_bits tcb_bits TCBObject;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Initialize the kernel by inserting capabilities for the TCB's CNode, VTable, and IPC buffer into the root CNode. Update the TCB object to set the IPC buffer, and configure the user context by setting the CPSR register and the next program counter.",
    "input": "",
    "output": "do_kernel_op $ (do\n     cap_insert_local root_cnode_cap (cap_slot_pptr root_cnode_cap BI_CAP_IT_CNODE)\n                               (tcb_pptr, tcb_cnode_index 0); (* tcbCTable *)\n     cap_insert_local root_cnode_cap (cap_slot_pptr root_cnode_cap BI_CAP_IT_PD)\n                               (tcb_pptr, tcb_cnode_index 1); (* tcbVTable *)\n     cap_insert_local root_cnode_cap (cap_slot_pptr root_cnode_cap BI_CAP_IT_IPCBUF)\n                               (tcb_pptr, tcb_cnode_index 4); (* tcbBuffer *)\n\n     tcb_obj \\<leftarrow> get_object tcb_pptr;\n     tcb_obj' \\<leftarrow> return $\n                case tcb_obj\n                  of TCB tcb \\<Rightarrow> TCB (tcb\\<lparr>tcb_ipc_buffer := ipcbuf_vptr\\<rparr>);\n     set_object tcb_pptr tcb_obj';\n\n     as_user tcb_pptr $ set_register CPSR 0x1f;\n     as_user tcb_pptr $ setNextPC ui_v_entry;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Sets up the reply master for a thread and transitions its state to running, ensuring the thread is ready for execution.",
    "input": "",
    "output": "setup_reply_master_local tcb_pptr;\n     set_thread_state tcb_pptr Running;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Initializes the kernel by setting the current thread to the idle thread, switching to a new thread, and writing the thread capability to the specified slot in the root cnode. This ensures that the kernel is in a known state and ready for further operations.",
    "input": "",
    "output": "idle_thread \\<leftarrow> gets idle_thread;\n     modify (\\<lambda>s. s\\<lparr> cur_thread := idle_thread \\<rparr>);\n\n     switch_to_thread tcb_pptr;\n\n     cap \\<leftarrow> return $ ThreadCap tcb_pptr;\n     write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_TCB) cap\n   od)\n   odE\"\n\ndefinition\n  create_device_frames :: \"cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_device_frames root_cnode_cap \\<equiv> doE\n     dev_regs \\<leftarrow> do_kernel_op $ do_machine_op getDeviceRegions;\n\n     (swp mapME) dev_regs (\\<lambda>(start,end). doE",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Allocate memory frames, preferentially using 1M frames if the start and end addresses are aligned, otherwise using 4K frames. The function creates frame capabilities, updates the boot information with device region details, and ensures that the regions do not overlap, maintaining the integrity of the memory layout.",
    "input": "",
    "output": "frame_size \\<leftarrow>\n         returnOk $ if (is_aligned start (pageBitsForSize ARMSection)\n                        \\<and> is_aligned end (pageBitsForSize ARMSection))\n                    then ARMSection\n                    else ARMSmallPage;\n\n       slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n       (swp mapME) [start,(start + 2^(pageBitsForSize frame_size))\n                       .e. (end - 1)]\n         (\\<lambda>f. doE\n                frame_cap \\<leftarrow> create_it_frame_cap f 0 None\n                                                (frame_size = ARMSection);\n                provide_cap root_cnode_cap frame_cap\n              odE);\n\n       slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n       bi_dev_reg \\<leftarrow> returnOk (addrFromPPtr start,\n                              of_nat (pageBitsForSize frame_size),\n                              (slot_pos_before, slot_pos_after));\n\n       liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n         bi_f_dev_reg_list := (bi_f_dev_reg_list $\n                                 ki_bootinfo s) @ [bi_dev_reg]\n         \\<rparr>\\<rparr>);\n\n       bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n       sync_bootinfo_frame bi_frame\n\n     odE);\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_num_dev_regs := of_nat $ length (bi_f_dev_reg_list $\n                                               ki_bootinfo s)\n       \\<rparr>\\<rparr>);\n\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame\n   odE\"\n\nfun (* for (ptr,bits)-style regions which don't straddle the end of memory *)\n  no_region_overlap :: \"(paddr \\<times> nat) \\<Rightarrow> (paddr \\<times> nat) \\<Rightarrow> bool\" where\n  \"no_region_overlap (ptr1,bits1) (ptr2,bits2) =\n     ({ptr1 .. ptr1 + 2 ^ bits1 - 1} \\<inter> {ptr2 .. ptr2 + 2 ^ bits2 - 1} = {})\"\n\ndefinition\n  freemem_regions :: \"obj_ref set \\<Rightarrow> ((paddr \\<times> nat) list,'z::state_ext) s_monad\" where\n  \"freemem_regions free \\<equiv> do\n     regs \\<leftarrow> select {lst. (\\<forall>(ptr,bits) \\<in> set lst. is_aligned ptr bits \\<and>\n                                           {ptr .. ptr + 2 ^ bits - 1} \\<subseteq> free)\n                         \\<and> distinct_prop no_region_overlap lst};\n     return regs\n   od\"\n\ndefinition\n  create_untyped_obj :: \"cap \\<Rightarrow> (paddr \\<times> paddr) \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_untyped_obj root_cnode_cap boot_mem_reuse_reg \\<equiv> doE\n\n     slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Memory Reuse: Reuse the boot code and data frames by providing untyped capabilities for the specified memory regions, ensuring efficient memory utilization during initialization.",
    "input": "",
    "output": "(swp mapME) [fst boot_mem_reuse_reg,(fst boot_mem_reuse_reg + 2^pageBits)\n                   .e. (snd boot_mem_reuse_reg - 1)]\n                  (\\<lambda>i. provide_untyped_cap root_cnode_cap i pageBits\n                                           slot_pos_before);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Allocate and Provide Untyped Objects: Allocate a minimum number of 4K untyped objects as requested and provide them with the appropriate capabilities.",
    "input": "",
    "output": "slot_pos_cur \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n     (swp mapME) [(slot_pos_cur - slot_pos_before)..<MIN_NUM_4K_UNTYPED_OBJ]\n       (\\<lambda>i. doE\n              pptr \\<leftarrow> alloc_region pageBits;\n              provide_untyped_cap root_cnode_cap pptr pageBits slot_pos_before\n            odE);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Initializes the kernel by allocating and mapping free memory regions, setting up untyped capabilities, updating boot information, and mapping kernel frames and devices. This ensures that the kernel is properly configured with the necessary memory and device mappings, and the boot information is synchronized.",
    "input": "",
    "output": "freemem \\<leftarrow> liftE $ gets ki_free_mem;\n     freeregs \\<leftarrow> do_kernel_op $ freemem_regions freemem;\n\n     (swp mapME) (take MAX_NUM_FREEMEM_REG freeregs)\n       (\\<lambda>(start,bits). provide_untyped_cap root_cnode_cap start bits\n                                           slot_pos_before);\n\n     slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_ut_obj_caps := (slot_pos_before, slot_pos_after) \\<rparr>\\<rparr>);\n\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame\n   odE\"\n\ndefinition\n  map_kernel_frame :: \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vm_rights \\<Rightarrow> vm_attributes\n                       \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"map_kernel_frame paddr vaddr vm_rights attributes \\<equiv> do\n\n     idx \\<leftarrow> return $ (vaddr && mask (pageBitsForSize ARMSection))\n                    >> pageBitsForSize ARMSmallPage;\n\n     global_pt \\<leftarrow> get_arm_global_pt;\n\n     pte \\<leftarrow> return $ SmallPagePTE paddr attributes vm_rights;\n\n     store_pte (global_pt + (idx << PTE_SIZE_BITS)) pte\n   od\"\n\n\ndefinition (* from plat/imx31/machine/hardware.c *)\n  map_kernel_devices :: \"(unit,'z::state_ext) s_monad\" where\n  \"map_kernel_devices \\<equiv> do\n     map_kernel_frame EPIT_PADDR EPIT_PPTR vm_kernel_only\n                      {ParityEnabled,PageCacheable};\n     map_kernel_frame AVIC_PADDR AVIC_PPTR vm_kernel_only\n                      {ParityEnabled,PageCacheable};\n     map_kernel_frame L2CC_PADDR L2CC_PPTR vm_kernel_only\n                      {ParityEnabled,PageCacheable}\n   od\"\n\ndefinition\n  map_kernel_window :: \"(unit,'z::state_ext) s_monad\" where\n  \"map_kernel_window \\<equiv> do\n\n     global_pd \\<leftarrow> gets (arm_global_pd \\<circ> arch_state);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initial Page Directory Index: The initial index into the page directory is calculated by shifting the kernel base address right by the number of bits corresponding to the ARM section size, ensuring that the index is divisible by 16.",
    "input": "",
    "output": "idx \\<leftarrow> return $ kernel_base >> pageBitsForSize ARMSection;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Physical Base Address: Set the initial physical address to be used for memory mapping.",
    "input": "",
    "output": "phys \\<leftarrow> return $ physBase;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Map the physical base at the kernel base in 16MB segments, setting up SuperSection Page Directory Entries (PDEs) with specific attributes such as parity enabled and page cacheable, but not finalizing the supersection.",
    "input": "",
    "output": "iterations \\<leftarrow> return ((2^(PD_BITS) - idx) >> 4);\n\n     (swp mapM) [0 .e. iterations - 1] (\\<lambda>i. do\n         idx' \\<leftarrow> return $ idx + i * 16;\n         phys' \\<leftarrow> return $ phys + i * (2^(pageBitsForSize(ARMSuperSection)));\n\n         pde \\<leftarrow> return $ SuperSectionPDE phys' {ParityEnabled,PageCacheable}\n                                         vm_kernel_only;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Supersection: Write 16 section entries for the supersection by storing the page directory entry (PDE) at each offset from 0 to 15.",
    "input": "",
    "output": "mapM (\\<lambda>offs. store_pde (idx' + offs) pde) [0 .e. 15]\n       od);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Advance Index and Physical Address: Update the index and physical address by adding the product of the number of iterations and their respective increments, ensuring they match the exit condition of the C loop.",
    "input": "",
    "output": "idx \\<leftarrow> return $ idx + iterations * 16; (* should be 2^PD_BITS - 16 *)\n     phys \\<leftarrow> return $ phys + iterations * (2^pageBitsForSize(ARMSuperSection));",
    "system": "",
    "history": []
  },
  {
    "instruction": "Map Memory Sections: Map 15 megabytes of memory using 1-megabyte frames, starting from a specified physical address. Each frame is mapped with specific attributes (parity enabled and page cacheable) and restricted to kernel-only access.",
    "input": "",
    "output": "(swp mapM) [0 .e. 14] (\\<lambda>i. do\n         phys' \\<leftarrow> return $ phys + i * (2^(pageBitsForSize(ARMSection)));\n         pde \\<leftarrow> return $ SectionPDE phys' {ParityEnabled,PageCacheable} 0\n                                   vm_kernel_only;\n         store_pde (idx + i) pde\n       od);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Advance Index and Physical Address: Increment the index and physical address to align with the exit condition of a loop, ensuring that they are updated by a fixed value corresponding to the page size and the number of entries.",
    "input": "",
    "output": "idx \\<leftarrow> return $ idx + 15; (* should be 2^PD_BITS - 1 *)\n     phys \\<leftarrow> return $ phys + 15 * (2^pageBitsForSize(ARMSection));",
    "system": "",
    "history": []
  },
  {
    "instruction": "Map Global Page Table: Map the global page table into the last slot of the global page directory by creating and storing a Page Table PDE.",
    "input": "",
    "output": "global_pt \\<leftarrow> get_arm_global_pt;\n     pde \\<leftarrow> return $ PageTablePDE (addrFromPPtr global_pt) {ParityEnabled} 0;\n     store_pde idx pde;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Page Table: Set up the initial page table by retyping a specified region of memory to be used as a page table, ensuring that the kernel has a properly configured memory structure for managing virtual-to-physical address translations.",
    "input": "",
    "output": "retype_region global_pt 1 PT_SIZE_BITS\n                   (ArchObject PageTableObj);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Map Kernel Frame: Maps the vector table from physical to virtual memory with specific attributes, including parity enabled and page cacheable, ensuring proper initialization and accessibility of the kernel's vector table.",
    "input": "",
    "output": "map_kernel_frame (addrFromPPtr arm_vector_table) PPTR_VECTOR_TABLE\n                      vm_kernel_only {ParityEnabled,PageCacheable};",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Map the global frame with read-only permissions and specific memory attributes (parity enabled and page cacheable) to ensure the integrity and performance of the kernel's global data.",
    "input": "",
    "output": "globals_frame \\<leftarrow> gets (arm_globals_frame \\<circ> arch_state);\n     map_kernel_frame (addrFromPPtr globals_frame) PPTR_GLOBALS_PAGE\n                      vm_read_only {ParityEnabled,PageCacheable};",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Initializes the kernel by setting up the virtual memory, initializing CPU and platform-specific components, creating root and IRQ cnode capabilities, and initializing interrupt handling. This ensures that the kernel is properly configured and ready for operation.",
    "input": "",
    "output": "map_kernel_frame (addrFromPPtr arm_kernel_stack) PPTR_KERNEL_STACK\n                      vm_kernel_only {ParityEnabled,PageCacheable};\n\n     map_kernel_devices\n   od\"\n\n\n\ndefinition\n  paddr_to_pptr_reg :: \"(paddr \\<times> paddr) \\<Rightarrow> (paddr \\<times> paddr)\" where\n  \"paddr_to_pptr_reg p_reg \\<equiv> (fst p_reg + pptrBaseOffset,\n                              snd p_reg + pptrBaseOffset)\"\n\ndefinition\n  init_kernel :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> word32 \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"init_kernel ui_p_reg_start ui_p_reg_end pv_offset v_entry \\<equiv>\n   let ui_v_reg_start = ui_p_reg_start - pv_offset;\n       ui_v_reg_end = ui_p_reg_end - pv_offset;\n       ui_v_reg = (ui_v_reg_start, ui_v_reg_end);\n       ui_reg = paddr_to_pptr_reg (ui_p_reg_start, ui_p_reg_end)\n   in\n   doE\n     do_kernel_op $ map_kernel_window;\n     do_kernel_op $ init_cpu;\n     do_kernel_op $ init_plat;\n     init_freemem ui_reg;\n     root_cnode_cap \\<leftarrow> create_root_cnode;\n     create_irq_cnode;\n     do_kernel_op $ init_irqs root_cnode_cap;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IPC Buffer and Boot Info Frame: Creates the initial thread's IPC buffer and boot info frame, ensuring that the necessary memory structures are set up for inter-process communication and boot information.",
    "input": "",
    "output": "ipcbuf_ret \\<leftarrow> create_ipcbuf_frame root_cnode_cap ui_v_reg;\n\n     bi_frame_vptr \\<leftarrow> create_bi_frame root_cnode_cap ui_v_reg\n                                     (snd ipcbuf_ret) 0 1;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Userland Image: Create and initialize frame objects for the userland image, store the information in the bootinfo frame, and synchronize the bootinfo frame to ensure the system is properly set up for boot.",
    "input": "",
    "output": "ui_fr_caps \\<leftarrow> create_frames_of_region root_cnode_cap ui_reg True pv_offset;\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_ui_frame_caps := ui_fr_caps \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Page Directory and Page Tables: Create and initialize the page directory and page tables for the userland image, and write the initialized page directory and page tables to the root CNode.",
    "input": "",
    "output": "it_pd_cap \\<leftarrow> create_it_pd_pts root_cnode_cap ui_v_reg (snd ipcbuf_ret)\n                                   bi_frame_vptr;\n     write_it_pd_pts root_cnode_cap it_pd_cap;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize ASID Pool: Create and initialize the initial thread's ASID pool, and write the ASID pool capability to the kernel's initial ASID pool. Additionally, create the idle thread to ensure the system is ready for operation.",
    "input": "",
    "output": "it_ap_cap \\<leftarrow> create_it_asid_pool root_cnode_cap;\n     do_kernel_op $ write_it_asid_pool it_ap_cap it_pd_cap;\n\n     create_idle_thread;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Initial Thread: Initializes the first thread in the system, setting up essential capabilities and resources such as the root CNode, initial page directory, virtual entry, and IPC buffer.",
    "input": "",
    "output": "create_initial_thread root_cnode_cap it_pd_cap v_entry bi_frame_vptr\n                           (snd ipcbuf_ret) (fst ipcbuf_ret);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Untyped Object: Initialize an untyped object in the kernel's memory space, reclaiming the boot code and data area. This ensures that the memory previously used for boot code and data is made available for other uses, optimizing memory utilization.",
    "input": "",
    "output": "create_untyped_obj root_cnode_cap (kernel_base, ki_boot_end);",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Device Frames: Initialize and allocate memory frames for device usage, ensuring that the necessary resources are available for device operations.",
    "input": "",
    "output": "create_device_frames root_cnode_cap;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Initialization: Initialize the kernel by setting the shared frame capabilities to zero, indicating no shared frame capabilities are used. Finalize the boot information and clean the cache to ensure the system starts in a known, consistent state.",
    "input": "",
    "output": "liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_sh_frame_caps := (0,0) \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame;\n\n     bi_finalise;\n\n     do_kernel_op $ do_machine_op cleanCache\n   odE\n  \"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Arguments Encoding: Defines the structure of arguments for various system calls, including operations on capabilities, untyped memory, thread control, interrupt handling, and domain management. These datatypes ensure that the system calls are provided with the necessary parameters to perform their intended actions, maintaining the integrity and functionality of the operating system.",
    "input": "",
    "output": "datatype cnode_invocation =\n    InsertCall cap cslot_ptr cslot_ptr\n  | MoveCall cap cslot_ptr cslot_ptr\n  | RevokeCall cslot_ptr\n  | DeleteCall cslot_ptr\n  | RotateCall cap cap cslot_ptr cslot_ptr cslot_ptr\n  | SaveCall cslot_ptr\n  | CancelBadgedSendsCall cap\n\ndatatype untyped_invocation =\n    Retype cslot_ptr bool obj_ref obj_ref apiobject_type nat \"cslot_ptr list\" bool\n\ndatatype tcb_invocation =\n    WriteRegisters machine_word bool \"machine_word list\" arch_copy_register_sets\n  | ReadRegisters machine_word bool machine_word arch_copy_register_sets\n  | CopyRegisters machine_word machine_word bool bool bool bool arch_copy_register_sets\n  | ThreadControl (tc_target: machine_word) (tc_slot: cslot_ptr)\n                  (tc_new_fault_ep: \"cap_ref option\")\n                  (tc_new_mcpriority: \"(word8 * obj_ref) option\")\n                  (tc_new_priority: \"(word8 * obj_ref) option\")\n                  (tc_new_croot: \"(cap * cslot_ptr) option\")\n                  (tc_new_vroot: \"(cap * cslot_ptr) option\")\n                  (tc_new_buffer: \"(vspace_ref * (cap * cslot_ptr) option) option\")\n  | Suspend \"obj_ref\"\n  | Resume \"obj_ref\"\n  | NotificationControl \"obj_ref\" \"obj_ref option\"\n  | SetTLSBase obj_ref machine_word\n\ndatatype irq_control_invocation =\n    IRQControl irq cslot_ptr cslot_ptr\n  | ArchIRQControl arch_irq_control_invocation\n\ndatatype irq_handler_invocation =\n    ACKIrq irq\n  | SetIRQHandler irq cap cslot_ptr\n  | ClearIRQHandler irq\n\ndatatype invocation =\n    InvokeUntyped untyped_invocation\n  | InvokeEndpoint obj_ref machine_word bool bool\n  | InvokeNotification obj_ref machine_word\n  | InvokeReply obj_ref cslot_ptr bool\n  | InvokeTCB tcb_invocation\n  | InvokeDomain obj_ref word8\n  | InvokeCNode cnode_invocation\n  | InvokeIRQControl irq_control_invocation\n  | InvokeIRQHandler irq_handler_invocation\n  | InvokeArchObject arch_invocation\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Access and Modification: Retrieve and update capabilities in a uniform manner from either a CNode or a TCB. Ensure that the capability slots are well-formed and within the valid range, and update the corresponding fields in the TCB or CNode.",
    "input": "",
    "output": "text \\<open>\n Recall that a capability may reside in either a CNode, or inside a TCB;\nthe following definitions allow the kernel model to retrieve and update\ncapabilities in a uniform fashion.\\<close>\ndefinition\n  get_cap :: \"cslot_ptr \\<Rightarrow> (cap,'z::state_ext) s_monad\"\nwhere\n  \"get_cap \\<equiv> \\<lambda>(oref, cref). do\n     obj \\<leftarrow> get_object oref;\n     caps \\<leftarrow> case obj of\n             CNode sz cnode \\<Rightarrow> do\n                                assert (well_formed_cnode_n sz cnode);\n                                return cnode\n                              od\n           | TCB tcb     \\<Rightarrow> return (tcb_cnode_map tcb)\n           | _ \\<Rightarrow> fail;\n     assert_opt (caps cref)\n   od\"\n\ndefinition\n  set_cap :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_cap cap \\<equiv> \\<lambda>(oref, cref). do\n     obj \\<leftarrow> get_object oref;\n     obj' \\<leftarrow> case obj of\n               CNode sz cn \\<Rightarrow> if cref \\<in> dom cn \\<and> well_formed_cnode_n sz cn\n                                then return $ CNode sz $ cn (cref \\<mapsto> cap)\n                                else fail\n             | TCB tcb \\<Rightarrow>\n                   if cref = tcb_cnode_index 0 then\n                       return $ TCB $ tcb \\<lparr> tcb_ctable := cap \\<rparr>\n                   else if cref = tcb_cnode_index 1 then\n                       return $ TCB $ tcb \\<lparr> tcb_vtable := cap \\<rparr>\n                   else if cref = tcb_cnode_index 2 then\n                       return $ TCB $ tcb \\<lparr> tcb_reply := cap \\<rparr>\n                   else if cref = tcb_cnode_index 3 then\n                       return $ TCB $ tcb \\<lparr> tcb_caller := cap \\<rparr>\n                   else if cref = tcb_cnode_index 4 then\n                       return $ TCB $ tcb \\<lparr> tcb_ipcframe := cap \\<rparr>\n                   else\n                       fail\n             | _ \\<Rightarrow> fail;\n     set_object oref obj'\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure Slot Emptiness: Verify that a given capability slot is empty, and if it contains a non-null capability, an error is thrown to indicate the slot must be cleared.",
    "input": "",
    "output": "definition\n  ensure_empty :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"ensure_empty slot \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap slot;\n    whenE (cap \\<noteq> NullCap) (throwError DeleteFirst)\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Capability Derivation Tree: Updates the capability derivation tree to a new value, ensuring that the system's capability structure is correctly maintained.",
    "input": "",
    "output": "text \\<open>Set the capability derivation tree.\\<close>\ndefinition\n  set_cdt :: \"cdt \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_cdt t \\<equiv> do\n    s \\<leftarrow> get;\n    put $ s\\<lparr> cdt := t \\<rparr>\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Capability Derivation Tree: Modify the capability derivation tree by applying a given function to the current tree, ensuring that the updated tree reflects the changes accurately.",
    "input": "",
    "output": "definition\n  update_cdt :: \"(cdt \\<Rightarrow> cdt) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"update_cdt f \\<equiv> do\n     t \\<leftarrow> gets cdt;\n     set_cdt (f t)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Original Flag: Update the original flag for a specified capability slot, ensuring that the flag reflects whether the capability is an original or a derived one.",
    "input": "",
    "output": "definition\n  set_original :: \"cslot_ptr \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_original slot v \\<equiv> do\n     r \\<leftarrow> gets is_original_cap;\n     modify (\\<lambda>s. s \\<lparr> is_original_cap := r (slot := v) \\<rparr>)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Derivation Tree Relations: Define relationships between capability slots in the capability derivation tree, including direct parent-child relationships, transitive parent-child relationships, and reflexive-transitive parent-child relationships. These relations enable the system to track and manage the hierarchical structure of capabilities within the CSpace.",
    "input": "",
    "output": "definition\n  is_cdt_parent :: \"cdt \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\" where\n  \"is_cdt_parent t p c \\<equiv> t c = Some p\"\n\ndefinition\n  cdt_parent_rel :: \"cdt \\<Rightarrow> (cslot_ptr \\<times> cslot_ptr) set\" where\n  \"cdt_parent_rel t \\<equiv> {(p,c). is_cdt_parent t p c}\"\n\nabbreviation\n  parent_of :: \"cdt \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of _\" [60,0,60] 61)\nwhere\n  \"t \\<turnstile> p cdt_parent_of c \\<equiv> (p,c) \\<in> cdt_parent_rel t\"\n\nabbreviation\n  parent_of_trancl :: \"cdt \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>+ _\" [60,0,60] 61)\nwhere\n  \"t \\<turnstile> x cdt_parent_of\\<^sup>+ y \\<equiv> (x, y) \\<in> (cdt_parent_rel t)\\<^sup>+\"\n\nabbreviation\n  parent_of_rtrancl :: \"cdt \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>* _\" [60,0,60] 61)\nwhere\n  \"t \\<turnstile> x cdt_parent_of\\<^sup>* y \\<equiv> (x, y) \\<in> (cdt_parent_rel t)\\<^sup>*\"\n\n\nnotation\n  parent_of (\"_ \\<Turnstile> _ \\<leadsto> _\" [60,0,60] 60)\nand\n  parent_of_trancl (\"_ \\<Turnstile> _ \\<rightarrow> _\" [60,0,60] 60)\nand\n  parent_of_rtrancl (\"_ \\<Turnstile> _ \\<rightarrow>* _\" [60,0,60] 60)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Descendants of a CSlot: Identify all the descendant slots of a given slot in the capability derivation tree, forming a set that includes all slots that are reachable from the given slot through the parent-child relationships in the tree.",
    "input": "",
    "output": "definition\n  descendants_of :: \"cslot_ptr \\<Rightarrow> cdt \\<Rightarrow> cslot_ptr set\" where\n  \"descendants_of p t \\<equiv> {q. (p,q) \\<in> (cdt_parent_rel t)\\<^sup>+}\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Message Information: Obtain the message information from the specified thread's message info register and convert it to a structured message information format.",
    "input": "",
    "output": "definition\n  get_message_info :: \"obj_ref \\<Rightarrow> (message_info,'z::state_ext) s_monad\"\nwhere\n  \"get_message_info thread \\<equiv> do\n     x \\<leftarrow> as_user thread $ getRegister msg_info_register;\n     return $ data_to_message_info x\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Modify Capabilities: Adjust the rights of a capability by removing specified rights, ensuring that the capability's permissions are appropriately restricted.",
    "input": "",
    "output": "definition\n  remove_rights :: \"cap_rights \\<Rightarrow> cap \\<Rightarrow> cap\"\nwhere\n \"remove_rights rights cap \\<equiv> cap_rights_update (cap_rights cap - rights) cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Additional Capabilities: Retrieve the identities of additional capabilities from the thread's IPC buffer. Load the word offsets corresponding to the extra capabilities and convert them to capability pointers.",
    "input": "",
    "output": "definition\n  buffer_cptr_index :: nat\nwhere\n \"buffer_cptr_index \\<equiv> (msg_max_length + 2)\"\n\nprimrec\n  get_extra_cptrs :: \"obj_ref option \\<Rightarrow> message_info \\<Rightarrow> (cap_ref list,'z::state_ext) s_monad\"\nwhere\n  \"get_extra_cptrs (Some buf) mi =\n    (liftM (map data_to_cptr) $ mapM (load_word_offs buf)\n        [buffer_cptr_index ..< buffer_cptr_index + (unat (mi_extra_caps mi))])\"\n| \"get_extra_cptrs None mi = return []\"\n\ndefinition\n  get_extra_cptr :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> (cap_ref,'z::state_ext) s_monad\"\nwhere\n  \"get_extra_cptr buffer n \\<equiv> liftM data_to_cptr\n      (load_word_offs buffer (n + buffer_cptr_index))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup and Retrieve Extra Capabilities: Retrieve the additional capability pointers from the thread's IPC buffer and look up the corresponding capabilities and their slot pointers in the sender's CSpace, handling any faults that may occur during the process.",
    "input": "",
    "output": "definition\n  lookup_extra_caps :: \"obj_ref \\<Rightarrow> data option \\<Rightarrow> message_info \\<Rightarrow> ((cap \\<times> cslot_ptr) list,'z::state_ext) f_monad\" where\n  \"lookup_extra_caps thread buffer mi \\<equiv> doE\n       cptrs \\<leftarrow> liftE $ get_extra_cptrs buffer mi;\n       mapME (\\<lambda>cptr. cap_fault_on_failure (of_bl cptr) False $ lookup_cap_and_slot thread cptr) cptrs\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Transfer and Unwrapping: During message passing, capabilities are divided into two groups. Capabilities to the same endpoint as the message are not copied; instead, their badges are unwrapped and stored in the receiver's message buffer. Other capabilities are copied into the specified slots, ensuring that the receiver can efficiently demonstrate authority to multiple services provided by the sender.",
    "input": "",
    "output": "definition\n  set_extra_badge :: \"obj_ref \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_extra_badge buffer badge n \\<equiv>\n      store_word_offs buffer (buffer_cptr_index + n) badge\"\n\ntype_synonym transfer_caps_data = \"(cap \\<times> cslot_ptr) list \\<times> cslot_ptr list\"\n\nfun\n  transfer_caps_loop :: \"obj_ref option \\<Rightarrow> obj_ref \\<Rightarrow> nat\n                          \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> cslot_ptr list\n                          \\<Rightarrow> message_info \\<Rightarrow> (message_info,'z::state_ext) s_monad\"\nwhere\n  \"transfer_caps_loop ep rcv_buffer n [] slots\n      mi = return (MI (mi_length mi) (of_nat n) (mi_caps_unwrapped mi)\n                        (mi_label mi))\"\n| \"transfer_caps_loop ep rcv_buffer n ((cap, slot) # morecaps)\n         slots mi =\n  const_on_failure (MI (mi_length mi) (of_nat n) (mi_caps_unwrapped mi)\n                       (mi_label mi)) (doE\n    transfer_rest \\<leftarrow> returnOk $ transfer_caps_loop ep\n         rcv_buffer (n + 1) morecaps;\n    if (is_ep_cap cap \\<and> ep = Some (obj_ref_of cap))\n    then doE\n       liftE $ set_extra_badge rcv_buffer (cap_ep_badge cap) n;\n       liftE $ transfer_rest slots (MI (mi_length mi) (mi_extra_caps mi)\n         (mi_caps_unwrapped mi || (1 << n)) (mi_label mi))\n    odE\n    else if slots \\<noteq> []\n    then doE\n      cap' \\<leftarrow> derive_cap slot cap;\n      whenE (cap' = NullCap) $ throwError undefined;\n      liftE $ cap_insert cap' slot (hd slots);\n      liftE $ transfer_rest (tl slots) mi\n    odE\n    else returnOk (MI (mi_length mi) (of_nat n) (mi_caps_unwrapped mi)\n                       (mi_label mi))\n  odE)\"\n\ndefinition\n  transfer_caps :: \"message_info \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n                   obj_ref option \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow>\n                   (message_info,'z::state_ext) s_monad\"\nwhere\n  \"transfer_caps info caps endpoint receiver recv_buffer \\<equiv> do\n     dest_slots \\<leftarrow> get_receive_slots receiver recv_buffer;\n     mi' \\<leftarrow> return $ MI (mi_length info) 0 0 (mi_label info);\n     case recv_buffer of\n       None \\<Rightarrow> return mi'\n     | Some receive_buffer \\<Rightarrow>\n         transfer_caps_loop endpoint receive_buffer 0 caps dest_slots mi'\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Fault Handling: When a thread attempts to access services without the necessary resources, it is blocked, and a fault message is sent to its supervisor. Upon receiving a reply to the fault message, the thread is reactivated.",
    "input": "",
    "output": "text \\<open>Threads fault when they attempt to access services that are not backed\nby any resources. Such a thread is then blocked and a fault messages is sent to\nits supervisor. When a reply to that message is sent the thread is reactivated.\n\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Message Formatting: Construct a message for a given fault type, including relevant details such as the program counter, capability pointer, and other fault-specific information. The message is formatted based on the type of fault, ensuring that the necessary data is included for proper handling.",
    "input": "",
    "output": "fun\n  make_fault_msg :: \"fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n  \"make_fault_msg (CapFault cptr rp lf) thread = (do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (1, pc # cptr # (if rp then 1 else 0) # msg_from_lookup_failure lf)\n   od)\"\n| \"make_fault_msg (UnknownSyscallException n) thread = (do\n     msg \\<leftarrow> as_user thread $ mapM getRegister syscallMessage;\n     return (2, msg @ [n])\n   od)\"\n| \"make_fault_msg (UserException exception code) thread = (do\n     msg \\<leftarrow> as_user thread $ mapM getRegister exceptionMessage;\n     return (3, msg @ [exception, code])\n   od)\"\n| \"make_fault_msg (ArchFault af) thread = make_arch_fault_msg af thread \" (* arch_fault *)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Handling: Processes fault replies by interpreting the message based on the type of the original fault. For certain faults, it reconfigures the thread to save the recipient an additional system call. The function returns a boolean indicating whether the thread should be restarted.",
    "input": "",
    "output": "fun\n  handle_fault_reply :: \"fault \\<Rightarrow> obj_ref \\<Rightarrow>\n                         data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_fault_reply (CapFault cptr rp lf) thread x y = return True\"\n| \"handle_fault_reply (UnknownSyscallException n) thread label msg = do\n     t \\<leftarrow> arch_get_sanitise_register_info thread;\n     as_user thread $ zipWithM_x\n         (\\<lambda>r v. setRegister r $ sanitise_register t r v)\n         syscallMessage msg;\n     return (label = 0)\n   od\"\n| \"handle_fault_reply (UserException exception code) thread label msg = do\n     t \\<leftarrow> arch_get_sanitise_register_info thread;\n     as_user thread $ zipWithM_x\n         (\\<lambda>r v. setRegister r $ sanitise_register t r v)\n         exceptionMessage msg;\n     return (label = 0)\n   od\"\n| \" handle_fault_reply (ArchFault af) thread label msg =\n    handle_arch_fault_reply af thread label msg\" (* arch_fault *)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Message Transfer: Transfers a fault message from a faulting thread to its supervisor, including setting the message information and badge register for the receiver.",
    "input": "",
    "output": "definition\n  do_fault_transfer :: \"data \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref\n                             \\<Rightarrow> obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"do_fault_transfer badge sender receiver buf \\<equiv> do\n    fault \\<leftarrow> thread_get tcb_fault sender;\n    f \\<leftarrow> (case fault of\n         Some f \\<Rightarrow> return f\n       | None \\<Rightarrow> fail);\n    (label, msg) \\<leftarrow> make_fault_msg f sender;\n    sent \\<leftarrow> set_mrs receiver buf msg;\n    set_message_info receiver $ MI sent 0 0 label;\n    as_user receiver $ setRegister badge_register badge\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Synchronous Message Transfer: Transfers a non-fault message from the sender to the receiver, including the message data, badge, and optionally additional capabilities. The transfer updates the message information for the receiver and sets the badge register.",
    "input": "",
    "output": "text \\<open>Transfer a non-fault message.\\<close>\ndefinition\n  do_normal_transfer :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> obj_ref option\n                                    \\<Rightarrow> data \\<Rightarrow> bool \\<Rightarrow> obj_ref\n                                    \\<Rightarrow> obj_ref option\n                                    \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"do_normal_transfer sender sbuf endpoint badge grant\n                     receiver rbuf  \\<equiv>\n  do\n    mi \\<leftarrow> get_message_info sender;\n    caps \\<leftarrow> if grant then lookup_extra_caps sender sbuf mi <catch> K (return [])\n      else return [];\n    mrs_transferred \\<leftarrow> copy_mrs sender sbuf receiver rbuf (mi_length mi);\n    mi' \\<leftarrow> transfer_caps mi caps endpoint receiver rbuf;\n    set_message_info receiver $ MI mrs_transferred (mi_extra_caps mi')\n                                   (mi_caps_unwrapped mi') (mi_label mi);\n    as_user receiver $ setRegister badge_register badge\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Synchronous Message Transfer: Perform a message transfer between a sender and a receiver, which may involve handling a fault. If no fault is present, a normal transfer is executed; otherwise, a fault-specific transfer is conducted.",
    "input": "",
    "output": "definition\n  do_ipc_transfer :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow>\n                       badge \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"do_ipc_transfer sender ep badge grant\n     receiver \\<equiv> do\n\n     recv_buffer \\<leftarrow> lookup_ipc_buffer True receiver;\n     fault \\<leftarrow> thread_get tcb_fault sender;\n\n     case fault\n        of None \\<Rightarrow> do\n            send_buffer \\<leftarrow> lookup_ipc_buffer False sender;\n            do_normal_transfer sender send_buffer ep badge grant\n                           receiver recv_buffer\n            od\n         | Some f \\<Rightarrow> do_fault_transfer badge sender receiver recv_buffer\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Synchronous Reply Transfer: Transfers a reply message from the sender to the receiver, deletes the one-use Reply capability, and updates the receiver's thread state. If the receiver is blocked on a reply, it resumes the receiver in the Running state; if there is a fault, it handles the fault, updates the receiver's fault status, and sets the receiver's state based on the fault handling result.",
    "input": "",
    "output": "definition\n  do_reply_transfer :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"do_reply_transfer sender receiver slot grant \\<equiv> do\n    state \\<leftarrow> get_thread_state receiver;\n    assert (state = BlockedOnReply);\n    fault \\<leftarrow> thread_get tcb_fault receiver;\n    case fault of\n      None \\<Rightarrow> do\n         do_ipc_transfer sender None 0 grant receiver;\n         cap_delete_one slot;\n         set_thread_state receiver Running;\n         do_extended_op (possible_switch_to receiver)\n      od\n    | Some f \\<Rightarrow> do\n         cap_delete_one slot;\n         mi \\<leftarrow> get_message_info sender;\n         buf \\<leftarrow> lookup_ipc_buffer False sender;\n         mrs \\<leftarrow> get_mrs sender buf mi;\n         restart \\<leftarrow> handle_fault_reply f receiver (mi_label mi) mrs;\n         thread_set (\\<lambda>tcb. tcb \\<lparr> tcb_fault := None \\<rparr>) receiver;\n         set_thread_state receiver (if restart then Restart else Inactive);\n         when restart $ do_extended_op (possible_switch_to receiver);\n         return ()\n       od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Synchronous Message Transfer: Transfers a reply message to a thread from the kernel, setting the badge register to 0, updating the IPC buffer with the message, and setting the message information.",
    "input": "",
    "output": "definition\n  reply_from_kernel :: \"obj_ref \\<Rightarrow> (data \\<times> data list) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"reply_from_kernel thread x \\<equiv> do\n    (label, msg) \\<leftarrow> return x;\n    buf \\<leftarrow> lookup_ipc_buffer True thread;\n    as_user thread $ setRegister badge_register 0;\n    len \\<leftarrow> set_mrs thread buf msg;\n    set_message_info thread $ MI len 0 0 label\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Install Reply Capability: Set up a one-use Reply capability for the sender, placing it in the receiver's CNode. The capability is configured with specific permissions, including AllowWrite and optionally AllowGrant, and the sender is placed in a BlockedOnReply state.",
    "input": "",
    "output": "definition\n  setup_caller_cap :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"setup_caller_cap sender receiver grant \\<equiv> do\n    set_thread_state sender BlockedOnReply;\n    cap_insert (ReplyCap sender False (if grant then {AllowGrant, AllowWrite} else {AllowWrite}))\n               (sender, tcb_cnode_index 2)\n      (receiver, tcb_cnode_index 3)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Synchronous Message Transfer: Handles message send operations on an endpoint by a thread, transferring the message to a waiting receiver if available. If no receiver is waiting and the thread is willing to block, it is placed in the sending queue of the endpoint. If the thread is not willing to block and there is no waiting receiver, the operation does nothing.",
    "input": "",
    "output": "definition\n  send_ipc :: \"bool \\<Rightarrow> bool \\<Rightarrow> badge \\<Rightarrow> bool \\<Rightarrow> bool\n                \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"send_ipc block call badge can_grant can_grant_reply thread epptr \\<equiv> do\n     ep \\<leftarrow> get_endpoint epptr;\n     case (ep, block) of\n         (IdleEP, True) \\<Rightarrow> do\n               set_thread_state thread (BlockedOnSend epptr\n                                   \\<lparr> sender_badge = badge,\n                                     sender_can_grant = can_grant,\n                                     sender_can_grant_reply = can_grant_reply,\n                                     sender_is_call = call \\<rparr>);\n               set_endpoint epptr $ SendEP [thread]\n             od\n       | (SendEP queue, True) \\<Rightarrow> do\n               set_thread_state thread (BlockedOnSend epptr\n                                   \\<lparr> sender_badge = badge,\n                                     sender_can_grant = can_grant,\n                                     sender_can_grant_reply = can_grant_reply,\n                                     sender_is_call = call\\<rparr>);\n               set_endpoint epptr $ SendEP (queue @ [thread])\n             od\n       | (IdleEP, False) \\<Rightarrow> return ()\n       | (SendEP queue, False) \\<Rightarrow> return ()\n       | (RecvEP (dest # queue), _) \\<Rightarrow> do\n                set_endpoint epptr $ (case queue of [] \\<Rightarrow> IdleEP\n                                                     | _ \\<Rightarrow> RecvEP queue);\n                recv_state \\<leftarrow> get_thread_state dest;\n                reply_can_grant \\<leftarrow> case recv_state\n                  of (BlockedOnReceive x data) \\<Rightarrow> do\n                           do_ipc_transfer thread (Some epptr) badge can_grant dest;\n                           return (receiver_can_grant data)\n                           od\n                  | _ \\<Rightarrow> fail;\n                set_thread_state dest Running;\n                do_extended_op (possible_switch_to dest);\n                when call $\n                  if (can_grant \\<or> can_grant_reply)\n                  then setup_caller_cap thread dest reply_can_grant\n                  else set_thread_state thread Inactive\n                od\n\n       | (RecvEP [], _) \\<Rightarrow> fail\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Message Reception on Endpoint: Handle a message receive operation on an endpoint by a thread. If a sender is waiting, the message is transferred; otherwise, the thread is placed in the endpoint's receiving queue.",
    "input": "",
    "output": "definition\n  isActive :: \"notification \\<Rightarrow> bool\"\nwhere\n  \"isActive ntfn \\<equiv> case ntfn_obj ntfn\n     of ActiveNtfn _ \\<Rightarrow> True\n      | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Synchronous Message Transfers: Handle the reception of IPC messages, including processing notifications, managing thread states, and transferring data between sender and receiver. The system ensures that threads are correctly blocked or unblocked based on the message reception status, and it properly updates endpoint states to reflect the current communication status.",
    "input": "",
    "output": "definition\n  complete_signal :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"complete_signal ntfnptr tcb \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     case ntfn_obj ntfn of\n       ActiveNtfn badge \\<Rightarrow> do\n           as_user tcb $ setRegister badge_register badge;\n           set_notification ntfnptr $ ntfn_set_obj ntfn IdleNtfn\n         od\n     | _ \\<Rightarrow> fail\n   od\"\n\ndefinition\n  do_nbrecv_failed_transfer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"do_nbrecv_failed_transfer thread = do as_user thread $ setRegister badge_register 0; return () od\"\n\ndefinition\n  receive_ipc :: \"obj_ref \\<Rightarrow> cap \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"receive_ipc thread cap is_blocking \\<equiv> do\n     (epptr,rights) \\<leftarrow> (case cap\n                       of EndpointCap ref badge rights \\<Rightarrow> return (ref,rights)\n                        | _ \\<Rightarrow> fail);\n     ep \\<leftarrow> get_endpoint epptr;\n     ntfnptr \\<leftarrow> get_bound_notification thread;\n     ntfn \\<leftarrow> case_option (return default_notification) get_notification ntfnptr;\n     if (ntfnptr \\<noteq> None \\<and> isActive ntfn)\n     then\n       complete_signal (the ntfnptr) thread\n     else\n       case ep\n         of IdleEP \\<Rightarrow> (case is_blocking of\n              True \\<Rightarrow> do\n                  set_thread_state thread (BlockedOnReceive epptr\n                                           \\<lparr>receiver_can_grant = (AllowGrant \\<in> rights)\\<rparr>);\n                  set_endpoint epptr (RecvEP [thread])\n                od\n              | False \\<Rightarrow> do_nbrecv_failed_transfer thread)\n            | RecvEP queue \\<Rightarrow> (case is_blocking of\n              True \\<Rightarrow> do\n                  set_thread_state thread (BlockedOnReceive epptr\n                                           \\<lparr>receiver_can_grant = (AllowGrant \\<in> rights)\\<rparr>);\n                  set_endpoint epptr (RecvEP (queue @ [thread]))\n                od\n              | False \\<Rightarrow> do_nbrecv_failed_transfer thread)\n          | SendEP q \\<Rightarrow> do\n              assert (q \\<noteq> []);\n              queue \\<leftarrow> return $ tl q;\n              sender \\<leftarrow> return $ hd q;\n              set_endpoint epptr $\n                (case queue of [] \\<Rightarrow> IdleEP | _ \\<Rightarrow> SendEP queue);\n              sender_state \\<leftarrow> get_thread_state sender;\n              data \\<leftarrow> (case sender_state\n                       of BlockedOnSend ref data \\<Rightarrow> return data\n                        | _ \\<Rightarrow> fail);\n              do_ipc_transfer sender (Some epptr)\n                        (sender_badge data) (sender_can_grant data)\n                        thread;\n              if (sender_is_call data)\n              then\n                if (sender_can_grant data \\<or> sender_can_grant_reply data)\n                then setup_caller_cap sender thread (AllowGrant \\<in> rights)\n                else set_thread_state sender Inactive\n              else do\n                set_thread_state sender Running;\n                do_extended_op (possible_switch_to sender)\n              od\n            od\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Waiting Notification: Updates the state of a waiting notification, setting the notification object and bound thread control block, transitioning the destination thread to the running state, and setting the badge register. If there are more threads in the queue, it updates the notification to reflect the new waiting state; otherwise, it sets the notification to idle. This ensures that the next thread in the queue is properly prepared for execution.",
    "input": "",
    "output": "text \\<open>Helper function to handle a signal operation in the case\nwhere a receiver is waiting.\\<close>\ndefinition\n  update_waiting_ntfn :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref option \\<Rightarrow> badge \\<Rightarrow>\n                         (unit,'z::state_ext) s_monad\"\nwhere\n  \"update_waiting_ntfn ntfnptr queue bound_tcb badge \\<equiv> do\n     assert (queue \\<noteq> []);\n     (dest,rest) \\<leftarrow> return $ (hd queue, tl queue);\n     set_notification ntfnptr $ \\<lparr>\n         ntfn_obj = (case rest of [] \\<Rightarrow> IdleNtfn | _ \\<Rightarrow> WaitingNtfn rest),\n         ntfn_bound_tcb = bound_tcb \\<rparr>;\n     set_thread_state dest Running;\n     as_user dest $ setRegister badge_register badge;\n     do_extended_op (possible_switch_to dest)\n\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Send Signal for Asynchronous Message Transfers: Sends a signal to a notification object, which may unblock a thread if it is blocked on receiving a message. If the thread is blocked, it cancels the IPC, sets the thread state to running, and updates the badge register. If the notification is in an idle or active state, it updates the notification object accordingly. If the notification is in a waiting state, it updates the waiting notification queue.",
    "input": "",
    "output": "definition\n  receive_blocked :: \"thread_state \\<Rightarrow> bool\"\nwhere\n  \"receive_blocked st \\<equiv> case st of\n       BlockedOnReceive _ _ \\<Rightarrow> True\n     | _ \\<Rightarrow> False\"\n\ndefinition\n  send_signal :: \"obj_ref \\<Rightarrow> badge \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"send_signal ntfnptr badge \\<equiv> do\n    ntfn \\<leftarrow> get_notification ntfnptr;\n    case (ntfn_obj ntfn, ntfn_bound_tcb ntfn) of\n          (IdleNtfn, Some tcb) \\<Rightarrow> do\n                  st \\<leftarrow> get_thread_state tcb;\n                  if (receive_blocked st)\n                  then do\n                      cancel_ipc tcb;\n                      set_thread_state tcb Running;\n                      as_user tcb $ setRegister badge_register badge;\n                      do_extended_op (possible_switch_to tcb)\n                    od\n                  else set_notification ntfnptr $ ntfn_set_obj ntfn (ActiveNtfn badge)\n            od\n       | (IdleNtfn, None) \\<Rightarrow> set_notification ntfnptr $ ntfn_set_obj ntfn (ActiveNtfn badge)\n       | (WaitingNtfn queue, bound_tcb) \\<Rightarrow> update_waiting_ntfn ntfnptr queue bound_tcb badge\n       | (ActiveNtfn badge', _) \\<Rightarrow>\n           set_notification ntfnptr $ ntfn_set_obj ntfn $\n             ActiveNtfn (combine_ntfn_badges badge badge')\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Notification Receive Operation: Handles the receive operation on a notification object by a thread. If a message is waiting, it transfers the badge to the thread and resets the notification object. If no message is waiting and the operation is blocking, the thread is placed in the receiving queue of the notification; if non-blocking, it performs a failed transfer action.",
    "input": "",
    "output": "definition\n  receive_signal :: \"obj_ref \\<Rightarrow> cap \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n   \"receive_signal thread cap is_blocking \\<equiv> do\n    ntfnptr \\<leftarrow>\n      case cap\n        of NotificationCap ntfnptr badge rights \\<Rightarrow> return ntfnptr\n         | _ \\<Rightarrow> fail;\n    ntfn \\<leftarrow> get_notification ntfnptr;\n    case ntfn_obj ntfn\n      of IdleNtfn \\<Rightarrow>\n                   (case is_blocking of\n                     True \\<Rightarrow> do\n                          set_thread_state thread (BlockedOnNotification ntfnptr);\n                          set_notification ntfnptr $ ntfn_set_obj ntfn $ WaitingNtfn [thread]\n                        od\n                   | False \\<Rightarrow> do_nbrecv_failed_transfer thread)\n       | WaitingNtfn queue \\<Rightarrow>\n                   (case is_blocking of\n                     True \\<Rightarrow> do\n                          set_thread_state thread (BlockedOnNotification ntfnptr);\n                          set_notification ntfnptr $ ntfn_set_obj ntfn $ WaitingNtfn (queue @ [thread])\n                        od\n                   | False \\<Rightarrow> do_nbrecv_failed_transfer thread)\n       | ActiveNtfn badge \\<Rightarrow> do\n                     as_user thread $ setRegister badge_register badge;\n                     set_notification ntfnptr $ ntfn_set_obj ntfn IdleNtfn\n                   od\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Send Fault IPC: When a thread encounters a fault, retrieve its fault handler capability and send a fault message to the designated endpoint. The message is sent only if the handler capability has the necessary permissions (AllowSend and either AllowGrant or AllowGrantReply). If the handler does not have the required permissions, a CapFault is thrown.",
    "input": "",
    "output": "text \\<open>When a thread encounters a fault, retreive its fault handler capability\nand send a fault message.\\<close>\ndefinition\n  send_fault_ipc :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n  \"send_fault_ipc tptr fault \\<equiv> doE\n     handler_cptr \\<leftarrow> liftE $ thread_get tcb_fault_handler tptr;\n     handler_cap \\<leftarrow> cap_fault_on_failure (of_bl handler_cptr) False $\n         lookup_cap tptr handler_cptr;\n\n     let f = CapFault (of_bl handler_cptr) False (MissingCapability 0)\n     in\n     (case handler_cap\n       of EndpointCap ref badge rights \\<Rightarrow>\n           if AllowSend \\<in> rights \\<and> (AllowGrant \\<in> rights \\<or> AllowGrantReply \\<in> rights)\n           then liftE $ (do\n               thread_set (\\<lambda>tcb. tcb \\<lparr> tcb_fault := Some fault \\<rparr>) tptr;\n               send_ipc True True (cap_ep_badge handler_cap)\n                        (AllowGrant \\<in> rights) True tptr (cap_ep_ptr handler_cap)\n             od)\n           else throwError f\n        | _ \\<Rightarrow> throwError f)\n   odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Double Fault: Set the thread state to inactive if a fault message cannot be sent, ensuring that the thread remains in an inactive state to prevent further execution.",
    "input": "",
    "output": "definition\n  handle_double_fault :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_double_fault tptr ex1 ex2 \\<equiv> set_thread_state tptr Inactive\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Thread Fault: Manages a thread fault by attempting to send a fault message. If sending the fault message fails, it catches the exception and handles a double fault.",
    "input": "",
    "output": "definition\n  handle_fault :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_fault thread ex \\<equiv> do\n     _ \\<leftarrow> gets_the $ get_tcb thread;\n     send_fault_ipc thread ex\n          <catch> handle_double_fault thread ex;\n     return ()\n   od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Invocation Decoding: Decodes CNode invocations to perform various operations such as copying, moving, revoking, deleting, saving, canceling badged sends, and rotating capabilities. Ensures the integrity of the operation by validating the invocation type, arguments, and capability rights, and handles the appropriate actions based on the decoded information.",
    "input": "",
    "output": "text \\<open>This definition decodes CNode invocations.\\<close>\n\ndefinition\n  decode_cnode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap \\<Rightarrow> cap list \\<Rightarrow> (cnode_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_cnode_invocation label args cap excaps \\<equiv> doE\n  unlessE (gen_invocation_type label \\<in> set [CNodeRevoke .e. CNodeSaveCaller]) $\n    throwError IllegalOperation;\n  whenE (length args < 2) (throwError TruncatedMessage);\n  index \\<leftarrow> returnOk $ data_to_cptr $ args ! 0;\n  bits \\<leftarrow> returnOk $ data_to_nat $ args ! 1;\n  args \\<leftarrow> returnOk $ drop 2 args;\n  dest_slot \\<leftarrow> lookup_target_slot cap index bits;\n  if length args \\<ge> 2 \\<and> length excaps > 0\n        \\<and> gen_invocation_type label \\<in> set [CNodeCopy .e. CNodeMutate] then\n  doE\n    src_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 0;\n    src_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 1;\n    args \\<leftarrow> returnOk $ drop 2 args;\n    src_root_cap \\<leftarrow> returnOk $ excaps ! 0;\n    ensure_empty dest_slot;\n    src_slot \\<leftarrow>\n         lookup_source_slot src_root_cap src_index src_depth;\n    src_cap \\<leftarrow> liftE $ get_cap src_slot;\n    whenE (src_cap = NullCap) $\n         throwError $ FailedLookup True $ MissingCapability src_depth;\n    (rights, cap_data, is_move) \\<leftarrow> case (gen_invocation_type label, args) of\n      (CNodeCopy, rightsWord # _) \\<Rightarrow> doE\n                    rights \\<leftarrow> returnOk $ data_to_rights $ rightsWord;\n                    returnOk $ (rights, None, False)\n                odE\n     | (CNodeMint, rightsWord # capData # _) \\<Rightarrow> doE\n                    rights \\<leftarrow> returnOk $ data_to_rights $ rightsWord;\n                    returnOk $ (rights, Some capData, False)\n                odE\n     | (CNodeMove, _) \\<Rightarrow> returnOk (all_rights, None, True)\n     | (CNodeMutate, capData # _) \\<Rightarrow> returnOk (all_rights, Some capData, True)\n     | _ \\<Rightarrow> throwError TruncatedMessage;\n    src_cap \\<leftarrow> returnOk $ mask_cap rights src_cap;\n    new_cap \\<leftarrow> (if is_move then returnOk else derive_cap src_slot) (case cap_data of\n                  Some w \\<Rightarrow> update_cap_data is_move w src_cap\n                | None \\<Rightarrow> src_cap);\n    whenE (new_cap = NullCap) $ throwError IllegalOperation;\n    returnOk $ (if is_move then MoveCall else InsertCall) new_cap src_slot dest_slot\n  odE\n  else if gen_invocation_type label = CNodeRevoke then returnOk $ RevokeCall dest_slot\n  else if gen_invocation_type label = CNodeDelete then returnOk $ DeleteCall dest_slot\n  else if gen_invocation_type label = CNodeSaveCaller then doE\n    ensure_empty dest_slot;\n    returnOk $ SaveCall dest_slot\n  odE\n  else if gen_invocation_type label = CNodeCancelBadgedSends then doE\n    cap \\<leftarrow> liftE $ get_cap dest_slot;\n    unlessE (has_cancel_send_rights cap) $ throwError IllegalOperation;\n    returnOk $ CancelBadgedSendsCall cap\n  odE\n  else if gen_invocation_type label = CNodeRotate \\<and> length args > 5\n          \\<and> length excaps > 1 then\n  doE\n    pivot_new_data \\<leftarrow> returnOk $ args ! 0;\n    pivot_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 1;\n    pivot_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 2;\n    src_new_data \\<leftarrow> returnOk $ args ! 3;\n    src_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 4;\n    src_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 5;\n    pivot_root_cap <- returnOk $ excaps ! 0;\n    src_root_cap <- returnOk $ excaps ! 1;\n\n    src_slot <- lookup_source_slot src_root_cap src_index src_depth;\n    pivot_slot <- lookup_pivot_slot pivot_root_cap pivot_index pivot_depth;\n\n    whenE (pivot_slot = src_slot \\<or> pivot_slot = dest_slot) $\n      throwError IllegalOperation;\n\n    unlessE (src_slot = dest_slot) $ ensure_empty dest_slot;\n\n    src_cap <- liftE $ get_cap src_slot;\n    whenE (src_cap = NullCap) $\n      throwError $ FailedLookup True $ MissingCapability src_depth;\n\n    pivot_cap <- liftE $ get_cap pivot_slot;\n    whenE (pivot_cap = NullCap) $\n      throwError $ FailedLookup False $ MissingCapability pivot_depth;\n\n    new_src_cap \\<leftarrow> returnOk $ update_cap_data True src_new_data src_cap;\n    new_pivot_cap \\<leftarrow> returnOk $ update_cap_data True pivot_new_data pivot_cap;\n\n    whenE (new_src_cap = NullCap) $ throwError IllegalOperation;\n    whenE (new_pivot_cap = NullCap) $ throwError IllegalOperation;\n\n    returnOk $ RotateCall new_src_cap new_pivot_cap src_slot pivot_slot dest_slot\n  odE\n  else\n    throwError TruncatedMessage\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Invocation Decoding: Decode and process various TCB invocations, including actions such as suspending, resuming, reconfiguring, and managing capabilities and registers of threads. This ensures that the system can interpret and execute thread-related operations accurately, maintaining the integrity and functionality of the kernel.",
    "input": "",
    "output": "text \\<open>The definitions in this section decode invocations\non TCBs.\n\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Decoding: Decode various system calls related to thread control block (TCB) operations, including reading, writing, and copying registers, setting priorities, configuring IPC buffers, managing notification bindings, and setting TLS base. The decoding process ensures that the provided arguments and capabilities are valid, and it constructs the appropriate TCB invocation based on the system call type.",
    "input": "",
    "output": "definition\n  decode_read_registers :: \"data list \\<Rightarrow> cap \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_read_registers data cap \\<equiv> case data of\n  flags#n#_ \\<Rightarrow> doE\n    range_check n 1 $ of_nat (length frameRegisters + length gpRegisters);\n    p \\<leftarrow> case cap of ThreadCap p \\<Rightarrow> returnOk p;\n    self \\<leftarrow> liftE $ gets cur_thread;\n    whenE (p = self) $ throwError IllegalOperation;\n    returnOk $ ReadRegisters p (flags !! 0) n ArchDefaultExtraRegisters\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition\n  decode_copy_registers :: \"data list \\<Rightarrow> cap \\<Rightarrow> cap list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_copy_registers data cap extra_caps \\<equiv> case data of\n  flags#_ \\<Rightarrow>  doE\n    suspend_source \\<leftarrow> returnOk (flags !! 0);\n    resume_target \\<leftarrow> returnOk (flags !! 1);\n    transfer_frame \\<leftarrow> returnOk (flags !! 2);\n    transfer_integer \\<leftarrow> returnOk (flags !! 3);\n    whenE (extra_caps = []) $ throwError TruncatedMessage;\n    src_tcb \\<leftarrow> (case extra_caps of\n      ThreadCap p # _ \\<Rightarrow> returnOk p\n    | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n    p \\<leftarrow> case cap of ThreadCap p \\<Rightarrow> returnOk p;\n    returnOk $ CopyRegisters p src_tcb\n                             suspend_source resume_target\n                             transfer_frame transfer_integer\n                             ArchDefaultExtraRegisters\n  odE\n| _ \\<Rightarrow>  throwError TruncatedMessage\"\n\n\ndefinition\n  decode_write_registers :: \"data list \\<Rightarrow> cap \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_write_registers data cap \\<equiv> case data of\n  flags#n#values \\<Rightarrow> doE\n    whenE (length values < unat n) $ throwError TruncatedMessage;\n    p \\<leftarrow> case cap of ThreadCap p \\<Rightarrow> returnOk p;\n    self \\<leftarrow> liftE $ gets cur_thread;\n    whenE (p = self) $ throwError IllegalOperation;\n    returnOk $ WriteRegisters p (flags !! 0)\n               (take (unat n) values) ArchDefaultExtraRegisters\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\n\ndefinition\n  check_prio :: \"data \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"check_prio new_prio auth_tcb \\<equiv>\n    doE\n      mcp \\<leftarrow> liftE $ thread_get tcb_mcpriority auth_tcb;\n      whenE (new_prio > ucast mcp) $ throwError (RangeError 0 (ucast mcp))\n    odE\"\n\n\ndefinition\n  decode_set_priority :: \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_priority args cap slot extra_caps \\<equiv> doE\n     whenE (length args = 0 \\<or> length extra_caps = 0) $ throwError TruncatedMessage;\n     prio \\<leftarrow> returnOk $ ucast (args ! 0);\n     auth_tcb \\<leftarrow> case fst (extra_caps ! 0) of\n         ThreadCap tcb_ptr \\<Rightarrow> returnOk tcb_ptr\n       | _ \\<Rightarrow> throwError (InvalidCapability 1);\n     check_prio (args ! 0) auth_tcb;\n     returnOk (ThreadControl (obj_ref_of cap) slot None None\n                             (Some (prio, auth_tcb)) None None None)\n     odE\"\n\n\ndefinition\n  decode_set_mcpriority :: \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_mcpriority args cap slot extra_caps \\<equiv> doE\n     whenE (length args = 0 \\<or> length extra_caps = 0) $ throwError TruncatedMessage;\n     new_mcp \\<leftarrow> returnOk $ ucast $ args ! 0;\n     auth_tcb \\<leftarrow> case fst (extra_caps ! 0) of\n         ThreadCap tcb_ptr \\<Rightarrow> returnOk tcb_ptr\n       | _ \\<Rightarrow> throwError (InvalidCapability 1);\n     check_prio (args ! 0) auth_tcb;\n     returnOk (ThreadControl (obj_ref_of cap) slot None (Some (new_mcp, auth_tcb))\n                             None None None None)\n     odE\"\n\n\ndefinition\n  decode_set_sched_params :: \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_sched_params args cap slot extra_caps \\<equiv> doE\n     whenE (length args < 2) $ throwError TruncatedMessage;\n     whenE (length extra_caps = 0) $ throwError TruncatedMessage;\n     new_mcp \\<leftarrow> returnOk $ ucast $ args ! 0;\n     new_prio \\<leftarrow> returnOk $ ucast $ args ! 1;\n     auth_tcb \\<leftarrow> case fst (extra_caps ! 0) of\n         ThreadCap tcb_ptr \\<Rightarrow> returnOk tcb_ptr\n       | _ \\<Rightarrow> throwError (InvalidCapability 1);\n     check_prio (args ! 0) auth_tcb;\n     check_prio (args ! 1) auth_tcb;\n     returnOk (ThreadControl (obj_ref_of cap) slot None\n                             (Some (new_mcp, auth_tcb)) (Some (new_prio, auth_tcb)) None None None)\n     odE\"\n\n\ndefinition\n  decode_set_ipc_buffer ::\n  \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_set_ipc_buffer args cap slot excs \\<equiv> doE\n  whenE (length args = 0) $ throwError TruncatedMessage;\n  whenE (length excs = 0) $ throwError TruncatedMessage;\n  buffer \\<leftarrow> returnOk $ data_to_vref $ args ! 0;\n  (bcap, bslot) \\<leftarrow> returnOk $ excs ! 0;\n  newbuf \\<leftarrow> if buffer = 0 then returnOk None\n           else doE\n      buffer_cap \\<leftarrow> derive_cap bslot bcap;\n      check_valid_ipc_buffer buffer buffer_cap;\n      returnOk $ Some (buffer_cap, bslot)\n    odE;\n  returnOk $\n    ThreadControl (obj_ref_of cap) slot None None None None None (Some (buffer, newbuf))\nodE\"\n\n\ndefinition\n  decode_set_space\n  :: \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_space args cap slot excaps \\<equiv> doE\n   whenE (length args < 3 \\<or> length excaps < 2) $ throwError TruncatedMessage;\n   fault_ep \\<leftarrow> returnOk $ args ! 0;\n   croot_data  \\<leftarrow> returnOk $ args ! 1;\n   vroot_data  \\<leftarrow> returnOk $ args ! 2;\n   croot_arg  \\<leftarrow> returnOk $ excaps ! 0;\n   vroot_arg  \\<leftarrow> returnOk $ excaps ! 1;\n   can_chg_cr \\<leftarrow> liftE $ liftM Not $ slot_cap_long_running_delete\n                      $ get_tcb_ctable_ptr $ obj_ref_of cap;\n   can_chg_vr \\<leftarrow> liftE $ liftM Not $ slot_cap_long_running_delete\n                      $ get_tcb_vtable_ptr $ obj_ref_of cap;\n   unlessE (can_chg_cr \\<and> can_chg_vr) $ throwError IllegalOperation;\n\n   croot_cap  \\<leftarrow> returnOk $ fst croot_arg;\n   croot_slot \\<leftarrow> returnOk $ snd croot_arg;\n   croot_cap' \\<leftarrow> derive_cap croot_slot $\n                   (if croot_data = 0 then id else update_cap_data False croot_data)\n                   croot_cap;\n   unlessE (is_cnode_cap croot_cap') $ throwError IllegalOperation;\n   croot \\<leftarrow> returnOk (croot_cap', croot_slot);\n\n   vroot_cap  \\<leftarrow> returnOk $ fst vroot_arg;\n   vroot_slot \\<leftarrow> returnOk $ snd vroot_arg;\n   vroot_cap' \\<leftarrow> derive_cap vroot_slot $\n                   (if vroot_data = 0 then id else update_cap_data False vroot_data)\n                   vroot_cap;\n   unlessE (is_valid_vtable_root vroot_cap') $ throwError IllegalOperation;\n   vroot \\<leftarrow> returnOk (vroot_cap', vroot_slot);\n\n   returnOk $ ThreadControl (obj_ref_of cap) slot (Some (to_bl fault_ep)) None None\n                            (Some croot) (Some vroot) None\n odE\"\n\n\ndefinition\n  decode_tcb_configure ::\n  \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_tcb_configure args cap slot extra_caps \\<equiv> doE\n     whenE (length args < 4) $ throwError TruncatedMessage;\n     whenE (length extra_caps < 3) $ throwError TruncatedMessage;\n     fault_ep \\<leftarrow> returnOk $ args ! 0;\n     croot_data \\<leftarrow> returnOk $ args ! 1;\n     vroot_data \\<leftarrow> returnOk $ args ! 2;\n     crootvroot \\<leftarrow> returnOk $ take 2 extra_caps;\n     buffer_cap \\<leftarrow> returnOk $ extra_caps ! 2;\n     buffer \\<leftarrow> returnOk $ args ! 3;\n     set_params \\<leftarrow> decode_set_ipc_buffer [buffer] cap slot [buffer_cap];\n     set_space \\<leftarrow> decode_set_space [fault_ep, croot_data, vroot_data] cap slot crootvroot;\n     returnOk $ ThreadControl (obj_ref_of cap) slot (tc_new_fault_ep set_space)\n                              None None\n                              (tc_new_croot set_space) (tc_new_vroot set_space)\n                              (tc_new_buffer set_params)\n   odE\"\n\ndefinition\n  decode_bind_notification ::\n  \"cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_bind_notification cap extra_caps \\<equiv> case cap of\n    ThreadCap tcb \\<Rightarrow> doE\n     whenE (length extra_caps = 0) $ throwError TruncatedMessage;\n     nTFN \\<leftarrow> liftE $ get_bound_notification tcb;\n     case nTFN of\n         Some _ \\<Rightarrow> throwError IllegalOperation\n       | None \\<Rightarrow> returnOk ();\n     (ntfnptr, rights) \\<leftarrow> case fst (hd extra_caps) of\n         NotificationCap ptr _ r \\<Rightarrow> returnOk (ptr, r)\n       | _ \\<Rightarrow> throwError IllegalOperation;\n     whenE (AllowRecv \\<notin> rights) $ throwError IllegalOperation;\n     ntfn \\<leftarrow> liftE  $ get_notification ntfnptr;\n     case (ntfn_obj ntfn, ntfn_bound_tcb ntfn) of\n         (IdleNtfn, None) \\<Rightarrow> returnOk ()\n       | (ActiveNtfn _, None) \\<Rightarrow> returnOk ()\n       | _ \\<Rightarrow> throwError IllegalOperation;\n      returnOk $ NotificationControl tcb (Some ntfnptr)\n   odE\n | _ \\<Rightarrow> throwError IllegalOperation\"\n\n\ndefinition\n  decode_unbind_notification :: \"cap \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_unbind_notification cap \\<equiv> case cap of\n     ThreadCap tcb \\<Rightarrow> doE\n       nTFN \\<leftarrow> liftE $ get_bound_notification tcb;\n       case nTFN of\n           None \\<Rightarrow> throwError IllegalOperation\n         | Some _ \\<Rightarrow> returnOk ();\n       returnOk $ NotificationControl tcb None\n    odE\n | _ \\<Rightarrow> throwError IllegalOperation\"\n\ndefinition\n  decode_set_tls_base :: \"data list \\<Rightarrow> cap \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_tls_base args cap \\<equiv> doE\n     whenE (length args = 0) $ throwError TruncatedMessage;\n     returnOk (SetTLSBase (obj_ref_of cap) (ucast (args ! 0)))\n   odE\"\n\ndefinition\n  decode_tcb_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n  (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n \"decode_tcb_invocation label args cap slot excs \\<equiv>\n  case gen_invocation_type label of\n      TCBReadRegisters \\<Rightarrow> decode_read_registers args cap\n    | TCBWriteRegisters \\<Rightarrow> decode_write_registers args cap\n    | TCBCopyRegisters \\<Rightarrow> decode_copy_registers args cap $ map fst excs\n    | TCBSuspend \\<Rightarrow> returnOk $ Suspend $ obj_ref_of cap\n    | TCBResume \\<Rightarrow> returnOk $ Resume $ obj_ref_of cap\n    | TCBConfigure \\<Rightarrow> decode_tcb_configure args cap slot excs\n    | TCBSetPriority \\<Rightarrow> decode_set_priority args cap slot excs\n    | TCBSetMCPriority \\<Rightarrow> decode_set_mcpriority args cap slot excs\n    | TCBSetSchedParams \\<Rightarrow> decode_set_sched_params args cap slot excs\n    | TCBSetIPCBuffer \\<Rightarrow> decode_set_ipc_buffer args cap slot excs\n    | TCBSetSpace \\<Rightarrow> decode_set_space args cap slot excs\n    | TCBBindNotification \\<Rightarrow> decode_bind_notification cap excs\n    | TCBUnbindNotification \\<Rightarrow> decode_unbind_notification cap\n    | TCBSetTLSBase \\<Rightarrow> decode_set_tls_base args cap\n    | _ \\<Rightarrow> throwError IllegalOperation\"\n\ndefinition\n  decode_domain_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    ((obj_ref \\<times> domain), 'z::state_ext) se_monad\"\nwhere\n  \"decode_domain_invocation label args excs \\<equiv> doE\n     whenE (gen_invocation_type label \\<noteq> DomainSetSet) $ throwError IllegalOperation;\n     domain \\<leftarrow> (case args of\n       x # xs \\<Rightarrow> doE\n         whenE (unat x \\<ge> numDomains) $ throwError $ InvalidArgument 0;\n         returnOk (ucast x)\n       odE\n       | _ \\<Rightarrow> throwError TruncatedMessage);\n     whenE (length excs = 0) $ throwError TruncatedMessage;\n     case (fst (hd excs)) of ThreadCap ptr \\<Rightarrow> returnOk $ (ptr, domain)\n       | _ \\<Rightarrow> throwError $ InvalidArgument 1\n   odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode IRQ System Calls: Decode system calls related to interrupt control and handling. For interrupt control, validate the arguments and capabilities, check if the IRQ is active, and ensure the destination slot is empty before returning an IRQ control invocation. For interrupt handlers, decode different types of IRQ operations such as acknowledging, setting, and clearing IRQ handlers, ensuring the provided capabilities are valid.",
    "input": "",
    "output": "text \\<open>The following two definitions decode system calls for the\ninterrupt controller and interrupt handlers\\<close>\n\ndefinition\n  decode_irq_control_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list\n                                     \\<Rightarrow> (irq_control_invocation,'z::state_ext) se_monad\" where\n \"decode_irq_control_invocation label args src_slot cps \\<equiv>\n  (if gen_invocation_type label = IRQIssueIRQHandler\n    then if length args \\<ge> 3 \\<and> length cps \\<ge> 1\n      then let irq_word = args ! 0;\n               index = args ! 1;\n               depth = args ! 2;\n               cnode = cps ! 0;\n               irq = ucast irq_word\n      in doE\n        arch_check_irq irq_word;\n        irq_active \\<leftarrow> liftE $ is_irq_active irq;\n        whenE irq_active $ throwError RevokeFirst;\n\n        dest_slot \\<leftarrow> lookup_target_slot\n               cnode (data_to_cptr index) (unat depth);\n        ensure_empty dest_slot;\n\n        returnOk $ IRQControl irq dest_slot src_slot\n      odE\n    else throwError TruncatedMessage\n  else liftME ArchIRQControl $ arch_decode_irq_control_invocation label args src_slot cps)\"\n\ndefinition\n  decode_irq_handler_invocation :: \"data \\<Rightarrow> irq \\<Rightarrow> (cap \\<times> cslot_ptr) list\n                                     \\<Rightarrow> (irq_handler_invocation,'z::state_ext) se_monad\" where\n \"decode_irq_handler_invocation label irq cps \\<equiv>\n  if gen_invocation_type label = IRQAckIRQ\n    then returnOk $ ACKIrq irq\n  else if gen_invocation_type label = IRQSetIRQHandler\n    then if cps \\<noteq> []\n      then let (cap, slot) = hd cps in\n      if is_ntfn_cap cap \\<and> AllowSend \\<in> cap_rights cap\n      then returnOk $ SetIRQHandler irq cap slot\n      else throwError $ InvalidCapability 0\n    else throwError TruncatedMessage\n  else if gen_invocation_type label = IRQClearIRQHandler\n    then returnOk $ ClearIRQHandler irq\n  else throwError IllegalOperation\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Untyped Memory Capability Invocation: Decodes and validates untyped memory capability invocations, ensuring that the operation is of the correct type, the arguments are complete, and the provided capabilities and parameters are valid. It checks the object type, size, and alignment, verifies the node and offset values, and ensures that the target slots are empty before proceeding with the retype operation.",
    "input": "",
    "output": "text \\<open>The definitions in this section deal with decoding invocations\nof untyped memory capabilities.\n\\<close>\n\ndefinition\n  data_to_obj_type :: \"data \\<Rightarrow> (apiobject_type,'z::state_ext) se_monad\" where\n  \"data_to_obj_type type \\<equiv> doE\n    n \\<leftarrow> returnOk $ data_to_nat type;\n    if n = 0 then\n      returnOk $ Untyped\n    else if n = 1 then\n      returnOk $ TCBObject\n    else if n = 2 then\n      returnOk $ EndpointObject\n    else if n = 3 then\n      returnOk $ NotificationObject\n    else if n = 4 then\n      returnOk $ CapTableObject\n    else (case arch_data_to_obj_type (n - 5)\n       of Some tp \\<Rightarrow> returnOk (ArchObject tp)\n        | None \\<Rightarrow> throwError (InvalidArgument 0))\n  odE\"\n\ndefinition\n  decode_untyped_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap \\<Rightarrow> cap list \\<Rightarrow> (untyped_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_untyped_invocation label args slot cap excaps \\<equiv> doE\n  unlessE (gen_invocation_type label = UntypedRetype) $ throwError IllegalOperation;\n  whenE (length args < 6) $ throwError TruncatedMessage;\n  whenE (length excaps = 0) $ throwError TruncatedMessage;\n  root_cap \\<leftarrow> returnOk $ excaps ! 0;\n  new_type \\<leftarrow> data_to_obj_type (args!0);\n\n  user_obj_size \\<leftarrow> returnOk $ data_to_nat (args!1);\n  object_size \\<leftarrow> returnOk (obj_bits_api new_type user_obj_size);\n  unlessE (user_obj_size < word_bits \\<and> object_size \\<le> untyped_max_bits)\n    $ throwError (RangeError 0 (of_nat untyped_max_bits));\n  whenE (new_type = CapTableObject \\<and> user_obj_size = 0)\n    $ throwError (InvalidArgument 1);\n  whenE (new_type = Untyped \\<and> user_obj_size < untyped_min_bits)\n    $ throwError (InvalidArgument 1);\n  node_index \\<leftarrow> returnOk $ data_to_cptr (args!2);\n  node_depth \\<leftarrow> returnOk $ data_to_nat (args!3);\n\n  node_cap \\<leftarrow> if node_depth = 0\n        then returnOk root_cap\n        else doE\n            node_slot \\<leftarrow> lookup_target_slot\n                root_cap node_index node_depth;\n            liftE $ get_cap node_slot\n        odE;\n\n  if is_cnode_cap node_cap\n        then  returnOk ()\n        else  throwError $ FailedLookup False $ MissingCapability node_depth;\n\n  node_offset \\<leftarrow> returnOk $ data_to_nat (args ! 4);\n  node_window \\<leftarrow> returnOk $ data_to_nat (args ! 5);\n  radix_bits \\<leftarrow> returnOk $ bits_of node_cap;\n  node_size \\<leftarrow> returnOk (2 ^ radix_bits);\n\n  whenE (node_offset < 0 \\<or> node_offset > node_size - 1) $\n    throwError $ RangeError 0 (of_nat (node_size - 1));\n\n  whenE (node_window < 1 \\<or> node_window > unat retypeFanOutLimit) $ throwError $ RangeError 1 retypeFanOutLimit;\n\n  whenE (node_window < 1 \\<or> node_window > node_size - node_offset) $\n    throwError $ RangeError 1 (of_nat (node_size - node_offset));\n\n  oref \\<leftarrow> returnOk $ obj_ref_of node_cap;\n  offsets \\<leftarrow> returnOk $ map (nat_to_cref radix_bits)\n                           [node_offset ..< node_offset + node_window];\n  slots \\<leftarrow> returnOk $ map (\\<lambda>cref. (oref, cref)) offsets;\n\n  mapME_x ensure_empty slots;\n\n  reset \\<leftarrow> liftE $ const_on_failure False $ (doE\n    ensure_no_children slot;\n    returnOk True\n  odE);\n\n  free_index \\<leftarrow> returnOk (if reset then 0 else free_index_of cap);\n  free_ref \\<leftarrow> returnOk (get_free_ref (obj_ref_of cap) free_index);\n  aligned_free_ref \\<leftarrow> returnOk (alignUp free_ref object_size);\n  untyped_free_bytes \\<leftarrow> returnOk (obj_size cap - of_nat (free_index));\n\n  max_count \\<leftarrow> returnOk ( untyped_free_bytes >> object_size);\n  whenE (unat max_count < node_window) $\n        throwError $ NotEnoughMemory $ untyped_free_bytes;\n\n  not_frame \\<leftarrow> returnOk (\\<not> is_frame_type new_type);\n  (ptr, is_device) \\<leftarrow> case cap of\n                        UntypedCap dev p n f \\<Rightarrow> returnOk (p,dev)\n                      | _ \\<Rightarrow> fail;\n  whenE (is_device \\<and> not_frame \\<and> new_type \\<noteq> Untyped) $\n           throwError $ InvalidArgument 1;\n  returnOk $ Retype slot reset ptr aligned_free_ref new_type user_obj_size slots is_device\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode System Call Invocations: Decodes and validates system call invocations based on the provided capability, ensuring that the invocation is allowed and dispatching to the appropriate handler. If the capability does not have the required rights, it returns an error.",
    "input": "",
    "output": "text \\<open>This definition is the toplevel decoding definition; it dispatches\nto the above definitions, after checking, in some cases, whether the\ninvocation is allowed.\n\\<close>\n\ndefinition\n  decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_invocation label args cap_index slot cap excaps \\<equiv>\n  case cap of\n    EndpointCap ptr badge rights \\<Rightarrow>\n      if AllowSend \\<in> rights then\n        returnOk $ InvokeEndpoint ptr badge (AllowGrant \\<in> rights) (AllowGrantReply \\<in> rights)\n      else throwError $ InvalidCapability 0\n  | NotificationCap ptr badge rights \\<Rightarrow>\n      if AllowSend \\<in> rights then\n        returnOk $ InvokeNotification ptr badge\n      else throwError $ InvalidCapability 0\n  | ReplyCap thread False rights \\<Rightarrow>\n      returnOk $ InvokeReply thread slot (AllowGrant \\<in> rights)\n  | IRQControlCap \\<Rightarrow>\n      liftME InvokeIRQControl\n        $ decode_irq_control_invocation label args slot (map fst excaps)\n  | IRQHandlerCap irq \\<Rightarrow>\n      liftME InvokeIRQHandler\n        $ decode_irq_handler_invocation label irq excaps\n  | ThreadCap ptr \\<Rightarrow>\n      liftME InvokeTCB $ decode_tcb_invocation label args cap slot excaps\n  | DomainCap \\<Rightarrow>\n      liftME (case_prod InvokeDomain) $ decode_domain_invocation label args excaps\n  | CNodeCap ptr bits _ \\<Rightarrow>\n      liftME InvokeCNode $ decode_cnode_invocation label args cap (map fst excaps)\n  | UntypedCap dev ptr sz fi \\<Rightarrow>\n      liftME InvokeUntyped $ decode_untyped_invocation label args slot cap (map fst excaps)\n  | ArchObjectCap arch_cap \\<Rightarrow>\n      liftME InvokeArchObject $\n        arch_decode_invocation label args cap_index slot arch_cap excaps\n  | _ \\<Rightarrow>\n      throwError $ InvalidCapability 0\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Endpoint Queue Management: Retrieve and update the queue of an endpoint. The queue can be either for sending or receiving, and the operations ensure that the queue is correctly accessed and modified.",
    "input": "",
    "output": "definition\n  get_ep_queue :: \"endpoint \\<Rightarrow> (obj_ref list,'z::state_ext) s_monad\"\nwhere\n \"get_ep_queue ep \\<equiv> case ep of SendEP q \\<Rightarrow> return q\n                              | RecvEP q \\<Rightarrow> return q\n                              | _ \\<Rightarrow> fail\"\n\nprimrec (nonexhaustive)\n  update_ep_queue :: \"endpoint \\<Rightarrow> obj_ref list \\<Rightarrow> endpoint\"\nwhere\n  \"update_ep_queue (RecvEP q) q' = RecvEP q'\"\n| \"update_ep_queue (SendEP q) q' = SendEP q'\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel Synchronous Message Operations: Cancels all message operations for threads queued within a synchronous message endpoint, transitioning them to the Restart state and re-enqueueing them for rescheduling. This ensures that the threads will reattempt their previous operations once they are scheduled again.",
    "input": "",
    "output": "definition\n  cancel_all_ipc :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_all_ipc epptr \\<equiv> do\n     ep \\<leftarrow> get_endpoint epptr;\n     case ep of IdleEP \\<Rightarrow> return ()\n               | _ \\<Rightarrow> do\n                        queue \\<leftarrow> get_ep_queue ep;\n                        set_endpoint epptr IdleEP;\n                        mapM_x (\\<lambda>t. do set_thread_state t Restart;\n                                       do_extended_op (tcb_sched_action (tcb_sched_enqueue) t) od) $ queue;\n                        do_extended_op (reschedule_required)\n                     od\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Badge Retrieval for Blocked Threads: Extract the badge from the payload of a thread that is blocked on a message send operation.",
    "input": "",
    "output": "primrec (nonexhaustive)\n  blocking_ipc_badge :: \"thread_state \\<Rightarrow> badge\"\nwhere\n  \"blocking_ipc_badge (BlockedOnSend t payload) = sender_badge payload\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel Badged Sends: Cancels all message send operations for threads queued in a specific endpoint and using a particular badge. Threads with the matching badge are set to the restart state and re-enqueued, while the endpoint is updated to reflect the remaining or cleared queue.",
    "input": "",
    "output": "definition\n  cancel_badged_sends :: \"obj_ref \\<Rightarrow> badge \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_badged_sends epptr badge \\<equiv> do\n    ep \\<leftarrow> get_endpoint epptr;\n    case ep of\n          IdleEP \\<Rightarrow> return ()\n        | RecvEP _ \\<Rightarrow>  return ()\n        | SendEP queue \\<Rightarrow>  do\n            set_endpoint epptr IdleEP;\n            queue' \\<leftarrow> (swp filterM queue) (\\<lambda> t. do\n                st \\<leftarrow> get_thread_state t;\n                if blocking_ipc_badge st = badge then do\n                  set_thread_state t Restart;\n                  do_extended_op (tcb_sched_action (tcb_sched_enqueue) t);\n                  return False od\n                else return True\n            od);\n            ep' \\<leftarrow> return (case queue' of\n                           [] \\<Rightarrow> IdleEP\n                         | _ \\<Rightarrow> SendEP queue');\n            set_endpoint epptr ep';\n            do_extended_op (reschedule_required)\n        od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel All Signals: Cancels all message operations on threads queued in a notification endpoint, transitioning the notification object to an idle state and re-enqueueing the affected threads for execution.",
    "input": "",
    "output": "abbreviation\n  do_unbind_notification :: \"obj_ref \\<Rightarrow> notification \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"do_unbind_notification ntfnptr ntfn tcbptr \\<equiv> do\n      ntfn' \\<leftarrow> return $ ntfn_set_bound_tcb ntfn None;\n      set_notification ntfnptr ntfn';\n      set_bound_notification tcbptr None\n    od\"\n\ndefinition\n  unbind_notification :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"unbind_notification tcb \\<equiv> do\n     ntfnptr \\<leftarrow> get_bound_notification tcb;\n     case ntfnptr of\n         Some ntfnptr' \\<Rightarrow> do\n             ntfn \\<leftarrow> get_notification ntfnptr';\n             do_unbind_notification ntfnptr' ntfn tcb\n          od\n       | None \\<Rightarrow> return ()\n   od\"\n\ndefinition\n  unbind_maybe_notification :: \"obj_ref \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"unbind_maybe_notification ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     (case ntfn_bound_tcb ntfn of\n       Some t \\<Rightarrow> do_unbind_notification ntfnptr ntfn t\n     | None \\<Rightarrow> return ())\n   od\"\n\ndefinition\n  cancel_all_signals :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_all_signals ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     case ntfn_obj ntfn of WaitingNtfn queue \\<Rightarrow> do\n                      _ \\<leftarrow> set_notification ntfnptr $ ntfn_set_obj ntfn IdleNtfn;\n                      mapM_x (\\<lambda>t. do set_thread_state t Restart;\n                                     do_extended_op (tcb_sched_action tcb_sched_enqueue t) od) queue;\n                      do_extended_op (reschedule_required)\n                     od\n               | _ \\<Rightarrow> return ()\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Get Blocking Object: Retrieve the endpoint pointer for a thread that is blocked on either sending or receiving a message. If the thread is not in a blocked state, the operation fails.",
    "input": "",
    "output": "definition\n  get_blocking_object :: \"thread_state \\<Rightarrow> (obj_ref,'z::state_ext) s_monad\"\nwhere\n \"get_blocking_object state \\<equiv>\n       case state of BlockedOnReceive epptr x \\<Rightarrow> return epptr\n                    | BlockedOnSend epptr x \\<Rightarrow> return epptr\n                    | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel IPC Operation: Cancels the IPC operation that a thread is currently engaged in by removing the thread from the endpoint's queue and setting the thread's state to inactive.",
    "input": "",
    "output": "definition\n  blocked_cancel_ipc :: \"thread_state \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"blocked_cancel_ipc state tptr \\<equiv> do\n     epptr \\<leftarrow> get_blocking_object state;\n     ep \\<leftarrow> get_endpoint epptr;\n     queue \\<leftarrow> get_ep_queue ep;\n     queue' \\<leftarrow> return $ remove1 tptr queue;\n     ep' \\<leftarrow> return (case queue' of [] \\<Rightarrow> IdleEP\n                                |  _ \\<Rightarrow> update_ep_queue ep queue');\n     set_endpoint epptr ep';\n     set_thread_state tptr Inactive\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fast Finalise Capability: Finalises a capability if it is of a type that can be immediately finalised, such as an Endpoint or Notification capability. For other types of capabilities, the operation fails.",
    "input": "",
    "output": "fun\n  fast_finalise :: \"cap \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"fast_finalise NullCap                  final = return ()\"\n| \"fast_finalise (ReplyCap r m R)         final = return ()\"\n| \"fast_finalise (EndpointCap r b R)      final =\n      (when final $ cancel_all_ipc r)\"\n| \"fast_finalise (NotificationCap r b R) final =\n      (when final $ do\n          unbind_maybe_notification r;\n          cancel_all_signals r\n       od)\"\n| \"fast_finalise (CNodeCap r bits g)      final = fail\"\n| \"fast_finalise (ThreadCap r)            final = fail\"\n| \"fast_finalise DomainCap                final = fail\"\n| \"fast_finalise (Zombie r b n)           final = fail\"\n| \"fast_finalise IRQControlCap            final = fail\"\n| \"fast_finalise (IRQHandlerCap irq)      final = fail\"\n| \"fast_finalise (UntypedCap dev r n f)       final = fail\"\n| \"fast_finalise (ArchObjectCap a)        final = fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Capability Management: Extract and represent the IRQ associated with a capability, either as an optional value or a set.",
    "input": "",
    "output": "definition\n  cap_irq_opt :: \"cap \\<Rightarrow> irq option\" where\n \"cap_irq_opt cap \\<equiv> case cap of IRQHandlerCap irq \\<Rightarrow> Some irq | _ \\<Rightarrow> None\"\n\ndefinition\n  cap_irqs :: \"cap \\<Rightarrow> irq set\" where\n \"cap_irqs cap \\<equiv> set_option (cap_irq_opt cap)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Generic Object References: A generic reference to an object can be an object reference, an IRQ reference, or an architecture-specific reference. These references are used for finalization and comparison to determine if capabilities refer to the same object. The system defines a mapping to extract architecture-specific references from capabilities and combines these with object and IRQ references to form a complete set of generic references. Additionally, a cleanup operation is defined to handle specific types of capabilities, ensuring they are appropriately managed or converted to a null capability.",
    "input": "",
    "output": "datatype gen_obj_ref =\n    ObjRef obj_ref\n  | IRQRef irq\n  | ArchRef arch_gen_obj_ref\n\ndefinition\n  arch_cap_set_map :: \"(arch_cap \\<Rightarrow> 'a set) \\<Rightarrow> cap \\<Rightarrow> 'a set\"\nwhere\n  \"arch_cap_set_map f cap \\<equiv> case cap of\n       ArchObjectCap acap \\<Rightarrow> f acap\n     | _ \\<Rightarrow> {}\"\n\nabbreviation\n  arch_gen_refs :: \"cap \\<Rightarrow> arch_gen_obj_ref set\"\nwhere\n  \"arch_gen_refs \\<equiv> arch_cap_set_map arch_gen_obj_refs\"\n\ndefinition\n  gen_obj_refs :: \"cap \\<Rightarrow> gen_obj_ref set\"\nwhere\n  \"gen_obj_refs c \\<equiv> ObjRef ` (obj_refs c)\n                      \\<union> IRQRef ` (cap_irqs c)\n                      \\<union> ArchRef ` (arch_gen_refs c)\"\n\ndefinition\n  cap_cleanup_opt :: \"cap \\<Rightarrow> cap\"\nwhere\n  \"cap_cleanup_opt c \\<equiv> case c of\n      IRQHandlerCap _ \\<Rightarrow> c\n    | ArchObjectCap acap \\<Rightarrow> arch_cap_cleanup_opt acap\n    | _ \\<Rightarrow> NullCap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Final Capability Detection: Determine if a given capability is the last remaining reference to an object in the system, triggering finalization actions when the final capability to the object is deleted.",
    "input": "",
    "output": "definition\n  is_final_cap' :: \"cap \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n \"is_final_cap' cap s \\<equiv>\n    \\<exists>cref. {cref. \\<exists>cap'. fst (get_cap cref s) = {(cap', s)}\n                       \\<and> (gen_obj_refs cap \\<inter> gen_obj_refs cap' \\<noteq> {})}\n         = {cref}\"\n\ndefinition\n  is_final_cap :: \"cap \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n  \"is_final_cap cap \\<equiv> gets (is_final_cap' cap)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Handler Deletion: Set the state of the specified IRQ to inactive after its handler capability is deleted.",
    "input": "",
    "output": "definition\n  deleted_irq_handler :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"deleted_irq_handler irq \\<equiv> set_irq_state IRQInactive irq\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Post-Capability Deletion Actions: Perform specific actions based on the type of capability deleted, such as handling IRQ handler capabilities and arch-specific capabilities. For other types of capabilities, no action is taken.",
    "input": "",
    "output": "definition\n  post_cap_deletion :: \"cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"post_cap_deletion cap \\<equiv> case cap of\n       IRQHandlerCap irq \\<Rightarrow> deleted_irq_handler irq\n     | ArchObjectCap acap \\<Rightarrow> arch_post_cap_deletion acap\n     | _ \\<Rightarrow> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Empty a Capability Slot: Ensures that a capability slot is emptied by setting it to `NullCap` and updating the CDT (Capability Descriptor Table) to remove any references to the slot. If the slot is not already empty, it performs additional cleanup operations, including updating parent references and executing extended operations for slot finalization.",
    "input": "",
    "output": "definition\n  empty_slot :: \"cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"empty_slot slot cleanup_info \\<equiv> do\n      cap \\<leftarrow> get_cap slot;\n      if cap = NullCap then\n        return ()\n      else do\n        slot_p \\<leftarrow> gets (\\<lambda>s. cdt s slot);\n        cdt \\<leftarrow> gets cdt;\n        parent \\<leftarrow> return $ cdt slot;\n        set_cdt ((\\<lambda>p. if cdt p = Some slot\n                     then parent\n                     else cdt p) (slot := None));\n        do_extended_op (empty_slot_ext slot slot_p);\n        set_original slot False;\n        set_cap NullCap slot;\n\n        post_cap_deletion cleanup_info\n      od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Deletion: Delete a capability from the specified slot, ensuring that the fast finalization process is applied if the capability is not null. This ensures that the capability is properly removed and its resources are efficiently released.",
    "input": "",
    "output": "definition\n  cap_delete_one :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"cap_delete_one slot \\<equiv> do\n    cap \\<leftarrow> get_cap slot;\n    unless (cap = NullCap) $ do\n      final \\<leftarrow> is_final_cap cap;\n      fast_finalise cap final;\n      empty_slot slot NullCap\n    od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel Reply IPC Operation: Cancels the message receive operation for a thread waiting on a reply capability by clearing the thread's fault, retrieving the capability from the specified CNode slot, and deleting the descendant capability if it exists.",
    "input": "",
    "output": "definition\n  reply_cancel_ipc :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"reply_cancel_ipc tptr \\<equiv> do\n    thread_set (\\<lambda>tcb. tcb \\<lparr> tcb_fault := None \\<rparr>) tptr;\n    cap \\<leftarrow> get_cap (tptr, tcb_cnode_index 2);\n    descs \\<leftarrow> gets (descendants_of (tptr, tcb_cnode_index 2) o cdt);\n    when (descs \\<noteq> {}) $ do\n      assert (\\<exists>cslot_ptr. descs = {cslot_ptr});\n      cslot_ptr \\<leftarrow> select descs;\n      cap_delete_one cslot_ptr\n    od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel Signal Operation: Removes a thread from the notification object's queue and updates the notification object's state. If the queue becomes empty, the notification object is set to an idle state. The thread's state is also updated to inactive.",
    "input": "",
    "output": "definition\n  cancel_signal :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_signal threadptr ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     queue \\<leftarrow> (case ntfn_obj ntfn of WaitingNtfn queue \\<Rightarrow> return queue\n                        | _ \\<Rightarrow> fail);\n     queue' \\<leftarrow> return $ remove1 threadptr queue;\n     newNTFN \\<leftarrow> return $ ntfn_set_obj ntfn (case queue' of [] \\<Rightarrow> IdleNtfn\n                                                      | _  \\<Rightarrow> WaitingNtfn queue');\n     set_notification ntfnptr newNTFN;\n     set_thread_state threadptr Inactive\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cancel IPC Operations: Cancels any message operations that a given thread is waiting on, including send, receive, notification, and reply operations. This ensures that the thread can be unblocked and resume normal execution.",
    "input": "",
    "output": "definition\n  cancel_ipc :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_ipc tptr \\<equiv> do\n     state \\<leftarrow> get_thread_state tptr;\n     case state\n       of\n          BlockedOnSend x y \\<Rightarrow> blocked_cancel_ipc state tptr\n        | BlockedOnReceive x y \\<Rightarrow> blocked_cancel_ipc state tptr\n        | BlockedOnNotification event \\<Rightarrow> cancel_signal tptr event\n        | BlockedOnReply \\<Rightarrow> reply_cancel_ipc tptr\n        | _ \\<Rightarrow> return ()\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Restart PC: Update the fault register of a thread with the value from the next instruction register, ensuring that the thread's restart point is correctly set for fault handling.",
    "input": "",
    "output": "definition\n  update_restart_pc :: \"obj_ref \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"update_restart_pc thread_ptr =\n        as_user thread_ptr (getRegister nextInstructionRegister\n                            >>= setRegister faultRegister)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Suspension: Suspends a thread by cancelling any pending IPC operations, updating the restart PC if the thread was running, setting the thread state to Inactive, and dequeuing it from the scheduler. This ensures that the thread is no longer eligible for execution and its state is properly managed.",
    "input": "",
    "output": "definition\n  suspend :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"suspend thread \\<equiv> do\n     cancel_ipc thread;\n     state \\<leftarrow> get_thread_state thread;\n     (if state = Running then update_restart_pc thread else return ());\n     set_thread_state thread Inactive;\n     do_extended_op (tcb_sched_action (tcb_sched_dequeue) thread)\n   od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Access Control Rights: Define the possible access-control rights in the system, including read, write, grant, and grant reply. Some rights are synonymous, where AllowSend is equivalent to AllowWrite, AllowRecv is equivalent to AllowRead, and CanModify is also equivalent to AllowWrite.",
    "input": "",
    "output": "datatype rights = AllowRead | AllowWrite | AllowGrant | AllowGrantReply\n\ndefinition\n  \"AllowSend \\<equiv> AllowWrite\"\ndefinition\n  \"AllowRecv \\<equiv> AllowRead\"\ndefinition\n  \"CanModify \\<equiv> AllowWrite\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Rights Definition: A cap_rights is a set of access rights that defines the permissions associated with a capability.",
    "input": "",
    "output": "type_synonym cap_rights = \"rights set\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "All Rights: Represents the complete set of possible rights that can be associated with a capability, encompassing all potential permissions and authorities.",
    "input": "",
    "output": "definition\n  all_rights :: cap_rights\nwhere\n \"all_rights \\<equiv> UNIV\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Store Word at Offset: Store a machine word at a specified offset in the IPC buffer, ensuring that the operation is within the user frame.",
    "input": "",
    "output": "definition\n  store_word_offs :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"store_word_offs ptr offs v \\<equiv>\n    do s \\<leftarrow> get;\n       assert (in_user_frame (ptr + of_nat (offs * word_size)) s);\n       do_machine_op $ storeWord (ptr + of_nat (offs * word_size)) v\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Message Information and Registers: Updates the message information and registers for a thread, ensuring that the message data is correctly stored in the thread's context. If a buffer is provided, additional message data beyond the initial set of message registers is stored in the specified buffer, allowing for the handling of larger messages.",
    "input": "",
    "output": "definition\n  set_message_info :: \"obj_ref \\<Rightarrow> message_info \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_message_info thread info \\<equiv>\n     as_user thread $ setRegister msg_info_register $\n                      message_info_to_data info\"\n\n\ndefinition\n  set_mrs :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> message list \\<Rightarrow> (length_type,'z::state_ext) s_monad\" where\n  \"set_mrs thread buf msgs \\<equiv>\n   do\n     tcb \\<leftarrow> gets_the $ get_tcb thread;\n     context \\<leftarrow> return (arch_tcb_get_registers (tcb_arch tcb));\n     new_regs \\<leftarrow> return (\\<lambda>reg. if reg \\<in> set (take (length msgs) msg_registers)\n                              then msgs ! (the_index msg_registers reg)\n                              else context reg);\n     set_object thread (TCB (tcb \\<lparr> tcb_arch := arch_tcb_set_registers new_regs (tcb_arch tcb) \\<rparr>));\n     remaining_msgs \\<leftarrow> return (drop (length msg_registers) msgs);\n     case buf of\n     None      \\<Rightarrow> return $ nat_to_len (min (length msg_registers) (length msgs))\n   | Some pptr \\<Rightarrow> do\n       zipWithM_x (\\<lambda>x. store_word_offs pptr x)\n          [length msg_registers + 1 ..< Suc msg_max_length] remaining_msgs;\n       return $ nat_to_len $ min (length msgs) msg_max_length\n     od\n   od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Types and Frame Identification: Defines a set of object types that can be created by retype operations, including untyped objects, TCBs, endpoints, notifications, capability tables, and architecture-specific objects. Additionally, it provides a predicate to determine if an object type represents a frame.",
    "input": "",
    "output": "datatype apiobject_type =\n    Untyped\n  | TCBObject\n  | EndpointObject\n  | NotificationObject\n  | CapTableObject\n  | ArchObject aobject_type\n\ndefinition\n  is_frame_type :: \"apiobject_type \\<Rightarrow> bool\"\nwhere\n  \"is_frame_type obj \\<equiv> case obj of\n        ArchObject aobj \\<Rightarrow> arch_is_frame_type aobj\n      | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Definitions for IPC: Define types for badges, message labels, and messages to provide more informative type signatures for IPC operations.",
    "input": "",
    "output": "type_synonym badge = data\ntype_synonym msg_label = data\ntype_synonym message = data",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Slot References: A capability slot reference is modeled as a tuple where the first element points to the object containing the capability, and the second element is the index of the slot within that object. This structure allows for precise identification and manipulation of capability slots within objects.",
    "input": "",
    "output": "type_synonym cnode_index = \"bool list\"\ntype_synonym cslot_ptr = \"obj_ref \\<times> cnode_index\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capabilities and Their Authorities: Define various types of capabilities, each conferring specific authority to manipulate or interact with different kernel objects and resources. These include null, untyped, endpoint, notification, reply, CNode, thread, domain, IRQ control, IRQ handler, zombie, and architecture-specific capabilities, ensuring controlled access and operations within the system.",
    "input": "",
    "output": "datatype cap\n         = NullCap\n         | UntypedCap bool obj_ref nat nat\n           \\<comment> \\<open>device flag, pointer, size in bits (i.e. @{text \"size = 2^bits\"}) and freeIndex (i.e. @{text \"freeRef = obj_ref + (freeIndex * 2^4)\"})\\<close>\n         | EndpointCap obj_ref badge cap_rights\n         | NotificationCap obj_ref badge cap_rights\n         | ReplyCap obj_ref bool cap_rights\n         | CNodeCap obj_ref nat \"bool list\"\n           \\<comment> \\<open>CNode ptr, number of bits translated, guard\\<close>\n         | ThreadCap obj_ref\n         | DomainCap\n         | IRQControlCap\n         | IRQHandlerCap irq\n         | Zombie obj_ref \"nat option\" nat\n           \\<comment> \\<open>@{text \"cnode ptr * nat + tcb or cspace ptr\"}\\<close>\n         | ArchObjectCap (the_arch_cap: arch_cap)\n\nlemmas cap_cases =\n  cap.induct[where cap=cap and P=\"\\<lambda>cap'. cap' = cap \\<longrightarrow> P cap'\" for cap P, simplified, rule_format]\n\nlemmas cap_cases_asm =\ncap.induct[where cap=cap and P=\"\\<lambda>cap'. cap = cap' \\<longrightarrow> P cap' \\<longrightarrow> R\" for P R cap,\n  simplified, rule_format, rotated -1]",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Representation: A CNode is represented as a function that maps cnode indices to optional capabilities, where empty slots are denoted by `None` and occupied slots contain a capability.",
    "input": "",
    "output": "type_synonym cnode_contents = \"cnode_index \\<Rightarrow> cap option\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Type Access Functions: Provide various functions to extract and determine specific properties of capability objects, such as badge, pointer, bits, free index, and type-specific attributes. These functions enable efficient and accurate manipulation and inspection of capabilities, ensuring the integrity and security of the system.",
    "input": "",
    "output": "definition\n  the_cnode_cap :: \"cap \\<Rightarrow> obj_ref \\<times> nat \\<times> bool list\" where\n  \"the_cnode_cap cap \\<equiv>\n  case cap of\n    CNodeCap oref bits guard \\<Rightarrow> (oref, bits, guard)\"\n\nprimrec (nonexhaustive)\n  cap_ep_badge :: \"cap \\<Rightarrow> badge\"\nwhere\n  \"cap_ep_badge (EndpointCap _ badge _) = badge\"\n| \"cap_ep_badge (NotificationCap _ badge _) = badge\"\n\nprimrec (nonexhaustive)\n  cap_ep_ptr :: \"cap \\<Rightarrow> badge\"\nwhere\n  \"cap_ep_ptr (EndpointCap obj_ref _ _) = obj_ref\"\n| \"cap_ep_ptr (NotificationCap obj_ref _ _) = obj_ref\"\n\ndefinition\n  bits_of :: \"cap \\<Rightarrow> nat\" where\n  \"bits_of cap \\<equiv> case cap of\n    UntypedCap _ _ bits _ \\<Rightarrow> bits\n  | CNodeCap _ radix_bits _ \\<Rightarrow> radix_bits\"\n\ndefinition\n  free_index_of :: \"cap \\<Rightarrow> nat\" where\n  \"free_index_of cap \\<equiv> case cap of\n    UntypedCap _ _ _ free_index \\<Rightarrow> free_index\"\n\ndefinition\n  is_reply_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_reply_cap cap \\<equiv> case cap of ReplyCap _ m _ \\<Rightarrow> \\<not> m | _ \\<Rightarrow> False\"\ndefinition\n  is_master_reply_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_master_reply_cap cap \\<equiv> case cap of ReplyCap _ m _ \\<Rightarrow> m | _ \\<Rightarrow> False\"\ndefinition\n  is_zombie :: \"cap \\<Rightarrow> bool\" where\n  \"is_zombie cap \\<equiv> case cap of Zombie _ _ _ \\<Rightarrow> True | _ \\<Rightarrow> False\"\ndefinition\n  is_arch_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_arch_cap cap \\<equiv> case cap of ArchObjectCap _ \\<Rightarrow> True | _ \\<Rightarrow> False\"\n\ncontext\nnotes [[function_internals =true]]\nbegin\n\nfun is_cnode_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_cnode_cap (CNodeCap _ _ _) = True\"\n| \"is_cnode_cap _                = False\"\n\nfun is_thread_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_thread_cap (ThreadCap _) = True\"\n| \"is_thread_cap _             = False\"\n\nfun is_domain_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_domain_cap DomainCap = True\"\n| \"is_domain_cap _ = False\"\n\nfun is_untyped_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_untyped_cap (UntypedCap _ _ _ _) = True\"\n| \"is_untyped_cap _                  = False\"\n\nfun is_ep_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_ep_cap (EndpointCap _ _ _) = True\"\n| \"is_ep_cap _                   = False\"\n\nfun is_ntfn_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_ntfn_cap (NotificationCap _ _ _) = True\"\n| \"is_ntfn_cap _                        = False\"\n\nprimrec (nonexhaustive)\n  cap_rights :: \"cap \\<Rightarrow> cap_rights\"\nwhere\n  \"cap_rights (EndpointCap _ _ cr) = cr\"\n| \"cap_rights (NotificationCap _ _ cr) = cr\"\n| \"cap_rights (ReplyCap _ _ cr) = cr\"\n| \"cap_rights (ArchObjectCap acap) = acap_rights acap\"\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Data Update: Modify the rights and badge of a capability. The `cap_rights_update` function updates the rights of different types of capabilities, while the `badge_update` function updates the badge of endpoint and notification capabilities. The `mask_cap` function restricts the rights of a capability to a specified set of rights.",
    "input": "",
    "output": "definition\n  cap_rights_update :: \"cap_rights \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"cap_rights_update cr' cap \\<equiv>\n   case cap of\n     EndpointCap oref badge cr \\<Rightarrow> EndpointCap oref badge cr'\n   | NotificationCap oref badge cr\n     \\<Rightarrow> NotificationCap oref badge (cr' - {AllowGrant, AllowGrantReply})\n   | ReplyCap t m cr \\<Rightarrow> ReplyCap t m (cr' - {AllowRead, AllowGrantReply} \\<union> {AllowWrite})\n   | ArchObjectCap acap \\<Rightarrow> ArchObjectCap (acap_rights_update cr' acap)\n   | _ \\<Rightarrow> cap\"\n\ndefinition\n  badge_update :: \"badge \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"badge_update data cap \\<equiv>\n   case cap of\n     EndpointCap oref badge cr \\<Rightarrow> EndpointCap oref (data && mask badge_bits) cr\n   | NotificationCap oref badge cr \\<Rightarrow> NotificationCap oref (data && mask badge_bits) cr\n   | _ \\<Rightarrow> cap\"\n\n\ndefinition\n  mask_cap :: \"cap_rights \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"mask_cap rights cap \\<equiv> cap_rights_update (cap_rights cap \\<inter> rights) cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Message Information Structure: Defines the structure of a message, including the number of data words, the number of extra capabilities, a bitmask for capability transfer details, and a label. This structure is used to interpret and convey the message's content and metadata during system calls and message passing.",
    "input": "",
    "output": "text \\<open>The message info is the first thing interpreted on a user system call\nand determines the structure of the message the user thread is sending either to\nanother user or to a system service. It is also passed to user threads receiving\na message to indicate the structure of the message they have received. The\n@{text mi_length} parameter is the number of data words in the body of the\nmessage. The @{text mi_extra_caps} parameter is the number of caps to be passed\ntogether with the message. The @{text mi_caps_unwrapped} parameter is a bitmask\nallowing threads receiving a message to determine how extra capabilities were\ntransferred. The @{text mi_label} parameter is transferred directly from sender\nto receiver as part of the message.\n\\<close>\n\ndatatype message_info =\n  MI (mi_length: length_type)\n     (mi_extra_caps: length_type)\n     (mi_caps_unwrapped: data)\n     (mi_label: msg_label)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Message Encoding and Decoding: Encode a message information structure into a single data word by packing the length, extra capabilities, unwrapped status, and message label into specific bit positions. Decode a data word back into a message information structure by extracting and interpreting the packed values from their respective bit positions.",
    "input": "",
    "output": "primrec\n  message_info_to_data :: \"message_info \\<Rightarrow> data\"\nwhere\n  \"message_info_to_data (MI len exc unw mlabel) =\n   (let\n        extra = exc << 7;\n        unwrapped = unw << 9;\n        label = mlabel << 12\n    in\n       label || extra || unwrapped || len)\"\n\ndefinition\n  data_to_message_info :: \"data \\<Rightarrow> message_info\"\nwhere\n  \"data_to_message_info w \\<equiv>\n   MI (let v = w && mask 7 in if v > 120 then 120 else v)\n      ((w >> 7) && mask 2)\n      ((w >> 9) && mask 3)\n      ((w >> 12) && mask msg_label_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Endpoint Communication States: An endpoint can be in one of three states: idle, waiting to send, or waiting to receive. When both sending and receiving threads are present, messages are transferred immediately.",
    "input": "",
    "output": "text \\<open>Endpoints are synchronous points of communication for threads. At any\ntime an endpoint may contain a queue of threads waiting to send, a queue of\nthreads waiting to receive or be idle. Whenever threads would be waiting to\nsend and receive simultaneously messages are transferred immediately.\n\\<close>\n\ndatatype endpoint\n           = IdleEP\n           | SendEP \"obj_ref list\"\n           | RecvEP \"obj_ref list\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Notification States: Notifications can be in one of three states: idle, waiting, or active. An idle notification is not in use, a waiting notification has a list of threads waiting to receive, and an active notification contains a badge indicating it has been triggered. Notifications also have an optional bound thread control block (TCB) that can be associated with them.",
    "input": "",
    "output": "datatype ntfn\n           = IdleNtfn\n           | WaitingNtfn \"obj_ref list\"\n           | ActiveNtfn badge\n\nrecord notification =\n  ntfn_obj :: ntfn\n  ntfn_bound_tcb :: \"obj_ref option\"\n\n\ndefinition\n  default_ep :: endpoint where\n  \"default_ep \\<equiv> IdleEP\"\n\ndefinition\n  default_ntfn :: ntfn where\n  \"default_ntfn \\<equiv> IdleNtfn\"\n\ndefinition\n  default_notification :: notification where\n  \"default_notification \\<equiv> \\<lparr>\n     ntfn_obj = default_ntfn,\n     ntfn_bound_tcb = None \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Control Block Representation: A TCB represents a thread in the kernel, containing its state (Running, Inactive, Restart, BlockedOnReceive, BlockedOnSend, BlockedOnReply, BlockedOnNotification, IdleThreadState), capabilities for system calls and virtual address space, and additional fields for fault handling, IPC, and notification. The TCB also includes special-purpose capability slots such as CTable, VTable, Reply, Caller, and IPCFrame, which manage the thread's access to system resources and communication.",
    "input": "",
    "output": "record sender_payload =\n sender_badge           :: badge\n sender_can_grant       :: bool\n sender_can_grant_reply :: bool\n sender_is_call         :: bool\n\nrecord receiver_payload =\n receiver_can_grant :: bool\n\ndatatype thread_state\n  = Running\n  | Inactive\n  | Restart\n  | BlockedOnReceive obj_ref receiver_payload\n  | BlockedOnSend obj_ref sender_payload\n  | BlockedOnReply\n  | BlockedOnNotification obj_ref\n  | IdleThreadState\n\ntype_synonym priority = word8\n\nrecord tcb =\n tcb_ctable        :: cap\n tcb_vtable        :: cap\n tcb_reply         :: cap\n tcb_caller        :: cap\n tcb_ipcframe      :: cap\n tcb_state         :: thread_state\n tcb_fault_handler :: cap_ref\n tcb_ipc_buffer    :: vspace_ref\n tcb_fault         :: \"fault option\"\n tcb_bound_notification     :: \"obj_ref option\"\n tcb_mcpriority    :: priority\n tcb_arch          :: arch_tcb (* arch_tcb must have a field for user context *)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Scheduling Eligibility: Determines the schedulability of a thread based on its state. A thread is considered runnable if it is in the Running or Restart state, and not runnable if it is in any other state such as Inactive, BlockedOnReceive, BlockedOnSend, BlockedOnNotification, IdleThreadState, or BlockedOnReply.",
    "input": "",
    "output": "primrec\n  runnable :: \"Structures_A.thread_state \\<Rightarrow> bool\"\nwhere\n  \"runnable (Running)               = True\"\n| \"runnable (Inactive)              = False\"\n| \"runnable (Restart)               = True\"\n| \"runnable (BlockedOnReceive x y)  = False\"\n| \"runnable (BlockedOnSend x y)     = False\"\n| \"runnable (BlockedOnNotification x) = False\"\n| \"runnable (IdleThreadState)       = False\"\n| \"runnable (BlockedOnReply)        = False\"\n\n\ndefinition\n  default_tcb :: tcb where\n  \"default_tcb \\<equiv> \\<lparr>\n      tcb_ctable   = NullCap,\n      tcb_vtable   = NullCap,\n      tcb_reply    = NullCap,\n      tcb_caller   = NullCap,\n      tcb_ipcframe = NullCap,\n      tcb_state    = Inactive,\n      tcb_fault_handler = to_bl (0::machine_word),\n      tcb_ipc_buffer = 0,\n      tcb_fault      = None,\n      tcb_bound_notification  = None,\n      tcb_mcpriority = minBound,\n      tcb_arch       = default_arch_tcb\\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Object Types: The system defines a set of kernel objects, which can be CNodes, TCBs, Endpoints, Notifications, or architecture-specific objects. Each type of object has a distinct structure and purpose, ensuring that the kernel can manage different resources and functionalities effectively.",
    "input": "",
    "output": "datatype kernel_object\n         = CNode nat cnode_contents \\<comment> \\<open>size in bits, and contents\\<close>\n         | TCB tcb\n         | Endpoint endpoint\n         | Notification notification\n         | ArchObj (the_arch_obj: arch_kernel_obj)\n\nlemmas kernel_object_cases =\n  kernel_object.induct[where kernel_object=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P, simplified, rule_format]\n\nlemmas kernel_object_cases_asm =\nkernel_object.induct[where kernel_object=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n  simplified, rule_format, rotated -1]\n\ndefinition aobj_of :: \"kernel_object \\<Rightarrow> arch_kernel_obj option\"\n  where\n  \"aobj_of ko \\<equiv> case ko of ArchObj aobj \\<Rightarrow> Some aobj | _ \\<Rightarrow> None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Well-Formed CNode: Ensures that a cnode's contents are well-formed by verifying that the domain of the cnode's contents matches the expected size.\n\nObject Size Calculation: Determines the size of different kernel objects and capabilities, ensuring that each object and capability has a defined size based on its type and attributes.",
    "input": "",
    "output": "definition\n  well_formed_cnode_n :: \"nat \\<Rightarrow> cnode_contents \\<Rightarrow> bool\" where\n \"well_formed_cnode_n n \\<equiv> \\<lambda>cs. dom cs = {x. length x = n}\"\n\nprimrec\n  obj_bits :: \"kernel_object \\<Rightarrow> nat\"\nwhere\n  \"obj_bits (CNode sz cs) = cte_level_bits + sz\"\n| \"obj_bits (TCB t) = tcb_bits\"\n| \"obj_bits (Endpoint ep) = endpoint_bits\"\n| \"obj_bits (Notification ntfn) = ntfn_bits\"\n| \"obj_bits (ArchObj ao) = arch_kobj_size ao\"\n\nprimrec (nonexhaustive)\n  obj_size :: \"cap \\<Rightarrow> machine_word\"\nwhere\n  \"obj_size NullCap = 0\"\n| \"obj_size (UntypedCap dev r bits f) = 1 << bits\"\n| \"obj_size (EndpointCap r b R) = 1 << obj_bits (Endpoint undefined)\"\n| \"obj_size (NotificationCap r b R) = 1 << obj_bits (Notification undefined)\"\n| \"obj_size (CNodeCap r bits g) = 1 << (cte_level_bits + bits)\"\n| \"obj_size (ThreadCap r) = 1 << obj_bits (TCB undefined)\"\n| \"obj_size (Zombie r zb n) = (case zb of None \\<Rightarrow> 1 << obj_bits (TCB undefined)\n                                        | Some n \\<Rightarrow> 1 << (cte_level_bits + n))\"\n| \"obj_size (ArchObjectCap a) = 1 << arch_obj_size a\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Object Types: Categorizes kernel objects into distinct types including TCB, Endpoint, Notification, Capability Table, and Architecture-specific objects. Each type is determined based on the structure and content of the kernel object, ensuring that objects are correctly identified and managed within the system.",
    "input": "",
    "output": "datatype a_type =\n    ATCB\n  | AEndpoint\n  | ANTFN\n  | ACapTable nat\n  | AGarbage nat \\<comment> \\<open>number of bytes of garbage\\<close>\n  | AArch aa_type\n\ndefinition\n  a_type :: \"kernel_object \\<Rightarrow> a_type\"\nwhere\n \"a_type ob \\<equiv> case ob of\n           CNode sz cspace           \\<Rightarrow> if well_formed_cnode_n sz cspace\n                                        then ACapTable sz else AGarbage (cte_level_bits + sz)\n         | TCB tcb                   \\<Rightarrow> ATCB\n         | Endpoint endpoint         \\<Rightarrow> AEndpoint\n         | Notification notification \\<Rightarrow> ANTFN\n         | ArchObj ao                \\<Rightarrow> AArch (aa_type ao)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Heap Structure: The kernel's heap is represented as a partial function that maps object references to optional kernel objects, allowing for the storage and retrieval of various kernel entities.",
    "input": "",
    "output": "text \\<open>The kernel's heap is a partial function containing kernel objects.\\<close>\ntype_synonym kheap = \"obj_ref \\<Rightarrow> kernel_object option\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Derivation Tree (CDT): The kernel maintains a capability derivation tree, which is a partial mapping from capability slots to their parent capability slots, supporting the Revoke operation that deletes all capabilities derived from a specific capability.",
    "input": "",
    "output": "type_synonym cdt = \"cslot_ptr \\<Rightarrow> cslot_ptr option\"\n\ndatatype irq_state =\n   IRQInactive\n | IRQSignal\n | IRQTimer\n | IRQReserved",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel State: The kernel state encompasses a heap, a capability derivation tree, a bitmap for tracking original capabilities, pointers to the current and idle threads, the machine state, per-IRQ pointers to cnodes for interrupt delivery, an array for managing interrupt usage, and the architecture-specific state. This comprehensive state ensures the kernel's functionality, security, and efficient management of resources and interrupts.",
    "input": "",
    "output": "record abstract_state =\n  kheap              :: kheap\n  cdt                :: cdt\n  is_original_cap    :: \"cslot_ptr \\<Rightarrow> bool\"\n  cur_thread         :: obj_ref\n  idle_thread        :: obj_ref\n  machine_state      :: machine_state\n  interrupt_irq_node :: \"irq \\<Rightarrow> obj_ref\"\n  interrupt_states   :: \"irq \\<Rightarrow> irq_state\"\n  arch_state         :: arch_state",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel State Extension: The kernel state is extended with an additional field of type 'a, allowing for different levels of abstraction and customization by choosing an appropriate concrete type for the extension.",
    "input": "",
    "output": "record 'a state = abstract_state + exst :: 'a",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine State Operation Wrapper: Lifts monadic operations on the underlying machine state to monadic operations on the kernel state, ensuring that the machine state is updated and the result is returned within the kernel state context.",
    "input": "",
    "output": "text \\<open>This wrapper lifts monadic operations on the underlying machine state to\nmonadic operations on the kernel state.\\<close>\ndefinition\n  do_machine_op :: \"(machine_state, 'a) nondet_monad \\<Rightarrow> ('z state, 'a) nondet_monad\"\nwhere\n \"do_machine_op mop \\<equiv> do\n    ms \\<leftarrow> gets machine_state;\n    (r, ms') \\<leftarrow> select_f (mop ms);\n    modify (\\<lambda>state. state \\<lparr> machine_state := ms' \\<rparr>);\n    return r\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "TCB CNode Index Generation: Generate the cnode indices for addressing capability slots within a TCB by converting natural numbers to their binary representation.",
    "input": "",
    "output": "definition\n  tcb_cnode_index :: \"nat \\<Rightarrow> cnode_index\" where\n  \"tcb_cnode_index n \\<equiv> to_bl (of_nat n :: 3 word)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Zombie CTE Bits: Determine the bit size of the CNode cap from which a zombie capability was created. If the capability was created from a TCB cap, it defaults to 3 bits.",
    "input": "",
    "output": "definition\n  zombie_cte_bits :: \"nat option \\<Rightarrow> nat\" where\n \"zombie_cte_bits N \\<equiv> case N of Some n \\<Rightarrow> n | None \\<Rightarrow> 3\"\n\nlemma zombie_cte_bits_simps[simp]:\n \"zombie_cte_bits (Some n) = n\"\n \"zombie_cte_bits None     = 3\"\n  by (simp add: zombie_cte_bits_def)+",
    "system": "",
    "history": []
  },
  {
    "instruction": "First Capability Slot Determination: Identify the first capability slot of a given kernel object, such as a thread, CNode, or zombie, by returning the appropriate cslot pointer.",
    "input": "",
    "output": "primrec (nonexhaustive)\n  first_cslot_of :: \"cap \\<Rightarrow> cslot_ptr\"\nwhere\n  \"first_cslot_of (ThreadCap oref) = (oref, tcb_cnode_index 0)\"\n| \"first_cslot_of (CNodeCap oref bits g) = (oref, replicate bits False)\"\n| \"first_cslot_of (Zombie oref bits n) = (oref, replicate (zombie_cte_bits bits) False)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object References of Capabilities: The function `obj_refs` determines the set of all objects referenced by a given capability. It returns an empty set for capabilities that do not reference any objects, and it returns a set containing the object references for those that do, such as CNodeCap, EndpointCap, NotificationCap, ThreadCap, and Zombie.",
    "input": "",
    "output": "primrec\n  obj_refs :: \"cap \\<Rightarrow> obj_ref set\"\nwhere\n  \"obj_refs NullCap = {}\"\n| \"obj_refs (ReplyCap r m cr) = {}\"\n| \"obj_refs IRQControlCap = {}\"\n| \"obj_refs (IRQHandlerCap irq) = {}\"\n| \"obj_refs (UntypedCap dev r s f) = {}\"\n| \"obj_refs (CNodeCap r bits guard) = {r}\"\n| \"obj_refs (EndpointCap r b cr) = {r}\"\n| \"obj_refs (NotificationCap r b cr) = {r}\"\n| \"obj_refs (ThreadCap r) = {r}\"\n| \"obj_refs DomainCap = {}\"\n| \"obj_refs (Zombie ptr b n) = {ptr}\"\n| \"obj_refs (ArchObjectCap x) = set_option (aobj_ref x)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Reference Extraction: Extracts the object reference from a given capability, supporting various types of capabilities including UntypedCap, ReplyCap, CNodeCap, EndpointCap, NotificationCap, ThreadCap, Zombie, and ArchObjectCap. Additionally, it defines a mapping for TCB capabilities to their respective cnode indices.",
    "input": "",
    "output": "primrec (nonexhaustive)\n  obj_ref_of :: \"cap \\<Rightarrow> obj_ref\"\nwhere\n  \"obj_ref_of (UntypedCap dev r s f) = r\"\n| \"obj_ref_of (ReplyCap r m cr) = r\"\n| \"obj_ref_of (CNodeCap r bits guard) = r\"\n| \"obj_ref_of (EndpointCap r b cr) = r\"\n| \"obj_ref_of (NotificationCap r b cr) = r\"\n| \"obj_ref_of (ThreadCap r) = r\"\n| \"obj_ref_of (Zombie ptr b n) = ptr\"\n| \"obj_ref_of (ArchObjectCap x) = the (aobj_ref x)\"\n\nprimrec (nonexhaustive)\n  cap_bits_untyped :: \"cap \\<Rightarrow> nat\"\nwhere\n  \"cap_bits_untyped (UntypedCap dev r s f) = s\"\n\ndefinition tcb_cnode_map :: \"tcb \\<Rightarrow> cnode_index \\<Rightarrow> cap option\"\n  where\n  \"tcb_cnode_map tcb \\<equiv>\n   [tcb_cnode_index 0 \\<mapsto> tcb_ctable tcb,\n    tcb_cnode_index 1 \\<mapsto> tcb_vtable tcb,\n    tcb_cnode_index 2 \\<mapsto> tcb_reply tcb,\n    tcb_cnode_index 3 \\<mapsto> tcb_caller tcb,\n    tcb_cnode_index 4 \\<mapsto> tcb_ipcframe tcb]\"\n\ndefinition cap_of :: \"kernel_object \\<Rightarrow> cnode_index \\<Rightarrow> cap option\"\n  where\n  \"cap_of kobj \\<equiv> case kobj of CNode _ cs \\<Rightarrow> cs | TCB tcb \\<Rightarrow> tcb_cnode_map tcb | _ \\<Rightarrow> Map.empty\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Caps of Kernel Object: Extracts the set of all capabilities contained within a given kernel object.",
    "input": "",
    "output": "definition\n  caps_of :: \"kernel_object \\<Rightarrow> cap set\" where\n  \"caps_of kobj \\<equiv> ran (cap_of kobj)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Transfer Structure: Defines a structure for capability transfers, including the root, index, and depth of the receiving capability.",
    "input": "",
    "output": "record captransfer =\n  ct_receive_root :: cap_ref\n  ct_receive_index :: cap_ref\n  ct_receive_depth :: data",
    "system": "",
    "history": []
  },
  {
    "instruction": "IPC Buffer Alignment: The IPC buffer must be aligned to a page that can fully contain the maximum possible IPC message, including data, extra capabilities, and additional metadata, without spilling over into another page. This ensures the integrity and proper handling of the IPC buffer during capability transfers.",
    "input": "",
    "output": "definition cap_transfer_data_size :: nat\n  where\n  \"cap_transfer_data_size \\<equiv> 3\"\n\ndefinition msg_max_length :: nat\n  where\n  \"msg_max_length \\<equiv> 120\"\n\ndefinition msg_max_extra_caps :: nat\n  where\n  \"msg_max_extra_caps \\<equiv> 3\"\n\ndefinition max_ipc_length :: nat\n  where\n  \"max_ipc_length \\<equiv> cap_transfer_data_size + msg_max_length + msg_max_extra_caps + 2\"\n\ndefinition msg_align_bits :: nat\n  where\n  \"msg_align_bits \\<equiv> word_size_bits + (LEAST n. max_ipc_length \\<le> 2 ^ n)\"\n\nlemma msg_align_bits':\n  \"msg_align_bits = word_size_bits + 7\"\nproof -\n  have \"(LEAST n. (cap_transfer_data_size + msg_max_length + msg_max_extra_caps + 2) \\<le> 2 ^ n) = 7\"\n  proof (rule Least_equality)\n    show \"(cap_transfer_data_size + msg_max_length + msg_max_extra_caps + 2)  \\<le> 2 ^ 7\"\n      by (simp add: cap_transfer_data_size_def msg_max_length_def msg_max_extra_caps_def)\n  next\n    fix y\n    assume \"(cap_transfer_data_size + msg_max_length + msg_max_extra_caps + 2) \\<le> 2 ^ y\"\n    hence \"(2 :: nat) ^ 7 \\<le> 2 ^ y\"\n      by (simp add: cap_transfer_data_size_def msg_max_length_def msg_max_extra_caps_def)\n    thus \"7 \\<le> y\"\n      by (rule power_le_imp_le_exp [rotated], simp)\n  qed\n  thus ?thesis unfolding msg_align_bits_def max_ipc_length_def by simp\nqed\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Interpret Capability Rights: Convert a user data word into a set of capability rights, including AllowWrite, AllowRead, AllowGrant, and AllowGrantReply, based on the bits in the data.",
    "input": "",
    "output": "text \\<open>Interpret a set of rights from a user data word.\\<close>\ndefinition\n  data_to_rights :: \"data \\<Rightarrow> cap_rights\" where\n  \"data_to_rights data \\<equiv> let\n    w = data_to_16 data\n   in {x. case x of AllowWrite \\<Rightarrow> w !! 0\n                  | AllowRead \\<Rightarrow> w !! 1\n                  | AllowGrant \\<Rightarrow> w !! 2\n                  | AllowGrantReply \\<Rightarrow> w !! 3}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure No Children: Verify that a capability stored in a slot does not have any children. If the capability is a parent, an error is thrown to prevent further operations.",
    "input": "",
    "output": "definition\n  ensure_no_children :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"ensure_no_children cslot_ptr \\<equiv> doE\n    cdt \\<leftarrow> liftE $ gets cdt;\n    whenE (\\<exists>c. cdt c = Some cslot_ptr) (throwError RevokeFirst)\n  odE\"\n\ndefinition\n  max_free_index :: \"nat \\<Rightarrow> nat\" where\n  \"max_free_index magnitude_bits \\<equiv> 2 ^ magnitude_bits\"\n\ndefinition\n  free_index_update :: \"(nat \\<Rightarrow> nat) \\<Rightarrow> cap \\<Rightarrow> cap\"\nwhere\n  \"free_index_update g cap \\<equiv>\n   case cap of UntypedCap dev ref sz f \\<Rightarrow> UntypedCap dev ref sz (g f) | _ \\<Rightarrow> cap\"\n\nprimrec (nonexhaustive)\n  untyped_sz_bits :: \"cap \\<Rightarrow> nat\"\nwhere\n  \"untyped_sz_bits (UntypedCap dev ref sz f) = sz\"\n\nabbreviation\n  max_free_index_update :: \"cap \\<Rightarrow> cap\"\nwhere\n  \"max_free_index_update cap \\<equiv> cap \\<lparr> free_index:= max_free_index (untyped_sz_bits cap) \\<rparr>\"\n\ndefinition\n  set_untyped_cap_as_full :: \"cap \\<Rightarrow> cap \\<Rightarrow> obj_ref \\<times> bool list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_untyped_cap_as_full src_cap new_cap src_slot \\<equiv>\n   if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n       \\<and> obj_ref_of src_cap = obj_ref_of new_cap \\<and> cap_bits_untyped src_cap = cap_bits_untyped new_cap)\n       then set_cap (max_free_index_update src_cap) src_slot else return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Derive Capability: Transform a capability into a form suitable for copying, considering the specific constraints and limitations of different capability types. Some capabilities may be converted to a null capability or left unchanged based on their type.",
    "input": "",
    "output": "definition\nderive_cap :: \"cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (cap,'z::state_ext) se_monad\" where\n\"derive_cap slot cap \\<equiv>\n case cap of\n    ArchObjectCap c \\<Rightarrow> arch_derive_cap c\n    | UntypedCap dev ptr sz f \\<Rightarrow> doE ensure_no_children slot; returnOk cap odE\n    | Zombie ptr n sz \\<Rightarrow> returnOk NullCap\n    | ReplyCap ptr m cr \\<Rightarrow> returnOk NullCap\n    | IRQControlCap \\<Rightarrow> returnOk NullCap\n    | _ \\<Rightarrow> returnOk cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Transform Capability Data: Update a capability based on user-supplied data, with the transformation rules varying by capability type. If the preserve flag is set, the update is performed in-place, and certain changes are disallowed to maintain existing CDT relationships. For endpoint and notification capabilities, the badge is updated if it is zero and the preserve flag is not set. For CNode capabilities, the guard and bits are updated, and the result is validated. For architecture-specific capabilities, a specialized update function is used.",
    "input": "",
    "output": "definition\n  update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> cap \\<Rightarrow> cap\" where\n\"update_cap_data preserve w cap \\<equiv>\n  if is_ep_cap cap then\n    if cap_ep_badge cap = 0 \\<and> \\<not> preserve then\n      badge_update w cap\n    else NullCap\n  else if is_ntfn_cap cap then\n    if cap_ep_badge cap = 0 \\<and> \\<not> preserve then\n      badge_update w cap\n    else NullCap\n  else if is_cnode_cap cap then\n    let\n        (oref, bits, guard) = the_cnode_cap cap;\n        (guard_size', guard'') = update_cnode_cap_data w;\n        guard' = drop (size guard'' - guard_size') (to_bl guard'')\n    in\n        if guard_size' + bits > word_bits\n        then NullCap\n        else CNodeCap oref bits guard'\n  else if is_arch_cap cap then\n    arch_update_cap_data preserve w (the_arch_cap cap)\n  else\n    cap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Resolve Capability Address: Recursively resolves a capability address to a CNode slot by traversing multiple CNodes. Ensures that the guard matches and there are enough bits to resolve, and continues until all bits in the address are used or no further CNodes are available.",
    "input": "",
    "output": "text \\<open>\nRecursively looks up a capability address to a CNode slot by walking over\nmultiple CNodes until all the bits in the address are used or there are\nno further CNodes.\n\\<close>\nfunction resolve_address_bits' :: \"'z itself \\<Rightarrow> cap \\<times> cap_ref \\<Rightarrow> (cslot_ptr \\<times> cap_ref,'z::state_ext) lf_monad\"\nwhere\n  \"resolve_address_bits' z (cap, cref) =\n  (case cap of\n     CNodeCap oref radix_bits guard  \\<Rightarrow>\n     if radix_bits + size guard = 0 then\n       fail \\<comment> \\<open>nothing is translated: table broken\\<close>\n     else doE\n       whenE (\\<not> guard \\<le> cref)\n             \\<comment> \\<open>guard does not match\\<close>\n             (throwError $ GuardMismatch (size cref) guard);\n\n       whenE (size cref < radix_bits + size guard)\n             \\<comment> \\<open>not enough bits to resolve: table malformed\\<close>\n             (throwError $ DepthMismatch (size cref) (radix_bits+size guard));\n\n       offset \\<leftarrow> returnOk $ take radix_bits (drop (size guard) cref);\n       rest \\<leftarrow> returnOk $ drop (radix_bits + size guard) cref;\n       if rest = [] then\n         returnOk ((oref,offset), [])\n       else doE\n         next_cap \\<leftarrow> liftE $ get_cap (oref, offset);\n         if is_cnode_cap next_cap then\n           resolve_address_bits' z (next_cap, rest)\n         else\n           returnOk ((oref,offset), rest)\n       odE\n     odE\n   | _ \\<Rightarrow> throwError InvalidRoot)\"\n  by auto\n\nlemma rab_termination:\n  \"\\<forall>cref guard radix_bits.\n    \\<not> length cref \\<le> radix_bits + length guard \\<and>\n    (0 < radix_bits \\<or> guard \\<noteq> []) \\<longrightarrow>\n      length cref - (radix_bits + length guard) < length cref\"\n  apply clarsimp\n  apply (erule disjE)\n   apply arith\n  apply (clarsimp simp: neq_Nil_conv)\n  apply arith\n  done\n\ntermination\n  apply (relation \"measure (\\<lambda>(z,cap, cs). size cs)\")\n  apply (auto simp: whenE_def returnOk_def return_def rab_termination)\n  done\n\ndeclare resolve_address_bits'.simps[simp del]\n\ndefinition resolve_address_bits where\n\"resolve_address_bits \\<equiv> resolve_address_bits' TYPE('z::state_ext)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Lookup: Provides specialized methods for looking up capabilities and their slots in the CSpace, supporting various standard cases such as resolving addresses, checking for valid cnode capabilities, and handling depth mismatches. These methods ensure that the correct capability and slot are retrieved or an appropriate error is thrown, maintaining the integrity and security of the CSpace.",
    "input": "",
    "output": "definition\n  lookup_slot_for_thread :: \"obj_ref \\<Rightarrow> cap_ref \\<Rightarrow> (cslot_ptr \\<times> cap_ref,'z::state_ext) lf_monad\"\nwhere\n  \"lookup_slot_for_thread thread cref \\<equiv> doE\n     tcb \\<leftarrow> liftE $ gets_the $ get_tcb thread;\n     resolve_address_bits (tcb_ctable tcb, cref)\n  odE\"\n\ndefinition\n  lookup_cap_and_slot :: \"obj_ref \\<Rightarrow> cap_ref \\<Rightarrow> (cap \\<times> cslot_ptr,'z::state_ext) lf_monad\" where\n  \"lookup_cap_and_slot thread cptr \\<equiv> doE\n      (slot, cr) \\<leftarrow> lookup_slot_for_thread thread cptr;\n      cap \\<leftarrow> liftE $ get_cap slot;\n      returnOk (cap, slot)\n  odE\"\n\ndefinition\n  lookup_cap :: \"obj_ref \\<Rightarrow> cap_ref \\<Rightarrow> (cap,'z::state_ext) lf_monad\" where\n  \"lookup_cap thread ref \\<equiv> doE\n     (ref', _) \\<leftarrow> lookup_slot_for_thread thread ref;\n     liftE $ get_cap ref'\n   odE\"\n\ndefinition\n  lookup_slot_for_cnode_op ::\n  \"bool \\<Rightarrow> cap \\<Rightarrow> cap_ref \\<Rightarrow> nat \\<Rightarrow> (cslot_ptr,'z::state_ext) se_monad\"\nwhere\n \"lookup_slot_for_cnode_op is_source croot ptr depth \\<equiv>\n  if is_cnode_cap croot then\n  doE\n    whenE (depth < 1 \\<or> depth > word_bits)\n      $ throwError (RangeError 1 (of_nat word_bits));\n    lookup_error_on_failure is_source $ doE\n      ptrbits_for_depth \\<leftarrow> returnOk $ drop (length ptr - depth) ptr;\n      (slot, rem) \\<leftarrow> resolve_address_bits (croot, ptrbits_for_depth);\n      case rem of\n        [] \\<Rightarrow> returnOk slot\n      | _  \\<Rightarrow> throwError $ DepthMismatch (length rem) 0\n    odE\n  odE\n  else\n    throwError (FailedLookup is_source InvalidRoot)\"\n\ndefinition\n  lookup_source_slot :: \"cap \\<Rightarrow> cap_ref \\<Rightarrow> nat \\<Rightarrow> (cslot_ptr,'z::state_ext) se_monad\"\nwhere\n \"lookup_source_slot \\<equiv> lookup_slot_for_cnode_op True\"\n\ndefinition\n  lookup_target_slot :: \"cap \\<Rightarrow> cap_ref \\<Rightarrow> nat \\<Rightarrow> (cslot_ptr,'z::state_ext) se_monad\"\nwhere\n \"lookup_target_slot \\<equiv> lookup_slot_for_cnode_op False\"\n\ndefinition\n  lookup_pivot_slot :: \"cap \\<Rightarrow> cap_ref \\<Rightarrow> nat \\<Rightarrow> (cslot_ptr,'z::state_ext) se_monad\"\nwhere\n \"lookup_pivot_slot  \\<equiv> lookup_slot_for_cnode_op True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Transfer Interpretation: Interprets user-provided data to determine the parameters for a capability transfer, including the receive root, index, and depth. It ensures that the specified slots are valid and empty before proceeding with the transfer, maintaining the integrity of the capability space.",
    "input": "",
    "output": "text \\<open>These functions are used in interpreting from user arguments the manner\nin which a capability transfer should take place.\\<close>\n\ndefinition\n  captransfer_from_words :: \"machine_word \\<Rightarrow> (captransfer,'z::state_ext) s_monad\"\nwhere\n  \"captransfer_from_words ptr \\<equiv> do\n     w0 \\<leftarrow> do_machine_op $ loadWord ptr;\n     w1 \\<leftarrow> do_machine_op $ loadWord (ptr + word_size);\n     w2 \\<leftarrow> do_machine_op $ loadWord (ptr + 2 * word_size);\n     return \\<lparr> ct_receive_root = data_to_cptr w0,\n              ct_receive_index = data_to_cptr w1,\n              ct_receive_depth = w2 \\<rparr>\n   od\"\n\ndefinition\n  load_cap_transfer :: \"obj_ref \\<Rightarrow> (captransfer,'z::state_ext) s_monad\" where\n \"load_cap_transfer buffer \\<equiv> do\n     offset \\<leftarrow> return $ msg_max_length + msg_max_extra_caps + 2;\n     captransfer_from_words (buffer + of_nat offset * word_size)\n  od\"\n\nfun\n  get_receive_slots :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow>\n                         (cslot_ptr list,'z::state_ext) s_monad\"\nwhere\n  \"get_receive_slots thread (Some buffer) = do\n     ct \\<leftarrow> load_cap_transfer buffer;\n\n     empty_on_failure $ doE\n       cnode \\<leftarrow> unify_failure $\n                  lookup_cap thread (ct_receive_root ct);\n       slot \\<leftarrow> unify_failure $ lookup_target_slot cnode\n                  (ct_receive_index ct) (unat (ct_receive_depth ct));\n\n       cap \\<leftarrow> liftE $ get_cap slot;\n\n       whenE (cap \\<noteq> NullCap) (throwError ());\n\n       returnOk [slot]\n     odE\n   od\"\n|  \"get_receive_slots x None = return []\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Long-Running Deletion: Determine if the deletion of a capability is a long-running operation based on its type. The deletion is considered long-running for CNode, Zombie, and Thread capabilities, and it checks if the capability is the final one in the slot.",
    "input": "",
    "output": "text \\<open>Deletion of the final capability to any object is a long running\noperation if the capability is of these types.\\<close>\ndefinition\n  long_running_delete :: \"cap \\<Rightarrow> bool\" where\n \"long_running_delete cap \\<equiv> case cap of\n    CNodeCap ptr bits gd \\<Rightarrow> True\n  | Zombie ptr bits n \\<Rightarrow> True\n  | ThreadCap ptr \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"\n\n\ndefinition\n  slot_cap_long_running_delete :: \"cslot_ptr \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"slot_cap_long_running_delete slot \\<equiv> do\n     cap \\<leftarrow> get_cap slot;\n     case cap of\n         NullCap \\<Rightarrow> return False\n       | _ \\<Rightarrow> do\n           final \\<leftarrow> is_final_cap cap;\n           return (final \\<and> long_running_delete cap)\n         od\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Swap: Exchanges the contents of two capability slots, including updating their states and transforming them as requested. The operation also updates the children and parents in the capability derivation tree (CDT) to reflect the swap, ensuring the integrity of the CSpace structure.",
    "input": "",
    "output": "definition\n  cap_swap :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cap_swap cap1 slot1 cap2 slot2 \\<equiv>\n  do\n    set_cap cap2 slot1;\n    set_cap cap1 slot2;\n    slot1_p \\<leftarrow> gets (\\<lambda>s. cdt s slot1);\n    slot2_p \\<leftarrow> gets (\\<lambda>s. cdt s slot2);\n    cdt \\<leftarrow> gets cdt;\n    \\<comment> \\<open>update children:\\<close>\n    cdt' \\<leftarrow> return (\\<lambda>n. if cdt n = Some slot1\n                        then Some slot2\n                        else if cdt n = Some slot2\n                        then Some slot1\n                        else cdt n);\n    \\<comment> \\<open>update parents:\\<close>\n    set_cdt (cdt' (slot1 := cdt' slot2, slot2 := cdt' slot1));\n    do_extended_op (cap_swap_ext slot1 slot2 slot1_p slot2_p);\n    is_original \\<leftarrow> gets is_original_cap;\n    set_original slot1 (is_original slot2);\n    set_original slot2 (is_original slot1)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Movement: Move a capability from one slot to another, updating the capability table and parent references to reflect the new location of the capability. The original capability in the source slot is replaced with a null capability, and the originality flag is updated accordingly.",
    "input": "",
    "output": "definition\n  cap_move :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cap_move new_cap src_slot dest_slot \\<equiv> do\n    set_cap new_cap dest_slot;\n    set_cap NullCap src_slot;\n    src_p \\<leftarrow> gets (\\<lambda>s. cdt s src_slot);\n    dest_p \\<leftarrow> gets (\\<lambda>s. cdt s dest_slot);\n    cdt \\<leftarrow> gets cdt;\n    parent \\<leftarrow> return $ cdt src_slot;\n    cdt' \\<leftarrow> return $ cdt(dest_slot := parent, src_slot := None);\n    set_cdt (\\<lambda>r. if cdt' r = Some src_slot then Some dest_slot else cdt' r);\n    do_extended_op (cap_move_ext src_slot dest_slot src_p dest_p);\n    is_original \\<leftarrow> gets is_original_cap;\n    set_original dest_slot (is_original src_slot);\n    set_original src_slot False\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Swap for Deletion: Swaps the capabilities between two different capability slots without altering the capabilities themselves, ensuring that the existing capabilities are preserved during the swap.",
    "input": "",
    "output": "definition\n  cap_swap_for_delete :: \"cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cap_swap_for_delete slot1 slot2 \\<equiv>\n  when (slot1 \\<noteq> slot2) $ do\n    cap1 \\<leftarrow> get_cap slot1;\n    cap2 \\<leftarrow> get_cap slot2;\n    cap_swap cap1 slot1 cap2 slot2\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Recursive Deletion Calls: Define the types of recursive deletion operations, including deleting a capability table entry, finalizing a slot, and reducing a zombie capability. These operations are parameterized with a capability slot pointer and a boolean flag to indicate specific behaviors.",
    "input": "",
    "output": "datatype\n  rec_del_call\n  = CTEDeleteCall cslot_ptr bool\n  | FinaliseSlotCall cslot_ptr bool\n  | ReduceZombieCall cap cslot_ptr bool",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate Capability Slot: Determine the location of a capability slot by calculating the nth slot beyond a specified base slot. This ensures that capabilities can be accurately referenced and managed within the CSpace.",
    "input": "",
    "output": "definition\n  locate_slot :: \"cslot_ptr \\<Rightarrow> nat \\<Rightarrow> cslot_ptr\" where\n \"locate_slot \\<equiv> \\<lambda>(a, b) n. (a, drop (32 - length b)\n                           (to_bl (of_bl b + of_nat n :: word32)))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Revoking and Deleting IRQ Handler Capabilities: Upon deletion of an IRQ handler capability, the system retrieves the slot associated with the specified IRQ and deletes the capability from that slot.",
    "input": "",
    "output": "definition\n  deleting_irq_handler :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"deleting_irq_handler irq \\<equiv> do\n    slot \\<leftarrow> get_irq_slot irq;\n    cap_delete_one slot\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Finalization: When a capability is deleted, the system performs specific actions based on the type of capability. It returns two capabilities: one to be re-inserted into the slot (often a Zombie for long-running operations) and another representing any post-deletion actions required, such as clearing an IRQ or unbinding notifications. The finalization process ensures that the system handles the deletion of capabilities correctly and maintains the integrity of the CSpace.",
    "input": "",
    "output": "fun\n  finalise_cap :: \"cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"finalise_cap NullCap                  final = return (NullCap, NullCap)\"\n| \"finalise_cap (UntypedCap dev r bits f)    final = return (NullCap, NullCap)\"\n| \"finalise_cap (ReplyCap r m R)         final = return (NullCap, NullCap)\"\n| \"finalise_cap (EndpointCap r b R)      final =\n      (liftM (K (NullCap, NullCap)) $ when final $ cancel_all_ipc r)\"\n| \"finalise_cap (NotificationCap r b R)  final =\n      (liftM (K (NullCap, NullCap)) $ when final $ do\n          unbind_maybe_notification r;\n          cancel_all_signals r\n        od)\"\n| \"finalise_cap (CNodeCap r bits g)  final =\n      return (if final then Zombie r (Some bits) (2 ^ bits) else NullCap, NullCap)\"\n| \"finalise_cap (ThreadCap r)            final =\n      do\n         when final $ unbind_notification r;\n         when final $ suspend r;\n         when final $ prepare_thread_delete r;\n         return (if final then (Zombie r None 5) else NullCap, NullCap)\n      od\"\n| \"finalise_cap DomainCap                final = return (NullCap, NullCap)\"\n| \"finalise_cap (Zombie r b n)           final =\n      do assert final; return (Zombie r b n, NullCap) od\"\n| \"finalise_cap IRQControlCap            final = return (NullCap, NullCap)\"\n| \"finalise_cap (IRQHandlerCap irq)      final = (\n       if final then do\n         deleting_irq_handler irq;\n         return (NullCap, (IRQHandlerCap irq))\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (ArchObjectCap a)        final =\n      (arch_finalise_cap a final)\"\n\ndefinition\n  can_fast_finalise :: \"cap \\<Rightarrow> bool\" where\n \"can_fast_finalise cap \\<equiv> case cap of\n    ReplyCap r m R \\<Rightarrow> True\n  | EndpointCap r b R \\<Rightarrow> True\n  | NotificationCap r b R \\<Rightarrow> True\n  | NullCap \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fast Finalisation: Ensures that a capability is deleted when it is known that a long-running operation is impossible, by finalising the capability and verifying that the result is a null capability.",
    "input": "",
    "output": "lemma fast_finalise_def2:\n  \"fast_finalise cap final = do\n     assert (can_fast_finalise cap);\n     result \\<leftarrow> finalise_cap cap final;\n     assert (result = (NullCap, NullCap))\n   od\"\n  supply K_def[simp]\n  by (cases cap, simp_all add: liftM_def assert_def can_fast_finalise_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Removability: Determines if a capability can be removed based on its type and the slots it covers. Null capabilities are always removable, and Zombie capabilities are removable if they cover no slots or only the slot in which they are currently stored.",
    "input": "",
    "output": "primrec (nonexhaustive)\n  cap_removeable :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\"\nwhere\n  \"cap_removeable NullCap slot = True\"\n| \"cap_removeable (Zombie slot' bits n) slot =\n    ((n = 0) \\<or> (n = 1 \\<and> (slot', replicate (zombie_cte_bits bits) False) = slot))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cyclic Zombie Check: Ensures that a capability is not a zombie referring to the CNode or TCB slot in which it is stored, preventing cyclic references and maintaining the integrity of the capability system.",
    "input": "",
    "output": "definition\n  cap_cyclic_zombie :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\" where\n \"cap_cyclic_zombie cap slot \\<equiv> case cap of\n         Zombie slot' bits n \\<Rightarrow> (slot', replicate (zombie_cte_bits bits) False) = slot\n       | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Recursive Capability Deletion: Perform a complete recursive deletion of capabilities, including finalizing slots, handling cyclic zombies, and reducing zombie capabilities. The operation ensures that all related capabilities are properly cleaned up and slots are emptied, maintaining the integrity of the capability space.",
    "input": "",
    "output": "function (sequential)\n  rec_del :: \"rec_del_call \\<Rightarrow> (bool * cap,'z::state_ext) p_monad\"\nwhere\n  \"rec_del (CTEDeleteCall slot exposed) s =\n (doE\n    (success, cleanup_info) \\<leftarrow> rec_del (FinaliseSlotCall slot exposed);\n    without_preemption $ when (exposed \\<or> success) $ empty_slot slot cleanup_info;\n    returnOk undefined\n  odE) s\"\n|\n  \"rec_del (FinaliseSlotCall slot exposed) s =\n (doE\n    cap \\<leftarrow> without_preemption $ get_cap slot;\n    if (cap = NullCap)\n    then returnOk (True, NullCap)\n    else (doE\n      is_final \\<leftarrow> without_preemption $ is_final_cap cap;\n      (remainder, cleanup_info) \\<leftarrow> without_preemption $ finalise_cap cap is_final;\n      if (cap_removeable remainder slot)\n      then returnOk (True, cleanup_info)\n      else if (cap_cyclic_zombie remainder slot \\<and> \\<not> exposed)\n      then doE\n        without_preemption $ set_cap remainder slot;\n        returnOk (False, NullCap)\n      odE\n      else doE\n        without_preemption $ set_cap remainder slot;\n        rec_del (ReduceZombieCall remainder slot exposed);\n        preemption_point;\n        rec_del (FinaliseSlotCall slot exposed)\n      odE\n    odE)\n  odE) s\"\n\n| \"rec_del (ReduceZombieCall (Zombie ptr bits (Suc n)) slot False) s =\n (doE\n    cn \\<leftarrow> returnOk $ first_cslot_of (Zombie ptr bits (Suc n));\n    assertE (cn \\<noteq> slot);\n    without_preemption $ cap_swap_for_delete cn slot;\n    returnOk undefined\n  odE) s\"\n|\n \"rec_del (ReduceZombieCall (Zombie ptr bits (Suc n)) slot True) s =\n (doE\n    end_slot \\<leftarrow> returnOk (ptr, nat_to_cref (zombie_cte_bits bits) n);\n    rec_del (CTEDeleteCall end_slot False);\n    new_cap \\<leftarrow> without_preemption $ get_cap slot;\n    if (new_cap = Zombie ptr bits (Suc n))\n    then without_preemption $ set_cap (Zombie ptr bits n) slot\n    else assertE (new_cap = NullCap \\<or>\n                  is_zombie new_cap \\<and> first_cslot_of new_cap = slot\n                   \\<and> first_cslot_of (Zombie ptr bits (Suc n)) \\<noteq> slot);\n    returnOk undefined\n  odE) s\"\n|\n \"rec_del (ReduceZombieCall cap slot exposed) s =\n  fail s\"\n  by pat_completeness auto",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Deletion: Recursively delete a capability from the specified slot, ensuring that all associated resources and references are properly removed.",
    "input": "",
    "output": "definition\n  cap_delete :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n \"cap_delete slot \\<equiv> doE rec_del (CTEDeleteCall slot True); returnOk () odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Prepare Capability for Deletion: Finalize the capability in a specified slot, preparing it for deletion without actually removing it. This ensures that the capability is in a state where it can be safely deleted later.",
    "input": "",
    "output": "definition\n  finalise_slot :: \"cslot_ptr \\<Rightarrow> bool \\<Rightarrow> (bool * cap,'z::state_ext) p_monad\"\nwhere\n  \"finalise_slot p e \\<equiv> rec_del (FinaliseSlotCall p e)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Recursive Delete Call Properties: Determine if a recursive delete call is exposed, identify if it is a CTE delete call, and extract the slot associated with the call. These properties help in managing the revocation and deletion of capabilities by providing information about the type and exposure status of the delete operation.",
    "input": "",
    "output": "primrec\n  exposed_rdcall :: \"rec_del_call \\<Rightarrow> bool\"\nwhere\n  \"exposed_rdcall (CTEDeleteCall slot exposed) = exposed\"\n| \"exposed_rdcall (FinaliseSlotCall slot exposed) = exposed\"\n| \"exposed_rdcall (ReduceZombieCall cap slot exposed) = exposed\"\n\nprimrec\n  isCTEDeleteCall :: \"rec_del_call \\<Rightarrow> bool\"\nwhere\n  \"isCTEDeleteCall (CTEDeleteCall slot exposed) = True\"\n| \"isCTEDeleteCall (FinaliseSlotCall slot exposed) = False\"\n| \"isCTEDeleteCall (ReduceZombieCall cap slot exposed) = False\"\n\nprimrec\n  slot_rdcall :: \"rec_del_call \\<Rightarrow> cslot_ptr\"\nwhere\n  \"slot_rdcall (CTEDeleteCall slot exposed) = slot\"\n| \"slot_rdcall (FinaliseSlotCall slot exposed) = slot\"\n| \"slot_rdcall (ReduceZombieCall cap slot exposed) = slot\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Revoke and Delete Derived Capabilities: Recursively revoke and delete all derived capabilities of a given capability, ensuring that the capability tree is properly cleaned up.",
    "input": "",
    "output": "function cap_revoke :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n\"cap_revoke slot s = (doE\n    cap \\<leftarrow> without_preemption $ get_cap slot;\n    cdt \\<leftarrow> without_preemption $ gets cdt;\n    descendants \\<leftarrow> returnOk $ descendants_of slot cdt;\n    whenE (cap \\<noteq> NullCap \\<and> descendants \\<noteq> {}) (doE\n      child \\<leftarrow> without_preemption $ select_ext (next_revoke_cap slot) descendants;\n      cap \\<leftarrow> without_preemption $ get_cap child;\n      assertE (cap \\<noteq> NullCap);\n      cap_delete child;\n      preemption_point;\n      cap_revoke slot\n    odE)\nodE) s\"\nby auto",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Region Comparison: Determines if two capabilities refer to the same memory region or object. This is based on the type and properties of the capabilities, including their references, sizes, and specific attributes, ensuring that only compatible and overlapping capabilities are considered to be in the same region.",
    "input": "",
    "output": "definition\n  get_badge :: \"cap \\<Rightarrow> badge option\" where\n \"get_badge cap \\<equiv> case cap of\n    NotificationCap oref badge cr \\<Rightarrow> Some badge\n  | EndpointCap oref badge cr      \\<Rightarrow> Some badge\n  | _                              \\<Rightarrow> None\"\n\n\ndefinition\n  is_physical :: \"cap \\<Rightarrow> bool\" where\n  \"is_physical cap \\<equiv> case cap of\n    NullCap \\<Rightarrow> False\n  | DomainCap \\<Rightarrow> False\n  | IRQControlCap \\<Rightarrow> False\n  | IRQHandlerCap _ \\<Rightarrow> False\n  | ReplyCap _ _ _ \\<Rightarrow> False\n  | ArchObjectCap c \\<Rightarrow> arch_is_physical c\n  | _ \\<Rightarrow> True\"\n\nfun\n  same_region_as :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"same_region_as NullCap c' = False\"\n| \"same_region_as (UntypedCap dev r bits free) c' =\n    (is_physical c' \\<and>\n     r \\<le> obj_ref_of c' \\<and>\n     obj_ref_of c' \\<le> obj_ref_of c' + obj_size c' - 1 \\<and>\n     obj_ref_of c' + obj_size c' - 1 \\<le> r + (1 << bits) - 1)\"\n| \"same_region_as (EndpointCap r b R) c' =\n    (is_ep_cap c' \\<and> obj_ref_of c' = r)\"\n| \"same_region_as (NotificationCap r b R) c' =\n    (is_ntfn_cap c' \\<and> obj_ref_of c' = r)\"\n| \"same_region_as (CNodeCap r bits g) c' =\n    (is_cnode_cap c' \\<and> obj_ref_of c' = r \\<and> bits_of c' = bits)\"\n| \"same_region_as (ReplyCap n m cr) c' = (\\<exists>m' cr. c' = ReplyCap n m' cr)\"\n| \"same_region_as (ThreadCap r) c' =\n    (is_thread_cap c' \\<and> obj_ref_of c' = r)\"\n| \"same_region_as (Zombie r b n) c' = False\"\n| \"same_region_as (IRQControlCap) c' =\n    (c' = IRQControlCap \\<or> (\\<exists>n. c' = IRQHandlerCap n))\"\n| \"same_region_as DomainCap c' = (c' = DomainCap)\"\n| \"same_region_as (IRQHandlerCap n) c' =\n    (c' = IRQHandlerCap n)\"\n| \"same_region_as (ArchObjectCap a) c' =\n    (case c' of ArchObjectCap a' \\<Rightarrow> arch_same_region_as a a' | _ \\<Rightarrow> False)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Capabilities for Same Object: Determine if two capabilities refer to the same object by comparing their types and properties, ensuring that they are either of the same region or, in the case of architecture-specific capabilities, that they refer to the same architectural object.",
    "input": "",
    "output": "definition\n  same_object_as :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\" where\n \"same_object_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (UntypedCap dev r bits free, _) \\<Rightarrow> False\n    | (IRQControlCap, IRQHandlerCap n) \\<Rightarrow> False\n    | (ArchObjectCap ac, ArchObjectCap ac') \\<Rightarrow> same_aobject_as ac ac'\n    | _ \\<Rightarrow> same_region_as cp cp')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Parent-Child Relationship for Capabilities: A capability \\( c \\) should be a parent of another capability \\( c' \\) if \\( c \\) is the original capability to the object and covers the same memory region as \\( c' \\). For endpoint and notification capabilities, \\( c \\) should also have a non-zero badge, and \\( c' \\) should have the same badge but not be an original badged endpoint or notification capability.",
    "input": "",
    "output": "definition\n  should_be_parent_of :: \"cap \\<Rightarrow> bool \\<Rightarrow> cap \\<Rightarrow> bool \\<Rightarrow> bool\" where\n  \"should_be_parent_of c original c' original' \\<equiv>\n   original \\<and>\n   same_region_as c c' \\<and>\n   (case c of\n      EndpointCap ref badge R \\<Rightarrow> badge \\<noteq> 0 \\<longrightarrow> cap_ep_badge c' = badge \\<and> \\<not>original'\n    | NotificationCap ref badge R \\<Rightarrow> badge \\<noteq> 0 \\<longrightarrow> cap_ep_badge c' = badge \\<and> \\<not>original'\n    | _ \\<Rightarrow> True)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Revocability: Determines if a new capability should be considered revocable based on its type and attributes. Specifically, it checks for newly badged endpoint capabilities, IRQ handlers, untyped capabilities, and certain architecture-specific capabilities.",
    "input": "",
    "output": "definition\n  is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"is_cap_revocable new_cap src_cap \\<equiv> case new_cap of\n      ArchObjectCap acap \\<Rightarrow> arch_is_cap_revocable new_cap src_cap\n    | EndpointCap _ _ _ \\<Rightarrow> cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n    | NotificationCap _ _ _ \\<Rightarrow> cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n    | IRQHandlerCap _ \\<Rightarrow> src_cap = IRQControlCap\n    | UntypedCap _ _ _ _ \\<Rightarrow> True\n    | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Capability Insertion and Movement: Insert a new capability into the CSpace as either a sibling or child of an existing capability, determined by the function `should_be_parent_of`. The operation ensures that the destination slot is empty, updates the capability tables, and sets the originality status of the new capability.",
    "input": "",
    "output": "definition\n  cap_insert :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"cap_insert new_cap src_slot dest_slot \\<equiv> do\n    src_cap \\<leftarrow> get_cap src_slot;\n\n    dest_original \\<leftarrow> return $ is_cap_revocable new_cap src_cap;\n\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_untyped_cap_as_full src_cap new_cap src_slot;\n    set_cap new_cap dest_slot;\n\n    is_original \\<leftarrow> gets is_original_cap;\n    src_parent \\<leftarrow> return $\n       should_be_parent_of src_cap (is_original src_slot) new_cap dest_original;\n    src_p \\<leftarrow> gets (\\<lambda>s. cdt s src_slot);\n    dest_p \\<leftarrow> gets (\\<lambda>s. cdt s dest_slot);\n    update_cdt (\\<lambda>cdt. cdt (dest_slot := if src_parent\n                                        then Some src_slot\n                                        else cdt src_slot));\n    do_extended_op (cap_insert_ext src_parent src_slot dest_slot src_p dest_p);\n    set_original dest_slot dest_original\n  od\"\n\n\ndefinition\n  has_cancel_send_rights :: \"cap \\<Rightarrow> bool\" where\n  \"has_cancel_send_rights cap \\<equiv> case cap of\n   EndpointCap _ _ R \\<Rightarrow> R = all_rights\n   | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "TCB Registers and Capabilities Merge: Overwrite the capabilities stored in a TCB (such as ctable, vtable, reply, caller, and ipcframe) with those from another TCB while preserving the register set and other fields.",
    "input": "",
    "output": "definition\n  tcb_registers_caps_merge :: \"tcb \\<Rightarrow> tcb \\<Rightarrow> tcb\"\nwhere\n \"tcb_registers_caps_merge regtcb captcb \\<equiv>\n  regtcb \\<lparr> tcb_ctable := tcb_ctable captcb,\n           tcb_vtable := tcb_vtable captcb,\n           tcb_reply := tcb_reply captcb,\n           tcb_caller := tcb_caller captcb,\n           tcb_ipcframe := tcb_ipcframe captcb \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Capability Operations: Authorize various operations on capabilities within CNodes, including inserting, moving, rotating, saving, revoking, deleting, and recycling capabilities. These operations ensure the proper management and manipulation of capabilities, maintaining the integrity and security of the capability space.",
    "input": "",
    "output": "text \\<open>The CNode capability confers authority to various methods\nwhich act on CNodes and the capabilities within them. Copies of\ncapabilities may be inserted in empty CNode slots by\nInsert. Capabilities may be moved to empty slots with Move or swapped\nwith others in a three way rotate by Rotate. A Reply capability stored\nin a thread's last-caller slot may be saved into a regular CNode slot\nwith Save.  The Revoke, Delete and Recycle methods may also be\ninvoked on the capabilities stored in the CNode.\\<close>\n\ndefinition\n  invoke_cnode :: \"cnode_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n  \"invoke_cnode i \\<equiv> case i of\n    RevokeCall dest_slot \\<Rightarrow> cap_revoke dest_slot\n  | DeleteCall dest_slot \\<Rightarrow> cap_delete dest_slot\n  | InsertCall cap src_slot dest_slot \\<Rightarrow>\n       without_preemption $ cap_insert cap src_slot dest_slot\n  | MoveCall cap src_slot dest_slot \\<Rightarrow>\n       without_preemption $ cap_move cap src_slot dest_slot\n  | RotateCall cap1 cap2 slot1 slot2 slot3 \\<Rightarrow>\n       without_preemption $\n       if slot1 = slot3 then\n         cap_swap cap1 slot1 cap2 slot2\n       else\n         do cap_move cap2 slot2 slot3; cap_move cap1 slot1 slot2 od\n  | SaveCall slot \\<Rightarrow> without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    src_slot \\<leftarrow> return (thread, tcb_cnode_index 3);\n    cap \\<leftarrow> get_cap src_slot;\n    (case cap of\n          NullCap \\<Rightarrow> return ()\n        | ReplyCap _ False _ \\<Rightarrow> cap_move cap src_slot slot\n        | _ \\<Rightarrow> fail) od\n  | CancelBadgedSendsCall (EndpointCap ep b R) \\<Rightarrow>\n    without_preemption $ when (b \\<noteq> 0) $ cancel_badged_sends ep b\n  | CancelBadgedSendsCall _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Cap Classification: Defines different classes of capabilities, including physical, reply, IRQ, ASID master, null, domain, and I/O port, to establish invariants and ensure the correct handling and management of capabilities within the system.",
    "input": "",
    "output": "datatype capclass =\n  PhysicalClass | ReplyClass \"obj_ref\" | IRQClass | ASIDMasterClass | NullClass | DomainClass | IOPortClass\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Object Management: Access and modify kernel objects in the kernel heap. Ensure that the object being set has the same type as the existing object at the specified reference, maintaining the integrity and consistency of the kernel's data structures.",
    "input": "",
    "output": "definition\n  get_object :: \"obj_ref \\<Rightarrow> (kernel_object,'z::state_ext) s_monad\"\nwhere\n  \"get_object ptr \\<equiv> do\n     kh \\<leftarrow> gets kheap;\n     assert (kh ptr \\<noteq> None);\n     return $ the $ kh ptr\n   od\"\n\ndefinition\n  set_object :: \"obj_ref \\<Rightarrow> kernel_object \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_object ptr obj \\<equiv> do\n     kobj <- get_object ptr;\n     assert (a_type kobj = a_type obj);\n     s \\<leftarrow> get;\n     put (s\\<lparr>kheap := (kheap s)(ptr \\<mapsto> obj)\\<rparr>)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Control Block (TCB) Management: Provides mechanisms to access, retrieve, and modify TCBs and their associated fields, including thread state, bound notifications, and priorities. These operations ensure that the kernel can effectively manage and update thread properties, maintaining the integrity and performance of the system.",
    "input": "",
    "output": "definition\n  get_tcb :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> tcb option\"\nwhere\n  \"get_tcb tcb_ref state \\<equiv>\n   case kheap state tcb_ref of\n      None      \\<Rightarrow> None\n    | Some kobj \\<Rightarrow> (case kobj of\n        TCB tcb \\<Rightarrow> Some tcb\n      | _       \\<Rightarrow> None)\"\n\ndefinition\n  thread_get :: \"(tcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> ('a,'z::state_ext) s_monad\"\nwhere\n  \"thread_get f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb tptr;\n     return $ f tcb\n   od\"\n\ndefinition\n  thread_set :: \"(tcb \\<Rightarrow> tcb) \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"thread_set f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb tptr;\n     set_object tptr $ TCB $ f tcb\n   od\"\n\ndefinition\n  arch_thread_get :: \"(arch_tcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> ('a,'z::state_ext) s_monad\"\nwhere\n  \"arch_thread_get f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb tptr;\n     return $ f (tcb_arch tcb)\n   od\"\n\ndefinition\n  arch_thread_set :: \"(arch_tcb \\<Rightarrow> arch_tcb) \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"arch_thread_set f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb tptr;\n     set_object tptr $ TCB $ tcb \\<lparr> tcb_arch := f (tcb_arch tcb) \\<rparr>\n   od\"\n\ndefinition\n  get_thread_state :: \"obj_ref \\<Rightarrow> (thread_state,'z::state_ext) s_monad\"\nwhere\n  \"get_thread_state ref \\<equiv> thread_get tcb_state ref\"\n\ndefinition\n  get_bound_notification :: \"obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\"\nwhere\n  \"get_bound_notification ref \\<equiv> thread_get tcb_bound_notification ref\"\n\ndefinition\n  set_bound_notification :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"set_bound_notification ref ntfn \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb ref;\n     set_object ref (TCB (tcb \\<lparr> tcb_bound_notification := ntfn \\<rparr>))\n   od\"\n\ndefinition set_thread_state_ext :: \"obj_ref \\<Rightarrow> unit det_ext_monad\" where\n  \"set_thread_state_ext t \\<equiv> do\n     ts \\<leftarrow> get_thread_state t;\n     cur \\<leftarrow> gets cur_thread;\n     action \\<leftarrow> gets scheduler_action;\n     when (\\<not> (runnable ts) \\<and> cur = t \\<and> action = resume_cur_thread) (set_scheduler_action choose_new_thread)\n   od\"\n\ndefinition\n  set_thread_state :: \"obj_ref \\<Rightarrow> thread_state \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_thread_state ref ts \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb ref;\n     set_object ref (TCB (tcb \\<lparr> tcb_state := ts \\<rparr>));\n     do_extended_op (set_thread_state_ext ref)\n   od\"\n\ndefinition\n  set_priority :: \"obj_ref \\<Rightarrow> priority \\<Rightarrow> unit det_ext_monad\" where\n  \"set_priority tptr prio \\<equiv> do\n     tcb_sched_action tcb_sched_dequeue tptr;\n     thread_set_priority tptr prio;\n     ts \\<leftarrow> get_thread_state tptr;\n     when (runnable ts) $ do\n       cur \\<leftarrow> gets cur_thread;\n       if tptr = cur then reschedule_required else possible_switch_to tptr\n     od\n   od\"\n\ndefinition\n  set_mcpriority :: \"obj_ref \\<Rightarrow> priority \\<Rightarrow> (unit, 'z::state_ext) s_monad\"  where\n  \"set_mcpriority ref mcp \\<equiv> thread_set (\\<lambda>tcb. tcb\\<lparr>tcb_mcpriority:=mcp\\<rparr>) ref \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Object Management: Manage simple kernel objects (such as endpoints and notifications) by retrieving and setting their values. Ensure that the object type is valid and use a partial inverse function to safely convert between the kernel object and its specific type.",
    "input": "",
    "output": "(* to be used for abstraction unifying kernel objects other than TCB and CNode *)\n\ndefinition\n  partial_inv :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> ('b \\<Rightarrow> 'a option)\"\nwhere\n  \"partial_inv f x = (if \\<exists>!y. f y = x then Some (THE y. f y = x) else None)\"\n\nlemma proj_inj: \"inj f \\<Longrightarrow> (partial_inv f ko = Some v) = (f v = ko)\"\n  by (auto simp: partial_inv_def the_equality injD)\n\nlemma inj_Endpoint: \"inj Endpoint\" by (auto intro: injI)\nlemma inj_Notification: \"inj Notification\"  by (auto intro: injI)\n\nlemmas proj_inj_ep[simp] = proj_inj[OF inj_Endpoint]\nlemma proj_ko_type_ep[simp]: \"(\\<exists>v. partial_inv Endpoint  ko = Some (v::endpoint)) = (a_type ko = AEndpoint)\"\n  by (cases ko; auto simp: partial_inv_def a_type_def)\n\nlemmas proj_inj_ntfn[simp] = proj_inj[OF inj_Notification]\nlemma proj_ko_type_ntfn[simp]:\n  \"(\\<exists>v. partial_inv Notification  ko = Some (v::notification)) = (a_type ko = ANTFN)\"\n  by (cases ko; auto simp: partial_inv_def a_type_def)\n\n\nabbreviation\n  \"is_simple_type \\<equiv> (\\<lambda>ob. a_type ob \\<in> {AEndpoint, ANTFN})\"\n\n\ndefinition\n  get_simple_ko :: \"('a \\<Rightarrow> kernel_object) \\<Rightarrow> obj_ref \\<Rightarrow> ('a,'z::state_ext) s_monad\"\nwhere\n  \"get_simple_ko f ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     assert (is_simple_type kobj);\n     (case partial_inv f kobj of Some e \\<Rightarrow> return e | _ \\<Rightarrow> fail)\n   od\"\n\n\ndefinition\n  set_simple_ko :: \"('a \\<Rightarrow> kernel_object) \\<Rightarrow> obj_ref \\<Rightarrow> 'a \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_simple_ko f ptr ep \\<equiv> do\n     obj \\<leftarrow> get_object ptr;\n     assert (is_simple_type obj);\n     assert (partial_inv f obj \\<noteq> None);\n     set_object ptr (f ep)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Endpoint and Notification Management: Provides operations to get and set the state of endpoints and notifications, allowing for the management of their bound threads and associated objects. This ensures that the kernel can effectively handle synchronous and asynchronous communication and signaling between threads.",
    "input": "",
    "output": "abbreviation\n  get_endpoint :: \"obj_ref \\<Rightarrow> (endpoint,'z::state_ext) s_monad\" where\n  \"get_endpoint \\<equiv> get_simple_ko Endpoint\"\n\nabbreviation\n  set_endpoint :: \"obj_ref \\<Rightarrow> endpoint \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_endpoint \\<equiv> set_simple_ko Endpoint\"\n\nabbreviation\n  get_notification :: \"obj_ref \\<Rightarrow> (notification,'z::state_ext) s_monad\" where\n  \"get_notification \\<equiv> get_simple_ko Notification\"\n\nabbreviation\n  set_notification :: \"obj_ref \\<Rightarrow> notification \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_notification \\<equiv> set_simple_ko Notification\"\n\nabbreviation\n  ntfn_set_bound_tcb :: \"notification \\<Rightarrow> obj_ref option \\<Rightarrow> notification\" where\n  \"ntfn_set_bound_tcb ntfn t \\<equiv> ntfn \\<lparr> ntfn_bound_tcb := t \\<rparr>\"\n\nabbreviation\n  ntfn_set_obj :: \"notification \\<Rightarrow> ntfn \\<Rightarrow> notification\" where\n  \"ntfn_set_obj ntfn a \\<equiv> ntfn \\<lparr> ntfn_obj := a \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ State and Slot Management: Access and modify the state of an IRQ, and retrieve the slot associated with an IRQ. Ensures that the IRQ state is updated in the system state and the corresponding interrupt is masked or unmasked based on the new state.",
    "input": "",
    "output": "definition\n  get_irq_state :: \"irq \\<Rightarrow> (irq_state,'z::state_ext) s_monad\" where\n \"get_irq_state irq \\<equiv> gets (\\<lambda>s. interrupt_states s irq)\"\n\ndefinition\n  set_irq_state :: \"irq_state \\<Rightarrow> irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"set_irq_state state irq \\<equiv> do\n    modify (\\<lambda>s. s \\<lparr> interrupt_states := (interrupt_states s) (irq := state)\\<rparr>);\n    do_machine_op $ maskInterrupt (state = IRQInactive) irq\n  od\"\n\ndefinition\n  get_irq_slot :: \"irq \\<Rightarrow> (cslot_ptr,'z::state_ext) s_monad\" where\n \"get_irq_slot irq \\<equiv> gets (\\<lambda>st. (interrupt_irq_node st irq, []))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ State Check: Determines if a specified IRQ identifier is currently active by checking its state and ensuring it is not marked as inactive.",
    "input": "",
    "output": "definition\n  is_irq_active :: \"irq \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n \"is_irq_active irq \\<equiv> liftM (\\<lambda>st. st \\<noteq> IRQInactive) $ get_irq_state irq\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Change User Context: Allows the execution of a specified user monad in the context of a given thread, updating the thread's architectural context and ensuring that the changes are reflected in the system state.",
    "input": "",
    "output": "text \\<open>\n  Changes user context of specified thread by running\n  specified user monad.\n\\<close>\ndefinition\n  as_user :: \"obj_ref \\<Rightarrow> 'a user_monad \\<Rightarrow> ('a,'z::state_ext) s_monad\"\nwhere\n  \"as_user tptr f \\<equiv> do\n    tcb \\<leftarrow> gets_the $ get_tcb tptr;\n    uc \\<leftarrow> return $ arch_tcb_context_get (tcb_arch tcb);\n    (a, uc') \\<leftarrow> select_f $ f uc;\n    new_tcb \\<leftarrow> return $ tcb \\<lparr> tcb_arch := arch_tcb_context_set uc' (tcb_arch tcb)\\<rparr>;\n    set_object tptr (TCB new_tcb);\n    return a\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Raise Exception on Condition Failure: Throws an exception if a given condition does not hold, ensuring that the system maintains its integrity and handles errors appropriately.",
    "input": "",
    "output": "definition\nthrow_on_false :: \"'e \\<Rightarrow> (bool,'z::state_ext) s_monad \\<Rightarrow> ('e + unit,'z::state_ext) s_monad\" where\n\"throw_on_false ex f \\<equiv> doE v \\<leftarrow> liftE f; unlessE v $ throwError ex odE\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling: The system distinguishes between faults and errors, where faults are reported to the user's fault handler and errors are reported directly to the user. Capability lookup failures can be classified as either a fault or an error based on the context, ensuring that the appropriate response is triggered for different types of issues.",
    "input": "",
    "output": "datatype lookup_failure\n     = InvalidRoot\n     | MissingCapability nat\n     | DepthMismatch nat nat\n     | GuardMismatch nat \"bool list\"\n\ndatatype fault\n         = CapFault obj_ref bool lookup_failure\n         | UnknownSyscallException data\n         | UserException data data\n         | ArchFault arch_fault\n\ndatatype syscall_error\n         = InvalidArgument nat\n         | InvalidCapability nat\n         | IllegalOperation\n         | RangeError data data\n         | AlignmentError\n         | FailedLookup bool lookup_failure\n         | TruncatedMessage\n         | DeleteFirst\n         | RevokeFirst\n         | NotEnoughMemory data",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Error Messaging: Generate a message from a system call error, encoding the type of error and any associated data into a structured format. This allows for clear and consistent communication of failure conditions back to the thread attempting the operation.",
    "input": "",
    "output": "primrec\n  msg_from_lookup_failure :: \"lookup_failure \\<Rightarrow> data list\"\nwhere\n  \"msg_from_lookup_failure InvalidRoot           = [1]\"\n| \"msg_from_lookup_failure (MissingCapability n) = [2, of_nat n]\"\n| \"msg_from_lookup_failure (DepthMismatch n m)   = [3, of_nat n, of_nat m]\"\n| \"msg_from_lookup_failure (GuardMismatch n g)   = [4, of_nat n, of_bl g, of_nat (size g)]\"\n\nprimrec\n  msg_from_syscall_error :: \"syscall_error \\<Rightarrow> (data \\<times> data list)\"\nwhere\n  \"msg_from_syscall_error (InvalidArgument n)    = (1, [of_nat n])\"\n| \"msg_from_syscall_error (InvalidCapability n)  = (2, [of_nat n])\"\n| \"msg_from_syscall_error IllegalOperation       = (3, [])\"\n| \"msg_from_syscall_error (RangeError minv maxv) = (4, [minv, maxv])\"\n| \"msg_from_syscall_error AlignmentError         = (5, [])\"\n| \"msg_from_syscall_error (FailedLookup s lf)    = (6, [if s then 1 else 0]@(msg_from_lookup_failure lf))\"\n| \"msg_from_syscall_error TruncatedMessage       = (7, [])\"\n| \"msg_from_syscall_error DeleteFirst            = (8, [])\"\n| \"msg_from_syscall_error RevokeFirst            = (9, [])\"\n| \"msg_from_syscall_error (NotEnoughMemory n)    = (10, [n])\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "State Transformation: Transforms a state of type `'a state` to a state of type `'b state` by applying a function `t` to the `exst` field, while preserving all other fields of the state.",
    "input": "",
    "output": "definition trans_state :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> 'a state \\<Rightarrow> 'b state\" where\n\"trans_state t s = \\<lparr>kheap = kheap s, cdt = cdt s, is_original_cap = is_original_cap s,\n                     cur_thread = cur_thread s, idle_thread = idle_thread s,\n                     machine_state = machine_state s,\n                     interrupt_irq_node = interrupt_irq_node s,\n                     interrupt_states = interrupt_states s, arch_state = arch_state s,\n                     exst = t(exst s)\\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "State Transformation: The `trans_state` function updates the extended state (`exst`) of the system while preserving other state components such as `kheap`, `cdt`, `is_original_cap`, `cur_thread`, `idle_thread`, `machine_state`, `interrupt_irq_node`, `interrupt_states`, and `arch_state`. This ensures that the transformation is isolated to the extended state, maintaining the integrity of the rest of the system's state.",
    "input": "",
    "output": "lemma trans_state[simp]: \"kheap (trans_state t s) = kheap s\"\n                            \"cdt (trans_state t s) = cdt s\"\n                            \"is_original_cap (trans_state t s) = is_original_cap s\"\n                            \"cur_thread (trans_state t s) = cur_thread s\"\n                            \"idle_thread (trans_state t s) = idle_thread s\"\n                            \"machine_state (trans_state t s) = machine_state s\"\n                            \"interrupt_irq_node (trans_state t s) = interrupt_irq_node s\"\n                           \"interrupt_states (trans_state t s) = interrupt_states s\"\n                            \"arch_state (trans_state t s) = arch_state s\"\n                            \"exst (trans_state t s) = (t (exst s))\"\n                            \"exst (trans_state (\\<lambda>_. e) s) = e\"\n  apply (simp add: trans_state_def)+\n  done\n\nlemma trans_state_update[simp]:\n \"trans_state t (kheap_update f s) = kheap_update f (trans_state t s)\"\n \"trans_state t (cdt_update g s) = cdt_update g (trans_state t s)\"\n \"trans_state t (is_original_cap_update h s) = is_original_cap_update h (trans_state t s)\"\n \"trans_state t (cur_thread_update i s) = cur_thread_update i (trans_state t s)\"\n \"trans_state t (idle_thread_update j s) = idle_thread_update j (trans_state t s)\"\n \"trans_state t (machine_state_update k s) = machine_state_update k (trans_state t s)\"\n \"trans_state t (interrupt_irq_node_update l s) = interrupt_irq_node_update l (trans_state t s)\"\n \"trans_state t (arch_state_update m s) = arch_state_update m (trans_state t s)\"\n \"trans_state t (interrupt_states_update p s) = interrupt_states_update p (trans_state t s)\"\n  apply (simp add: trans_state_def)+\n  done\n\n\nlemma trans_state_update':\n  \"trans_state f = exst_update f\"\n  apply (rule ext)\n  apply simp\n  done\n\nlemma trans_state_update''[simp]:\n  \"trans_state t' (trans_state t s) = trans_state (\\<lambda>e. t' (t e)) s\"\n  apply simp\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Truncate State: Remove all extended state information, effectively discarding the additional data and retaining only the base state.",
    "input": "",
    "output": "abbreviation \"truncate_state \\<equiv> trans_state (\\<lambda>_. ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Deterministic Abstract Specification: Tracks the state of the scheduler and maintains ordering information about sibling nodes in the CDT, ensuring predictable and consistent behavior.",
    "input": "",
    "output": "text \\<open>\\label{s:det-spec}\n  The deterministic abstract specification tracks the state of the scheduler\nand ordering information about sibling nodes in the CDT.\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Scheduler Actions: Define the possible actions that the scheduler can take, including resuming the current thread, switching to a specified thread, or choosing a new thread. These actions are part of the scheduling state and determine the next thread to be executed.",
    "input": "",
    "output": "datatype scheduler_action =\n    resume_cur_thread\n  | switch_thread (sch_act_target : obj_ref)\n  | choose_new_thread\n\ntype_synonym domain = word8\n\nrecord etcb =\n tcb_priority :: \"priority\"\n tcb_time_slice :: \"nat\"\n tcb_domain :: \"domain\"\n\ndefinition default_priority :: \"priority\" where\n  \"default_priority \\<equiv> minBound\"\n\ndefinition default_domain :: \"domain\" where\n  \"default_domain \\<equiv> minBound\"\n\ndefinition default_etcb :: \"etcb\" where\n  \"default_etcb \\<equiv> \\<lparr>tcb_priority = default_priority, tcb_time_slice = timeSlice, tcb_domain = default_domain\\<rparr>\"\n\ntype_synonym ready_queue = \"obj_ref list\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ordered Child List in CDT: Each entry in the CDT maintains an ordered list of its children, encoding the order of sibling nodes.",
    "input": "",
    "output": "type_synonym cdt_list = \"cslot_ptr \\<Rightarrow> cslot_ptr list\"\n\ndefinition work_units_limit :: \"machine_word\" where\n  \"work_units_limit = 0x64\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Extended State Management: Maintains a detailed state including work units completed, scheduler actions, extended kernel heap, domain lists, current domain, domain time, and ready queues. This comprehensive state tracking supports the deterministic behavior and scheduling of the system.",
    "input": "",
    "output": "record det_ext =\n   work_units_completed_internal :: \"machine_word\"\n   scheduler_action_internal :: scheduler_action\n   ekheap_internal :: \"obj_ref \\<Rightarrow> etcb option\"\n   domain_list_internal :: \"(domain \\<times> machine_word) list\"\n   domain_index_internal :: nat\n   cur_domain_internal :: domain\n   domain_time_internal :: \"machine_word\"\n   ready_queues_internal :: \"domain \\<Rightarrow> priority \\<Rightarrow> ready_queue\"\n   cdt_list_internal :: cdt_list",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Abstract State Extension: The state of the nondeterministic abstract specification includes an extension with the `det_ext` record, enriching the abstract state to support deterministic behavior.",
    "input": "",
    "output": "type_synonym det_state = \"det_ext state\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "State Access and Update: Provides accessor and update functions for various components of the deterministic abstract state, including work units completed, scheduler actions, extended kernel heap, domain lists, domain indices, current domain, domain time, ready queues, and CDT lists. These functions enable the manipulation and retrieval of state information in a consistent and controlled manner.",
    "input": "",
    "output": "abbreviation\n  \"work_units_completed (s::det_state) \\<equiv> work_units_completed_internal (exst s)\"\n\nabbreviation\n  \"work_units_completed_update f (s::det_state) \\<equiv>  trans_state (work_units_completed_internal_update f) s\"\n\nabbreviation\n  \"scheduler_action (s::det_state) \\<equiv> scheduler_action_internal (exst s)\"\n\nabbreviation\n  \"scheduler_action_update f (s::det_state) \\<equiv>  trans_state (scheduler_action_internal_update f) s\"\n\nabbreviation\n  \"ekheap (s::det_state) \\<equiv> ekheap_internal (exst s)\"\n\nabbreviation\n  \"ekheap_update f (s::det_state) \\<equiv> trans_state (ekheap_internal_update f) s\"\n\nabbreviation\n  \"domain_list (s::det_state) \\<equiv> domain_list_internal (exst s)\"\n\nabbreviation\n  \"domain_list_update f (s::det_state) \\<equiv> trans_state (domain_list_internal_update f) s\"\n\nabbreviation\n  \"domain_index (s::det_state) \\<equiv> domain_index_internal (exst s)\"\n\nabbreviation\n  \"domain_index_update f (s::det_state) \\<equiv> trans_state (domain_index_internal_update f) s\"\n\nabbreviation\n  \"cur_domain (s::det_state) \\<equiv> cur_domain_internal (exst s)\"\n\nabbreviation\n  \"cur_domain_update f (s::det_state) \\<equiv> trans_state (cur_domain_internal_update f) s\"\n\nabbreviation\n  \"domain_time (s::det_state) \\<equiv> domain_time_internal (exst s)\"\n\nabbreviation\n  \"domain_time_update f (s::det_state) \\<equiv> trans_state (domain_time_internal_update f) s\"\n\nabbreviation\n  \"ready_queues (s::det_state) \\<equiv> ready_queues_internal (exst s)\"\n\nabbreviation\n  \"ready_queues_update f (s::det_state) \\<equiv> trans_state (ready_queues_internal_update f) s\"\n\nabbreviation\n  \"cdt_list (s::det_state) \\<equiv> cdt_list_internal (exst s)\"\n\nabbreviation\n  \"cdt_list_update f (s::det_state) \\<equiv> trans_state (cdt_list_internal_update f) s\"\n\ntype_synonym 'a det_ext_monad = \"(det_state,'a) nondet_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve ETCB Information: Obtain and return a specific attribute of an extended thread control block (ETCB) by applying a given function to the ETCB.",
    "input": "",
    "output": "definition\n  get_etcb :: \"obj_ref \\<Rightarrow> det_state \\<Rightarrow> etcb option\"\nwhere\n  \"get_etcb tcb_ref es \\<equiv> ekheap es tcb_ref\"\n\ndefinition\n  ethread_get :: \"(etcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> 'a det_ext_monad\"\nwhere\n  \"ethread_get f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_etcb tptr;\n     return $ f tcb\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Scheduling and Thread Management: The system provides mechanisms for managing thread priorities, domains, and scheduling actions, including enqueuing, dequeuing, and appending threads to ready queues. It also includes functions to set and get the current domain, decrement the domain time, and manage the control dependency tree (CDT) list. These operations ensure that threads are scheduled and managed correctly, while also allowing for nondeterministic updates to the CDT list.",
    "input": "",
    "output": "definition\n  ethread_get_when :: \"bool \\<Rightarrow> (etcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> 'a det_ext_monad\"\nwhere\n  \"ethread_get_when b f tptr \\<equiv> if b then (ethread_get f tptr) else return undefined\"\n\ndefinition set_eobject :: \"obj_ref \\<Rightarrow> etcb \\<Rightarrow> unit det_ext_monad\"\n  where\n \"set_eobject ptr obj \\<equiv>\n  do es \\<leftarrow> get;\n    ekh \\<leftarrow> return $ (ekheap es)(ptr \\<mapsto> obj);\n    put (es\\<lparr>ekheap := ekh\\<rparr>)\n  od\"\n\ndefinition\n  ethread_set :: \"(etcb \\<Rightarrow> etcb) \\<Rightarrow> obj_ref \\<Rightarrow> unit det_ext_monad\"\nwhere\n  \"ethread_set f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_etcb tptr;\n     set_eobject tptr $ f tcb\n   od\"\n\ndefinition\n  set_scheduler_action :: \"scheduler_action \\<Rightarrow> unit det_ext_monad\" where\n  \"set_scheduler_action action \\<equiv>\n     modify (\\<lambda>es. es\\<lparr>scheduler_action := action\\<rparr>)\"\n\ndefinition\n  thread_set_priority :: \"obj_ref \\<Rightarrow> priority \\<Rightarrow> unit det_ext_monad\" where\n  \"thread_set_priority tptr prio \\<equiv> ethread_set (\\<lambda>tcb. tcb\\<lparr>tcb_priority := prio\\<rparr>) tptr\"\n\ndefinition\n  thread_set_time_slice :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> unit det_ext_monad\" where\n  \"thread_set_time_slice tptr time \\<equiv> ethread_set (\\<lambda>tcb. tcb\\<lparr>tcb_time_slice := time\\<rparr>) tptr\"\n\ndefinition\n  thread_set_domain :: \"obj_ref \\<Rightarrow> domain \\<Rightarrow> unit det_ext_monad\" where\n  \"thread_set_domain tptr domain \\<equiv> ethread_set (\\<lambda>tcb. tcb\\<lparr>tcb_domain := domain\\<rparr>) tptr\"\n\n\ndefinition\n  get_tcb_queue :: \"domain \\<Rightarrow> priority \\<Rightarrow> ready_queue det_ext_monad\" where\n  \"get_tcb_queue d prio \\<equiv> do\n     queues \\<leftarrow> gets ready_queues;\n     return (queues d prio)\n   od\"\n\ndefinition\n  set_tcb_queue :: \"domain \\<Rightarrow> priority \\<Rightarrow> ready_queue \\<Rightarrow> unit det_ext_monad\" where\n  \"set_tcb_queue d prio queue \\<equiv>\n     modify (\\<lambda>es. es\\<lparr> ready_queues :=\n      (\\<lambda>d' p. if d' = d \\<and> p = prio then queue else ready_queues es d' p)\\<rparr>)\"\n\n\ndefinition\n  tcb_sched_action :: \"(obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref list) \\<Rightarrow> obj_ref  \\<Rightarrow> unit det_ext_monad\" where\n  \"tcb_sched_action action thread \\<equiv> do\n     d \\<leftarrow> ethread_get tcb_domain thread;\n     prio \\<leftarrow> ethread_get tcb_priority thread;\n     queue \\<leftarrow> get_tcb_queue d prio;\n     set_tcb_queue d prio (action thread queue)\n   od\"\n\ndefinition\n  tcb_sched_enqueue :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref list\" where\n  \"tcb_sched_enqueue thread queue \\<equiv> if (thread \\<notin> set queue) then thread # queue else queue\"\n\ndefinition\n  tcb_sched_append :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref list\" where\n  \"tcb_sched_append thread queue \\<equiv> if (thread \\<notin> set queue) then queue @ [thread] else queue\"\n\ndefinition\n  tcb_sched_dequeue :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref list\" where\n  \"tcb_sched_dequeue thread queue \\<equiv> filter (\\<lambda>x. x \\<noteq> thread) queue\"\n\n\ndefinition reschedule_required :: \"unit det_ext_monad\" where\n  \"reschedule_required \\<equiv> do\n     action \\<leftarrow> gets scheduler_action;\n     case action of switch_thread t \\<Rightarrow> tcb_sched_action (tcb_sched_enqueue) t | _ \\<Rightarrow> return ();\n     set_scheduler_action choose_new_thread\n   od\"\n\ndefinition\n  possible_switch_to :: \"obj_ref \\<Rightarrow> unit det_ext_monad\" where\n  \"possible_switch_to target \\<equiv> do\n     cur_dom \\<leftarrow> gets cur_domain;\n     target_dom \\<leftarrow> ethread_get tcb_domain target;\n     action \\<leftarrow> gets scheduler_action;\n\n     if (target_dom \\<noteq> cur_dom) then\n       tcb_sched_action tcb_sched_enqueue target\n     else if (action \\<noteq> resume_cur_thread) then\n       do\n         reschedule_required;\n         tcb_sched_action tcb_sched_enqueue target\n       od\n     else\n       set_scheduler_action $ switch_thread target\n   od\"\n\ndefinition\n  next_domain :: \"unit det_ext_monad\" where\n  \"next_domain \\<equiv>\n    modify (\\<lambda>s.\n      let domain_index' = (domain_index s + 1) mod length (domain_list s) in\n      let next_dom = (domain_list s)!domain_index'\n      in s\\<lparr> domain_index := domain_index',\n            cur_domain := fst next_dom,\n            domain_time := snd next_dom,\n            work_units_completed := 0\\<rparr>)\"\n\ndefinition\n  dec_domain_time :: \"unit det_ext_monad\" where\n  \"dec_domain_time = modify (\\<lambda>s. s\\<lparr>domain_time := domain_time s - 1\\<rparr>)\"\n\ndefinition set_cdt_list :: \"cdt_list \\<Rightarrow> (det_state, unit) nondet_monad\" where\n  \"set_cdt_list t \\<equiv> do\n    s \\<leftarrow> get;\n    put $ s\\<lparr> cdt_list := t \\<rparr>\n  od\"\n\ndefinition\n  update_cdt_list :: \"(cdt_list \\<Rightarrow> cdt_list) \\<Rightarrow> (det_state, unit) nondet_monad\"\nwhere\n  \"update_cdt_list f \\<equiv> do\n     t \\<leftarrow> gets cdt_list;\n     set_cdt_list (f t)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Traversal of CDT Structure: Traverse the Capability Delegation Table (CDT) to find the next child, sibling, or non-child slot in prefix traversal order. This ensures that the structure can be navigated systematically, allowing for efficient and ordered access to the slots.",
    "input": "",
    "output": "definition next_child :: \"cslot_ptr \\<Rightarrow> cdt_list \\<Rightarrow> cslot_ptr option\" where\n  \"next_child slot t \\<equiv> case (t slot) of [] \\<Rightarrow> None |\n                                        x # xs \\<Rightarrow> Some x\"\n\ndefinition next_sib :: \"cslot_ptr \\<Rightarrow> cdt_list \\<Rightarrow> cdt \\<Rightarrow> cslot_ptr option\" where\n  \"next_sib slot t m \\<equiv> case m slot of None \\<Rightarrow> None |\n                       Some p \\<Rightarrow> after_in_list (t p) slot\"\n\n\nfunction (domintros) next_not_child :: \"cslot_ptr \\<Rightarrow> cdt_list \\<Rightarrow> cdt \\<Rightarrow> cslot_ptr option\" where\n  \"next_not_child slot t m = (if next_sib slot t m = None\n                             then (case m slot of\n                               None \\<Rightarrow> None |\n                               Some p \\<Rightarrow> next_not_child p t m)\n                             else next_sib slot t m)\"\n  by auto",
    "system": "",
    "history": []
  },
  {
    "instruction": "Traversal of CDT Slots: The function `next_slot` traverses the capability domain tree (CDT) to find the next slot. It first checks if the current slot has children; if so, it traverses to the first child using `next_child`. If the current slot has no children, it moves up the tree to find a sibling or an ancestor with a new node to visit using `next_not_child`.",
    "input": "",
    "output": "definition next_slot :: \"cslot_ptr \\<Rightarrow> cdt_list \\<Rightarrow> cdt \\<Rightarrow> cslot_ptr option\" where\n  \"next_slot slot t m \\<equiv> if t slot \\<noteq> []\n                        then next_child slot t\n                        else next_not_child slot t m\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Extended Operations for Deterministic Abstract Specification: Manage and manipulate various system components, including ready queues, capabilities, and ASID pools. These operations include selecting the highest priority non-empty queue, re-typing memory regions, swapping and moving capabilities, inserting and creating capabilities, emptying slots, revoking capabilities, selecting free ASIDs, and updating and resetting work units. These operations ensure the system's state is correctly maintained and updated, supporting efficient and secure resource management.",
    "input": "",
    "output": "definition max_non_empty_queue :: \"(priority \\<Rightarrow> ready_queue) \\<Rightarrow> ready_queue\" where\n  \"max_non_empty_queue queues \\<equiv> queues (Max {prio. queues prio \\<noteq> []})\"\n\n\ndefinition default_ext :: \"apiobject_type \\<Rightarrow> domain \\<Rightarrow> etcb option\" where\n  \"default_ext type cdom \\<equiv>\n      case type of TCBObject \\<Rightarrow> Some (default_etcb\\<lparr>tcb_domain := cdom\\<rparr>)\n                         | _ \\<Rightarrow> None\"\n\ndefinition retype_region_ext :: \"obj_ref list \\<Rightarrow> apiobject_type \\<Rightarrow> unit det_ext_monad\" where\n  \"retype_region_ext ptrs type \\<equiv>  do\n                                     ekh \\<leftarrow> gets ekheap;\n                                     cdom \\<leftarrow> gets cur_domain;\n                                     ekh' \\<leftarrow> return $ foldr (\\<lambda>p ekh. (ekh(p := default_ext type cdom))) ptrs ekh;\n                                     modify (\\<lambda>s. s\\<lparr>ekheap := ekh'\\<rparr>)\n                                  od\"\n\ndefinition cap_swap_ext where\n\"cap_swap_ext \\<equiv> (\\<lambda> slot1 slot2 slot1_op slot2_op.\n      do\n       update_cdt_list (\\<lambda>list. list(slot1 := list slot2, slot2 := list slot1));\n       update_cdt_list\n        (\\<lambda>list. case if slot2_op = Some slot1 then Some slot2\n                     else if slot2_op = Some slot2 then Some slot1 else slot2_op of\n                None \\<Rightarrow> (case if slot1_op = Some slot1 then Some slot2\n                            else if slot1_op = Some slot2 then Some slot1 else slot1_op of\n                       None \\<Rightarrow> list\n                       | Some slot2_p \\<Rightarrow> list(slot2_p := list_replace (list slot2_p) slot1 slot2))\n                | Some slot1_p \\<Rightarrow>\n                    (case if slot1_op = Some slot1 then Some slot2\n                         else if slot1_op = Some slot2 then Some slot1 else slot1_op of\n                    None \\<Rightarrow> list(slot1_p := list_replace (list slot1_p) slot2 slot1)\n                    | Some slot2_p \\<Rightarrow>\n                        if slot1_p = slot2_p\n                        then list(slot1_p := list_swap (list slot1_p) slot1 slot2)\n                        else list(slot1_p := list_replace (list slot1_p) slot2 slot1,\n                                  slot2_p := list_replace (list slot2_p) slot1 slot2)))\n    od)\"\n\ndefinition cap_move_ext where\n\"cap_move_ext \\<equiv> (\\<lambda> src_slot dest_slot src_p dest_p.\n do\n\n    update_cdt_list (\\<lambda>list. case (dest_p) of\n      None \\<Rightarrow> list |\n      Some p \\<Rightarrow> list (p := list_remove (list p) dest_slot));\n\n   if (src_slot = dest_slot) then return () else\n\n    (do\n    update_cdt_list (\\<lambda>list. case (src_p) of\n      None \\<Rightarrow> list |\n      Some p \\<Rightarrow> list (p := list_replace (list p) src_slot dest_slot));\n\n    update_cdt_list (\\<lambda>list. list (src_slot := [], dest_slot := (list src_slot) @ (list dest_slot)))\n    od)\n\n  od)\"\n\n\ndefinition cap_insert_ext where\n\"cap_insert_ext \\<equiv> (\\<lambda> src_parent src_slot dest_slot src_p dest_p.\n do\n\n update_cdt_list (\\<lambda>list. case (dest_p) of\n      None \\<Rightarrow> list |\n      Some p \\<Rightarrow> (list (p := list_remove (list p) dest_slot)));\n\n    update_cdt_list (\\<lambda>list. case (src_p) of\n      None \\<Rightarrow> list (\n        src_slot := if src_parent then [dest_slot] @ (list src_slot) else list src_slot) |\n      Some p \\<Rightarrow> list (\n        src_slot := if src_parent then [dest_slot] @ (list src_slot) else list src_slot,\n        p := if (src_parent \\<and> p \\<noteq> src_slot) then (list p) else if (src_slot \\<noteq> dest_slot) then (list_insert_after (list p) src_slot dest_slot) else (dest_slot # (list p))))\n od)\"\n\ndefinition empty_slot_ext where\n\"empty_slot_ext \\<equiv> (\\<lambda> slot slot_p.\n\n    update_cdt_list (\\<lambda>list. case slot_p of None \\<Rightarrow> list (slot := []) |\n      Some p \\<Rightarrow> if (p = slot) then list(p := list_remove (list p) slot) else list (p := list_replace_list (list p) slot (list slot), slot := [])))\"\n\ndefinition create_cap_ext where\n\"create_cap_ext \\<equiv> (\\<lambda> untyped dest dest_p. do\n\n    update_cdt_list (\\<lambda>list. case dest_p of\n      None \\<Rightarrow> list |\n      Some p \\<Rightarrow> (list (p := list_remove (list p) dest)));\n\n    update_cdt_list (\\<lambda>list. list (untyped := [dest] @ (list untyped)))\n  od)\"\n\ndefinition next_revoke_cap where\n\"next_revoke_cap \\<equiv> (\\<lambda>slot ext. the (next_child slot (cdt_list ext)))\"\n\ndefinition\n  free_asid_select :: \"(asid_high_index \\<rightharpoonup> 'a) \\<Rightarrow> asid_high_index\"\nwhere\n  \"free_asid_select \\<equiv> \\<lambda>asid_table. fst (hd (filter (\\<lambda>(x,y). x \\<le> 2 ^ asid_high_bits - 1 \\<and> y = None) (assocs asid_table)))\"\n\ndefinition\n  free_asid_pool_select :: \"(asid_low_index \\<rightharpoonup> 'a) \\<Rightarrow> asid \\<Rightarrow> asid_low_index\"\nwhere\n  \"free_asid_pool_select \\<equiv> (\\<lambda>pool base.\n     fst (hd ((filter (\\<lambda> (x,y). ucast x + base \\<noteq> 0 \\<and> y = None) (assocs pool)))))\"\n\ndefinition update_work_units where\n  \"update_work_units \\<equiv>\n     modify (\\<lambda>s. s\\<lparr>work_units_completed := work_units_completed s + 1\\<rparr>)\"\n\ndefinition reset_work_units where\n  \"reset_work_units \\<equiv>\n     modify (\\<lambda>s. s\\<lparr>work_units_completed := 0\\<rparr>)\"\n\ndefinition work_units_limit_reached where\n  \"work_units_limit_reached \\<equiv> do\n     work_units \\<leftarrow> gets work_units_completed;\n     return (work_units_limit \\<le> work_units)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Abstract State Extension: Provides a framework for extending the state with deterministic and nondeterministic behaviors. It includes operations to unwrap and wrap the extended state, handle monadic operations, and select switch conditions, enabling flexible and modular state management.",
    "input": "",
    "output": "class state_ext =\n fixes unwrap_ext :: \"'a state \\<Rightarrow> det_ext state\"\n fixes wrap_ext :: \"(det_ext \\<Rightarrow> det_ext) \\<Rightarrow> ('a \\<Rightarrow> 'a)\"\n fixes wrap_ext_op :: \"unit det_ext_monad \\<Rightarrow> ('a state,unit) nondet_monad\"\n fixes wrap_ext_bool :: \"bool det_ext_monad \\<Rightarrow> ('a state,bool) nondet_monad\"\n fixes select_switch :: \"'a \\<Rightarrow> bool\"\n fixes ext_init :: \"'a\"\n\ndefinition detype_ext :: \"obj_ref set \\<Rightarrow> 'z::state_ext \\<Rightarrow> 'z\" where\n \"detype_ext S \\<equiv> wrap_ext (\\<lambda>s. s\\<lparr>ekheap_internal := (\\<lambda>x. if x \\<in> S then None else ekheap_internal s x)\\<rparr>)\"\n\ninstantiation  det_ext_ext :: (type) state_ext\nbegin\n\ndefinition \"unwrap_ext_det_ext_ext == (\\<lambda>x. x) :: det_ext state \\<Rightarrow> det_ext state\"\n\ndefinition \"wrap_ext_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext \\<Rightarrow> det_ext) \\<Rightarrow> det_ext \\<Rightarrow> det_ext\"\n\ndefinition \"wrap_ext_op_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext state \\<Rightarrow> ((unit \\<times> det_ext state) set) \\<times> bool)\n  \\<Rightarrow> det_ext state  \\<Rightarrow> ((unit \\<times> det_ext state) set) \\<times> bool\"\n\ndefinition \"wrap_ext_bool_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext state \\<Rightarrow> ((bool \\<times> det_ext state) set) \\<times> bool)\n  \\<Rightarrow> det_ext state \\<Rightarrow> ((bool \\<times> det_ext state) set) \\<times> bool\"\n\ndefinition \"select_switch_det_ext_ext == (\\<lambda>_. True)  :: det_ext\\<Rightarrow> bool\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Deterministic Extension: The deterministic extension is initialized with default values, including an empty heap with a single idle thread, a domain list, and ready queues. This setup provides a starting point for the system's execution, but it may not satisfy all invariants.",
    "input": "",
    "output": "definition \"ext_init_det_ext_ext \\<equiv>\n     \\<lparr>work_units_completed_internal = 0,\n      scheduler_action_internal = resume_cur_thread,\n      ekheap_internal = Map.empty (idle_thread_ptr \\<mapsto> default_etcb),\n      domain_list_internal = [(0,15)],\n      domain_index_internal = 0,\n      cur_domain_internal = 0,\n      domain_time_internal = 15,\n      ready_queues_internal = const (const []),\n      cdt_list_internal = const []\\<rparr> :: det_ext\"\n\ninstance ..\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Abstract Specification: The specification defines an abstract state with no meaningful extended state, using the unit type. It includes functions to unwrap and wrap the extended state, handle operations, and initialize the state, all of which are defined to have no effect or return a default value, ensuring that the extended state remains trivial and nondeterministic.",
    "input": "",
    "output": "text \\<open>\\label{s:nondet-spec}\nThe nondeterministic abstract specification instantiates the extended state\nwith the unit type -- i.e. it doesn't have any meaningful extended state.\n\\<close>\n\ninstantiation unit :: state_ext\nbegin\n\n\ndefinition \"unwrap_ext_unit == (\\<lambda>_. undefined) :: unit state \\<Rightarrow> det_ext state\"\n\ndefinition \"wrap_ext_unit == (\\<lambda>f s. ()) :: (det_ext \\<Rightarrow> det_ext) \\<Rightarrow> unit \\<Rightarrow> unit\"\n\n\ndefinition \"wrap_ext_op_unit == (\\<lambda>m. return ()) ::\n  (det_ext state \\<Rightarrow> ((unit \\<times> det_ext state) set) \\<times> bool) \\<Rightarrow> unit state \\<Rightarrow> ((unit \\<times> unit state) set) \\<times> bool\"\n\ndefinition \"wrap_ext_bool_unit == (\\<lambda>m. select UNIV) ::\n  (det_ext state \\<Rightarrow> ((bool \\<times> det_ext state ) set) \\<times> bool) \\<Rightarrow> unit state \\<Rightarrow> ((bool \\<times> unit state) set) \\<times> bool\"\n\ndefinition \"select_switch_unit == (\\<lambda>s. False) :: unit \\<Rightarrow> bool\"\n\ndefinition \"ext_init_unit \\<equiv> () :: unit\"\n\ninstance ..\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Choice Based on Extended Operation: Execute an extended operation to obtain a boolean value, which is then used to non-deterministically choose between two computations. The choice is made based on the result of the extended operation, ensuring that the extended state is not modified during the process.",
    "input": "",
    "output": "lemmas ext_init_def = ext_init_det_ext_ext_def ext_init_unit_def\n\ndefinition OR_choice :: \"bool det_ext_monad \\<Rightarrow> ('z::state_ext state,'a) nondet_monad \\<Rightarrow> ('z state,'a) nondet_monad \\<Rightarrow> ('z state,'a) nondet_monad\" where\n\"OR_choice c f g \\<equiv>\n  do\n    ex \\<leftarrow> get;\n    (rv,_) \\<leftarrow> select_f (mk_ef ((wrap_ext_bool c) ex));\n    if rv then f else g\n  od\"\n\ndefinition OR_choiceE :: \"bool det_ext_monad \\<Rightarrow> ('z::state_ext state,'e + 'a) nondet_monad \\<Rightarrow> ('z state,'e + 'a) nondet_monad \\<Rightarrow> ('z state,'e + 'a) nondet_monad\" where\n\"OR_choiceE c f g \\<equiv>\n  doE\n    ex \\<leftarrow> liftE get;\n    (rv,_) \\<leftarrow> liftE $ select_f (mk_ef ((wrap_ext_bool c) ex));\n    if rv then f else g\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Execute Extended Operation: Perform an extended operation on the extended state, updating it based on the result of the operation while ignoring any return value.",
    "input": "",
    "output": "definition do_extended_op :: \"unit det_ext_monad \\<Rightarrow> ('z::state_ext state,unit) nondet_monad\" where\n \"do_extended_op eop \\<equiv> do\n                         ex \\<leftarrow> get;\n                         (_,es') \\<leftarrow> select_f (mk_ef ((wrap_ext_op eop) ex));\n                         modify (\\<lambda> state. state\\<lparr>exst := (exst es')\\<rparr>)\n                        od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Selection: Select a value from a given set, using the extended state to determine the selection method. If the select switch in the extended state is true, the value is determined by a function of the extended state; otherwise, it is chosen nondeterministically from the set. The selected value is then asserted to be a member of the set.",
    "input": "",
    "output": "definition select_ext :: \"(det_ext state \\<Rightarrow> 'd) \\<Rightarrow> ('d set) \\<Rightarrow> ('a::state_ext state,'d) nondet_monad\" where\n  \"select_ext a S \\<equiv> do\n                      s \\<leftarrow> get;\n                      x \\<leftarrow> if (select_switch (exst s)) then (return (a (unwrap_ext s)))\n                          else (select S);\n                      assert (x \\<in> S);\n                      return x\n                    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Valid CDT List: Ensures that for each pointer, the list of capabilities associated with it in the CDT list is exactly the set of capabilities that map to that pointer in the CDT, and all such lists are distinct.",
    "input": "",
    "output": "definition valid_list_2 :: \"cdt_list \\<Rightarrow> cdt \\<Rightarrow> bool\" where\n  \"valid_list_2 t m \\<equiv> (\\<forall>p. set (t p) = {c. m c = Some p}) \\<and> (\\<forall>p. distinct (t p))\"\n\nabbreviation valid_list :: \"det_ext state \\<Rightarrow> bool\" where\n  \"valid_list s \\<equiv> valid_list_2 (cdt_list s) (cdt s)\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Default Capability Creation: Generates a default capability for a given object type, address, and size. The capability is specific to the object type, ensuring that the newly created object has the appropriate initial permissions and properties.",
    "input": "",
    "output": "text \\<open>The original capability created when an object of a given type is\ncreated with a particular address and size.\\<close>\nprimrec\n  default_cap :: \"apiobject_type  \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> cap\"\nwhere\n  \"default_cap CapTableObject oref s _ = CNodeCap oref s []\"\n| \"default_cap Untyped oref s dev = UntypedCap dev oref s 0\"\n| \"default_cap TCBObject oref s _ = ThreadCap oref\"\n| \"default_cap EndpointObject oref s _ = EndpointCap oref 0 UNIV\"\n| \"default_cap NotificationObject oref s _ =\n     NotificationCap oref 0 {AllowRead, AllowWrite}\"\n| \"default_cap (ArchObject aobj) oref s dev = ArchObjectCap (arch_default_cap aobj oref s dev)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create and Install Capability: Create a new capability for a specified object type, size, and device status, and install it into the destination slot. This ensures that the newly created object is properly initialized and accessible through the installed capability.",
    "input": "",
    "output": "definition\n  create_cap ::\n  \"apiobject_type \\<Rightarrow> nat \\<Rightarrow> cslot_ptr \\<Rightarrow> bool \\<Rightarrow> cslot_ptr \\<times> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"create_cap type bits untyped is_device \\<equiv> \\<lambda>(dest,oref). do\n    dest_p \\<leftarrow> gets (\\<lambda>s. cdt s dest);\n    cdt \\<leftarrow> gets cdt;\n    set_cdt (cdt (dest \\<mapsto> untyped));\n    do_extended_op (create_cap_ext untyped dest dest_p);\n    set_original dest True;\n    set_cap (default_cap type oref bits is_device) dest\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Empty CNode Object: An empty CNode object is defined such that it contains `NullCap` for all slots up to the specified number of bits, and `None` for any slot beyond that. This ensures that the CNode is initialized with a known, default state, facilitating safe and predictable behavior in the system.",
    "input": "",
    "output": "text \\<open>Properties of an empty CNode object.\\<close>\ndefinition\n  empty_cnode :: \"nat \\<Rightarrow> cnode_contents\" where\n  \"empty_cnode bits \\<equiv> \\<lambda>x. if length x = bits then Some NullCap else None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Default Object Initialization: Define the initial state of various types of kernel objects when they are created, ensuring that each object is instantiated with a default configuration appropriate to its type.",
    "input": "",
    "output": "definition\n  default_object :: \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> kernel_object\" where\n  \"default_object api dev n \\<equiv> case api of\n           Untyped \\<Rightarrow> undefined\n         | CapTableObject \\<Rightarrow> CNode n (empty_cnode n)\n         | TCBObject \\<Rightarrow> TCB default_tcb\n         | EndpointObject \\<Rightarrow> Endpoint default_ep\n         | NotificationObject \\<Rightarrow> Notification default_notification\n         | ArchObject aobj \\<Rightarrow> ArchObj (default_arch_object aobj dev n)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Object Size Determination: Calculate the size in bits of an object based on its type and requested size, ensuring that the object is appropriately sized for its intended use.",
    "input": "",
    "output": "definition\n  obj_bits_api :: \"apiobject_type \\<Rightarrow> nat \\<Rightarrow> nat\" where\n  \"obj_bits_api type obj_size_bits \\<equiv> case type of\n           Untyped \\<Rightarrow> obj_size_bits\n         | CapTableObject \\<Rightarrow> obj_size_bits + slot_bits\n         | TCBObject \\<Rightarrow> obj_bits (TCB default_tcb)\n         | EndpointObject \\<Rightarrow> obj_bits (Endpoint undefined)\n         | NotificationObject \\<Rightarrow> obj_bits (Notification undefined)\n         | ArchObject aobj \\<Rightarrow> obj_bits $ ArchObj $ default_arch_object aobj False obj_size_bits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retype Region: Create a specified number of objects of a given type and size, starting from a base object reference. The function updates the kernel heap with the new objects and returns a list of pointers to the created objects. If the type is not untyped, it initializes each object with default settings and performs an extended operation for retype.",
    "input": "",
    "output": "text \\<open>\nCreate @{text \"numObjects\"} objects, starting from\n@{text obj_ref}, return of list pointers to them. For some types, each\nreturned pointer points to a group of objects.\n\\<close>\n\ndefinition\n  retype_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> apiobject_type \\<Rightarrow> bool \\<Rightarrow> (obj_ref list,'z::state_ext) s_monad\"\nwhere\n  \"retype_region ptr numObjects o_bits type dev \\<equiv> do\n    obj_size \\<leftarrow> return $ 2 ^ obj_bits_api type o_bits;\n    ptrs \\<leftarrow> return $ map (\\<lambda>p. ptr_add ptr (p * obj_size)) [0..< numObjects];\n    when (type \\<noteq> Untyped) (do\n      kh \\<leftarrow> gets kheap;\n      kh' \\<leftarrow> return $ foldr (\\<lambda>p kh. kh(p \\<mapsto> default_object type dev o_bits)) ptrs kh;\n      do_extended_op (retype_region_ext ptrs type);\n      modify $ kheap_update (K kh')\n    od);\n    return $ ptrs\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Untyped Capability Invocation: Allows the invocation of untyped capabilities, enabling the reconfiguration and management of memory regions by updating the system's extended state.",
    "input": "",
    "output": "abbreviation (input) \"extended_state_update \\<equiv> trans_state\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Remove Objects from Heap: The detype operation removes a specified set of objects from the heap, effectively deallocating them and updating the extended state accordingly.",
    "input": "",
    "output": "definition\n  detype :: \"(obj_ref set) \\<Rightarrow> 'z::state_ext state \\<Rightarrow> 'z::state_ext state\" where\n \"detype S s \\<equiv> s \\<lparr> kheap := (\\<lambda>x. if x \\<in> S then None else kheap s x), extended_state := detype_ext S (exst s)\\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Delete Objects: Free and de-allocate memory within a specified region, ensuring that the memory is no longer accessible or usable.",
    "input": "",
    "output": "definition\n  delete_objects :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"delete_objects ptr bits = do\n     do_machine_op (freeMemory ptr bits);\n     modify (detype {ptr..ptr + 2 ^ bits - 1})\n  od\"\n\ndefinition\n  get_free_ref :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> obj_ref\" where\n  \"get_free_ref base free_index \\<equiv> base +  (of_nat free_index)\"\n\ndefinition\n  get_free_index :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> nat\" where\n  \"get_free_index base free \\<equiv> unat $ (free - base)\"\n\nprimrec(nonexhaustive) is_device_untyped_cap\nwhere\n  \"is_device_untyped_cap (UntypedCap isdev _ _ _) = isdev\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reset Untyped Capability: Clear and reset the underlying memory and object level representation of an untyped capability, progressively moving the free region pointer back to the start of the newly cleared region. If the capability is a device or its size is smaller than the reset chunk size, clear the entire memory region at once; otherwise, clear the memory in chunks and update the capability accordingly.",
    "input": "",
    "output": "definition\n  reset_untyped_cap :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"reset_untyped_cap src_slot = doE\n  cap \\<leftarrow> liftE $ get_cap src_slot;\n  sz \\<leftarrow> returnOk $ bits_of cap;\n  base \\<leftarrow> returnOk $ obj_ref_of cap;\n  if free_index_of cap = 0\n    then returnOk ()\n  else doE\n    liftE $ delete_objects base sz;\n  dev \\<leftarrow> returnOk $ is_device_untyped_cap cap;\n\n  if dev \\<or> sz < resetChunkBits\n      then liftE $ do\n        unless dev $ do_machine_op $ clearMemory base (2 ^ sz);\n        set_cap (UntypedCap dev base sz 0) src_slot\n      od\n    else mapME_x (\\<lambda>i. doE\n          liftE $ do_machine_op $ clearMemory (base + (of_nat i << resetChunkBits))\n              (2 ^ resetChunkBits);\n          liftE $ set_cap (UntypedCap dev base sz\n              (i * 2 ^ resetChunkBits)) src_slot;\n          preemption_point\n        odE) (rev [i \\<leftarrow> [0 ..< 2 ^ (sz - resetChunkBits)].\n            i * 2 ^ resetChunkBits < free_index_of cap])\n    odE\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Untyped Capability Retyping: Allows the reconfiguration of a memory region by clearing existing objects, creating new objects of a specified type, initializing them, and installing new capabilities. This process updates the untyped capability to reflect the space used and ensures that the new objects are properly set up and linked with their corresponding capabilities.",
    "input": "",
    "output": "definition\n  invoke_untyped :: \"untyped_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n\"invoke_untyped ui \\<equiv> case ui\n    of Retype src_slot reset base retype_base new_type obj_sz slots is_device \\<Rightarrow>\ndoE\n  whenE reset $ reset_untyped_cap src_slot;\n  liftE $ do\n\n  cap \\<leftarrow> get_cap src_slot;\n\n  \\<comment> \\<open>Update the untyped cap to track the amount of space used.\\<close>\n  total_object_size \\<leftarrow> return $ (of_nat (length slots) << (obj_bits_api new_type obj_sz));\n  free_ref \\<leftarrow> return $ retype_base + total_object_size;\n  set_cap (UntypedCap is_device base (bits_of cap) (unat (free_ref - base))) src_slot;\n\n  \\<comment> \\<open>Create new objects.\\<close>\n  orefs \\<leftarrow> retype_region retype_base (length slots) obj_sz new_type is_device;\n  init_arch_objects new_type is_device retype_base (length slots) obj_sz orefs;\n  sequence_x (map (create_cap new_type obj_sz src_slot is_device) (zip slots orefs))\nod odE\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Basic Kernel Monad: Represents a monadic computation in the kernel that does not handle faults, interrupts, or errors.",
    "input": "",
    "output": "type_synonym ('a,'z) s_monad = \"('z state, 'a) nondet_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Fault Monad: Handles exceptions by potentially throwing a fault, which is typically reported to the current thread's fault handler.",
    "input": "",
    "output": "type_synonym ('a,'z) f_monad = \"(fault + 'a,'z) s_monad\"\n\nterm \"a::(unit,'a) s_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Error Handling in System Calls: The error monad allows for the throwing of a `syscall_error` exception, which is typically reported to the current thread as the result of a system call.",
    "input": "",
    "output": "type_synonym ('a,'z) se_monad = \"(syscall_error + 'a,'z) s_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup Failure Monad: Handles exceptions by potentially throwing a `lookup_failure` exception, which can be reported either directly to the current thread or to its fault handler.",
    "input": "",
    "output": "type_synonym ('a,'z) lf_monad = \"(lookup_failure + 'a,'z) s_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Preemption Monad: Represents a computation that may throw an interrupt exception, allowing for the possibility of preemption during its execution.",
    "input": "",
    "output": "type_synonym ('a,'z) p_monad = \"(unit + 'a,'z) s_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Abbreviations: Define shorthand notations for various monad types to simplify the representation of state transformations, error handling, and system calls. These abbreviations streamline the specification and implementation of system behaviors.",
    "input": "",
    "output": "translations\n  (type) \"'a s_monad\" <= (type) \"state \\<Rightarrow> (('a \\<times> state) \\<Rightarrow> bool) \\<times> bool\"\n  (type) \"'a f_monad\" <= (type) \"(fault + 'a) s_monad\"\n  (type) \"'a se_monad\" <= (type) \"(syscall_error + 'a) s_monad\"\n  (type) \"'a lf_monad\" <= (type) \"(lookup_failure + 'a) s_monad\"\n  (type) \"'a p_monad\" <=(type) \"(unit + 'a) s_monad\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Non-Preemptible Execution: Ensures that operations within preemptible blocks are executed without preemption, maintaining the atomicity and integrity of critical sections.",
    "input": "",
    "output": "definition\n  without_preemption :: \"('a,'z::state_ext) s_monad \\<Rightarrow> ('a,'z::state_ext) p_monad\"\nwhere without_preemption_def[simp]:\n \"without_preemption \\<equiv> liftE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Preemption Point: Allows preemption at a specific point by updating work units and checking if the work units limit has been reached. If the limit is reached, it resets the work units and handles any active interrupt, otherwise, it continues without interruption.",
    "input": "",
    "output": "definition\n  preemption_point :: \"(unit,'z::state_ext) p_monad\" where\n \"preemption_point \\<equiv> doE liftE $ do_extended_op update_work_units;\n                         OR_choiceE (work_units_limit_reached)\n                           (doE liftE $ do_extended_op reset_work_units;\n                                irq_opt \\<leftarrow> liftE $ do_machine_op (getActiveIRQ True);\n                                case_option (returnOk ()) (K (throwError $ ())) irq_opt\n                           odE) (returnOk ())\n                     odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling and Conversion: Convert and handle different types of exceptions or failures by transforming them into various error types or return values, ensuring that the system can gracefully manage and respond to errors.",
    "input": "",
    "output": "definition\n  cap_fault_on_failure :: \"obj_ref \\<Rightarrow> bool \\<Rightarrow> ('a,'z::state_ext) lf_monad \\<Rightarrow> ('a,'z::state_ext) f_monad\" where\n \"cap_fault_on_failure cptr rp m \\<equiv> handleE' m (throwError \\<circ> CapFault cptr rp)\"\n\ndefinition\n  lookup_error_on_failure ::  \"bool \\<Rightarrow> ('a,'z::state_ext) lf_monad \\<Rightarrow> ('a,'z::state_ext) se_monad\" where\n \"lookup_error_on_failure s m \\<equiv> handleE' m (throwError \\<circ> FailedLookup s)\"\n\ndefinition\n  null_cap_on_failure :: \"(cap,'z::state_ext) lf_monad \\<Rightarrow> (cap,'z::state_ext) s_monad\" where\n \"null_cap_on_failure \\<equiv> liftM (case_sum (\\<lambda>x. NullCap) id)\"\n\ndefinition\n  unify_failure :: \"('f + 'a,'z::state_ext) s_monad \\<Rightarrow> (unit + 'a,'z::state_ext) s_monad\" where\n \"unify_failure m \\<equiv> handleE' m (\\<lambda>x. throwError ())\"\n\ndefinition\n  empty_on_failure :: \"('f + 'a list,'z::state_ext) s_monad \\<Rightarrow> ('a list,'z::state_ext) s_monad\" where\n \"empty_on_failure m \\<equiv> m <catch> (\\<lambda>x. return [])\"\n\ndefinition\n  const_on_failure :: \"'a \\<Rightarrow> ('f + 'a,'z::state_ext) s_monad \\<Rightarrow> ('a,'z::state_ext) s_monad\" where\n \"const_on_failure c m \\<equiv> m <catch> (\\<lambda>x. return c)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Range Check: Ensures that a given value is within a specified inclusive range, throwing a `RangeError` if the value is outside the range.",
    "input": "",
    "output": "definition\n  range_check :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"range_check v min_v max_v \\<equiv>\n    unlessE (v \\<ge> min_v \\<and> v \\<le> max_v) $ throwError $ RangeError min_v max_v\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Execution: The system call operation is divided into three phases, each with its own handler for faults and errors. The first phase may result in a fault, the second phase may result in an error, and the third phase may be interrupted. Handlers are provided to manage faults and errors, ensuring that the system call can be executed correctly and safely.",
    "input": "",
    "output": "text\\<open>The @{term syscall} operation generically describes the usual\nexecution of system calls in three phases, where the first phase may\nresult in a fault, the second phase may result in an error and the third\nphase may be interrupted. The first two phases are used for argument decoding\nand checking. The last phase commits and executes the system call.\n\nThe @{term syscall} operation has five arguments:\n\\begin{itemize}\n\\item the first operation @{text m_fault} to execute, that may\nresult in a fault;\n\\item the fault handler @{text h_fault} to execute if the first\noperation resulted in a fault;\n\\item the second operation @{text m_error} to execute (if no fault\noccurred in the first operation); this second operation may result in\nan error;\n\\item the error handler @{text h_error} to execute if the second\noperation resulted in an error;\n\\item the third and last operation @{text m_finalise} to execute (if\nno error occurred in the second operation); this operation may be\ninterrupted.\n\\end{itemize}\n\\<close>\n\ndefinition\n  syscall :: \"('a,'z::state_ext) f_monad\n                  \\<Rightarrow> (fault \\<Rightarrow> ('c,'z::state_ext) s_monad)\n                  \\<Rightarrow> ('a \\<Rightarrow> ('b,'z::state_ext) se_monad)\n                  \\<Rightarrow> (syscall_error \\<Rightarrow> ('c,'z::state_ext) s_monad)\n               \\<Rightarrow> ('b \\<Rightarrow> ('c,'z::state_ext) p_monad) \\<Rightarrow> ('c,'z::state_ext) p_monad\"\nwhere\n\"syscall m_fault h_fault m_error h_error m_finalise \\<equiv> doE\n    r_fault \\<leftarrow> without_preemption $ m_fault;\n    case r_fault of\n          Inl f \\<Rightarrow>   without_preemption $ h_fault f\n        | Inr a \\<Rightarrow>   doE\n            r_error \\<leftarrow> without_preemption $ m_error a;\n            case r_error of\n                  Inl e \\<Rightarrow>   without_preemption $ h_error e\n                | Inr b \\<Rightarrow>   m_finalise b\n        odE\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Operations: The system supports seven types of system calls, categorized into two main families: sending and receiving messages. Sending operations include blocking and non-blocking sends, as well as a call operation that provides a reply capability to the receiver. Receiving operations include receiving messages, replying to calls, and a combined reply-receive operation to optimize user-kernel mode switching. Additionally, a yield operation allows a user to donate its remaining timeslice.",
    "input": "",
    "output": "text\\<open>The kernel user can perform seven kinds of system calls,\ndescribed by the enumerated type @{term syscall}, defined in \\autoref{s:spec_syscall}.\nThese seven system calls can be categorised into two broad\nfamilies: sending messages and receiving messages, the two main\nservices provided by the kernel.\n\nThe usual case for sending messages (@{text Send} event) consists of the user\nsending a message to an object, without expecting any answer. The sender is\nblocked until the receiver is waiting to receive. In case the\nreceiver is not trusted, an explicit non-blocking send operation can\nbe used (@{text NBSend} event). If a reply is requested from the\nreceiver, the Call operation can be used (@{text Call} event). The Call operation\nwill automatically provide a @{text Reply} capability to the receiver.\n\nAll three sending operations are handled by the @{text\nhandle_invocation} operation, which takes two boolean arguments, one\nto indicate if a reply is requested and the other to indicate if the\nsend is blocking or not.\n\nThe other direction is the reception of messages. This is done by\nperforming a Recv operation on an endpoint kernel object. The receiver\nis then blocked until a sender performs a Send operation on the\nendpoint object, resulting in a message transfer between the sender\nand the receiver. The receiver may also perform a Reply operation\n(@{text Reply} event) in response to a @{text Call}, which is always\nnon-blocking. When the receiver is a user-level server, it generally\nruns a loop waiting for messages. On handling a received message, the\nserver will send a reply and then return to waiting. To avoid\nexcessive switching between user and kernel mode, the kernel provides\na ReplyRecv operation, which is simply a Reply followed by Recv.\n\nFinally, the last event, @{text Yield}, enables the user to donate its\nremaining timeslice.\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "System Call Execution: The system call process involves three main phases: capability lookup, argument decoding, and invocation execution. Capability lookup ensures the validity of the invocation, while argument decoding checks for the correctness and sufficiency of the provided arguments. The actual invocation is then performed, which can be preempted, and the system state is updated accordingly.",
    "input": "",
    "output": "fun\n  perform_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\nwhere\n  \"perform_invocation block call (InvokeUntyped i) =\n    doE\n      invoke_untyped i;\n      returnOk []\n    odE\"\n\n| \"perform_invocation block call (InvokeEndpoint ep badge canGrant canGrantReply) =\n    (without_preemption $ do\n       thread \\<leftarrow> gets cur_thread;\n       send_ipc block call badge canGrant canGrantReply thread ep;\n       return []\n     od)\"\n\n| \"perform_invocation block call (InvokeNotification ep badge) =\n    doE\n      without_preemption $ send_signal ep badge;\n      returnOk []\n    odE\"\n\n| \"perform_invocation block call (InvokeTCB i) = invoke_tcb i\"\n\n| \"perform_invocation block call (InvokeDomain tptr d) = invoke_domain tptr d\"\n\n| \"perform_invocation block call (InvokeReply thread slot grant) =\n    liftE (do\n      sender \\<leftarrow> gets cur_thread;\n      do_reply_transfer sender thread slot grant;\n      return []\n    od)\"\n\n| \"perform_invocation block call (InvokeCNode i) =\n    doE\n      invoke_cnode i;\n      returnOk []\n    odE\"\n\n| \"perform_invocation block call (InvokeIRQControl i) =\n   doE\n     invoke_irq_control i;\n     returnOk []\n   odE\"\n\n| \"perform_invocation block call (InvokeIRQHandler i) =\n   doE\n     liftE $ invoke_irq_handler i;\n     returnOk []\n   odE\"\n\n| \"perform_invocation block call (InvokeArchObject i) =\n    arch_perform_invocation i\"\n\n\ndefinition\n  handle_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"handle_invocation calling blocking \\<equiv> doE\n    thread \\<leftarrow> liftE $ gets cur_thread;\n    info \\<leftarrow> without_preemption $ get_message_info thread;\n    ptr \\<leftarrow> without_preemption $ liftM data_to_cptr $\n          as_user thread $ getRegister cap_register;\n    syscall\n      (doE\n         (cap, slot) \\<leftarrow> cap_fault_on_failure (of_bl ptr) False $\n                           lookup_cap_and_slot thread ptr;\n         buffer \\<leftarrow> liftE $ lookup_ipc_buffer False thread;\n         extracaps \\<leftarrow> lookup_extra_caps thread buffer info;\n         returnOk (slot, cap, extracaps, buffer)\n       odE)\n      (\\<lambda>fault. when blocking $ handle_fault thread fault)\n      (\\<lambda>(slot,cap,extracaps,buffer). doE\n            args \\<leftarrow> liftE $ get_mrs thread buffer info;\n            decode_invocation (mi_label info) args ptr slot cap extracaps\n       odE)\n      (\\<lambda>err. when calling $\n            reply_from_kernel thread $ msg_from_syscall_error err)\n      (\\<lambda>oper. doE\n            without_preemption $ set_thread_state thread Restart;\n            reply \\<leftarrow> perform_invocation blocking calling oper;\n            without_preemption $ do\n                state \\<leftarrow> get_thread_state thread;\n                case state of\n                      Restart \\<Rightarrow> do\n                          when calling $\n                              reply_from_kernel thread (0, reply);\n                          set_thread_state thread Running\n                      od\n                    | _ \\<Rightarrow>  return ()\n            od\n       odE)\n  odE\"\n\n\ndefinition\n  handle_yield :: \"(unit,'z::state_ext) s_monad\" where\n  \"handle_yield \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n     do_extended_op (tcb_sched_action (tcb_sched_dequeue) thread);\n     do_extended_op (tcb_sched_action (tcb_sched_append) thread);\n     do_extended_op (reschedule_required)\n   od\"\n\ndefinition\n  handle_send :: \"bool \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n  \"handle_send bl \\<equiv> handle_invocation False bl\"\n\ndefinition\n  handle_call :: \"(unit,'z::state_ext) p_monad\" where\n \"handle_call \\<equiv> handle_invocation True True\"\n\ndefinition\n  delete_caller_cap :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"delete_caller_cap t \\<equiv> cap_delete_one (t, tcb_cnode_index 3)\"\n\ndefinition\n  handle_recv :: \"bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"handle_recv is_blocking \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n\n     ep_cptr \\<leftarrow> liftM data_to_cptr $ as_user thread $\n                 getRegister cap_register;\n\n     (cap_fault_on_failure (of_bl ep_cptr) True $ doE\n        ep_cap \\<leftarrow> lookup_cap thread ep_cptr;\n\n        let flt = (throwError $ MissingCapability 0)\n        in\n        case ep_cap\n          of EndpointCap ref badge rights \\<Rightarrow>\n             (if AllowRecv \\<in> rights\n              then liftE $ do\n                 delete_caller_cap thread;\n                 receive_ipc thread ep_cap is_blocking\n                od\n              else flt)\n           | NotificationCap ref badge rights \\<Rightarrow>\n             (if AllowRecv \\<in> rights\n              then doE\n                ntfn \\<leftarrow> liftE $ get_notification ref;\n                boundTCB \\<leftarrow> returnOk $ ntfn_bound_tcb ntfn;\n                if boundTCB = Some thread \\<or> boundTCB = None\n                then liftE $ receive_signal thread ep_cap is_blocking\n                else flt\n               odE\n              else flt)\n           | _ \\<Rightarrow> flt\n      odE)\n      <catch> handle_fault thread\n   od\"\n\ndefinition\n  handle_reply :: \"(unit,'z::state_ext) s_monad\" where\n \"handle_reply \\<equiv> do\n    thread \\<leftarrow> gets cur_thread;\n    caller_cap \\<leftarrow> get_cap (thread, tcb_cnode_index 3);\n    case caller_cap of\n      ReplyCap caller False R \\<Rightarrow>\n        do_reply_transfer thread caller (thread, tcb_cnode_index 3) (AllowGrant \\<in> R)\n    | NullCap \\<Rightarrow> return ()\n    | _ \\<Rightarrow> fail\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Event Handling: Manages different types of system events, including system calls, unknown system calls, user-level faults, interrupts, virtual memory faults, and hypervisor events. Each event is processed with specific handlers, and most operations are executed without preemption to ensure atomicity and consistency.",
    "input": "",
    "output": "fun\n  handle_event :: \"event \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"handle_event (SyscallEvent call) =\n   (case call of\n          SysSend \\<Rightarrow> handle_send True\n        | SysNBSend \\<Rightarrow> handle_send False\n        | SysCall \\<Rightarrow> handle_call\n        | SysRecv \\<Rightarrow> without_preemption $ handle_recv True\n        | SysYield \\<Rightarrow> without_preemption handle_yield\n        | SysReply \\<Rightarrow> without_preemption handle_reply\n        | SysReplyRecv \\<Rightarrow> without_preemption $ do\n            handle_reply;\n            handle_recv True\n          od\n        | SysNBRecv \\<Rightarrow> without_preemption $ handle_recv False)\"\n\n| \"handle_event (UnknownSyscall n) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_fault thread $ UnknownSyscallException $ of_nat n;\n    return ()\n  od)\"\n\n| \"handle_event (UserLevelFault w1 w2) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_fault thread $ UserException (w1 && mask 32) (w2 && mask 28);\n    return ()\n  od)\"\n\n| \"handle_event Interrupt = (without_preemption $ do\n    active \\<leftarrow> do_machine_op $ getActiveIRQ False;\n    case active of\n       Some irq \\<Rightarrow> handle_interrupt irq\n     | None \\<Rightarrow> return ()\n  od)\"\n\n| \"handle_event (VMFaultEvent fault_type) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_vm_fault thread fault_type <catch> handle_fault thread;\n    return ()\n  od)\"\n\n| \"handle_event (HypervisorEvent hypfault_type) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_hypervisor_fault thread hypfault_type\n  od)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Entry Point: Manages the main event loop by handling events, managing potential preemption interrupts, and scheduling threads. It ensures that the system processes events, handles interruptions, and switches to the active thread efficiently.",
    "input": "",
    "output": "text \\<open>\n  This function is the main kernel entry point. The main event loop of the\n  kernel handles events, handles a potential preemption interrupt, schedules\n  and switches back to the active thread.\n\\<close>\n\ndefinition\n  call_kernel :: \"event \\<Rightarrow> (unit,'z::state_ext_sched) s_monad\" where\n  \"call_kernel ev \\<equiv> do\n       handle_event ev <handle>\n           (\\<lambda>_. without_preemption $ do\n                  irq \\<leftarrow> do_machine_op $ getActiveIRQ True;\n                  when (irq \\<noteq> None) $ handle_interrupt (the irq)\n                od);\n       schedule;\n       activate_thread\n   od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "No code or comment provided for summarization. Please provide the necessary information to generate the property.",
    "input": "",
    "output": "end",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invocation Type Determination: Maps a data value to an invocation label, ensuring that the data is converted to a valid invocation type or defaults to an invalid invocation if no corresponding label exists.",
    "input": "",
    "output": "(*\n Generic functions for invocation labels\n*)\n\nchapter \"Kernel Object Invocations\"\n\ntheory InvocationLabels_A\nimports\n  MiscMachine_A\n  \"ExecSpec.ArchLabelFuns_H\"\nbegin\n\ndefinition\n  invocation_type :: \"data \\<Rightarrow> invocation_label\"\nwhere\n \"invocation_type x \\<equiv> if \\<exists>(v :: invocation_label). fromEnum v = data_to_nat x\n                      then toEnum (data_to_nat x) else GenInvocationLabel InvalidInvocation\"\n\ndefinition\n  gen_invocation_type :: \"data \\<Rightarrow> gen_invocation_labels\"\nwhere\n \"gen_invocation_type x \\<equiv>\n   case invocation_type x of\n     GenInvocationLabel l \\<Rightarrow> l\n   | ArchInvocationLabel _ \\<Rightarrow> InvalidInvocation\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Active TCB: Obtain the TCB at a given address if the thread is in a runnable state.",
    "input": "",
    "output": "definition\n  getActiveTCB :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> tcb option\"\nwhere\n  \"getActiveTCB tcb_ref state \\<equiv>\n   case (get_tcb tcb_ref state)\n     of None           \\<Rightarrow> None\n      | Some tcb       \\<Rightarrow> if (runnable $ tcb_state tcb)\n                         then Some tcb else None\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve All Active Threads: Obtain a set of all threads in the system that are currently schedulable.",
    "input": "",
    "output": "definition\n  allActiveTCBs :: \"(obj_ref set,'z::state_ext) s_monad\" where\n  \"allActiveTCBs \\<equiv> do\n    state \\<leftarrow> get;\n    return {x. getActiveTCB x state \\<noteq> None}\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Switch to Specified Thread: Transitions the current execution context to the specified thread by dequeuing it from the scheduler, updating the current thread, and performing architecture-specific switch operations.",
    "input": "",
    "output": "definition\n  switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"switch_to_thread t \\<equiv> do\n     state \\<leftarrow> get;\n     assert (get_tcb t state \\<noteq> None);\n     arch_switch_to_thread t;\n     do_extended_op (tcb_sched_action (tcb_sched_dequeue) t);\n     modify (\\<lambda>s. s \\<lparr> cur_thread := t \\<rparr>)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread State Validation: Ensures that a thread is in a runnable state before switching to it, preventing the kernel from scheduling non-runnable threads.",
    "input": "",
    "output": "definition guarded_switch_to :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"guarded_switch_to thread \\<equiv> do ts \\<leftarrow> get_thread_state thread;\n                    assert (runnable ts);\n                    switch_to_thread thread\n                 od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Switch to Idle Thread: Switches the current thread to the idle thread, updating the system state to reflect this change. This ensures that the system remains in a valid state when no other threads are ready to run.",
    "input": "",
    "output": "definition\n  switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n  \"switch_to_idle_thread \\<equiv> do\n     thread \\<leftarrow> gets idle_thread;\n     arch_switch_to_idle_thread;\n     modify (\\<lambda>s. s \\<lparr> cur_thread := thread \\<rparr>)\n   od\"\n\nclass state_ext_sched = state_ext +\n  fixes schedule :: \"(unit,'a) s_monad\"\n\ndefinition choose_thread :: \"det_ext state \\<Rightarrow> (unit \\<times> det_ext state) set \\<times> bool\" where\n\"choose_thread \\<equiv>\n      do\n        d \\<leftarrow> gets cur_domain;\n        queues \\<leftarrow> gets (\\<lambda>s. ready_queues s d);\n        if (\\<forall>prio. queues prio = []) then (switch_to_idle_thread)\n        else (guarded_switch_to (hd (max_non_empty_queue queues)))\n      od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Priority Scheduling: Determines if a given priority is the highest among the ready threads in a specified domain. If no threads are ready, it trivially returns true. This ensures that the scheduler can make informed decisions about thread prioritization and scheduling, maintaining efficient and fair execution of threads.",
    "input": "",
    "output": "definition\n  is_highest_prio :: \"domain \\<Rightarrow> priority \\<Rightarrow> det_ext state \\<Rightarrow> bool\"\nwhere\n  \"is_highest_prio d p s \\<equiv>\n    (\\<forall>prio. ready_queues s d prio = [])\n    \\<or> p \\<ge> Max {prio. ready_queues s d prio \\<noteq> []}\"\n\ninstantiation  det_ext_ext :: (type) state_ext_sched\nbegin\n\ndefinition\n  \"schedule_switch_thread_fastfail ct it ct_prio target_prio \\<equiv>\n     if ct \\<noteq> it\n     then return (target_prio < ct_prio)\n     else return True\"\n\ndefinition\n  \"schedule_choose_new_thread \\<equiv> do\n     dom_time \\<leftarrow> gets domain_time;\n     when (dom_time = 0) next_domain;\n     choose_thread;\n     set_scheduler_action resume_cur_thread\n   od\"\n\ndefinition\n  \"schedule_det_ext_ext \\<equiv> do\n     ct \\<leftarrow> gets cur_thread;\n     ct_st \\<leftarrow> get_thread_state ct;\n     ct_runnable \\<leftarrow> return $ runnable ct_st;\n     action \\<leftarrow> gets scheduler_action;\n     (case action\n       of resume_cur_thread \\<Rightarrow> do\n            id \\<leftarrow> gets idle_thread;\n            assert (ct_runnable \\<or> ct = id);\n            return ()\n         od\n       | choose_new_thread \\<Rightarrow> do\n           when ct_runnable (tcb_sched_action tcb_sched_enqueue ct);\n           schedule_choose_new_thread\n         od\n       | switch_thread candidate \\<Rightarrow> do\n           when ct_runnable (tcb_sched_action tcb_sched_enqueue ct);\n\n           it \\<leftarrow> gets idle_thread;\n           target_prio \\<leftarrow> ethread_get tcb_priority candidate;\n\n           \\<comment> \\<open>Infoflow does not like asking about the idle thread's priority or domain.\\<close>\n           ct_prio \\<leftarrow> ethread_get_when (ct \\<noteq> it) tcb_priority ct;\n           \\<comment> \\<open>When to look at the bitmaps. This optimisation is used in the C fast path,\n              but there we know @{text cur_thread} is not idle.\\<close>\n           fastfail \\<leftarrow> schedule_switch_thread_fastfail ct it ct_prio target_prio;\n\n           cur_dom \\<leftarrow> gets cur_domain;\n           highest \\<leftarrow> gets (is_highest_prio cur_dom target_prio);\n           if (fastfail \\<and> \\<not>highest)\n           then do\n               \\<comment> \\<open>Candidate is not best candidate, choose a new thread\\<close>\n               tcb_sched_action tcb_sched_enqueue candidate;\n               set_scheduler_action choose_new_thread;\n               schedule_choose_new_thread\n             od\n           else if (ct_runnable \\<and> ct_prio = target_prio)\n           then do\n               \\<comment> \\<open>Current thread was runnable and candidate is not strictly better\n                  want current thread to run next, so append the candidate to end of queue\n                  and choose again\\<close>\n               tcb_sched_action tcb_sched_append candidate;\n               set_scheduler_action choose_new_thread;\n               schedule_choose_new_thread\n             od\n           else do\n             guarded_switch_to candidate;\n             \\<comment> \\<open>Duplication assists in wp proof under different scheduler actions\\<close>\n             set_scheduler_action resume_cur_thread\n           od\n        od)\n    od\"\n\ninstance ..\nend\n\n\ninstantiation unit :: state_ext_sched\nbegin",
    "system": "",
    "history": []
  },
  {
    "instruction": "Scheduler Flexibility: The scheduler can choose any active thread or the idle thread for execution. If the selected thread is the current thread, it may skip the context switch. Similarly, if the idle thread is the current thread, it may omit the switch to the idle thread.",
    "input": "",
    "output": "definition schedule_unit :: \"(unit,unit) s_monad\" where\n\"schedule_unit \\<equiv> (do\n   cur \\<leftarrow> gets cur_thread;\n   threads \\<leftarrow> allActiveTCBs;\n   thread \\<leftarrow> select threads;\n   (if thread = cur then\n     return () \\<sqinter> switch_to_thread thread\n   else\n     switch_to_thread thread)\n od) \\<sqinter>\n (do\n   cur \\<leftarrow> gets cur_thread;\n   idl \\<leftarrow> gets idle_thread;\n   if idl = cur then\n     return () \\<sqinter> switch_to_idle_thread\n   else switch_to_idle_thread\n  od)\"\n\ninstance ..\nend\n\n\nlemmas schedule_def = schedule_det_ext_ext_def schedule_unit_def\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Bit Definitions: Define the number of bits for ASID, including high bits, low bits, and total bits, to specify the structure and size of the ASID used in the system.",
    "input": "",
    "output": "translations\n  (type) \"'a user_monad\" <= (type) \"user_context \\<Rightarrow> ('a \\<times> user_context) set \\<times> bool\"\n\ndefinition\n  asid_high_bits :: nat\nwhere\n  \"asid_high_bits \\<equiv> LENGTH(asid_high_len)\"\n\ndefinition\n  asid_low_bits :: nat\nwhere\n  \"asid_low_bits \\<equiv> LENGTH(asid_low_len)\"\n\ndefinition\n  asid_bits :: nat\nwhere\n  \"asid_bits \\<equiv> LENGTH(asid_len)\"\n\nlemmas asid_bits_defs =\n  asid_bits_def asid_high_bits_def asid_low_bits_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Sanity Checks for ASID and IPA Configuration: Ensure that the ASID bits are correctly split into high and low bits, and that the total number of ASID bits does not exceed the defined length. Additionally, define the IPA size based on the configuration setting.",
    "input": "",
    "output": "lemma asid_bits_len_checks:\n  \"asid_bits = asid_high_bits + asid_low_bits\"\n  \"asid_bits \\<le> LENGTH(asid_rep_len)\"\n  unfolding asid_bits_defs by auto\n\ndefinition ipa_size :: nat where\n  \"ipa_size \\<equiv> if config_ARM_PA_SIZE_BITS_40 then 40 else 44\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQ Control: Allows the creation and management of IRQHandler capabilities, as well as the execution of architecture-specific interrupt actions. This ensures that interrupts are handled correctly and efficiently, maintaining system stability and performance.",
    "input": "",
    "output": "fun\n  invoke_irq_control :: \"irq_control_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"invoke_irq_control (IRQControl irq handler_slot control_slot) =\n     liftE (do set_irq_state IRQSignal irq;\n               cap_insert (IRQHandlerCap irq) control_slot handler_slot od)\"\n| \"invoke_irq_control (ArchIRQControl invok) =\n     arch_invoke_irq_control invok\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IRQHandler Operations: Manage the delivery and acknowledgment of interrupts by configuring or clearing the Notification capabilities in the relevant per-IRQ slot. This ensures that interrupts are properly handled and acknowledged, maintaining the system's responsiveness and stability.",
    "input": "",
    "output": "fun\n  invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"invoke_irq_handler (ACKIrq irq) = arch_invoke_irq_handler (ACKIrq irq)\"\n| \"invoke_irq_handler (SetIRQHandler irq cap slot) = (do\n     irq_slot \\<leftarrow> get_irq_slot irq;\n     cap_delete_one irq_slot;\n     cap_insert cap slot irq_slot\n   od)\"\n| \"invoke_irq_handler (ClearIRQHandler irq) = (do\n     irq_slot \\<leftarrow> get_irq_slot irq;\n     cap_delete_one irq_slot\n   od)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Interrupt: Processes interrupts by checking the interrupt state and performing appropriate actions. For a timer interrupt, it decrements the current thread's time slice and reschedules if necessary, while for a signal interrupt, it sends a notification if a valid notification capability is present.",
    "input": "",
    "output": "definition timer_tick :: \"unit det_ext_monad\" where\n  \"timer_tick \\<equiv> do\n     cur \\<leftarrow> gets cur_thread;\n     state \\<leftarrow> get_thread_state cur;\n     case state of Running \\<Rightarrow> do\n       ts \\<leftarrow> ethread_get tcb_time_slice cur;\n       let ts' = ts - 1 in\n       if (ts' > 0) then thread_set_time_slice cur ts' else do\n         thread_set_time_slice cur timeSlice;\n         tcb_sched_action tcb_sched_append cur;\n         reschedule_required\n       od\n     od\n     | _ \\<Rightarrow> return ();\n     when (numDomains > 1) (do\n       dec_domain_time;\n       dom_time \\<leftarrow> gets domain_time;\n       when (dom_time = 0) reschedule_required\n     od)\n   od\"\n\ndefinition\n  handle_interrupt :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"handle_interrupt irq \\<equiv>\n   if irq > maxIRQ then do_machine_op $ do\n    maskInterrupt True irq;\n    ackInterrupt irq\n    od\n  else do\n   st \\<leftarrow> get_irq_state irq;\n   case st of\n     IRQSignal \\<Rightarrow> do\n       slot \\<leftarrow> get_irq_slot irq;\n       cap \\<leftarrow> get_cap slot;\n       when (is_ntfn_cap cap \\<and> AllowSend \\<in> cap_rights cap)\n         $ send_signal (obj_ref_of cap) (cap_ep_badge cap);\n       arch_mask_irq_signal irq\n     od\n   | IRQTimer \\<Rightarrow> do\n       do_extended_op timer_tick;\n       do_machine_op resetTimer\n     od\n   | IRQInactive \\<Rightarrow> fail \\<comment> \\<open>not meant to be able to get IRQs from inactive lines\\<close>\n   | IRQReserved \\<Rightarrow> handle_reserved_irq irq;\n   do_machine_op $ ackInterrupt irq\n   od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Access Rights: Define different levels of access rights for pages, including kernel-only access, read-only access, and read-write access.",
    "input": "",
    "output": "type_synonym vm_rights = cap_rights\n\ndefinition vm_kernel_only :: vm_rights\nwhere\n  \"vm_kernel_only \\<equiv> {}\"\n\ndefinition vm_read_only :: vm_rights\nwhere\n  \"vm_read_only \\<equiv> {AllowRead}\"\n\ndefinition vm_read_write :: vm_rights\nwhere\n  \"vm_read_write \\<equiv> {AllowRead,AllowWrite}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Valid Virtual Memory Rights: Ensures that only permitted combinations of virtual-memory rights are used, specifically allowing read-write, read-only, or kernel-only access. The validation function adjusts any given set of rights to the largest permissible subset according to these rules.",
    "input": "",
    "output": "definition valid_vm_rights :: \"vm_rights set\"\nwhere\n  \"valid_vm_rights \\<equiv> {vm_read_write, vm_read_only, vm_kernel_only}\"\n\ndefinition validate_vm_rights :: \"vm_rights \\<Rightarrow> vm_rights\"\nwhere\n  \"validate_vm_rights rs \\<equiv>\n     if AllowRead \\<in> rs\n     then if AllowWrite \\<in> rs then vm_read_write else vm_read_only\n     else vm_kernel_only\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Mask VM Rights: Ensures that the intersection of VM rights and capability rights is valid by applying a validation function, preventing invalid combinations such as `{AllowWrite}`.",
    "input": "",
    "output": "definition mask_vm_rights :: \"vm_rights \\<Rightarrow> cap_rights \\<Rightarrow> vm_rights\"\nwhere\n  \"mask_vm_rights V R \\<equiv> validate_vm_rights (V \\<inter> R)\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "No code or comment is provided for summarization. Please provide the necessary code and, if available, the comment to generate the property.",
    "input": "",
    "output": "end",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure Reply Capability: If a thread does not already have a master Reply capability in its reply slot, this function sets up a new master Reply capability with permissions for granting and writing.",
    "input": "",
    "output": "text \\<open>Threads that are active always have a master Reply capability to\nthemselves stored in their reply slot. This is so that a derived Reply\ncapability can be generated immediately if they wish to issue one. This function\nsets up a new master Reply capability if one does not exist.\\<close>\ndefinition\n  \"setup_reply_master thread \\<equiv> do\n     old_cap <- get_cap (thread, tcb_cnode_index 2);\n     when (old_cap = NullCap) $ do\n         set_original (thread, tcb_cnode_index 2) True;\n         set_cap (ReplyCap thread True {AllowGrant, AllowWrite}) (thread, tcb_cnode_index 2)\n     od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Reactivation: Reactivates a thread if it is not already running or idle. This involves canceling any ongoing IPC, setting up the reply master, updating the thread state to Restart, and enqueuing the thread for scheduling. If the reactivated thread has higher priority, a context switch may be initiated.",
    "input": "",
    "output": "definition\n  restart :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"restart thread \\<equiv> do\n    state \\<leftarrow> get_thread_state thread;\n    when (\\<not> runnable state \\<and> \\<not> idle state) $ do\n      cancel_ipc thread;\n      setup_reply_master thread;\n      set_thread_state thread Restart;\n      do_extended_op (tcb_sched_action (tcb_sched_enqueue) thread);\n      do_extended_op (possible_switch_to thread)\n    od\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread Activation: Activates the current thread by setting its state to running, restarting it with the correct program counter if necessary, and handling the idle thread specially.",
    "input": "",
    "output": "definition\n  activate_thread :: \"(unit,'z::state_ext) s_monad\" where\n  \"activate_thread \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n     state \\<leftarrow> get_thread_state thread;\n     (case state\n       of Running \\<Rightarrow> return ()\n        | Restart \\<Rightarrow> (do\n            pc \\<leftarrow> as_user thread getRestartPC;\n            as_user thread $ setNextPC pc;\n            set_thread_state thread Running\n          od)\n        | IdleThreadState \\<Rightarrow> arch_activate_idle_thread thread\n        | _ \\<Rightarrow> fail)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Load Word Offsets: Retrieve a machine word from a specified offset in an object's memory. The function supports loading words using both natural number and data type offsets, ensuring flexibility in accessing memory contents.",
    "input": "",
    "output": "definition\n  load_word_offs :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> (machine_word,'z::state_ext) s_monad\" where\n \"load_word_offs ptr offs \\<equiv>\n    do_machine_op $ loadWord (ptr + of_nat (offs * word_size))\"\ndefinition\n  load_word_offs_word :: \"obj_ref \\<Rightarrow> data \\<Rightarrow> (machine_word,'z::state_ext) s_monad\" where\n \"load_word_offs_word ptr offs \\<equiv>\n    do_machine_op $ loadWord (ptr + (offs * word_size))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Copy Message Registers: Copy a specified number of message registers from the sender thread to the receiver thread, including both hardware and buffer message registers. The function ensures that the values are correctly transferred and returns the total number of registers copied.",
    "input": "",
    "output": "definition\n  copy_mrs :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> obj_ref \\<Rightarrow>\n               obj_ref option \\<Rightarrow> length_type \\<Rightarrow> (length_type,'z::state_ext) s_monad\" where\n  \"copy_mrs sender sbuf receiver rbuf n \\<equiv>\n   do\n     hardware_mrs \\<leftarrow> return $ take (unat n) msg_registers;\n     mapM (\\<lambda>r. do\n         v \\<leftarrow> as_user sender $ getRegister r;\n         as_user receiver $ setRegister r v\n       od) hardware_mrs;\n     buf_mrs \\<leftarrow> case (sbuf, rbuf) of\n       (Some sb_ptr, Some rb_ptr) \\<Rightarrow> mapM (\\<lambda>x. do\n                                       v \\<leftarrow> load_word_offs sb_ptr x;\n                                       store_word_offs rb_ptr x v\n                                     od)\n               [length msg_registers + 1 ..< Suc (unat n)]\n     | _ \\<Rightarrow> return [];\n     return $ min n $ nat_to_len $ length hardware_mrs + length buf_mrs\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "TCB CTable and VTable Access: Retrieve the capability table (ctable) and virtual address table (vtable) pointers for a given TCB. These pointers are used to access the specific slots in the TCB's cnode.",
    "input": "",
    "output": "definition\n  get_tcb_ctable_ptr :: \"obj_ref \\<Rightarrow> cslot_ptr\" where\n  \"get_tcb_ctable_ptr tcb_ref \\<equiv> (tcb_ref, tcb_cnode_index 0)\"\n\ndefinition\n  get_tcb_vtable_ptr :: \"obj_ref \\<Rightarrow> cslot_ptr\" where\n  \"get_tcb_vtable_ptr tcb_ref \\<equiv> (tcb_ref, tcb_cnode_index 1)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Optional TCB Update: Conditionally update the TCB at a specified address based on the presence of an optional value. If the value is present, apply the given function to update the TCB; otherwise, do nothing.",
    "input": "",
    "output": "definition\n  option_update_thread :: \"obj_ref \\<Rightarrow> ('a \\<Rightarrow> tcb \\<Rightarrow> tcb) \\<Rightarrow> 'a option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"option_update_thread thread fn \\<equiv> case_option (return ()) (\\<lambda>v. thread_set (fn v) thread)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Cap at Slot: Ensures that a capability is present at a specified slot before performing an operation. This prevents issues where the parent capability might have been moved or deleted, maintaining the integrity of the capability system.",
    "input": "",
    "output": "definition\n  check_cap_at :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"check_cap_at cap slot m \\<equiv> do\n    cap' \\<leftarrow> get_cap slot;\n    when (same_object_as cap cap') m\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Bind Notification: Establishes a binding between a thread and a notification, updating the notification to reference the thread and setting the thread's bound notification.",
    "input": "",
    "output": "definition\n  bind_notification :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"bind_notification tcbptr ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     ntfn' \\<leftarrow> return $ ntfn_set_bound_tcb ntfn (Some tcbptr);\n     set_notification ntfnptr ntfn';\n     set_bound_notification tcbptr $ Some ntfnptr\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "TCB Invocation Actions: Allows threads to perform a variety of actions, including suspending and resuming other threads, reconfiguring thread settings (such as fault handlers, priorities, and capability roots), managing IPC buffers, copying and modifying register sets, controlling notifications, and setting the TLS base. These actions ensure that threads can manage their state and capabilities effectively, maintaining the integrity and performance of the system. \n\nDomain Management: Sets the scheduling domain for a thread, ensuring it is correctly dequeued, its domain is updated, and it is re-enqueued if runnable. If the thread being updated is the current thread, a reschedule is required, optimizing the system's scheduling and execution efficiency.",
    "input": "",
    "output": "fun\n  invoke_tcb :: \"tcb_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\nwhere\n  \"invoke_tcb (Suspend thread) = liftE (do suspend thread; return [] od)\"\n| \"invoke_tcb (Resume thread) = liftE (do restart thread; return [] od)\"\n\n| \"invoke_tcb (ThreadControl target slot faultep mcp priority croot vroot buffer)\n   = doE\n    liftE $ option_update_thread target (tcb_fault_handler_update o K) faultep;\n    liftE $  case mcp of None \\<Rightarrow> return()\n     | Some (newmcp, _) \\<Rightarrow> set_mcpriority target newmcp;\n    (case croot of None \\<Rightarrow> returnOk ()\n     | Some (new_cap, src_slot) \\<Rightarrow> doE\n      cap_delete (target, tcb_cnode_index 0);\n      liftE $ check_cap_at new_cap src_slot\n            $ check_cap_at (ThreadCap target) slot\n            $ cap_insert new_cap src_slot (target, tcb_cnode_index 0)\n    odE);\n    (case vroot of None \\<Rightarrow> returnOk ()\n     | Some (new_cap, src_slot) \\<Rightarrow> doE\n      cap_delete (target, tcb_cnode_index 1);\n      liftE $ check_cap_at new_cap src_slot\n            $ check_cap_at (ThreadCap target) slot\n            $ cap_insert new_cap src_slot (target, tcb_cnode_index 1)\n    odE);\n    (case buffer of None \\<Rightarrow> returnOk ()\n     | Some (ptr, frame) \\<Rightarrow> doE\n      cap_delete (target, tcb_cnode_index 4);\n      liftE $ thread_set (\\<lambda>t. t \\<lparr> tcb_ipc_buffer := ptr \\<rparr>) target;\n      liftE $ case frame of None \\<Rightarrow> return ()\n       | Some (new_cap, src_slot) \\<Rightarrow>\n            check_cap_at new_cap src_slot\n          $ check_cap_at (ThreadCap target) slot\n          $ cap_insert new_cap src_slot (target, tcb_cnode_index 4);\n      cur \\<leftarrow> liftE $ gets cur_thread;\n      liftE $ when (target = cur) (do_extended_op reschedule_required)\n    odE);\n    liftE $ case priority\n              of None \\<Rightarrow> return()\n               | Some (prio, _) \\<Rightarrow> do_extended_op (set_priority target prio);\n    returnOk []\n  odE\"\n\n| \"invoke_tcb (CopyRegisters dest src suspend_source resume_target transfer_frame transfer_integer transfer_arch) =\n  (liftE $ do\n    when suspend_source $ suspend src;\n    when resume_target $ restart dest;\n    when transfer_frame $ do\n        mapM_x (\\<lambda>r. do\n                v \\<leftarrow> as_user src $ getRegister r;\n                as_user dest $ setRegister r v\n        od) frame_registers;\n        pc \\<leftarrow> as_user dest getRestartPC;\n        as_user dest $ setNextPC pc\n    od;\n    when transfer_integer $\n        mapM_x (\\<lambda>r. do\n                v \\<leftarrow> as_user src $ getRegister r;\n                as_user dest $ setRegister r v\n        od) gpRegisters;\n    cur \\<leftarrow> gets cur_thread;\n    arch_post_modify_registers cur dest;\n    when (dest = cur) (do_extended_op reschedule_required);\n    return []\n  od)\"\n\n| \"invoke_tcb (ReadRegisters src suspend_source n arch) =\n  (liftE $ do\n    when suspend_source $ suspend src;\n    self \\<leftarrow> gets cur_thread;\n    regs \\<leftarrow> return (take (unat n) $ frame_registers @ gp_registers);\n    as_user src $ mapM getRegister regs\n  od)\"\n\n| \"invoke_tcb (WriteRegisters dest resume_target values arch) =\n  (liftE $ do\n    self \\<leftarrow> gets cur_thread;\n    b \\<leftarrow> arch_get_sanitise_register_info dest;\n    as_user dest $ do\n        zipWithM (\\<lambda>r v. setRegister r (sanitise_register b r v))\n            (frameRegisters @ gpRegisters) values;\n        pc \\<leftarrow> getRestartPC;\n        setNextPC pc\n    od;\n    arch_post_modify_registers self dest;\n    when resume_target $ restart dest;\n    when (dest = self) (do_extended_op reschedule_required);\n    return []\n  od)\"\n\n| \"invoke_tcb (NotificationControl tcb (Some ntfnptr)) =\n  (liftE $ do\n    bind_notification tcb ntfnptr;\n    return []\n  od)\"\n\n| \"invoke_tcb (NotificationControl tcb None) =\n  (liftE $ do\n    unbind_notification tcb;\n    return []\n  od)\"\n\n| \"invoke_tcb (SetTLSBase tcb tls_base) =\n  (liftE $ do\n    as_user tcb $ setRegister tlsBaseRegister tls_base;\n    cur \\<leftarrow> gets cur_thread;\n    when (tcb = cur) (do_extended_op reschedule_required);\n    return []\n  od)\"\n\ndefinition\n  set_domain :: \"obj_ref \\<Rightarrow> domain \\<Rightarrow> unit det_ext_monad\" where\n  \"set_domain tptr new_dom \\<equiv> do\n     cur \\<leftarrow> gets cur_thread;\n     tcb_sched_action tcb_sched_dequeue tptr;\n     thread_set_domain tptr new_dom;\n     ts \\<leftarrow> get_thread_state tptr;\n     when (runnable ts) (tcb_sched_action tcb_sched_enqueue tptr);\n     when (tptr = cur) reschedule_required\n   od\"\n\ndefinition invoke_domain:: \"obj_ref \\<Rightarrow> domain \\<Rightarrow> (data list,'z::state_ext) p_monad\"\nwhere\n  \"invoke_domain thread domain \\<equiv>\n     liftE (do do_extended_op (set_domain thread domain); return [] od)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Message Register Retrieval: Collects message registers from both the sending thread's current register file and its IPC buffer, ensuring that all necessary data for the message is gathered.",
    "input": "",
    "output": "definition\n  get_mrs :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> message_info \\<Rightarrow>\n              (message list,'z::state_ext) s_monad\" where\n  \"get_mrs thread buf info \\<equiv> do\n     context \\<leftarrow> thread_get (arch_tcb_get_registers o tcb_arch) thread;\n     cpu_mrs \\<leftarrow> return (map context msg_registers);\n     buf_mrs \\<leftarrow> case buf\n       of None      \\<Rightarrow> return []\n        | Some pptr \\<Rightarrow> mapM (\\<lambda>x. load_word_offs pptr x)\n               [length msg_registers + 1 ..< Suc msg_max_length];\n     return (take (unat (mi_length info)) $ cpu_mrs @ buf_mrs)\n   od\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific Interrupt Handling: Manages the handling of reserved interrupts and invokes interrupt handlers, including acknowledging and masking interrupts.",
    "input": "",
    "output": "(*\nFormalisation of interrupt handling.\n*)\n\nchapter \"Arch-specific Interrupts\"\n\ntheory ArchInterrupt_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition handle_reserved_irq :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where \"handle_reserved_irq irq = return ()\"\n\nfun arch_invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_invoke_irq_handler (ACKIrq irq) = (do_machine_op $ maskInterrupt False irq)\"\n| \"arch_invoke_irq_handler _ = return ()\"\n\ndefinition arch_mask_irq_signal :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_mask_irq_signal irq \\<equiv> do_machine_op $ maskInterrupt True irq\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Switch to Thread's Virtual Address Space: Transition the system to a specified thread's virtual address space context and clear the load-exclusive monitor, ensuring that the memory operations are correctly aligned with the new context.",
    "input": "",
    "output": "definition\n  arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> do\n     set_vm_root t;\n     do_machine_op $ clearExMonitor\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Clear Globals Frame on Idle Thread Switch: When switching to the idle thread, the global frame is cleared to facilitate information flow reasoning.",
    "input": "",
    "output": "definition\n   arch_switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n   \"arch_switch_to_idle_thread \\<equiv> do\n     thread \\<leftarrow> gets idle_thread;\n     set_vm_root thread\n   od\"\n\ndefinition\n  arch_activate_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_activate_idle_thread t \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Control Invocation: Creates a new ASID pool object, provides a capability to it, and connects it to the global virtual ASID table. This ensures that the ASID pool is properly initialized and integrated into the system's memory management, maintaining the integrity and efficiency of address space identification.",
    "input": "",
    "output": "definition\nperform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_control_invocation iv \\<equiv> case iv of\n  MakePool frame slot parent base \\<Rightarrow> do\n    delete_objects frame page_bits;\n    pcap \\<leftarrow> get_cap parent;\n    set_cap (max_free_index_update pcap) parent;\n    retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n    cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n    assert (base && mask asid_low_bits = 0);\n    asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n    modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>arm_asid_table := asid_table'\\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Assign ASID to Page Directory: The ASIDPool capability allows the assignment of a virtual ASID to a page directory. This involves updating the page directory's ASID and the ASID pool with the new mapping, ensuring that the page directory is correctly associated with the specified ASID.",
    "input": "",
    "output": "definition\nperform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_pool_invocation iv \\<equiv> case iv of Assign asid pool_ptr ct_slot \\<Rightarrow>\ndo\n    pd_cap \\<leftarrow> get_cap ct_slot;\n    case pd_cap of\n      ArchObjectCap (PageDirectoryCap pd_base _) \\<Rightarrow> do\n        pool \\<leftarrow> get_asid_pool pool_ptr;\n        pool' \\<leftarrow> return (pool (ucast asid \\<mapsto> pd_base));\n        set_cap (ArchObjectCap $ PageDirectoryCap pd_base (Some asid)) ct_slot;\n        set_asid_pool pool_ptr pool'\n      od\n    | _ \\<Rightarrow> fail\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Directory Invocation: The PageDirectory capability allows for the flushing of cache entries associated with a specific page directory. It ensures that the virtual machine root is set for the flush operation, performs the cache flush, and resets the virtual machine root if it was switched, maintaining the integrity of the memory management system.",
    "input": "",
    "output": "definition\n  perform_page_directory_invocation :: \"page_directory_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_page_directory_invocation iv \\<equiv> case iv of\n       PageDirectoryFlush typ start end pstart pd asid \\<Rightarrow>\n         when (start < end) $ do\n           root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n           do_machine_op $ do_flush typ start end pstart;\n           when root_switched $ do\n             tcb \\<leftarrow> gets cur_thread;\n             set_vm_root tcb\n           od\n        od\n     | PageDirectoryNothing \\<Rightarrow> return ()\"\n\ndefinition\n  pte_check_if_mapped :: \"32 word \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pte_check_if_mapped slot \\<equiv> do\n     pt \\<leftarrow> get_master_pte slot;\n     return (pt \\<noteq> InvalidPTE)\n  od\"\n\ndefinition\n  pde_check_if_mapped :: \"32 word \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pde_check_if_mapped slot \\<equiv> do\n     pd \\<leftarrow> get_master_pde slot;\n     return (pd \\<noteq> InvalidPDE)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Capability Operations: The page capability allows for mapping, unmapping, and flushing memory pages. It ensures that pages can be correctly managed in the virtual memory system, including updating page tables, invalidating TLB entries, and cleaning cache ranges as necessary.",
    "input": "",
    "output": "definition\nperform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n\"perform_page_invocation iv \\<equiv> case iv of\n  PageMap asid cap ct_slot entries \\<Rightarrow> do\n    set_cap cap ct_slot;\n    case entries of\n          Inl (pte, slots) \\<Rightarrow> do\n            flush \\<leftarrow> pte_check_if_mapped (hd slots);\n            store_pte (hd slots) pte;\n            mapM (swp store_pte InvalidPTE) (tl slots);\n            do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                (addrFromPPtr (hd slots));\n            if flush then (invalidate_tlb_by_asid asid) else return ()\n          od\n        | Inr (pde, slots) \\<Rightarrow> do\n            flush \\<leftarrow> pde_check_if_mapped (hd slots);\n            store_pde (hd slots) pde;\n            mapM (swp store_pde InvalidPDE) (tl slots);\n            do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                (addrFromPPtr (hd slots));\n            if flush then (invalidate_tlb_by_asid asid) else return ()\n          od;\n    return []\n  od\n| PageUnmap cap ct_slot \\<Rightarrow>\n    (case cap of\n      PageCap dev p R vp_size vp_mapped_addr \\<Rightarrow> do\n        case vp_mapped_addr of\n            Some (asid, vaddr) \\<Rightarrow> unmap_page vp_size asid vaddr p\n          | None \\<Rightarrow> return ();\n        cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n        set_cap (ArchObjectCap $ update_map_data cap None) ct_slot;\n        return []\n      od\n    | _ \\<Rightarrow> fail)\n| PageFlush typ start end pstart pd asid \\<Rightarrow> do\n    when (start < end) $ do\n      root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n      do_machine_op $ do_flush typ start end pstart;\n      when root_switched $ do\n        tcb \\<leftarrow> gets cur_thread;\n        set_vm_root tcb\n      od\n    od;\n    return []\n  od\n| PageGetAddr ptr \\<Rightarrow>\n    return [addrFromPPtr ptr]\n  \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Management: Authorizes the mapping and unmapping of page tables. It allows setting and storing page directory entries for mapping, and unmaps page tables by invalidating the corresponding page table entries and cleaning the cache.",
    "input": "",
    "output": "definition\nperform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_table_invocation iv \\<equiv>\ncase iv of PageTableMap cap ct_slot pde pd_slot \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pde pd_slot pde;\n    do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot)\n  od\n  | PageTableUnmap (ArchObjectCap (PageTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_page_table asid vaddr p;\n      pte_bits \\<leftarrow> return 2;\n      slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 << pt_bits) - 1];\n      mapM_x (swp store_pte InvalidPTE) slots;\n      do_machine_op $ cleanCacheRange_PoU p (p + (1 << pt_bits) - 1)\n                                          (addrFromPPtr p)\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocation Handling: Dispatches ARM-specific system calls by invoking the appropriate operations for page tables, page directories, pages, ASID control, and ASID pools. Each invocation is handled by a corresponding function that performs the specific operation and returns the result.",
    "input": "",
    "output": "definition\n  arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\" where\n  \"arch_perform_invocation i \\<equiv> liftE $\n    case i of\n      InvokePageTable oper \\<Rightarrow> do\n        perform_page_table_invocation oper;\n        return []\n      od\n    | InvokePageDirectory oper \\<Rightarrow> do\n        perform_page_directory_invocation oper;\n        return []\n      od\n    | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n    | InvokeASIDControl oper \\<Rightarrow> do\n        perform_asid_control_invocation oper;\n        return []\n      od\n    | InvokeASIDPool oper \\<Rightarrow> do\n        perform_asid_pool_invocation oper;\n        return []\n      od\n  \"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Hypervisor Fault: The system handles hypervisor fault events, specifically returning without action when the fault type is ARMNoHypFaults.",
    "input": "",
    "output": "chapter \"Handle Hyperviser Fault Event\"\n\ntheory Hypervisor_A\nimports Exceptions_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"word32 \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n\"handle_hypervisor_fault thread ARMNoHypFaults = return ()\"\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reserve Memory Region: Reserve a specified number of bytes in memory, potentially tagging the region as kernel data. The function currently acts as a placeholder and does not perform any actual reservation or tagging.",
    "input": "",
    "output": "definition\n  reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Architecture-Specific Objects: Initialize architecture-specific objects, such as page directories, page tables, and various page sizes, by setting their sizes and performing cache cleaning operations. The initialization process ensures that the objects are properly configured and ready for use, with specific actions taken based on the type of object and whether it is a device or not.",
    "input": "",
    "output": "definition vs_apiobj_size where\n  \"vs_apiobj_size ty \\<equiv>\n     case ty of\n       ArchObject SmallPageObj \\<Rightarrow> pageBitsForSize ARMSmallPage\n     | ArchObject LargePageObj \\<Rightarrow> pageBitsForSize ARMLargePage\n     | ArchObject SectionObj \\<Rightarrow> pageBitsForSize ARMSection\n     | ArchObject SuperSectionObj \\<Rightarrow> pageBitsForSize ARMSuperSection\n     | ArchObject PageTableObj \\<Rightarrow> pt_bits\n     | ArchObject PageDirectoryObj \\<Rightarrow> pd_bits\"\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv> do\n     when (new_type = ArchObject PageDirectoryObj) $ mapM_x copy_global_mappings refs;\n     if \\<not>is_device \\<and>\n        new_type \\<in> {ArchObject SmallPageObj, ArchObject LargePageObj,\n                    ArchObject SectionObj, ArchObject SuperSectionObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_RAM ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else if new_type \\<in> {ArchObject PageTableObj, ArchObject PageDirectoryObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_PoU ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else\n       return ()\n   od\"\n\ndefinition\n  empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context \\<rparr>\"\n\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Post Cap Deletion: Perform no additional actions after a capability is deleted.",
    "input": "",
    "output": "definition\n  arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arch_post_cap_deletion _ \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Generic Object References: The system defines arch-specific generic object references, but they are not utilized, as the set of such references for any arch_cap is empty. Additionally, the cleanup operation for arch_caps results in a NullCap, indicating that no specific cleanup is required for these arch-specific capabilities.",
    "input": "",
    "output": "datatype arch_gen_obj_ref = unit\n\ndefinition\n  arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\"\nwhere\n  \"arch_gen_obj_refs _ = {}\"\n\ndefinition\n  arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Dummy Initial State: Defines initial pointers for the TCB and IRQ node within a dummy kernel state, ensuring that the invariants and refinement relation are consistent.",
    "input": "",
    "output": "definition\n  init_tcb_ptr :: word32 where\n  \"init_tcb_ptr = kernel_base + 0x2000\"\n\ndefinition\n  init_irq_node_ptr :: word32 where\n  \"init_irq_node_ptr = kernel_base + 0x8000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Kernel State: The kernel state is initialized with specific memory regions, including a global page directory and a data page, and an idle thread. The initialization ensures that the kernel has a well-defined starting point, with the necessary structures and objects set up to begin execution. This includes setting up the architecture-specific state, such as the ASID tables and the global page directory, and initializing the kernel heap with the idle thread and other essential components.",
    "input": "",
    "output": "definition\n  init_globals_frame :: word32 where\n  \"init_globals_frame = kernel_base + 0x5000\"\n\ndefinition\n  init_global_pd :: word32 where\n  \"init_global_pd = kernel_base + 0x60000\"\n\ndefinition\n  \"init_arch_state \\<equiv> \\<lparr>\n    arm_asid_table = Map.empty,\n    arm_hwasid_table = Map.empty,\n    arm_next_asid = 0,\n    arm_asid_map = Map.empty,\n    arm_global_pd = init_global_pd,\n    arm_global_pts = [],\n    arm_kernel_vspace = \\<lambda>ref.\n      if ref \\<in> {kernel_base .. kernel_base + mask 20}\n      then ArmVSpaceKernelWindow\n      else ArmVSpaceInvalidRegion\n  \\<rparr>\"\n\ndefinition\n  [simp]:\n  \"global_pd \\<equiv> (\\<lambda>_. InvalidPDE)( ucast (kernel_base >> 20) := SectionPDE (addrFromPPtr kernel_base) {} 0 {})\"\n\ndefinition\n  \"init_kheap \\<equiv>\n  (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n       then Some (CNode 0 (empty_cnode 0)) else None)\n  (idle_thread_ptr \\<mapsto> TCB \\<lparr>\n    tcb_ctable = NullCap,\n    tcb_vtable = NullCap,\n    tcb_reply = NullCap,\n    tcb_caller = NullCap,\n    tcb_ipcframe = NullCap,\n    tcb_state = IdleThreadState,\n    tcb_fault_handler = replicate word_bits False,\n    tcb_ipc_buffer = 0,\n    tcb_fault = None,\n    tcb_bound_notification = None,\n    tcb_mcpriority = minBound,\n    tcb_arch = init_arch_tcb\n  \\<rparr>,\n  init_globals_frame \\<mapsto> ArchObj (DataPage False ARMSmallPage), \\<comment> \\<open>same reason as why we kept the definition of @{term init_globals_frame}\\<close>\n  init_global_pd \\<mapsto> ArchObj (PageDirectory global_pd)\n  )\"\n\ndefinition\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. Structures_A.IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Mapping Entries: Generate the necessary page table entries (PTEs) or page directory entries (PDEs) to map a given frame size at a specified virtual address, ensuring the correct attributes and rights are applied. The function handles different frame sizes, including small pages, large pages, sections, and super sections, and calculates the appropriate offsets for large and super section mappings.",
    "input": "",
    "output": "definition largePagePTE_offsets :: \"obj_ref list\"\n  where\n  \"largePagePTE_offsets \\<equiv>\n    let pts = of_nat 2\n    in [0, 2 ^ pts  .e.  (15 << 2)]\"\n\ndefinition superSectionPDE_offsets :: \"obj_ref list\"\n  where\n  \"superSectionPDE_offsets \\<equiv>\n    let pts = of_nat 2\n    in [0, 2 ^ pts  .e.  (15 << 2)]\"\n\nfun create_mapping_entries ::\n  \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vm_rights \\<Rightarrow> vm_attributes \\<Rightarrow> word32 \\<Rightarrow>\n  ((pte * word32 list) + (pde * word32 list),'z::state_ext) se_monad\"\nwhere\n  \"create_mapping_entries base vptr ARMSmallPage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (SmallPagePTE base (attrib - {Global, ParityEnabled})\n                                 vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMLargePage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (LargePagePTE base (attrib - {Global, ParityEnabled})\n                                 vm_rights, map (\\<lambda>x. x + p) largePagePTE_offsets)\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SectionPDE base (attrib - {Global}) 0 vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSuperSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SuperSectionPDE base (attrib - {Global}) vm_rights, map (\\<lambda>x. x + p) superSectionPDE_offsets)\n  odE\"\n\ndefinition get_master_pde :: \"word32 \\<Rightarrow> (pde,'z::state_ext)s_monad\"\n  where \"get_master_pde ptr \\<equiv> do\n    pde \\<leftarrow> (get_pde (ptr && ~~ mask 6));\n    (case pde of SuperSectionPDE _ _ _ \\<Rightarrow> return pde\n    | _ \\<Rightarrow> get_pde ptr)\n  od\"\n\ndefinition get_master_pte :: \"word32 \\<Rightarrow> (pte, 'z::state_ext)s_monad\"\n  where \"get_master_pte ptr \\<equiv> do\n    pte \\<leftarrow> (get_pte (ptr && ~~ mask 6));\n    (case pte of LargePagePTE _ _ _ \\<Rightarrow> return pte\n    | _ \\<Rightarrow> get_pte ptr)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure Safe Mapping: Verify that new page table entries (PTEs) or page directory entries (PDEs) replace either invalid entries or entries of the same granularity, preventing unsafe mappings within larger frames.",
    "input": "",
    "output": "fun ensure_safe_mapping ::\n  \"(pte * word32 list) + (pde * word32 list) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n\"ensure_safe_mapping (Inl (InvalidPTE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inl (SmallPagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda>slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | SmallPagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inl (LargePagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | LargePagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inr (InvalidPDE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inr (PageTablePDE _ _ _, _)) = fail\"\n|\n\"ensure_safe_mapping (Inr (SectionPDE _ _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SectionPDE _ _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"\n|\n\"ensure_safe_mapping (Inr (SuperSectionPDE _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SuperSectionPDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup IPC Buffer: Verify a thread's authority to access its IPC buffer. Check if the thread has the necessary read or write permissions based on whether it is the receiver or not.",
    "input": "",
    "output": "definition\nlookup_ipc_buffer :: \"bool \\<Rightarrow> word32 \\<Rightarrow> (word32 option,'z::state_ext) s_monad\" where\n\"lookup_ipc_buffer is_receiver thread \\<equiv> do\n    buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n    buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n    buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n    (case buffer_cap of\n      ArchObjectCap (PageCap _ p R vms _) \\<Rightarrow>\n        if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n        then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n        else return None\n    | _ \\<Rightarrow> return None)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate Page Directory: Find the page directory associated with a given virtual ASID by checking the ASID table and the corresponding ASID pool. If the ASID or the page directory is not found, an error is thrown.",
    "input": "",
    "output": "definition\nfind_pd_for_asid :: \"asid \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"find_pd_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pd \\<leftarrow> returnOk (pool (ucast asid));\n    (case pd of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate and Validate Page Directory: Find the page directory for a given ASID, ensuring that the process is successful and returns a valid pointer to a real page directory.",
    "input": "",
    "output": "definition\nfind_pd_for_asid_assert :: \"asid \\<Rightarrow> (word32,'z::state_ext) s_monad\" where\n\"find_pd_for_asid_assert asid \\<equiv> do\n   pd \\<leftarrow> find_pd_for_asid asid <catch> K fail;\n   get_pde pd;\n   return pd\n od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle VM Fault: Format and propagate a virtual machine fault message to the thread's supervisor after encountering a page fault, including the fault address and type-specific fault information.",
    "input": "",
    "output": "fun\nhandle_vm_fault :: \"word32 \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n\"handle_vm_fault thread ARMDataAbort = doE\n    addr \\<leftarrow> liftE $ do_machine_op getFAR;\n    fault \\<leftarrow> liftE $ do_machine_op getDFSR;\n    throwError $ ArchFault $ VMFault addr [0, fault && mask 14]\nodE\"\n|\n\"handle_vm_fault thread ARMPrefetchAbort = doE\n    pc \\<leftarrow> liftE $ as_user thread $ getRestartPC;\n    fault \\<leftarrow> liftE $ do_machine_op getIFSR;\n    throwError $ ArchFault $ VMFault pc [1, fault && mask 14]\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Load Hardware ASID: Retrieve the optional hardware ASID currently associated with a given virtual ASID by consulting the ASID map in the system state.",
    "input": "",
    "output": "definition\nload_hw_asid :: \"asid \\<Rightarrow> (hardware_asid option,'z::state_ext) s_monad\" where\n\"load_hw_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    return $ option_map fst $ asid_map asid\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Associate a Hardware ASID: Map a virtual ASID to a hardware ASID and update the corresponding page directory. Ensure that both the ASID map and the hardware ASID table are updated to reflect the new association, maintaining the integrity of the address space mappings.",
    "input": "",
    "output": "definition\nstore_hw_asid :: \"asid \\<Rightarrow> hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"store_hw_asid asid hw_asid \\<equiv> do\n    pd \\<leftarrow> find_pd_for_asid_assert asid;\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid \\<mapsto> (hw_asid, pd)));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>);\n    hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid \\<mapsto> asid));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate TLB by ASID: Clear all TLB mappings associated with a given virtual ASID. If the ASID is mapped to a hardware ASID, invalidate the corresponding TLB entries.",
    "input": "",
    "output": "definition\ninvalidate_tlb_by_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_tlb_by_asid asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flush Virtual ASID: Flush all cache and TLB entries associated with a given virtual ASID. If the ASID is mapped to a hardware ASID, invalidate the local TLB for that hardware ASID.",
    "input": "",
    "output": "definition\nflush_space :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_space asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    do_machine_op cleanCaches_PoU;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate ASID: Remove the mapping from a specified virtual ASID to its corresponding hardware ASID, ensuring that the ASID is no longer associated with any hardware ASID in the system.",
    "input": "",
    "output": "definition\ninvalidate_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate Hardware ASID Entry: Remove the mapping from a specified hardware ASID to any virtual ASID, ensuring that the hardware ASID is no longer associated with any virtual ASID in the system.",
    "input": "",
    "output": "definition\ninvalidate_hw_asid_entry :: \"hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_hw_asid_entry hw_asid \\<equiv> do\n  hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n  hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid:= None));\n  modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate ASID Entry: Remove virtual to physical mappings associated with a given ASID, including invalidating the hardware ASID entry if it exists.",
    "input": "",
    "output": "definition\ninvalidate_asid_entry :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid_entry asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  when (maybe_hw_asid \\<noteq> None) $ invalidate_hw_asid_entry (the maybe_hw_asid);\n  invalidate_asid asid\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Find Free Hardware ASID: Locate an unused hardware ASID, and if none are available, reclaim one in a round-robin manner by invalidating the current next ASID and updating the next ASID pointer.",
    "input": "",
    "output": "definition\nfind_free_hw_asid :: \"(hardware_asid,'z::state_ext) s_monad\" where\n\"find_free_hw_asid \\<equiv> do\n    hw_asid_table \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    next_asid \\<leftarrow> gets (arm_next_asid \\<circ> arch_state);\n    maybe_asid \\<leftarrow> return (find (\\<lambda>a. hw_asid_table a = None)\n                    (take (length [minBound :: hardware_asid .e. maxBound])\n                        ([next_asid .e. maxBound] @ [minBound .e. next_asid])));\n    (case maybe_asid of\n       Some hw_asid \\<Rightarrow> return hw_asid\n     | None \\<Rightarrow>  do\n            invalidate_asid $ the $ hw_asid_table next_asid;\n            do_machine_op $ invalidateLocalTLB_ASID next_asid;\n            invalidate_hw_asid_entry next_asid;\n            new_next_asid \\<leftarrow> return (next_asid + 1);\n            modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_next_asid := new_next_asid \\<rparr>\\<rparr>);\n            return next_asid\n       od)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware ASID Retrieval and Assignment: Retrieve the hardware ASID associated with a given virtual ASID, and if none is assigned, find and assign a new hardware ASID. This ensures that each virtual ASID has a corresponding hardware ASID for proper memory management.",
    "input": "",
    "output": "definition\nget_hw_asid :: \"asid \\<Rightarrow> (hardware_asid,'z::state_ext) s_monad\" where\n\"get_hw_asid asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  (case maybe_hw_asid of\n    Some hw_asid \\<Rightarrow> return hw_asid\n  | None \\<Rightarrow>  do\n      new_hw_asid \\<leftarrow> find_free_hw_asid;\n      store_hw_asid asid new_hw_asid;\n      return new_hw_asid\n  od)\nod\"\n\n\nabbreviation\n  \"arm_context_switch_hwasid pd hwasid \\<equiv> do\n              set_current_pd $ addrFromPPtr pd;\n              setHardwareASID hwasid\n          od\"\n\ndefinition\n  arm_context_switch :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arm_context_switch pd asid \\<equiv> do\n      hwasid \\<leftarrow> get_hw_asid asid;\n      do_machine_op $ arm_context_switch_hwasid pd hwasid\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set VM Root: Switch the address space to the given thread's configured page directory, or to the global address space if the thread's configuration is invalid. Ensures that the correct address space is active for the thread, maintaining the integrity of memory access and execution.",
    "input": "",
    "output": "definition\n  set_vm_root :: \"word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow> doE\n           pd' \\<leftarrow> find_pd_for_asid asid;\n           whenE (pd \\<noteq> pd') $ throwError InvalidRoot;\n           liftE $ arm_context_switch pd asid\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_pd \\<leftarrow> gets (arm_global_pd \\<circ> arch_state);\n       do_machine_op $ set_current_pd $ addrFromKPPtr global_pd\n    od)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Deletion: Before deleting an ASID pool, deactivate all page directories installed in it by flushing and invalidating their entries. This ensures that the ASID pool is safely removed from the system, maintaining the integrity of the virtual memory management.",
    "input": "",
    "output": "definition\ndelete_asid_pool :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid_pool base ptr \\<equiv> do\n  assert (base && mask asid_low_bits = 0);\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n    pool \\<leftarrow> get_asid_pool ptr;\n    mapM (\\<lambda>offset. (when (pool (ucast offset) \\<noteq> None) $ do\n                          flush_space $ base + offset;\n                          invalidate_asid_entry $ base + offset\n                    od)) [0  .e.  (1 << asid_low_bits) - 1];\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>);\n    tcb \\<leftarrow> gets cur_thread;\n    set_vm_root tcb\n  od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Delete ASID: Deactivates and removes a page directory from the ASID pool, ensuring that the associated ASID is flushed and invalidated. This process maintains the integrity of the virtual memory system by updating the ASID pool and setting the VM root for the current thread.",
    "input": "",
    "output": "definition\ndelete_asid :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pd \\<equiv> do\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  (case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (ucast asid) = Some pd) $ do\n                flush_space asid;\n                invalidate_asid_entry asid;\n                pool' \\<leftarrow> return (pool (ucast asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set VM Root for Flush: Switch to a specific address space to perform a flush operation by checking and potentially updating the current thread's virtual memory root. If the current page directory does not match the target, a context switch is performed.\n\nFlush Operations: Perform different types of cache flush operations (clean, invalidate, clean and invalidate, or unify) on a specified range of virtual addresses, ensuring that the cache is synchronized with main memory.",
    "input": "",
    "output": "definition\nset_vm_root_for_flush :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"set_vm_root_for_flush pd asid \\<equiv> do\n    tcb \\<leftarrow> gets cur_thread;\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    not_is_pd \\<leftarrow> (case thread_root of\n                    ArchObjectCap (PageDirectoryCap cur_pd (Some _)) \\<Rightarrow> return (cur_pd \\<noteq> pd)\n                  | _ \\<Rightarrow> return True);\n    (if not_is_pd then do\n        arm_context_switch pd asid;\n        return True\n    od\n    else return False)\nod\"\n\ndefinition\ndo_flush :: \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\" where\n\"do_flush flush_type vstart vend pstart \\<equiv>\n    case flush_type of\n       Clean \\<Rightarrow> cleanCacheRange_RAM vstart vend pstart\n     | Invalidate \\<Rightarrow> invalidateCacheRange_RAM vstart vend pstart\n     | CleanInvalidate \\<Rightarrow> cleanInvalidateCacheRange_RAM vstart vend pstart\n     | Unify \\<Rightarrow> do\n         cleanCacheRange_PoU vstart vend pstart;\n         dsb;\n         invalidateCacheRange_I vstart vend pstart;\n         branchFlushRange vstart vend pstart;\n         isb\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flush Page Table Mappings: Invalidate the local TLB for a given ASID and flush mappings associated with a page table. Ensure that the virtual pointer is aligned to the section size, and if the hardware ASID is present, perform the TLB invalidation. If the root has been switched during the process, reset the VM root for the current thread.",
    "input": "",
    "output": "definition\nflush_table :: \"word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_table pd asid vptr pt \\<equiv> do\n    assert (vptr && mask (pageBitsForSize ARMSection) = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_ASID hw_asid;\n      when root_switched $ do\n        tcb \\<leftarrow> gets cur_thread;\n        set_vm_root tcb\n      od\n    od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flush Page Mappings: Invalidate the mappings associated with a given page in the virtual memory, ensuring that the Translation Lookaside Buffer (TLB) is updated. If a hardware ASID is present, it is used to invalidate the TLB entry, and the virtual machine root is reset if it was switched during the operation.",
    "input": "",
    "output": "definition\nflush_page :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_page page_size pd asid vptr\\<equiv> do\n    assert (vptr && mask pageBits = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_VAASID (vptr || ucast hw_asid);\n      when root_switched $ do\n          tcb \\<leftarrow> gets cur_thread;\n          set_vm_root tcb\n      od\n   od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Mapping: Determine the page directory in which a given page table is mapped, if any. This involves finding the page directory for the specified ASID, locating the appropriate slot, and checking if the page table address matches the one in the page directory entry.",
    "input": "",
    "output": "definition\npage_table_mapped :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n\"page_table_mapped asid vaddr pt \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    pd_slot \\<leftarrow> returnOk $ lookup_pd_slot pd vaddr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    case pde of\n      PageTablePDE addr _ _ \\<Rightarrow> returnOk $\n             if addrFromPPtr pt = addr then Some pd else None\n    | _ \\<Rightarrow> returnOk None\nodE <catch> (K $ return None)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page Table: Unmaps a specified page table from its page directory. If the page table is mapped, it invalidates the corresponding page directory entry, cleans the cache, and flushes the table to ensure the changes are effective.",
    "input": "",
    "output": "definition\nunmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page_table asid vaddr pt \\<equiv> do\n    pdOpt \\<leftarrow> page_table_mapped asid vaddr pt;\n    case pdOpt of\n      None \\<Rightarrow> return ()\n    | Some pd \\<Rightarrow> do\n        pd_slot \\<leftarrow> return $ lookup_pd_slot pd vaddr;\n        store_pde pd_slot InvalidPDE;\n        do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot);\n        flush_table pd asid vaddr pt\n    od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Mapping: Verify that a given frame is correctly mapped by a specified mapping entry. The function checks if the physical address and page size of the frame match the corresponding values in the page table or page directory entry.",
    "input": "",
    "output": "definition\ncheck_mapping_pptr :: \"obj_ref \\<Rightarrow> vmpage_size \\<Rightarrow> (obj_ref + obj_ref) \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"check_mapping_pptr pptr pgsz tablePtr \\<equiv> case tablePtr of\n   Inl ptePtr \\<Rightarrow> do\n     pte \\<leftarrow> get_pte ptePtr;\n     return $ case pte of\n       SmallPagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSmallPage\n     | LargePagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMLargePage\n     | _ \\<Rightarrow> False\n   od\n | Inr pdePtr \\<Rightarrow> do\n     pde \\<leftarrow> get_pde pdePtr;\n     return $ case pde of\n       SectionPDE x _ _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSection\n     | SuperSectionPDE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSuperSection\n     | _ \\<Rightarrow> False\n   od\"\n\n\ndefinition\n  \"last_byte_pte x \\<equiv> let pte_bits = 2 in x + ((1 << pte_bits) - 1)\"\n\ndefinition\n  \"last_byte_pde x \\<equiv> let pde_bits = 2 in x + ((1 << pde_bits) - 1)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page: Unmaps a page from the virtual address space if the given mapping details are still current. This involves locating the appropriate page directory, checking the mapping, invalidating the page table entries or page directory entries, and cleaning the cache. The operation ensures that the page is properly unmapped and the cache is updated to reflect the changes.",
    "input": "",
    "output": "definition\nunmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page pgsz asid vptr pptr \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    (case pgsz of\n          ARMSmallPage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                store_pte p InvalidPTE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMLargePage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                assert $ p && mask 6 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) [0, 4  .e.  60]);\n                mapM (swp store_pte InvalidPTE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE\n        | ARMSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                store_pde p InvalidPDE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMSuperSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                assert $ p && mask 6 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) [0, 4  .e.  60]);\n                mapM (swp store_pde InvalidPDE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE);\n    liftE $ flush_page pgsz pd asid vptr\nodE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Derive Capabilities: Ensures that PageTable and PageDirectory capabilities can only be derived if they have a virtual ASID and location assigned, preventing illegal operations and maintaining the integrity of address spaces.",
    "input": "",
    "output": "definition\n  arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\"\nwhere\n  \"arch_derive_cap c \\<equiv> case c of\n     PageTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageTableCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageDirectoryCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageDirectoryCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageCap dev r R pgs x \\<Rightarrow> returnOk (ArchObjectCap (PageCap dev r R pgs None))\n   | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n   | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Update Cap Data: Ensures that no user-modifiable data is stored in ARM-specific capabilities, maintaining the integrity and security of the capability system.",
    "input": "",
    "output": "definition\n  arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Finalize ARM-Specific Capabilities: Perform necessary actions to finalize ARM-specific capabilities, including deleting ASID pools, page directories, and page tables, and unmapping pages. Upon finalization, the capabilities are replaced with null capabilities.",
    "input": "",
    "output": "definition\n  arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n    (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n    delete_asid_pool b ptr;\n    return (NullCap, NullCap)\n    od\n  | (PageDirectoryCap ptr (Some a), True) \\<Rightarrow> do\n    delete_asid a ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n    unmap_page_table a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageCap _ ptr _ s (Some (a, v)), _) \\<Rightarrow> do\n     unmap_page s a v ptr;\n     return (NullCap, NullCap)\n  od\n  | _ \\<Rightarrow> return (NullCap, NullCap)\"\n\n\ndefinition (* prepares a thread for deletion; nothing to do for ARM *)\n  prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"prepare_thread_delete p \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Valid IPC Buffer Check: Ensures that the virtual address space capability for an IPC buffer is a valid page directory, and checks the alignment of the virtual pointer. If the capability is not a valid page directory or the virtual pointer is not properly aligned, it throws an error.",
    "input": "",
    "output": "definition\n  is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv> \\<exists>r a. c = ArchObjectCap (PageDirectoryCap r (Some a))\"\n\ndefinition\ncheck_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n\"check_valid_ipc_buffer vptr c \\<equiv> case c of\n  (ArchObjectCap (PageCap False _ _ _ _)) \\<Rightarrow> doE\n    whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError;\n    returnOk ()\n  odE\n| _ \\<Rightarrow> throwError IllegalOperation\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode VM Attributes: Extract and decode the virtual memory attributes from a 32-bit word, setting specific attributes based on the bits within the word. The attributes include PageCacheable, ParityEnabled, and XNever, which are conditionally included based on the corresponding bit values.",
    "input": "",
    "output": "definition\nattribs_from_word :: \"word32 \\<Rightarrow> vm_attributes\" where\n\"attribs_from_word w \\<equiv>\n  let V = (if w !!0 then {PageCacheable} else {});\n      V' = (if w!!1 then insert ParityEnabled V else V)\n  in if w!!2 then insert XNever V' else V'\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Mapping Data: Modify the mapping data associated with a page or page table capability. This ensures that the capability's metadata is updated to reflect the new mapping information.",
    "input": "",
    "output": "definition\n  update_map_data :: \"arch_cap \\<Rightarrow> (word32 \\<times> word32) option \\<Rightarrow> arch_cap\" where\n  \"update_map_data cap m \\<equiv> case cap of PageCap dev p R sz _ \\<Rightarrow> PageCap dev p R sz m\n                                     | PageTableCap p _ \\<Rightarrow> PageTableCap p m\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Resolve Virtual Address: Determine the frame and size of a given virtual address by traversing the page directory and page table, returning the corresponding frame and page size if the address is valid.",
    "input": "",
    "output": "definition\n  resolve_vaddr :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> ((vmpage_size \\<times> obj_ref) option, 'z::state_ext) s_monad\"\nwhere\n  \"resolve_vaddr pd vaddr \\<equiv> do\n     pd_slot \\<leftarrow> return $ lookup_pd_slot pd vaddr;\n     pde \\<leftarrow> get_master_pde pd_slot;\n     case pde of\n         SectionPDE f _ _ _ \\<Rightarrow> return $ Some (ARMSection, f)\n       | SuperSectionPDE f _ _ \\<Rightarrow> return $ Some (ARMSuperSection, f)\n       | PageTablePDE t _ _ \\<Rightarrow> (do\n           pt \\<leftarrow> return $ ptrFromPAddr t;\n           pte_slot \\<leftarrow> return $ lookup_pt_slot_no_fail pt vaddr;\n           pte \\<leftarrow> get_master_pte pte_slot;\n           case pte of\n               LargePagePTE f _ _ \\<Rightarrow> return $ Some (ARMLargePage, f)\n             | SmallPagePTE f _ _ \\<Rightarrow> return $ Some (ARMSmallPage, f)\n             | _ \\<Rightarrow> return None\n         od)\n       | _ \\<Rightarrow> return None\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Pointer in User Frame: A pointer is considered to be inside a user frame if its top bits, when masked, point to a data page in the kernel heap.",
    "input": "",
    "output": "definition\n  in_user_frame :: \"word32 \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n  \"in_user_frame p s \\<equiv>\n   \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) =\n        Some (ArchObj (DataPage False sz))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Numeric Value Visibility: Ensure the numeric value of `msg_align_bits` is explicitly visible by unfolding and simplifying its definition.",
    "input": "",
    "output": "lemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual ASID High Bits: Extract the high bits of a virtual ASID, which are used to index into the ASID table for managing address space identifiers in the ARM architecture.",
    "input": "",
    "output": "text \\<open>The high bits of a virtual ASID.\\<close>\ndefinition\n  asid_high_bits_of :: \"asid \\<Rightarrow> 7 word\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"\n\nlocale_abbrev\n  \"asid_table \\<equiv> \\<lambda>s. arm_asid_table (arch_state s)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Manipulate VSpace Structures: Access and modify ASID pools, page directories, and page tables within the kernel heap to manage virtual memory mappings and address space identifiers.",
    "input": "",
    "output": "text \\<open>Manipulate ASID pools, page directories and page tables in the kernel\nheap.\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access and Management: Provides functions to get and set ASID pools and page directories, allowing for the manipulation of virtual memory structures. Additionally, it includes a function to set the current page directory in the ARM architecture, ensuring that the translation table base register is updated and the changes are synchronized.",
    "input": "",
    "output": "locale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\"\n  where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"\n\ndefinition\n  get_asid_pool :: \"obj_ref \\<Rightarrow> (10 word \\<rightharpoonup> obj_ref,'z::state_ext) s_monad\" where\n  \"get_asid_pool ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (ASIDPool pool) \\<Rightarrow> return pool\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_asid_pool :: \"obj_ref \\<Rightarrow> (10 word \\<rightharpoonup> obj_ref) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"set_asid_pool ptr pool \\<equiv> set_object ptr (ArchObj (arch_kernel_obj.ASIDPool pool))\"\n\ndefinition\n  get_pd :: \"obj_ref \\<Rightarrow> (12 word \\<Rightarrow> pde,'z::state_ext) s_monad\" where\n  \"get_pd ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageDirectory pd) \\<Rightarrow> return pd\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pd :: \"obj_ref \\<Rightarrow> (12 word \\<Rightarrow> pde) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pd ptr pd \\<equiv> set_object ptr (ArchObj (PageDirectory pd))\"\n\ndefinition\n  set_current_pd :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_current_pd pd \\<equiv> do\n     dsb;\n     writeTTBR0 ((pd && 0xffffe000) || 0x18);\n     isb\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Page Directory Access: Provides functions to retrieve and modify entries in the page directory and page table. The `get_pde` and `store_pde` functions access and update specific entries in the page directory, while `get_pt` and `set_pt` functions handle the retrieval and modification of the entire page table.",
    "input": "",
    "output": "definition\n  get_pde :: \"obj_ref \\<Rightarrow> (pde,'z::state_ext) s_monad\" where\n  \"get_pde ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pd_bits);\n     offset \\<leftarrow> return ((ptr && mask pd_bits) >> 2);\n     pd \\<leftarrow> get_pd base;\n     return $ pd (ucast offset)\n   od\"\n\ndefinition\n  store_pde :: \"obj_ref \\<Rightarrow> pde \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pde p pde \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pd_bits);\n    offset \\<leftarrow> return ((p && mask pd_bits) >> 2);\n    pd \\<leftarrow> get_pd base;\n    pd' \\<leftarrow> return $ pd (ucast offset := pde);\n    set_pd base pd'\n  od\"\n\n\ndefinition\n  get_pt :: \"obj_ref \\<Rightarrow> (word8 \\<Rightarrow> pte,'z::state_ext) s_monad\" where\n  \"get_pt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pt :: \"obj_ref \\<Rightarrow> (word8 \\<Rightarrow> pte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pt ptr pt \\<equiv> set_object ptr (ArchObj (PageTable pt))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Entry Access: Retrieve and store PTEs in the page table. The functions calculate the base address and offset of the PTE, access the page table, and either return or update the PTE at the specified location.",
    "input": "",
    "output": "definition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> 2);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> 2);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Copy Global Mappings: Copies the mappings that create the kernel window from the global page directory to a new page directory object, ensuring that the kernel window is consistently mapped in every virtual address space.",
    "input": "",
    "output": "text \\<open>The kernel window is mapped into every virtual address space from the\n@{term kernel_base} pointer upwards. This function copies the mappings which\ncreate the kernel window into a new page directory object.\\<close>\ndefinition\ncopy_global_mappings :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"copy_global_mappings new_pd \\<equiv> do\n    global_pd \\<leftarrow> gets (arm_global_pd \\<circ> arch_state);\n    pde_bits \\<leftarrow> return 2;\n    pd_size \\<leftarrow> return (1 << (pd_bits - pde_bits));\n    mapM_x (\\<lambda>index. do\n        offset \\<leftarrow> return (index << pde_bits);\n        pde \\<leftarrow> get_pde (global_pd + offset);\n        store_pde (new_pd + offset) pde\n    od) [kernel_base >> 20  .e.  pd_size - 1]\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Compute Page Directory Entry Pointer: Given a page-directory reference and a virtual address, compute the pointer to the corresponding page directory entry in kernel memory.",
    "input": "",
    "output": "definition\nlookup_pd_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> word32\" where\n\"lookup_pd_slot pd vptr \\<equiv>\n    let pd_index = vptr >> 20\n    in pd + (pd_index << 2)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup Page Table Slot: Given a page-directory reference and a virtual address, the function computes a pointer to the corresponding page table entry (PTE) in kernel memory. The function fails if the virtual address is mapped on a section or super section, ensuring that only valid PTEs are accessed.",
    "input": "",
    "output": "definition\nlookup_pt_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"lookup_pt_slot pd vptr \\<equiv> doE\n    pd_slot \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    (case pde of\n          PageTablePDE ptab _ _ \\<Rightarrow>   (doE\n            pt \\<leftarrow> returnOk (ptrFromPAddr ptab);\n            pt_index \\<leftarrow> returnOk ((vptr >> 12) && 0xff);\n            pt_slot \\<leftarrow> returnOk (pt + (pt_index << 2));\n            returnOk pt_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability 20)\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup Page Table Slot: Computes the page table slot address for a given virtual page number (VPN) within a known page table, ensuring that the operation does not fail.",
    "input": "",
    "output": "definition\n  lookup_pt_slot_no_fail :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> word32\"\nwhere\n  \"lookup_pt_slot_no_fail pt vptr \\<equiv>\n     let pt_index = ((vptr >> 12) && 0xff)\n     in pt + (pt_index << 2)\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Virtual Page Alignment: Ensure that the given virtual page pointer is aligned to the specified page size, throwing an alignment error if the condition is not met.",
    "input": "",
    "output": "text \\<open>This definition ensures that the given pointer is aligned\nto the given page size.\\<close>\n\ndefinition\n  check_vp_alignment :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $\n       throwError AlignmentError\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Convert Invocation Label to Flush Type: Maps architecture-specific invocation labels to corresponding flush types, enabling the system to determine the appropriate method for handling data and instruction cache operations.",
    "input": "",
    "output": "definition\n  label_to_flush_type :: \"invocation_label \\<Rightarrow> flush_type\"\nwhere\n  \"label_to_flush_type label \\<equiv> case label of\n       ArchInvocationLabel ARMPDClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPageClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPDInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPageInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPDCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPageCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPDUnify_Instruction \\<Rightarrow> Unify\n     | ArchInvocationLabel ARMPageUnify_Instruction \\<Rightarrow> Unify\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-specific Invocation Decoding: Decode and validate architecture-specific system calls, including operations on page directories, page tables, pages, ASID controls, and ASID pools. These operations ensure that the system call parameters are correctly interpreted and validated, and appropriate actions such as mapping, unmapping, flushing, and managing ASID pools are performed. \n\n- **Page Directory Operations**: Validate and perform operations like flushing page directories, ensuring valid addresses and permissions.\n- **Page Table Operations**: Map and unmap page tables, ensuring correct alignment and permissions, and handling additional capabilities.\n- **Page Operations**: Map, unmap, and flush pages, ensuring valid addresses, permissions, and alignments.\n- **ASID Control Operations**: Create ASID pools, ensuring free ASIDs and valid frame allocations.\n- **ASID Pool Operations**: Assign ASIDs to page directories, ensuring valid pool and directory associations.\n- **IRQ Control Operations**: Issue IRQ handlers, ensuring valid IRQ numbers and target slots.",
    "input": "",
    "output": "text \\<open>This definition decodes architecture-specific invocations.\n\\<close>\n\ndefinition\n  page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\nwhere\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"\n\n\ndefinition\n  arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n\"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n\n  PageDirectoryCap _ _ \\<Rightarrow>\n    if isPDFlushLabel (invocation_type label) then\n    if length args > 1\n    then let start = args ! 0;\n             end = args ! 1\n    in doE\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            whenE (start \\<ge> kernel_base \\<or> end > kernel_base) $ throwError IllegalOperation;\n            (pd,asid) \\<leftarrow> (case cap of\n                    PageDirectoryCap pd (Some asid) \\<Rightarrow> returnOk (pd,asid)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 0);\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 0;\n            frame_info \\<leftarrow> liftE $ resolve_vaddr pd start;\n            case frame_info of\n                None \\<Rightarrow> returnOk $ InvokePageDirectory PageDirectoryNothing\n              | Some (frame_size, frame_base) \\<Rightarrow>\n                    let base_start = page_base start frame_size;\n                        base_end = page_base (end - 1) frame_size;\n                        offset = start && mask (pageBitsForSize frame_size);\n                        pstart = frame_base + offset\n                    in doE\n                        whenE (base_start \\<noteq> base_end) $ throwError $\n                            RangeError start (base_start + mask (pageBitsForSize frame_size));\n                        returnOk $ InvokePageDirectory $\n                            PageDirectoryFlush (label_to_flush_type (invocation_type label))\n                            start (end - 1) pstart pd asid\n                    odE\n    odE\n    else throwError TruncatedMessage\n    else throwError IllegalOperation\n\n| PageTableCap p mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageTableMap then\n    if length args > 1 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             attr = args ! 1;\n             pd_cap = fst (extra_caps ! 0)\n    in doE\n            whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            whenE (vaddr \\<ge> kernel_base) $ throwError $ InvalidArgument 0;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            pd_index \\<leftarrow> returnOk (shiftr vaddr 20);\n            vaddr' \\<leftarrow> returnOk (vaddr && ~~ mask 20);\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << 2));\n            oldpde \\<leftarrow> liftE $ get_master_pde pd_slot;\n            unlessE (oldpde = InvalidPDE) $ throwError DeleteFirst;\n            pde \\<leftarrow> returnOk (PageTablePDE (addrFromPPtr p)\n                               (attribs_from_word attr \\<inter> {ParityEnabled}) 0);\n            returnOk $ InvokePageTable $\n                PageTableMap\n                (ArchObjectCap $ PageTableCap p (Some (asid, vaddr')))\n                cte pde pd_slot\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageTableUnmap\n    then doE\n            final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n            unlessE final $ throwError RevokeFirst;\n            returnOk $ InvokePageTable $ PageTableUnmap (ArchObjectCap cap) cte\n    odE\n    else throwError IllegalOperation\n\n| PageCap dev p R pgsz mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageMap then\n    if length args > 2 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             rights_mask = args ! 1;\n             attr = args ! 2;\n             pd_cap = fst (extra_caps ! 0)\n        in doE\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            case mapped_address of\n              Some (asid', vaddr') \\<Rightarrow> doE\n                whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n                whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0)\n              odE\n            | None \\<Rightarrow> doE\n                vtop \\<leftarrow> returnOk (vaddr + (1 << (pageBitsForSize pgsz)) - 1);\n                whenE (vtop \\<ge> kernel_base) $ throwError $ InvalidArgument 0\n              odE;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            vm_rights \\<leftarrow> returnOk (mask_vm_rights R (data_to_rights rights_mask));\n            check_vp_alignment pgsz vaddr;\n            entries \\<leftarrow> create_mapping_entries (addrFromPPtr p)\n                                              vaddr pgsz vm_rights\n                                              (attribs_from_word attr) pd;\n            ensure_safe_mapping entries;\n            returnOk $ InvokePage $ PageMap asid\n                (ArchObjectCap $ PageCap dev p R pgsz (Some (asid, vaddr)))\n                cte entries\n        odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageUnmap\n    then  returnOk $ InvokePage $ PageUnmap cap cte\n    else if isPageFlushLabel (invocation_type label) then\n        if length args > 1\n        then let start = args ! 0;\n                 end = args ! 1\n        in doE\n            (asid, vaddr) \\<leftarrow> (case mapped_address of\n                Some a \\<Rightarrow> returnOk a\n              | _ \\<Rightarrow> throwError IllegalOperation);\n            pd \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            page_size \\<leftarrow> returnOk $ 1 << pageBitsForSize pgsz;\n            whenE (start \\<ge> page_size \\<or> end > page_size) $ throwError $ InvalidArgument 0;\n            returnOk $ InvokePage $ PageFlush\n                (label_to_flush_type (invocation_type label)) (start + vaddr)\n                (end + vaddr - 1) (addrFromPPtr p + start) pd asid\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageGetAddress\n    then returnOk $ InvokePage $ PageGetAddr p\n  else  throwError IllegalOperation\n\n| ASIDControlCap \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMASIDControlMakePool then\n    if length args > 1 \\<and> length extra_caps > 1\n    then let index = args ! 0;\n             depth = args ! 1;\n             (untyped, parent_slot) = extra_caps ! 0;\n             root = fst (extra_caps ! 1)\n         in doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            free_set \\<leftarrow> returnOk (- dom asid_table \\<inter> {x. x \\<le> 2 ^ asid_high_bits - 1});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n            base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n            (p,n) \\<leftarrow> (case untyped of UntypedCap False p n f \\<Rightarrow> returnOk (p,n)\n                                    | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            frame \\<leftarrow> (if n = pageBits\n                      then doE\n                        ensure_no_children parent_slot;\n                        returnOk p\n                      odE\n                      else  throwError $ InvalidCapability 1);\n            dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n            ensure_empty dest_slot;\n            returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n        odE\n    else  throwError TruncatedMessage\n    else  throwError IllegalOperation\n\n| ASIDPoolCap p base \\<Rightarrow>\n  if invocation_type label = ArchInvocationLabel ARMASIDPoolAssign then\n  if length extra_caps > 0\n  then\n    let (pd_cap, pd_cap_slot) = extra_caps ! 0\n     in case pd_cap of\n          ArchObjectCap (PageDirectoryCap _ None) \\<Rightarrow> doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n            whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n            whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n            pool \\<leftarrow> liftE $ get_asid_pool p;\n            free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n            returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pd_cap_slot\n          odE\n        | _ \\<Rightarrow>  throwError $ InvalidCapability 1\n  else  throwError TruncatedMessage\n  else  throwError IllegalOperation\"\n\n\ndefinition\n  arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n \"arch_data_to_obj_type n \\<equiv>\n  if n = 0 then Some PageDirectoryObj\n  else if n = 1 then Some SmallPageObj\n  else if n = 2 then Some LargePageObj\n  else if n = 3 then Some SectionObj\n  else if n = 4 then Some SuperSectionObj\n  else if n = 5 then Some PageTableObj\n  else None\"\n\ndefinition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> whenE (irq > maxIRQ) $ throwError (RangeError 0 maxIRQ)\"\n\ndefinition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n    (if invocation_type label = ArchInvocationLabel ARMIRQIssueIRQHandler\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n\n          returnOk $ ArchIRQControlIssue irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM System Call Arguments: Define the datatypes for arguments used in ARM-specific system calls, including operations for page directory and table management, ASID control, and page manipulation. These datatypes support various actions such as flushing, mapping, and unmapping, ensuring that the system can handle memory and address space management effectively.",
    "input": "",
    "output": "datatype flush_type = Clean | Invalidate | CleanInvalidate | Unify\n\ndatatype page_directory_invocation =\n    PageDirectoryFlush (pd_flush_type: flush_type) (pd_flush_start: vspace_ref)\n                       (pd_flush_end: vspace_ref) (pd_flush_pstart: word32)\n                       (pd_flush_pd: obj_ref) (pd_flush_asid: asid)\n  | PageDirectoryNothing\n\ndatatype page_table_invocation =\n    PageTableMap cap cslot_ptr pde obj_ref\n  | PageTableUnmap cap cslot_ptr\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation\n     = PageMap\n         (page_map_asid: asid)\n         (page_map_cap: cap)\n         (page_map_ct_slot: cslot_ptr)\n         (page_map_entries: \"pte \\<times> (obj_ref list) + pde \\<times> (obj_ref list)\")\n     | PageUnmap\n         (page_unmap_cap: arch_cap)\n         (page_unmap_cap_slot: cslot_ptr)\n     | PageFlush\n         (page_flush_type: flush_type)\n         (page_flush_start: vspace_ref)\n         (page_flush_end: vspace_ref)\n         (page_flush_pstart: word32)\n         (page_flush_pd: obj_ref)\n         (page_flush_asid: asid)\n     | PageGetAddr\n         (page_get_paddr: obj_ref)\n\ndatatype arch_invocation\n     = InvokePageTable page_table_invocation\n     | InvokePageDirectory page_directory_invocation\n     | InvokePage page_invocation\n     | InvokeASIDControl asid_control_invocation\n     | InvokeASIDPool asid_pool_invocation\n\ndatatype arch_copy_register_sets = ARMNoExtraRegisters\n\ndefinition \"ArchDefaultExtraRegisters \\<equiv> ARMNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    ArchIRQControlIssue irq cslot_ptr cslot_ptr bool\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Define Architecture-Specific Capabilities: Introduce an ASID as a 32-bit word and define VM attributes including parity enable, page cacheability, global, and XNever. These attributes are used to specify various memory properties in the system.",
    "input": "",
    "output": "text \\<open>An ASID is simply a word.\\<close>\ntype_synonym asid = \"word32\"\n\ndatatype vm_attribute = ParityEnabled | PageCacheable | Global | XNever\ntype_synonym vm_attributes = \"vm_attribute set\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM Architecture-Specific Capabilities: Defines a set of architecture-specific capabilities including ASID pools, ASID controller, page directories, page tables, and page mappings. These capabilities are used to manage memory and virtual address spaces in the ARM kernel.",
    "input": "",
    "output": "text \\<open>The ARM kernel supports capabilities for ASID pools and an ASID controller capability,\nalong with capabilities for page directories, page tables, and page mappings.\\<close>\n\ndatatype arch_cap =\n   ASIDPoolCap obj_ref asid\n | ASIDControlCap\n | PageCap bool obj_ref cap_rights vmpage_size \"(asid * vspace_ref) option\"\n | PageTableCap obj_ref \"(asid * vspace_ref) option\"\n | PageDirectoryCap obj_ref \"asid option\"\n\nlemmas arch_cap_cases =\n  arch_cap.induct[where arch_cap=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P, simplified, rule_format]\n\nlemmas arch_cap_cases_asm =\narch_cap.induct[where arch_cap=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n  simplified, rule_format, rotated -1]\n\ndefinition\n  is_page_cap :: \"arch_cap \\<Rightarrow> bool\" where\n  \"is_page_cap c \\<equiv> \\<exists>x0 x1 x2 x3 x4. c = PageCap x0 x1 x2 x3 x4\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Objects: Define the structure and properties of architecture-specific objects, including page directory entries (PDEs) and page table entries (PTEs), which can contain various types of mappings and references. Additionally, it defines the size, device status, and object references for different types of architectural capabilities, ensuring that memory and capabilities are correctly managed and referenced in the system.",
    "input": "",
    "output": "text \\<open>This section gives the types and auxiliary definitions for the\narchitecture-specific objects: a page directory entry (@{text \"pde\"})\ncontains either an invalid entry, a page table reference, a section\nreference, or a super-section reference; a page table entry contains\neither an invalid entry, a large page, or a small page mapping;\nfinally, an architecture-specific object is either an ASID pool, a\npage table, a page directory, or a data page used to model user\nmemory.\n\\<close>\n\ndatatype pde =\n   InvalidPDE\n | PageTablePDE obj_ref vm_attributes machine_word\n | SectionPDE obj_ref vm_attributes machine_word cap_rights\n | SuperSectionPDE obj_ref vm_attributes cap_rights\n\ndatatype pte =\n   InvalidPTE\n | LargePagePTE obj_ref vm_attributes cap_rights\n | SmallPagePTE obj_ref vm_attributes cap_rights\n\ndatatype arch_kernel_obj =\n   ASIDPool \"10 word \\<rightharpoonup> obj_ref\"\n | PageTable \"word8 \\<Rightarrow> pte\"\n | PageDirectory \"12 word \\<Rightarrow> pde\"\n | DataPage bool vmpage_size\n\nlemmas arch_kernel_obj_cases =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P,\n                         simplified, rule_format]\n\nlemmas arch_kernel_obj_cases_asm =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n                         simplified, rule_format, rotated -1]\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 4\"\n\nprimrec\n  arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\nwhere\n  \"arch_obj_size (ASIDPoolCap p as) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (PageCap dev x rs sz as4) = pageBitsForSize sz\"\n| \"arch_obj_size (PageDirectoryCap x as2) = 14\"\n| \"arch_obj_size (PageTableCap x as3) = 10\"\n\nprimrec\n  arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_cap_is_device (PageCap dev x rs sz as4) = dev\"\n| \"arch_cap_is_device ASIDControlCap = False\"\n| \"arch_cap_is_device (ASIDPoolCap p as) = False\"\n| \"arch_cap_is_device (PageTableCap x as3) = False\"\n| \"arch_cap_is_device (PageDirectoryCap x as2) = False\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 9\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 4\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 29\"\n\nprimrec\n  arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\nwhere\n  \"arch_kobj_size (ASIDPool p) = pageBits\"\n| \"arch_kobj_size (PageTable pte) = 10\"\n| \"arch_kobj_size (PageDirectory pde) = 14\"\n| \"arch_kobj_size (DataPage dev sz) = pageBitsForSize sz\"\n\nprimrec\n  aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\nwhere\n  \"aobj_ref (ASIDPoolCap p as) = Some p\"\n| \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref (PageCap dev x rs sz as4) = Some x\"\n| \"aobj_ref (PageDirectoryCap x as2) = Some x\"\n| \"aobj_ref (PageTableCap x as3) = Some x\"\n\nprimrec (nonexhaustive)\n  acap_rights :: \"arch_cap \\<Rightarrow> cap_rights\"\nwhere\n \"acap_rights (PageCap dev x rs sz as) = rs\"\n\ndefinition\n  acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n \"acap_rights_update rs ac \\<equiv> case ac of\n    PageCap dev x rs' sz as \\<Rightarrow> PageCap dev x (validate_vm_rights rs) sz as\n  | _                   \\<Rightarrow> ac\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Object Types: Defines a set of ARM-specific object types, including different page sizes, page tables, and ASID pools. Each object type has a corresponding default capability and default object, which are used to initialize the architecture-specific objects with appropriate properties and permissions.",
    "input": "",
    "output": "datatype\n  aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | SectionObj\n  | SuperSectionObj\n  | PageTableObj\n  | PageDirectoryObj\n  | ASIDPoolObj\n\ndefinition\n  arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\"\nwhere\n  \"arch_is_frame_type aobj \\<equiv> case aobj of\n         SmallPageObj \\<Rightarrow> True\n       | LargePageObj \\<Rightarrow> True\n       | SectionObj \\<Rightarrow> True\n       | SuperSectionObj \\<Rightarrow> True\n       | _ \\<Rightarrow> False\"\n\ndefinition\n  arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\" where\n \"arch_default_cap tp r n dev \\<equiv> case tp of\n  SmallPageObj \\<Rightarrow> PageCap dev r vm_read_write ARMSmallPage None\n  | LargePageObj \\<Rightarrow> PageCap dev r vm_read_write ARMLargePage None\n  | SectionObj \\<Rightarrow> PageCap dev r vm_read_write ARMSection None\n  | SuperSectionObj \\<Rightarrow> PageCap dev r vm_read_write ARMSuperSection None\n  | PageTableObj \\<Rightarrow> PageTableCap r None\n  | PageDirectoryObj \\<Rightarrow> PageDirectoryCap r None\n  | ASIDPoolObj \\<Rightarrow> ASIDPoolCap r 0\" (* unused *)\n\ndefinition\n  default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\" where\n \"default_arch_object tp dev n \\<equiv> case tp of\n    SmallPageObj \\<Rightarrow> DataPage dev ARMSmallPage\n  | LargePageObj \\<Rightarrow> DataPage dev ARMLargePage\n  | SectionObj \\<Rightarrow> DataPage dev ARMSection\n  | SuperSectionObj \\<Rightarrow> DataPage dev ARMSuperSection\n  | PageTableObj \\<Rightarrow> PageTable (\\<lambda>x. InvalidPTE)\n  | PageDirectoryObj \\<Rightarrow> PageDirectory (\\<lambda>x. InvalidPDE)\n  | ASIDPoolObj \\<Rightarrow> ASIDPool (\\<lambda>_. None)\"\n\ntype_synonym hw_asid = word8\n\ntype_synonym arm_vspace_region_uses = \"vspace_ref \\<Rightarrow> arm_vspace_region_use\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific State: The ARM-specific state includes the first level of the ASID table, a mapping from hardware ASIDs to seL4 ASIDs, the next hardware ASID to preempt, an inverse map from seL4 ASIDs to hardware ASIDs along with their associated page directories, and the address and description of the page directory and page tables for the shared address space. This ensures that the architecture-specific details are managed and maintained for efficient memory management and virtualization.",
    "input": "",
    "output": "text \\<open>The architecture-specific state for the ARM model\nconsists of the first level of the ASID table (@{text \"arm_asid_table\"}), a\nmap from hardware ASIDs to seL4 ASIDs (@{text \"arm_hwasid_table\"}),\nthe next hardware ASID to preempt (@{text \"arm_next_asid\"}), the\ninverse map from seL4 ASIDs to hardware ASIDs (first component of\n@{text \"arm_asid_map\"}), and the address of the page directory and\npage tables mapping the shared address space, along with a description\nof this space (@{text \"arm_global_pd\"}, @{text \"arm_global_pts\"}, and\n@{text \"arm_kernel_vspace\"} respectively).\n\nHardware ASIDs are only ever associated with seL4 ASIDs that have a\ncurrently active page directory. The second component of\n@{text \"arm_asid_map\"} values is the address of that page directory.\n\\<close>\n\nend\n\nqualify ARM_A (in Arch)\n\nrecord arch_state =\n  arm_asid_table    :: \"7 word \\<rightharpoonup> obj_ref\"\n  arm_hwasid_table  :: \"ARM_A.hw_asid \\<rightharpoonup> ARM_A.asid\"\n  arm_next_asid     :: ARM_A.hw_asid\n  arm_asid_map      :: \"ARM_A.asid \\<rightharpoonup> (ARM_A.hw_asid \\<times> obj_ref)\"\n  arm_global_pd     :: obj_ref\n  arm_global_pts    :: \"obj_ref list\"\n  arm_kernel_vspace :: ARM_A.arm_vspace_region_uses\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  pd_bits :: \"nat\" where\n  \"pd_bits \\<equiv> pageBits + 2\"\n\ndefinition\n  pt_bits :: \"nat\" where\n  \"pt_bits \\<equiv> pageBits - 2\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM-Specific Data Types: Define a set of data types for ARM architecture-specific kernel objects, including AASIDPool, APageTable, APageDirectory, AUserData, and ADeviceData. These types are used to classify different kinds of memory management structures and data pages, ensuring that the system can correctly manage and interact with these objects based on their specific roles in the ARM architecture.",
    "input": "",
    "output": "datatype aa_type =\n    AASIDPool\n  | APageTable\n  | APageDirectory\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\"\nwhere\n \"aa_type ao \\<equiv> (case ao of\n           PageTable pt             \\<Rightarrow> APageTable\n         | PageDirectory pd         \\<Rightarrow> APageDirectory\n         | DataPage dev sz          \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n         | ASIDPool f               \\<Rightarrow> AASIDPool)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Badge Bits Definition: The badge word is defined to have 28 bits.",
    "input": "",
    "output": "definition\n  badge_bits :: nat where\n  badge_bits_def [simp]: \"badge_bits \\<equiv> 28\"\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM-Specific TCB: Defines architecture-specific data types and structures for the Thread Control Block (TCB) tailored to ARM architecture, ensuring that the TCB can effectively manage and represent ARM-specific thread state and control information.",
    "input": "",
    "output": "qualify ARM_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific TCB Register Management: Provides functions to set and get user registers in the architecture-specific part of the TCB, ensuring that the register context is correctly updated and accessed.",
    "input": "",
    "output": "definition\n  arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_set_registers regs a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := UserContext regs \\<rparr>\"\n\ndefinition\n  arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\"\nwhere\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Fault Handling: Generate and handle architecture-specific fault messages. The system constructs a fault message containing the program counter, virtual pointer, and architecture-specific data, and processes the reply to the fault, returning a boolean value indicating successful handling.",
    "input": "",
    "output": "(*\nFunctions for fault handling.\n*)\n\nchapter \\<open>arch fault related functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData) od\"\n\ndefinition\n  handle_arch_fault_reply :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_arch_fault_reply vmf thread x y \\<equiv> return True\"\n\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-specific TCB Functions: Provide architecture-specific operations for sanitizing register values and managing post-modification actions. The sanitization function ensures that specific registers, such as the CPSR, are set to valid values, while the post-modification function handles any necessary actions after modifying thread registers.",
    "input": "",
    "output": "(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"sanitise_register t r v \\<equiv> case r of\n      CPSR \\<Rightarrow> (v && 0xf8000000) || 0x150\n    | _    \\<Rightarrow> v\"\n\n\ndefinition\n  arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\nwhere\n  \"arch_get_sanitise_register_info t \\<equiv> return False\"\n\ndefinition\n  arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\nwhere\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "CNode Capability Update: Extract and update the guard size and guard bits from the provided data, ensuring that the new values are correctly masked and shifted to maintain the integrity of the cnode capability.",
    "input": "",
    "output": "definition\n  update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 18;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capabilities: Distinguish between physical and non-physical capabilities, where ASIDControlCap is treated as a non-physical capability, and all other architectural capabilities are considered physical.",
    "input": "",
    "output": "definition\n  arch_is_physical :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_is_physical cap \\<equiv> case cap of ASIDControlCap \\<Rightarrow> False | _ \\<Rightarrow> True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check if Two Architectural Capabilities Refer to the Same or Overlapping Regions: Determine whether two architectural capabilities refer to the same object or if one capability's region is contained within the region of the other. This ensures that the capabilities are compatible in terms of their memory regions.",
    "input": "",
    "output": "fun\n  arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_same_region_as (PageCap dev r R s x) (PageCap dev' r' R' s' x') =\n   (let\n     topA = r + (1 << pageBitsForSize s) - 1;\n     topB = r' + (1 << pageBitsForSize s') - 1\n   in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB)\"\n| \"arch_same_region_as (PageTableCap r x) (PageTableCap r' x') = (r' = r)\"\n| \"arch_same_region_as (PageDirectoryCap r x) (PageDirectoryCap r' x') = (r' = r)\"\n| \"arch_same_region_as ASIDControlCap ASIDControlCap = True\"\n| \"arch_same_region_as (ASIDPoolCap r a) (ASIDPoolCap r' a') = (r' = r)\"\n| \"arch_same_region_as _ _ = False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Arch Capabilities for Same Object: Determine if two architecture capabilities refer to the same object by comparing their device, reference, and page size, and ensuring the reference is within the valid range. If they are not of the same type, use a generic region comparison.",
    "input": "",
    "output": "definition\n  same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n \"same_aobject_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (PageCap dev ref _ pgsz _,PageCap dev' ref' _ pgsz' _)\n          \\<Rightarrow> (dev, ref, pgsz) = (dev', ref', pgsz')\n              \\<and> ref \\<le> ref + 2 ^ pageBitsForSize pgsz - 1\n    | _ \\<Rightarrow> arch_same_region_as cp cp')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capability Revocation: Defines that no capability is revocable by another, as the function always returns false.",
    "input": "",
    "output": "declare same_aobject_as_def[simp]\n\ndefinition\n  arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"arch_is_cap_revocable c c' \\<equiv> False\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Instantiation for ARM Architecture: Defines concrete types for abstract type names, including object references, virtual space references, data, capability references, and length types, as well as specific lengths and indices for ASID (Address Space Identifier) components.",
    "input": "",
    "output": "type_synonym obj_ref            = machine_word\ntype_synonym vspace_ref         = machine_word\n\ntype_synonym data               = machine_word\ntype_synonym cap_ref            = \"bool list\"\ntype_synonym length_type        = machine_word\n\ntype_synonym asid_low_len       = 10\ntype_synonym asid_low_index    = \"asid_low_len word\"\n\ntype_synonym asid_high_len      = 7\ntype_synonym asid_high_index    = \"asid_high_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Representation: The ASID is represented as a machine word, with an invariant that the extra bits beyond the 17-bit ASID length must be zero.",
    "input": "",
    "output": "type_synonym asid_len           = 17\ntype_synonym asid_rep_len       = machine_word_len\ntype_synonym asid               = \"asid_rep_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Conversions: Define conversions between different data types, including identity functions for object and virtual space references, conversion from natural numbers to length types, and bitwise operations for combining notification badges and messages. Additionally, it includes conversions from data to various word sizes and capability pointers.",
    "input": "",
    "output": "definition\n  oref_to_data   :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_oref   :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition\n  vref_to_data   :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_vref   :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition\n  nat_to_len     :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition\n  data_to_nat    :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition\n  data_to_16     :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition\n  data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition\n  combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition\n  combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Data Conversion Simplifications: Provide simplification rules for converting between different data types, including object references, virtual references, natural numbers, 16-bit values, and capability pointers. These conversions ensure consistency and facilitate automatic unfolding in proofs.",
    "input": "",
    "output": "lemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Dependent Sizes: Define the standard sizes for slots and message labels, as well as the initial user context, which are specific to the underlying machine architecture.",
    "input": "",
    "output": "definition\n  slot_bits :: nat where\n  \"slot_bits \\<equiv> 4\"\n\ndefinition\n  msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 20\"\n\ndefinition\n  new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext ((\\<lambda>r. 0) (CPSR := 0x150))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Virtual Address Reservation: The kernel reserves a specific range of virtual addresses starting from a defined base address in every virtual address space, ensuring that this region is exclusively used by the kernel.",
    "input": "",
    "output": "definition\n  kernel_base :: \"vspace_ref\" where\n  \"kernel_base \\<equiv> 0xe0000000\"\n\ndefinition\n  idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = kernel_base + 0x1000\"\n\nend\n\narch_requalify_consts (A) kernel_base idle_thread_ptr\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operation Constants: Define constants for various machine operations, including message information, general-purpose and frame registers, capability and badge registers, and exception and syscall messages. These constants provide a standardized way to reference specific elements in the system's architecture.",
    "input": "",
    "output": "definition\n  nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\" where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len)\n                           (to_bl (of_nat n :: machine_word))\"\n\ndefinition\n \"msg_info_register \\<equiv> msgInfoRegister\"\ndefinition\n \"msg_registers \\<equiv> msgRegisters\"\ndefinition\n \"cap_register \\<equiv> capRegister\"\ndefinition\n \"badge_register \\<equiv> badgeRegister\"\ndefinition\n \"frame_registers \\<equiv> frameRegisters\"\ndefinition\n \"gp_registers \\<equiv> gpRegisters\"\ndefinition\n \"exception_message \\<equiv> exceptionMessage\"\ndefinition\n \"syscall_message \\<equiv> syscallMessage\"\n\ndatatype arch_fault\n    = VMFault vspace_ref \"machine_word list\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Maximum IRQ Definition: The maximum number of interrupts (maxIRQ) is defined either through the Kernel_Config for ARM architectures or manually for X64 architectures.",
    "input": "",
    "output": "arch_requalify_consts\n  maxIRQ\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Address Space Switching: Switch the virtual address space context to a specified thread or the idle thread, ensuring that the correct memory mappings are in place.",
    "input": "",
    "output": "definition\n  arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> set_vm_root t\"\n\ndefinition\n   arch_switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n   \"arch_switch_to_idle_thread \\<equiv> do\n     thread \\<leftarrow> gets idle_thread;\n     set_vm_root thread\n   od\"\n\ndefinition\n  arch_activate_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_activate_idle_thread t \\<equiv> return ()\"\n\ndefinition\n  \"store_asid_pool_entry pool_ptr asid pml4base \\<equiv> do\n    pool \\<leftarrow> get_asid_pool pool_ptr;\n    pool' \\<leftarrow> return (pool(asid_low_bits_of asid := pml4base));\n    set_asid_pool pool_ptr pool'\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Control: Create a new ASID pool object, provide a capability to it, and connect it to the global virtual ASID table. This ensures that the ASID pool is properly initialized and integrated into the system's memory management.",
    "input": "",
    "output": "definition\nperform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_control_invocation iv \\<equiv> case iv of\n  MakePool frame slot parent base \\<Rightarrow> do\n    delete_objects frame page_bits;\n    pcap \\<leftarrow> get_cap parent;\n    set_cap (max_free_index_update pcap) parent;\n    retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n    cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n    assert (asid_low_bits_of base = 0);\n    asid_table \\<leftarrow> gets (x64_asid_table \\<circ> arch_state);\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n    modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>x64_asid_table := asid_table'\\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Assignment: Assigns a virtual ASID to a page directory, updating the capability and storing the ASID pool entry. Ensures that the page directory is correctly associated with the specified ASID, facilitating proper memory management and virtual address translation.\n\nPage Unmapping: Unmaps a page from the specified ASID and virtual address, updating the capability to reflect the unmapped state. Ensures that the page is no longer accessible in the virtual address space, maintaining the integrity of the memory management system.",
    "input": "",
    "output": "definition\nperform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_pool_invocation iv \\<equiv> case iv of Assign asid pool_ptr ct_slot \\<Rightarrow>\ndo\n    pml4_cap \\<leftarrow> get_cap ct_slot;\n    case pml4_cap of\n      ArchObjectCap (PML4Cap pml4_base _) \\<Rightarrow> do\n        set_cap (ArchObjectCap $ PML4Cap pml4_base (Some asid)) ct_slot;\n        store_asid_pool_entry pool_ptr asid (Some pml4_base)\n      od\n    | _ \\<Rightarrow> fail\nod\"\n\n\ndefinition\n  pte_check_if_mapped :: \"obj_ref \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pte_check_if_mapped slot \\<equiv> do\n     pt \\<leftarrow> get_pte slot;\n     return (pt \\<noteq> InvalidPTE)\n  od\"\n\ndefinition\n  pde_check_if_mapped :: \"obj_ref \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pde_check_if_mapped slot \\<equiv> do\n     pd \\<leftarrow> get_pde slot;\n     return (pd \\<noteq> InvalidPDE)\n  od\"\n\ndefinition\n  perform_page_invocation_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_page_invocation_unmap cap ct_slot \\<equiv>\n      (case cap\n         of PageCap dev base rights map_type sz mapped \\<Rightarrow> do\n            case mapped of Some (asid, vaddr) \\<Rightarrow> unmap_page sz asid vaddr base\n                          | None \\<Rightarrow> return ();\n            cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n            set_cap (ArchObjectCap $ update_map_data cap None (Some VMNoMap)) ct_slot\n          od\n      | _ \\<Rightarrow> fail)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Management: Allows the manipulation of memory pages, including mapping, unmapping, and flushing. The page capability is used to set or remove page table entries and invalidate the page structure cache, ensuring that the memory management operations are performed securely and efficiently.",
    "input": "",
    "output": "definition\nperform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n\"perform_page_invocation iv \\<equiv> case iv of\n    PageMap cap ct_slot entries vspace \\<Rightarrow> do\n      set_cap cap ct_slot;\n      case entries of\n          (VMPTE pte, slot) \\<Rightarrow> store_pte slot pte\n        | (VMPDE pde, slot) \\<Rightarrow> store_pde slot pde\n        | (VMPDPTE pdpte, slot) \\<Rightarrow> store_pdpte slot pdpte;\n      asid \\<leftarrow> case cap of\n                  ArchObjectCap (PageCap _ _ _ _ _ (Some (as, _))) \\<Rightarrow> return as\n                | _ \\<Rightarrow> fail;\n      invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid;\n      return []\n    od\n  | PageUnmap cap ct_slot \\<Rightarrow>\n      (case cap of\n        PageCap dev base rights map_type sz mapped \\<Rightarrow> do\n            case mapped of\n              Some _ \\<Rightarrow> (case map_type of\n                          VMVSpaceMap \\<Rightarrow> perform_page_invocation_unmap cap ct_slot\n                        | _ \\<Rightarrow> fail)\n            | None \\<Rightarrow> return ();\n            return []\n        od\n      | _ \\<Rightarrow> fail)\n\\<^cancel>\\<open>| PageIOMap asid cap ct_slot entries \\<Rightarrow> undefined\\<close>\n  | PageGetAddr ptr \\<Rightarrow>\n      return [addrFromPPtr ptr]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Management: Allows the mapping and unmapping of page tables. It involves setting and storing page directory entries, invalidating page structure caches, and updating capability mappings. Unmapping includes removing the page table from the address space, clearing relevant slots, and updating the capability to reflect the unmapped state.",
    "input": "",
    "output": "definition\nperform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_table_invocation iv \\<equiv>\ncase iv of PageTableMap cap ct_slot pde pd_slot vspace \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pde pd_slot pde;\n    asid <- case cap of ArchObjectCap (PageTableCap  _ (Some (as, _))) \\<Rightarrow> return as\n            | _ \\<Rightarrow> fail;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\n  | PageTableUnmap (ArchObjectCap (PageTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_page_table asid vaddr p;\n      pte_bits \\<leftarrow> return word_size_bits;\n      slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 <<  pt_bits) - 1];\n      mapM_x (swp store_pte InvalidPTE) slots\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "PageDirectory Invocation: Allows the mapping and unmapping of page tables. Mapping involves setting a capability, storing a page directory pointer table entry, and invalidating the page structure cache for the specified address space. Unmapping involves removing the page directory entry, updating the capability to remove the mapped address, and clearing the corresponding slots.",
    "input": "",
    "output": "definition\nperform_page_directory_invocation :: \"page_directory_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_directory_invocation iv \\<equiv>\ncase iv of PageDirectoryMap cap ct_slot pdpte pdpt_slot vspace \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pdpte pdpt_slot pdpte;\n    asid <- case cap of ArchObjectCap (PageDirectoryCap _ (Some (as, _))) \\<Rightarrow> return as\n            | _ \\<Rightarrow> fail;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\n  | PageDirectoryUnmap (ArchObjectCap (PageDirectoryCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_pd asid vaddr p;\n      pde_bits \\<leftarrow> return word_size_bits;\n      slots \\<leftarrow> return [p, p + (1 << pde_bits) .e. p + (1 << pd_bits) - 1];\n      mapM_x (swp store_pde InvalidPDE) slots\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "PageDirectory and I/O Port Management: PageDirectory capabilities allow for mapping and unmapping of page tables, including updating the page table entries and invalidating the page structure cache. I/O port capabilities enable reading from and writing to I/O ports, as well as controlling I/O port access by setting masks and inserting I/O port capabilities into slots.",
    "input": "",
    "output": "definition\nperform_pdpt_invocation :: \"pdpt_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_pdpt_invocation iv \\<equiv>\ncase iv of PDPTMap cap ct_slot pml4e pml4_slot vspace \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pml4e pml4_slot pml4e;\n    asid <- case cap of ArchObjectCap (PDPointerTableCap _ (Some (as, _))) \\<Rightarrow> return as\n            | _ \\<Rightarrow> fail;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\n  | PDPTUnmap (ArchObjectCap (PDPointerTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_pdpt asid vaddr p;\n      pdept_bits \\<leftarrow> return word_size_bits;\n      slots \\<leftarrow> return [p, p + (1 << pdept_bits) .e. p + (1 << pdpt_bits) - 1];\n      mapM_x (swp store_pdpte InvalidPDPTE) slots\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"\n\ndefinition\n  port_out :: \"('a word \\<Rightarrow> unit machine_monad) \\<Rightarrow> ('a word) \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"port_out f w = do\n    do_machine_op $ f w;\n    return []\n  od\"\n\ndefinition\n  port_in :: \"(data machine_monad) \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"port_in f = do\n    res \\<leftarrow> do_machine_op f;\n    return [res]\n  od\"\n\ndefinition\n  perform_io_port_invocation :: \"io_port_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_io_port_invocation i \\<equiv> (\n    case i of (IOPortInvocation port port_data) \\<Rightarrow> (\n      case port_data of\n        IOPortIn8 \\<Rightarrow> port_in (in8 port)\n      | IOPortIn16 \\<Rightarrow> port_in (in16 port)\n      | IOPortIn32 \\<Rightarrow> port_in (in32 port)\n      | IOPortOut8 w \\<Rightarrow> port_out (out8 port) w\n      | IOPortOut16 w \\<Rightarrow> port_out (out16 port) w\n      | IOPortOut32 w \\<Rightarrow> port_out (out32 port) w\n    )\n    )\"\n\ndefinition\n  perform_ioport_control_invocation :: \"io_port_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_ioport_control_invocation i \\<equiv>\n    case i of (IOPortControlInvocation f l dest_slot control_slot) \\<Rightarrow> do\n      set_ioport_mask f l True;\n      c \\<leftarrow> return $ ArchObjectCap $ IOPortCap f l;\n      cap_insert (ArchObjectCap (IOPortCap f l)) control_slot dest_slot\n    od\"\n\nabbreviation\n  arch_no_return :: \"(unit, 'z::state_ext) s_monad \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\nwhere\n  \"arch_no_return oper \\<equiv> do oper; return [] od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocation Handling: Dispatches and performs various x64-specific system calls, including operations on page tables, page directories, PDPTs, pages, ASID control, ASID pools, I/O ports, and I/O port control. Each invocation is handled by a corresponding function, ensuring the correct execution of architectural operations.",
    "input": "",
    "output": "definition\n  arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\" where\n  \"arch_perform_invocation i \\<equiv> liftE $\n    case i of\n          InvokePageTable oper \\<Rightarrow> arch_no_return $ perform_page_table_invocation oper\n        | InvokePageDirectory oper \\<Rightarrow> arch_no_return $ perform_page_directory_invocation oper\n        | InvokePDPT oper \\<Rightarrow> arch_no_return $ perform_pdpt_invocation oper\n        | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n        | InvokeASIDControl oper \\<Rightarrow> arch_no_return $ perform_asid_control_invocation oper\n        | InvokeASIDPool oper \\<Rightarrow> arch_no_return $ perform_asid_pool_invocation oper\n        | InvokeIOPort oper \\<Rightarrow> perform_io_port_invocation oper\n        | InvokeIOPortControl oper \\<Rightarrow> arch_no_return $ perform_ioport_control_invocation oper\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Hypervisor Fault: Process hypervisor fault events, where the function `handle_hypervisor_fault` returns without any action if the fault type is `X64NoHypFaults`.",
    "input": "",
    "output": "chapter \"Handle Hyperviser Fault Event\"\n\ntheory Hypervisor_A\nimports Exceptions_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"machine_word \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n\"handle_hypervisor_fault thread X64NoHypFaults = return ()\"\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reserve Memory Region: Reserve a specified number of bytes in memory, potentially tagging the region as kernel data. This function currently acts as a placeholder and does not perform any actual reservation or tagging.",
    "input": "",
    "output": "definition\n  reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Architecture-Specific Objects: Initialize architecture-specific objects based on the object type. If the object type is a PML4 object, copy global mappings for the provided references. Additionally, define an empty user context and an initial architecture-specific thread control block with this empty context.",
    "input": "",
    "output": "definition\n  init_arch_objects :: \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list\n   \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs\n    \\<equiv> when (new_type = ArchObject PML4Obj) (mapM_x copy_global_mappings refs)\"\n\ndefinition\n  empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0) (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context \\<rparr>\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Post-Capability Deletion Actions: Perform specific actions after a capability is deleted, such as freeing the I/O port range for an IOPortCap. For other types of capabilities, no action is taken.",
    "input": "",
    "output": "definition\n  arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arch_post_cap_deletion ac \\<equiv> case ac of\n       IOPortCap f l \\<Rightarrow> free_ioport_range f l\n     | _ \\<Rightarrow> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Generic Object References: Defines a set of architecture-specific generic object references, specifically for I/O ports, and provides a cleanup operation to convert architecture-specific capabilities into a standard capability format.",
    "input": "",
    "output": "datatype arch_gen_obj_ref = IOPortRef io_port\n\ndefinition\n  arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\"\nwhere\n  \"arch_gen_obj_refs ac \\<equiv> case ac of\n      IOPortCap f l \\<Rightarrow> IOPortRef ` {f}\n    | _ \\<Rightarrow> {}\"\n\ndefinition\n  arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_cap_cleanup_opt ac \\<equiv> case ac of IOPortCap f l \\<Rightarrow> ArchObjectCap (IOPortCap f l) | _ \\<Rightarrow> NullCap\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IRQ Node Pointer: The IRQ node pointer is initialized to a specific memory address, which is 8KiB (0x2000) offset from the kernel base address.",
    "input": "",
    "output": "definition\n  init_irq_node_ptr :: obj_ref where\n  \"init_irq_node_ptr = kernel_base + 0x2000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Global PML4: Set the initial global page map level 4 (PML4) to a specific memory address, which is 4KiB offset from the kernel base.",
    "input": "",
    "output": "definition\n  init_global_pml4 :: obj_ref where\n  \"init_global_pml4 = kernel_base + 0x4000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Global Page Directory Pointer Table: Set the initial address of the global page directory pointer table to a fixed offset from the kernel base.",
    "input": "",
    "output": "definition\n  init_global_pdpt :: obj_ref where\n  \"init_global_pdpt = kernel_base + 0x5000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Architecture State: Initializes the architecture state with predefined values, including an empty ASID table, a global PML4, a kernel virtual space, and other essential components such as PDPTs, PDS, and IOAPIC settings. This ensures that the system is set up with a valid and consistent initial state for memory management and interrupt handling.",
    "input": "",
    "output": "definition\n  init_global_pd :: obj_ref where\n  \"init_global_pd = kernel_base + 0x6000\"\n\ndefinition\n  \"init_arch_state \\<equiv> \\<lparr>\n    x64_asid_table = Map.empty,\n    x64_global_pml4 = init_global_pml4,\n    x64_kernel_vspace =\n      \\<lambda>ref. if ref \\<in> {pptr_base .. pptr_base + mask pml4_shift_bits}\n              then X64VSpaceKernelWindow\n              else X64VSpaceInvalidRegion,\n    x64_global_pts = [],\n    x64_global_pdpts = [init_global_pdpt],\n    x64_global_pds = [init_global_pd],\n    x64_current_cr3 = cr3 0 0,\n    x64_allocated_io_ports = \\<lambda>_. False,\n    x64_num_ioapics = 1,\n    x64_ioapic_nirqs = \\<lambda>_. ucast ioapicIRQLines,\n    x64_irq_state = K IRQFree\n   \\<rparr>\"\n\ndefinition [simp]:\n  \"global_pml4 \\<equiv> (\\<lambda>_ :: 9 word. InvalidPML4E)\n    (0x1FF := PDPointerTablePML4E (addrFromPPtr init_global_pdpt) {} {})\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Global PDPT Mapping: The kernel utilizes huge page mappings in the global Page Directory Pointer Table (PDPT) to provide a comprehensive view of all physical memory, with the exception of the highest PDPT entry, which maps to the global page directory.",
    "input": "",
    "output": "definition [simp]:\n  \"global_pdpt \\<equiv> (\\<lambda> i :: 9 word. HugePagePDPTE (ucast i << 30) {} {})\n                    (0x1FF := PageDirectoryPDPTE (addrFromPPtr init_global_pd) {} {})\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Kernel State: The kernel initializes its state with a global page directory, an idle thread, and other essential components. The initial state includes setting up the kheap, capability derivation tree, interrupt controller, and architecture-specific state, ensuring that the system is ready for operation.",
    "input": "",
    "output": "definition [simp]:\n  \"global_pd \\<equiv> (\\<lambda> i :: 9 word. LargePagePDE (0x03FE00 + ucast i << 21) {} {})\"\n\ndefinition\n  \"init_kheap \\<equiv>\n    (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n           then Some (CNode 0 (empty_cnode 0))\n           else None)\n    (idle_thread_ptr \\<mapsto>\n       TCB \\<lparr>\n         tcb_ctable = NullCap,\n         tcb_vtable = NullCap,\n         tcb_reply = NullCap,\n         tcb_caller = NullCap,\n         tcb_ipcframe = NullCap,\n         tcb_state = IdleThreadState,\n         tcb_fault_handler = replicate word_bits False,\n         tcb_ipc_buffer = 0,\n         tcb_fault = None,\n         tcb_bound_notification = None,\n         tcb_mcpriority = minBound,\n         tcb_arch = init_arch_tcb\n         \\<rparr>,\n     init_global_pml4 \\<mapsto> ArchObj (PageMapL4 global_pml4),\n     init_global_pdpt \\<mapsto> ArchObj (PDPointerTable global_pdpt),\n     init_global_pd \\<mapsto> ArchObj (PageDirectory global_pd)\n    )\"\n\ndefinition\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. Structures_A.IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Attributes Mask: Defines a set of page attributes that are always set to False when pages are mapped, including global, dirty, accessed, execute disable, and PAT attributes.",
    "input": "",
    "output": "definition\n  \"attr_mask = {Global,Dirty,PTAttr Accessed,PTAttr ExecuteDisable}\"\n\ndefinition\n  \"attr_mask' = attr_mask \\<union> {PAT}\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Mapping Entries: Generate the necessary entries for mapping different sizes of memory frames (small, large, and huge pages) at a specified virtual address. The function ensures that the appropriate page table or directory entry is created with the given base address, rights, and attributes, and it returns the entry along with the corresponding slot.",
    "input": "",
    "output": "primrec create_mapping_entries ::\n  \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vm_rights \\<Rightarrow> frame_attrs \\<Rightarrow> obj_ref \\<Rightarrow>\n  (vm_page_entry * obj_ref,'z::state_ext) se_monad\"\nwhere\n  \"create_mapping_entries base vptr X64SmallPage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ (VMPTE (SmallPagePTE base (attrib - attr_mask) vm_rights), p)\n  odE\"\n\n| \"create_mapping_entries base vptr X64LargePage vm_rights attrib pdpt =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pd_slot pdpt vptr;\n    returnOk $ (VMPDE (LargePagePDE base (attrib - attr_mask) vm_rights), p)\n  odE\"\n\n| \"create_mapping_entries base vptr X64HugePage vm_rights attrib pml4 =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pdpt_slot pml4 vptr;\n    returnOk $ (VMPDPTE (HugePagePDPTE base (attrib - attr_mask') vm_rights), p)\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure Safe Mapping: Verify that the given virtual memory entries are either invalid or replace existing invalid entries, ensuring safe mapping and unmapping operations. It allows SmallPagePTE, LargePagePDE, and HugePagePDPTE entries if they are replacing invalid entries, and fails for PageTablePDE and PageDirectoryPDPTE entries.",
    "input": "",
    "output": "fun ensure_safe_mapping ::\n  \"(vm_page_entry * obj_ref) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n\"ensure_safe_mapping (VMPTE InvalidPTE, _) = returnOk ()\"\n|\n\"ensure_safe_mapping (VMPDE InvalidPDE, _) = returnOk ()\"\n|\n\"ensure_safe_mapping (VMPDPTE InvalidPDPTE, _) = returnOk ()\"\n|\n\"ensure_safe_mapping (VMPTE (SmallPagePTE _ _ _), pt_slot) = returnOk ()\"\n|\n\"ensure_safe_mapping (VMPDE (LargePagePDE _ _ _), pd_slot) =\n    doE\n        pde \\<leftarrow> liftE $ get_pde pd_slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | LargePagePDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE\"\n|\n\"ensure_safe_mapping (VMPDPTE (HugePagePDPTE _ _ _), pdpt_slot) =\n    doE\n        pdpt \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n        (case pdpt of\n              InvalidPDPTE \\<Rightarrow> returnOk ()\n            | HugePagePDPTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE\"\n|\n\"ensure_safe_mapping (VMPDE (PageTablePDE _ _ _), _) = fail\"\n|\n\"ensure_safe_mapping (VMPDPTE (PageDirectoryPDPTE _ _ _), _) = fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "IPC Buffer Lookup: Verify the thread's authority to access its IPC buffer, ensuring that the thread has the appropriate read or write permissions based on whether it is the receiver or not.",
    "input": "",
    "output": "definition\nlookup_ipc_buffer :: \"bool \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n\"lookup_ipc_buffer is_receiver thread \\<equiv> do\n    buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n    buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n    buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n    (case buffer_cap of\n      ArchObjectCap (PageCap _ p R _ vms _) \\<Rightarrow>\n        if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n        then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n        else return None\n    | _ \\<Rightarrow> return None)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate Page Directory: Find the page directory associated with a given virtual ASID by navigating through the ASID table and ASID pool, ensuring the ASID is valid and returning the corresponding PML4 pointer. If the ASID or PML4 entry is not found, an error is thrown.",
    "input": "",
    "output": "definition\nfind_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"find_vspace_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (x64_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pml4 \\<leftarrow> returnOk (pool (asid_low_bits_of asid));\n    (case pml4 of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate and Validate Page Directory: Find the page directory for a given ASID, ensuring that the operation is successful and returns a valid pointer to an existing page directory.",
    "input": "",
    "output": "definition\nfind_vspace_for_asid_assert :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) s_monad\" where\n\"find_vspace_for_asid_assert asid \\<equiv> do\n   pml4 \\<leftarrow> find_vspace_for_asid asid <catch> K fail;\n   get_pml4 pml4;\n   return pml4\n od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle VM Fault: Format and propagate a VM fault message to the thread's supervisor, including the fault address and error register value, based on the type of fault (data or instruction).",
    "input": "",
    "output": "definition\nhandle_vm_fault :: \"obj_ref \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n\"handle_vm_fault thread fault_type = doE\n    addr \\<leftarrow> liftE $ do_machine_op getFaultAddress;\n    fault \\<leftarrow> liftE $ as_user thread $ getRegister ErrorRegister;\n    case fault_type of\n        X64DataFault \\<Rightarrow> throwError $ ArchFault $ VMFault addr [0, fault && mask 5]\n      | X64InstructionFault \\<Rightarrow> throwError $ ArchFault $ VMFault addr [1, fault && mask 5]\nodE\"\n\ndefinition\n  get_current_cr3 :: \"(cr3, 'z::state_ext) s_monad\"\nwhere\n  \"get_current_cr3 \\<equiv> gets (x64_current_cr3 \\<circ> arch_state)\"\n\ndefinition\n  set_current_cr3 :: \"cr3 \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_current_cr3 c \\<equiv>\n     modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>x64_current_cr3 := c\\<rparr>\\<rparr>)\"\n\ndefinition\n  invalidate_page_structure_cache_asid :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"invalidate_page_structure_cache_asid vspace asid \\<equiv>\n     do_machine_op $ invalidateLocalPageStructureCacheASID vspace (ucast asid)\"\n\ndefinition\n  getCurrentVSpaceRoot :: \"(obj_ref, 'z::state_ext) s_monad\"\nwhere\n  \"getCurrentVSpaceRoot \\<equiv> do\n      cur \\<leftarrow> get_current_cr3;\n      return $ cr3_base_address cur\n   od\"\n\ndefinition\n  \"cr3_addr_mask \\<equiv> mask pml4_shift_bits << asid_bits\"\n\ndefinition\n  make_cr3 :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> cr3\"\nwhere\n  \"make_cr3 vspace asid \\<equiv> cr3 (vspace && cr3_addr_mask) asid\"\n\ndefinition\n  set_current_vspace_root :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"set_current_vspace_root vspace asid \\<equiv> set_current_cr3 $ make_cr3 vspace asid\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Virtual Memory Root: Switch the current address space to the one associated with a given thread's virtual memory root. If the thread's virtual memory root is invalid, switch to the global address space. This ensures that the system operates within a valid and correctly configured address space.",
    "input": "",
    "output": "definition\n  set_vm_root :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PML4Cap pml4 (Some asid)) \\<Rightarrow> doE\n           pml4' \\<leftarrow> find_vspace_for_asid asid;\n           whenE (pml4 \\<noteq> pml4') $ throwError InvalidRoot;\n           cur_cr3 \\<leftarrow> liftE $ get_current_cr3;\n           whenE (cur_cr3 \\<noteq> make_cr3 (addrFromPPtr pml4) asid) $\n              liftE $ set_current_cr3 $ make_cr3 (addrFromPPtr pml4) asid\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_pml4 \\<leftarrow> gets (x64_global_pml4 \\<circ> arch_state);\n       set_current_vspace_root (addrFromKPPtr global_pml4) 0\n    od)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Deletion: Remove the ASID pool associated with a given base ASID, invalidating all virtual to physical mappings for each ASID in the pool. This ensures that any mappings involving the virtual ASID are removed, maintaining the integrity of the virtual memory system.",
    "input": "",
    "output": "definition\nhw_asid_invalidate :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"hw_asid_invalidate asid vspace \\<equiv>\n  do_machine_op $ invalidateASID vspace (ucast asid)\"\n\ndefinition\ndelete_asid_pool :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid_pool base ptr \\<equiv> do\n  assert (asid_low_bits_of base = 0);\n  asid_table \\<leftarrow> gets (x64_asid_table \\<circ> arch_state);\n  when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n    pool \\<leftarrow> get_asid_pool ptr;\n    mapM (\\<lambda>offset. (when (pool (ucast offset) \\<noteq> None) $\n                          hw_asid_invalidate (base + offset) (the (pool (ucast offset)))))\n                    [0 .e. (1 << asid_low_bits) - 1];\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> x64_asid_table := asid_table' \\<rparr>\\<rparr>);\n    tcb \\<leftarrow> gets cur_thread;\n    set_vm_root tcb\n  od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Deletion: When deleting a Page Map Level 4 (PML4) from an ASID pool, the corresponding ASID is deactivated by invalidating the hardware ASID, updating the ASID pool to remove the PML4, and setting the virtual memory root for the current thread. This ensures that the ASID is properly deactivated and the system's memory management is maintained.",
    "input": "",
    "output": "definition\ndelete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pml4 \\<equiv> do\n  asid_table \\<leftarrow> gets (x64_asid_table \\<circ> arch_state);\n  case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (asid_low_bits_of asid) = Some pml4) $ do\n                hw_asid_invalidate asid pml4;\n                pool' \\<leftarrow> return (pool (asid_low_bits_of asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od\nod\"\n\ndefinition\n  flush_all :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_all vspace asid \\<equiv> do_machine_op $ invalidateASID vspace (ucast asid)\"\n\nabbreviation\n  flush_pdpt :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_pdpt \\<equiv> flush_all\"\n\nabbreviation\n  flush_pd :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_pd \\<equiv> flush_all\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flush Page Table Mappings: Invalidate mappings associated with a specified page table, ensuring that all entries are flushed for a given ASID. This process iterates over each entry in the page table, and if the entry is valid, it invalidates the corresponding translation for the specified virtual address and ASID.",
    "input": "",
    "output": "definition\nflush_table :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_table pml4_ref vptr pt_ref asid \\<equiv> do\n    assert (vptr && mask (ptTranslationBits + pageBits) = 0);\n           pt \\<leftarrow> get_pt pt_ref;\n           forM_x [0 .e. (-1::9 word)] (\\<lambda>index. do\n             pte \\<leftarrow> return $ pt index;\n             case pte of\n               InvalidPTE \\<Rightarrow> return ()\n             | _ \\<Rightarrow> do_machine_op $ invalidateTranslationSingleASID (vptr + (ucast index << pageBits)) (ucast asid)\n           od)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page Directory Pointer Table: Unmaps a specified Page Directory Pointer Table (PDPT) from a given address space identifier (ASID) and virtual space reference. Ensures the PDPT is valid for the ASID, flushes the PDPT, and updates the PML4 entry to an invalid state.",
    "input": "",
    "output": "definition\nunmap_pdpt :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_pdpt asid vaddr pdpt \\<equiv> doE\n  vspace \\<leftarrow> find_vspace_for_asid asid;\n  pm_slot \\<leftarrow> returnOk $ lookup_pml4_slot vspace vaddr;\n  pml4e \\<leftarrow> liftE $ get_pml4e pm_slot;\n  case pml4e of\n    PDPointerTablePML4E pt' _ _ \\<Rightarrow>\n      if pt' = addrFromPPtr pdpt then returnOk () else throwError InvalidRoot\n    | _ \\<Rightarrow> throwError InvalidRoot;\n  liftE $ do\n    flush_pdpt vspace asid;\n    store_pml4e pm_slot InvalidPML4E\n  od\nodE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page Directory: Unmaps a specified page directory from the page directory pointer table. It ensures that the correct page directory is targeted, flushes the page directory, updates the page directory pointer table entry to an invalid state, and invalidates the page structure cache for the associated address space identifier.",
    "input": "",
    "output": "definition\nunmap_pd :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_pd asid vaddr pd \\<equiv> doE\n  vspace \\<leftarrow> find_vspace_for_asid asid;\n  pdpt_slot \\<leftarrow> lookup_pdpt_slot vspace vaddr;\n  pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n  case pdpte of\n    PageDirectoryPDPTE pd' _ _ \\<Rightarrow>\n      if pd' = addrFromPPtr pd then returnOk () else throwError InvalidRoot\n    | _ \\<Rightarrow> throwError InvalidRoot;\n  liftE $ do\n    flush_pd vspace asid;\n    store_pdpte pdpt_slot InvalidPDPTE;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\nodE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page Table: Unmaps a specified page table from its page directory by finding the corresponding page directory, validating the page table entry, and then flushing, invalidating, and clearing the page table entry. If the page table does not match or the entry is invalid, an error is thrown.",
    "input": "",
    "output": "definition\nunmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page_table asid vaddr pt \\<equiv> doE\n    vspace \\<leftarrow> find_vspace_for_asid asid;\n    pd_slot \\<leftarrow> lookup_pd_slot vspace vaddr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    case pde of\n      PageTablePDE addr _ _ \\<Rightarrow>\n        if addrFromPPtr pt = addr then returnOk () else throwError InvalidRoot\n      | _ \\<Rightarrow> throwError InvalidRoot;\n    liftE $ do\n      flush_table vspace vaddr pt asid;\n      store_pde pd_slot InvalidPDE;\n      invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n    od\nodE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Mapping Physical Pointer: Verify if a given physical page pointer is mapped by a specific virtual memory mapping entry. This ensures that the base address of the mapping entry matches the address derived from the physical page pointer.",
    "input": "",
    "output": "definition\ncheck_mapping_pptr :: \"machine_word \\<Rightarrow> vm_page_entry \\<Rightarrow> bool\" where\n\"check_mapping_pptr pptr entry \\<equiv> case entry of\n   VMPTE (SmallPagePTE base _ _) \\<Rightarrow> base = addrFromPPtr pptr\n | VMPDE (LargePagePDE base _ _) \\<Rightarrow> base = addrFromPPtr pptr\n | VMPDPTE (HugePagePDPTE base _ _) \\<Rightarrow> base = addrFromPPtr pptr\n | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page: Unmaps a page from the virtual address space if the given mapping details are still current. It checks the page size and corresponding page table entry, and if the physical page pointer matches, it invalidates the page table entry and flushes the translation cache for the specified ASID.",
    "input": "",
    "output": "definition\nunmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page pgsz asid vptr pptr \\<equiv> doE\n    vspace \\<leftarrow> find_vspace_for_asid asid;\n    case pgsz of\n          X64SmallPage \\<Rightarrow> doE\n            pt_slot \\<leftarrow> lookup_pt_slot vspace vptr;\n            pte \\<leftarrow> liftE $ get_pte pt_slot;\n            unlessE (check_mapping_pptr pptr (VMPTE pte)) $ throwError InvalidRoot;\n            liftE $ store_pte pt_slot InvalidPTE\n          odE\n        | X64LargePage \\<Rightarrow> doE\n            pd_slot \\<leftarrow> lookup_pd_slot vspace vptr;\n            pde \\<leftarrow> liftE $ get_pde pd_slot;\n            unlessE (check_mapping_pptr pptr (VMPDE pde)) $ throwError InvalidRoot;\n            liftE $ store_pde pd_slot InvalidPDE\n          odE\n        | X64HugePage \\<Rightarrow> doE\n            pdpt_slot \\<leftarrow> lookup_pdpt_slot vspace vptr;\n            pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n            unlessE (check_mapping_pptr pptr (VMPDPTE pdpte)) $ throwError InvalidRoot;\n            liftE $ store_pdpte pdpt_slot InvalidPDPTE\n          odE;\n    liftE $ do_machine_op $ invalidateTranslationSingleASID vptr (ucast asid)\nodE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capability Derivation: Ensures that page table structure capabilities (PageTableCap, PageDirectoryCap, PDPointerTableCap, PML4Cap) can only be derived if they have a virtual ASID and location assigned. If these conditions are not met, an IllegalOperation error is thrown. Other architectural capabilities are derived without additional checks.",
    "input": "",
    "output": "definition\n  arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\"\nwhere\n  \"arch_derive_cap c \\<equiv> case c of\n     PageTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageTableCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageDirectoryCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageDirectoryCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PDPointerTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PDPointerTableCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PML4Cap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PML4Cap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageCap dev r R mt pgs x \\<Rightarrow> returnOk $ ArchObjectCap (PageCap dev r R VMNoMap pgs None)\n   | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n   | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\n\\<^cancel>\\<open>FIXME x64-vtd:\n   | IOSpaceCap _ _ \\<Rightarrow> returnOk c\n   | IOPageTableCap _ _ _ \\<Rightarrow> returnOk c\\<close>\n   | IOPortCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\n   | IOPortControlCap \\<Rightarrow> returnOk NullCap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Capability Data Update: Ensures that the architecture-specific capability data is updated without allowing any user-modifiable data to be stored in x64-specific capabilities.",
    "input": "",
    "output": "definition\n  arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Capability Finalization: Finalize x64-specific capabilities by performing specific actions such as deleting ASID pools, unmapping PML4, PDPT, page directories, and page tables, and unmap pages. The finalization process returns a pair of `NullCap` for most cases, except for IOPort capabilities, which return an `ArchObjectCap` containing the original IOPort capability.",
    "input": "",
    "output": "definition\n  arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n    (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n    delete_asid_pool b ptr;\n    return (NullCap, NullCap)\n    od\n  | (PML4Cap ptr (Some a), True) \\<Rightarrow> do\n    delete_asid a ptr;\n    return (NullCap, NullCap)\n  od\n  | (PDPointerTableCap ptr (Some (a,v)), True) \\<Rightarrow> do\n    unmap_pdpt a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageDirectoryCap ptr (Some (a,v)), True) \\<Rightarrow> do\n    unmap_pd a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n    unmap_page_table a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageCap _ ptr _ _ s (Some (a, v)), _) \\<Rightarrow> do\n     unmap_page s a v ptr;\n     return (NullCap, NullCap)\n  od\n  | (IOPortCap f l, True) \\<Rightarrow> return (NullCap, (ArchObjectCap (IOPortCap f l)))\n  \\<comment> \\<open>FIXME x64-vtd: IOSpaceCap and IOPageTableCap for @{text arch_finalise_cap}\\<close>\n  | _ \\<Rightarrow> return (NullCap, NullCap)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Address Space Validation: Ensures that a thread's virtual address space capability is valid by checking if it points to a mapped PML4, which is a requirement for the x64 architecture. For IPC buffer validation, it specifically checks if the capability is a PageCap and if the provided virtual pointer is aligned; otherwise, it throws an error.",
    "input": "",
    "output": "definition\n  is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv> \\<exists>r a. c = ArchObjectCap (PML4Cap r (Some a))\"\n\ndefinition\ncheck_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n\"check_valid_ipc_buffer vptr c \\<equiv> case c of\n  (ArchObjectCap (PageCap False _ _ _ _ _)) \\<Rightarrow> doE\n    whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError;\n    returnOk ()\n  odE\n| _ \\<Rightarrow> throwError IllegalOperation\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode VM Attributes: Extract and decode the virtual memory attributes from a user-provided machine word, determining specific attributes such as write-through, cache disabled, and PAT (Page Attribute Table) based on the bit values.",
    "input": "",
    "output": "definition\nattribs_from_word :: \"machine_word \\<Rightarrow> frame_attrs\" where\n\"attribs_from_word w \\<equiv>\n  let V = (if w !!0 then {PTAttr WriteThrough} else {});\n      V' = (if w!!1 then insert (PTAttr CacheDisabled) V else V)\n  in if w!!2 then insert PAT V' else V'\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Mapping Data: Modify the mapping data in a page or page table capability, updating the ASID and virtual space reference, as well as the type of the virtual memory mapping.",
    "input": "",
    "output": "definition\n  update_map_data :: \"arch_cap \\<Rightarrow> (asid \\<times> vspace_ref) option \\<Rightarrow> vmmap_type option \\<Rightarrow> arch_cap\" where\n  \"update_map_data cap m mt \\<equiv> case cap of\n     PageCap dev p R _ sz _ \\<Rightarrow> PageCap dev p R (the mt) sz m\n   | PageTableCap p _ \\<Rightarrow> PageTableCap p m\n   | PageDirectoryCap p _ \\<Rightarrow> PageDirectoryCap p m\n   | PDPointerTableCap p _ \\<Rightarrow> PDPointerTableCap p m\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "User Frame Check: Determine if a pointer is within a user frame by checking if the top bits of the pointer point to a DataPage in the kernel heap.\n\nThread Deletion Preparation: Prepare a thread for deletion by ensuring that if the thread is using the FPU, the FPU ownership is switched to a default state.",
    "input": "",
    "output": "definition\n  in_user_frame :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n  \"in_user_frame p s \\<equiv>\n   \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) =\n        Some (ArchObj (DataPage False sz))\"\n\ndefinition\n  fpu_thread_delete :: \"obj_ref \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"fpu_thread_delete thread_ptr \\<equiv> do\n    using_fpu \\<leftarrow> do_machine_op (nativeThreadUsingFPU thread_ptr);\n    when using_fpu $ do_machine_op (switchFpuOwner 0 0)\n  od\"\n\ndefinition\n  prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"prepare_thread_delete thread_ptr \\<equiv> fpu_thread_delete thread_ptr\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Numeric Value Visibility: Ensure the numeric value of `msg_align_bits` is explicitly visible by unfolding and simplifying its definition.",
    "input": "",
    "output": "lemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Extract High ASID Bits: Extract the high bits of a given ASID to form an ASID high index, which is used for accessing the virtual address space.",
    "input": "",
    "output": "text \\<open>The high bits of a virtual ASID.\\<close>\ndefinition\n  asid_high_bits_of :: \"asid \\<Rightarrow> asid_high_index\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Low Bits Extraction: Extract the low bits of a virtual ASID and convert them to an ASID low index.",
    "input": "",
    "output": "definition\n  asid_low_bits_of :: \"asid \\<Rightarrow> asid_low_index\" where\n  \"asid_low_bits_of asid \\<equiv> ucast asid\"\n\nlemmas asid_bits_of_defs =\n  asid_high_bits_of_def asid_low_bits_of_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Heap Access: Provides functions to manipulate ASID pools, page directories, and page tables within the kernel heap, enabling efficient management of virtual memory structures.",
    "input": "",
    "output": "text \\<open>Manipulate ASID pools, page directories and page tables in the kernel\nheap.\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access and Management: Provides functions to get and set ASID pools and page directories, enabling the kernel to manage virtual address spaces and their associated data structures.",
    "input": "",
    "output": "locale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\"\n  where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"\n\ndefinition\n  get_asid_pool :: \"obj_ref \\<Rightarrow> (asid_low_index \\<rightharpoonup> obj_ref, 'z::state_ext) s_monad\" where\n  \"get_asid_pool ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (ASIDPool pool) \\<Rightarrow> return pool\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_asid_pool :: \"obj_ref \\<Rightarrow> (asid_low_index \\<rightharpoonup> obj_ref) \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n \"set_asid_pool ptr pool \\<equiv> set_object ptr (ArchObj (ASIDPool pool))\"\n\ndefinition\n  get_pd :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pde,'z::state_ext) s_monad\" where\n  \"get_pd ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageDirectory pd) \\<Rightarrow> return pd\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pd :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pde) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pd ptr pd \\<equiv> set_object ptr (ArchObj (PageDirectory pd))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Page Directory Access: Provides functions to access and modify the page directory (PDE) and page table (PTE) entries in the x64 virtual space. The functions calculate the base and offset of the given pointer, retrieve or store the corresponding PDE, and handle the retrieval and setting of PTEs for a given page table.",
    "input": "",
    "output": "definition\n  get_pde :: \"obj_ref \\<Rightarrow> (pde,'z::state_ext) s_monad\" where\n  \"get_pde ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pd_bits);\n     offset \\<leftarrow> return ((ptr && mask pd_bits) >> word_size_bits);\n     pd \\<leftarrow> get_pd base;\n     return $ pd (ucast offset)\n   od\"\n\ndefinition\n  store_pde :: \"obj_ref \\<Rightarrow> pde \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pde p pde \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pd_bits);\n    offset \\<leftarrow> return ((p && mask pd_bits) >> word_size_bits);\n    pd \\<leftarrow> get_pd base;\n    pd' \\<leftarrow> return $ pd (ucast offset := pde);\n    set_pd base pd'\n  od\"\n\n\ndefinition\n  get_pt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pte,'z::state_ext) s_monad\" where\n  \"get_pt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pt ptr pt \\<equiv> set_object ptr (ArchObj (PageTable pt))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access and Modification: Provides functions to access and modify the x64 virtual space, including retrieving and storing PTEs, and getting and setting PDPTs. These functions ensure that the kernel can effectively manage and manipulate the virtual memory structures.",
    "input": "",
    "output": "definition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\"\n\ndefinition\n  get_pdpt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pdpte,'z::state_ext) s_monad\" where\n  \"get_pdpt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PDPointerTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pdpt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pdpte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pdpt ptr pt \\<equiv> set_object ptr (ArchObj (PDPointerTable pt))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access and Modification: Provides functions to access and modify the x64 virtual address space, including retrieving and storing PDPTEs, and getting and setting the PML4 table. These operations ensure that the kernel can manage and manipulate the virtual memory mappings effectively.",
    "input": "",
    "output": "definition\n  get_pdpte :: \"obj_ref \\<Rightarrow> (pdpte,'z::state_ext) s_monad\" where\n  \"get_pdpte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pdpt_bits);\n     offset \\<leftarrow> return ((ptr && mask pdpt_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pdpt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pdpte :: \"obj_ref \\<Rightarrow> pdpte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pdpte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pdpt_bits);\n    offset \\<leftarrow> return ((p && mask pdpt_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pdpt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pdpt base pt'\n  od\"\n\ndefinition\n  get_pml4 :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pml4e,'z::state_ext) s_monad\" where\n  \"get_pml4 ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageMapL4 pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pml4 :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pml4e) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pml4 ptr pt \\<equiv> set_object ptr (ArchObj (PageMapL4 pt))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "PML4E Access and Modification: Retrieve and modify the PML4E entry at a given pointer in kernel memory. The functions calculate the base address and offset, access the PML4 table, and either return or update the specific PML4E entry.",
    "input": "",
    "output": "definition\n  get_pml4e :: \"obj_ref \\<Rightarrow> (pml4e,'z::state_ext) s_monad\" where\n  \"get_pml4e ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pml4_bits);\n     offset \\<leftarrow> return ((ptr && mask pml4_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pml4 base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pml4e :: \"obj_ref \\<Rightarrow> pml4e \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pml4e p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pml4_bits);\n    offset \\<leftarrow> return ((p && mask pml4_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pml4 base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pml4 base pt'\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Index Calculation: Compute the indices for different levels of the x64 virtual address space (page table, page directory, page directory pointer table, and page map level 4) by shifting and masking the virtual pointer.",
    "input": "",
    "output": "definition\nget_pt_index :: \"vspace_ref \\<Rightarrow> machine_word\" where\n\"get_pt_index vptr \\<equiv> (vptr >> pt_shift_bits) && mask ptTranslationBits\"\n\ndefinition\nget_pd_index :: \"vspace_ref \\<Rightarrow> machine_word\" where\n\"get_pd_index vptr \\<equiv> (vptr >> (pd_shift_bits)) && mask ptTranslationBits\"\n\ndefinition\nget_pdpt_index :: \"vspace_ref \\<Rightarrow> machine_word\" where\n\"get_pdpt_index vptr \\<equiv> (vptr >> (pdpt_shift_bits)) && mask ptTranslationBits\"\n\ndefinition\nget_pml4_index :: \"vspace_ref \\<Rightarrow> machine_word\" where\n\"get_pml4_index vptr \\<equiv> (vptr >> pml4_shift_bits) && mask ptTranslationBits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Copy Global Mappings: Replicate the kernel window mappings from the global page directory into a new page directory object, ensuring that the kernel's virtual address space is consistently mapped across different page directories.",
    "input": "",
    "output": "definition\ncopy_global_mappings :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"copy_global_mappings new_pm \\<equiv> do\n    global_pm \\<leftarrow> gets (x64_global_pml4 \\<circ> arch_state);\n    base \\<leftarrow> return $ get_pml4_index pptr_base;\n    pme_bits \\<leftarrow> return word_size_bits;\n    pm_size \\<leftarrow> return (1 << ptTranslationBits);\n    mapM_x (\\<lambda>index. do\n        offset \\<leftarrow> return (index << pme_bits);\n        pme \\<leftarrow> get_pml4e (global_pm + offset);\n        store_pml4e (new_pm + offset) pme\n    od) [base  .e.  pm_size - 1]\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup: Traverse the page directories and tables to locate the slot corresponding to a given virtual address. This involves walking the PML4 and PDPT levels, ensuring that the correct page directory pointer is retrieved and the appropriate slot is identified.",
    "input": "",
    "output": "definition\nlookup_pml4_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\" where\n\"lookup_pml4_slot pm vptr \\<equiv> let pm_index = get_pml4_index vptr\n                             in pm + (pm_index << word_size_bits)\"\n\ndefinition\nlookup_pdpt_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"lookup_pdpt_slot pd vptr \\<equiv> doE\n    pml4_slot \\<leftarrow> returnOk (lookup_pml4_slot pd vptr);\n    pml4e \\<leftarrow> liftE $ get_pml4e pml4_slot;\n    (case pml4e of\n          PDPointerTablePML4E tab _ _ \\<Rightarrow> (doE\n            pd \\<leftarrow> returnOk (ptrFromPAddr tab);\n            pd_index \\<leftarrow> returnOk (get_pdpt_index vptr);\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << word_size_bits));\n            returnOk pd_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability pml4_shift_bits)\n odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup PDPT Slot: Provides a non-failing method to determine the slot in the Page Directory Pointer Table (PDPT) for a given virtual address, assuming the base address of the PDPT is known.",
    "input": "",
    "output": "definition\n  lookup_pdpt_slot_no_fail :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\nwhere\n  \"lookup_pdpt_slot_no_fail pdpt vptr \\<equiv>\n     pdpt + (get_pdpt_index vptr << word_size_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup Page Directory Slot: Computes a pointer to the page directory entry (PDE) in kernel memory by first locating the corresponding page-directory-pointer-table entry (PDPTE) and then using it to find the page directory. If the PDPTE is not a valid page directory, an error is thrown.",
    "input": "",
    "output": "definition\nlookup_pd_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"lookup_pd_slot pd vptr \\<equiv> doE\n    pdpt_slot \\<leftarrow> lookup_pdpt_slot pd vptr;\n    pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n    (case pdpte of\n          PageDirectoryPDPTE tab _ _ \\<Rightarrow> (doE\n            pd \\<leftarrow> returnOk (ptrFromPAddr tab);\n            pd_index \\<leftarrow> returnOk (get_pd_index vptr);\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << word_size_bits));\n            returnOk pd_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability pdpt_shift_bits)\n odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup PD Slot Without Failure: Provides a reliable method to determine the physical address of a page directory slot given a known page directory pointer table (PDPT) and a virtual space reference (vptr). This ensures that the lookup operation does not fail, facilitating efficient and predictable memory management.",
    "input": "",
    "output": "definition\n  lookup_pd_slot_no_fail :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\nwhere\n  \"lookup_pd_slot_no_fail pd vptr \\<equiv>\n     pd + (get_pd_index vptr << word_size_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Slot Lookup: Given a virtual address, the function computes and returns a pointer to the corresponding page table entry (PTE) in kernel memory. If the virtual address is mapped on a section or super section, the function fails.",
    "input": "",
    "output": "definition\nlookup_pt_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"lookup_pt_slot vspace vptr \\<equiv> doE\n    pd_slot \\<leftarrow> lookup_pd_slot vspace vptr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    (case pde of\n          PageTablePDE ptab _ _ \\<Rightarrow>   (doE\n            pt \\<leftarrow> returnOk (ptrFromPAddr ptab);\n            pt_index \\<leftarrow> returnOk (get_pt_index vptr);\n            pt_slot \\<leftarrow> returnOk (pt + (pt_index << word_size_bits));\n            returnOk pt_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability pd_shift_bits)\n   odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup Page Table Slot: Provides a non-failing method to determine the page table slot for a given virtual address, assuming the page directory is already known. This ensures efficient and reliable access to the VSpace structure.",
    "input": "",
    "output": "definition\n  lookup_pt_slot_no_fail :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\nwhere\n  \"lookup_pt_slot_no_fail pt vptr \\<equiv>\n     pt + (get_pt_index vptr << word_size_bits)\"\n\n\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Virtual Page Alignment: Ensure that the given virtual page pointer is aligned to the specified page size, throwing an alignment error if the condition is not met.",
    "input": "",
    "output": "text \\<open>This definition ensures that the given pointer is aligned\nto the given page size.\\<close>\n\ndefinition\n  check_vp_alignment :: \"vmpage_size \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $\n       throwError AlignmentError\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-specific Invocation Decoding: Decode and validate architecture-specific system calls, including page, page table, page directory, and PDPT mappings and unmappings, as well as ASID pool assignments. This ensures that the system calls are correctly interpreted and executed, maintaining the integrity and security of the virtual memory system.",
    "input": "",
    "output": "text \\<open>This definition decodes architecture-specific invocations.\n\\<close>\n\ndefinition\n  page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\nwhere\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"\n\n\n\n*)\n\ndefinition\ndecode_page_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap\n                            \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_page_invocation label args cte cap extra_caps \\<equiv> (case cap of\n  PageCap dev p R map_type pgsz mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel X64PageMap then\n    if length args > 2 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             rights_mask = args ! 1;\n             attr = args ! 2;\n             vspace_cap = fst (extra_caps ! 0)\n         in doE\n             (vspace, asid) \\<leftarrow> (case vspace_cap of\n                                   ArchObjectCap (PML4Cap pm (Some asid)) \\<Rightarrow>\n                                         returnOk (pm, asid)\n                                 | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n             case mapped_address of\n               Some (asid', vaddr') \\<Rightarrow> doE\n                 whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n                 whenE (map_type \\<noteq> VMVSpaceMap) $ throwError IllegalOperation;\n                 whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0)\n               odE\n             | None \\<Rightarrow> doE\n                 vtop \\<leftarrow> returnOk $ vaddr + bit (pageBitsForSize pgsz);\n                 whenE (vaddr > user_vtop \\<or> vtop > user_vtop) $ throwError $ InvalidArgument 0\n               odE;\n             vspace' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n             whenE (vspace' \\<noteq> vspace) $ throwError $ InvalidCapability 1;\n             vm_rights \\<leftarrow> returnOk $ mask_vm_rights R $ data_to_rights rights_mask;\n             check_vp_alignment pgsz vaddr;\n             entries \\<leftarrow> create_mapping_entries (addrFromPPtr p) vaddr pgsz vm_rights\n                                               (attribs_from_word attr) vspace;\n             ensure_safe_mapping entries;\n             returnOk $ InvokePage $ PageMap\n               (ArchObjectCap $ PageCap dev p R VMVSpaceMap pgsz (Some (asid,vaddr))) cte entries vspace\n          odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel X64PageUnmap then\n             \\<^cancel>\\<open>case map_type of\n                 VMIOSpaceMap \\<Rightarrow> decode_io_unmap_invocation label args cte cap extra_caps\n               | _ \\<Rightarrow>\\<close> returnOk $ InvokePage $ PageUnmap cap cte\n    \\<^cancel>\\<open>FIXME x64-vtd:\n    else if invocation_type label = ArchInvocationLabel X64PageMapIO\n    then decode_io_map_invocation label args cte cap extra_caps \\<close>\n    else if invocation_type label = ArchInvocationLabel X64PageGetAddress\n    then returnOk $ InvokePage $ PageGetAddr p\n  else throwError IllegalOperation\n | _ \\<Rightarrow> fail)\"\n\ndefinition filter_frame_attrs :: \"frame_attrs \\<Rightarrow> table_attrs\"\nwhere\n  \"filter_frame_attrs attrs \\<equiv> {s. \\<exists>s' \\<in> attrs. s' = PTAttr s}\"\n\ndefinition\n  decode_page_table_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                                  (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_page_table_invocation label args cte cap extra_caps \\<equiv> (case cap of\n    PageTableCap p mapped_address \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64PageTableMap then\n      if length args > 1 \\<and> length extra_caps > 0\n      then let vaddr = args ! 0;\n               attr = args ! 1;\n               pml4_cap = fst (extra_caps ! 0)\n      in doE\n               whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n               vaddr' \\<leftarrow> returnOk $ vaddr && ~~ mask pd_shift_bits;\n               (pml4, asid) \\<leftarrow> (case pml4_cap of\n                   ArchObjectCap (PML4Cap pml4 (Some asid)) \\<Rightarrow> returnOk (pml4, asid)\n                   | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n               whenE (user_vtop < vaddr') $ throwError $ InvalidArgument 0;\n               pml4' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n               whenE (pml4' \\<noteq> pml4) $ throwError $ InvalidCapability 1;\n               pd_slot \\<leftarrow> lookup_error_on_failure False $ lookup_pd_slot pml4 vaddr';\n               old_pde \\<leftarrow> liftE $ get_pde pd_slot;\n               unlessE (old_pde = InvalidPDE) $ throwError DeleteFirst;\n               pde \\<leftarrow> returnOk (PageTablePDE (addrFromPPtr p)\n                                  (filter_frame_attrs $ attribs_from_word attr) vm_read_write);\n               cap' <- returnOk $ ArchObjectCap $ PageTableCap p $ Some (asid, vaddr');\n               returnOk $ InvokePageTable $ PageTableMap cap' cte pde pd_slot pml4\n            odE\n      else throwError TruncatedMessage\n      else if invocation_type label = ArchInvocationLabel X64PageTableUnmap then doE\n               final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n               unlessE final $ throwError RevokeFirst;\n               returnOk $ InvokePageTable $ PageTableUnmap (ArchObjectCap cap) cte\n        odE\n      else throwError IllegalOperation\n  | _ \\<Rightarrow> fail)\"\n\ndefinition\n  decode_page_directory_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                                      (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_page_directory_invocation label args cte cap extra_caps \\<equiv> (case cap of\n    PageDirectoryCap p mapped_address \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64PageDirectoryMap then\n      if length args > 1 \\<and> length extra_caps > 0\n      then let vaddr = args ! 0;\n               attr = args ! 1;\n               pml4_cap = fst (extra_caps ! 0)\n      in doE\n               whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n               vaddr' \\<leftarrow> returnOk $ vaddr && ~~ mask pdpt_shift_bits;\n               (pml4, asid) \\<leftarrow> (case pml4_cap of\n                       ArchObjectCap (PML4Cap pml4 (Some asid)) \\<Rightarrow> returnOk (pml4, asid)\n                       | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n               whenE (user_vtop < vaddr') $ throwError $ InvalidArgument 0;\n               pml4' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n               whenE (pml4' \\<noteq> pml4) $ throwError $ InvalidCapability 1;\n               pdpt_slot \\<leftarrow> lookup_error_on_failure False $ lookup_pdpt_slot pml4 vaddr';\n               old_pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n               unlessE (old_pdpte = InvalidPDPTE) $ throwError DeleteFirst;\n               pdpte \\<leftarrow> returnOk (PageDirectoryPDPTE (addrFromPPtr p)\n                          (filter_frame_attrs $ attribs_from_word attr) vm_read_write);\n               cap' <- returnOk $ ArchObjectCap $ PageDirectoryCap p $ Some (asid, vaddr');\n               returnOk $ InvokePageDirectory $ PageDirectoryMap cap' cte pdpte pdpt_slot pml4\n        odE\n      else throwError TruncatedMessage\n      else if invocation_type label = ArchInvocationLabel X64PageDirectoryUnmap then doE\n               final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n               unlessE final $ throwError RevokeFirst;\n               returnOk $ InvokePageDirectory $ PageDirectoryUnmap (ArchObjectCap cap) cte\n            odE\n      else throwError IllegalOperation\n  | _ \\<Rightarrow> fail)\"\n\ndefinition\n  decode_pdpt_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                                      (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_pdpt_invocation label args cte cap extra_caps \\<equiv> (case cap of\n    PDPointerTableCap p mapped_address \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64PDPTMap then\n      if length args > 1 \\<and> length extra_caps > 0\n      then let vaddr = args ! 0;\n               attr = args ! 1;\n               pml4_cap = fst (extra_caps ! 0)\n      in doE\n               whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n               vaddr' \\<leftarrow> returnOk $ vaddr && ~~ mask pml4_shift_bits;\n               (pml4 ,asid) \\<leftarrow> (case pml4_cap of\n                       ArchObjectCap (PML4Cap pml4 (Some asid)) \\<Rightarrow> returnOk (pml4, asid)\n                       | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n               whenE (user_vtop < vaddr') $ throwError $ InvalidArgument 0;\n               pml4' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid (asid);\n               whenE (pml4' \\<noteq> pml4) $ throwError $ InvalidCapability 1;\n               pml_slot \\<leftarrow> returnOk $ lookup_pml4_slot pml4 vaddr';\n               old_pml4e \\<leftarrow> liftE $ get_pml4e pml_slot;\n               unlessE (old_pml4e = InvalidPML4E) $ throwError DeleteFirst;\n               pml4e \\<leftarrow> returnOk (PDPointerTablePML4E (addrFromPPtr p)\n                          (filter_frame_attrs $ attribs_from_word attr) vm_read_write);\n               cap' <- returnOk $ ArchObjectCap $ PDPointerTableCap p $ Some (asid, vaddr');\n               returnOk $ InvokePDPT $ PDPTMap cap' cte pml4e pml_slot pml4\n            odE\n      else throwError TruncatedMessage\n      else if invocation_type label = ArchInvocationLabel X64PDPTUnmap then doE\n               final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n               unlessE final $ throwError RevokeFirst;\n               returnOk $ InvokePDPT $ PDPTUnmap (ArchObjectCap cap) cte\n         odE\n      else throwError IllegalOperation\n  | _ \\<Rightarrow> fail)\"\n\ndefinition\n  arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n    PDPointerTableCap _ _ \\<Rightarrow> decode_pdpt_invocation label args cte cap extra_caps\n  | PageDirectoryCap _ _ \\<Rightarrow> decode_page_directory_invocation label args cte cap extra_caps\n  | PageTableCap _ _ \\<Rightarrow> decode_page_table_invocation label args cte cap extra_caps\n  | PageCap _ _ _ _ _ _ \\<Rightarrow> decode_page_invocation label args cte cap extra_caps\n  | ASIDControlCap \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64ASIDControlMakePool then\n      if length args > 1 \\<and> length extra_caps > 1\n      then let index = args ! 0;\n               depth = args ! 1;\n               (untyped, parent_slot) = extra_caps ! 0;\n               root = fst (extra_caps ! 1)\n      in doE\n               asid_table \\<leftarrow> liftE $ gets (x64_asid_table \\<circ> arch_state);\n               free_set \\<leftarrow> returnOk (- dom asid_table);\n               whenE (free_set = {}) $ throwError DeleteFirst;\n               free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n               base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n               (p,n) \\<leftarrow> (case untyped of UntypedCap False p n f \\<Rightarrow> returnOk (p,n)\n                                        | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n               frame \\<leftarrow> (if n = pageBits\n                        then doE\n                            ensure_no_children parent_slot;\n                            returnOk p\n                          odE\n                        else  throwError $ InvalidCapability 1);\n               dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n               ensure_empty dest_slot;\n               returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n           odE\n   else throwError TruncatedMessage\n   else throwError IllegalOperation\n\n  | ASIDPoolCap p base \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64ASIDPoolAssign then\n      if length extra_caps > 0\n      then let (pd_cap, pd_cap_slot) = extra_caps ! 0 in\n            case pd_cap of\n               ArchObjectCap (PML4Cap _ None) \\<Rightarrow> doE\n                  asid_table \\<leftarrow> liftE $ gets (x64_asid_table \\<circ> arch_state);\n                  pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n                  whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n                  whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n                  pool \\<leftarrow> liftE $ get_asid_pool p;\n                  free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n                  whenE (free_set = {}) $ throwError DeleteFirst;\n                  offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n                  returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pd_cap_slot\n              odE\n            | _ \\<Rightarrow> throwError $ InvalidCapability 1\n      else throwError TruncatedMessage\n      else throwError IllegalOperation\n\n  | IOPortCap f l \\<Rightarrow> decode_port_invocation label args (IOPortCap f l)\n  | IOPortControlCap \\<Rightarrow> decode_ioport_control_invocation label args cte cap (map fst extra_caps)\n  | PML4Cap a b \\<Rightarrow> throwError IllegalOperation\"\n\ndefinition\n  arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n \"arch_data_to_obj_type n \\<equiv>\n  if      n = 0 then Some PDPTObj\n  else if n = 1 then Some PML4Obj\n  else if n = 2 then Some HugePageObj\n  else if n = 3 then Some SmallPageObj\n  else if n = 4 then Some LargePageObj\n  else if n = 5 then Some PageTableObj\n  else if n = 6 then Some PageDirectoryObj\n  else None\"\n\ndefinition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> throwError IllegalOperation\"\n\nend (* context Arch *)\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Management Invocations: Define the operations for managing memory structures, including mapping and unmapping of page directory pointer tables, page directories, and page tables, as well as creating ASID pools and assigning ASIDs. These operations ensure that memory is correctly allocated and deallocated, maintaining the integrity and efficiency of the virtual memory system.",
    "input": "",
    "output": "datatype pdpt_invocation =\n    PDPTMap cap cslot_ptr pml4e obj_ref obj_ref\n  | PDPTUnmap cap cslot_ptr\n\ndatatype page_directory_invocation =\n    PageDirectoryMap cap cslot_ptr pdpte obj_ref obj_ref\n  | PageDirectoryUnmap cap cslot_ptr\n\ndatatype page_table_invocation =\n    PageTableMap cap cslot_ptr pde obj_ref obj_ref\n  | PageTableUnmap cap cslot_ptr\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation\n     = PageMap\n         (page_map_cap: cap)\n         (page_map_ct_slot: cslot_ptr)\n         (page_map_entries: \"vm_page_entry \\<times> obj_ref\")\n         (page_map_vspace: obj_ref)\n     | PageUnmap\n         (page_unmap_cap: arch_cap)\n         (page_unmap_cap_slot: cslot_ptr)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page and I/O Port Operations: Enable the management of page mappings and I/O port operations, including reading from and writing to I/O ports with different data sizes (8-bit, 16-bit, 32-bit). These operations ensure that memory and I/O interactions are controlled and secure.",
    "input": "",
    "output": "| PageGetAddr\n         (page_get_paddr: obj_ref)\n\ndatatype io_port_invocation_data\n  = IOPortIn8 | IOPortIn16 | IOPortIn32\n  | IOPortOut8 \"8 word\" | IOPortOut16 \"16 word\" | IOPortOut32 \"32 word\"\n\ndatatype io_port_invocation = IOPortInvocation io_port io_port_invocation_data\n\ndatatype io_port_control_invocation = IOPortControlInvocation io_port io_port cslot_ptr cslot_ptr",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocations: Define a set of architectural operations including page table, page directory, PDPT, page, ASID control, ASID pool, I/O port, and I/O port control invocations. These operations allow for the management and manipulation of memory and I/O resources in the system.",
    "input": "",
    "output": "datatype arch_invocation\n     = InvokePageTable page_table_invocation\n     | InvokePageDirectory page_directory_invocation\n     | InvokePDPT pdpt_invocation\n     | InvokePage page_invocation\n     | InvokeASIDControl asid_control_invocation\n     | InvokeASIDPool asid_pool_invocation\n     | InvokeIOPort io_port_invocation\n     | InvokeIOPortControl io_port_control_invocation",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural IRQ Control: Supports the issuance of IRQ handlers for IOAPIC and MSI interrupts, allowing for the configuration of interrupt handling with specific control parameters.",
    "input": "",
    "output": "datatype arch_copy_register_sets = X64NoExtraRegisters\n\ndefinition \"ArchDefaultExtraRegisters \\<equiv> X64NoExtraRegisters\"\n\ndatatype arch_irq_control_invocation\n  = IssueIRQHandlerIOAPIC irq cslot_ptr cslot_ptr\n      machine_word machine_word machine_word machine_word machine_word\n  | IssueIRQHandlerMSI irq cslot_ptr cslot_ptr\n      machine_word machine_word machine_word machine_word\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Data Types: Defines architecture-specific data types, including `io_port` and `io_asid`, both represented as 16-bit words.",
    "input": "",
    "output": "type_synonym io_port = \"16 word\"\ntype_synonym io_asid = \"16 word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "x64-Specific Capabilities: The x64 kernel supports various architecture-specific capabilities, including ASID pools, ASID controller, IO ports, IO port controller, and different types of virtual memory mappings such as page, page table, page directory, PD pointer table, and PML4. These capabilities enable the management and control of memory and I/O resources specific to the x64 architecture.",
    "input": "",
    "output": "text \\<open>The x64 kernel supports capabilities for ASID pools and an ASID controller capability,\nalong with capabilities for IO ports and spaces, as well as virtual memory mappings.\\<close>\n\ndatatype arch_cap =\n   ASIDPoolCap (acap_asid_pool : obj_ref) (acap_asid_base : asid)\n | ASIDControlCap\n | IOPortCap (acap_io_port_first_port : io_port) (acap_io_port_last_port : io_port)\n | IOPortControlCap\n\n | PageCap bool obj_ref (acap_rights : cap_rights) vmmap_type vmpage_size \"(asid * vspace_ref) option\"\n | PageTableCap obj_ref \"(asid * vspace_ref) option\"\n | PageDirectoryCap obj_ref \"(asid * vspace_ref) option\"\n | PDPointerTableCap obj_ref \"(asid * vspace_ref) option\"\n | PML4Cap obj_ref \"asid option\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "CR3 Data Type: Represents a control register 3 (CR3) with a base address and a process context identifier (PCID). The base address and PCID can be extracted from the CR3 data type, allowing for the manipulation and retrieval of these architecture-specific properties.",
    "input": "",
    "output": "datatype cr3 = cr3 obj_ref asid\n\nprimrec\n  cr3_base_address :: \"cr3 \\<Rightarrow> obj_ref\"\nwhere\n  \"cr3_base_address (cr3 addr _) = addr\"\n\nprimrec\n  cr3_pcid :: \"cr3 \\<Rightarrow> asid\"\nwhere\n  \"cr3_pcid (cr3 _ pcid) = pcid\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Data Types: Define various x64-specific data types and their attributes, including table and frame attributes, page table entries (PML4E, PDPTE, PDE, PTE), and I/O translation structures (IOCTE, IOPT, IORTE). These data types and their attributes are used to manage memory and I/O translations, ensuring proper access control and memory management.",
    "input": "",
    "output": "datatype table_attr = Accessed | CacheDisabled | WriteThrough | ExecuteDisable\ntype_synonym table_attrs = \"table_attr set\"\n\ndatatype frame_attr = PTAttr table_attr | Global | PAT | Dirty\ntype_synonym frame_attrs = \"frame_attr set\"\n\ndatatype pml4e\n     = InvalidPML4E\n     | PDPointerTablePML4E\n         (pml4_table : obj_ref)\n         (pml4e_attrs : table_attrs)\n         (pml4e_rights : vm_rights)\n\ndatatype pdpte\n     = InvalidPDPTE\n     | PageDirectoryPDPTE\n         (pdpt_table : obj_ref)\n         (pdpt_table_attrs : table_attrs)\n         (pdpt_rights : vm_rights)\n     | HugePagePDPTE\n         (pdpt_frame : obj_ref)\n         (pdpt_frame_attrs : frame_attrs)\n         (pdpt_rights : vm_rights)\n\ndatatype pde\n      = InvalidPDE\n      | PageTablePDE\n         obj_ref\n         (pt_attrs : table_attrs)\n         (pde_rights : cap_rights)\n      | LargePagePDE\n         obj_ref\n         (pde_page_attrs : frame_attrs)\n         (pde_rights: cap_rights)\n\ndatatype pte\n      = InvalidPTE\n      | SmallPagePTE\n         (pte_frame: obj_ref)\n         (pte_frame_attrs : frame_attrs)\n         (pte_rights : cap_rights)\n\n\ndatatype vm_page_entry = VMPTE pte | VMPDE pde | VMPDPTE pdpte\n\ndatatype translation_type = NotTranslated | Translated\n\ndatatype iocte =\n   InvalidIOCTE\n | VTDCTE\n   (domain_id : word16)\n   (res_mem_reg: bool)\n   (address_width: nat)\n   (next_level_ptr: obj_ref)\n   (translation_type: translation_type)\n   (iocte_present : bool)\n\ndatatype iopte =\n   InvalidIOPTE\n | VTDPTE\n   (frame_ptr : obj_ref)\n   (io_pte_rights  : vm_rights)\n\ndatatype iorte =\n   InvalidIORTE\n | VTDRTE\n   (context_table : obj_ref)\n   (iorte_present : bool)\n\ndatatype arch_kernel_obj =\n   ASIDPool \"9 word \\<rightharpoonup> obj_ref\"\n | PageTable \"9 word \\<Rightarrow> pte\"\n | PageDirectory \"9 word \\<Rightarrow> pde\"\n | PDPointerTable \"9 word \\<Rightarrow> pdpte\"\n | PageMapL4 \"9 word \\<Rightarrow> pml4e\"\n | DataPage bool vmpage_size\n\n\ndefinition table_size :: nat where\n  \"table_size = ptTranslationBits + word_size_bits\"\n\ndefinition iotable_size :: nat where\n  \"iotable_size = ptTranslationBits + 2*word_size_bits\"\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 5\"\n\nprimrec\n  arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\nwhere\n  \"arch_obj_size (ASIDPoolCap _ _) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (IOPortCap _ _) = 0\"\n| \"arch_obj_size IOPortControlCap = 0\"\n\n| \"arch_obj_size (PageCap _ _ _ _ sz _) = pageBitsForSize sz\"\n| \"arch_obj_size (PageTableCap _ _) = table_size\"\n| \"arch_obj_size (PageDirectoryCap _ _) = table_size\"\n| \"arch_obj_size (PDPointerTableCap _ _) = table_size\"\n| \"arch_obj_size (PML4Cap _ _) = table_size\"\n\nprimrec\n  arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_cap_is_device (ASIDPoolCap _ _) = False\"\n| \"arch_cap_is_device ASIDControlCap = False\"\n| \"arch_cap_is_device (IOPortCap _ _) = False\"\n| \"arch_cap_is_device IOPortControlCap = False\"\n\n| \"arch_cap_is_device (PageCap is_dev _ _ _ _ _) = is_dev\"\n| \"arch_cap_is_device (PageTableCap _ _) = False\"\n| \"arch_cap_is_device (PageDirectoryCap _ _) = False\"\n| \"arch_cap_is_device (PDPointerTableCap _ _) = False\"\n| \"arch_cap_is_device (PML4Cap _ _) = False\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 11\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 5\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 47\"\n\nprimrec\n  arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\nwhere\n  \"arch_kobj_size (ASIDPool _) = pageBits\"\n| \"arch_kobj_size (PageTable _) = table_size\"\n| \"arch_kobj_size (PageDirectory _) = table_size\"\n| \"arch_kobj_size (PDPointerTable _) = table_size\"\n| \"arch_kobj_size (PageMapL4 _) = table_size\"\n| \"arch_kobj_size (DataPage _ sz) = pageBitsForSize sz\"\n\nprimrec\n  aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\nwhere\n  \"aobj_ref (ASIDPoolCap x _) = Some x\"\n| \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref (IOPortCap _ _) = None\"\n| \"aobj_ref IOPortControlCap = None\"\n\n| \"aobj_ref (PageCap _ x _ _ _ _) = Some x\"\n| \"aobj_ref (PageDirectoryCap x _) = Some x\"\n| \"aobj_ref (PageTableCap x _) = Some x\"\n| \"aobj_ref (PDPointerTableCap x _) = Some x\"\n| \"aobj_ref (PML4Cap x _) = Some x\"\n\n\ndefinition\n  acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n \"acap_rights_update rs ac \\<equiv> case ac of\n    PageCap dev x rs' m sz as \\<Rightarrow> PageCap dev x (validate_vm_rights rs) m sz as\n  | _                   \\<Rightarrow> ac\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Object Types and Default Objects: Defines a set of architecture-specific object types, including various page sizes, page tables, and other memory management structures. For each object type, it specifies whether the object is a frame type and provides default capabilities and kernel objects, ensuring consistent initialization and management of x64-specific memory and interrupt resources.",
    "input": "",
    "output": "datatype\n  aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | HugePageObj\n  | PageTableObj\n  | PageDirectoryObj\n  | PDPTObj\n  | PML4Obj\n  | ASIDPoolObj\n\ndatatype X64IRQState =\n   IRQFree\n | IRQReserved\n | IRQMSI\n      (MSIBus : machine_word)\n      (MSIDev : machine_word)\n      (MSIFunc : machine_word)\n      (MSIHandle : machine_word)\n | IRQIOAPIC\n      (IRQioapic : machine_word)\n      (IRQPin : machine_word)\n      (IRQLevel : machine_word)\n      (IRQPolarity : machine_word)\n      (IRQMasked : bool)\n\ndefinition\n  arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\"\nwhere\n  \"arch_is_frame_type aobj \\<equiv> case aobj of\n         SmallPageObj \\<Rightarrow> True\n       | LargePageObj \\<Rightarrow> True\n       | HugePageObj \\<Rightarrow> True\n       | _ \\<Rightarrow> False\"\n\ndefinition\n  arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\" where\n \"arch_default_cap tp r n dev \\<equiv> case tp of\n    SmallPageObj \\<Rightarrow> PageCap dev r vm_read_write VMNoMap X64SmallPage None\n  | LargePageObj \\<Rightarrow> PageCap dev r vm_read_write VMNoMap X64LargePage None\n  | HugePageObj \\<Rightarrow> PageCap dev r vm_read_write VMNoMap X64HugePage None\n  | PageTableObj \\<Rightarrow> PageTableCap r None\n  | PageDirectoryObj \\<Rightarrow> PageDirectoryCap r None\n  | PDPTObj \\<Rightarrow> PDPointerTableCap r None\n  | PML4Obj \\<Rightarrow> PML4Cap r None\n  | ASIDPoolObj \\<Rightarrow> ASIDPoolCap r 0\" (* unused *)\n\ndefinition\n  default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\" where\n \"default_arch_object tp dev n \\<equiv> case tp of\n    SmallPageObj \\<Rightarrow> DataPage dev X64SmallPage\n  | LargePageObj \\<Rightarrow> DataPage dev X64LargePage\n  | HugePageObj \\<Rightarrow> DataPage dev X64HugePage\n  | PageTableObj \\<Rightarrow> PageTable (\\<lambda>x. InvalidPTE)\n  | PageDirectoryObj \\<Rightarrow> PageDirectory (\\<lambda>x. InvalidPDE)\n  | PDPTObj \\<Rightarrow> PDPointerTable (\\<lambda>x. InvalidPDPTE)\n  | PML4Obj \\<Rightarrow> PageMapL4 (\\<lambda>x. InvalidPML4E)\n  | ASIDPoolObj \\<Rightarrow> ASIDPool (\\<lambda>_. None)\"\n\ntype_synonym x64_vspace_region_uses = \"vspace_ref \\<Rightarrow> x64vspace_region_use\"\n\nend\n\nqualify X64_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific State: Defines the x64-specific data types and structures, including ASID tables, global page tables (PML4, PDPT, PD, PT), kernel virtual space, I/O port allocations, and IRQ state. These structures and their associated bit definitions ensure proper memory management, virtual address translation, and I/O handling in the x64 architecture.",
    "input": "",
    "output": "record arch_state =\n  x64_asid_table            :: \"3 word \\<rightharpoonup> obj_ref\"\n  x64_global_pml4           :: obj_ref\n  x64_kernel_vspace         :: X64_A.x64_vspace_region_uses\n  x64_global_pts            :: \"obj_ref list\"\n  x64_global_pdpts          :: \"obj_ref list\"\n  x64_global_pds            :: \"obj_ref list\"\n  x64_current_cr3           :: \"X64_A.cr3\"\n  x64_allocated_io_ports    :: \"X64_A.io_port \\<Rightarrow> bool\"\n  x64_num_ioapics           :: \"64 word\"\n  x64_ioapic_nirqs          :: \"machine_word \\<Rightarrow> 8 word\"\n  x64_irq_state             :: \"8 word \\<Rightarrow> X64_A.X64IRQState\"\n\n\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  pd_shift_bits :: \"nat\" where\n  \"pd_shift_bits \\<equiv> pageBits + ptTranslationBits\"\n\ndefinition\n  pt_shift_bits :: \"nat\" where\n  \"pt_shift_bits \\<equiv> pageBits\"\n\ndefinition\n  pdpt_shift_bits :: \"nat\" where\n  \"pdpt_shift_bits \\<equiv> pageBits + ptTranslationBits + ptTranslationBits\"\n\ndefinition\n  pml4_shift_bits :: \"nat\" where\n  \"pml4_shift_bits \\<equiv> pageBits + ptTranslationBits + ptTranslationBits + ptTranslationBits\"\n\ndefinition\n  pt_bits :: \"nat\" where\n  \"pt_bits \\<equiv> table_size\"\n\ndefinition\n  pd_bits :: \"nat\" where\n  \"pd_bits \\<equiv> table_size\"\n\ndefinition\n  pdpt_bits :: \"nat\" where\n  \"pdpt_bits \\<equiv> table_size\"\n\ndefinition\n  pml4_bits :: \"nat\" where\n  \"pml4_bits \\<equiv> table_size\"\n\ndefinition\n  iopt_bits :: \"nat\" where\n  \"iopt_bits \\<equiv> iotable_size\"\n\ndefinition\n  vtd_cte_size_bits :: \"nat\" where\n  \"vtd_cte_size_bits \\<equiv> 8\"\n\ndefinition\n  vtd_pt_bits :: \"nat\" where\n  \"vtd_pt_bits \\<equiv> iotable_size\"\n\ndefinition\n  x64_num_io_pt_levels :: \"nat\" where\n  \"x64_num_io_pt_levels \\<equiv> 4\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Object Type Classification: Classifies architectural kernel objects into specific types such as AASIDPool, APageTable, APageDirectory, APDPointerTable, APageMapL4, AUserData, and ADeviceData. This classification ensures that each object is accurately represented and managed according to its type, facilitating proper memory management and system integrity.",
    "input": "",
    "output": "datatype aa_type =\n    AASIDPool\n  | APageTable\n  | APageDirectory\n  | APDPointerTable\n  | APageMapL4\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\"\nwhere\n \"aa_type ao \\<equiv> (case ao of\n           PageTable pt             \\<Rightarrow> APageTable\n         | PageDirectory pd         \\<Rightarrow> APageDirectory\n         | DataPage dev sz          \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n         | ASIDPool f               \\<Rightarrow> AASIDPool\n         | PDPointerTable pdpt      \\<Rightarrow> APDPointerTable\n         | PageMapL4 pm             \\<Rightarrow> APageMapL4)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Badge Bits Definition: The badge word is defined with 64 bits.",
    "input": "",
    "output": "definition\n  badge_bits :: nat where\n  \"badge_bits \\<equiv> 64\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific TCB: Defines x64-specific data types and structures for the Thread Control Block (TCB), ensuring that the TCB is tailored to the architectural requirements of x64 systems.",
    "input": "",
    "output": "qualify X64_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific TCB: Contains a field for user context, which is essential for managing the architectural state of a thread.",
    "input": "",
    "output": "record arch_tcb =\n  tcb_context :: user_context\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  default_arch_tcb :: arch_tcb where\n  \"default_arch_tcb \\<equiv> \\<lparr>tcb_context = new_context\\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific TCB Context Management: Provides accessor functions to set and get the user context within the architecture-specific TCB, ensuring compatibility with the user monad for operations that need to be performed in the context of a specific user.",
    "input": "",
    "output": "definition\n  arch_tcb_context_set :: \"user_context \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_context_set uc a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := uc \\<rparr>\"\n\ndefinition\n  arch_tcb_context_get :: \"arch_tcb \\<Rightarrow> user_context\"\nwhere\n  \"arch_tcb_context_get a_tcb \\<equiv> tcb_context a_tcb\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific TCB Register Management: Provides functions to set and get user registers in the architecture-specific part of the TCB, ensuring that the user context is correctly updated and retrieved.",
    "input": "",
    "output": "definition\n  arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_set_registers regs a_tcb \\<equiv>\n    a_tcb \\<lparr> tcb_context := UserContext (fpu_state (tcb_context a_tcb)) regs \\<rparr>\"\n\ndefinition\n  arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\"\nwhere\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Fault Handling: Generate and handle architecture-specific fault messages. The system creates a fault message containing the program counter, virtual pointer, and architecture-specific data, and processes the fault reply, returning a boolean value.",
    "input": "",
    "output": "(*\nFunctions for fault handling.\n*)\n\nchapter \\<open>arch fault related functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData) od\"\n\ndefinition\n  handle_arch_fault_reply :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_arch_fault_reply vmf thread x y \\<equiv> return True\"\n\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-specific TCB Functions: Define and implement architecture-specific operations for sanitizing register values and handling post-modification of registers. Sanitization ensures that specific registers are set to safe values under certain conditions, and post-modification updates the error register if the target thread is not the current thread.",
    "input": "",
    "output": "(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  sanitise_or_flags :: machine_word\nwhere\n  \"sanitise_or_flags \\<equiv> bit 1 || bit 9\"\n\ndefinition\n  sanitise_and_flags :: machine_word\nwhere\n  \"sanitise_and_flags \\<equiv> mask 12 && ~~ bit 8 && ~~ bit 3 && ~~ bit 5\"\n\ndefinition\n  sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"sanitise_register t r v \\<equiv>\n    let val = (if r = FaultIP \\<or> r = NextIP \\<or> r = FS_BASE \\<or> r = GS_BASE\n               then if v > 0x00007fffffffffff \\<and> v < 0xffff800000000000 then 0 else v\n               else v)\n    in\n      if r = FLAGS then (val || sanitise_or_flags) && sanitise_and_flags else val\"\n\ndefinition\n  arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\nwhere\n  \"arch_get_sanitise_register_info t \\<equiv> return False\"\n\ndefinition\n  arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\nwhere\n  \"arch_post_modify_registers cur t \\<equiv> when (t \\<noteq> cur) $ as_user t $ setRegister ErrorRegister 0\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Region Equivalence: Determines if two I/O port capabilities refer to the same region, either by having identical first and last port numbers for IOPortCap, or by being an IOPortControlCap that encompasses all I/O port capabilities.",
    "input": "",
    "output": "| \"arch_same_region_as (IOPortCap frst lst) c' =\n   (\\<exists>frst' lst'. c' = IOPortCap frst' lst' \\<and> frst' = frst \\<and> lst' = lst)\"\n| \"arch_same_region_as IOPortControlCap c' = (c' = IOPortControlCap \\<or> (\\<exists>f l. c' = IOPortCap f l))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Arch Capabilities for Same Object: Determine if two architecture capabilities refer to the same object by comparing their device, reference, and page size. Additionally, check if an I/O port capability is revocable based on the presence of an I/O port control capability.",
    "input": "",
    "output": "definition\n  same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n \"same_aobject_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (PageCap dev ref _ _ pgsz _, PageCap dev' ref' _ _ pgsz' _)\n          \\<Rightarrow> (dev, ref, pgsz) = (dev', ref', pgsz')\n              \\<and> ref \\<le> ref + 2 ^ pageBitsForSize pgsz - 1\n    | (IOPortControlCap, IOPortCap f' l') \\<Rightarrow> False\n    | _ \\<Rightarrow> arch_same_region_as cp cp')\"\n\ndeclare same_aobject_as_def[simp]\n\ndefinition\n  arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"arch_is_cap_revocable new_cap src_cap \\<equiv>\n           if \\<exists>f l. new_cap = ArchObjectCap (IOPortCap f l)\n             then src_cap = ArchObjectCap IOPortControlCap\n             else False\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Instantiation for x64 Architecture: Defines concrete types for abstract type names, including object references, virtual space references, data, capability references, and length types, as well as specific lengths and indices for ASID (Address Space Identifier) components.",
    "input": "",
    "output": "type_synonym obj_ref            = machine_word\ntype_synonym vspace_ref         = machine_word\n\ntype_synonym data               = machine_word\ntype_synonym cap_ref            = \"bool list\"\ntype_synonym length_type        = machine_word\n\ntype_synonym asid_low_len      = 9\ntype_synonym asid_low_index    = \"asid_low_len word\"\n\ntype_synonym asid_high_len      = 3\ntype_synonym asid_high_index    = \"asid_high_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Representation: The ASID is represented as a machine word, requiring invariants to ensure that the extra bits beyond the 12-bit ASID length are zero.",
    "input": "",
    "output": "type_synonym asid_len           = 12\ntype_synonym asid_rep_len       = machine_word_len\ntype_synonym asid               = \"asid_rep_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Conversions: Convert between different data types, including object references, virtual space references, natural numbers, lengths, and various word sizes. These conversions ensure seamless interoperability and data representation consistency across the system.",
    "input": "",
    "output": "definition\n  oref_to_data   :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_oref   :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition\n  vref_to_data   :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_vref   :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition\n  nat_to_len     :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition\n  data_to_nat    :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition\n  data_to_16     :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition\n  data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition\n  combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition\n  combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Data Conversion Simplifications: Provide simplification rules for converting between different data representations, including object references, virtual references, natural numbers, 16-bit values, and capability pointers.",
    "input": "",
    "output": "lemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Dependent Sizes: Define the standard sizes for various architectural components, including slot bits, message label bits, and the base physical pointer, ensuring consistent and architecture-specific configurations.",
    "input": "",
    "output": "definition\n  slot_bits :: nat where\n  \"slot_bits \\<equiv> 5\"\n\ndefinition\n  msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 52\"\n\ndefinition\n  new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext FPUNullState ((\\<lambda>r. 0)(CS := selCS3, SS := selDS3, FLAGS := 0x202))\"\n\ndefinition\n  pptr_base :: \"machine_word\" where\n  \"pptr_base = Platform.X64.pptrBase\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "User Virtual Address Space: Defines the upper boundary of the virtual address space available to user processes, ensuring that user-level applications have a defined and restricted memory range.",
    "input": "",
    "output": "definition\n  user_vtop :: \"machine_word\" where\n  \"user_vtop = Platform.X64.pptrUserTop\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Base and Idle Thread Pointer: The kernel reserves a specific range of virtual addresses starting from a defined base address, and the idle thread pointer is set to a fixed offset from this base.",
    "input": "",
    "output": "definition\n  kernel_base :: \"vspace_ref\" where\n  \"kernel_base \\<equiv> 0xffffffff80000000\"\n\ndefinition\n  idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = kernel_base + 0x1000\"\n\nend\n\narch_requalify_consts (A) idle_thread_ptr\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Convert Natural Number to Capability Reference: Convert a natural number to a capability reference by dropping the higher-order bits that exceed the specified length and converting the remaining bits to a boolean list.",
    "input": "",
    "output": "definition\n  nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\" where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len)\n                           (to_bl (of_nat n :: machine_word))\"\ndefinition\n \"msg_info_register \\<equiv> msgInfoRegister\"\ndefinition\n \"msg_registers \\<equiv> msgRegisters\"\ndefinition\n \"cap_register \\<equiv> capRegister\"\ndefinition\n \"badge_register \\<equiv> badgeRegister\"\ndefinition\n \"frame_registers \\<equiv> frameRegisters\"\ndefinition\n \"gp_registers \\<equiv> gpRegisters\"\ndefinition\n \"exception_message \\<equiv> exceptionMessage\"\ndefinition\n \"syscall_message \\<equiv> syscallMessage\"\n\ndatatype arch_fault\n  = VMFault vspace_ref \"machine_word list\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Max IRQ Definition: The maximum number of interrupts (maxIRQ) is defined either in the Kernel_Config for ARM architectures or manually for RISCV64 architectures.",
    "input": "",
    "output": "arch_requalify_consts\n  maxIRQ\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Control: Creates a new ASID pool object, provides a capability to it, and connects it to the global virtual ASID table. This ensures that the new ASID pool is properly initialized and integrated into the system's memory management.",
    "input": "",
    "output": "definition perform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_asid_control_invocation iv \\<equiv> case iv of\n     MakePool frame slot parent base \\<Rightarrow> do\n       delete_objects frame pageBits;\n       pcap \\<leftarrow> get_cap parent;\n       set_cap (max_free_index_update pcap) parent;\n       retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n       cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n       assert (asid_low_bits_of base = 0);\n       asid_table \\<leftarrow> gets (riscv_asid_table \\<circ> arch_state);\n       asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n       modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>riscv_asid_table := asid_table'\\<rparr>\\<rparr>)\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Assignment: Assign an ASID to a top-level page table, updating the capability and storing the ASID pool entry. This ensures that the page table is correctly associated with the ASID, enabling proper memory management and address translation.",
    "input": "",
    "output": "definition perform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_asid_pool_invocation iv \\<equiv> case iv of\n     Assign asid pool_ptr ct_slot \\<Rightarrow> do\n       pt_cap \\<leftarrow> get_cap ct_slot;\n       assert $ is_ArchObjectCap pt_cap;\n       acap \\<leftarrow> return $ the_arch_cap pt_cap;\n       assert $ is_PageTableCap acap;\n       set_cap (ArchObjectCap $ update_map_data acap $ Some (asid,0)) ct_slot;\n       pt_base \\<leftarrow> return $ acap_obj acap;\n       copy_global_mappings pt_base;\n       store_asid_pool_entry pool_ptr asid (Some pt_base)\n     od\"\n\ndefinition perform_pg_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_pg_inv_unmap cap ct_slot \\<equiv> do\n     assert $ is_FrameCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> unmap_page (acap_fsize cap) asid vaddr (acap_obj cap)\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data (the_arch_cap old_cap) None) ct_slot\n   od\"\n\ndefinition perform_pg_inv_map :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_pg_inv_map cap ct_slot pte slot \\<equiv> do\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte slot pte;\n     do_machine_op sfence\n   od\"\n\ndefinition perform_pg_inv_get_addr :: \"obj_ref \\<Rightarrow> (data list,'z::state_ext) s_monad\"\n  where\n  \"perform_pg_inv_get_addr ptr \\<equiv> return [addrFromPPtr ptr]\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Frame Capability Authority: The frame capability allows for the mapping and unmapping of memory. It enables the setting and storing of page table entries, as well as the unmap and invalidation of page table entries, ensuring that memory is managed correctly and securely.",
    "input": "",
    "output": "definition perform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\"\n  where\n  \"perform_page_invocation iv \\<equiv> case iv of\n     PageMap cap ct_slot (pte,slot) \\<Rightarrow> do perform_pg_inv_map cap ct_slot pte slot; return [] od\n   | PageUnmap cap ct_slot \\<Rightarrow> do perform_pg_inv_unmap cap ct_slot; return [] od\n   | PageGetAddr ptr \\<Rightarrow> perform_pg_inv_get_addr ptr\"\n\n\ndefinition perform_pt_inv_map :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_pt_inv_map cap ct_slot pte slot = do\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte slot pte;\n     do_machine_op sfence\n   od\"\n\ndefinition perform_pt_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_pt_inv_unmap cap ct_slot = do\n     assert $ is_PageTableCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> do\n         p \\<leftarrow> return $ acap_obj cap;\n         unmap_page_table asid vaddr p;\n         slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 << pt_bits) - 1];\n         mapM_x (swp store_pte InvalidPTE) slots\n       od\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data old_cap None) ct_slot\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "PageTable Invocation: Allows the mapping and unmapping of page tables. This ensures that the memory layout can be dynamically adjusted, providing the necessary control over the virtual address space.",
    "input": "",
    "output": "definition perform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_page_table_invocation iv \\<equiv> case iv of\n     PageTableMap cap ct_slot pte slot \\<Rightarrow> perform_pt_inv_map cap ct_slot pte slot\n   | PageTableUnmap cap ct_slot \\<Rightarrow> perform_pt_inv_unmap cap ct_slot\"\n\nlocale_abbrev arch_no_return :: \"(unit, 'z::state_ext) s_monad \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\n  where\n  \"arch_no_return oper \\<equiv> do oper; return [] od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocation Handling: Dispatches RISCV64-specific system calls to their respective handlers for page table, page, ASID control, and ASID pool operations. Ensures that each invocation is processed by the appropriate function, maintaining the integrity and security of the system's memory management.",
    "input": "",
    "output": "definition arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\n  where\n  \"arch_perform_invocation i \\<equiv> liftE $ case i of\n     InvokePageTable oper \\<Rightarrow> arch_no_return $ perform_page_table_invocation oper\n   | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n   | InvokeASIDControl oper \\<Rightarrow> arch_no_return $ perform_asid_control_invocation oper\n   | InvokeASIDPool oper \\<Rightarrow> arch_no_return $ perform_asid_pool_invocation oper\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Hypervisor Faults: The system handles hypervisor fault events by processing the specified fault type. If the fault type is `RISCVNoHypFaults`, no action is taken, and the function returns immediately.",
    "input": "",
    "output": "chapter \"Handle Hypervisor Fault Events\"\n\ntheory Hypervisor_A\nimports Exceptions_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"machine_word \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\n  where\n  \"handle_hypervisor_fault thread RISCVNoHypFaults = return ()\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reserve Memory Region: Reserve a specified number of bytes in memory, optionally tagging the region as kernel data. This function currently acts as a placeholder and does not perform any actual reservation or tagging.",
    "input": "",
    "output": "definition reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialize Architecture-Specific Objects: Initialize architecture-specific objects, including setting up the context for a new thread control block (TCB) with an empty user context.",
    "input": "",
    "output": "definition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv> return ()\"\n\ndefinition empty_context :: user_context\n  where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb\n  where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context \\<rparr>\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Post-Capability Deletion Actions: No specific actions are taken after a capability is deleted.",
    "input": "",
    "output": "definition arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\n  where\n  \"arch_post_cap_deletion ac \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Generic Object References: There are no arch-specific generic object references, as the set of such references for any arch_cap is empty. Additionally, the cleanup operation for any arch_cap results in a NullCap.",
    "input": "",
    "output": "datatype arch_gen_obj_ref = unit\n\ndefinition arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\"\n  where\n  \"arch_gen_obj_refs ac \\<equiv> {}\"\n\ndefinition arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\"\n  where\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Global Page Table Pointer: The global page table pointer is set to a sufficiently aligned address for one page, specifically at the base physical pointer plus 0x2000.",
    "input": "",
    "output": "definition riscv_global_pt_ptr :: obj_ref\n  where\n  \"riscv_global_pt_ptr = pptr_base + 0x2000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IRQ Node Pointer: The IRQ node pointer is initialized to a memory address that is sufficiently aligned for the IRQ type and CTE level bits, ensuring proper alignment and access.",
    "input": "",
    "output": "definition init_irq_node_ptr :: obj_ref\n  where\n  \"init_irq_node_ptr = pptr_base + 0x3000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Canonical User Address: Defines the highest user-level virtual address that is still canonical, ensuring valid mappings in the page tables.",
    "input": "",
    "output": "definition canonical_user :: \"vspace_ref\" where\n  \"canonical_user \\<equiv> mask canonical_bit\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Region Initialization: The initial virtual space is divided into distinct regions, including a kernel window and an ELF window, each covered by a single maximum page table level entry. The sizes of these regions are chosen to be sufficiently large to accommodate necessary objects and constraints, ensuring that the invariants are consistent and suitable for real kernel configurations.",
    "input": "",
    "output": "definition kernel_window_bits :: nat where\n  \"kernel_window_bits \\<equiv> 22\"\n\ndefinition init_vspace_uses :: \"vspace_ref \\<Rightarrow> riscvvspace_region_use\"\n  where\n  \"init_vspace_uses p \\<equiv>\n     if p \\<in> {pptr_base ..< pptr_base + (1 << kernel_window_bits)} then RISCVVSpaceKernelWindow\n     else if p \\<in> {kernel_elf_base ..< kernel_elf_base + (1 << pageBits)} then RISCVVSpaceKernelELFWindow\n     else if p \\<le> canonical_user then RISCVVSpaceUserRegion\n     else RISCVVSpaceInvalidRegion\"\n\ndefinition init_arch_state :: arch_state\n  where\n  \"init_arch_state \\<equiv> \\<lparr>\n     riscv_asid_table = Map.empty,\n     riscv_global_pts = (\\<lambda>level. if level = max_pt_level then {riscv_global_pt_ptr} else {}),\n     riscv_kernel_vspace = init_vspace_uses\n   \\<rparr>\"\n\ndefinition toplevel_bits :: nat\n  where\n  \"toplevel_bits = pt_bits_left max_pt_level\"\n\ndefinition elf_index :: pt_index\n  where\n  \"elf_index = ucast (pt_index max_pt_level kernel_elf_base)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Kernel State: The kernel state is initialized with specific mappings and objects, including a global page table, an idle thread, and an interrupt controller. The global page table includes special entries for the physical pointer base and the kernel ELF base, ensuring that the memory layout aligns with the required invariants.",
    "input": "",
    "output": "definition global_pte :: \"pt_index \\<Rightarrow> pte\"\n  where\n  \"global_pte idx \\<equiv>\n     if idx = 0x100\n     then PagePTE ((ucast (idx && mask (ptTranslationBits - 1)) << ptTranslationBits * size max_pt_level))\n                  {} vm_kernel_only\n     else if idx = elf_index\n     then PagePTE (ucast ((kernelELFPAddrBase && ~~mask toplevel_bits) >> pageBits)) {} vm_kernel_only\n     else InvalidPTE\"\n\ndefinition init_global_pt :: kernel_object\n  where\n  \"init_global_pt \\<equiv> ArchObj $ PageTable (\\<lambda>idx. if idx \\<in> kernel_mapping_slots\n                                                then global_pte idx\n                                                else InvalidPTE)\"\n\ndefinition init_kheap :: kheap\n  where\n  \"init_kheap \\<equiv>\n    (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n           then Some (CNode 0 (empty_cnode 0))\n           else None)\n    (idle_thread_ptr \\<mapsto>\n       TCB \\<lparr>\n         tcb_ctable = NullCap,\n         tcb_vtable = NullCap,\n         tcb_reply = NullCap,\n         tcb_caller = NullCap,\n         tcb_ipcframe = NullCap,\n         tcb_state = IdleThreadState,\n         tcb_fault_handler = replicate word_bits False,\n         tcb_ipc_buffer = 0,\n         tcb_fault = None,\n         tcb_bound_notification = None,\n         tcb_mcpriority = minBound,\n         tcb_arch = init_arch_tcb\n         \\<rparr>,\n      riscv_global_pt_ptr \\<mapsto> init_global_pt\n    )\"\n\ndefinition init_cdt :: cdt\n  where\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition init_ioc :: \"cslot_ptr \\<Rightarrow> bool\"\n  where\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition init_A_st :: \"'z::state_ext state\"\n  where\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "IPC Buffer Lookup and Authority Check: Verify a thread's authority to read or write to its IPC buffer. The function checks the buffer's capabilities to ensure the thread has the appropriate read or write permissions, depending on whether it is the receiver or not.",
    "input": "",
    "output": "definition lookup_ipc_buffer :: \"bool \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\"\n  where\n  \"lookup_ipc_buffer is_receiver thread \\<equiv> do\n     buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n     buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n     buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n     case buffer_cap of\n       ArchObjectCap (FrameCap p R vms False _) \\<Rightarrow>\n         if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n         then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n         else return None\n     | _ \\<Rightarrow> return None\n   od\"\n\ndefinition pool_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\"\n  where\n  \"pool_for_asid asid \\<equiv> \\<lambda>s. riscv_asid_table (arch_state s) (asid_high_bits_of asid)\"\n\ndefinition vspace_for_pool :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (obj_ref \\<rightharpoonup> asid_pool) \\<Rightarrow> obj_ref option\"\n  where\n  \"vspace_for_pool pool_ptr asid \\<equiv> do {\n     pool \\<leftarrow> oapply pool_ptr;\n     K $ pool (asid_low_bits_of asid)\n   }\"\n\ndefinition vspace_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\"\n  where\n  \"vspace_for_asid asid = do {\n     oassert (0 < asid);\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     vspace_for_pool pool_ptr asid \\<circ> asid_pools_of\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate VSpace for ASID: Retrieve the top-level page table (vspace) associated with a given virtual ASID. If no vspace is found, an `InvalidRoot` exception is thrown.",
    "input": "",
    "output": "definition find_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\"\n  where\n  \"find_vspace_for_asid asid \\<equiv> doE\n    vspace_opt \\<leftarrow> liftE $ gets $ vspace_for_asid asid;\n    throw_opt InvalidRoot vspace_opt\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VM Fault Handling: Format and propagate a VM fault message to the thread's supervisor based on the type of page fault encountered, including load, store, and instruction access faults.",
    "input": "",
    "output": "definition handle_vm_fault :: \"obj_ref \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\n  where\n  \"handle_vm_fault thread fault_type = doE\n    addr \\<leftarrow> liftE $ do_machine_op read_stval;\n    let\n      loadf = (\\<lambda>a. throwError $ ArchFault $ VMFault a [0, vmFaultTypeFSR RISCVLoadAccessFault]);\n      storef = (\\<lambda>a. throwError $ ArchFault $ VMFault a [0, vmFaultTypeFSR RISCVStoreAccessFault]);\n      instrf = (\\<lambda>a. throwError $ ArchFault $ VMFault a [1, vmFaultTypeFSR RISCVInstructionAccessFault])\n    in\n      case fault_type of\n        RISCVLoadPageFault \\<Rightarrow> loadf addr\n      | RISCVLoadAccessFault \\<Rightarrow> loadf addr\n      | RISCVStorePageFault \\<Rightarrow> storef addr\n      | RISCVStoreAccessFault \\<Rightarrow> storef addr\n      | RISCVInstructionPageFault \\<Rightarrow> instrf addr\n      | RISCVInstructionAccessFault \\<Rightarrow> instrf addr\n  odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Address Space Management: Switch the address space to that of a specified thread or to the global address space if the thread's configuration is invalid. This ensures that the virtual memory root is correctly set, and any necessary ASID pool or page table mappings are updated or deleted, maintaining the integrity and consistency of the virtual memory system.",
    "input": "",
    "output": "definition set_vm_root :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PageTableCap pt (Some (asid, _))) \\<Rightarrow> doE\n           pt' \\<leftarrow> find_vspace_for_asid asid;\n           whenE (pt \\<noteq> pt') $ throwError InvalidRoot;\n           liftE $ do_machine_op $ setVSpaceRoot (addrFromPPtr pt) (ucast asid)\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_pt \\<leftarrow> gets global_pt;\n       do_machine_op $ setVSpaceRoot (addrFromKPPtr global_pt) 0\n    od)\n  od\"\n\n\ndefinition delete_asid_pool :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"delete_asid_pool base ptr \\<equiv> do\n     assert (asid_low_bits_of base = 0);\n     asid_table \\<leftarrow> gets (riscv_asid_table \\<circ> arch_state);\n     when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n       pool \\<leftarrow> get_asid_pool ptr;\n       asid_table' \\<leftarrow> return $ asid_table (asid_high_bits_of base:= None);\n       modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> riscv_asid_table := asid_table' \\<rparr>\\<rparr>);\n       tcb \\<leftarrow> gets cur_thread;\n       set_vm_root tcb\n     od\n   od\"\n\n\ndefinition delete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"delete_asid asid pt \\<equiv> do\n     asid_table \\<leftarrow> gets (riscv_asid_table \\<circ> arch_state);\n     case asid_table (asid_high_bits_of asid) of\n       None \\<Rightarrow> return ()\n     | Some pool_ptr \\<Rightarrow> do\n         pool \\<leftarrow> get_asid_pool pool_ptr;\n         when (pool (asid_low_bits_of asid) = Some pt) $ do\n           do_machine_op $ hwASIDFlush (ucast asid);\n           pool' \\<leftarrow> return $ pool (asid_low_bits_of asid := None);\n           set_asid_pool pool_ptr pool';\n           tcb \\<leftarrow> gets cur_thread;\n           set_vm_root tcb\n         od\n       od\n   od\"\n\ndefinition unmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"unmap_page_table asid vaddr pt \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     pt_slot \\<leftarrow> pt_lookup_from_level max_pt_level top_level_pt vaddr pt;\n     liftE $ store_pte pt_slot InvalidPTE;\n     liftE $ do_machine_op sfence\n   odE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Lookup: Perform a lookup in the page table for a given ASID and virtual space reference, down to the specified level. If the lookup reaches the bottom level, return a pointer to the table at that level; otherwise, return the level and the corresponding object reference where the lookup terminated, which could be due to hitting a page or an invalid entry.",
    "input": "",
    "output": "definition vs_lookup_table :: \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"vs_lookup_table bot_level asid vptr \\<equiv> do {\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     if bot_level = asid_pool_level\n     then oreturn (asid_pool_level, pool_ptr)\n     else do {\n       top_level_pt \\<leftarrow> vspace_for_pool pool_ptr asid \\<circ> asid_pools_of;\n       pt_walk max_pt_level bot_level top_level_pt vptr \\<circ> ptes_of\n     }\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Space Lookup Slot: Returns a pointer to a slot in the virtual space table at the specified level. If the level is the ASID pool level, it returns a pointer to the ASID pool itself, otherwise, it returns a pointer to the specific slot within the table.",
    "input": "",
    "output": "definition vs_lookup_slot :: \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"vs_lookup_slot bot_level asid vref \\<equiv> do {\n     (level', table) \\<leftarrow> vs_lookup_table bot_level asid vref;\n     if level' = asid_pool_level then\n       oreturn (level', table)\n     else\n       oreturn (level', pt_slot_offset level' table vref)\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page: Unmaps a page from the virtual address space if the provided mapping details are still current. It ensures that the page table entry is valid and matches the given physical page, then invalidates the entry and flushes the translation cache.",
    "input": "",
    "output": "definition unmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"unmap_page pgsz asid vptr pptr \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     (lev, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot top_level_pt vptr \\<circ> ptes_of;\n     unlessE (pt_bits_left lev = pageBitsForSize pgsz) $ throwError InvalidRoot;\n     pte \\<leftarrow> liftE $ get_pte slot;\n     unlessE (is_PagePTE pte \\<and> pptr_from_pte pte = pptr) $ throwError InvalidRoot;\n     liftE $ store_pte slot InvalidPTE;\n     liftE $ do_machine_op sfence\n   odE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Capabilities Derivation: Page table capabilities can only be derived if they have an assigned ASID and location, ensuring that they are not shared between address spaces or virtual locations. Other architectural capabilities, such as frame capabilities, ASID control capabilities, and ASID pool capabilities, can be derived without these constraints.",
    "input": "",
    "output": "definition arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\"\n  where\n  \"arch_derive_cap c \\<equiv>\n     case c of\n       PageTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n     | PageTableCap _ None \\<Rightarrow> throwError IllegalOperation\n     | FrameCap r R sz dev mp \\<Rightarrow> returnOk $ ArchObjectCap (FrameCap r R sz dev None)\n     | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n     | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64 Capability Data Integrity: Ensures that no user-modifiable data is stored in RISCV64-specific capabilities, maintaining the integrity and security of the system.",
    "input": "",
    "output": "definition arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\n  where\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Finalize RISCV64-Specific Capabilities: Perform specific actions to finalize RISCV64 capabilities, including deleting ASID pools, unmapping page tables, and unmapping frames, and return null capabilities.",
    "input": "",
    "output": "definition arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\n  where\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n     (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n       delete_asid_pool b ptr;\n       return (NullCap, NullCap)\n     od\n   | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n       doE\n         vroot \\<leftarrow> find_vspace_for_asid a;\n         if vroot = ptr then liftE $ delete_asid a ptr else throwError InvalidRoot\n       odE <catch>\n       (\\<lambda>_. unmap_page_table a v ptr);\n       return (NullCap, NullCap)\n     od\n   | (FrameCap ptr _ sz _ (Some (a, v)), _) \\<Rightarrow> do\n       unmap_page sz a v ptr;\n       return (NullCap, NullCap)\n     od\n   | _ \\<Rightarrow> return (NullCap, NullCap)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Address Space Validity: A virtual address space capability is valid if and only if it points to a mapped page table.",
    "input": "",
    "output": "definition is_valid_vtable_root :: \"cap \\<Rightarrow> bool\"\n  where\n  \"is_valid_vtable_root c \\<equiv>\n     case c of ArchObjectCap (PageTableCap _ (Some _)) \\<Rightarrow> True | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Valid IPC Buffer: Validate the alignment of the virtual pointer for an IPC buffer. If the virtual pointer is not aligned according to the specified `msg_align_bits`, an `AlignmentError` is thrown. For any other type of capability, an `IllegalOperation` error is thrown.",
    "input": "",
    "output": "lemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\ndefinition check_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_valid_ipc_buffer vptr c \\<equiv>\n     case c of\n       ArchObjectCap (FrameCap _ _ _ False _) \\<Rightarrow>\n         whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError\n     | _ \\<Rightarrow> throwError IllegalOperation\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Pointer in User Frame: A pointer is considered to be inside a user frame if its top bits correspond to a DataPage in the kernel heap.",
    "input": "",
    "output": "definition in_user_frame :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\"\n  where\n  \"in_user_frame p s \\<equiv>\n     \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) = Some (ArchObj (DataPage False sz))\"\n\ndefinition prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"prepare_thread_delete thread_ptr \\<equiv> return ()\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID High Bits Extraction: Extract the high bits of a virtual ASID by shifting and casting the ASID to an ASID high index.",
    "input": "",
    "output": "text \\<open>The high bits of a virtual ASID.\\<close>\ndefinition asid_high_bits_of :: \"asid \\<Rightarrow> asid_high_index\"\n  where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Low Bits Extraction: Extract the low bits of a virtual ASID and convert them to an ASID low index.",
    "input": "",
    "output": "definition asid_low_bits_of :: \"asid \\<Rightarrow> asid_low_index\"\n  where\n  \"asid_low_bits_of asid \\<equiv> ucast asid\"\n\nlemmas asid_bits_of_defs = asid_high_bits_of_def asid_low_bits_of_def\n\nlocale_abbrev\n  \"asid_table \\<equiv> \\<lambda>s. riscv_asid_table (arch_state s)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Access VSpace Information: Provides a way to access the architecture-specific kernel objects, such as virtual space (VSpace) information, from the kernel heap. This allows the system to manage and interact with the VSpace effectively.",
    "input": "",
    "output": "(* declared in Arch as workaround for VER-1099 *)\nlocale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\"\n  where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool and Page Table Management: Manipulate ASID pools and page tables in the kernel heap, allowing for the retrieval and updating of ASID mappings and page table entries.",
    "input": "",
    "output": "locale_abbrev asid_pools_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> asid_pool\"\n  where\n  \"asid_pools_of \\<equiv> \\<lambda>s. aobjs_of s |> asid_pool_of\"\n\nlocale_abbrev get_asid_pool :: \"obj_ref \\<Rightarrow> (asid_low_index \\<rightharpoonup> obj_ref, 'z::state_ext) s_monad\"\n  where\n  \"get_asid_pool \\<equiv> gets_map asid_pools_of\"\n\ndefinition set_asid_pool :: \"obj_ref \\<Rightarrow> (asid_low_index \\<rightharpoonup> obj_ref) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_asid_pool ptr pool \\<equiv> do\n     get_asid_pool ptr;\n     set_object ptr (ArchObj (ASIDPool pool))\n   od\"\n\nlocale_abbrev pts_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> pt\"\n  where\n  \"pts_of \\<equiv> \\<lambda>s. aobjs_of s |> pt_of\"\n\nlocale_abbrev get_pt :: \"obj_ref \\<Rightarrow> (pt_index \\<Rightarrow> pte,'z::state_ext) s_monad\"\n  where\n  \"get_pt \\<equiv> gets_map pts_of\"\n\ndefinition set_pt :: \"obj_ref \\<Rightarrow> (pt_index \\<Rightarrow> pte) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_pt ptr pt \\<equiv> do\n     get_pt ptr;\n     set_object ptr (ArchObj (PageTable pt))\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Table Base Calculation: Compute the base address of the table containing a given page table entry, assuming proper alignment.",
    "input": "",
    "output": "locale_abbrev table_base :: \"obj_ref \\<Rightarrow> obj_ref\" where\n  \"table_base p \\<equiv> p && ~~mask pt_bits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Index Calculation: Compute the index within the page table that a given page table entry addresses, using bitwise operations to extract and shift the relevant bits.",
    "input": "",
    "output": "locale_abbrev table_index :: \"obj_ref \\<Rightarrow> pt_index\" where\n  \"table_index p \\<equiv> ucast (p && mask pt_bits >> pte_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Entry Access: Retrieve the page table entry (PTE) at a given address, ensuring that the address is properly aligned to avoid accessing invalid regions between PTEs.",
    "input": "",
    "output": "definition pte_of :: \"obj_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pt) \\<rightharpoonup> pte\"\n  where\n  \"pte_of p \\<equiv> do {\n     oassert (is_aligned p pte_bits);\n     pt \\<leftarrow> oapply (table_base p);\n     oreturn $ pt (table_index p)\n   }\"\n\nlocale_abbrev ptes_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> pte\"\n  where\n  \"ptes_of s \\<equiv> \\<lambda>p. pte_of p (pts_of s)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel PTE Access and Modification: Retrieve and store page table entries (PTEs) in the kernel's memory. Ensures that PTEs are accessed and modified correctly, maintaining the integrity of the virtual address space.",
    "input": "",
    "output": "locale_abbrev get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\"\n  where\n  \"get_pte \\<equiv> gets_map ptes_of\"\n\ndefinition store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"store_pte p pte \\<equiv> do\n     assert (is_aligned p pte_bits);\n     base \\<leftarrow> return $ table_base p;\n     index \\<leftarrow> return $ table_index p;\n     pt \\<leftarrow> get_pt (table_base p);\n     pt' \\<leftarrow> return $ pt (index := pte);\n     set_pt base pt'\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access: Calculate the index for a given virtual address and level in the page table, using the remaining bits after shifting the virtual address by the sum of the translation bits and page bits, and masking with the translation bits.",
    "input": "",
    "output": "definition pt_bits_left :: \"vm_level \\<Rightarrow> nat\"\n  where\n  \"pt_bits_left level = ptTranslationBits * size level + pageBits\"\n\ndefinition pt_index :: \"vm_level \\<Rightarrow> vspace_ref \\<Rightarrow> machine_word\"\n  where\n  \"pt_index level vptr \\<equiv> (vptr >> pt_bits_left level) && mask ptTranslationBits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Extract Top-Level Global Page Table: Retrieve the single top-level global page table from the architecture state.",
    "input": "",
    "output": "definition riscv_global_pt :: \"arch_state \\<Rightarrow> obj_ref\"\n  where\n  \"riscv_global_pt s = the_elem (riscv_global_pts s max_pt_level)\"\n\nlocale_abbrev global_pt :: \"'z state \\<Rightarrow> obj_ref\"\n  where\n  \"global_pt s \\<equiv> riscv_global_pt (arch_state s)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Copy Global Mappings: Replicate the kernel window mappings into a new top-level page table object. This ensures that the kernel's virtual address space is consistently available across different page tables, maintaining the integrity and accessibility of the kernel memory.",
    "input": "",
    "output": "definition copy_global_mappings :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"copy_global_mappings new_pm \\<equiv> do\n    global_pt \\<leftarrow> gets global_pt;\n    base \\<leftarrow> return $ pt_index max_pt_level pptr_base;\n    pt_size \\<leftarrow> return $ 1 << ptTranslationBits;\n    mapM_x (\\<lambda>index. do\n        offset \\<leftarrow> return (index << pte_bits);\n        pme \\<leftarrow> get_pte (global_pt + offset);\n        store_pte (new_pm + offset) pme\n    od) [base  .e.  pt_size - 1]\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Entry to Physical Pointer: Convert a page table entry (PTE) to a physical pointer, ensuring that the resulting address is at least page-aligned. \n\nPage Table Slot Offset: Calculate the offset of a specific slot in the page table based on the virtual address and the level of the page table, aligning it with the appropriate page table entry size.",
    "input": "",
    "output": "definition pptr_from_pte :: \"pte \\<Rightarrow> vspace_ref\"\n  where\n  \"pptr_from_pte pte \\<equiv> ptrFromPAddr (addr_from_pte pte)\"\n\ndefinition pt_slot_offset :: \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\n  where\n  \"pt_slot_offset level pt_ptr vptr = pt_ptr + (pt_index level vptr << pte_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Walk: Recursively traverses the page table structure from a specified level down to a base level or until a page is reached, returning the level and the pointer to the final page table or page.",
    "input": "",
    "output": "fun pt_walk ::\n  \"vm_level \\<Rightarrow> vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pte) \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"pt_walk level bot_level pt_ptr vptr = do {\n     if bot_level < level\n     then do {\n       pte \\<leftarrow> oapply (pt_slot_offset level pt_ptr vptr);\n       if is_PageTablePTE pte\n         then pt_walk (level - 1) bot_level (pptr_from_pte pte) vptr\n         else oreturn (level, pt_ptr)\n     }\n     else oreturn (level, pt_ptr)\n   }\"\n\ndeclare pt_walk.simps[simp del]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Slot Lookup: Retrieves a slot in the page table structure corresponding to a given virtual space reference, returning the level and object pointer of the slot. The slot at level 0 is either an invalid or a page PTE, while higher levels may also include a page table PTE.",
    "input": "",
    "output": "definition pt_lookup_slot_from_level ::\n  \"vm_level \\<Rightarrow> vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pte) \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"pt_lookup_slot_from_level level bot_level pt_ptr vptr = do {\n     (level', pt_ptr') \\<leftarrow> pt_walk level bot_level pt_ptr vptr;\n     oreturn (level', pt_slot_offset level' pt_ptr' vptr)\n   }\"\n\ndefinition pt_lookup_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pte) \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"pt_lookup_slot = pt_lookup_slot_from_level max_pt_level 0\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Lookup: Recursively searches the page table hierarchy starting from a given level, using the provided virtual address and target page table pointer, to find the slot that points to the target page table. Ensures that the search is valid by checking the level and PTE type, and continues the search at lower levels if the current level does not match the target.",
    "input": "",
    "output": "fun pt_lookup_from_level ::\n  \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (machine_word, 'z::state_ext) lf_monad\"\n  where\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr s = (doE\n     unlessE (0 < level) $ throwError InvalidRoot;\n     slot <- returnOk $ pt_slot_offset level pt_ptr vptr;\n     pte <- liftE $ gets_the $ oapply slot o ptes_of;\n     unlessE (is_PageTablePTE pte) $ throwError InvalidRoot;\n     ptr <- returnOk (pptr_from_pte pte);\n     if ptr = target_pt_ptr\n       then returnOk slot\n       else pt_lookup_from_level (level - 1) ptr vptr target_pt_ptr\n   odE) s\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Access VSpace: Perform basic operations on the RISCV64 virtual space, ensuring type safety and maintaining the global free index counter.",
    "input": "",
    "output": "declare pt_lookup_from_level.simps[simp del]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Lookup: Perform a lookup in the page table starting from a specified level to find the target page table pointer for a given virtual address.",
    "input": "",
    "output": "schematic_goal pt_lookup_from_level_simps:\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr = ?rhs\"\n  by (rule ext, rule pt_lookup_from_level.simps)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Mapping Slots: Defines the set of top-level table slots that are used for kernel mappings, starting from the base physical pointer and extending to the top of virtual memory. These slots encompass the kernel window, kernel ELF window, and kernel device window.",
    "input": "",
    "output": "definition kernel_mapping_slots :: \"pt_index set\" where\n  \"kernel_mapping_slots \\<equiv> {i. i \\<ge> ucast (pptr_base >> pt_bits_left max_pt_level)}\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Virtual Page Alignment: Ensure that the virtual page address is properly aligned for the specified page size. If the alignment check fails, an alignment error is thrown.",
    "input": "",
    "output": "definition check_vp_alignment :: \"vmpage_size \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $ throwError AlignmentError\"\n\ndefinition page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\n  where\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocation Decoding: Decode and validate architecture-specific system calls, ensuring that the provided arguments and capabilities are correct and complete. This includes handling IRQ control, frame mapping and unmapping, page table operations, and ASID pool management. Each invocation type is checked for proper argument length, capability validity, and alignment, with appropriate errors thrown for invalid or truncated messages.",
    "input": "",
    "output": "definition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> whenE (irq > ucast maxIRQ \\<or> irq = ucast irqInvalid) $\n                          throwError (RangeError 1 (ucast maxIRQ))\"\n\ndefinition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n     (if invocation_type label = ArchInvocationLabel RISCVIRQIssueIRQHandler\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n          returnOk $ RISCVIRQControlInvocation irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\ndefinition attribs_from_word :: \"machine_word \\<Rightarrow> vm_attributes\"\n  where\n  \"attribs_from_word w \\<equiv> if \\<not> w!!0 then {Execute} else {}\"\n\ndefinition make_user_pte :: \"vspace_ref \\<Rightarrow> vm_attributes \\<Rightarrow> vm_rights \\<Rightarrow> pte\"\n  where\n  \"make_user_pte addr attr rights \\<equiv>\n    if rights = {} \\<and> attr = {}\n    then InvalidPTE\n    else PagePTE (ucast (addr >> pageBits)) (attr \\<union> {User}) rights\"\n\ndefinition check_slot :: \"obj_ref \\<Rightarrow> (pte \\<Rightarrow> bool) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_slot slot test = doE\n     pte \\<leftarrow> liftE $ get_pte slot;\n     unlessE (test pte) $ throwError DeleteFirst\n   odE\"\n\ntype_synonym 'z arch_decoder =\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    (arch_invocation,'z) se_monad\"\n\ndefinition decode_fr_inv_map :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_fr_inv_map label args cte cap extra_caps \\<equiv> case cap of\n     FrameCap p R pgsz dev mapped_address \\<Rightarrow>\n       if length args > 2 \\<and> length extra_caps > 0\n       then let\n           vaddr = args ! 0;\n           rights_mask = args ! 1;\n           attr = args ! 2;\n           vspace_cap = fst (extra_caps ! 0)\n         in doE\n           (pt, asid) \\<leftarrow> case vspace_cap of\n                           ArchObjectCap (PageTableCap pt (Some (asid, _))) \\<Rightarrow> returnOk (pt, asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1;\n           pt' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n           whenE (pt' \\<noteq> pt) $ throwError $ InvalidCapability 1;\n           pg_bits \\<leftarrow> returnOk $ pageBitsForSize pgsz;\n           vtop \\<leftarrow> returnOk $ vaddr + mask (pageBitsForSize pgsz);\n           whenE (vtop \\<ge> user_vtop) $ throwError $ InvalidArgument 0;\n           check_vp_alignment pgsz vaddr;\n           (level, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot pt vaddr \\<circ> ptes_of;\n           unlessE (pt_bits_left level = pg_bits) $\n             throwError $ FailedLookup False $ MissingCapability $ pt_bits_left level;\n           case mapped_address of\n             Some (asid', vaddr') \\<Rightarrow> doE\n               whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n               whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0);\n               check_slot slot (Not \\<circ> is_PageTablePTE)\n             odE\n           | None \\<Rightarrow> check_slot slot ((=) InvalidPTE);\n           vm_rights \\<leftarrow> returnOk $ mask_vm_rights R (data_to_rights rights_mask);\n           attribs \\<leftarrow> returnOk $ attribs_from_word attr;\n           pte \\<leftarrow> returnOk $ make_user_pte (addrFromPPtr p) attribs vm_rights;\n           returnOk $ InvokePage $ PageMap (FrameCap p R pgsz dev (Some (asid,vaddr))) cte (pte,slot)\n         odE\n       else throwError TruncatedMessage\n     | _ \\<Rightarrow> fail\"\n\ndefinition decode_frame_invocation :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_frame_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel RISCVPageMap\n     then decode_fr_inv_map label args cte cap extra_caps\n     else if invocation_type label = ArchInvocationLabel RISCVPageUnmap\n     then returnOk $ InvokePage $ PageUnmap cap cte\n     else if invocation_type label = ArchInvocationLabel RISCVPageGetAddress\n     then returnOk $ InvokePage $ PageGetAddr (acap_obj cap)\n     else throwError IllegalOperation\"\n\ndefinition decode_pt_inv_map :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_pt_inv_map label args cte cap extra_caps \\<equiv> case cap of\n     PageTableCap p mapped_address \\<Rightarrow>\n       if length args > 1 \\<and> length extra_caps > 0\n       then let\n           vaddr = args ! 0;\n           attr = args ! 1;\n           vspace_cap = fst (extra_caps ! 0)\n         in doE\n           whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n           (pt, asid) \\<leftarrow> case vspace_cap of\n                           ArchObjectCap (PageTableCap pt (Some (asid,_))) \\<Rightarrow> returnOk (pt, asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1;\n           whenE (user_vtop \\<le> vaddr) $ throwError $ InvalidArgument 0;\n           pt' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n           whenE (pt' \\<noteq> pt) $ throwError $ InvalidCapability 1;\n           (level, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot pt vaddr \\<circ> ptes_of;\n           old_pte \\<leftarrow> liftE $ get_pte slot;\n           whenE (pt_bits_left level = pageBits \\<or> old_pte \\<noteq> InvalidPTE) $ throwError DeleteFirst;\n           pte \\<leftarrow> returnOk $ PageTablePTE (ucast (addrFromPPtr p >> pageBits)) {};\n           cap' <- returnOk $ PageTableCap p $ Some (asid, vaddr && ~~mask (pt_bits_left level));\n           returnOk $ InvokePageTable $ PageTableMap cap' cte pte slot\n         odE\n       else throwError TruncatedMessage\n     | _ \\<Rightarrow> fail\"\n\ndefinition decode_page_table_invocation :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_page_table_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel RISCVPageTableMap\n     then decode_pt_inv_map label args cte cap extra_caps\n     else if invocation_type label = ArchInvocationLabel RISCVPageTableUnmap\n     then doE\n       final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n       unlessE final $ throwError RevokeFirst;\n       case cap of\n         PageTableCap pt (Some (asid, _)) \\<Rightarrow> doE\n             \\<comment> \\<open>cannot invoke unmap on top level page table\\<close>\n             pt_opt \\<leftarrow> liftE $ gets $ vspace_for_asid asid;\n             whenE (pt_opt = Some pt) $ throwError RevokeFirst\n           odE\n       | _ \\<Rightarrow> returnOk ();\n       returnOk $ InvokePageTable $ PageTableUnmap cap cte\n     odE\n     else throwError IllegalOperation\"\n\ndefinition decode_asid_control_invocation :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_asid_control_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel RISCVASIDControlMakePool\n     then if length args > 1 \\<and> length extra_caps > 1\n     then let\n         index = args ! 0;\n         depth = args ! 1;\n         (untyped, parent_slot) = extra_caps ! 0;\n         root = fst (extra_caps ! 1)\n       in doE\n         asid_table \\<leftarrow> liftE $ gets (riscv_asid_table \\<circ> arch_state);\n         free_set \\<leftarrow> returnOk (- dom asid_table);\n         whenE (free_set = {}) $ throwError DeleteFirst;\n         free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n         base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n         (p,n) \\<leftarrow> case untyped of\n                    UntypedCap False p n _ \\<Rightarrow> returnOk (p,n)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 1;\n         frame \\<leftarrow> if n = pageBits then doE\n                    ensure_no_children parent_slot;\n                    returnOk p\n                  odE\n                  else throwError $ InvalidCapability 1;\n         dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n         ensure_empty dest_slot;\n         returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n       odE\n     else throwError TruncatedMessage\n     else throwError IllegalOperation\"\n\ndefinition decode_asid_pool_invocation :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_asid_pool_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel RISCVASIDPoolAssign\n     then if length extra_caps > 0\n     then let\n         (pt_cap, pt_cap_slot) = extra_caps ! 0;\n         p = acap_obj cap;\n         base = acap_asid_base cap\n       in case pt_cap of\n         ArchObjectCap (PageTableCap _ None) \\<Rightarrow> doE\n           asid_table \\<leftarrow> liftE $ gets (riscv_asid_table \\<circ> arch_state);\n           pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n           whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n           whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n           pool \\<leftarrow> liftE $ get_asid_pool p;\n           free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n           whenE (free_set = {}) $ throwError DeleteFirst;\n           offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n           returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pt_cap_slot\n         odE\n       | _ \\<Rightarrow> throwError $ InvalidCapability 1\n     else throwError TruncatedMessage\n     else throwError IllegalOperation\"\n\ndefinition arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n     PageTableCap _ _   \\<Rightarrow> decode_page_table_invocation label args cte cap extra_caps\n   | FrameCap _ _ _ _ _ \\<Rightarrow> decode_frame_invocation label args cte cap extra_caps\n   | ASIDControlCap     \\<Rightarrow> decode_asid_control_invocation label args cte cap extra_caps\n   | ASIDPoolCap _ _    \\<Rightarrow> decode_asid_pool_invocation label args cte cap extra_caps\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Data to Object Type Mapping: Convert a numerical value to a corresponding architecture-specific object type, such as HugePageObj, SmallPageObj, LargePageObj, or PageTableObj. If the numerical value does not match any of the predefined types, it returns None.",
    "input": "",
    "output": "definition arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\"\n  where\n  \"arch_data_to_obj_type n \\<equiv>\n     if      n = 0 then Some HugePageObj\n     else if n = 1 then Some SmallPageObj\n     else if n = 2 then Some LargePageObj\n     else if n = 3 then Some PageTableObj\n     else None\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocations: Define the structure and types for RISCV64-specific system calls, including page table mappings and unmappings, ASID pool assignments, page mappings, unmappings, and address retrieval, and IRQ control. These invocations provide a structured way to handle architectural operations, ensuring that the system can manage memory, interrupts, and other low-level resources effectively.",
    "input": "",
    "output": "datatype page_table_invocation =\n    PageTableMap\n      (pt_inv_cap : arch_cap)\n      (pt_inv_cslot : cslot_ptr)\n      (pt_map_pte : pte)\n      (pt_map_slot : obj_ref)\n  | PageTableUnmap\n      (pt_inv_cap : arch_cap)\n      (pt_inv_cslot : cslot_ptr)\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation =\n    PageMap\n      (pg_inv_cap : arch_cap)\n      (pg_inv_cslot : cslot_ptr)\n      (pg_inv_entries : \"pte \\<times> obj_ref\")\n  | PageUnmap\n      (pg_inv_cap : arch_cap)\n      (pg_inv_cslot : cslot_ptr)\n  | PageGetAddr\n      (pg_get_paddr : obj_ref)\n\ndatatype arch_invocation =\n    InvokePageTable page_table_invocation\n  | InvokePage page_invocation\n  | InvokeASIDControl asid_control_invocation\n  | InvokeASIDPool asid_pool_invocation\n\ndatatype arch_copy_register_sets =\n    RISCVNoExtraRegisters\n\ndefinition ArchDefaultExtraRegisters :: arch_copy_register_sets\n  where\n  \"ArchDefaultExtraRegisters = RISCVNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    RISCVIRQControlInvocation irq cslot_ptr cslot_ptr bool\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64 Architecture-Specific Capabilities: Defines capabilities for ASID pools, ASID controller, frame, and page table. These capabilities include specific attributes such as object references, ASID bases, rights, frame sizes, device flags, and mapping data, enabling fine-grained control over virtual memory and address space management.",
    "input": "",
    "output": "text \\<open>\n  The RISCV64 kernel supports capabilities for ASID pools and an ASID controller capability,\n  along with capabilities for virtual memory mappings.\n\\<close>\n\ndatatype arch_cap =\n    ASIDPoolCap (acap_obj : obj_ref) (acap_asid_base : asid)\n  | ASIDControlCap\n  | FrameCap\n      (acap_obj : obj_ref)\n      (acap_rights : cap_rights)\n      (acap_fsize : vmpage_size)\n      (acap_is_device : bool)\n      (acap_map_data : \"(asid \\<times> vspace_ref) option\")\n  | PageTableCap (acap_obj : obj_ref) (acap_map_data : \"(asid \\<times> vspace_ref) option\")",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Mapping Data: Modify the mapping data in a frame or page table capability, updating the ASID and virtual space reference as needed.",
    "input": "",
    "output": "definition update_map_data :: \"arch_cap \\<Rightarrow> (asid \\<times> vspace_ref) option \\<Rightarrow> arch_cap\"\n  where\n  \"update_map_data cap m \\<equiv> case cap of\n     FrameCap p R sz dev _  \\<Rightarrow> FrameCap p R sz dev m\n   | PageTableCap p _ \\<Rightarrow> PageTableCap p m\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64 VM Attributes: Define a set of attributes that can be applied to page or page table entries, including global, execute, and user permissions. These attributes are used to control the access and behavior of memory regions in the RISCV64 architecture.",
    "input": "",
    "output": "(* This datatype does not match up with the executable spec directly:\n   This one here models all \"things\" one can set on a page or page table entry.\n   The attributes accessible to users are the ones returned by attribs_from_word. *)\ndatatype vm_attribute = Global | Execute | User\ntype_synonym vm_attributes = \"vm_attribute set\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64 Page Table Entry (PTE) Structure: Defines a PTE with three possible types: `InvalidPTE`, `PagePTE`, and `PageTablePTE`. Each valid PTE type includes a page number (ppn) of 52 bits, attributes, and, for `PagePTE`, additional rights. The ppn is stored as a shifted address, and the actual address can be retrieved using `addr_from_pte`.",
    "input": "",
    "output": "type_synonym pte_ppn_len = 52 (* machine_word_len - pt_bits *)\ntype_synonym pte_ppn = \"pte_ppn_len word\"\n\ndefinition ppn_len :: nat where\n  \"ppn_len \\<equiv> LENGTH(pte_ppn_len)\"\n\ndatatype pte =\n    InvalidPTE\n  | PagePTE (pte_ppn : pte_ppn) (pte_attr : vm_attributes) (pte_rights : vm_rights)\n  | PageTablePTE (pte_ppn : pte_ppn) (pte_attr : vm_attributes)\n\ntype_synonym pt_index_len = 9\ntype_synonym pt_index = \"pt_index_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Data Types: Define and ensure the correctness of architecture-specific data types, such as `asid_pool` and `pt`, which are used to manage address space identifiers and page tables, respectively. The lemma ensures that the length of `pt_index_len` matches the defined `ptTranslationBits`, providing a sanity check for the translation bits.",
    "input": "",
    "output": "lemma \"LENGTH(pt_index_len) = ptTranslationBits\"\n  by (simp add: ptTranslationBits_def)\n\ntype_synonym asid_pool = \"asid_low_index \\<rightharpoonup> obj_ref\"\ntype_synonym pt = \"pt_index \\<Rightarrow> pte\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64-Specific Data Types and Sizes: Define architecture-specific object types, including ASID pools, page tables, and data pages, and specify their sizes. Additionally, define the sizes and properties of various architectural capabilities, such as frame caps, ASID pool caps, and page table caps, and provide functions to determine the size and device nature of these capabilities.",
    "input": "",
    "output": "datatype (discs_sels) arch_kernel_obj =\n    ASIDPool asid_pool\n  | PageTable pt\n  | DataPage bool vmpage_size\n\ndefinition asid_pool_of :: \"arch_kernel_obj \\<rightharpoonup> asid_pool\"\n  where\n  \"asid_pool_of ko \\<equiv> case ko of ASIDPool pool \\<Rightarrow> Some pool | _ \\<Rightarrow> None\"\n\ndefinition pt_of :: \"arch_kernel_obj \\<rightharpoonup> pt\"\n  where\n  \"pt_of ko \\<equiv> case ko of PageTable pt \\<Rightarrow> Some pt | _ \\<Rightarrow> None\"\n\ndefinition pte_bits :: nat\n  where\n  \"pte_bits = word_size_bits\"\n\ndefinition table_size :: nat\n  where\n  \"table_size = ptTranslationBits + pte_bits\"\n\ndefinition pt_bits :: \"nat\"\n  where\n  \"pt_bits \\<equiv> table_size\"\n\ndefinition addr_from_ppn :: \"pte_ppn \\<Rightarrow> paddr\"\n  where\n  \"addr_from_ppn ppn = ucast ppn << pt_bits\"\n\nabbreviation addr_from_pte :: \"pte \\<Rightarrow> paddr\"\n  where\n  \"addr_from_pte pte \\<equiv> addr_from_ppn (pte_ppn pte)\"\n\nprimrec arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\n  where\n  \"arch_obj_size (ASIDPoolCap _ _) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (FrameCap _ _ sz _ _) = pageBitsForSize sz\"\n| \"arch_obj_size (PageTableCap _ _ ) = table_size\"\n\nfun arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\n  where\n  \"arch_cap_is_device (FrameCap _ _ _ is_dev _) = is_dev\"\n| \"arch_cap_is_device _ = False\"\n\ndefinition cte_level_bits :: nat\n  where\n  \"cte_level_bits \\<equiv> 5\"\n\ndefinition tcb_bits :: nat\n  where\n  \"tcb_bits \\<equiv> 10\"\n\ndefinition endpoint_bits :: nat\n  where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat\n  where\n  \"ntfn_bits \\<equiv> 5\"\n\ndefinition untyped_min_bits :: nat\n  where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat\n  where\n  \"untyped_max_bits \\<equiv> 38\"\n\nprimrec arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\n  where\n  \"arch_kobj_size (ASIDPool _) = pageBits\"\n| \"arch_kobj_size (PageTable _) = table_size\"\n| \"arch_kobj_size (DataPage _ sz) = pageBitsForSize sz\"\n\nfun aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\n  where\n  \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref c = Some (acap_obj c)\"\n\ndefinition acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\"\n  where\n  \"acap_rights_update R acap \\<equiv>\n    case acap of\n      FrameCap ref cR sz dev as \\<Rightarrow> FrameCap ref (validate_vm_rights R) sz dev as\n    | _ \\<Rightarrow> acap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Length of PTE Physical Page Number: The length of the physical page number in a page table entry is defined as the difference between the total word bits and the bits used for the page table.",
    "input": "",
    "output": "lemma \"LENGTH(pte_ppn_len) = word_bits - pt_bits\"\n  by (simp add: pte_bits_def ptTranslationBits_def word_size_bits_def word_bits_def\n                pt_bits_def table_size_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64-Specific Data Types: Defines architecture-specific object types including small, large, and huge page objects, page table objects, and ASID pool objects. These types are used to create default architectural capabilities and objects with specific properties, such as read-write permissions and page sizes, ensuring that the system can manage memory and address spaces effectively.",
    "input": "",
    "output": "datatype aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | HugePageObj\n  | PageTableObj\n  | ASIDPoolObj\n\ndefinition arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\"\n  where\n  \"arch_is_frame_type aobj \\<equiv> aobj \\<noteq> PageTableObj\"\n\ndefinition arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\"\n  where\n  \"arch_default_cap tp r n dev \\<equiv> case tp of\n     SmallPageObj \\<Rightarrow> FrameCap r vm_read_write RISCVSmallPage dev None\n   | LargePageObj \\<Rightarrow> FrameCap r vm_read_write RISCVLargePage dev None\n   | HugePageObj  \\<Rightarrow> FrameCap r vm_read_write RISCVHugePage dev None\n   | PageTableObj \\<Rightarrow> PageTableCap r None\n   | ASIDPoolObj  \\<Rightarrow> ASIDPoolCap r 0\" (* unused, but nicer properties when defined *)\n\ndefinition default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\"\n  where\n  \"default_arch_object tp dev n \\<equiv> case tp of\n     SmallPageObj \\<Rightarrow> DataPage dev RISCVSmallPage\n   | LargePageObj \\<Rightarrow> DataPage dev RISCVLargePage\n   | HugePageObj  \\<Rightarrow> DataPage dev RISCVHugePage\n   | PageTableObj \\<Rightarrow> PageTable (\\<lambda>_. InvalidPTE)\n   | ASIDPoolObj  \\<Rightarrow> ASIDPool Map.empty\"\n\ntype_synonym riscv_vspace_region_uses = \"vspace_ref \\<Rightarrow> riscvvspace_region_use\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Memory Levels: The architecture defines four levels of virtual memory, with the highest level containing ASID pools and the lower levels containing page tables. The top level is designated for ASID pools, followed by three levels of page tables, where the bottom level (level 0) contains only InvalidPTEs or PagePTEs.",
    "input": "",
    "output": "type_synonym vm_level = 4\n\ndefinition asid_pool_level :: vm_level\n  where\n  \"asid_pool_level = maxBound\"\n\ndefinition max_pt_level :: vm_level\n  where\n  \"max_pt_level = asid_pool_level - 1\"\n\nend\n\nqualify RISCV64_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64 Architecture State: Maintains architecture-specific state including an ASID table, global page table sets for different VM levels, and a kernel virtual space mapping.",
    "input": "",
    "output": "record arch_state =\n  riscv_asid_table :: \"asid_high_index \\<rightharpoonup> obj_ref\"\n  riscv_global_pts :: \"RISCV64_A.vm_level \\<Rightarrow> obj_ref set\"\n  riscv_kernel_vspace :: \"obj_ref \\<Rightarrow> RISCV64_H.riscvvspace_region_use\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64 Global Page Tables: The architecture-specific state includes generalized global page tables, with constraints that limit the set of tables at the maximum page table level to a singleton and ensure that the ASID pool level contains no tables. Other levels may have multiple or no tables, depending on kernel initialization.",
    "input": "",
    "output": "end_qualify\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Object Types: Define the types of architectural objects, including AASIDPool, APageTable, AUserData with a specified virtual page size, and ADeviceData with a specified virtual page size. These types categorize different kinds of memory and control structures in the system. \n\nBadge Bits: Specify the number of bits used for badges, which is set to 64 bits.",
    "input": "",
    "output": "datatype aa_type =\n    AASIDPool\n  | APageTable\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\"\n  where\n  \"aa_type ao \\<equiv> case ao of\n     PageTable pt    \\<Rightarrow> APageTable\n   | DataPage dev sz \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n   | ASIDPool f      \\<Rightarrow> AASIDPool\"\n\ndefinition badge_bits :: nat\n  where\n  \"badge_bits \\<equiv> 64\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "RISCV64-Specific TCB: Defines architecture-specific data types and structures for the TCB, tailored to the RISCV64 architecture, ensuring that the thread control block is optimized for the specific features and requirements of the RISCV64 platform.",
    "input": "",
    "output": "qualify RISCV64_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific TCB: Contains a field for user context, ensuring that the architecture-specific part of the TCB is properly initialized with a default user context.",
    "input": "",
    "output": "record arch_tcb =\n  tcb_context :: user_context\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition default_arch_tcb :: arch_tcb\n  where\n  \"default_arch_tcb \\<equiv> \\<lparr>tcb_context = new_context\\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch TCB Context Management: Provides functions to set and get the user context within the architecture-specific TCB, ensuring compatibility with user-level operations.",
    "input": "",
    "output": "definition arch_tcb_context_set :: \"user_context \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\n  where\n  \"arch_tcb_context_set uc a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := uc \\<rparr>\"\n\ndefinition arch_tcb_context_get :: \"arch_tcb \\<Rightarrow> user_context\"\n  where\n  \"arch_tcb_context_get a_tcb \\<equiv> tcb_context a_tcb\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific TCB Register Management: Provides accessor functions to set and get user registers in the architecture-specific part of the TCB, ensuring that the register context is correctly updated and retrieved.",
    "input": "",
    "output": "definition arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\n  where\n  \"arch_tcb_set_registers regs a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := UserContext regs \\<rparr>\"\n\ndefinition arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\"\n  where\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-specific Fault Handling: Generate and handle architecture-specific fault messages. The system creates a fault message containing the program counter, virtual pointer, and architecture-specific data, and processes the fault reply, returning a boolean indicating successful handling.",
    "input": "",
    "output": "chapter \\<open>Architecture-specific Fault-handling Functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\n  where\n  \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData)\n   od\"\n\ndefinition handle_arch_fault_reply ::\n  \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\n  where\n  \"handle_arch_fault_reply vmf thread x y \\<equiv> return True\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-specific TCB Functions: Provide architecture-specific operations for sanitizing register values, retrieving sanitization information, and performing post-modification actions on registers. These functions ensure that register modifications are handled in an architecture-appropriate manner, maintaining the integrity and consistency of the system state.",
    "input": "",
    "output": "chapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\n  where\n  \"sanitise_register t r v \\<equiv> v\"\n\ndefinition arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\n  where\n  \"arch_get_sanitise_register_info t \\<equiv> return False\"\n\ndefinition arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\n  where\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update CNode Capability Data: Extract new guard size and guard bits from the provided data, ensuring that the CNode capability is updated with the specified guard parameters.",
    "input": "",
    "output": "definition update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\"\n  where\n  \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 58;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capability Physicality: Distinguish between physical and non-physical architectural capabilities, where ASIDControlCap is considered non-physical, and all other types of architectural capabilities are considered physical.",
    "input": "",
    "output": "definition arch_is_physical :: \"arch_cap \\<Rightarrow> bool\"\n  where\n  \"arch_is_physical cap \\<equiv> case cap of ASIDControlCap \\<Rightarrow> False | _ \\<Rightarrow> True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Same Region: Determine if two architecture capabilities refer to the same object or if the second capability is contained within the region of the first. This ensures that the capabilities are consistent and correctly aligned, maintaining the integrity of memory regions.",
    "input": "",
    "output": "fun arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\n  where\n  \"arch_same_region_as (FrameCap r _ sz _ _) c' =\n   (is_FrameCap c' \\<and>\n     (let\n        r' = acap_obj c';\n        sz' = acap_fsize c';\n        topA = r + (1 << pageBitsForSize sz) - 1;\n        topB = r' + (1 << pageBitsForSize sz') - 1\n      in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB))\"\n| \"arch_same_region_as (PageTableCap r _) c' = (\\<exists>r' d'. c' = PageTableCap r' d' \\<and> r = r')\"\n| \"arch_same_region_as ASIDControlCap c' = (c' = ASIDControlCap)\"\n| \"arch_same_region_as (ASIDPoolCap r _) c' = (\\<exists>r' d'. c' = ASIDPoolCap r' d' \\<and> r = r')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Capabilities for Same Object: Determine if two architecture capabilities refer to the same object by comparing their device, reference, and size. If both are frame capabilities, they must have matching device, reference, and size, and the reference must be within the bounds of the frame. For other types of capabilities, a different comparison function is used.",
    "input": "",
    "output": "definition same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\n  where\n  \"same_aobject_as cap cap' \\<equiv>\n     case (cap, cap') of\n       (FrameCap ref _ sz dev _, FrameCap ref' _ sz' dev' _) \\<Rightarrow>\n         (dev, ref, sz) = (dev', ref', sz') \\<and> ref \\<le> ref + 2 ^ pageBitsForSize sz - 1\n     | _ \\<Rightarrow> arch_same_region_as cap cap'\"\n\ndeclare same_aobject_as_def[simp]\n\ndefinition arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\n  where\n  \"arch_is_cap_revocable new_cap src_cap \\<equiv> False\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Instantiation for RISCV64 Architecture: Defines concrete types for abstract type names, including object references, virtual space references, data, capability references, and length types, as well as specific bit lengths and indices for ASID (Address Space Identifier) components.",
    "input": "",
    "output": "type_synonym obj_ref         = machine_word\ntype_synonym vspace_ref      = machine_word\n\ntype_synonym data            = machine_word\ntype_synonym cap_ref         = \"bool list\"\ntype_synonym length_type     = machine_word\n\ntype_synonym asid_low_len    = 9\ntype_synonym asid_low_index  = \"asid_low_len word\"\n\ntype_synonym asid_high_len   = 7\ntype_synonym asid_high_index = \"asid_high_len word\"\n\ntype_synonym asid_len        = 16\ntype_synonym asid_rep_len    = asid_len\ntype_synonym asid            = \"asid_rep_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Conversions: Define conversions between different data types, including object references, virtual space references, natural numbers, lengths, and various word sizes. These conversions ensure seamless data manipulation and interoperability within the system.",
    "input": "",
    "output": "definition oref_to_data :: \"obj_ref \\<Rightarrow> data\"\n  where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition data_to_oref :: \"data \\<Rightarrow> obj_ref\"\n  where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition vref_to_data :: \"vspace_ref \\<Rightarrow> data\"\n  where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition data_to_vref :: \"data \\<Rightarrow> vspace_ref\"\n  where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition nat_to_len :: \"nat \\<Rightarrow> length_type\"\n  where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition data_to_nat :: \"data \\<Rightarrow> nat\"\n  where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition data_to_16 :: \"data \\<Rightarrow> 16 word\"\n  where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition data_to_cptr :: \"data \\<Rightarrow> cap_ref\"\n  where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\"\n  where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\"\n  where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Data Conversion Simplifications: Define and simplify conversions between different data types, including object references, virtual references, natural numbers, 16-bit data, and capability pointers. These simplifications facilitate automatic unfolding in proofs, ensuring consistent and efficient data handling.",
    "input": "",
    "output": "lemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Dependent Sizes: Define the standard sizes for slots and message labels, as well as the initial state for a new user context.",
    "input": "",
    "output": "definition slot_bits :: nat\n  where\n  \"slot_bits \\<equiv> 5\"\n\ndefinition msg_label_bits :: nat\n  where\n  [simp]: \"msg_label_bits \\<equiv> 52\"\n\ndefinition new_context :: \"user_context\"\n  where\n  \"new_context \\<equiv> UserContext ((\\<lambda>_. 0) (SSTATUS := sstatusSPIE))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Virtual Address Reservation: The kernel reserves a range of virtual addresses starting from the lowest virtual address in the kernel window, ensuring that this space is not available for user processes.",
    "input": "",
    "output": "definition pptr_base :: \"machine_word\"\n  where\n  \"pptr_base = Platform.RISCV64.pptrBase\"\n\ntext \"Virtual address space available to users.\"\ndefinition user_vtop :: \"machine_word\"\n  where\n  \"user_vtop = Platform.RISCV64.pptrUserTop\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Device Mapping Base: Defines the virtual address for the start of the kernel device mapping region, which is located in the highest 1GiB of memory.",
    "input": "",
    "output": "definition kdev_base :: \"machine_word\"\n  where\n  \"kdev_base = Platform.RISCV64.kdevBase\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel ELF Base: Specifies the virtual address at which the kernel code is mapped in the virtual address space.",
    "input": "",
    "output": "definition kernel_elf_base :: \"vspace_ref\"\n  where\n  \"kernel_elf_base \\<equiv> Platform.RISCV64.kernelELFBase\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Idle Thread Pointer Definition: The idle thread pointer is defined as an arbitrary aligned address, ensuring the existence of a designated location for the idle thread in the virtual space.",
    "input": "",
    "output": "definition idle_thread_ptr :: vspace_ref\n  where\n  \"idle_thread_ptr = pptr_base + 0x1000\"\n\n\ndefinition nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\"\n  where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len) (to_bl (of_nat n :: machine_word))\"\n\ndefinition msg_info_register :: register\n  where\n  \"msg_info_register \\<equiv> msgInfoRegister\"\n\ndefinition msg_registers :: \"register list\"\n  where\n  \"msg_registers \\<equiv> msgRegisters\"\n\ndefinition cap_register :: register\n  where\n  \"cap_register \\<equiv> capRegister\"\n\ndefinition badge_register :: register\n  where\n  \"badge_register \\<equiv> badgeRegister\"\n\ndefinition frame_registers :: \"register list\"\n  where\n  \"frame_registers \\<equiv> frameRegisters\"\n\ndefinition gp_registers :: \"register list\"\n  where\n  \"gp_registers \\<equiv> gpRegisters\"\n\ndefinition exception_message :: \"register list\"\n  where\n  \"exception_message \\<equiv> exceptionMessage\"\n\ndefinition syscall_message :: \"register list\"\n  where\n  \"syscall_message \\<equiv> syscallMessage\"\n\ndatatype arch_fault\n  = VMFault (vm_fault_address : vspace_ref) (vm_fault_arch_data : \"machine_word list\")\n\nend\n\narch_requalify_consts (A) idle_thread_ptr\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Validate IRQ Range: Ensure that the provided IRQ number is within the valid range, throwing a `RangeError` if the IRQ is out of bounds.",
    "input": "",
    "output": "text \\<open>This is used by some decode functions. VCPU decode functions are the first that need to bounds\n  check IRQs from the user.\\<close>\ndefinition arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"arch_check_irq irq \\<equiv> whenE (irq > maxIRQ \\<or> irq < ucast minIRQ)\n                          $ throwError (RangeError (ucast minIRQ) maxIRQ)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Set TCB: Decodes the capability and extra slots to set the TCB for a VCPU. Ensures that the operation is only valid if the first extra slot contains a ThreadCap, otherwise it throws an error.",
    "input": "",
    "output": "definition decode_vcpu_set_tcb ::\n  \"arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_set_tcb cap extras \\<equiv> case (cap, extras) of\n     (VCPUCap v, fs#_) \\<Rightarrow> (case fs of\n           (ThreadCap t, _) \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUSetTCB v t\n         | _ \\<Rightarrow> throwError IllegalOperation)\n   | (VCPUCap v, _) \\<Rightarrow> throwError TruncatedMessage\n   | _ \\<Rightarrow> throwError IllegalOperation\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Register Access: Enables reading and writing of VCPU registers, with the method of access (direct or through hardware) determined by whether the VCPU is the current one and its active state. If the VCPU is the current one and the register is saved when disabled, direct access is used; otherwise, hardware access is performed.",
    "input": "",
    "output": "definition read_vcpu_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word,'z::state_ext) s_monad\" where\n  \"read_vcpu_register vcpu_ptr reg \\<equiv> do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (on_cur_vcpu, active) \\<leftarrow> return (case cur_vcpu of\n         Some (vcpu_ptr', a) \\<Rightarrow> (vcpu_ptr' = vcpu_ptr, a)\n       | _ \\<Rightarrow> (False, False));\n\n     if on_cur_vcpu\n       then if vcpuRegSavedWhenDisabled reg \\<and> \\<not>active\n              then vcpu_read_reg vcpu_ptr reg\n              else do_machine_op $ readVCPUHardwareReg reg\n       else vcpu_read_reg vcpu_ptr reg\n  od\"\n\ndefinition\n  write_vcpu_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"write_vcpu_register vcpu_ptr reg val \\<equiv>\n  do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu o arch_state);\n     (on_cur_vcpu, active) \\<leftarrow> return (case cur_vcpu of\n         Some (cv, a) \\<Rightarrow> (cv = vcpu_ptr, a)\n       | _ \\<Rightarrow> (False, False));\n\n     if on_cur_vcpu\n       then if vcpuRegSavedWhenDisabled reg \\<and> \\<not>active\n         then vcpu_write_reg vcpu_ptr reg val\n         else do_machine_op $ writeVCPUHardwareReg reg val\n       else vcpu_write_reg vcpu_ptr reg val\n  od\"\n\ndefinition decode_vcpu_read_register ::\n  \"machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_read_register args cap \\<equiv> case (args, cap) of\n      (reg#_, VCPUCap p) \\<Rightarrow> if fromEnum (maxBound::vcpureg) < unat reg\n                           then throwError (InvalidArgument 1)\n                           else returnOk $ InvokeVCPU $ VCPUReadRegister p $ toEnum (unat reg)\n    | (_, _) \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition decode_vcpu_write_register :: \"machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_write_register args cap \\<equiv> case (args, cap) of\n    (reg#val#_, VCPUCap p) \\<Rightarrow> if fromEnum (maxBound::vcpureg) < unat reg\n                              then throwError (InvalidArgument 1)\n                              else returnOk $ InvokeVCPU $ VCPUWriteRegister p (toEnum (unat reg)) val\n  | (_, _) \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_read_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\n  where\n  \"invoke_vcpu_read_register v reg \\<equiv> do\n     val \\<leftarrow> read_vcpu_register v reg;\n     return [val]\n   od\"\n\ndefinition\n  invoke_vcpu_write_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"invoke_vcpu_write_register v reg val \\<equiv>  write_vcpu_register v reg val\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Interrupt Injection: Allows the injection of a virtual interrupt into a VCPU by constructing a virtual interrupt (virq) with specified parameters (group, priority, and ID), validating the input values, and updating the VCPU's state. The function ensures that the virq is not already active before injecting it, maintaining the integrity of the VCPU's interrupt state.",
    "input": "",
    "output": "definition make_virq :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> virq\" where\n  \"make_virq grp prio irq \\<equiv>\n    let\n      groupShift = 30;\n      prioShift = 23;\n      irqPending = 1 << 28;\n      eoiirqen = 1 << 19\n    in ((grp && 1) << groupShift) || ((prio && 0x1F) << prioShift) || (irq && 0x3FF)\n       || irqPending || eoiirqen\"\n\ndefinition virq_type :: \"virq \\<Rightarrow> nat\" where\n  \"virq_type virq \\<equiv> unat ((virq >> 28) && 3)\"\n\ndefinition is_virq_active :: \"virq \\<Rightarrow> bool\" where\n  \"is_virq_active virq \\<equiv> virq_type virq = 2\"\n\ndefinition decode_vcpu_inject_irq ::\n  \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_inject_irq ptrs cap \\<equiv> case (ptrs, cap) of\n  (mr0 # _, VCPUCap p) \\<Rightarrow> doE\n     vid \\<leftarrow> returnOk (mr0 && 0xFFFF);\n     priority \\<leftarrow> returnOk ((mr0 >> 16) && 0xFF);\n     group \\<leftarrow> returnOk ((mr0 >> 24) && 0xFF);\n     index \\<leftarrow> returnOk ((mr0 >> 32) && 0xFF);\n     range_check vid 0 ((1 << 10) - 1);\n     range_check priority 0 31;\n     range_check group 0 1;\n     num_list_regs \\<leftarrow> liftE $ gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     whenE (index \\<ge> of_nat num_list_regs) $\n        (throwError $ RangeError 0 (of_nat num_list_regs - 1));\n\n     vcpu \\<leftarrow> liftE $ get_vcpu p;\n     vcpuLR \\<leftarrow> returnOk (vgic_lr $ vcpu_vgic $ vcpu);\n\n     whenE (is_virq_active (vcpuLR (unat index))) $ throwError DeleteFirst;\n\n     virq \\<leftarrow> returnOk (make_virq group priority vid);\n     returnOk $ InvokeVCPU $ VCPUInjectIRQ p (unat index) virq\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_inject_irq :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invoke_vcpu_inject_irq vr index virq \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    if (cur_v \\<noteq> None \\<and> fst (the cur_v) = vr)\n    then do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat index) virq\n    else vgic_update_lr vr index virq\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Acknowledge VPPI: Acknowledge a Virtual Posted-Interrupt (VPPI) event for a VCPU. This action updates the VCPU's VPPI mask to unmask the specified VPPI event, allowing the VCPU to handle the interrupt.",
    "input": "",
    "output": "definition decode_vcpu_ack_vppi ::\n  \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_ack_vppi mrs cap \\<equiv>\n     case (mrs, cap)\n       of (mr0 # _, VCPUCap vcpu_ptr) \\<Rightarrow> doE\n           arch_check_irq mr0;\n           (case irq_vppi_event_index (ucast mr0)\n            of None \\<Rightarrow> throwError $ InvalidArgument 0\n             | Some vppi \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUAckVPPI vcpu_ptr vppi)\n         odE\n       | _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_ack_vppi :: \"obj_ref \\<Rightarrow> vppievent_irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invoke_vcpu_ack_vppi vcpu_ptr vppi =\n     vcpu_update vcpu_ptr\n                 (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := False) \\<rparr>)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Invocation and Decoding: VCPU can perform various operations including setting the associated TCB, reading and writing registers, injecting IRQs, and acknowledging VPPIs. These operations are decoded from invocation labels and arguments, ensuring that the correct VCPU actions are executed based on the provided parameters.",
    "input": "",
    "output": "definition\n  perform_vcpu_invocation :: \"vcpu_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_vcpu_invocation iv \\<equiv> case iv of\n     VCPUSetTCB vcpu tcb \\<Rightarrow> do associate_vcpu_tcb vcpu tcb; return [] od\n   | VCPUReadRegister vcpu reg \\<Rightarrow> invoke_vcpu_read_register vcpu reg\n   | VCPUWriteRegister vcpu reg val \\<Rightarrow> do invoke_vcpu_write_register vcpu reg val; return [] od\n   | VCPUInjectIRQ vcpu index vir \\<Rightarrow> do invoke_vcpu_inject_irq vcpu index vir; return [] od\n   | VCPUAckVPPI vcpu vppi \\<Rightarrow> do invoke_vcpu_ack_vppi vcpu vppi; return [] od\"\n\ndefinition decode_vcpu_invocation ::\n  \"machine_word \\<Rightarrow> machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_invocation label args cap extras \\<equiv> case cap of\n  VCPUCap _ \\<Rightarrow> (case invocation_type label of\n      ArchInvocationLabel ARMVCPUSetTCB \\<Rightarrow> decode_vcpu_set_tcb cap extras\n    | ArchInvocationLabel ARMVCPUReadReg \\<Rightarrow> decode_vcpu_read_register args cap\n    | ArchInvocationLabel ARMVCPUWriteReg \\<Rightarrow> decode_vcpu_write_register args cap\n    | ArchInvocationLabel ARMVCPUInjectIRQ \\<Rightarrow> decode_vcpu_inject_irq args cap\n    | ArchInvocationLabel ARMVCPUAckVPPI \\<Rightarrow> decode_vcpu_ack_vppi args cap\n    |  _ \\<Rightarrow> throwError IllegalOperation)\n  | _ \\<Rightarrow> throwError IllegalOperation\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific Interrupt Handling: Manages virtual and physical interrupts, including handling maintenance interrupts, masking interrupts, and updating the state of the current virtual CPU. Ensures that interrupt-related faults are handled only when the current thread is in a runnable state.",
    "input": "",
    "output": "chapter \"Arch-specific Interrupts\"\n\ntheory ArchInterrupt_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition virqSetEOIIRQEN :: \"virq \\<Rightarrow> machine_word \\<Rightarrow> virq\" where\n  \"virqSetEOIIRQEN virq v \\<equiv>\n     if virq_type virq = 3\n     then virq\n     else (virq && ~~0x80000) || ((v << 19) && 0x80000)\"\n\ndefinition vgic_maintenance :: \"(unit,'z::state_ext) s_monad\" where\n  \"vgic_maintenance = do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     case cur_vcpu\n       of Some (vcpu_ptr, True) \\<Rightarrow> do\n            eisr0 \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_eisr0;\n            eisr1 \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_eisr1;\n            flags \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_misr;\n            vgic_misr_eoi \\<leftarrow> return $ vgicHCREN;\n            irq_idx \\<leftarrow> return (if eisr0 \\<noteq> 0 then word_ctz eisr0 else word_ctz eisr1 + 32);\n            gic_vcpu_num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs o arch_state);\n            fault \\<leftarrow> if flags && vgic_misr_eoi \\<noteq> 0\n                    then\n                      if eisr0 = 0 \\<and> eisr1 = 0 \\<or> irq_idx \\<ge> gic_vcpu_num_list_regs\n                      then return $ VGICMaintenance None\n                      else do\n                        virq <- do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat irq_idx);\n                        virqen <- return $ virqSetEOIIRQEN virq 0;\n                        do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat irq_idx) virqen;\n                        vgic_update_lr vcpu_ptr irq_idx virqen;\n                        return $ VGICMaintenance $ Some $ of_nat irq_idx\n                      od\n                    else return $ VGICMaintenance None;\n\n            ct \\<leftarrow> gets cur_thread;\n            st \\<leftarrow> get_thread_state ct;\n            \\<comment> \\<open>until a proof links active current vcpu to runnable current thread, we need this\n               check: @{term handle_fault} needs a runnable current thread\\<close>\n            when (runnable st) $ handle_fault ct $ ArchFault fault\n          od\n        | _ \\<Rightarrow> return ()\n   od\"\n\ndefinition vppi_event :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vppi_event irq = do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     case cur_vcpu\n       of Some (vcpu_ptr, True) \\<Rightarrow> do\n            do_machine_op $ maskInterrupt True irq;\n            vppi \\<leftarrow> return $ the $ irq_vppi_event_index irq;\n            vcpu_update vcpu_ptr\n                        (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := True) \\<rparr>);\n            ct \\<leftarrow> gets cur_thread;\n            st \\<leftarrow> get_thread_state ct;\n            \\<comment> \\<open>until a proof links active current vcpu to runnable current thread, we need this\n               check: @{term handle_fault} needs a runnable current thread\\<close>\n            when (runnable st) $ handle_fault ct $ ArchFault $ VPPIEvent irq\n          od\n        | _ \\<Rightarrow> return ()\n   od\"\n\ndefinition handle_reserved_irq :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"handle_reserved_irq irq \\<equiv> do\n     when (irq = irqVGICMaintenance) vgic_maintenance;\n     when (irq_vppi_event_index irq \\<noteq> None) $ vppi_event irq\n   od\"\n\nfun arch_invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_invoke_irq_handler (ACKIrq irq) = (do_machine_op $ maskInterrupt False irq)\"\n| \"arch_invoke_irq_handler _ = return ()\"\n\ndefinition arch_mask_irq_signal :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_mask_irq_signal irq \\<equiv> do_machine_op $ maskInterrupt True irq\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Control Invocation: Creates a new ASID pool object, provides a capability to it, and connects it to the global virtual ASID table. This ensures that the ASID pool is properly initialized and integrated into the system's memory management.",
    "input": "",
    "output": "definition perform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_asid_control_invocation iv \\<equiv> case iv of\n     MakePool frame slot parent base \\<Rightarrow> do\n       delete_objects frame pageBits;\n       pcap \\<leftarrow> get_cap parent;\n       set_cap (max_free_index_update pcap) parent;\n       retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n       cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n       assert (asid_low_bits_of base = 0);\n       asid_table \\<leftarrow> gets asid_table;\n       asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n       modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>arm_asid_table := asid_table'\\<rparr>\\<rparr>)\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Management: Assign an ASID to a top-level page table, updating the corresponding capability and storing the ASID pool entry. This ensures that the ASID is correctly associated with the page table, enabling proper memory management and virtual address translation.\n\nPage Table Operations: Perform operations such as mapping and unmapping pages, updating the page table entries, and invalidating TLB entries. These operations ensure that the page tables are correctly managed, maintaining the integrity of the virtual memory system.",
    "input": "",
    "output": "definition perform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_asid_pool_invocation iv \\<equiv> case iv of\n     Assign asid pool_ptr ct_slot \\<Rightarrow> do\n       pt_cap \\<leftarrow> get_cap ct_slot;\n       assert $ is_ArchObjectCap pt_cap;\n       acap \\<leftarrow> return $ the_arch_cap pt_cap;\n       assert $ is_PageTableCap acap;\n       set_cap (ArchObjectCap $ update_map_data acap $ Some (asid,0)) ct_slot;\n       pt_base \\<leftarrow> return $ acap_obj acap;\n       store_asid_pool_entry pool_ptr asid (Some (ASIDPoolVSpace None pt_base))\n     od\"\n\ndefinition perform_pg_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pg_inv_unmap cap ct_slot \\<equiv> do\n     assert $ is_FrameCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> unmap_page (acap_fsize cap) asid vaddr (acap_obj cap)\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data (the_arch_cap old_cap) None) ct_slot\n   od\"\n\ndefinition perform_pg_inv_map ::\n  \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> vm_level \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pg_inv_map cap ct_slot pte slot level \\<equiv> do\n     old_pte \\<leftarrow> get_pte level slot;\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte level slot pte;\n     do_machine_op $ cleanByVA_PoU slot (addrFromPPtr slot);\n     when (old_pte \\<noteq> InvalidPTE) $ do\n        (asid, vaddr) \\<leftarrow> assert_opt $ acap_map_data cap;\n        invalidate_tlb_by_asid_va asid vaddr\n     od\n   od\"\n\ndefinition perform_pg_inv_get_addr ::\n  \"obj_ref \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_pg_inv_get_addr ptr \\<equiv> return [addrFromPPtr ptr]\"\n\ndefinition do_flush :: \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\" where\n  \"do_flush type vstart vend pstart \\<equiv>\n     case type of\n       Clean \\<Rightarrow> cleanCacheRange_RAM vstart vend pstart\n     | Invalidate \\<Rightarrow> invalidateCacheRange_RAM vstart vend pstart\n     | CleanInvalidate \\<Rightarrow> cleanInvalidateCacheRange_RAM vstart vend pstart\n     | Unify \\<Rightarrow> do\n         cleanCacheRange_PoU vstart vend pstart;\n         dsb;\n         invalidateCacheRange_I vstart vend pstart;\n         isb\n       od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Flush Operation: Perform a memory flush operation on a specified range of virtual and physical addresses. The type of flush (vspace or page) determines the specific behavior, ensuring that the memory is correctly updated and synchronized.",
    "input": "",
    "output": "definition perform_flush ::\n  \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_flush type vstart vend pstart space asid \\<equiv> do\n     start \\<leftarrow> return $ ptrFromPAddr pstart;\n     end \\<leftarrow> return $ start + (vend - vstart);\n     when (start < end) $ do_machine_op $ do_flush type start end pstart\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Frame Capability Operations: Authorize the mapping and unmapping of memory, querying the physical address of a page, and flushing specific memory ranges. These operations ensure that memory management is secure and efficient, maintaining the integrity and performance of the system.",
    "input": "",
    "output": "definition perform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_page_invocation iv \\<equiv> case iv of\n     PageMap cap ct_slot (pte,slot,level) \\<Rightarrow> do\n       perform_pg_inv_map cap ct_slot pte slot level;\n       return []\n     od\n   | PageUnmap cap ct_slot \\<Rightarrow> do perform_pg_inv_unmap cap ct_slot; return [] od\n   | PageGetAddr ptr \\<Rightarrow> perform_pg_inv_get_addr ptr\n   | PageFlush type start end pstart space asid \\<Rightarrow> do\n       perform_flush type start end pstart space asid;\n       return []\n     od\"\n\n\ndefinition perform_pt_inv_map ::\n  \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> vm_level \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pt_inv_map cap ct_slot pte slot level = do\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte level slot pte;\n     do_machine_op $ cleanByVA_PoU slot (addrFromPPtr slot)\n   od\"\n\ndefinition perform_pt_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pt_inv_unmap cap ct_slot = do\n     assert $ is_PageTableCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> do\n         p \\<leftarrow> return $ acap_obj cap;\n         unmap_page_table asid vaddr p;\n         slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + mask (pt_bits (acap_pt_type cap))];\n         mapM_x (swp (store_pte (acap_pt_type cap)) InvalidPTE) slots;\n         do_machine_op $ cleanCacheRange_PoU p (p + mask (pt_bits (acap_pt_type cap)))\n                                             (addrFromPPtr p)\n       od\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data old_cap None) ct_slot\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "PageTable Invocation: Allows the mapping and unmapping of page tables. This ensures that memory management operations are performed with the appropriate authority, maintaining the integrity and security of the system's memory.",
    "input": "",
    "output": "definition perform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_page_table_invocation iv \\<equiv> case iv of\n     PageTableMap cap ct_slot pte slot level \\<Rightarrow> perform_pt_inv_map cap ct_slot pte slot level\n   | PageTableUnmap cap ct_slot \\<Rightarrow> perform_pt_inv_unmap cap ct_slot\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Invocation: VSpace capabilities allow for the flushing of memory regions. The invocation can either do nothing or perform a flush operation, which involves specifying the type, start and end addresses, physical start address, space, and ASID to ensure the memory is correctly managed and updated.",
    "input": "",
    "output": "definition perform_vspace_invocation :: \"vspace_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_vspace_invocation iv \\<equiv> case iv of\n     VSpaceNothing \\<Rightarrow> return ()\n   | VSpaceFlush type start end pstart space asid \\<Rightarrow> perform_flush type start end pstart space asid\"\n\nlocale_abbrev arch_no_return :: \"(unit, 'z::state_ext) s_monad \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\n  where\n  \"arch_no_return oper \\<equiv> do oper; return [] od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocation Handling: Dispatches AARCH64-specific system calls to the appropriate handlers for operations on virtual spaces, page tables, pages, ASID control, ASID pools, and VCPUs. Ensures that each invocation is processed by the corresponding architectural function, maintaining the integrity and functionality of the system's memory and virtualization components.",
    "input": "",
    "output": "definition arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\n  where\n  \"arch_perform_invocation i \\<equiv> liftE $ case i of\n     InvokeVSpace oper \\<Rightarrow> arch_no_return $ perform_vspace_invocation oper\n   | InvokePageTable oper \\<Rightarrow> arch_no_return $ perform_page_table_invocation oper\n   | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n   | InvokeASIDControl oper \\<Rightarrow> arch_no_return $ perform_asid_control_invocation oper\n   | InvokeASIDPool oper \\<Rightarrow> arch_no_return $ perform_asid_pool_invocation oper\n   | InvokeVCPU oper \\<Rightarrow> perform_vcpu_invocation oper\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Hypervisor Faults: Process hypervisor fault events by checking if the FPU is enabled, and based on the fault type, either handle a specific user exception or an architectural fault. If the FPU is not enabled, the fault handling fails.",
    "input": "",
    "output": "chapter \\<open>Handle Hypervisor Fault Events\\<close>\n\ntheory Hypervisor_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"machine_word \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\n  where\n  \"handle_hypervisor_fault thread (ARMVCPUFault hsr) = do\n     fpu_enabled \\<leftarrow> do_machine_op isFpuEnable;\n     if \\<not>fpu_enabled\n     then fail\n     else if hsr = 0x2000000 \\<comment> \\<open>@{text UNKNOWN_FAULT}\\<close>\n          then do\n            esr \\<leftarrow> do_machine_op getESR;\n            handle_fault thread (UserException (esr && mask 32) 0)\n          od\n          else handle_fault thread (ArchFault $ VCPUFault (ucast hsr))\n   od\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reserve Memory Region: Reserve a specified number of bytes in memory, optionally tagging the region as kernel data. This function currently acts as a placeholder and does not perform any actual reservation or tagging.",
    "input": "",
    "output": "definition reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Architecture-Specific Objects: Initialize architecture-specific objects based on their type, including cleaning cache ranges for page and table objects. For non-device page objects, clean the cache range as RAM, and for page table and virtual space objects, clean the cache range with PoU (Preserve on Update).",
    "input": "",
    "output": "definition vs_apiobj_size where\n  \"vs_apiobj_size ty \\<equiv>\n     case ty of\n       ArchObject SmallPageObj \\<Rightarrow> pageBitsForSize ARMSmallPage\n     | ArchObject LargePageObj \\<Rightarrow> pageBitsForSize ARMLargePage\n     | ArchObject HugePageObj \\<Rightarrow> pageBitsForSize ARMHugePage\n     | ArchObject PageTableObj \\<Rightarrow> table_size NormalPT_T\n     | ArchObject VSpaceObj \\<Rightarrow> table_size VSRootPT_T\"\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv>\n     if \\<not>is_device \\<and>\n        new_type \\<in> {ArchObject SmallPageObj, ArchObject LargePageObj, ArchObject HugePageObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_RAM ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else if new_type \\<in> {ArchObject PageTableObj, ArchObject VSpaceObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_PoU ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else\n       return ()\"\n\ndefinition empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (FPUState (\\<lambda>_. 0) 0 0) (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context, tcb_vcpu = None \\<rparr>\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Post-Capability Deletion Action: Perform any necessary architectural actions after a capability is deleted. In this case, no specific action is required.",
    "input": "",
    "output": "definition arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n  \"arch_post_cap_deletion ac \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Generic Object References: The system defines arch-specific generic object references, but they are not covered by the generic references. The set of arch-specific generic object references for any arch_cap is empty, and the cleanup operation for any arch_cap results in a NullCap.",
    "input": "",
    "output": "datatype arch_gen_obj_ref = unit\n\ndefinition arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\" where\n  \"arch_gen_obj_refs ac \\<equiv> {}\"\n\ndefinition arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\" where\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Global Page Table Pointer Alignment: The global page table pointer is set to a memory address that is sufficiently aligned for one page, ensuring proper alignment for page table operations.",
    "input": "",
    "output": "definition arm_global_pt_ptr :: obj_ref where\n  \"arm_global_pt_ptr = pptr_base + 0x2000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of IRQ Node Pointer: The IRQ node pointer is initialized to a memory address that is sufficiently aligned for the IRQ type and CTE level bits, ensuring proper alignment and access for interrupt handling.",
    "input": "",
    "output": "definition init_irq_node_ptr :: obj_ref where\n  \"init_irq_node_ptr = pptr_base + 0xc000\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Canonical User-Virtual Address: Defines the highest user-virtual address that is still considered canonical, which may exceed the maximum mappable user address. For AArch64-hyp, this value represents the top of the entire IPA address space, ensuring that all user-virtual addresses are within a valid and usable range.",
    "input": "",
    "output": "definition canonical_user :: \"vspace_ref\" where\n  \"canonical_user \\<equiv> mask ipa_size\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Virtual Space Regions: Define the initial state of the architecture, including an empty ASID table, a function to initialize virtual space regions based on their addresses, an empty VMID table, and other necessary components. The virtual space regions are categorized as either part of the kernel window or invalid, ensuring that the invariants for the kernel-level page table mappings are consistent.",
    "input": "",
    "output": "definition init_vspace_uses :: \"vspace_ref \\<Rightarrow> arm_vspace_region_use\" where\n  \"init_vspace_uses p \\<equiv>\n     if p \\<in> {pptr_base ..< pptr_base + (1 << 30)} then ArmVSpaceKernelWindow\n     else ArmVSpaceInvalidRegion\"\n\n\ndefinition init_arch_state :: arch_state where\n  \"init_arch_state \\<equiv> \\<lparr>\n     arm_asid_table = Map.empty,\n     arm_kernel_vspace = init_vspace_uses,\n     arm_vmid_table = Map.empty,\n     arm_next_vmid = 0,\n     arm_us_global_vspace = arm_global_pt_ptr,\n     arm_current_vcpu = None,\n     arm_gicvcpu_numlistregs = undefined\n   \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Kernel State: The kernel state is initialized with an empty global page table, an idle thread in the idle state, and an interrupt controller with initial mappings. The kernel heap is set up with specific capabilities for the idle thread and a global page table object, while the capability derivation tree and original capabilities are initially empty.",
    "input": "",
    "output": "definition global_pt_obj :: arch_kernel_obj where\n  \"global_pt_obj \\<equiv> PageTable (VSRootPT (\\<lambda>_. InvalidPTE))\"\n\ndefinition init_kheap :: kheap where\n  \"init_kheap \\<equiv>\n    (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n           then Some (CNode 0 (empty_cnode 0))\n           else None)\n    (idle_thread_ptr \\<mapsto>\n       TCB \\<lparr>\n         tcb_ctable = NullCap,\n         tcb_vtable = NullCap,\n         tcb_reply = NullCap,\n         tcb_caller = NullCap,\n         tcb_ipcframe = NullCap,\n         tcb_state = IdleThreadState,\n         tcb_fault_handler = replicate word_bits False,\n         tcb_ipc_buffer = 0,\n         tcb_fault = None,\n         tcb_bound_notification = None,\n         tcb_mcpriority = minBound,\n         tcb_arch = init_arch_tcb\n         \\<rparr>,\n     arm_global_pt_ptr \\<mapsto> ArchObj global_pt_obj\n    )\"\n\ndefinition init_cdt :: cdt where\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition init_ioc :: \"cslot_ptr \\<Rightarrow> bool\" where\n  \"init_ioc \\<equiv>\n     \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                    (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition init_A_st :: \"'z::state_ext state\"\n  where\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n \nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup IPC Buffer Authority: Verify that a thread has the necessary authority to read from or write to its IPC buffer. The function checks the buffer's capabilities and ensures that the thread's access rights are appropriate for the operation, either reading or writing, based on whether the thread is a receiver or not.",
    "input": "",
    "output": "definition lookup_ipc_buffer :: \"bool \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n  \"lookup_ipc_buffer is_receiver thread \\<equiv> do\n     buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n     buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n     buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n     case buffer_cap of\n       ArchObjectCap (FrameCap p R vms False _) \\<Rightarrow>\n         if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n         then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n         else return None\n     | _ \\<Rightarrow> return None\n   od\"\n\ndefinition pool_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\" where\n  \"pool_for_asid asid \\<equiv> \\<lambda>s. asid_table s (asid_high_bits_of asid)\"\n\ndefinition entry_for_pool :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (obj_ref \\<rightharpoonup> asid_pool) \\<Rightarrow> asid_pool_entry option\"\n  where\n  \"entry_for_pool pool_ptr asid \\<equiv> do {\n     pool \\<leftarrow> oapply pool_ptr;\n     K $ pool (asid_low_bits_of asid)\n   }\"\n\ndefinition vspace_for_pool :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (obj_ref \\<rightharpoonup> asid_pool) \\<Rightarrow> obj_ref option\" where\n  \"vspace_for_pool pool_ptr asid \\<equiv> do {\n     entry \\<leftarrow> entry_for_pool pool_ptr asid;\n     oreturn $ ap_vspace entry\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Mapping: Retrieve the ASID pool entry corresponding to a given ASID. This involves finding the appropriate pool for the ASID and then locating the specific entry within that pool.",
    "input": "",
    "output": "definition entry_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> asid_pool_entry option\" where\n  \"entry_for_asid asid = do {\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     entry_for_pool pool_ptr asid \\<circ> asid_pools_of\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update ASID Pool Entry: Modify an entry in the ASID pool by applying a function to the current entry and updating the pool with the new value. This ensures that the ASID map is correctly updated, reflecting changes in the virtual address space.",
    "input": "",
    "output": "definition update_asid_pool_entry ::\n  \"(asid_pool_entry \\<rightharpoonup> asid_pool_entry) \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n  \"update_asid_pool_entry f asid \\<equiv> do\n     pool_ptr \\<leftarrow> gets_the $ pool_for_asid asid;\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     idx \\<leftarrow> return $ asid_low_bits_of asid;\n     entry \\<leftarrow> assert_opt $ pool idx;\n     set_asid_pool pool_ptr (pool (idx := f entry))\n   od\"\n\ndefinition vspace_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\" where\n  \"vspace_for_asid asid = do {\n     oassert (0 < asid);\n     entry \\<leftarrow> entry_for_asid asid;\n     oreturn $ ap_vspace entry\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate VSpace for ASID: Find the top-level page table associated with a given virtual ASID, ensuring that the ASID is valid and returning an error if it is not. Load VMID: Retrieve the VMID associated with a given ASID by accessing the corresponding entry in the system state.",
    "input": "",
    "output": "definition find_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n  \"find_vspace_for_asid asid \\<equiv> doE\n     vspace_opt \\<leftarrow> liftE $ gets $ vspace_for_asid asid;\n     throw_opt InvalidRoot vspace_opt\n   odE\"\n\ndefinition load_vmid :: \"asid \\<Rightarrow> (vmid option, 'z::state_ext) s_monad\" where\n  \"load_vmid asid \\<equiv> do\n     entry \\<leftarrow> gets_the $ entry_for_asid asid;\n     return $ ap_vmid entry\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Associate VMID with ASID: Store a VMID in the ASID pool and update the VMID table to map the VMID to the ASID, ensuring that the association is maintained in the system.",
    "input": "",
    "output": "definition store_vmid :: \"asid \\<Rightarrow> vmid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_vmid asid hw_asid \\<equiv> do\n     update_asid_pool_entry (\\<lambda>entry. Some $ ASIDPoolVSpace (Some hw_asid) (ap_vspace entry)) asid;\n     vmid_table \\<leftarrow> gets (arm_vmid_table \\<circ> arch_state);\n     vmid_table' \\<leftarrow> return $ vmid_table (hw_asid \\<mapsto> asid);\n     modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_vmid_table := vmid_table' \\<rparr>\\<rparr>)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate TLB by ASID: Clear all TLB mappings associated with a given ASID. If the ASID is associated with a VMID, perform a machine operation to invalidate the translation for that VMID.",
    "input": "",
    "output": "definition invalidate_tlb_by_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_tlb_by_asid asid \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     case maybe_vmid of\n       None \\<Rightarrow> return ()\n     | Some vmid \\<Rightarrow> do_machine_op $ invalidateTranslationASID (ucast vmid)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate TLB by ASID and VA: Clear all TLB mappings associated with the given ASID and virtual address. If a valid VMID is found for the ASID, it performs the TLB invalidation using the combined VMID and virtual address.",
    "input": "",
    "output": "definition invalidate_tlb_by_asid_va :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_tlb_by_asid_va asid vaddr \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     case maybe_vmid of\n       None \\<Rightarrow> return ()\n     | Some vmid \\<Rightarrow>\n         do_machine_op $\n           invalidateTranslationSingle $ (ucast vmid << word_bits-asid_bits) || (vaddr >> pageBits)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate ASID: Removes the mapping from a given virtual ASID to its associated VMID, ensuring that the ASID is no longer linked to any virtual memory space.",
    "input": "",
    "output": "definition invalidate_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_asid asid \\<equiv>\n     update_asid_pool_entry (\\<lambda>entry. Some $ ASIDPoolVSpace None (ap_vspace entry)) asid\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate VMID Entry: Remove the mapping from a specified VMID to its associated ASID in the VMID table, ensuring that the VMID is no longer linked to any ASID.",
    "input": "",
    "output": "definition invalidate_vmid_entry :: \"vmid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_vmid_entry vmid \\<equiv> do\n     vmid_table \\<leftarrow> gets (arm_vmid_table \\<circ> arch_state);\n     vmid_table' \\<leftarrow> return (vmid_table (vmid := None));\n     modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_vmid_table := vmid_table' \\<rparr>\\<rparr>)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate ASID Entry: Remove mappings associated with the specified ASID, including invalidating the corresponding VMID entry if it exists.",
    "input": "",
    "output": "definition invalidate_asid_entry :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_asid_entry asid \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     when (maybe_vmid \\<noteq> None) $ invalidate_vmid_entry (the maybe_vmid);\n     invalidate_asid asid\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Find Free VMID: Locate an unused VMID, either by finding an available one in the VMID table or, if none are available, by reclaiming and invalidating the VMID currently assigned to the next ASID.",
    "input": "",
    "output": "definition find_free_vmid :: \"(vmid,'z::state_ext) s_monad\" where\n  \"find_free_vmid \\<equiv> do\n     vmid_table \\<leftarrow> gets (arm_vmid_table \\<circ> arch_state);\n     next_vmid \\<leftarrow> gets (arm_next_vmid \\<circ> arch_state);\n     maybe_vmid \\<leftarrow> return $ find (\\<lambda>a. vmid_table a = None)\n                                 (take (length [minBound :: vmid .e. maxBound])\n                                       ([next_vmid .e. maxBound] @ [minBound .e. next_vmid]));\n     case maybe_vmid of\n       Some vmid \\<Rightarrow> return vmid\n     | None \\<Rightarrow> do\n         invalidate_asid $ the $ vmid_table next_vmid;\n         do_machine_op $ invalidateTranslationASID (ucast next_vmid);\n         invalidate_vmid_entry next_vmid;\n         modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_next_vmid := next_vmid + 1 \\<rparr>\\<rparr>);\n         return next_vmid\n       od\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VMID Retrieval and Assignment: Retrieve the VMID associated with an ASID, and if no VMID is assigned, allocate a new one and associate it with the ASID.",
    "input": "",
    "output": "definition get_vmid :: \"asid \\<Rightarrow> (vmid, 'z::state_ext) s_monad\" where\n  \"get_vmid asid \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     case maybe_vmid of\n       Some vmid \\<Rightarrow> return vmid\n     | None \\<Rightarrow>  do\n         new_hw_asid \\<leftarrow> find_free_vmid;\n         store_vmid asid new_hw_asid;\n         return new_hw_asid\n       od\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle VM Fault: Format and propagate a VM fault message to the thread's supervisor after encountering a page fault. The fault message includes the fault address and type, with address translation if a VCPU is active.",
    "input": "",
    "output": "definition handle_vm_fault :: \"obj_ref \\<Rightarrow> vmfault_type \\<Rightarrow> (unit, 'z::state_ext) f_monad\" where\n  \"handle_vm_fault thread fault \\<equiv> case fault of\n     ARMDataAbort \\<Rightarrow> doE\n       addr \\<leftarrow> liftE $ do_machine_op getFAR;\n       fault \\<leftarrow> liftE $ do_machine_op getESR;\n       cur_v \\<leftarrow> liftE $ gets (arm_current_vcpu \\<circ> arch_state);\n       addr \\<leftarrow> if (\\<exists>v. cur_v = Some (v, True)) \\<comment> \\<open>VCPU active\\<close>\n              then doE\n                  \\<comment> \\<open>address bits of PAR register after S1 translation\\<close>\n                  par_el1_mask \\<leftarrow> returnOk $ 0xfffffffff000;\n                  addr' \\<leftarrow> liftE $ do_machine_op $ addressTranslateS1 addr;\n                  returnOk $ (addr' && par_el1_mask) || (addr && mask pageBits)\n                odE\n              else returnOk addr;\n       \\<comment> \\<open>32 is the width of the FSR field in the C VMFault structure\\<close>\n       throwError $ ArchFault $ VMFault addr [0, fault && mask 32]\n     odE\n   | ARMPrefetchAbort \\<Rightarrow> doE\n       pc \\<leftarrow> liftE $ as_user thread $ getRestartPC;\n       fault \\<leftarrow> liftE $ do_machine_op getESR;\n       cur_v \\<leftarrow> liftE $ gets (arm_current_vcpu \\<circ> arch_state);\n       pc \\<leftarrow> if (\\<exists>v. cur_v = Some (v, True)) \\<comment> \\<open>VCPU active\\<close>\n            then doE\n                \\<comment> \\<open>address bits of PAR register after S1 translation\\<close>\n                par_el1_mask \\<leftarrow> returnOk $ 0xfffffffff000;\n                pc' \\<leftarrow> liftE $ do_machine_op $ addressTranslateS1 pc;\n                returnOk $ (pc' && par_el1_mask) || (pc && mask pageBits)\n              odE\n            else returnOk pc;\n       \\<comment> \\<open>32 is the width of the FSR field in the C VMFault structure\\<close>\n       throwError $ ArchFault $ VMFault pc [1, fault && mask 32]\n     odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Switch Address Space: Switch the current address space to the one associated with the provided ASID, using the corresponding VMID. This ensures that the virtual memory context is correctly updated for the specified address space.",
    "input": "",
    "output": "definition arm_context_switch :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arm_context_switch vspace asid = do\n     vmid <- get_vmid asid;\n     do_machine_op $ setVSpaceRoot (addrFromPPtr vspace) (ucast vmid)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set Global User VSpace: Switch the system to use the global user address space by setting the virtual space root to the global user virtual space with VMID 0.",
    "input": "",
    "output": "definition set_global_user_vspace :: \"(unit,'z::state_ext) s_monad\" where\n  \"set_global_user_vspace = do\n     global <- gets (arm_us_global_vspace \\<circ> arch_state);\n     do_machine_op $ setVSpaceRoot (addrFromKPPtr global) 0\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Address Space Management: Switch the current address space to that of a specified thread or to the global address space if the thread's configuration is invalid. Ensure that the page table and ASID are correctly validated and updated, and handle invalid configurations by setting the global user address space.",
    "input": "",
    "output": "definition set_vm_root :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_vm_root tcb \\<equiv> do\n     thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n     thread_root \\<leftarrow> get_cap thread_root_slot;\n     (case thread_root of\n        ArchObjectCap (PageTableCap pt VSRootPT_T (Some (asid, _))) \\<Rightarrow> doE\n          pt' \\<leftarrow> find_vspace_for_asid asid;\n          whenE (pt \\<noteq> pt') $ throwError InvalidRoot;\n          liftE $ arm_context_switch pt asid\n        odE\n      | _ \\<Rightarrow> throwError InvalidRoot) <catch> (\\<lambda>_. set_global_user_vspace)\n  od\"\n\n\ndefinition delete_asid_pool :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"delete_asid_pool base ptr \\<equiv> do\n     assert (asid_low_bits_of base = 0);\n     asid_table \\<leftarrow> gets asid_table;\n     when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n       pool \\<leftarrow> get_asid_pool ptr;\n       mapM (\\<lambda>offset. when (pool (ucast offset) \\<noteq> None) $ do\n                            invalidate_tlb_by_asid $ base + offset;\n                            invalidate_asid_entry $ base + offset\n                      od) [0  .e.  mask asid_low_bits];\n       asid_table' \\<leftarrow> return $ asid_table (asid_high_bits_of base:= None);\n       modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>);\n       tcb \\<leftarrow> gets cur_thread;\n       set_vm_root tcb\n     od\n   od\"\n\n\ndefinition delete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"delete_asid asid pt \\<equiv> do\n     pool_ptr_op \\<leftarrow> gets (pool_for_asid asid);\n     case pool_ptr_op of\n       None \\<Rightarrow> return ()\n     | Some pool_ptr \\<Rightarrow> do\n         pool \\<leftarrow> get_asid_pool pool_ptr;\n         when (\\<exists>vmid. pool (asid_low_bits_of asid) = Some (ASIDPoolVSpace vmid pt)) $ do\n           invalidate_tlb_by_asid asid;\n           invalidate_asid_entry asid;\n           \\<comment> \\<open>re-read here, because @{text invalidate_asid_entry} changes the ASID pool:\\<close>\n           pool \\<leftarrow> get_asid_pool pool_ptr;\n           pool' \\<leftarrow> return $ pool (asid_low_bits_of asid := None);\n           set_asid_pool pool_ptr pool';\n           tcb \\<leftarrow> gets cur_thread;\n           set_vm_root tcb\n         od\n       od\n   od\"\n\n\ndefinition unmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"unmap_page_table asid vaddr pt \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     (pt_slot, level) \\<leftarrow> pt_lookup_from_level max_pt_level top_level_pt vaddr pt;\n     liftE $ store_pte (level_type level) pt_slot InvalidPTE;\n     liftE $ do_machine_op $ cleanByVA_PoU pt_slot (addrFromPPtr pt_slot);\n     liftE $ invalidate_tlb_by_asid asid\n   odE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Memory Lookup: Perform a lookup in the page table for a given ASID and virtual space reference down to a specified level, returning the level and corresponding object reference. If the lookup reaches the bottom level or encounters a page or invalid entry, it terminates early.",
    "input": "",
    "output": "definition vs_lookup_table ::\n  \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"vs_lookup_table bot_level asid vptr \\<equiv> do {\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     if bot_level = asid_pool_level\n     then oreturn (asid_pool_level, pool_ptr)\n     else do {\n       top_level_pt \\<leftarrow> vspace_for_pool pool_ptr asid \\<circ> asid_pools_of;\n       pt_walk max_pt_level bot_level top_level_pt vptr \\<circ> ptes_of\n     }\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Lookup Slot: Retrieve a pointer to a slot in the virtual space table at the specified level. If the lookup reaches the ASID pool level, return the pointer to the ASID pool itself, otherwise, return the pointer to the specific slot within the table.",
    "input": "",
    "output": "definition vs_lookup_slot ::\n  \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"vs_lookup_slot bot_level asid vref \\<equiv> do {\n     (level', table) \\<leftarrow> vs_lookup_table bot_level asid vref;\n     if level' = asid_pool_level then\n       oreturn (level', table)\n     else\n       oreturn (level', pt_slot_offset level' table vref)\n   }\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page: Unmaps a page from the virtual address space if the given mapping details are still current. This involves finding the top-level page table, locating the correct slot, validating the page table entry, and then invalidating the page table entry and cleaning the cache.",
    "input": "",
    "output": "definition unmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"unmap_page pgsz asid vptr pptr \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     (lev, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot top_level_pt vptr \\<circ> ptes_of;\n     unlessE (pt_bits_left lev = pageBitsForSize pgsz) $ throwError InvalidRoot;\n     pte \\<leftarrow> liftE $ get_pte lev slot;\n     unlessE (is_PagePTE pte \\<and> pptr_from_pte pte = pptr) $ throwError InvalidRoot;\n     liftE $ store_pte lev slot InvalidPTE;\n     liftE $ do_machine_op $ cleanByVA_PoU slot (addrFromPPtr slot);\n     liftE $ invalidate_tlb_by_asid_va asid vptr\n   odE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Derive Capabilities: Ensures that page table capabilities are only derived if they have an ASID and location assigned, preventing them from having multiple current ASIDs or being shared between address spaces. Other architecture-specific capabilities are derived without additional checks.",
    "input": "",
    "output": "definition arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\" where\n  \"arch_derive_cap c \\<equiv>\n     case c of\n       PageTableCap _ _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n     | PageTableCap _ _ None \\<Rightarrow> throwError IllegalOperation\n     | FrameCap r R sz dev mp \\<Rightarrow> returnOk $ ArchObjectCap (FrameCap r R sz dev None)\n     | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n     | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\n     | VCPUCap _ \\<Rightarrow> returnOk (ArchObjectCap c)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Update Cap Data: Ensures that no user-modifiable data is stored in AARCH64-specific capabilities, maintaining the integrity and security of the system.",
    "input": "",
    "output": "definition arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\" where\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Finalize AARCH64-Specific Capabilities: Perform specific actions to finalize AARCH64-specific capabilities, such as deleting ASID pools, unmapping page tables, and finalizing VCPUs. Upon finalization, the capabilities are converted to NullCap.",
    "input": "",
    "output": "definition arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\" where\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n     (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n       delete_asid_pool b ptr;\n       return (NullCap, NullCap)\n     od\n   | (PageTableCap ptr VSRootPT_T (Some (a, v)), True) \\<Rightarrow> do\n       delete_asid a ptr;\n       return (NullCap, NullCap)\n     od\n   | (PageTableCap ptr NormalPT_T (Some (a, v)), True) \\<Rightarrow> do\n       unmap_page_table a v ptr;\n       return (NullCap, NullCap)\n     od\n   | (FrameCap ptr _ sz _ (Some (a, v)), _) \\<Rightarrow> do\n       unmap_page sz a v ptr;\n       return (NullCap, NullCap)\n     od\n   | (VCPUCap vcpu_ref, True) \\<Rightarrow> do\n      vcpu_finalise vcpu_ref;\n      return (NullCap, NullCap)\n     od\n   | _ \\<Rightarrow> return (NullCap, NullCap)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Address Space Validity: A virtual address space capability is valid if and only if it points to a mapped page table, ensuring the integrity and correctness of the virtual memory management on the AARCH64 architecture.",
    "input": "",
    "output": "definition is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv>\n     case c of ArchObjectCap (PageTableCap _ VSRootPT_T (Some _)) \\<Rightarrow> True | _ \\<Rightarrow> False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Valid IPC Buffer: Validate the alignment of the virtual pointer for an IPC buffer. If the virtual pointer is not aligned according to the specified `msg_align_bits`, an `AlignmentError` is thrown. For any other type of capability, an `IllegalOperation` error is thrown.",
    "input": "",
    "output": "lemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\ndefinition check_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_valid_ipc_buffer vptr c \\<equiv>\n     case c of\n       ArchObjectCap (FrameCap _ _ _ False _) \\<Rightarrow>\n         whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError\n     | _ \\<Rightarrow> throwError IllegalOperation\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Pointer in User Frame: A pointer is considered to be inside a user frame if its top bits correspond to a DataPage in the kernel heap. \n\nThread Deletion Preparation: Prepares a thread for deletion by removing its FPU state and dissociating its VCPU, if present, ensuring that all associated resources are properly cleaned up.",
    "input": "",
    "output": "definition in_user_frame :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n  \"in_user_frame p s \\<equiv>\n     \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) = Some (ArchObj (DataPage False sz))\"\n\ndefinition fpu_thread_delete :: \"obj_ref \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n  \"fpu_thread_delete thread_ptr \\<equiv> do_machine_op (fpuThreadDeleteOp thread_ptr)\"\n\ndefinition prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"prepare_thread_delete thread_ptr \\<equiv> do\n     fpu_thread_delete thread_ptr;\n     t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu thread_ptr;\n     case t_vcpu of\n       Some v \\<Rightarrow> dissociate_vcpu_tcb v thread_ptr\n     | None \\<Rightarrow> return ()\n   od\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Extract High ASID Bits: Extract the high bits of a virtual ASID to form an ASID high index, which is used for accessing the kernel heap.",
    "input": "",
    "output": "text \\<open>The high bits of a virtual ASID.\\<close>\ndefinition asid_high_bits_of :: \"asid \\<Rightarrow> asid_high_index\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Low Bits Extraction: Extract the low bits of a given ASID and convert them to an ASID low index.",
    "input": "",
    "output": "definition asid_low_bits_of :: \"asid \\<Rightarrow> asid_low_index\" where\n  \"asid_low_bits_of asid \\<equiv> ucast asid\"\n\nlemmas asid_bits_of_defs = asid_high_bits_of_def asid_low_bits_of_def\n\nlocale_abbrev asid_table :: \"'z::state_ext state \\<Rightarrow> asid_high_index \\<rightharpoonup> obj_ref\" where\n  \"asid_table \\<equiv> \\<lambda>s. arm_asid_table (arch_state s)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Accessing AARCH64 VSpace: Provides a mechanism to access and manipulate the architecture-specific kernel objects (aobjs) in the kernel heap, enabling the management and interaction with the virtual space.",
    "input": "",
    "output": "(* declared in Arch as workaround for VER-1099 *)\nlocale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\" where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Management: Manipulate ASID pools and page tables in the kernel heap, allowing for the retrieval and updating of ASID pools and page tables to maintain the virtual memory structure.",
    "input": "",
    "output": "locale_abbrev asid_pools_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> asid_pool\" where\n  \"asid_pools_of \\<equiv> \\<lambda>s. aobjs_of s |> asid_pool_of\"\n\nlocale_abbrev get_asid_pool :: \"obj_ref \\<Rightarrow> (asid_pool, 'z::state_ext) s_monad\" where\n  \"get_asid_pool \\<equiv> gets_map asid_pools_of\"\n\ndefinition set_asid_pool :: \"obj_ref \\<Rightarrow> asid_pool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_asid_pool ptr pool \\<equiv> do\n     get_asid_pool ptr;\n     set_object ptr (ArchObj (ASIDPool pool))\n   od\"\n\nlocale_abbrev pts_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> pt\" where\n  \"pts_of \\<equiv> \\<lambda>s. aobjs_of s |> pt_of\"\n\nlocale_abbrev get_pt :: \"obj_ref \\<Rightarrow> (pt,'z::state_ext) s_monad\" where\n  \"get_pt \\<equiv> gets_map pts_of\"\n\ndefinition set_pt :: \"obj_ref \\<Rightarrow> pt \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pt ptr pt \\<equiv> do\n     get_pt ptr;\n     set_object ptr (ArchObj (PageTable pt))\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Table Base Calculation: Compute the base address of the table that a page table entry at a given address belongs to, assuming proper alignment. This ensures that the correct table is accessed for further operations in the virtual address space.",
    "input": "",
    "output": "locale_abbrev table_base :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref\" where\n  \"table_base pt_t p \\<equiv> p && ~~mask (pt_bits pt_t)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Table Index Calculation: Compute the index within a page table that a given page table entry addresses, based on the provided address and the specified table type. This ensures accurate mapping and access to the relevant entries in the AARCH64 VSpace.",
    "input": "",
    "output": "locale_abbrev table_index :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> machine_word\" where\n  \"table_index pt_t p \\<equiv> p && mask (pt_bits pt_t) >> pte_bits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Apply Page Table: Access a specific entry in a page table using an index. The index is applied to either a normal page table or a virtual space root page table, with higher-order bits of the index being ignored.",
    "input": "",
    "output": "definition pt_apply :: \"pt \\<Rightarrow> machine_word \\<Rightarrow> pte\" where\n  \"pt_apply pt idx \\<equiv> case pt of NormalPT npt \\<Rightarrow> npt (ucast idx) | VSRootPT vs \\<Rightarrow> vs (ucast idx)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Extract Page Table Entry: Retrieve a specific PTE from the page table at a given level, ensuring that the provided address is properly aligned and the page table type matches.",
    "input": "",
    "output": "definition level_pte_of :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pt) \\<rightharpoonup> pte\" where\n  \"level_pte_of pt_t p \\<equiv> do {\n      oassert (is_aligned p pte_bits);\n      pt \\<leftarrow> oapply (table_base pt_t p);\n      oassert (pt_type pt = pt_t);\n      oreturn $ pt_apply pt (table_index pt_t p)\n   }\"\n\ntype_synonym ptes_of = \"pt_type \\<Rightarrow> obj_ref \\<rightharpoonup> pte\"\n\nlocale_abbrev ptes_of :: \"'z::state_ext state \\<Rightarrow> ptes_of\" where\n  \"ptes_of s pt_t p \\<equiv> level_pte_of pt_t p (pts_of s)\"\n\nlemmas ptes_of_def = level_pte_of_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Page Table Entry: Given a pointer to a PTE in kernel memory, the function retrieves and returns the corresponding page table entry.",
    "input": "",
    "output": "locale_abbrev get_pte :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte pt_t \\<equiv> gets_map (swp ptes_of pt_t)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Page Table Entries: Modify the page table entries in the virtual space by updating the specified index with a new page table entry. This ensures that the page table is correctly updated, maintaining the integrity of the virtual address space.",
    "input": "",
    "output": "definition pt_upd :: \"pt \\<Rightarrow> machine_word \\<Rightarrow> pte \\<Rightarrow> pt\" where\n  \"pt_upd pt idx pte \\<equiv> case pt of\n                         VSRootPT vs \\<Rightarrow> VSRootPT (vs(ucast idx := pte))\n                       | NormalPT pt \\<Rightarrow> NormalPT (pt(ucast idx := pte))\"\n\ndefinition store_pte :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte pt_t p pte \\<equiv> do\n     assert (is_aligned p pte_bits);\n     base \\<leftarrow> return $ table_base pt_t p;\n     pt \\<leftarrow> get_pt base;\n     assert (pt_type pt = pt_t);\n     set_pt base (pt_upd pt (table_index pt_t p) pte)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Index Calculation: Computes the index for a given virtual space reference at a specific page table level, using bitwise operations to extract the relevant bits based on the level and the virtual space reference.",
    "input": "",
    "output": "(* During pt_walk, we will only call this with level \\<le> max_pt_level, but in the invariants we\n   also make use of this function for level = asid_pool_level. *)\ndefinition pt_bits_left :: \"vm_level \\<Rightarrow> nat\" where\n  \"pt_bits_left level =\n    (if level = asid_pool_level\n     then ptTranslationBits VSRootPT_T + ptTranslationBits NormalPT_T * size max_pt_level\n     else ptTranslationBits NormalPT_T * size level)\n    + pageBits\"\n\ndefinition pt_index :: \"vm_level \\<Rightarrow> vspace_ref \\<Rightarrow> machine_word\" where\n  \"pt_index level vptr \\<equiv>\n     (vptr >> pt_bits_left level) && mask (ptTranslationBits level)\"\n\n\nlocale_abbrev global_pt :: \"'z state \\<Rightarrow> obj_ref\" where\n  \"global_pt s \\<equiv> arm_us_global_vspace (arch_state s)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access: Convert a page table entry (PTE) to a physical pointer and calculate the offset of a specific slot in a page table based on the virtual address, allowing for precise manipulation and access within the AARCH64 virtual address space.",
    "input": "",
    "output": "definition pptr_from_pte :: \"pte \\<Rightarrow> vspace_ref\" where\n  \"pptr_from_pte pte \\<equiv> ptrFromPAddr (pte_base_addr pte)\"\n\ndefinition pt_slot_offset :: \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\" where\n  \"pt_slot_offset level pt_ptr vptr = pt_ptr + (pt_index level vptr << pte_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Walk: Recursively traverses the page table structure from a specified level down to a base level or until a page is reached, returning the level and pointer of the final page table.",
    "input": "",
    "output": "fun pt_walk ::\n  \"vm_level \\<Rightarrow> vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> ptes_of \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"pt_walk level bot_level pt_ptr vptr = do {\n     if bot_level < level\n     then do {\n       pte \\<leftarrow> oapply2 (level_type level) (pt_slot_offset level pt_ptr vptr);\n       if is_PageTablePTE pte\n         then pt_walk (level - 1) bot_level (pptr_from_pte pte) vptr\n         else oreturn (level, pt_ptr)\n     }\n     else oreturn (level, pt_ptr)\n   }\"\n\ndeclare pt_walk.simps[simp del]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Slot Lookup: Retrieve a slot in the page table structure, returning the level and an object pointer to the slot. The slot is located at the returned level, and its type depends on the level, being either an InvalidPTE, PagePTE, or PageTablePTE.",
    "input": "",
    "output": "definition pt_lookup_slot_from_level ::\n  \"vm_level \\<Rightarrow> vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> ptes_of \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"pt_lookup_slot_from_level level bot_level pt_ptr vptr = do {\n     (level', pt_ptr') \\<leftarrow> pt_walk level bot_level pt_ptr vptr;\n     oreturn (level', pt_slot_offset level' pt_ptr' vptr)\n   }\"\n\ndefinition pt_lookup_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> ptes_of \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"pt_lookup_slot = pt_lookup_slot_from_level max_pt_level 0\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Lookup: Recursively searches the page table hierarchy starting from a specified level, using the provided virtual address to find the slot that points to the target page table pointer. Ensures that the search is valid by checking the level and verifying that each PTE encountered is a valid page table entry.",
    "input": "",
    "output": "fun pt_lookup_from_level ::\n  \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (machine_word \\<times> vm_level, 'z::state_ext) lf_monad\"\n  where\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr s = (doE\n     unlessE (0 < level) $ throwError InvalidRoot;\n     slot <- returnOk $ pt_slot_offset level pt_ptr vptr;\n     pte <- liftE $ gets_the $ oapply slot o swp ptes_of level;\n     unlessE (is_PageTablePTE pte) $ throwError InvalidRoot;\n     ptr <- returnOk (pptr_from_pte pte);\n     if ptr = target_pt_ptr\n       then returnOk (slot, level)\n       else pt_lookup_from_level (level - 1) ptr vptr target_pt_ptr\n   odE) s\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VSpace Access: Perform basic operations on the AARCH64 VSpace, including managing the global free index counter to avoid type variable warnings.",
    "input": "",
    "output": "declare pt_lookup_from_level.simps[simp del]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Lookup from Level: Provides a simplified rule for looking up a page table entry at a specified level, given a page table pointer, virtual address, and target page table pointer.",
    "input": "",
    "output": "schematic_goal pt_lookup_from_level_simps:\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr = ?rhs\"\n  by (rule ext, rule pt_lookup_from_level.simps)\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Virtual Page Alignment: Ensure that the virtual page address is properly aligned for the given page size, throwing an alignment error if the condition is not met.",
    "input": "",
    "output": "definition check_vp_alignment :: \"vmpage_size \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $ throwError AlignmentError\"\n\ndefinition page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\" where\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-specific System Call Decoding: Decodes architecture-specific system calls by interpreting the invocation label and arguments, validating the provided capabilities, and performing the corresponding actions such as managing IRQs, mapping and unmapping pages, flushing memory, and controlling ASID pools. This ensures that the system calls are correctly interpreted and executed, maintaining the integrity and security of the system.",
    "input": "",
    "output": "definition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n     (if invocation_type label = ArchInvocationLabel ARMIRQIssueIRQHandlerTrigger\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n          returnOk $ ARMIRQControlInvocation irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\ndefinition attribs_from_word :: \"machine_word \\<Rightarrow> vm_attributes\" where\n  \"attribs_from_word w \\<equiv> {attr.  \\<not>w!!0 \\<and> attr = Device \\<or> \\<not>w !! 2 \\<and> attr = Execute}\"\n\ndefinition make_user_pte :: \"paddr \\<Rightarrow> vm_attributes \\<Rightarrow> vm_rights \\<Rightarrow> vmpage_size \\<Rightarrow> pte\" where\n  \"make_user_pte addr attr rights vm_size \\<equiv>\n     PagePTE addr (vm_size = ARMSmallPage) (attr - {Global}) rights\"\n\ndefinition check_vspace_root :: \"cap \\<Rightarrow> nat \\<Rightarrow> (obj_ref \\<times> asid, 'z) se_monad\" where\n  \"check_vspace_root cap arg_no \\<equiv>\n     case cap of\n       ArchObjectCap (PageTableCap pt VSRootPT_T (Some (asid, _))) \\<Rightarrow> returnOk (pt, asid)\n     | _ \\<Rightarrow> throwError $ InvalidCapability arg_no\"\n\ntype_synonym 'z arch_decoder =\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    (arch_invocation,'z) se_monad\"\n\ndefinition decode_fr_inv_map :: \"'z::state_ext arch_decoder\" where\n  \"decode_fr_inv_map label args cte cap extra_caps \\<equiv> case cap of\n     FrameCap p R pgsz dev mapped_address \\<Rightarrow>\n       if length args > 2 \\<and> length extra_caps > 0\n       then let\n           vaddr = args ! 0;\n           rights_mask = args ! 1;\n           attr = args ! 2;\n           vspace_cap = fst (extra_caps ! 0)\n         in doE\n           (pt, asid) \\<leftarrow> check_vspace_root vspace_cap 1;\n           pt' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n           whenE (pt' \\<noteq> pt) $ throwError $ InvalidCapability 1;\n           check_vp_alignment pgsz vaddr;\n           pg_bits \\<leftarrow> returnOk $ pageBitsForSize pgsz;\n           case mapped_address of\n             Some (asid', vaddr') \\<Rightarrow> doE\n               whenE (asid' \\<noteq> asid) $ throwError $ InvalidCapability 1;\n               whenE (vaddr' \\<noteq> vaddr) $ throwError $ InvalidArgument 0\n             odE\n           | None \\<Rightarrow> doE\n               vtop \\<leftarrow> returnOk $ vaddr + mask (pageBitsForSize pgsz);\n               whenE (vtop > user_vtop) $ throwError $ InvalidArgument 0\n             odE;\n           (level, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot pt vaddr \\<circ> ptes_of;\n           unlessE (pt_bits_left level = pg_bits) $\n             throwError $ FailedLookup False $ MissingCapability $ pt_bits_left level;\n           vm_rights \\<leftarrow> returnOk $ mask_vm_rights R (data_to_rights rights_mask);\n           attribs \\<leftarrow> returnOk $ attribs_from_word attr;\n           pte \\<leftarrow> returnOk $ make_user_pte (addrFromPPtr p) attribs vm_rights pgsz;\n           returnOk $ InvokePage $ PageMap (FrameCap p R pgsz dev (Some (asid,vaddr))) cte\n                                           (pte,slot,level)\n         odE\n       else throwError TruncatedMessage\n     | _ \\<Rightarrow> fail\"\n\ndefinition label_to_flush_type :: \"data \\<Rightarrow> flush_type\" where\n  \"label_to_flush_type label \\<equiv>\n     case invocation_type label of\n       ArchInvocationLabel ARMVSpaceClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPageClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMVSpaceInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPageInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMVSpaceCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPageCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMVSpaceUnify_Instruction \\<Rightarrow> Unify\n     | ArchInvocationLabel ARMPageUnify_Instruction \\<Rightarrow> Unify\"\n\ndefinition decode_fr_inv_flush :: \"'z::state_ext arch_decoder\" where\n  \"decode_fr_inv_flush label args cte cap extra_caps \\<equiv> case cap of\n     FrameCap p R pgsz dev mapped_address \\<Rightarrow>\n        if length args > 1\n        then let\n          start = args ! 0;\n          end = args ! 1\n        in doE\n          (asid, vaddr) \\<leftarrow> case mapped_address of\n                             Some a \\<Rightarrow> returnOk a\n                           | _ \\<Rightarrow> throwError IllegalOperation;\n          vspace \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n          whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n          page_size \\<leftarrow> returnOk $ 1 << pageBitsForSize pgsz;\n          whenE (start \\<ge> page_size \\<or> end > page_size) $ throwError $ InvalidArgument 0;\n          pstart \\<leftarrow> returnOk $ addrFromPPtr p + start;\n          \\<comment> \\<open>flush only inside the kernel window:\\<close>\n          whenE (pstart < paddrBase \\<or> ((end - start) + pstart > paddrTop)) $\n            throwError IllegalOperation;\n          returnOk $ InvokePage $\n            PageFlush (label_to_flush_type label)\n                      (vaddr + start) (vaddr + end - 1)\n                      pstart vspace asid\n        odE\n        else throwError TruncatedMessage\n   | _ \\<Rightarrow> fail\"\n\n\ndefinition decode_frame_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_frame_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel ARMPageMap\n     then decode_fr_inv_map label args cte cap extra_caps\n     else if invocation_type label = ArchInvocationLabel ARMPageUnmap\n     then returnOk $ InvokePage $ PageUnmap cap cte\n     else if invocation_type label = ArchInvocationLabel ARMPageGetAddress\n     then returnOk $ InvokePage $ PageGetAddr (acap_obj cap)\n     else if isPageFlushLabel (invocation_type label)\n     then decode_fr_inv_flush label args cte cap extra_caps\n     else throwError IllegalOperation\"\n\ndefinition decode_pt_inv_map :: \"'z::state_ext arch_decoder\" where\n  \"decode_pt_inv_map label args cte cap extra_caps \\<equiv> case cap of\n     PageTableCap p t mapped_address \\<Rightarrow>\n       if length args > 1 \\<and> length extra_caps > 0\n       then let\n           vaddr = args ! 0;\n           attr = args ! 1;\n           vspace_cap = fst (extra_caps ! 0)\n         in doE\n           whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n           (pt, asid) \\<leftarrow> check_vspace_root vspace_cap 1;\n           whenE (user_vtop < vaddr) $ throwError $ InvalidArgument 0;\n           pt' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n           whenE (pt' \\<noteq> pt) $ throwError $ InvalidCapability 1;\n           (level, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot pt vaddr \\<circ> ptes_of;\n           old_pte \\<leftarrow> liftE $ get_pte (level_type level) slot;\n           whenE (pt_bits_left level = pageBits \\<or> old_pte \\<noteq> InvalidPTE) $ throwError DeleteFirst;\n           pte \\<leftarrow> returnOk $ PageTablePTE (ppn_from_pptr p);\n           cap' <- returnOk $ PageTableCap p t $ Some (asid, vaddr && ~~mask (pt_bits_left level));\n           returnOk $ InvokePageTable $ PageTableMap cap' cte pte slot level\n         odE\n       else throwError TruncatedMessage\n     | _ \\<Rightarrow> fail\"\n\ndefinition decode_page_table_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_page_table_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel ARMPageTableMap\n     then decode_pt_inv_map label args cte cap extra_caps\n     else if invocation_type label = ArchInvocationLabel ARMPageTableUnmap\n     then doE\n       final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n       unlessE final $ throwError RevokeFirst;\n       returnOk $ InvokePageTable $ PageTableUnmap cap cte\n     odE\n     else throwError IllegalOperation\"\n\ndefinition level_of_vmsize :: \"vmpage_size \\<Rightarrow> vm_level\" where\n  \"level_of_vmsize vmsz \\<equiv>\n     case vmsz of\n       ARMSmallPage \\<Rightarrow> 0\n     | ARMLargePage \\<Rightarrow> 1\n     | ARMHugePage \\<Rightarrow> 2\"\n\ndefinition vmsize_of_level :: \"vm_level \\<Rightarrow> vmpage_size\" where\n  \"vmsize_of_level level \\<equiv>\n     if level = 0 then ARMSmallPage\n     else if level = 1 then ARMLargePage\n     else ARMHugePage\"\n\ndefinition lookup_frame :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> ptes_of \\<Rightarrow> (vmpage_size \\<times> paddr) option\" where\n  \"lookup_frame vspace vaddr = do {\n     (level, slot) \\<leftarrow> pt_lookup_slot vspace vaddr;\n     pte \\<leftarrow> oapply2 (level_type level) slot;\n     oassert (is_PagePTE pte);\n     oassert (level \\<le> 2);\n     oreturn (vmsize_of_level level, pte_base_addr pte)\n   }\"\n\ndefinition decode_vs_inv_flush :: \"'z::state_ext arch_decoder\" where\n  \"decode_vs_inv_flush label args cte cap extra_caps \\<equiv> case cap of\n     PageTableCap p VSRootPT_T mapped_address \\<Rightarrow>\n        if length args > 1\n        then let\n          start = args ! 0;\n          end = args ! 1\n        in doE\n          whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n          whenE (end > pptrUserTop) $ throwError $ IllegalOperation;\n          (vspace, asid) \\<leftarrow> check_vspace_root (ArchObjectCap cap) 0;\n          vspace' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n          whenE (vspace' \\<noteq> vspace) $ throwError $ InvalidCapability 0;\n          frame_info \\<leftarrow> liftE $ gets $ lookup_frame p start \\<circ> ptes_of;\n          case frame_info of\n            None \\<Rightarrow> returnOk $ InvokeVSpace VSpaceNothing\n          | Some (pgsz, paddr) \\<Rightarrow> doE\n              bits_left  \\<leftarrow> returnOk $ pt_bits_left (level_of_vmsize pgsz);\n              base_start \\<leftarrow> returnOk $ page_base start pgsz;\n              base_end \\<leftarrow> returnOk $ page_base (end - 1) pgsz;\n              whenE (base_start \\<noteq> base_end) $\n                throwError $ RangeError start (base_start + mask bits_left);\n              pstart \\<leftarrow> returnOk $ paddr + (start && mask bits_left);\n              returnOk $ InvokeVSpace $\n                VSpaceFlush (label_to_flush_type label) start (end - 1) pstart vspace asid\n            odE\n        odE\n        else throwError TruncatedMessage\n   | _ \\<Rightarrow> fail\"\n\ndefinition decode_vspace_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_vspace_invocation label args cte cap extra_caps \\<equiv>\n     if isVSpaceFlushLabel (invocation_type label)\n     then decode_vs_inv_flush label args cte cap extra_caps\n     else throwError IllegalOperation\"\n\ndefinition decode_asid_control_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_asid_control_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel ARMASIDControlMakePool\n     then if length args > 1 \\<and> length extra_caps > 1\n     then let\n         index = args ! 0;\n         depth = args ! 1;\n         (untyped, parent_slot) = extra_caps ! 0;\n         root = fst (extra_caps ! 1)\n       in doE\n         asid_table \\<leftarrow> liftE $ gets asid_table;\n         free_set \\<leftarrow> returnOk (- dom asid_table);\n         whenE (free_set = {}) $ throwError DeleteFirst;\n         free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n         base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n         (p,n) \\<leftarrow> case untyped of\n                    UntypedCap False p n _ \\<Rightarrow> returnOk (p,n)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 1;\n         frame \\<leftarrow> if n = pageBits then doE\n                    ensure_no_children parent_slot;\n                    returnOk p\n                  odE\n                  else throwError $ InvalidCapability 1;\n         dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n         ensure_empty dest_slot;\n         returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n       odE\n     else throwError TruncatedMessage\n     else throwError IllegalOperation\"\n\ndefinition decode_asid_pool_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_asid_pool_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel ARMASIDPoolAssign\n     then if length extra_caps > 0\n     then let\n         (pt_cap, pt_cap_slot) = extra_caps ! 0;\n         p = acap_obj cap;\n         base = acap_asid_base cap\n       in case pt_cap of\n         ArchObjectCap (PageTableCap _ VSRootPT_T None) \\<Rightarrow> doE\n           asid_table \\<leftarrow> liftE $ gets asid_table;\n           pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n           whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n           whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n           pool \\<leftarrow> liftE $ get_asid_pool p;\n           free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n           whenE (free_set = {}) $ throwError DeleteFirst;\n           offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n           returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pt_cap_slot\n         odE\n       | _ \\<Rightarrow> throwError $ InvalidCapability 1\n     else throwError TruncatedMessage\n     else throwError IllegalOperation\"\n\ndefinition arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n     PageTableCap _ VSRootPT_T _ \\<Rightarrow> decode_vspace_invocation label args cte cap extra_caps\n   | PageTableCap _ NormalPT_T _ \\<Rightarrow> decode_page_table_invocation label args cte cap extra_caps\n   | FrameCap _ _ _ _ _        \\<Rightarrow> decode_frame_invocation label args cte cap extra_caps\n   | ASIDControlCap            \\<Rightarrow> decode_asid_control_invocation label args cte cap extra_caps\n   | ASIDPoolCap _ _           \\<Rightarrow> decode_asid_pool_invocation label args cte cap extra_caps\n   | VCPUCap _                 \\<Rightarrow> decode_vcpu_invocation label args cap extra_caps\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Data to Object Type Mapping: Convert a numerical value to a corresponding architecture-specific object type, such as HugePage, VSpace, SmallPage, LargePage, PageTable, or VCPU. If the numerical value does not match any of these, it returns None.",
    "input": "",
    "output": "definition arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n  \"arch_data_to_obj_type n \\<equiv>\n     if      n = 0 then Some HugePageObj\n     else if n = 1 then Some VSpaceObj\n     else if n = 2 then Some SmallPageObj\n     else if n = 3 then Some LargePageObj\n     else if n = 4 then Some PageTableObj\n     else if n = 5 then Some VCPUObj\n     else None\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU State Management: Retrieve and update the VCPU state associated with a given object reference. This ensures that the VCPU-related state and registers can be manipulated effectively, maintaining the integrity and performance of the system.",
    "input": "",
    "output": "locale_abbrev vcpus_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> vcpu\" where\n  \"vcpus_of \\<equiv> \\<lambda>s. aobjs_of s |> vcpu_of\"\n\ndefinition get_vcpu :: \"obj_ref \\<Rightarrow> (vcpu,'z::state_ext) s_monad\" where\n  \"get_vcpu \\<equiv> gets_map vcpus_of\"\n\ndefinition set_vcpu :: \"obj_ref \\<Rightarrow> vcpu \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_vcpu ptr vcpu \\<equiv> set_object ptr (ArchObj (VCPU vcpu))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU State and Register Manipulation: Provides functions to update, save, and restore VCPU-related state and registers. This includes updating the VCPU and VGIC state, saving and restoring individual or ranges of VCPU registers, and managing the virtual timer by saving and restoring its control and counter values. These operations ensure that the VCPU's state is accurately maintained and can be effectively managed during context switches and other critical operations.",
    "input": "",
    "output": "definition vcpu_update :: \"obj_ref \\<Rightarrow> (vcpu \\<Rightarrow> vcpu) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_update vr f \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    set_vcpu vr (f vcpu)\n  od\"\n\ndefinition vgic_update ::\n  \"obj_ref \\<Rightarrow> (gic_vcpu_interface \\<Rightarrow> gic_vcpu_interface) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vgic_update vr f \\<equiv> vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_vgic := f (vcpu_vgic vcpu) \\<rparr> )\"\n\ndefinition vgic_update_lr :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vgic_update_lr vr irq_idx virq \\<equiv>\n    vgic_update vr (\\<lambda>vgic. vgic \\<lparr> vgic_lr := (vgic_lr vgic)(irq_idx := virq) \\<rparr>)\"\n\ndefinition vcpu_save_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_save_reg vr reg \\<equiv> do\n    rval \\<leftarrow> do_machine_op (readVCPUHardwareReg reg);\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := rval) \\<rparr> )\n  od\"\n\ndefinition vcpu_save_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_save_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_save_reg vr reg) [from .e. to]\"\n\ndefinition vcpu_restore_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_restore_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    do_machine_op (writeVCPUHardwareReg reg (vcpu_regs vcpu reg))\n  od\"\n\ndefinition vcpu_restore_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"vcpu_restore_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_restore_reg vr reg) [from .e. to]\"\n\ndefinition vcpu_read_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word, 'z::state_ext) s_monad\" where\n  \"vcpu_read_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    return (vcpu_regs vcpu reg)\n  od\"\n\ndefinition vcpu_write_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"vcpu_write_reg vr reg val \\<equiv>\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := val) \\<rparr> )\"\n\ndefinition save_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"save_virt_timer vcpu_ptr \\<equiv> do\n     vcpu_save_reg vcpu_ptr VCPURegCNTV_CTL;\n     do_machine_op $ writeVCPUHardwareReg VCPURegCNTV_CTL 0;\n     vcpu_save_reg vcpu_ptr VCPURegCNTV_CVAL;\n     vcpu_save_reg vcpu_ptr VCPURegCNTVOFF;\n     vcpu_save_reg vcpu_ptr VCPURegCNTKCTL_EL1;\n     do_machine_op check_export_arch_timer;\n     cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu_update vcpu_ptr (\\<lambda>vcpu. vcpu\\<lparr>vcpu_vtimer := VirtTimer cntpct \\<rparr>)\n   od\"\n\ndefinition irq_vppi_event_index :: \"irq \\<rightharpoonup> vppievent_irq\" where\n  \"irq_vppi_event_index irq \\<equiv>\n     if irq = irqVTimerEvent\n     then Some VPPIEventIRQ_VTimer\n     else None\"\n\ndefinition restore_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"restore_virt_timer vcpu_ptr \\<equiv> do\n     vcpu_restore_reg vcpu_ptr VCPURegCNTV_CVAL;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTKCTL_EL1;\n     current_cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu \\<leftarrow> get_vcpu vcpu_ptr;\n     last_pcount \\<leftarrow> return $ vtimerLastPCount $ vcpu_vtimer vcpu;\n     delta \\<leftarrow> return $ current_cntpct - last_pcount;\n     cntvoff \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTVOFF;\n     offset \\<leftarrow> return $ cntvoff + ucast delta;\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFF offset;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTVOFF;\n     \\<comment> \\<open>read again, so we don't have to reason about @{const vcpu_write_reg} changes in CRefine\\<close>\n     vcpu \\<leftarrow> get_vcpu vcpu_ptr;\n     masked \\<leftarrow> return $ (vcpu_vppi_masked vcpu (the $ irq_vppi_event_index irqVTimerEvent));\n     \\<comment> \\<open>we do not know here that irqVTimerEvent is IRQReserved, therefore not IRQInactive,\n        so the only way to prove we don't unmask an inactive interrupt is to check\\<close>\n     safe_to_unmask \\<leftarrow> is_irq_active irqVTimerEvent;\n     when safe_to_unmask $ do_machine_op $ maskInterrupt masked irqVTimerEvent;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTV_CTL\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Disable: Disables the VCPU mode on the hardware level by turning off the VGIC, saving relevant VCPU registers, and adjusting system control settings to ensure proper state transition. This includes saving the SCTLR and CPACR registers, disabling the S1 MMU, setting the HCR to native mode, enabling FPU instructions in EL0 and EL1, and masking the virtual timer interrupt.",
    "input": "",
    "output": "definition vcpu_disable :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_disable vo \\<equiv> do\n    do_machine_op dsb;\n    case vo of\n      Some vr \\<Rightarrow> do\n        hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n        vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n        vcpu_save_reg vr VCPURegSCTLR;\n        vcpu_save_reg vr VCPURegCPACR; \\<comment> \\<open>since FPU enabled\\<close>\n        do_machine_op isb\n      od\n    | _ \\<Rightarrow> return ();\n    do_machine_op $ do\n        set_gic_vcpu_ctrl_hcr 0; \\<comment> \\<open>turn VGIC off\\<close>\n        isb;\n        setSCTLR sctlrDefault; \\<comment> \\<open>turn S1 MMU off\\<close>\n        isb;\n        setHCR hcrNative;\n        isb;\n        \\<comment> \\<open>allow FPU instructions in EL0 and EL1 for native threads\\<close>\n        enableFpuEL01\n      od;\n    case vo of\n      Some vr \\<Rightarrow> do\n          save_virt_timer vr;\n          do_machine_op $ maskInterrupt True irqVTimerEvent\n        od\n    | _ \\<Rightarrow> return ()\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Enable VCPU Mode: Activate the VCPU mode on the hardware level by restoring specific VCPU registers, setting the HCR (Hypervisor Configuration Register) to enable VCPU, and configuring the GIC (Generic Interrupt Controller) for VCPU operation. This ensures that the VCPU is properly initialized and ready for virtualized execution.",
    "input": "",
    "output": "definition vcpu_enable :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_enable vr \\<equiv> do\n     vcpu_restore_reg vr VCPURegSCTLR;\n     vcpu \\<leftarrow> get_vcpu vr;\n     do_machine_op $ do\n        setHCR hcrVCPU;\n        isb;\n        set_gic_vcpu_ctrl_hcr (vgic_hcr $ vcpu_vgic vcpu)\n     od;\n     vcpu_restore_reg vr VCPURegCPACR; \\<comment> \\<open>FPU\\<close>\n     restore_virt_timer vr\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Invalidation: Invalidate the active VCPU by disabling it and updating the system state to remove the current VCPU reference. This ensures that the VCPU is properly prepared for removal, maintaining the integrity of the system's virtualization state.",
    "input": "",
    "output": "definition vcpu_invalidate_active :: \"(unit,'z::state_ext) s_monad\" where\n  \"vcpu_invalidate_active \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    case cur_v of\n      Some (vr, True) \\<Rightarrow> vcpu_disable None\n    | _ \\<Rightarrow> return ();\n    modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := None \\<rparr>\\<rparr>)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU State and Register Save: Saves the state and registers of a VCPU, including SCTLR, HCR, VMCR, APR, and GIC list registers, and updates the VGIC state. The function ensures that the VCPU's context is properly saved, maintaining the integrity of the virtualized environment.",
    "input": "",
    "output": "definition vcpu_save :: \"(obj_ref \\<times> bool) option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_save vb \\<equiv>\n     case vb\n     of Some (vr, active) \\<Rightarrow> do\n          do_machine_op dsb;\n\n          when active $ do\n            vcpu_save_reg vr VCPURegSCTLR;\n            hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n            vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n            save_virt_timer vr\n          od;\n\n          vmcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_vmcr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_vmcr := vmcr\\<rparr>);\n\n          apr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_apr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_apr := apr\\<rparr>);\n\n          num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n          gicIndices \\<leftarrow> return [0..<num_list_regs];\n\n          mapM (\\<lambda>vreg. do\n                    val \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat vreg);\n                    vgic_update_lr vr vreg val\n                  od)\n            gicIndices;\n\n          \\<comment> \\<open>armvVCPUSave\\<close>\n          vcpu_save_reg_range vr VCPURegTTBR0 VCPURegSPSR_EL1\n       od\n     | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Restore: Restores the state and registers of a VCPU, including turning off the VGIC, restoring GIC VCPU control state, setting specific GIC VCPU control registers, and restoring banked VCPU registers. The process ensures that the VCPU is correctly reinitialized and ready for execution.",
    "input": "",
    "output": "definition vcpu_restore :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_restore vr \\<equiv> do\n     do_machine_op $ set_gic_vcpu_ctrl_hcr 0;  \\<comment> \\<open>turn off VGIC\\<close>\n     do_machine_op $ isb;\n     vcpu \\<leftarrow> get_vcpu vr;  \\<comment> \\<open>restore GIC VCPU control state\\<close>\n     vgic \\<leftarrow> return (vcpu_vgic vcpu);\n     num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     gicIndices \\<leftarrow> return [0..<num_list_regs];\n     do_machine_op $ do\n         set_gic_vcpu_ctrl_vmcr (vgic_vmcr vgic);\n         set_gic_vcpu_ctrl_apr (vgic_apr vgic);\n         mapM (\\<lambda>p. set_gic_vcpu_ctrl_lr (of_nat (fst p)) (snd p))\n              (map (\\<lambda>i. (i, (vgic_lr vgic) i)) gicIndices)\n     od;\n    \\<comment> \\<open>restore banked VCPU registers except SCTLR (that's in VCPUEnable)\\<close>\n     vcpu_restore_reg_range vr VCPURegTTBR0 VCPURegSPSR_EL1;\n     vcpu_enable vr\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Switching: Manages the activation and deactivation of a VCPU. If a new VCPU is specified, it saves the state of the current VCPU (if active) and restores the state of the new VCPU, marking it as active. If no VCPU is specified, it deactivates the current VCPU and disables VCPU mode, preserving the state for potential future reactivation.",
    "input": "",
    "output": "definition vcpu_switch :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_switch v \\<equiv> case v of\n     None \\<Rightarrow> do\n       cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n       (case cur_v of\n          None \\<Rightarrow> return () \\<comment> \\<open>both null, current cannot be active\\<close>\n        | Some (vr, active) \\<Rightarrow> do \\<comment> \\<open>switch to thread without vcpu\\<close>\n            when active $ do  \\<comment> \\<open> save state if not saved already\\<close>\n              vcpu_disable (Some vr);\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (vr, False) \\<rparr>\\<rparr>)\n            od;\n            return ()\n          od)\n       od\n   | Some new \\<Rightarrow> do\n       cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n       (case cur_v of\n          None \\<Rightarrow> do \\<comment> \\<open>switch to the new vcpu with no current one\\<close>\n            vcpu_restore new;\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n          od\n        | Some (vr, active) \\<Rightarrow> \\<comment> \\<open>switch from an existing vcpu\\<close>\n            (if vr \\<noteq> new\n            then do \\<comment> \\<open>different vcpu\\<close>\n              vcpu_save cur_v;\n              vcpu_restore new;\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n            od\n            else \\<comment> \\<open>same vcpu\\<close>\n              when (\\<not> active) $ do\n                do_machine_op isb;\n                vcpu_enable new;\n                modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n              od))\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Dissociate VCPU and TCB: Safely remove the association between a VCPU and a TCB, ensuring that they were previously associated. Invalidate the active VCPU if it is the one being dissociated, update the TCB to remove the VCPU reference, and sanitize the SPSR_EL1 register of the TCB.",
    "input": "",
    "output": "definition dissociate_vcpu_tcb :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"dissociate_vcpu_tcb vr t \\<equiv> do\n     t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n     v \\<leftarrow> get_vcpu vr;\n     assert (t_vcpu = Some vr \\<and> vcpu_tcb v = Some t); \\<comment> \\<open>make sure they were associated\\<close>\n     cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     when (\\<exists>a. cur_v = Some (vr,a)) vcpu_invalidate_active;\n     arch_thread_set (\\<lambda>x. x \\<lparr> tcb_vcpu := None \\<rparr>) t;\n     set_vcpu vr (v\\<lparr> vcpu_tcb := None \\<rparr>);\n     as_user t $ do\n       sr \\<leftarrow> getRegister SPSR_EL1;\n       setRegister SPSR_EL1 $ sanitise_register False SPSR_EL1 sr\n     od\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Associate VCPU and TCB: Ensures a VCPU is associated with a TCB, removing any existing associations. If the TCB or VCPU is already associated, it first dissociates them before establishing the new association. If the TCB being associated is the current thread, it performs a VCPU switch to the new VCPU.",
    "input": "",
    "output": "definition associate_vcpu_tcb :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"associate_vcpu_tcb vcpu_ptr t \\<equiv> do\n     t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n     case t_vcpu of\n       Some p \\<Rightarrow> dissociate_vcpu_tcb p t\n     | _ \\<Rightarrow> return ();\n     v \\<leftarrow> get_vcpu vcpu_ptr;\n     case vcpu_tcb v of\n       Some p \\<Rightarrow> dissociate_vcpu_tcb vcpu_ptr p\n     | _ \\<Rightarrow> return ();\n     arch_thread_set (\\<lambda>x. x \\<lparr> tcb_vcpu := Some vcpu_ptr \\<rparr>) t;\n     set_vcpu vcpu_ptr (v\\<lparr> vcpu_tcb := Some t \\<rparr>);\n     ct \\<leftarrow> gets cur_thread;\n     when (t = ct) $ vcpu_switch (Some vcpu_ptr)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Finalization: Prepare a VCPU for removal by dissociating it from its associated TCB and cleaning up the current VCPU state.",
    "input": "",
    "output": "definition vcpu_finalise :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_finalise vr \\<equiv> do\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of\n      Some t \\<Rightarrow> dissociate_vcpu_tcb vr t\n    | None \\<Rightarrow> return ()\n   od\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocation Types: Define the various AARCH64-specific system call arguments, including operations for managing virtual space, page tables, ASID pools, pages, and VCPUs. These datatypes provide a structured way to handle different types of architectural invocations, ensuring that the system can perform specific actions such as flushing virtual spaces, mapping and unmapping page tables, assigning ASIDs, and controlling VCPUs.",
    "input": "",
    "output": "datatype vspace_invocation =\n    VSpaceNothing\n  | VSpaceFlush\n      (vs_flush_type : flush_type)\n      (vs_flush_start : vspace_ref)\n      (vs_flush_end : vspace_ref)\n      (vs_flush_pstart : paddr)\n      (vs_flush_space : obj_ref)\n      (vs_flush_asid : asid)\n\ndatatype page_table_invocation =\n    PageTableMap\n      (pt_inv_cap : arch_cap)\n      (pt_inv_cslot : cslot_ptr)\n      (pt_map_pte : pte)\n      (pt_map_slot : obj_ref)\n      (pt_map_level : vm_level)\n  | PageTableUnmap\n      (pt_inv_cap : arch_cap)\n      (pt_inv_cslot : cslot_ptr)\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation =\n    PageMap\n      (pg_inv_cap : arch_cap)\n      (pg_inv_cslot : cslot_ptr)\n      (pg_inv_entries : \"pte \\<times> obj_ref \\<times> vm_level\")\n  | PageUnmap\n      (pg_inv_cap : arch_cap)\n      (pg_inv_cslot : cslot_ptr)\n  | PageGetAddr\n      (pg_get_paddr : obj_ref)\n  | PageFlush\n      (pg_flush_type : flush_type)\n      (pg_flush_start : vspace_ref)\n      (pg_flush_end : vspace_ref)\n      (pg_flush_pStart : paddr)\n      (pg_flush_space : obj_ref)\n      (pg_flush_asid : asid)\n\ndatatype vcpu_invocation =\n    VCPUSetTCB\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_tcb : obj_ref)\n  | VCPUInjectIRQ\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_idx : nat)\n      (vcpu_inv_irq : virq)\n  | VCPUReadRegister\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_reg : vcpureg)\n  | VCPUWriteRegister\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_reg : vcpureg)\n      (vcpu_inv_val : machine_word)\n  | VCPUAckVPPI\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_eirq : vppievent_irq)\n\ndatatype arch_invocation =\n    InvokeVSpace vspace_invocation\n  | InvokePageTable page_table_invocation\n  | InvokePage page_invocation\n  | InvokeASIDControl asid_control_invocation\n  | InvokeASIDPool asid_pool_invocation\n  | InvokeVCPU vcpu_invocation\n\ndatatype arch_copy_register_sets =\n    ARMNoExtraRegisters\n\ndefinition ArchDefaultExtraRegisters :: arch_copy_register_sets where\n  \"ArchDefaultExtraRegisters = ARMNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    ARMIRQControlInvocation irq cslot_ptr cslot_ptr bool\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "AARCH64-Specific Capabilities: Define architecture-specific capabilities including ASID pools, ASID controller, frame, page table, and VCPU. These capabilities encapsulate specific properties such as object references, ASID bases, rights, sizes, device flags, and mapping data, enabling fine-grained control over memory and virtualization resources.",
    "input": "",
    "output": "text \\<open>\n  The AARCH64 kernel supports capabilities for ASID pools and an ASID controller capability,\n  along with capabilities for virtual memory mappings.\n\\<close>\n\ndatatype arch_cap =\n    ASIDPoolCap\n      (acap_obj : obj_ref)\n      (acap_asid_base : asid)\n  | ASIDControlCap\n  | FrameCap\n      (acap_obj : obj_ref)\n      (acap_rights : cap_rights)\n      (acap_fsize : vmpage_size)\n      (acap_is_device : bool)\n      (acap_map_data : \"(asid \\<times> vspace_ref) option\")\n  | PageTableCap\n      (acap_obj : obj_ref)\n      (acap_pt_type : pt_type)\n      (acap_map_data : \"(asid \\<times> vspace_ref) option\")\n  | VCPUCap\n      (acap_obj : obj_ref)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Mapping Data: Modify the mapping data in a frame or page table capability, updating the ASID and virtual space reference.",
    "input": "",
    "output": "definition update_map_data :: \"arch_cap \\<Rightarrow> (asid \\<times> vspace_ref) option \\<Rightarrow> arch_cap\" where\n  \"update_map_data cap m \\<equiv> case cap of\n     FrameCap p R sz dev _  \\<Rightarrow> FrameCap p R sz dev m\n   | PageTableCap p t _ \\<Rightarrow> PageTableCap p t m\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VM Attributes: Define a set of attributes that can be applied to virtual memory, including global, execute, and device-specific attributes. These attributes allow for fine-grained control over the properties and behavior of memory pages in the system.",
    "input": "",
    "output": "(* This datatype does not match up with the executable spec directly:\n   This one here models all \"things\" one can set on a page entry.\n   The attributes accessible to users are the ones returned by attribs_from_word. *)\ndatatype vm_attribute = Global | Execute | Device\ntype_synonym vm_attributes = \"vm_attribute set\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Physical Page Number Encoding: The base address for next-level tables of PagePTEs is encoded as a 36-bit field, with the bottom 12 bits always set to 0, ensuring alignment. This encoding ensures that the significant bits of the physical address are stored from the top of the intermediate physical address size down to the page bits, providing both size and alignment invariants.",
    "input": "",
    "output": "value_type ppn_len = \"ipa_size - pageBits\"\ntype_synonym ppn = \"ppn_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Entry (PTE) Structure: Defines the structure of a page table entry, which can represent an invalid entry, a small or large page with associated attributes and rights, or a page table. The base address of a PTE is determined based on its type, either from the page address for a page entry or from the page table physical number for a page table entry.",
    "input": "",
    "output": "lemma ppn_len_def':\n  \"ppn_len = ipa_size - pageBits\"\n  by (simp add: ppn_len_val pageBits_def ipa_size_def Kernel_Config.config_ARM_PA_SIZE_BITS_40_def)\n\ndatatype pte =\n    InvalidPTE\n  | PagePTE\n      (pte_page_addr : paddr)\n      (pte_is_small_page : bool)\n      (pte_attr : vm_attributes)\n      (pte_rights : vm_rights)\n  | PageTablePTE\n      (pte_ppn : ppn)\n\ndefinition paddr_from_ppn :: \"ppn \\<Rightarrow> paddr\" where\n  \"paddr_from_ppn addr \\<equiv> ucast addr << pageBits\"\n\ndefinition pte_base_addr :: \"pte \\<Rightarrow> paddr\" where\n  \"pte_base_addr pte \\<equiv>\n    if is_PageTablePTE pte then paddr_from_ppn (pte_ppn pte) else pte_page_addr pte\"\n\ndefinition ppn_from_pptr :: \"obj_ref \\<Rightarrow> ppn\" where\n  \"ppn_from_pptr p = ucast (addrFromPPtr p >> pageBits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Translation Bits: The number of translation bits for the VSpace root page table (VSRootPT_T) and the normal page table (NormalPT_T) are defined to match the length of their respective index types, ensuring proper alignment and addressing within the architecture.",
    "input": "",
    "output": "lemma vs_index_ptTranslationBits:\n  \"ptTranslationBits VSRootPT_T = LENGTH(vs_index_len)\"\n  by (simp add: ptTranslationBits_def vs_index_bits_def)\n\nlemma pt_index_ptTranslationBits:\n  \"ptTranslationBits NormalPT_T = LENGTH(pt_index_len)\"\n  by (simp add: ptTranslationBits_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Data Types: Define AARCH64-specific data types for ASID pools and page tables. ASID pools are represented as a mapping from ASID low indices to entries, where each entry contains an optional VMID and a reference to a virtual space. Page tables can be either VSRootPT, which maps virtual space indices to page table entries, or NormalPT, which maps page table indices to page table entries. The type of a page table is determined by its structure, distinguishing between VSRootPT and NormalPT.",
    "input": "",
    "output": "datatype asid_pool_entry = ASIDPoolVSpace (ap_vmid : \"vmid option\") (ap_vspace : obj_ref)\n\ntype_synonym asid_pool = \"asid_low_index \\<rightharpoonup> asid_pool_entry\"\n\ndatatype pt =\n    VSRootPT (the_vs : \"vs_index \\<Rightarrow> pte\")\n  | NormalPT (the_pt : \"pt_index \\<Rightarrow> pte\")\n\ndefinition pt_type :: \"pt \\<Rightarrow> pt_type\" where\n  \"pt_type pt \\<equiv> case pt of VSRootPT _ \\<Rightarrow> VSRootPT_T | NormalPT _ \\<Rightarrow> NormalPT_T\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "AARCH64 VCPU Structure: Defines a virtual CPU (vCPU) with fields for TCB reference, GIC vCPU interface, registers, VPII event masking, and a virtual timer. The default vCPU is initialized with specific values for the GIC interface, registers, and other components, ensuring a consistent and predictable initial state for vCPUs in the system.",
    "input": "",
    "output": "type_synonym virq = machine_word\n\nend\n\nqualify AARCH64_A (in Arch)\n\nrecord  gic_vcpu_interface =\n  vgic_hcr  :: word32\n  vgic_vmcr :: word32\n  vgic_apr  :: word32\n  vgic_lr   :: \"nat \\<Rightarrow> AARCH64_A.virq\"\n\nrecord vcpu =\n  vcpu_tcb  :: \"obj_ref option\"\n  vcpu_vgic :: \"gic_vcpu_interface\"\n  vcpu_regs :: \"vcpureg \\<Rightarrow> machine_word\"\n  vcpu_vppi_masked :: \"vppievent_irq \\<Rightarrow> bool\"\n  vcpu_vtimer :: virt_timer\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition \"vcpu_sctlr vcpu \\<equiv> vcpu_regs vcpu VCPURegSCTLR\"\n\ndefinition default_gic_vcpu_interface :: gic_vcpu_interface where\n  \"default_gic_vcpu_interface \\<equiv> \\<lparr>\n      vgic_hcr  = vgicHCREN,\n      vgic_vmcr = 0,\n      vgic_apr  = 0,\n      vgic_lr   = \\<lambda>_. 0\n   \\<rparr>\"\n\ndefinition\n  default_vcpu :: vcpu where\n  \"default_vcpu \\<equiv> \\<lparr>\n      vcpu_tcb    = None,\n      vcpu_vgic   = default_gic_vcpu_interface,\n      vcpu_regs   = (\\<lambda>_. 0) (VCPURegSCTLR := sctlrEL1VM),\n      vcpu_vppi_masked = (\\<lambda>_. False),\n      vcpu_vtimer = VirtTimer 0\n   \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Kernel Objects: Define and categorize architecture-specific kernel objects, including ASID pools, page tables, data pages, and VCPUs. Discriminators and selectors are provided for each type, allowing for the extraction of specific components such as ASID pools, page tables, and VCPUs from the kernel object.",
    "input": "",
    "output": "datatype (discs_sels) arch_kernel_obj =\n    ASIDPool asid_pool\n  | PageTable pt\n  | DataPage bool vmpage_size\n  | VCPU vcpu\n\ndefinition asid_pool_of :: \"arch_kernel_obj \\<rightharpoonup> asid_pool\" where\n  \"asid_pool_of ko \\<equiv> case ko of ASIDPool pool \\<Rightarrow> Some pool | _ \\<Rightarrow> None\"\n\ndefinition pt_of :: \"arch_kernel_obj \\<rightharpoonup> pt\" where\n  \"pt_of ko \\<equiv> case ko of PageTable pt \\<Rightarrow> Some pt | _ \\<Rightarrow> None\"\n\ndefinition vcpu_of :: \"arch_kernel_obj \\<rightharpoonup> vcpu\" where\n  \"vcpu_of ko \\<equiv> case ko of VCPU vcpu \\<Rightarrow> Some vcpu | _ \\<Rightarrow> None\"\n\ndefinition pte_bits :: nat where\n  \"pte_bits = word_size_bits\"\n\ndefinition table_size :: \"pt_type \\<Rightarrow> nat\" where\n  \"table_size pt_t = ptTranslationBits pt_t + pte_bits\"\n\ndefinition pt_bits :: \"pt_type \\<Rightarrow> nat\" where\n  \"pt_bits pt_t \\<equiv> table_size pt_t\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Object Sizes and Properties: Defines the sizes of architecture-specific objects such as ASID pools, frame caps, page tables, and VCPUs. Additionally, it specifies whether a frame cap is a device and provides a method to update the rights of a frame cap.",
    "input": "",
    "output": "lemma ppn_len:\n  \"LENGTH(ppn_len) = ipa_size - pt_bits NormalPT_T\"\n  by (simp add: pt_bits_def table_size_def ptTranslationBits_def pte_bits_def word_size_bits_def\n                ipa_size_def Kernel_Config.config_ARM_PA_SIZE_BITS_40_def)\n\nprimrec arch_obj_size :: \"arch_cap \\<Rightarrow> nat\" where\n  \"arch_obj_size (ASIDPoolCap _ _) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (FrameCap _ _ sz _ _) = pageBitsForSize sz\"\n| \"arch_obj_size (PageTableCap _ pt_t _ ) = table_size pt_t\"\n| \"arch_obj_size (VCPUCap _) = vcpuBits\"\n\nfun arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_cap_is_device (FrameCap _ _ _ is_dev _) = is_dev\"\n| \"arch_cap_is_device _ = False\"\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 5\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 11\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 5\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 47\"\n\nprimrec arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\" where\n  \"arch_kobj_size (ASIDPool _) = pageBits\"\n| \"arch_kobj_size (PageTable pt) = table_size (pt_type pt)\"\n| \"arch_kobj_size (DataPage _ sz) = pageBitsForSize sz\"\n| \"arch_kobj_size (VCPU _) = vcpuBits\"\n\nfun aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\" where\n  \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref c = Some (acap_obj c)\"\n\ndefinition acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n  \"acap_rights_update R acap \\<equiv>\n    case acap of\n      FrameCap ref cR sz dev as \\<Rightarrow> FrameCap ref (validate_vm_rights R) sz dev as\n    | _ \\<Rightarrow> acap\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "AARCH64-Specific Data Types: Defines architecture-specific object types and their default capabilities, including small, large, and huge page objects, page table objects, virtual space objects, ASID pool objects, and VCPU objects. These definitions ensure that the system can correctly manage and allocate different types of memory and virtualization resources.",
    "input": "",
    "output": "datatype aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | HugePageObj\n  | PageTableObj\n  | VSpaceObj\n  | ASIDPoolObj (* used internally, not on API level *)\n  | VCPUObj\n\ndefinition arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\" where\n  \"arch_is_frame_type aobj \\<equiv> case aobj of\n     SmallPageObj \\<Rightarrow> True\n   | LargePageObj \\<Rightarrow> True\n   | HugePageObj \\<Rightarrow> True\n   | _ \\<Rightarrow> False\"\n\ndefinition arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\" where\n  \"arch_default_cap tp r n dev \\<equiv> case tp of\n     SmallPageObj \\<Rightarrow> FrameCap r vm_read_write ARMSmallPage dev None\n   | LargePageObj \\<Rightarrow> FrameCap r vm_read_write ARMLargePage dev None\n   | HugePageObj  \\<Rightarrow> FrameCap r vm_read_write ARMHugePage dev None\n   | PageTableObj \\<Rightarrow> PageTableCap r NormalPT_T None\n   | VSpaceObj    \\<Rightarrow> PageTableCap r VSRootPT_T None\n   | VCPUObj      \\<Rightarrow> VCPUCap r\n   | ASIDPoolObj  \\<Rightarrow> ASIDPoolCap r 0\" (* unused, but nicer properties when defined *)\n\ndefinition default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\" where\n  \"default_arch_object tp dev n \\<equiv> case tp of\n     SmallPageObj \\<Rightarrow> DataPage dev ARMSmallPage\n   | LargePageObj \\<Rightarrow> DataPage dev ARMLargePage\n   | HugePageObj  \\<Rightarrow> DataPage dev ARMHugePage\n   | PageTableObj \\<Rightarrow> PageTable (NormalPT (\\<lambda>_. InvalidPTE))\n   | VSpaceObj    \\<Rightarrow> PageTable (VSRootPT (\\<lambda>_. InvalidPTE))\n   | VCPUObj \\<Rightarrow> VCPU default_vcpu\n   | ASIDPoolObj  \\<Rightarrow> ASIDPool Map.empty\"\n\ntype_synonym arm_vspace_region_uses = \"vspace_ref \\<Rightarrow> arm_vspace_region_use\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VM Level Configuration: The number of virtual memory levels is determined by the configuration, with 4 levels if `config_ARM_PA_SIZE_BITS_40` is set, and 5 levels otherwise. The top level contains ASID pools, and the subsequent levels contain page tables, with the bottom level (level 0) containing only InvalidPTEs or PagePTEs.",
    "input": "",
    "output": "value_type vm_level = \"if config_ARM_PA_SIZE_BITS_40 then 4 else (5::int)\"\n\ndefinition asid_pool_level :: vm_level where\n  \"asid_pool_level = maxBound\"\n\ndefinition max_pt_level :: vm_level where\n  \"max_pt_level = asid_pool_level - 1\"\n\ndefinition level_type :: \"vm_level \\<Rightarrow> pt_type\" where\n  \"level_type level \\<equiv> if level = max_pt_level then VSRootPT_T else NormalPT_T\"\n\ndeclare [[coercion_enabled]]\ndeclare [[coercion level_type]]\n\nend\n\nqualify AARCH64_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific State: The `arch_state` record maintains architecture-specific data for the AARCH64 system, including ASID tables, kernel virtual space, VMID tables, the next VMID, a global user-space virtual space, the current VCPU (with an active flag), and the number of GICvCPU list registers. This ensures that the system can manage and track the state of virtual memory, virtual CPUs, and interrupt handling effectively.",
    "input": "",
    "output": "record arch_state =\n  arm_asid_table :: \"asid_high_index \\<rightharpoonup> obj_ref\"\n  arm_kernel_vspace :: \"AARCH64_A.arm_vspace_region_uses\"\n  arm_vmid_table :: \"AARCH64_A.vmid \\<rightharpoonup> asid\"\n  arm_next_vmid :: AARCH64_A.vmid\n  arm_us_global_vspace :: \"obj_ref\"\n  arm_current_vcpu    :: \"(obj_ref \\<times> bool) option\"\n  arm_gicvcpu_numlistregs :: nat\n\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "AARCH64-Specific Data Types: Defines a set of data types specific to the AARCH64 architecture, including AASIDPool, APageTable, AVCPU, AUserData, and ADeviceData, each with specific attributes. The `aa_type` function maps an architectural kernel object to its corresponding AARCH64-specific type, ensuring that the object's properties are correctly represented.",
    "input": "",
    "output": "datatype aa_type =\n    AASIDPool\n  | APageTable (a_pt_t : pt_type)\n  | AVCPU\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\" where\n  \"aa_type ao \\<equiv> case ao of\n     PageTable pt    \\<Rightarrow> APageTable (pt_type pt)\n   | DataPage dev sz \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n   | ASIDPool _      \\<Rightarrow> AASIDPool\n   | VCPU _          \\<Rightarrow> AVCPU\"\n\ndefinition badge_bits :: nat where\n  \"badge_bits \\<equiv> 64\"\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "AARCH64-Specific TCB Data Types: Define and qualify AARCH64-specific data types for the TCB, including VCPU, to ensure proper handling and representation of architecture-specific thread control block information.",
    "input": "",
    "output": "qualify AARCH64_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-specific TCB: The architecture-specific part of a TCB includes a user context and an optional VCPU reference, ensuring that the TCB can manage both the user-level state and virtual CPU associations.",
    "input": "",
    "output": "record arch_tcb =\n  tcb_context :: user_context\n  tcb_vcpu    :: \"obj_ref option\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition default_arch_tcb :: arch_tcb where\n  \"default_arch_tcb \\<equiv> \\<lparr>tcb_context = new_context, tcb_vcpu = None\\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Access and Modify TCB Context: Provides functions to set and get the user context within the architecture-specific TCB, ensuring compatibility with the user monad for operations that need to be performed on behalf of a user.",
    "input": "",
    "output": "definition arch_tcb_context_set :: \"user_context \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\" where\n  \"arch_tcb_context_set uc a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := uc \\<rparr>\"\n\ndefinition arch_tcb_context_get :: \"arch_tcb \\<Rightarrow> user_context\" where\n  \"arch_tcb_context_get a_tcb \\<equiv> tcb_context a_tcb\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Access and Modify User Registers: Provides functions to set and get the user registers in the architecture-specific TCB, ensuring that the FPU state is preserved when updating the register values.",
    "input": "",
    "output": "definition arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\" where\n  \"arch_tcb_set_registers regs a_tcb \\<equiv>\n    a_tcb \\<lparr> tcb_context := UserContext (fpu_state (tcb_context a_tcb)) regs \\<rparr>\"\n\ndefinition arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\" where\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Generate Architecture-specific Fault Messages: Construct messages for different types of architecture-specific faults, including VMFault, VCPUFault, VPPIEvent, and VGICMaintenance. These messages contain relevant fault data and are formatted according to the specific fault type.",
    "input": "",
    "output": "chapter \\<open>Architecture-specific Fault-handling Functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\" where\n  \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData)\n   od\"\n| \"make_arch_fault_msg (VCPUFault hsr) thread = return (7, [hsr])\"\n| \"make_arch_fault_msg (VPPIEvent irq) thread = return (8, [ucast irq])\"\n| \"make_arch_fault_msg (VGICMaintenance archData) thread = do\n      msg \\<leftarrow> return $ (case archData of None \\<Rightarrow> [-1] | Some idx \\<Rightarrow> [idx]);\n      return (6, msg)\n   od\"\n\ndefinition handle_arch_fault_reply ::\n  \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\n  where\n  \"handle_arch_fault_reply vmf thread x y \\<equiv> return True\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-specific TCB Functions: Sanitize and manage thread control block (TCB) registers based on architecture-specific rules. The sanitization process ensures that specific register values are modified to maintain system integrity, and the post-modification process updates the state accordingly.",
    "input": "",
    "output": "chapter \\<open>Architecture-specific TCB functions\\<close>\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\" where\n  \"sanitise_register b r v \\<equiv> case r of\n     SPSR_EL1 \\<Rightarrow> if b \\<and> v && 0x1f \\<in> {0,4,5} then v else v && 0xf0000000 || 0x140\n   | _ \\<Rightarrow> v\"\n\ndefinition arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\" where\n  \"arch_get_sanitise_register_info t \\<equiv> do\n     vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n     return (vcpu \\<noteq> None)\n   od\"\n\ndefinition arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\" where\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update CNode Capability Data: Extract new guard size and guard bits from the provided data, ensuring that the CNode capability is modified according to the user's request.",
    "input": "",
    "output": "definition update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n  \"update_cnode_cap_data w \\<equiv>\n     let\n       guard_bits = 58;\n       guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n       guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n     in (guard_size', guard'')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capability Physicality: Distinguish between physical and non-physical architectural capabilities, where an ASIDControlCap is considered non-physical, and all other architectural capabilities are considered physical.",
    "input": "",
    "output": "definition arch_is_physical :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_is_physical cap \\<equiv> case cap of ASIDControlCap \\<Rightarrow> False | _ \\<Rightarrow> True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Capabilities for Same Region: Determine if two architecture capabilities refer to the same memory region or object. This involves comparing their base addresses and sizes for frame capabilities, and checking for exact matches for other types of capabilities such as page table, ASID control, ASID pool, and VCPU.",
    "input": "",
    "output": "fun arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n  \"arch_same_region_as (FrameCap r _ sz _ _) c' =\n   (is_FrameCap c' \\<and>\n     (let\n        r' = acap_obj c';\n        sz' = acap_fsize c';\n        topA = r + (1 << pageBitsForSize sz) - 1;\n        topB = r' + (1 << pageBitsForSize sz') - 1\n      in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB))\"\n| \"arch_same_region_as (PageTableCap r pt_t _) c' = (\\<exists>r' d'. c' = PageTableCap r' pt_t d' \\<and> r = r')\"\n| \"arch_same_region_as ASIDControlCap c' = (c' = ASIDControlCap)\"\n| \"arch_same_region_as (ASIDPoolCap r _) c' = (\\<exists>r' d'. c' = ASIDPoolCap r' d' \\<and> r = r')\"\n| \"arch_same_region_as (VCPUCap r) c' = (\\<exists>r'. c' = VCPUCap r' \\<and> r = r')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Arch Capabilities for Same Object: Determine if two architecture capabilities refer to the same object by comparing their references, sizes, and device identifiers. If they are frame capabilities, ensure that the references and sizes match and that the reference is within the valid range; otherwise, use a general region comparison.",
    "input": "",
    "output": "definition same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n  \"same_aobject_as cap cap' \\<equiv>\n     case (cap, cap') of\n       (FrameCap ref _ sz dev _, FrameCap ref' _ sz' dev' _) \\<Rightarrow>\n         (dev, ref, sz) = (dev', ref', sz') \\<and> ref \\<le> ref + 2 ^ pageBitsForSize sz - 1\n     | _ \\<Rightarrow> arch_same_region_as cap cap'\"\n\ndeclare same_aobject_as_def[simp]\n\ndefinition arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\" where\n  \"arch_is_cap_revocable new_cap src_cap \\<equiv> False\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Instantiation for AARCH64: Defines concrete types for abstract type names such as object references, virtual space references, data, capability references, and length types, specific to the AARCH64 architecture. This includes detailed bit-length specifications for ASID (Address Space Identifier) components and VMID (Virtual Machine Identifier).",
    "input": "",
    "output": "type_synonym obj_ref         = machine_word\ntype_synonym vspace_ref      = machine_word\n\ntype_synonym data            = machine_word\ntype_synonym cap_ref         = \"bool list\"\ntype_synonym length_type     = machine_word\n\ntype_synonym asid_low_len    = 9\ntype_synonym asid_low_index  = \"asid_low_len word\"\n\ntype_synonym asid_high_len   = 7\ntype_synonym asid_high_index = \"asid_high_len word\"\n\ntype_synonym asid_len        = 16\ntype_synonym asid_rep_len    = asid_len\ntype_synonym asid            = \"asid_rep_len word\"\n\ntype_synonym vmid            = \"8 word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Conversions: Convert between different data types, including object references, virtual space references, natural numbers, lengths, and various word sizes, using identity functions, type casting, and bitwise operations.",
    "input": "",
    "output": "definition oref_to_data :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition data_to_oref :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition vref_to_data :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition data_to_vref :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition nat_to_len :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition data_to_nat :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition data_to_16 :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Data Conversion Simplifications: Define and simplify conversions between data representations, including object references, virtual references, natural numbers, 16-bit values, and capability pointers. These simplifications facilitate automatic unfolding in proofs, ensuring consistent and efficient data handling.",
    "input": "",
    "output": "lemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Dependent Sizes: Define the standard sizes for slots and message labels, as well as the initial state for a new user context. These definitions ensure that the system adheres to the specific architectural constraints of the underlying machine.",
    "input": "",
    "output": "definition slot_bits :: nat where\n  \"slot_bits \\<equiv> 5\"\n\ndefinition msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 52\"\n\ndefinition new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext (FPUState (\\<lambda>_. 0) 0 0) ((\\<lambda>_. 0) (SPSR_EL1 := pstateUser))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Virtual Address Reservation: The kernel reserves a range of virtual addresses starting from the lowest virtual address in the kernel window, ensuring that these addresses are not available for user processes.",
    "input": "",
    "output": "definition pptr_base :: \"machine_word\" where\n  \"pptr_base = Platform.AARCH64.pptrBase\"\n\ntext \"Virtual address space available to users.\"\ndefinition user_vtop :: \"machine_word\" where\n  \"user_vtop = Platform.AARCH64.pptrUserTop\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual Address for Kernel Device Mapping: The `kdev_base` is defined as the starting virtual address for the kernel device mapping region, located in the highest 1GiB of memory.",
    "input": "",
    "output": "definition kdev_base :: \"machine_word\" where\n  \"kdev_base = Platform.AARCH64.kdevBase\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel ELF Base: Defines the virtual address at which the kernel code is mapped in the virtual address space.",
    "input": "",
    "output": "definition kernel_elf_base :: \"vspace_ref\" where\n  \"kernel_elf_base \\<equiv> Platform.AARCH64.kernelELFBase\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Idle Thread Pointer Definition: Defines an arbitrary aligned address for the idle thread, which must exist but does not need to match a specific concrete value in the C implementation.",
    "input": "",
    "output": "definition idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = pptr_base + 0x1000\"\n\n\ndefinition nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\" where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len) (to_bl (of_nat n :: machine_word))\"\n\ndefinition msg_info_register :: register where\n  \"msg_info_register \\<equiv> msgInfoRegister\"\n\ndefinition msg_registers :: \"register list\" where\n  \"msg_registers \\<equiv> msgRegisters\"\n\ndefinition cap_register :: register where\n  \"cap_register \\<equiv> capRegister\"\n\ndefinition badge_register :: register where\n  \"badge_register \\<equiv> badgeRegister\"\n\ndefinition frame_registers :: \"register list\" where\n  \"frame_registers \\<equiv> frameRegisters\"\n\ndefinition gp_registers :: \"register list\" where\n  \"gp_registers \\<equiv> gpRegisters\"\n\ndefinition exception_message :: \"register list\" where\n  \"exception_message \\<equiv> exceptionMessage\"\n\ndefinition syscall_message :: \"register list\" where\n  \"syscall_message \\<equiv> syscallMessage\"\n\ndatatype arch_fault\n  = VMFault (vm_fault_address : vspace_ref) (vm_fault_arch_data : \"machine_word list\")\n  | VCPUFault (vcpu_hsr : data)\n  | VPPIEvent (vppi_irq : irq)\n  | VGICMaintenance (vgic_maintenance_data : \"data option\")\n\n\nend\n\narch_requalify_consts (A) idle_thread_ptr\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Register Masking: Ensures that certain bits in the registers are preserved and cannot be written by the user, maintaining the integrity of specific register parts.",
    "input": "",
    "output": "consts\n  register_mask :: \"machine_word option\" (* no need for option? *)\n\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural IRQ Validation: Ensures that the provided IRQ number is within the valid range, throwing a `RangeError` if the IRQ exceeds the maximum allowed value.",
    "input": "",
    "output": "text \\<open>\n  This is used by some decode functions. VCPU decode functions are the first that need to bounds\n  check IRQs from the user.\n  \\<close>\n\ndefinition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> whenE (irq > maxIRQ) $ throwError (RangeError 0 maxIRQ)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Set TCB: Decodes the VCPU capability and sets the TCB for a VCPU. Ensures that the operation is only valid if the provided capability is a VCPU capability and the extra slot contains a thread capability, otherwise it throws an error.",
    "input": "",
    "output": "definition decode_vcpu_set_tcb :: \"arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere \"decode_vcpu_set_tcb cap extras \\<equiv> case (cap, extras) of\n  (VCPUCap v, fs#_) \\<Rightarrow> (case fs of\n        (ThreadCap t, _) \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUSetTCB v t\n      | _ \\<Rightarrow> throwError IllegalOperation)\n |(VCPUCap v, _) \\<Rightarrow> throwError TruncatedMessage\n | _ \\<Rightarrow> throwError IllegalOperation\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Register Access: Provides mechanisms to read and write VCPU registers, ensuring that the appropriate method is used based on whether the VCPU is the current one and its active state. If the VCPU is the current one and the register is saved when disabled, it uses specific read/write functions; otherwise, it accesses the hardware directly.",
    "input": "",
    "output": "definition\n  read_vcpu_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word,'z::state_ext) s_monad\"\nwhere\n  \"read_vcpu_register vcpu_ptr reg \\<equiv> do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (on_cur_vcpu, active) \\<leftarrow> return (case cur_vcpu of\n         Some (vcpu_ptr', a) \\<Rightarrow> (vcpu_ptr' = vcpu_ptr, a)\n       | _ \\<Rightarrow> (False, False));\n\n     if on_cur_vcpu\n       then if vcpuRegSavedWhenDisabled reg \\<and> \\<not>active\n              then vcpu_read_reg vcpu_ptr reg\n              else do_machine_op $ readVCPUHardwareReg reg\n       else vcpu_read_reg vcpu_ptr reg\n  od\"\n\ndefinition\n  write_vcpu_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"write_vcpu_register vcpu_ptr reg val \\<equiv>\n  do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu o arch_state);\n     (on_cur_vcpu, active) \\<leftarrow> return (case cur_vcpu of\n         Some (cv, a) \\<Rightarrow> (cv = vcpu_ptr, a)\n       | _ \\<Rightarrow> (False, False));\n\n     if on_cur_vcpu\n       then if vcpuRegSavedWhenDisabled reg \\<and> \\<not>active\n         then vcpu_write_reg vcpu_ptr reg val\n         else do_machine_op $ writeVCPUHardwareReg reg val\n       else vcpu_write_reg vcpu_ptr reg val\n  od\"\n\ndefinition decode_vcpu_read_register :: \"machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_vcpu_read_register args cap \\<equiv> case (args, cap) of\n      (reg#_, VCPUCap p) \\<Rightarrow> if fromEnum (maxBound::vcpureg) < unat reg\n                           then throwError (InvalidArgument 1)\n                           else returnOk $ InvokeVCPU $ VCPUReadRegister p $ toEnum (unat reg)\n    | (_, _) \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition decode_vcpu_write_register :: \"machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_vcpu_write_register args cap \\<equiv> case (args, cap) of\n    (reg#val#_, VCPUCap p) \\<Rightarrow> if fromEnum (maxBound::vcpureg) < unat reg\n                              then throwError (InvalidArgument 1)\n                              else returnOk $ InvokeVCPU $ VCPUWriteRegister p (toEnum (unat reg)) val\n  | (_, _) \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_read_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\nwhere \"invoke_vcpu_read_register v reg \\<equiv> do\n   val \\<leftarrow> read_vcpu_register v reg;\n   return [val]\nod\"\n\ndefinition\n  invoke_vcpu_write_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"invoke_vcpu_write_register v reg val \\<equiv>  write_vcpu_register v reg val\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Interrupt Injection: Decode and inject a virtual interrupt into a VCPU. The function extracts the virtual interrupt ID, priority, group, and index from the provided parameters, performs range checks, and constructs a virtual interrupt (virq) to be injected. If the VCPU is the current VCPU, it sets the GIC VCPU control register; otherwise, it updates the VCPU's local register.",
    "input": "",
    "output": "definition make_virq :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> virq\" where\n  \"make_virq grp prio irq \\<equiv>\n  let\n    groupShift = 30;\n    prioShift = 23;\n    irqPending = 1 << 28;\n    eoiirqen = 1 << 19\n  in ((grp && 1) << groupShift) || ((prio && 0x1F) << prioShift) || (irq && 0x3FF) || irqPending || eoiirqen\"\n\n\ndefinition decode_vcpu_inject_irq :: \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_vcpu_inject_irq ptrs cap \\<equiv> case (ptrs, cap) of\n  (mr0 # mr1 # _, VCPUCap p) \\<Rightarrow> doE\n     vid \\<leftarrow> returnOk (mr0 && 0xFFFF);\n     priority \\<leftarrow> returnOk ((mr0 >> 16) && 0xFF);\n     group \\<leftarrow> returnOk ((mr0 >> 24) && 0xFF);\n     index \\<leftarrow> returnOk (mr1 && 0xFF);\n     range_check vid 0 ((1 << 10) - 1);\n     range_check priority 0 31;\n     range_check group 0 1;\n     num_list_regs \\<leftarrow> liftE $ gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     whenE (index \\<ge> of_nat num_list_regs) $\n        (throwError $ RangeError 0 (of_nat num_list_regs - 1));\n\n     vcpu \\<leftarrow> liftE $ get_vcpu p;\n     vcpuLR \\<leftarrow> returnOk (vgic_lr $ vcpu_vgic $ vcpu);\n\n     whenE (vcpuLR (unat index) && vgic_irq_mask = vgic_irq_active) $ throwError DeleteFirst;\n\n     virq \\<leftarrow> returnOk (make_virq group priority vid);\n     returnOk $ InvokeVCPU $ VCPUInjectIRQ p (unat index) virq\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition\n  invoke_vcpu_inject_irq :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"invoke_vcpu_inject_irq vr index virq \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    if (cur_v \\<noteq> None \\<and> fst (the cur_v) = vr)\n    then do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat index) virq\n    else vgic_update_lr vr index virq\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Acknowledge VCPU VPPI: The system acknowledges a VPPI (Virtual Platform Performance Interrupt) event for a VCPU by unmasking the corresponding VPPI in the VCPU's state, allowing the VCPU to handle the interrupt.",
    "input": "",
    "output": "definition decode_vcpu_ack_vppi ::\n  \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_ack_vppi mrs cap \\<equiv>\n     case (mrs, cap)\n       of (mr0 # _, VCPUCap vcpu_ptr) \\<Rightarrow> doE\n           arch_check_irq mr0;\n           (case irq_vppi_event_index (ucast mr0)\n            of None \\<Rightarrow> throwError $ InvalidArgument 0\n             | Some vppi \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUAckVPPI vcpu_ptr vppi)\n         odE\n       | _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_ack_vppi :: \"obj_ref \\<Rightarrow> vppievent_irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"invoke_vcpu_ack_vppi vcpu_ptr vppi =\n     vcpu_update vcpu_ptr\n                 (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := False) \\<rparr>)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Invocation and Decoding: Supports VCPU operations including setting the associated TCB, reading and writing registers, injecting IRQs, and acknowledging VPPIs. These operations are decoded from the invocation type and arguments, ensuring that the VCPU can perform and manage its state effectively.",
    "input": "",
    "output": "definition\nperform_vcpu_invocation :: \"vcpu_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n\"perform_vcpu_invocation iv \\<equiv> case iv of\n    VCPUSetTCB vcpu tcb \\<Rightarrow> do associate_vcpu_tcb vcpu tcb; return [] od\n  | VCPUReadRegister vcpu reg \\<Rightarrow> invoke_vcpu_read_register vcpu reg\n  | VCPUWriteRegister vcpu reg val \\<Rightarrow> do invoke_vcpu_write_register vcpu reg val; return [] od\n  | VCPUInjectIRQ vcpu index vir \\<Rightarrow> do invoke_vcpu_inject_irq vcpu index vir; return [] od\n  | VCPUAckVPPI vcpu vppi \\<Rightarrow> do invoke_vcpu_ack_vppi vcpu vppi; return [] od\"\n\n\ndefinition decode_vcpu_invocation ::\n\"machine_word \\<Rightarrow> machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_vcpu_invocation label args cap extras \\<equiv> case cap of\nVCPUCap _ \\<Rightarrow> (case invocation_type label of\n    ArchInvocationLabel ARMVCPUSetTCB \\<Rightarrow> decode_vcpu_set_tcb cap extras\n  | ArchInvocationLabel ARMVCPUReadReg \\<Rightarrow> decode_vcpu_read_register args cap\n  | ArchInvocationLabel ARMVCPUWriteReg \\<Rightarrow> decode_vcpu_write_register args cap\n  | ArchInvocationLabel ARMVCPUInjectIRQ \\<Rightarrow> decode_vcpu_inject_irq args cap\n  | ArchInvocationLabel ARMVCPUAckVPPI \\<Rightarrow> decode_vcpu_ack_vppi args cap\n  |  _ \\<Rightarrow> throwError IllegalOperation)\n| _ \\<Rightarrow> throwError IllegalOperation\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "VGIC Maintenance: Manages the VGIC (Virtual Generic Interrupt Controller) by handling maintenance interrupts, updating the EOI (End of Interrupt) status, and managing virtual IRQs. It ensures that the current vCPU's state is updated and any faults are handled if the current thread is runnable. Additionally, it processes VPPIs (Virtual Physical Peripheral Interrupts) by masking the interrupt and updating the vCPU's VPPi masked state.",
    "input": "",
    "output": "definition\n  virqSetEOIIRQEN :: \"virq \\<Rightarrow> 32 word \\<Rightarrow> virq\"\nwhere\n  \"virqSetEOIIRQEN virq v =\n    (if ((virq >> 28) && 3 = 3)\n    then virq\n    else (virq && ~~0x80000) || ((v << 19) && 0x80000))\"\n\ndefinition\n  vgic_maintenance :: \"(unit,'z::state_ext) s_monad\"\nwhere\n  \"vgic_maintenance = do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     case cur_vcpu\n       of Some (vcpu_ptr, True) \\<Rightarrow> do\n            eisr0 \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_eisr0;\n            eisr1 \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_eisr1;\n            flags \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_misr;\n            vgic_misr_eoi \\<leftarrow> return $ 1;\n            irq_idx \\<leftarrow> return (if eisr0 \\<noteq> 0 then word_ctz eisr0 else word_ctz eisr1 + 32);\n            gic_vcpu_num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs o arch_state);\n            fault \\<leftarrow> if flags && vgic_misr_eoi \\<noteq> 0\n                    then\n                      if eisr0 = 0 \\<and> eisr1 = 0 \\<or> irq_idx \\<ge> gic_vcpu_num_list_regs\n                      then return $ VGICMaintenance None\n                      else do\n                        virq <- do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat irq_idx);\n                        virqen <- return $ virqSetEOIIRQEN virq 0;\n                        do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat irq_idx) virqen;\n                        vgic_update_lr vcpu_ptr irq_idx virqen;\n                        return $ VGICMaintenance $ Some $ of_nat irq_idx\n                      od\n                    else return $ VGICMaintenance None;\n\n            ct \\<leftarrow> gets cur_thread;\n            st \\<leftarrow> get_thread_state ct;\n            \\<comment> \\<open>until a proof links active current vcpu to runnable current thread, we need this\n               check: @{term handle_fault} needs a runnable current thread\\<close>\n            when (runnable st) $ handle_fault ct $ ArchFault fault\n          od\n        | _ \\<Rightarrow> return ()\n   od\"\n\ndefinition vppi_event :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vppi_event irq = do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     case cur_vcpu\n       of Some (vcpu_ptr, True) \\<Rightarrow> do\n            do_machine_op $ maskInterrupt True irq;\n            vppi \\<leftarrow> return $ the $ irq_vppi_event_index irq;\n            vcpu_update vcpu_ptr\n                        (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := True) \\<rparr>);\n            ct \\<leftarrow> gets cur_thread;\n            st \\<leftarrow> get_thread_state ct;\n            \\<comment> \\<open>until a proof links active current vcpu to runnable current thread, we need this\n               check: @{term handle_fault} needs a runnable current thread\\<close>\n            when (runnable st) $ handle_fault ct $ ArchFault $ VPPIEvent irq\n          od\n        | _ \\<Rightarrow> return ()\n   od\"\n\ndefinition\n  handle_reserved_irq :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_reserved_irq irq \\<equiv>\n     if irq = irqVGICMaintenance then vgic_maintenance\n     else if irq_vppi_event_index irq \\<noteq> None then vppi_event irq\n     else return ()\"\n\nfun arch_invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_invoke_irq_handler (ACKIrq irq) = (do_machine_op $ maskInterrupt False irq)\"\n| \"arch_invoke_irq_handler _ = return ()\"\n\ndefinition arch_mask_irq_signal :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_mask_irq_signal irq \\<equiv> do_machine_op $ maskInterrupt True irq\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Switch to Thread's Virtual Address Space: Switch the virtual address space context to the specified thread, update the VCPU state, and clear the load-exclusive monitor.",
    "input": "",
    "output": "definition\n  arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> do\n     t' \\<leftarrow> gets_the $ get_tcb t;\n     vcpu_switch $ tcb_vcpu $ tcb_arch t';\n     set_vm_root t;\n     do_machine_op $ clearExMonitor\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Idle Thread Management: The system switches to the idle thread by updating the virtual machine root, and no special handling is required for activating the idle thread.",
    "input": "",
    "output": "definition\n   arch_switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n   \"arch_switch_to_idle_thread \\<equiv> do\n     vcpu_switch None;\n     t \\<leftarrow> gets idle_thread;\n     set_vm_root t\n   od\"\n\ndefinition\n  arch_activate_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_activate_idle_thread t \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Control: Create a new ASID pool object, provide a capability to it, and connect it to the global virtual ASID table. This ensures that the new ASID pool is properly initialized and integrated into the system's memory management.",
    "input": "",
    "output": "definition\nperform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_control_invocation iv \\<equiv> case iv of\n  MakePool frame slot parent base \\<Rightarrow> do\n    delete_objects frame page_bits;\n    pcap \\<leftarrow> get_cap parent;\n    set_cap (max_free_index_update pcap) parent;\n    retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n    cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n    assert (base && mask asid_low_bits = 0);\n    asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n    modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>arm_asid_table := asid_table'\\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Assign ASID to Page Directory: The ASIDPool capability allows the assignment of a virtual ASID to a page directory. This involves updating the page directory's ASID and the ASID pool with the new mapping, ensuring that the page directory is correctly associated with the specified ASID.",
    "input": "",
    "output": "definition\nperform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_pool_invocation iv \\<equiv> case iv of Assign asid pool_ptr ct_slot \\<Rightarrow>\ndo\n    pd_cap \\<leftarrow> get_cap ct_slot;\n    case pd_cap of\n      ArchObjectCap (PageDirectoryCap pd_base _) \\<Rightarrow> do\n        pool \\<leftarrow> get_asid_pool pool_ptr;\n        pool' \\<leftarrow> return (pool (ucast asid \\<mapsto> pd_base));\n        set_cap (ArchObjectCap $ PageDirectoryCap pd_base (Some asid)) ct_slot;\n        set_asid_pool pool_ptr pool'\n      od\n    | _ \\<Rightarrow> fail\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Directory Invocation: Allows the invocation of operations on a page directory, such as flushing cache entries within a specified range. The operation ensures that the virtual machine root is correctly set and restored if necessary, maintaining the integrity and consistency of the memory management system.",
    "input": "",
    "output": "definition\n  perform_page_directory_invocation :: \"page_directory_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_page_directory_invocation iv \\<equiv> case iv of\n       PageDirectoryFlush typ start end pstart pd asid \\<Rightarrow>\n         when (start < end) $ do\n           root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n           do_machine_op $ do_flush typ start end pstart;\n           when root_switched $ do\n             tcb \\<leftarrow> gets cur_thread;\n             set_vm_root tcb\n           od\n        od\n     | PageDirectoryNothing \\<Rightarrow> return ()\"\n\ndefinition\n  pte_check_if_mapped :: \"32 word \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pte_check_if_mapped slot \\<equiv> do\n     pt \\<leftarrow> get_master_pte slot;\n     return (pt \\<noteq> InvalidPTE)\n  od\"\n\ndefinition\n  pde_check_if_mapped :: \"32 word \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pde_check_if_mapped slot \\<equiv> do\n     pd \\<leftarrow> get_master_pde slot;\n     return (pd \\<noteq> InvalidPDE)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Capability Operations: Authorize the mapping, unmapping, and flushing of memory pages. Mapping involves setting the page table entries or page directory entries and updating the cache, while unmapping removes the page from the address space and updates the capability. Flushing ensures that the specified memory range is cleaned and the translation lookaside buffer (TLB) is invalidated if necessary.",
    "input": "",
    "output": "definition\nperform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n\"perform_page_invocation iv \\<equiv> case iv of\n  PageMap asid cap ct_slot entries \\<Rightarrow> do\n    set_cap cap ct_slot;\n    case entries of\n          Inl (pte, slots) \\<Rightarrow> do\n            flush \\<leftarrow> pte_check_if_mapped (hd slots);\n            store_pte (hd slots) pte;\n            mapM (swp store_pte InvalidPTE) (tl slots);\n            do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                (addrFromPPtr (hd slots));\n            if flush then (invalidate_tlb_by_asid asid) else return ()\n          od\n        | Inr (pde, slots) \\<Rightarrow> do\n            flush \\<leftarrow> pde_check_if_mapped (hd slots);\n            store_pde (hd slots) pde;\n            mapM (swp store_pde InvalidPDE) (tl slots);\n            do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                (addrFromPPtr (hd slots));\n            if flush then (invalidate_tlb_by_asid asid) else return ()\n          od;\n    return []\n  od\n| PageUnmap cap ct_slot \\<Rightarrow>\n    (case cap of\n      PageCap dev p R vp_size vp_mapped_addr \\<Rightarrow> do\n        case vp_mapped_addr of\n            Some (asid, vaddr) \\<Rightarrow> unmap_page vp_size asid vaddr p\n          | None \\<Rightarrow> return ();\n        cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n        set_cap (ArchObjectCap $ update_map_data cap None) ct_slot;\n        return []\n      od\n    | _ \\<Rightarrow> fail)\n| PageFlush typ start end pstart pd asid \\<Rightarrow> do\n    when (start < end) $ do\n      root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n      do_machine_op $ do_flush typ start end pstart;\n      when root_switched $ do\n        tcb \\<leftarrow> gets cur_thread;\n        set_vm_root tcb\n      od\n    od;\n    return []\n  od\n| PageGetAddr ptr \\<Rightarrow>\n    return [addrFromPPtr ptr]\n  \"",
    "system": "",
    "history": []
  },
  {
    "instruction": "PageTable Capabilities: Allow the mapping and unmapping of page tables. This includes setting and storing page directory entries, cleaning the cache by virtual address, unmaping page tables, invalidating page table entries, and updating the capability's mapping data.",
    "input": "",
    "output": "definition\nperform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_table_invocation iv \\<equiv>\ncase iv of PageTableMap cap ct_slot pde pd_slot \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pde pd_slot pde;\n    do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot)\n  od\n  | PageTableUnmap (ArchObjectCap (PageTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_page_table asid vaddr p;\n      slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 << pt_bits) - 1];\n      mapM_x (swp store_pte InvalidPTE) slots;\n      do_machine_op $ cleanCacheRange_PoU p (p + (1 << pt_bits) - 1)\n                                          (addrFromPPtr p)\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Invocation Dispatcher: Dispatches ARM-specific system calls to their respective handlers for page tables, page directories, pages, ASID control, ASID pools, and VCPUs. Ensures that each invocation is processed by the appropriate function, maintaining the integrity and functionality of the memory management and virtualization components.",
    "input": "",
    "output": "definition\n  arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\" where\n  \"arch_perform_invocation i \\<equiv> liftE $\n    case i of\n          InvokePageTable oper \\<Rightarrow> do perform_page_table_invocation oper; return [] od\n        | InvokePageDirectory oper \\<Rightarrow> do perform_page_directory_invocation oper; return [] od\n        | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n        | InvokeASIDControl oper \\<Rightarrow> do perform_asid_control_invocation oper; return [] od\n        | InvokeASIDPool oper \\<Rightarrow> do perform_asid_pool_invocation oper; return [] od\n        | InvokeVCPU oper \\<Rightarrow> perform_vcpu_invocation oper\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle Hypervisor Fault: Processes hypervisor fault events by converting them into architecture-specific faults and handling them accordingly.",
    "input": "",
    "output": "chapter \"Handle Hypervisor Fault Event\"\n\ntheory Hypervisor_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"word32 \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n\"handle_hypervisor_fault thread (ARMVCPUFault hsr) =\n   handle_fault thread (ArchFault $ VCPUFault hsr)\"\n\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reserve Memory Region: Reserve a specified number of bytes in memory, potentially tagging the region as kernel data. The function currently acts as a placeholder and does not perform any actual reservation or tagging.",
    "input": "",
    "output": "definition\n  reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialise Architecture-Specific Objects: Initialize architecture-specific objects based on their type, including page directories, page tables, and various page sizes. The initialization process involves copying global mappings for page directories, and cleaning cache ranges for different object types to ensure proper memory management and device handling.",
    "input": "",
    "output": "definition vs_apiobj_size where\n  \"vs_apiobj_size ty \\<equiv>\n     case ty of\n       ArchObject SmallPageObj \\<Rightarrow> pageBitsForSize ARMSmallPage\n     | ArchObject LargePageObj \\<Rightarrow> pageBitsForSize ARMLargePage\n     | ArchObject SectionObj \\<Rightarrow> pageBitsForSize ARMSection\n     | ArchObject SuperSectionObj \\<Rightarrow> pageBitsForSize ARMSuperSection\n     | ArchObject PageTableObj \\<Rightarrow> pt_bits\n     | ArchObject PageDirectoryObj \\<Rightarrow> pd_bits\"\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv> do\n     when (new_type = ArchObject PageDirectoryObj) $ mapM_x copy_global_mappings refs;\n     if \\<not>is_device \\<and>\n        new_type \\<in> {ArchObject SmallPageObj, ArchObject LargePageObj,\n                    ArchObject SectionObj, ArchObject SuperSectionObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_RAM ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else if new_type \\<in> {ArchObject PageTableObj, ArchObject PageDirectoryObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_PoU ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else\n       return ()\n   od\"\n\ndefinition\n  empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context, tcb_vcpu = None \\<rparr>\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Post Cap Deletion: No specific actions are taken after a capability is deleted.",
    "input": "",
    "output": "definition\n  arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arch_post_cap_deletion _ \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch-Specific Generic Object References: The system defines arch-specific generic object references, but they are not used in the current context, as the set of such references for any arch_cap is empty. Additionally, the cleanup operation for arch_caps results in a NullCap, indicating no specific cleanup action is defined.",
    "input": "",
    "output": "datatype arch_gen_obj_ref = unit\n\ndefinition\n  arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\"\nwhere\n  \"arch_gen_obj_refs _ = {}\"\n\ndefinition\n  arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Initialization of Kernel State: The kernel initializes various components, including the idle thread, initial TCB, interrupt node, global frame, and architecture state. This setup ensures that the kernel has a well-defined starting point, with specific memory regions and data structures allocated and configured to support system operations.",
    "input": "",
    "output": "definition\n  init_tcb_ptr :: word32 where\n  \"init_tcb_ptr = kernel_base + 0x2000\"\n\ndefinition\n  init_irq_node_ptr :: word32 where\n  \"init_irq_node_ptr = kernel_base + 0x8000\"\n\ndefinition\n  init_globals_frame :: word32 where\n  \"init_globals_frame = kernel_base + 0x5000\"\n\ndefinition\n  \"us_global_pd_ptr = kernel_base + 0x60000\"\n\ndefinition\n  \"init_arch_state \\<equiv> \\<lparr>\n    arm_asid_table = Map.empty,\n    arm_hwasid_table = Map.empty,\n    arm_next_asid = 0,\n    arm_asid_map = Map.empty,\n    arm_current_vcpu = None,\n    arm_gicvcpu_numlistregs = undefined,\n    arm_kernel_vspace = (\\<lambda>ref.\n      if ref \\<in> {kernel_base .. kernel_base + mask 20}\n      then ArmVSpaceKernelWindow\n      else ArmVSpaceInvalidRegion),\n    arm_us_global_pd = us_global_pd_ptr\n  \\<rparr>\"\n\ndefinition [simp]: \"us_global_pd \\<equiv> ArchObj (PageDirectory (\\<lambda>_. InvalidPDE))\"\n\ndefinition\n  \"init_kheap \\<equiv>\n  (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n       then Some (CNode 0 (empty_cnode 0)) else None)\n  (idle_thread_ptr \\<mapsto> TCB \\<lparr>\n    tcb_ctable = NullCap,\n    tcb_vtable = NullCap,\n    tcb_reply = NullCap,\n    tcb_caller = NullCap,\n    tcb_ipcframe = NullCap,\n    tcb_state = IdleThreadState,\n    tcb_fault_handler = replicate word_bits False,\n    tcb_ipc_buffer = 0,\n    tcb_fault = None,\n    tcb_bound_notification = None,\n    tcb_mcpriority = minBound,\n    tcb_arch = init_arch_tcb\n  \\<rparr>,\n  us_global_pd_ptr \\<mapsto> us_global_pd)\"\n\ndefinition\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. Structures_A.IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Mapping Entries: Generate the necessary page table or page directory entries to map frames of different sizes at a given virtual address, ensuring that the correct offsets and attributes are applied for small pages, large pages, sections, and super sections.",
    "input": "",
    "output": "definition largePagePTE_offsets :: \"obj_ref list\"\n  where\n  \"largePagePTE_offsets \\<equiv>\n    let pts = of_nat pte_bits\n    in [0, 2 ^ pts  .e.  (15 << pte_bits)]\"\n\ndefinition superSectionPDE_offsets :: \"obj_ref list\"\n  where\n  \"superSectionPDE_offsets \\<equiv>\n    let pts = of_nat pde_bits\n    in [0, 2 ^ pts  .e.  (15 << pde_bits)]\"\n\nfun create_mapping_entries ::\n  \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vm_rights \\<Rightarrow> vm_attributes \\<Rightarrow> word32 \\<Rightarrow>\n  ((pte * word32 list) + (pde * word32 list),'z::state_ext) se_monad\"\nwhere\n  \"create_mapping_entries base vptr ARMSmallPage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (SmallPagePTE base attrib vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMLargePage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (LargePagePTE base attrib vm_rights, map (\\<lambda>x. x + p) largePagePTE_offsets)\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SectionPDE base attrib vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSuperSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SuperSectionPDE base attrib vm_rights, map (\\<lambda>x. x + p) superSectionPDE_offsets)\n  odE\"\n\ndefinition get_master_pde :: \"word32 \\<Rightarrow> (pde,'z::state_ext)s_monad\"\n  where \"get_master_pde ptr \\<equiv> do\n    pde \\<leftarrow> (get_pde (ptr && ~~ mask 7));\n    (case pde of SuperSectionPDE _ _ _ \\<Rightarrow> return pde\n    | _ \\<Rightarrow> get_pde ptr)\n  od\"\n\ndefinition get_master_pte :: \"word32 \\<Rightarrow> (pte, 'z::state_ext)s_monad\"\n  where \"get_master_pte ptr \\<equiv> do\n    pte \\<leftarrow> (get_pte (ptr && ~~ mask 7));\n    (case pte of LargePagePTE _ _ _ \\<Rightarrow> return pte\n    | _ \\<Rightarrow> get_pte ptr)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ensure Safe Mapping: Verify that new page table or page directory entries replace either invalid entries or entries of the same granularity, preventing unsafe mappings.",
    "input": "",
    "output": "fun ensure_safe_mapping ::\n  \"(pte * word32 list) + (pde * word32 list) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n\"ensure_safe_mapping (Inl (InvalidPTE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inl (SmallPagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda>slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | SmallPagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inl (LargePagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | LargePagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inr (InvalidPDE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inr (PageTablePDE _, _)) = fail\"\n|\n\"ensure_safe_mapping (Inr (SectionPDE _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SectionPDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"\n|\n\"ensure_safe_mapping (Inr (SuperSectionPDE _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SuperSectionPDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup IPC Buffer: Verify the thread's authority to access its IPC buffer. Check if the thread has the appropriate read or write permissions for the buffer, based on whether it is the receiver or not.",
    "input": "",
    "output": "definition\nlookup_ipc_buffer :: \"bool \\<Rightarrow> word32 \\<Rightarrow> (word32 option,'z::state_ext) s_monad\" where\n\"lookup_ipc_buffer is_receiver thread \\<equiv> do\n    buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n    buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n    buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n    (case buffer_cap of\n      ArchObjectCap (PageCap _ p R vms _) \\<Rightarrow>\n        if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n        then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n        else return None\n    | _ \\<Rightarrow> return None)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate Page Directory: Find the page directory associated with a given virtual ASID by looking up the ASID in the ASID table and then in the corresponding ASID pool. If the ASID or the page directory is not found, an error is thrown.",
    "input": "",
    "output": "definition\nfind_pd_for_asid :: \"asid \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"find_pd_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pd \\<leftarrow> returnOk (pool (ucast asid));\n    (case pd of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Locate and Validate Page Directory: Locate the page directory for a given ASID and ensure it is valid by retrieving a page directory entry. If the page directory is not found, the operation fails.",
    "input": "",
    "output": "definition\nfind_pd_for_asid_assert :: \"asid \\<Rightarrow> (word32,'z::state_ext) s_monad\" where\n\"find_pd_for_asid_assert asid \\<equiv> do\n   pd \\<leftarrow> find_pd_for_asid asid <catch> K fail;\n   get_pde pd;\n   return pd\n od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Handle VM Fault: Generate a formatted VM fault message for a thread's supervisor after encountering a page fault. The message includes the fault address and relevant fault information, ensuring that the supervisor can appropriately handle the fault.",
    "input": "",
    "output": "fun\nhandle_vm_fault :: \"word32 \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n\"handle_vm_fault thread ARMDataAbort = doE\n    addr \\<leftarrow> liftE $ do_machine_op getHDFAR;\n    uaddr \\<leftarrow> liftE $ do_machine_op (addressTranslateS1 addr);\n    fault \\<leftarrow> liftE $ do_machine_op getHSR;\n    let faddr = (uaddr && complement (mask pageBits)) || (addr && mask pageBits)\n    in\n    throwError $ ArchFault $ VMFault faddr [0, fault && 0x3ffffff]\nodE\"\n|\n\"handle_vm_fault thread ARMPrefetchAbort = doE\n    pc \\<leftarrow> liftE $ as_user thread $ getRestartPC;\n    upc \\<leftarrow> liftE $ do_machine_op (addressTranslateS1 pc);\n    fault \\<leftarrow> liftE $ do_machine_op getHSR;\n    let faddr = (upc && complement (mask pageBits)) || (pc && mask pageBits)\n    in\n    throwError $ ArchFault $ VMFault faddr [1, fault && 0x3ffffff]\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Load Hardware ASID: Retrieve the optional hardware ASID associated with a given virtual ASID from the ASID map.",
    "input": "",
    "output": "definition\nload_hw_asid :: \"asid \\<Rightarrow> (hardware_asid option,'z::state_ext) s_monad\" where\n\"load_hw_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    return $ option_map fst $ asid_map asid\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Associate a hardware ASID with a virtual ASID: Store the association between a virtual ASID and a hardware ASID in the system's ASID map, and update the hardware ASID table to reflect this mapping.",
    "input": "",
    "output": "definition\nstore_hw_asid :: \"asid \\<Rightarrow> hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"store_hw_asid asid hw_asid \\<equiv> do\n    pd \\<leftarrow> find_pd_for_asid_assert asid;\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid \\<mapsto> (hw_asid, pd)));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>);\n    hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid \\<mapsto> asid));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate TLB by ASID: Clear all TLB mappings associated with a given virtual ASID. If the hardware ASID is found, it invalidates the corresponding TLB entries; otherwise, it does nothing.",
    "input": "",
    "output": "definition\ninvalidate_tlb_by_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_tlb_by_asid asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flush Virtual ASID: Flush all cache and TLB entries associated with a given virtual ASID. If the ASID is mapped to a hardware ASID, invalidate the local TLB for that hardware ASID; otherwise, perform a general cache clean operation.",
    "input": "",
    "output": "definition\nflush_space :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_space asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    do_machine_op cleanCaches_PoU;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate ASID: Remove the mapping from a specified virtual ASID to its corresponding hardware ASID, ensuring that the ASID is no longer associated with any hardware ASID in the system.",
    "input": "",
    "output": "definition\ninvalidate_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate Hardware ASID Entry: Remove the mapping from a specified hardware ASID to its corresponding virtual ASID, ensuring that the hardware ASID is no longer associated with any virtual ASID in the system.",
    "input": "",
    "output": "definition\ninvalidate_hw_asid_entry :: \"hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_hw_asid_entry hw_asid \\<equiv> do\n  hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n  hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid:= None));\n  modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Invalidate ASID Entry: Remove virtual to physical mappings for a given ASID by invalidating the hardware ASID entry if it exists, followed by invalidating the ASID itself.",
    "input": "",
    "output": "definition\ninvalidate_asid_entry :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid_entry asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  when (maybe_hw_asid \\<noteq> None) $ invalidate_hw_asid_entry (the maybe_hw_asid);\n  invalidate_asid asid\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Find Free Hardware ASID: Locate an unused hardware ASID, and if none are available, reclaim one in a round-robin manner by invalidating the current next ASID and updating the next ASID to the next value.",
    "input": "",
    "output": "definition\nfind_free_hw_asid :: \"(hardware_asid,'z::state_ext) s_monad\" where\n\"find_free_hw_asid \\<equiv> do\n    hw_asid_table \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    next_asid \\<leftarrow> gets (arm_next_asid \\<circ> arch_state);\n    maybe_asid \\<leftarrow> return (find (\\<lambda>a. hw_asid_table a = None)\n                    (take (length [minBound :: hardware_asid .e. maxBound])\n                        ([next_asid .e. maxBound] @ [minBound .e. next_asid])));\n    (case maybe_asid of\n       Some hw_asid \\<Rightarrow> return hw_asid\n     | None \\<Rightarrow>  do\n            invalidate_asid $ the $ hw_asid_table next_asid;\n            do_machine_op $ invalidateLocalTLB_ASID next_asid;\n            invalidate_hw_asid_entry next_asid;\n            new_next_asid \\<leftarrow> return (next_asid + 1);\n            modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_next_asid := new_next_asid \\<rparr>\\<rparr>);\n            return next_asid\n       od)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hardware ASID Management: Retrieve the hardware ASID associated with a given virtual ASID, and if none is assigned, allocate a new hardware ASID and store it. This ensures that each virtual ASID is correctly mapped to a unique hardware ASID, facilitating efficient context switching.",
    "input": "",
    "output": "definition\nget_hw_asid :: \"asid \\<Rightarrow> (hardware_asid,'z::state_ext) s_monad\" where\n\"get_hw_asid asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  (case maybe_hw_asid of\n    Some hw_asid \\<Rightarrow> return hw_asid\n  | None \\<Rightarrow>  do\n      new_hw_asid \\<leftarrow> find_free_hw_asid;\n      store_hw_asid asid new_hw_asid;\n      return new_hw_asid\n  od)\nod\"\n\n\nabbreviation\n  \"arm_context_switch_hwasid pd hwasid \\<equiv> writeContextIDAndPD hwasid (addrFromPPtr pd)\"\n\ndefinition\n  arm_context_switch :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arm_context_switch pd asid \\<equiv> do\n    hwasid \\<leftarrow> get_hw_asid asid;\n    do_machine_op $ arm_context_switch_hwasid pd hwasid\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU State and Register Manipulation: Provides functions to update, save, and restore VCPU-related state and registers, including the virtual GIC (VGIC) interface, individual registers, and virtual timer values. These operations ensure that the VCPU's state is accurately maintained and can be effectively managed during context switches and other system events.",
    "input": "",
    "output": "definition\n  vcpu_update :: \"obj_ref \\<Rightarrow> (vcpu \\<Rightarrow> vcpu) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_update vr f \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    set_vcpu vr (f vcpu)\n  od\"\n\ndefinition\n  vgic_update :: \"obj_ref \\<Rightarrow> (gic_vcpu_interface \\<Rightarrow> gic_vcpu_interface) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vgic_update vr f \\<equiv> vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_vgic := f (vcpu_vgic vcpu) \\<rparr> )\"\n\ndefinition\n  vgic_update_lr :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vgic_update_lr vr irq_idx virq \\<equiv>\n    vgic_update vr (\\<lambda>vgic. vgic \\<lparr> vgic_lr := (vgic_lr vgic)(irq_idx := virq) \\<rparr>)\"\n\ndefinition\n  vcpu_save_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_save_reg vr reg \\<equiv> do\n    rval \\<leftarrow> do_machine_op (readVCPUHardwareReg reg);\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := rval) \\<rparr> )\n  od\"\n\ndefinition\n  vcpu_save_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_save_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_save_reg vr reg) [from .e. to]\"\n\ndefinition\n  vcpu_restore_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_restore_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    do_machine_op (writeVCPUHardwareReg reg (vcpu_regs vcpu reg))\n  od\"\n\ndefinition\n  vcpu_restore_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_restore_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_restore_reg vr reg) [from .e. to]\"\n\ndefinition\n  vcpu_read_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word, 'z::state_ext) s_monad\"\nwhere\n  \"vcpu_read_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    return (vcpu_regs vcpu reg)\n  od\"\n\ndefinition\n  vcpu_write_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_write_reg vr reg val \\<equiv>\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := val) \\<rparr> )\"\n\ndefinition save_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"save_virt_timer vcpu_ptr \\<equiv> do\n     vcpu_save_reg vcpu_ptr VCPURegCNTV_CTL;\n     do_machine_op $ writeVCPUHardwareReg VCPURegCNTV_CTL 0;\n     cval \\<leftarrow> do_machine_op get_cntv_cval_64;\n     cntvoff \\<leftarrow> do_machine_op get_cntv_off_64;\n     vcpu_write_reg vcpu_ptr VCPURegCNTV_CVALhigh (ucast (cval >> 32));\n     vcpu_write_reg vcpu_ptr VCPURegCNTV_CVALlow (ucast cval);\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFFhigh (ucast (cntvoff >> 32));\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFFlow (ucast cntvoff);\n     cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu_update vcpu_ptr (\\<lambda>vcpu. vcpu\\<lparr>vcpu_vtimer := VirtTimer cntpct \\<rparr>)\n   od\"\n\ndefinition irq_vppi_event_index :: \"irq \\<rightharpoonup> vppievent_irq\" where\n  \"irq_vppi_event_index irq \\<equiv>\n     if irq = irqVTimerEvent\n     then Some VPPIEventIRQ_VTimer\n     else None\"\n\ndefinition restore_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"restore_virt_timer vcpu_ptr \\<equiv> do\n     cval_high \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTV_CVALhigh;\n     cval_low \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTV_CVALlow;\n     (cval :: 64 word) \\<leftarrow> return $ ((ucast cval_high) << 32) || ucast cval_low;\n     do_machine_op $ set_cntv_cval_64 cval;\n     current_cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu \\<leftarrow> get_vcpu vcpu_ptr;\n     last_pcount \\<leftarrow> return $ vtimerLastPCount $ vcpu_vtimer vcpu;\n     delta \\<leftarrow> return $ current_cntpct - last_pcount;\n     offs_high \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTVOFFhigh;\n     offs_low \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTVOFFlow;\n     (offset :: 64 word) \\<leftarrow> return $ (((ucast offs_high) << 32) || ucast offs_low) + delta;\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFFhigh (ucast (offset >> 32));\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFFlow (ucast offset);\n     do_machine_op $ set_cntv_off_64 offset;\n     masked \\<leftarrow> return $ (vcpu_vppi_masked vcpu (the $ irq_vppi_event_index irqVTimerEvent));\n     \\<comment> \\<open>we do not know here that irqVTimerEvent is IRQReserved, therefore not IRQInactive,\n        so the only way to prove we don't unmask an inactive interrupt is to check\\<close>\n     safe_to_unmask \\<leftarrow> is_irq_active irqVTimerEvent;\n     when safe_to_unmask $ do_machine_op $ maskInterrupt masked irqVTimerEvent;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTV_CTL\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VPCU Mode Disabling: Disables the VPCU mode on the hardware level by turning off the VGIC, SI MMU, and setting the HCR to its native state. Additionally, it saves the VCPU register and virtual timer, and masks the virtual timer interrupt if a VCPU reference is provided.",
    "input": "",
    "output": "definition\n  vcpu_disable :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_disable vo \\<equiv> do\n    do_machine_op dsb;\n    (case vo of\n      Some vr \\<Rightarrow> do\n        hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n        vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n        vcpu_save_reg vr VCPURegSCTLR;\n        do_machine_op isb\n      od\n    | _ \\<Rightarrow> return ());\n    do_machine_op $ do\n        set_gic_vcpu_ctrl_hcr 0; \\<comment> \\<open>turn VGIC off\\<close>\n        isb;\n        setSCTLR sctlrDefault; \\<comment> \\<open>turn SI MMU off\\<close>\n        setHCR hcrNative;\n        isb\n      od;\n    case vo of\n      Some vr \\<Rightarrow> do\n          save_virt_timer vr;\n          do_machine_op $ maskInterrupt True irqVTimerEvent\n        od\n      | _ \\<Rightarrow> return ()\n    od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Enable VCPU Mode: Activate the VCPU mode on the hardware level by restoring the VCPU register, setting the HCR for VCPU, updating the GIC VCPU control, and restoring the virtual timer.",
    "input": "",
    "output": "definition\n  vcpu_enable :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_enable vr \\<equiv> do\n     vcpu_restore_reg vr VCPURegSCTLR;\n     vcpu \\<leftarrow> get_vcpu vr;\n     do_machine_op $ do\n        setHCR hcrVCPU;\n        isb;\n        set_gic_vcpu_ctrl_hcr (vgic_hcr $ vcpu_vgic vcpu)\n     od;\n     restore_virt_timer vr\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Prepare VCPU for Removal: Invalidate the active VCPU by disabling it and clearing the current VCPU reference in the system state.",
    "input": "",
    "output": "definition\n  vcpu_invalidate_active :: \"(unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_invalidate_active \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    case cur_v of\n      Some (vr, True) \\<Rightarrow> vcpu_disable None\n    | _ \\<Rightarrow> return ();\n    modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := None \\<rparr>\\<rparr>)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Dissociate VCPU and TCB: Ensures the removal of the connection between a TCB and a VCPU, invalidating the active VCPU if it is the one being dissociated. It also sanitizes the CPSR register for the TCB to maintain system integrity.",
    "input": "",
    "output": "definition dissociate_vcpu_tcb :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere \"dissociate_vcpu_tcb vr t \\<equiv> do\n  t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n  v \\<leftarrow> get_vcpu vr;\n  assert (t_vcpu = Some vr \\<and> vcpu_tcb v = Some t); \\<comment> \\<open>make sure they were associated\\<close>\n  cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n  when (\\<exists>a. cur_v = Some (vr,a)) vcpu_invalidate_active;\n  arch_thread_set (\\<lambda>x. x \\<lparr> tcb_vcpu := None \\<rparr>) t;\n  set_vcpu vr (v\\<lparr> vcpu_tcb := None \\<rparr>);\n  as_user t $ do\n    cpsr \\<leftarrow> getRegister CPSR;\n    setRegister CPSR $ sanitise_register False CPSR cpsr\n  od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Save: Saves the state of a VCPU, including its registers and context. It updates the VCPU's control registers, saves the virtual timer, and retrieves and updates the GIC (Generic Interrupt Controller) related registers. This ensures that the VCPU's state is preserved and can be restored accurately.",
    "input": "",
    "output": "definition\n  vcpu_save :: \"(obj_ref \\<times> bool) option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_save vb \\<equiv>\n     case vb\n     of Some (vr, active) \\<Rightarrow> do\n          do_machine_op dsb;\n\n          when active $ do\n            vcpu_save_reg vr VCPURegSCTLR;\n            hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n            vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n            save_virt_timer vr\n          od;\n\n          vmcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_vmcr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_vmcr := vmcr\\<rparr>);\n\n          apr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_apr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_apr := apr\\<rparr>);\n\n          num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n          gicIndices \\<leftarrow> return [0..<num_list_regs];\n\n          mapM (\\<lambda>vreg. do\n                    val \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat vreg);\n                    vgic_update_lr vr vreg val\n                  od)\n            gicIndices;\n\n          vcpu_save_reg_range vr VCPURegACTLR VCPURegSPSRfiq;\n          do_machine_op isb\n       od\n     | _ \\<Rightarrow> fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Vcpu Restore: Restores the VCPU's state by turning off the VGIC, restoring GIC VCPU control state, setting specific GIC VCPU control registers, and restoring a range of banked VCPU registers, followed by enabling the VCPU.",
    "input": "",
    "output": "definition\n  vcpu_restore :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_restore vr \\<equiv> do\n     do_machine_op $ set_gic_vcpu_ctrl_hcr 0;  \\<comment> \\<open>turn off VGIC\\<close>\n     do_machine_op $ isb;\n     vcpu \\<leftarrow> get_vcpu vr;  \\<comment> \\<open>restore GIC VCPU control state\\<close>\n     vgic \\<leftarrow> return (vcpu_vgic vcpu);\n     num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     gicIndices \\<leftarrow> return [0..<num_list_regs];\n     do_machine_op $ do\n         set_gic_vcpu_ctrl_vmcr (vgic_vmcr vgic);\n         set_gic_vcpu_ctrl_apr (vgic_apr vgic);\n         mapM (\\<lambda>p. set_gic_vcpu_ctrl_lr (of_nat (fst p)) (snd p))\n              (map (\\<lambda>i. (i, (vgic_lr vgic) i)) gicIndices)\n     od;\n    \\<comment> \\<open>restore banked VCPU registers except SCTLR (that's in VCPUEnable)\\<close>\n     vcpu_restore_reg_range vr VCPURegACTLR VCPURegSPSRfiq;\n     vcpu_enable vr\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Switching: Switch the active VCPU to a new one, or mark the current VCPU as inactive and disable VCPU mode if no new VCPU is provided. If the new VCPU is different from the current one, save the state of the current VCPU and restore the state of the new VCPU. If the same VCPU is being reactivated, enable it and update its active status.",
    "input": "",
    "output": "definition vcpu_switch :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_switch v \\<equiv> case v of\n   None \\<Rightarrow> do\n     cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (case cur_v of\n        None \\<Rightarrow> return () \\<comment> \\<open>both null, current cannot be active\\<close>\n      | Some (vr, active) \\<Rightarrow> do \\<comment> \\<open>switch to thread without vcpu\\<close>\n          when active $ do  \\<comment> \\<open> save state if not saved already\\<close>\n            vcpu_disable (Some vr);\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (vr, False) \\<rparr>\\<rparr>)\n          od;\n          return ()\n        od)\n     od\n | Some new \\<Rightarrow> do\n     cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (case cur_v of\n        None \\<Rightarrow> do \\<comment> \\<open>switch to the new vcpu with no current one\\<close>\n          vcpu_restore new;\n          modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n        od\n      | Some (vr, active) \\<Rightarrow> \\<comment> \\<open>switch from an existing vcpu\\<close>\n          (if vr \\<noteq> new\n          then do \\<comment> \\<open>different vcpu\\<close>\n            vcpu_save cur_v;\n            vcpu_restore new;\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n          od\n          else \\<comment> \\<open>same vcpu\\<close>\n            when (\\<not> active) $ do\n              do_machine_op isb;\n              vcpu_enable new;\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n            od))\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Associate and Dissociate VCPU and TCB: Ensures a TCB is associated with a VCPU, and any existing associations are removed. This process maintains the integrity of the TCB-VCPU relationship, ensuring that each TCB is correctly linked to a single VCPU and vice versa. If the TCB being associated is the current thread, a VCPU switch is performed to reflect the new association.",
    "input": "",
    "output": "definition associate_vcpu_tcb :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"associate_vcpu_tcb vr t \\<equiv> do\n    t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n    case t_vcpu of Some p \\<Rightarrow> dissociate_vcpu_tcb p t\n                 | _ \\<Rightarrow> return ();\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of Some p \\<Rightarrow> dissociate_vcpu_tcb vr p\n                     | _ \\<Rightarrow> return ();\n    arch_thread_set (\\<lambda>x. x \\<lparr> tcb_vcpu := Some vr \\<rparr>) t;\n    set_vcpu vr (v\\<lparr> vcpu_tcb := Some t \\<rparr>);\n    ct \\<leftarrow> gets cur_thread;\n    when (t = ct) $ vcpu_switch (Some vr)\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "VCPU Finalization: Prepare a VCPU for removal by dissociating it from its associated TCB, if any, and cleaning up the current VCPU state.",
    "input": "",
    "output": "definition vcpu_finalise :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_finalise vr \\<equiv> do\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of\n      Some t \\<Rightarrow> dissociate_vcpu_tcb vr t\n    | None \\<Rightarrow> return ()\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Set VM Root: Switch the address space to the one associated with a given thread, using its page directory and ASID. If the thread's root is invalid or not correctly configured, switch to the global address space. This ensures that the system operates within a valid and correctly configured address space, maintaining the integrity and security of memory access.",
    "input": "",
    "output": "definition\n  set_vm_root :: \"word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow> doE\n           pd' \\<leftarrow> find_pd_for_asid asid;\n           whenE (pd \\<noteq> pd') $ throwError InvalidRoot;\n           liftE $ arm_context_switch pd asid\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_us_pd \\<leftarrow> gets (arm_us_global_pd o arch_state);\n       do_machine_op $ set_current_pd $ addrFromKPPtr global_us_pd\n    od)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Pool Deletion: Before deleting an ASID pool, deactivate all page directories installed in it by flushing and invalidating their entries. Update the ASID table to remove the reference to the deleted pool and set the VM root for the current thread.",
    "input": "",
    "output": "definition\ndelete_asid_pool :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid_pool base ptr \\<equiv> do\n  assert (base && mask asid_low_bits = 0);\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n    pool \\<leftarrow> get_asid_pool ptr;\n    mapM (\\<lambda>offset. (when (pool (ucast offset) \\<noteq> None) $ do\n                          flush_space $ base + offset;\n                          invalidate_asid_entry $ base + offset\n                    od)) [0  .e.  (1 << asid_low_bits) - 1];\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>);\n    tcb \\<leftarrow> gets cur_thread;\n    set_vm_root tcb\n  od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Delete ASID: Deactivate and remove a page directory from an ASID pool. If the ASID is found in the pool, it flushes the space, invalidates the ASID entry, updates the pool to remove the page directory, and sets the VM root for the current thread.",
    "input": "",
    "output": "definition\ndelete_asid :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pd \\<equiv> do\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  (case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (ucast asid) = Some pd) $ do\n                flush_space asid;\n                invalidate_asid_entry asid;\n                pool' \\<leftarrow> return (pool (ucast asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od)\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Address Space Switch for Flush: Switch to a specific address space to perform a flush operation. If the current page directory does not match the target, a context switch is performed, and the flush operation is executed. The type of flush (clean, invalidate, clean-invalidate, or unify) determines the specific cache operations to be carried out.",
    "input": "",
    "output": "definition\nset_vm_root_for_flush :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"set_vm_root_for_flush pd asid \\<equiv> do\n    tcb \\<leftarrow> gets cur_thread;\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    not_is_pd \\<leftarrow> (case thread_root of\n                    ArchObjectCap (PageDirectoryCap cur_pd (Some _)) \\<Rightarrow> return (cur_pd \\<noteq> pd)\n                  | _ \\<Rightarrow> return True);\n    (if not_is_pd then do\n        arm_context_switch pd asid;\n        return True\n    od\n    else return False)\nod\"\n\ndefinition\ndo_flush :: \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\" where\n\"do_flush flush_type vstart vend pstart \\<equiv>\n    let vstart' = ptrFromPAddr pstart;\n        vend'  = vstart' + (vend - vstart)\n    in\n    (case flush_type of\n       Clean \\<Rightarrow> cleanCacheRange_RAM vstart' vend' pstart\n     | Invalidate \\<Rightarrow> invalidateCacheRange_RAM vstart' vend' pstart\n     | CleanInvalidate \\<Rightarrow> cleanInvalidateCacheRange_RAM vstart' vend' pstart\n     | Unify \\<Rightarrow> do\n         cleanCacheRange_PoU vstart' vend' pstart;\n         dsb;\n         invalidateCacheRange_I vstart' vend' pstart;\n         branchFlushRange vstart' vend' pstart;\n         isb\n     od)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flush Page Table Mappings: Invalidate the local TLB for a given ASID and flush mappings associated with a page table. If the hardware ASID is present, perform the invalidation and, if the VM root was switched, reset it to the current thread's VM root.",
    "input": "",
    "output": "definition\nflush_table :: \"word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_table pd asid vptr pt \\<equiv> do\n    assert (vptr && mask (pageBitsForSize ARMSection) = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_ASID hw_asid;\n      when root_switched $ do\n        tcb \\<leftarrow> gets cur_thread;\n        set_vm_root tcb\n      od\n    od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Flush Page Mappings: Invalidate the mappings associated with a given page in the virtual address space. This involves setting the virtual machine root for flushing, loading the hardware ASID, and invalidating the local TLB if the hardware ASID is present. If the root was switched during the process, it is reset to the current thread's virtual machine root.",
    "input": "",
    "output": "definition\nflush_page :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_page page_size pd asid vptr\\<equiv> do\n    assert (vptr && mask pageBits = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_VAASID (vptr || ucast hw_asid);\n      when root_switched $ do\n          tcb \\<leftarrow> gets cur_thread;\n          set_vm_root tcb\n      od\n   od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Mapping: Determine the page directory in which a given page table is mapped, if any. The function checks the page directory for the specified ASID and virtual address, and returns the page directory if the page table is found, otherwise it returns None.",
    "input": "",
    "output": "definition\npage_table_mapped :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n\"page_table_mapped asid vaddr pt \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    pd_slot \\<leftarrow> returnOk $ lookup_pd_slot pd vaddr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    case pde of\n      PageTablePDE addr \\<Rightarrow> returnOk $\n             if addrFromPPtr pt = addr then Some pd else None\n    | _ \\<Rightarrow> returnOk None\nodE <catch> (K $ return None)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page Table: Unmaps a specified page table from its page directory. If the page table is found, it invalidates the corresponding page directory entry, cleans the cache, and flushes the table to ensure the changes are effective.",
    "input": "",
    "output": "definition\nunmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page_table asid vaddr pt \\<equiv> do\n    pdOpt \\<leftarrow> page_table_mapped asid vaddr pt;\n    case pdOpt of\n      None \\<Rightarrow> return ()\n    | Some pd \\<Rightarrow> do\n        pd_slot \\<leftarrow> return $ lookup_pd_slot pd vaddr;\n        store_pde pd_slot InvalidPDE;\n        do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot);\n        flush_table pd asid vaddr pt\n    od\nod\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Mapping Validity: Verify that a given frame is correctly mapped by a specified mapping entry, ensuring the physical page address and page size match the expected values for the corresponding page table or page directory entry.",
    "input": "",
    "output": "definition\ncheck_mapping_pptr :: \"obj_ref \\<Rightarrow> vmpage_size \\<Rightarrow> (obj_ref + obj_ref) \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"check_mapping_pptr pptr pgsz tablePtr \\<equiv> case tablePtr of\n   Inl ptePtr \\<Rightarrow> do\n     pte \\<leftarrow> get_pte ptePtr;\n     return $ case pte of\n       SmallPagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSmallPage\n     | LargePagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMLargePage\n     | _ \\<Rightarrow> False\n   od\n | Inr pdePtr \\<Rightarrow> do\n     pde \\<leftarrow> get_pde pdePtr;\n     return $ case pde of\n       SectionPDE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSection\n     | SuperSectionPDE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSuperSection\n     | _ \\<Rightarrow> False\n   od\"\n\n\ndefinition\n  \"last_byte_pte x \\<equiv> x + ((1 << pte_bits) - 1)\"\n\ndefinition\n  \"last_byte_pde x \\<equiv> x + ((1 << pde_bits) - 1)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Unmap Page: Unmaps a page from the virtual address space if the provided mapping details are still current. This involves finding the appropriate page directory, checking the mapping, invalidating the corresponding page table entry or page directory entry, and cleaning the cache. The operation ensures that the page is properly unmapped and the cache is updated to reflect the changes.",
    "input": "",
    "output": "definition\nunmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page pgsz asid vptr pptr \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    (case pgsz of\n          ARMSmallPage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                store_pte p InvalidPTE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMLargePage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                assert $ p && mask 7 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) largePagePTE_offsets);\n                mapM (swp store_pte InvalidPTE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE\n        | ARMSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                store_pde p InvalidPDE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMSuperSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                assert $ p && mask 7 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) superSectionPDE_offsets);\n                mapM (swp store_pde InvalidPDE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE);\n    liftE $ flush_page pgsz pd asid vptr\nodE <catch> (K $ return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capability Derivation: Ensures that PageTable and PageDirectory capabilities can only be derived if they have a virtual ASID and location assigned. If these conditions are not met, an illegal operation error is thrown. Other architectural capabilities, such as Page, ASIDControl, ASIDPool, and VCPU, are derived without additional checks.",
    "input": "",
    "output": "definition\n  arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\"\nwhere\n  \"arch_derive_cap c \\<equiv> case c of\n     PageTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageTableCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageDirectoryCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageDirectoryCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageCap dev r R pgs x \\<Rightarrow> returnOk (ArchObjectCap (PageCap dev r R pgs None))\n   | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n   | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\n   | VCPUCap _ \\<Rightarrow> returnOk (ArchObjectCap c)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Update Capability Data: Ensures that no user-modifiable data is stored in ARM-specific capabilities, maintaining the integrity and security of the system.",
    "input": "",
    "output": "definition\n  arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capability Finalization: Perform specific actions to finalize AR_MHYP-specific capabilities, such as deleting ASID pools, unmapping page directories, page tables, and pages, and finalizing VCPUs. These actions ensure that the resources associated with these capabilities are properly released and cleaned up. \n\nThread Deletion Preparation: Prepare a thread for deletion by dissociating its VCPU, if it exists, ensuring that the thread's resources are properly managed before it is removed.",
    "input": "",
    "output": "definition\n  arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n    (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n    delete_asid_pool b ptr;\n    return (NullCap, NullCap)\n    od\n  | (PageDirectoryCap ptr (Some a), True) \\<Rightarrow> do\n    delete_asid a ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n    unmap_page_table a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageCap _ ptr _ s (Some (a, v)), _) \\<Rightarrow> do\n     unmap_page s a v ptr;\n     return (NullCap, NullCap)\n  od\n  | (VCPUCap vcpu_ref, True) \\<Rightarrow> do\n     vcpu_finalise vcpu_ref;\n     return (NullCap, NullCap)\n  od\n  | _ \\<Rightarrow> return (NullCap, NullCap)\"\n\ndefinition\n  prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"prepare_thread_delete p \\<equiv> do\n   t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu p;\n   case t_vcpu of\n   Some v \\<Rightarrow> dissociate_vcpu_tcb v p\n | None \\<Rightarrow> return ()\n od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Valid IPC Buffer: Ensures that the virtual address space capability for an IPC buffer is a valid page directory. If the capability is a non-page-directory, it throws an illegal operation error. For a page capability, it checks alignment and throws an alignment error if not properly aligned.",
    "input": "",
    "output": "definition\n  is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv> \\<exists>r a. c = ArchObjectCap (PageDirectoryCap r (Some a))\"\n\ndefinition\ncheck_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n\"check_valid_ipc_buffer vptr c \\<equiv> case c of\n  (ArchObjectCap (PageCap False _ _ _ _)) \\<Rightarrow> doE\n    whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError;\n    returnOk ()\n  odE\n| _ \\<Rightarrow> throwError IllegalOperation\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode VM Attributes: Extract and decode the virtual memory attributes from a 32-bit word, determining if the mapping should be cacheable and if it should have the XNever attribute.",
    "input": "",
    "output": "definition\nattribs_from_word :: \"word32 \\<Rightarrow> vm_attributes\" where\n\"attribs_from_word w \\<equiv>\n  let V = (if w !!0 then {PageCacheable} else {})\n  in if w!!2 then insert XNever V else V\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update Mapping Data: Modify the mapping data associated with a page or page table capability. This ensures that the capability's mapping information is updated to reflect the new values, maintaining the integrity of the memory management system.",
    "input": "",
    "output": "definition\n  update_map_data :: \"arch_cap \\<Rightarrow> (word32 \\<times> word32) option \\<Rightarrow> arch_cap\" where\n  \"update_map_data cap m \\<equiv> case cap of PageCap dev p R sz _ \\<Rightarrow> PageCap dev p R sz m\n                                     | PageTableCap p _ \\<Rightarrow> PageTableCap p m\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Resolve Virtual Address: Determine the frame size and corresponding object reference for a given virtual address by traversing the page directory and page table entries. This process identifies the type of frame (section, super section, large page, or small page) and its associated frame object, enabling accurate memory management and access.",
    "input": "",
    "output": "definition\n  resolve_vaddr :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> ((vmpage_size \\<times> obj_ref) option, 'z::state_ext) s_monad\"\nwhere\n  \"resolve_vaddr pd vaddr \\<equiv> do\n     pd_slot \\<leftarrow> return $ lookup_pd_slot pd vaddr;\n     pde \\<leftarrow> get_master_pde pd_slot;\n     case pde of\n         SectionPDE f _ _ \\<Rightarrow> return $ Some (ARMSection, f)\n       | SuperSectionPDE f _ _ \\<Rightarrow> return $ Some (ARMSuperSection, f)\n       | PageTablePDE t \\<Rightarrow> (do\n           pt \\<leftarrow> return $ ptrFromPAddr t;\n           pte_slot \\<leftarrow> return $ lookup_pt_slot_no_fail pt vaddr;\n           pte \\<leftarrow> get_master_pte pte_slot;\n           case pte of\n               LargePagePTE f _ _ \\<Rightarrow> return $ Some (ARMLargePage, f)\n             | SmallPagePTE f _ _ \\<Rightarrow> return $ Some (ARMSmallPage, f)\n             | _ \\<Rightarrow> return None\n         od)\n       | _ \\<Rightarrow> return None\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Pointer in User Frame: A pointer is considered to be inside a user frame if its top bits, when masked, point to a data page in the kernel heap.",
    "input": "",
    "output": "definition\n  in_user_frame :: \"word32 \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n  \"in_user_frame p s \\<equiv>\n   \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) =\n        Some (ArchObj (DataPage False sz))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Numeric Value Visibility: Ensure the numeric value of `msg_align_bits` is explicitly visible for clarity and ease of use.",
    "input": "",
    "output": "lemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID High Bits Extraction: Extract the high 7 bits of a given ASID by right-shifting the ASID and converting it to a 7-bit word.",
    "input": "",
    "output": "text \\<open>The high bits of a virtual ASID.\\<close>\ndefinition\n  asid_high_bits_of :: \"asid \\<Rightarrow> 7 word\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Heap Access: Manipulate ASID pools, page directories, and page tables within the kernel heap to manage memory and address space effectively.",
    "input": "",
    "output": "text \\<open>Manipulate ASID pools, page directories and page tables in the kernel\nheap.\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM VSpace Accessors: Provide functions to get and set ASID pools, VCPUs, and page directories in the kernel heap, enabling the management and manipulation of virtual address spaces.",
    "input": "",
    "output": "locale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\"\n  where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"\n\ndefinition\n  get_asid_pool :: \"obj_ref \\<Rightarrow> (10 word \\<rightharpoonup> obj_ref,'z::state_ext) s_monad\" where\n  \"get_asid_pool ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (ASIDPool pool) \\<Rightarrow> return pool\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_asid_pool :: \"obj_ref \\<Rightarrow> (10 word \\<rightharpoonup> obj_ref) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"set_asid_pool ptr pool \\<equiv> set_object ptr (ArchObj (arch_kernel_obj.ASIDPool pool))\"\n\ndefinition\n  get_vcpu :: \"obj_ref \\<Rightarrow> (vcpu,'z::state_ext) s_monad\" where\n  \"get_vcpu ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (VCPU v) \\<Rightarrow> return v\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_vcpu :: \"obj_ref \\<Rightarrow> vcpu \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_vcpu ptr vcpu \\<equiv> set_object ptr (ArchObj (VCPU vcpu))\"\n\ndefinition\n  get_pd :: \"obj_ref \\<Rightarrow> (11 word \\<Rightarrow> pde,'z::state_ext) s_monad\" where\n  \"get_pd ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageDirectory pd) \\<Rightarrow> return pd\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pd :: \"obj_ref \\<Rightarrow> (11 word \\<Rightarrow> pde) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pd ptr pd \\<equiv> set_object ptr (ArchObj (PageDirectory pd))\"\n\ndefinition\n  set_current_pd :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_current_pd pd \\<equiv> setCurrentPDPL2 pd\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Page Directory Access: Retrieve and modify the page table entries (PTEs) and page directory entries (PDEs) in the ARM VSpace. The functions allow for accessing and updating specific entries in the page tables and directories, ensuring that the memory mappings are correctly managed and maintained.",
    "input": "",
    "output": "definition\n  get_pde :: \"obj_ref \\<Rightarrow> (pde,'z::state_ext) s_monad\" where\n  \"get_pde ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pd_bits);\n     offset \\<leftarrow> return ((ptr && mask pd_bits) >> pde_bits);\n     pd \\<leftarrow> get_pd base;\n     return $ pd (ucast offset)\n   od\"\n\ndefinition\n  store_pde :: \"obj_ref \\<Rightarrow> pde \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pde p pde \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pd_bits);\n    offset \\<leftarrow> return ((p && mask pd_bits) >> pde_bits);\n    pd \\<leftarrow> get_pd base;\n    pd' \\<leftarrow> return $ pd (ucast offset := pde);\n    set_pd base pd'\n  od\"\n\n\ndefinition\n  get_pt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pte,'z::state_ext) s_monad\" where\n  \"get_pt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pt ptr pt \\<equiv> set_object ptr (ArchObj (PageTable pt))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Entry Access: Retrieve and store PTEs in the page table. The functions calculate the base address and offset of the PTE, access the page table, and either return or update the PTE at the specified location.",
    "input": "",
    "output": "definition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> pte_bits);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> pte_bits);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Copy Global Mappings: Copies the mappings that create the kernel window into a new page directory object, ensuring that the kernel window is accessible from the specified base pointer in every virtual address space.",
    "input": "",
    "output": "text \\<open>The kernel window is mapped into every virtual address space from the\n@{term kernel_base} pointer upwards. This function copies the mappings which\ncreate the kernel window into a new page directory object.\\<close>\ndefinition\ncopy_global_mappings :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"copy_global_mappings new_pd \\<equiv> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Compute Page Directory Entry Pointer: Given a page-directory reference and a virtual address, calculate the pointer to the corresponding page directory entry in kernel memory.",
    "input": "",
    "output": "definition\nlookup_pd_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> word32\" where\n\"lookup_pd_slot pd vptr \\<equiv>\n    let pd_index = vptr >> (pageBits + pt_bits - pte_bits) \\<comment> \\<open>ARMHYP\\<close>\n    in pd + (pd_index << pde_bits)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup Page Table Slot: Computes a pointer to the PTE in kernel memory for a given page-directory reference and virtual address. The function fails if the virtual address is mapped on a section or super section, ensuring that only valid page table entries are accessed.",
    "input": "",
    "output": "definition\nlookup_pt_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"lookup_pt_slot pd vptr \\<equiv> doE\n    pd_slot \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    (case pde of\n          PageTablePDE ptab \\<Rightarrow>   (doE\n            pt \\<leftarrow> returnOk (ptrFromPAddr ptab);\n            pt_index \\<leftarrow> returnOk ((vptr >> pageBits) && mask (pt_bits - pte_bits));\n            pt_slot \\<leftarrow> returnOk (pt + (pt_index << pte_bits));\n            returnOk pt_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability 21)\nodE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lookup Page Table Slot: Computes the address of a page table slot given a known page table and a virtual page number, ensuring that the operation does not fail.",
    "input": "",
    "output": "definition\n  lookup_pt_slot_no_fail :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> word32\"\nwhere\n  \"lookup_pt_slot_no_fail pt vptr \\<equiv>\n     let pt_index = ((vptr >> pageBits) && mask (pt_bits - pte_bits))\n     in pt + (pt_index << pte_bits)\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Virtual Page Alignment: Ensure that the given virtual page pointer is aligned to the specified page size, throwing an alignment error if the condition is not met.",
    "input": "",
    "output": "text \\<open>This definition ensures that the given pointer is aligned\nto the given page size.\\<close>\n\ndefinition\n  check_vp_alignment :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $\n       throwError AlignmentError\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Convert Invocation Label to Flush Type: Maps architecture-specific invocation labels to corresponding flush types, enabling the system to determine the appropriate method for handling memory operations such as cleaning, invalidating, or unifying data and instructions.",
    "input": "",
    "output": "definition\n  label_to_flush_type :: \"invocation_label \\<Rightarrow> flush_type\"\nwhere\n  \"label_to_flush_type label \\<equiv> case label of\n       ArchInvocationLabel ARMPDClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPageClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPDInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPageInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPDCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPageCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPDUnify_Instruction \\<Rightarrow> Unify\n     | ArchInvocationLabel ARMPageUnify_Instruction \\<Rightarrow> Unify\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Base Calculation: Compute the base address of a page given a virtual address and the size of the memory page. This ensures that the base address is aligned to the page boundary, facilitating efficient memory management and access.",
    "input": "",
    "output": "text \\<open>This definition decodes architecture-specific invocations.\n\\<close>\n\ndefinition\n  page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\nwhere\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode MMU Invocations: Decode architecture-specific system calls related to memory management, including operations on page directories, page tables, and pages. The decoding process validates the arguments, checks for valid capabilities, and performs specific actions such as mapping, unmapping, and flushing, ensuring the integrity and security of the memory management unit. \n\n- **Page Directory Operations**: Validate and decode operations for flushing page directories, ensuring that the provided addresses and ranges are valid and within the allowed limits.\n- **Page Table Operations**: Decode operations for mapping and unmapping page tables, validating the provided addresses, and ensuring the correct parent directory and ASID are used.\n- **Page Operations**: Decode operations for mapping, unmapping, and flushing pages, validating the provided addresses, rights, and attributes, and ensuring the correct parent directory and ASID are used.\n- **ASID Control Operations**: Decode operations for creating ASID pools, ensuring that the provided untyped capability is valid and the destination slot is empty.\n- **ASID Pool Operations**: Decode operations for assigning ASIDs to page directories, ensuring that the provided ASID pool and page directory capabilities are valid and the ASID is available.",
    "input": "",
    "output": "definition\n  isIOSpaceFrame :: \"arch_cap \\<Rightarrow> bool\"\n  where \"isIOSpaceFrame c \\<equiv> False\"\n\ndefinition\n  decode_mmu_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_mmu_invocation label args x_slot cte cap extra_caps \\<equiv>\ncase cap of\n\n  PageDirectoryCap _ _ \\<Rightarrow>\n    if isPDFlushLabel (invocation_type label) then\n    if length args > 1\n    then let start = args ! 0;\n             end = args ! 1\n    in doE\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            whenE (start \\<ge> kernel_base \\<or> end > kernel_base) $ throwError IllegalOperation;\n            (pd,asid) \\<leftarrow> (case cap of\n                    PageDirectoryCap pd (Some asid) \\<Rightarrow> returnOk (pd,asid)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 0);\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 0;\n            frame_info \\<leftarrow> liftE $ resolve_vaddr pd start;\n            case frame_info of\n                None \\<Rightarrow> returnOk $ InvokePageDirectory PageDirectoryNothing\n              | Some (frame_size, frame_base) \\<Rightarrow>\n                    let base_start = page_base start frame_size;\n                        base_end = page_base (end - 1) frame_size;\n                        offset = start && mask (pageBitsForSize frame_size);\n                        pstart = frame_base + offset\n                    in doE\n                        whenE (base_start \\<noteq> base_end) $ throwError $\n                            RangeError start (base_start + mask (pageBitsForSize frame_size));\n                        returnOk $ InvokePageDirectory $\n                            PageDirectoryFlush (label_to_flush_type (invocation_type label))\n                            start (end - 1) pstart pd asid\n                    odE\n    odE\n    else throwError TruncatedMessage\n    else throwError IllegalOperation\n\n| PageTableCap p mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageTableMap then\n    if length args > 1 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             pd_cap = fst (extra_caps ! 0)\n    in doE\n            whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            whenE (vaddr \\<ge> kernel_base) $ throwError $ InvalidArgument 0;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            pd_index \\<leftarrow> returnOk (shiftr vaddr (pageBits + pt_bits - pte_bits));\n            vaddr' \\<leftarrow> returnOk (vaddr && ~~ mask (pageBits + pt_bits - pte_bits));\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << pde_bits));\n            oldpde \\<leftarrow> liftE $ get_master_pde pd_slot;\n            unlessE (oldpde = InvalidPDE) $ throwError DeleteFirst;\n            pde \\<leftarrow> returnOk (PageTablePDE (addrFromPPtr p));\n            returnOk $ InvokePageTable $\n                PageTableMap\n                (ArchObjectCap $ PageTableCap p (Some (asid, vaddr')))\n                cte pde pd_slot\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageTableUnmap\n    then doE\n            final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n            unlessE final $ throwError RevokeFirst;\n            returnOk $ InvokePageTable $ PageTableUnmap (ArchObjectCap cap) cte\n    odE\n    else throwError IllegalOperation\n\n| PageCap dev p R pgsz mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageMap then\n    if length args > 2 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             rights_mask = args ! 1;\n             attr = args ! 2;\n             pd_cap = fst (extra_caps ! 0)\n        in doE\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            case mapped_address of\n              Some (asid', vaddr') \\<Rightarrow> doE\n                whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n                whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0)\n              odE\n            | None \\<Rightarrow> doE\n                vtop \\<leftarrow> returnOk (vaddr + (1 << (pageBitsForSize pgsz)) - 1);\n                whenE (vtop \\<ge> kernel_base) $ throwError $ InvalidArgument 0\n              odE;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            vm_rights \\<leftarrow> returnOk (mask_vm_rights R (data_to_rights rights_mask));\n            check_vp_alignment pgsz vaddr;\n            entries \\<leftarrow> create_mapping_entries (addrFromPPtr p)\n                                              vaddr pgsz vm_rights\n                                              (attribs_from_word attr) pd;\n            ensure_safe_mapping entries;\n            returnOk $ InvokePage $ PageMap asid\n                (ArchObjectCap $ PageCap dev p R pgsz (Some (asid, vaddr)))\n                cte entries\n        odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageUnmap\n    then  returnOk $ InvokePage $ PageUnmap cap cte\n    else if isPageFlushLabel (invocation_type label) then\n        if length args > 1\n        then let start = args ! 0;\n                 end = args ! 1;\n                 pstart = start + addrFromPPtr p\n        in doE\n            (asid, _) \\<leftarrow> (case mapped_address of\n                Some a \\<Rightarrow> returnOk a\n              | _ \\<Rightarrow> throwError IllegalOperation);\n            pd \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            page_size \\<leftarrow> returnOk $ 1 << pageBitsForSize pgsz;\n            whenE (start \\<ge> page_size \\<or> end > page_size) $ throwError $ InvalidArgument 0;\n            whenE (pstart < physBase \\<or> ((end - start) + pstart) > paddrTop) $ throwError IllegalOperation;\n            returnOk $ InvokePage $ PageFlush\n                (label_to_flush_type (invocation_type label)) (start + p) \\<comment> \\<open>check\\<close>\n                (end + p - 1) pstart pd asid\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageGetAddress\n    then returnOk $ InvokePage $ PageGetAddr p\n  else  throwError IllegalOperation\n\n| ASIDControlCap \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMASIDControlMakePool then\n    if length args > 1 \\<and> length extra_caps > 1\n    then let index = args ! 0;\n             depth = args ! 1;\n             (untyped, parent_slot) = extra_caps ! 0;\n             root = fst (extra_caps ! 1)\n         in doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            free_set \\<leftarrow> returnOk (- dom asid_table \\<inter> {x. x \\<le> (1 << asid_high_bits) - 1});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n            base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n            (p,n) \\<leftarrow> (case untyped of UntypedCap False p n f \\<Rightarrow> returnOk (p,n)\n                                    | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            frame \\<leftarrow> (if n = pageBits\n                      then doE\n                        ensure_no_children parent_slot;\n                        returnOk p\n                      odE\n                      else  throwError $ InvalidCapability 1);\n            dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n            ensure_empty dest_slot;\n            returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n        odE\n    else  throwError TruncatedMessage\n    else  throwError IllegalOperation\n\n| ASIDPoolCap p base \\<Rightarrow>\n  if invocation_type label = ArchInvocationLabel ARMASIDPoolAssign then\n  if length extra_caps > 0\n  then\n    let (pd_cap, pd_cap_slot) = extra_caps ! 0\n     in case pd_cap of\n          ArchObjectCap (PageDirectoryCap _ None) \\<Rightarrow> doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n            whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n            whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n            pool \\<leftarrow> liftE $ get_asid_pool p;\n            free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n            returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pd_cap_slot\n          odE\n        | _ \\<Rightarrow>  throwError $ InvalidCapability 1\n  else  throwError TruncatedMessage\n  else  throwError IllegalOperation\n| VCPUCap p \\<Rightarrow> fail \\<comment> \\<open>not an MMU invocation\\<close>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Decode Architecture-specific System Calls: Decode architecture-specific system call invocations based on the provided label, arguments, and capabilities. It handles different types of invocations, such as VCPU and MMU, and decodes IRQ control invocations, ensuring that the correct parameters are present and valid.",
    "input": "",
    "output": "definition\n  arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n VCPUCap _ \\<Rightarrow> decode_vcpu_invocation label args cap extra_caps\n\\<comment> \\<open>arm-hyp: add cases for iommu\\<close>\n| _ \\<Rightarrow> decode_mmu_invocation label args x_slot cte cap extra_caps\"\n\ndefinition\n  arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n \"arch_data_to_obj_type n \\<equiv>\n  if n = 0 then Some PageDirectoryObj\n  else if n = 1 then Some SmallPageObj\n  else if n = 2 then Some LargePageObj\n  else if n = 3 then Some SectionObj\n  else if n = 4 then Some SuperSectionObj\n  else if n = 5 then Some PageTableObj\n  else if n = 6 then Some VCPUObj\n  else None\"\n\ndefinition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n    (if invocation_type label = ArchInvocationLabel ARMIRQIssueIRQHandler\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n\n          returnOk $ ArchIRQControlIssue irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM System Call Arguments: Define the arguments for ARM-specific system calls, including operations on page directories, page tables, ASID control, ASID pools, and VCPUs. These datatypes provide a structured way to handle various memory management and virtualization tasks, ensuring that the system calls can be invoked with the necessary parameters.",
    "input": "",
    "output": "datatype flush_type = Clean | Invalidate | CleanInvalidate | Unify\n\ndatatype page_directory_invocation =\n    PageDirectoryFlush (pd_flush_type: flush_type) (pd_flush_start: vspace_ref)\n                       (pd_flush_end: vspace_ref) (pd_flush_pstart: word32)\n                       (pd_flush_pd: obj_ref) (pd_flush_asid: asid)\n  | PageDirectoryNothing\n\ndatatype page_table_invocation =\n    PageTableMap cap cslot_ptr pde obj_ref\n  | PageTableUnmap cap cslot_ptr\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation\n     = PageMap\n         (page_map_asid: asid)\n         (page_map_cap: cap)\n         (page_map_ct_slot: cslot_ptr)\n         (page_map_entries: \"pte \\<times> (obj_ref list) + pde \\<times> (obj_ref list)\")\n     | PageUnmap\n         (page_unmap_cap: arch_cap)\n         (page_unmap_cap_slot: cslot_ptr)\n     | PageFlush\n         (page_flush_type: flush_type)\n         (page_flush_start: vspace_ref)\n         (page_flush_end: vspace_ref)\n         (page_flush_pstart: word32)\n         (page_flush_pd: obj_ref)\n         (page_flush_asid: asid)\n     | PageGetAddr\n         (page_get_paddr: obj_ref)\n\ndatatype vcpu_invocation =\n       VCPUSetTCB obj_ref (*vcpu*) obj_ref (*tcb*)\n     | VCPUInjectIRQ obj_ref nat virq\n     | VCPUReadRegister obj_ref vcpureg\n     | VCPUWriteRegister obj_ref vcpureg machine_word\n     | VCPUAckVPPI obj_ref (* vcpu *) vppievent_irq\n\ndatatype arch_invocation\n     = InvokePageTable page_table_invocation\n     | InvokePageDirectory page_directory_invocation\n     | InvokePage page_invocation\n     | InvokeASIDControl asid_control_invocation\n     | InvokeASIDPool asid_pool_invocation\n     | InvokeVCPU vcpu_invocation",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM Copy Registers: The ARM platform does not currently support additional register sets for the \"CopyRegisters\" operation, limiting it to the standard register sets. Future updates may introduce support for a floating point unit.",
    "input": "",
    "output": "datatype arch_copy_register_sets = ARMNoExtraRegisters\n\ndefinition \"ArchDefaultExtraRegisters \\<equiv> ARMNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    ArchIRQControlIssue irq cslot_ptr cslot_ptr bool\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Define ASID and VM Attributes: An ASID is represented as a 32-bit word, and VM attributes are defined as a set of possible values including PageCacheable and XNever.",
    "input": "",
    "output": "text \\<open>An ASID is simply a word.\\<close>\ntype_synonym asid = \"word32\"\n\ndatatype vm_attribute = PageCacheable | XNever\ntype_synonym vm_attributes = \"vm_attribute set\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM-Specific Capabilities: The ARM kernel supports a variety of architecture-specific capabilities, including ASID pools, ASID controller, page directories, page tables, page mappings, and VCPU. These capabilities are used to manage memory and virtualization in the ARM architecture.",
    "input": "",
    "output": "text \\<open>The ARM kernel supports capabilities for ASID pools and an ASID controller capability,\nalong with capabilities for page directories, page tables, and page mappings.\\<close>\n\ndatatype arch_cap =\n   ASIDPoolCap obj_ref asid\n | ASIDControlCap\n | PageCap bool obj_ref cap_rights vmpage_size \"(asid * vspace_ref) option\"\n | PageTableCap obj_ref \"(asid * vspace_ref) option\"\n | PageDirectoryCap obj_ref \"asid option\"\n | VCPUCap obj_ref\n\nlemmas arch_cap_cases =\n  arch_cap.induct[where arch_cap=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P, simplified, rule_format]\n\nlemmas arch_cap_cases_asm =\narch_cap.induct[where arch_cap=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n  simplified, rule_format, rotated -1]\n\ndefinition\n  is_page_cap :: \"arch_cap \\<Rightarrow> bool\" where\n  \"is_page_cap c \\<equiv> \\<exists>x0 x1 x2 x3 x4. c = PageCap x0 x1 x2 x3 x4\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Objects: Define the types for architecture-specific objects, including page directory entries (PDEs) that can contain invalid entries, page table references, section references, or super-section references; page table entries that can contain invalid entries, large page mappings, or small page mappings; and architecture-specific objects that can be ASID pools, page tables, page directories, or data pages used to model user memory.",
    "input": "",
    "output": "text \\<open>This section gives the types and auxiliary definitions for the\narchitecture-specific objects: a page directory entry (@{text \"pde\"})\ncontains either an invalid entry, a page table reference, a section\nreference, or a super-section reference; a page table entry contains\neither an invalid entry, a large page, or a small page mapping;\nfinally, an architecture-specific object is either an ASID pool, a\npage table, a page directory, or a data page used to model user\nmemory.\n\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Page Entry Descriptors: Define the structure of page table and page entry descriptors, including invalid entries, page table pointers, section and super-section mappings, and large and small page mappings. These descriptors support the three-level table system for stage 2 translation, with the flexibility to omit the first level if second levels are stored contiguously.",
    "input": "",
    "output": "datatype pde =\n   InvalidPDE\n | PageTablePDE obj_ref\n | SectionPDE obj_ref vm_attributes cap_rights\n | SuperSectionPDE obj_ref vm_attributes cap_rights\n\ndatatype pte =\n   InvalidPTE\n | LargePagePTE obj_ref vm_attributes cap_rights\n | SmallPagePTE obj_ref vm_attributes cap_rights\n\ntype_synonym hyper_reg_context = machine_word",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table and Directory Sizes: Define the sizes of page table and directory entries, where each entry occupies 8 bytes. Page directories span four frames, and page tables span a single frame, with specific bit allocations for page directory (11 + 3 bits) and page table (9 + 3 bits) entries.",
    "input": "",
    "output": "definition\n  pde_bits :: \"nat\" where\n  \"pde_bits \\<equiv> 3\"\n\ndefinition\n  pte_bits :: \"nat\" where\n  \"pte_bits \\<equiv> 3\"\n\ndefinition\n  pd_bits :: \"nat\" where\n  \"pd_bits \\<equiv> 11 + pde_bits\"\n\ndefinition\n  pt_bits :: \"nat\" where\n  \"pt_bits \\<equiv> 9 + pte_bits\"\n\ndefinition\n  vcpu_bits :: \"nat\" where\n  \"vcpu_bits \\<equiv> pageBits\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Virtual CPU (vCPU) Definition: Defines a virtual CPU structure that includes a reference to a thread control block, a GIC vCPU interface, register values, vPPI masking, and a virtual timer. The GIC vCPU interface contains fields for handling virtual interrupt control, and the vCPU structure is initialized with default values for these components.",
    "input": "",
    "output": "type_synonym virq = machine_word\n\nend\n\nqualify ARM_HYP_A (in Arch)\n\nrecord  gic_vcpu_interface =\n  vgic_hcr  :: machine_word\n  vgic_vmcr :: machine_word\n  vgic_apr  :: machine_word\n  vgic_lr   :: \"nat \\<Rightarrow> ARM_HYP_A.virq\"\n\nrecord vcpu =\n  vcpu_tcb   :: \"obj_ref option\"\n  vcpu_vgic  :: gic_vcpu_interface\n  vcpu_regs :: \"vcpureg \\<Rightarrow> machine_word\"\n  vcpu_vppi_masked :: \"vppievent_irq \\<Rightarrow> bool\"\n  vcpu_vtimer :: virt_timer\n\nend_qualify\n\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition \"vcpu_sctlr vcpu \\<equiv> vcpu_regs vcpu VCPURegSCTLR\"\n\ndefinition\n  default_gic_vcpu_interface :: gic_vcpu_interface\nwhere\n  \"default_gic_vcpu_interface \\<equiv> \\<lparr>\n      vgic_hcr  = vgicHCREN,\n      vgic_vmcr = 0,\n      vgic_apr  = 0,\n      vgic_lr   = \\<lambda>_. 0 \\<rparr>\"\n\ndefinition\n  default_vcpu :: vcpu where\n  \"default_vcpu \\<equiv> \\<lparr>\n      vcpu_tcb    = None,\n      vcpu_vgic   = default_gic_vcpu_interface,\n      vcpu_regs   = (\\<lambda>_. 0) (VCPURegSCTLR := sctlrDefault\n                             , VCPURegACTLR := actlrDefault),\n      vcpu_vppi_masked = (\\<lambda>_. False),\n      vcpu_vtimer = VirtTimer 0\n      \\<rparr>\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Kernel Objects: Define and categorize ARM-specific kernel objects, including ASID pools, page tables, page directories, data pages, and VCPUs. Each object type has a specific size and structure, with ASID pools translating 10 bits, page tables having 512 entries, and data pages recording their size. VCPUs store a potential association to a TCB and an extended register context.",
    "input": "",
    "output": "datatype arch_kernel_obj =\n   ASIDPool \"10 word \\<rightharpoonup> obj_ref\"\n | PageTable \"9 word \\<Rightarrow> pte\"  (* ARMHYP *)\n | PageDirectory \"11 word \\<Rightarrow> pde\"  (* ARMHYP *)\n | DataPage bool vmpage_size\n | VCPU vcpu\n\nlemmas arch_kernel_obj_cases =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P,\n                         simplified, rule_format]\n\nlemmas arch_kernel_obj_cases_asm =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n                         simplified, rule_format, rotated -1]\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 4\"\n\nprimrec\n  arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\nwhere\n  \"arch_obj_size (ASIDPoolCap p as) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (PageCap dev x rs sz as4) = pageBitsForSize sz\"\n| \"arch_obj_size (PageDirectoryCap x as2) = pd_bits\"\n| \"arch_obj_size (PageTableCap x as3) = pt_bits\"\n| \"arch_obj_size (VCPUCap _) = vcpu_bits\"\n\nprimrec\n  arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_cap_is_device (PageCap dev x rs sz as4) = dev\"\n| \"arch_cap_is_device ASIDControlCap = False\"\n| \"arch_cap_is_device (ASIDPoolCap p as) = False\"\n| \"arch_cap_is_device (PageTableCap x as3) = False\"\n| \"arch_cap_is_device (PageDirectoryCap x as2) = False\"\n| \"arch_cap_is_device (VCPUCap _) = False\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 9\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 4\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 29\"\n\nprimrec\n  arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\nwhere\n  \"arch_kobj_size (ASIDPool p) = pageBits\"\n| \"arch_kobj_size (PageTable pte) = pt_bits\"\n| \"arch_kobj_size (PageDirectory pde) = pd_bits\"\n| \"arch_kobj_size (DataPage dev sz) = pageBitsForSize sz\"\n| \"arch_kobj_size (VCPU _) = vcpu_bits\"\n\nprimrec\n  aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\nwhere\n  \"aobj_ref (ASIDPoolCap p as) = Some p\"\n| \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref (PageCap dev x rs sz as4) = Some x\"\n| \"aobj_ref (PageDirectoryCap x as2) = Some x\"\n| \"aobj_ref (PageTableCap x as3) = Some x\"\n| \"aobj_ref (VCPUCap x) = Some x\"\n\nprimrec (nonexhaustive)\n  acap_rights :: \"arch_cap \\<Rightarrow> cap_rights\"\nwhere\n \"acap_rights (PageCap dev x rs sz as) = rs\"\n\ndefinition\n  acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n \"acap_rights_update rs ac \\<equiv> case ac of\n    PageCap dev x rs' sz as \\<Rightarrow> PageCap dev x (validate_vm_rights rs) sz as\n  | _                   \\<Rightarrow> ac\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific Object Types: Defines a set of ARM-specific object types, including various page sizes, page tables, page directories, ASID pools, and VCPU objects. Each object type can be checked for whether it is a frame type, and default capabilities and objects can be generated based on the type, device status, and other parameters.",
    "input": "",
    "output": "datatype\n  aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | SectionObj\n  | SuperSectionObj\n  | PageTableObj\n  | PageDirectoryObj\n  | ASIDPoolObj\n  | VCPUObj\n\ndefinition\n  arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\"\n  where\n    \"arch_is_frame_type aobj \\<equiv> case aobj of\n         SmallPageObj \\<Rightarrow> True\n       | LargePageObj \\<Rightarrow> True\n       | SectionObj \\<Rightarrow> True\n       | SuperSectionObj \\<Rightarrow> True\n       | _ \\<Rightarrow> False\"\n\ndefinition  arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\" where\n \"arch_default_cap tp r n dev \\<equiv> case tp of\n  SmallPageObj \\<Rightarrow> PageCap dev r vm_read_write ARMSmallPage None\n  | LargePageObj \\<Rightarrow> PageCap dev r vm_read_write ARMLargePage None\n  | SectionObj \\<Rightarrow> PageCap dev r vm_read_write ARMSection None\n  | SuperSectionObj \\<Rightarrow> PageCap dev r vm_read_write ARMSuperSection None\n  | PageTableObj \\<Rightarrow> PageTableCap r None\n  | PageDirectoryObj \\<Rightarrow> PageDirectoryCap r None\n  | VCPUObj \\<Rightarrow> VCPUCap r\n  | ASIDPoolObj \\<Rightarrow> ASIDPoolCap r 0\" (* unused *)\n\ndefinition\n  default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\" where\n \"default_arch_object tp dev n \\<equiv> case tp of\n    SmallPageObj \\<Rightarrow> DataPage dev ARMSmallPage\n  | LargePageObj \\<Rightarrow> DataPage dev ARMLargePage\n  | SectionObj \\<Rightarrow> DataPage dev ARMSection\n  | SuperSectionObj \\<Rightarrow> DataPage dev ARMSuperSection\n  | PageTableObj \\<Rightarrow> PageTable (\\<lambda>x. InvalidPTE)\n  | PageDirectoryObj \\<Rightarrow> PageDirectory (\\<lambda>x. InvalidPDE)\n  | VCPUObj \\<Rightarrow> VCPU default_vcpu\n  | ASIDPoolObj \\<Rightarrow> ASIDPool (\\<lambda>_. None)\"\n\ntype_synonym hw_asid = word8\n\ntype_synonym arm_vspace_region_uses = \"vspace_ref \\<Rightarrow> arm_vspace_region_use\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific State: The ARM model maintains a set of architecture-specific state components, including the first level of the ASID table, a mapping from hardware ASIDs to seL4 ASIDs, the next hardware ASID to be preempted, an inverse map from seL4 ASIDs to hardware ASIDs, and the address and description of the page directory and page tables for the shared address space. These components ensure that the ARM architecture's memory management and virtualization are correctly managed and synchronized.",
    "input": "",
    "output": "text \\<open>The architecture-specific state for the ARM model\nconsists of the first level of the ASID table (@{text \"arm_asid_table\"}), a\nmap from hardware ASIDs to seL4 ASIDs (@{text \"arm_hwasid_table\"}),\nthe next hardware ASID to preempt (@{text \"arm_next_asid\"}), the\ninverse map from seL4 ASIDs to hardware ASIDs (first component of\n@{text \"arm_asid_map\"}), and the address of the page directory and\npage tables mapping the shared address space, along with a description\nof this space (@{text \"arm_global_pd\"}, @{text \"arm_global_pts\"}, and\n@{text \"arm_kernel_vspace\"} respectively).\n\nHardware ASIDs are only ever associated with seL4 ASIDs that have a\ncurrently active page directory. The second component of\n@{text \"arm_asid_map\"} values is the address of that page directory.\n\\<close>\n\nend\n\nqualify ARM_HYP_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Specific State: The `arch_state` record encapsulates various architecture-specific components, including ASID tables, the next available ASID, mappings between ASIDs and virtual CPUs, the current virtual CPU, the number of GICvCPU list registers, the kernel's virtual space, and the global page directory. This structure ensures that the system maintains the necessary state for managing memory and virtualization on ARM architectures.",
    "input": "",
    "output": "record arch_state =\n  arm_asid_table    :: \"7 word \\<rightharpoonup> obj_ref\"\n  arm_hwasid_table  :: \"ARM_HYP_A.hw_asid \\<rightharpoonup> ARM_HYP_A.asid\"\n  arm_next_asid     :: ARM_HYP_A.hw_asid\n  arm_asid_map      :: \"ARM_HYP_A.asid \\<rightharpoonup> (ARM_HYP_A.hw_asid \\<times> obj_ref)\"\n  arm_current_vcpu    :: \"(obj_ref \\<times> bool) option\"\n  arm_gicvcpu_numlistregs :: nat\n  arm_kernel_vspace :: ARM_HYP_A.arm_vspace_region_uses\n  arm_us_global_pd  :: obj_ref\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM-Specific Architecture Object Types: Defines a set of types for ARM-specific architecture objects, including AASIDPool, APageTable, APageDirectory, AVCPU, and data pages (AUserData or ADeviceData) with varying sizes. These types categorize different kinds of architectural objects, ensuring they are correctly identified and managed within the system.",
    "input": "",
    "output": "datatype aa_type =\n    AASIDPool\n  | APageTable\n  | APageDirectory\n  | AVCPU\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\"\nwhere\n \"aa_type ao \\<equiv> (case ao of\n           PageTable pt             \\<Rightarrow> APageTable\n         | PageDirectory pd         \\<Rightarrow> APageDirectory\n         | DataPage dev sz          \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n         | ASIDPool f               \\<Rightarrow> AASIDPool\n         | VCPU v                   \\<Rightarrow> AVCPU)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Badge Bits Definition: The badge word is defined to have 28 bits.",
    "input": "",
    "output": "definition\n  badge_bits :: nat where\n  badge_bits_def [simp]: \"badge_bits \\<equiv> 28\"\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "ARM-Specific TCB: Defines architecture-specific data types and configurations for the Thread Control Block (TCB) in an ARM hypervisor environment, ensuring that the TCB is tailored to the specific requirements and capabilities of ARM architecture.",
    "input": "",
    "output": "qualify ARM_HYP_A (in Arch)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Register Management: Allows setting and retrieving user registers in the architecture-specific TCB. Setting updates the TCB context with the provided register values, while retrieving fetches the value of a specific register from the TCB context.",
    "input": "",
    "output": "definition\n  arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_set_registers regs a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := UserContext regs \\<rparr>\"\n\ndefinition\n  arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\"\nwhere\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Arch Fault Message Generation: Generates a message for different types of architectural faults, including VM faults, VCPU faults, VPPI events, and VGIC maintenance. The message includes specific data relevant to the fault type, such as the restart PC, virtual pointer, and additional fault-specific data.",
    "input": "",
    "output": "(*\nFunctions for fault handling.\n*)\n\nchapter \\<open>arch fault related functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n  \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData) od\"\n| \"make_arch_fault_msg (VCPUFault hsr) thread = return (7, [hsr])\"\n| \"make_arch_fault_msg (VPPIEvent irq) thread = return (8, [ucast irq])\"\n| \"make_arch_fault_msg (VGICMaintenance archData) thread = do\n      msg \\<leftarrow> return $ (case archData of None \\<Rightarrow> [-1] | Some idx \\<Rightarrow> [idx]);\n      return (6, msg)\n   od\"\n\ndefinition\n  handle_arch_fault_reply :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_arch_fault_reply af thread x y = return True\"\n\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Sanitise Register: Modifies the value of a register based on specific conditions, ensuring that certain bits are preserved or altered to maintain the integrity and security of the system. The sanitization process is particularly focused on the CPSR register, where it enforces specific bit patterns, while other registers remain unchanged.",
    "input": "",
    "output": "(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"sanitise_register t r v \\<equiv> case r of\n      CPSR \\<Rightarrow>\n       if t \\<and>\n          v && 0x1f \\<in> {0x10, 0x11, 0x12, 0x13, 0x17, 0x1b, 0x1f}\n            \\<comment> \\<open>@{text \\<open>PMODE_(USER/FIQ/IRQ/SUPERVISOR/ABORT/UNDEFINED/SYSTEM)\\<close>}\\<close>\n       then v\n       else (v && 0xf8000000) || 0x150\n    | _    \\<Rightarrow> v\"\n\ndefinition\n  arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\nwhere\n  \"arch_get_sanitise_register_info t \\<equiv> do\n          vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n          return (vcpu \\<noteq> None)\n   od\"\n\ndefinition\n  arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\nwhere\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Update CNode Capability Data: Extract new guard size and guard bits from the provided data, using specific bit masking and shifting operations to isolate the relevant information.",
    "input": "",
    "output": "definition\n  update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 18;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capability Physicality: Distinguish between physical and non-physical architectural capabilities, where ASIDControlCap is treated as non-physical, and all other types of capabilities are treated as physical.",
    "input": "",
    "output": "definition\n  arch_is_physical :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_is_physical cap \\<equiv> case cap of ASIDControlCap \\<Rightarrow> False | _ \\<Rightarrow> True\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check Same Region: Determine if two architectural capabilities refer to the same object or if one is contained within the region of the other. This includes comparing page, page table, page directory, ASID control, ASID pool, and VCPU capabilities.",
    "input": "",
    "output": "fun\n  arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_same_region_as (PageCap dev r R s x) (PageCap dev' r' R' s' x') =\n   (let\n     topA = r + (1 << pageBitsForSize s) - 1;\n     topB = r' + (1 << pageBitsForSize s') - 1\n   in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB)\"\n| \"arch_same_region_as (PageTableCap r x) (PageTableCap r' x') = (r' = r)\"\n| \"arch_same_region_as (PageDirectoryCap r x) (PageDirectoryCap r' x') = (r' = r)\"\n| \"arch_same_region_as ASIDControlCap ASIDControlCap = True\"\n| \"arch_same_region_as (ASIDPoolCap r a) (ASIDPoolCap r' a') = (r' = r)\"\n| \"arch_same_region_as (VCPUCap r) (VCPUCap r') = (r' = r)\"\n| \"arch_same_region_as _ _ = False\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Check if Two Arch Capabilities Point to the Same Object: Determine if two architecture capabilities refer to the same object by comparing their device, reference, and page size. If they are both page capabilities, ensure that the references fall within the same range. For other types of capabilities, use a general region comparison.",
    "input": "",
    "output": "definition\n  same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n \"same_aobject_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (PageCap dev ref _ pgsz _,PageCap dev' ref' _ pgsz' _)\n          \\<Rightarrow> (dev, ref, pgsz) = (dev', ref', pgsz')\n              \\<and> ref \\<le> ref + 2 ^ pageBitsForSize pgsz - 1\n    | _ \\<Rightarrow> arch_same_region_as cp cp')\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architectural Capability Revocation: Specifies that no capability is revocable by another, as defined by the function `arch_is_cap_revocable` which always returns `False`.",
    "input": "",
    "output": "declare same_aobject_as_def[simp]\n\ndefinition\n  arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"arch_is_cap_revocable c c' \\<equiv> False\"\n\nend\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Instantiation for ARM Architecture: Defines concrete types for abstract type names, including object references, virtual space references, data, capability references, and length types, as well as specific lengths and indices for ASID (Address Space Identifier) components.",
    "input": "",
    "output": "type_synonym obj_ref            = machine_word\ntype_synonym vspace_ref         = machine_word\n\ntype_synonym data               = machine_word\ntype_synonym cap_ref            = \"bool list\"\ntype_synonym length_type        = machine_word\n\ntype_synonym asid_low_len       = 10\ntype_synonym asid_low_index     = \"asid_low_len word\"\n\ntype_synonym asid_high_len      = 7\ntype_synonym asid_high_index    = \"asid_high_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "ASID Representation: The ASID is represented as a machine word with a length of 17 bits, requiring invariants to ensure that any extra bits beyond the 17-bit length are zero.",
    "input": "",
    "output": "type_synonym asid_len           = 17\ntype_synonym asid_rep_len       = machine_word_len\ntype_synonym asid               = \"asid_rep_len word\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Conversions: Convert between different data types, including object references, virtual space references, natural numbers, lengths, and various word sizes, using identity functions, type casting, and bitwise operations. These conversions ensure seamless data manipulation and interoperability within the system.",
    "input": "",
    "output": "definition\n  oref_to_data   :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_oref   :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition\n  vref_to_data   :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_vref   :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition\n  nat_to_len     :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition\n  data_to_nat    :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition\n  data_to_16     :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition\n  data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition\n  combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition\n  combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Data Conversion Simplifications: Provide simplification rules for converting between different data types, including object references, virtual references, natural numbers, and capability pointers, to facilitate automatic unfolding in proofs.",
    "input": "",
    "output": "lemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def",
    "system": "",
    "history": []
  },
  {
    "instruction": "Architecture-Dependent Sizes: Define the standard sizes for slots and message labels, which are specific to the underlying machine architecture. These sizes ensure consistent and predictable behavior in memory management and communication.",
    "input": "",
    "output": "definition\n  slot_bits :: nat where\n  \"slot_bits \\<equiv> 4\"\n\ndefinition\n  msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 20\"\n\ndefinition\n  new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext ((\\<lambda>r. 0) (CPSR := 0x150))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Kernel Virtual Address Space: The kernel reserves a specific range of virtual addresses starting from a defined base address, ensuring that this space is available for kernel use in every virtual address space.",
    "input": "",
    "output": "definition\n  kernel_base :: \"vspace_ref\" where\n  \"kernel_base \\<equiv> 0xe0000000\"\n\ndefinition\n  idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = kernel_base + 0x1000\"\n\nend\n\narch_requalify_consts (A) kernel_base idle_thread_ptr\n\ncontext Arch begin arch_global_naming (A)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Machine Operation Constants: Define constants for various machine operations, including message information, general-purpose and frame registers, capability and badge registers, and different types of architectural faults. These constants provide a standardized way to reference specific elements in the system, ensuring consistency and clarity in the implementation of machine operations.",
    "input": "",
    "output": "definition\n  nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\" where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len)\n                           (to_bl (of_nat n :: machine_word))\"\n\ndefinition\n \"msg_info_register \\<equiv> msgInfoRegister\"\ndefinition\n \"msg_registers \\<equiv> msgRegisters\"\ndefinition\n \"cap_register \\<equiv> capRegister\"\ndefinition\n \"badge_register \\<equiv> badgeRegister\"\ndefinition\n \"frame_registers \\<equiv> frameRegisters\"\ndefinition\n \"gp_registers \\<equiv> gpRegisters\"\ndefinition\n \"exception_message \\<equiv> exceptionMessage\"\ndefinition\n \"syscall_message \\<equiv> syscallMessage\"\n\n\ndatatype arch_fault =\n    VMFault vspace_ref \"machine_word list\"\n  | VGICMaintenance \"data option\" (* idx *)\n  | VCPUFault data (* hsr *)\n  | VPPIEvent irq (* vppi IRQ *)\n\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Heap State Equivalence: Two heap states are considered equivalent if they have the same heap type dictionary and the same memory contents, except for regions that correspond to specific types. The equivalence holds even if the memory contents differ in regions associated with types whose names are in a specified set, as long as the footprints of these types are valid. \n\nSubproperties:\n- Reflexivity: A heap state is always equivalent to itself.\n- Transitivity: If one heap state is equivalent to a second, and the second is equivalent to a third, then the first is equivalent to the third.\n- Update Preservation: Updating a memory region corresponding to a type with a valid footprint preserves the equivalence, provided the type's name is in the specified set.",
    "input": "",
    "output": "theory TypHeapLimits\n  imports CParser.TypHeapLib\nbegin\n\ndefinition\n  states_all_but_typs_eq :: \"char list set \\<Rightarrow> heap_raw_state \\<Rightarrow> heap_raw_state \\<Rightarrow> bool\"\nwhere\n \"states_all_but_typs_eq names hrs hrs'\n    = (hrs_htd hrs = hrs_htd hrs'\n        \\<and> (\\<forall>x. hrs_mem hrs x = hrs_mem hrs' x\n             \\<or> (\\<exists>p td. x \\<in> {p ..+ size_td td} \\<and> td_names td \\<subseteq> names\n                    \\<and> typ_name td \\<noteq> pad_typ_name\n                    \\<and> valid_footprint (hrs_htd hrs) p td)))\"\n\nlemma heap_list_eq_from_region_eq:\n  \"\\<forall>x \\<in> {p ..+ n}. hp x = hp' x\n    \\<Longrightarrow> heap_list hp n p = heap_list hp' n p\"\n  apply (induct n arbitrary: p)\n   apply simp\n  apply (simp add: intvl_def)\n  apply (frule_tac x=p in spec, drule mp, rule_tac x=0 in exI,\n         simp+)\n  apply (erule meta_allE, erule meta_mp)\n  apply clarsimp\n  apply (drule spec, erule mp)\n  apply (rule_tac x=\"Suc k\" in exI)\n  apply simp\n  done\n\nlemma states_all_but_typs_eq_clift:\n  \"\\<lbrakk> states_all_but_typs_eq names hrs hrs';\n      \\<forall>x \\<in> td_names (typ_info_t TYPE('a)). x \\<notin> names;\n      typ_name (typ_info_t TYPE('a)) \\<noteq> pad_typ_name \\<rbrakk>\n     \\<Longrightarrow> (clift hrs :: (_ \\<rightharpoonup> ('a :: c_type))) = clift hrs'\"\n  apply (rule ext, simp add: lift_t_def)\n  apply (cases hrs, cases hrs', clarsimp)\n  apply (simp add: lift_typ_heap_def restrict_map_def)\n  apply (simp add: s_valid_def proj_d_lift_state\n                   states_all_but_typs_eq_def hrs_htd_def\n                   hrs_mem_def)\n  apply clarsimp\n  apply (simp add: heap_list_s_heap_list h_t_valid_def)\n  apply (subst heap_list_eq_from_region_eq, simp_all)\n  apply clarsimp\n  apply (drule spec, erule disjE, assumption)\n  apply clarsimp\n  apply (drule(1) valid_footprint_neq_disjoint)\n    apply (clarsimp simp: typ_uinfo_t_def typ_tag_lt_def\n                          typ_tag_le_def)\n    apply (force dest: td_set_td_names\n                intro: td_set_td_names[OF td_set_self])\n   apply (clarsimp simp: field_of_def typ_uinfo_t_def)\n   apply (force dest: td_set_td_names\n               intro: td_set_td_names[OF td_set_self])\n  apply (simp add: size_of_def)\n  apply blast\n  done\n\nlemma states_all_but_typs_eq_refl:\n  \"states_all_but_typs_eq names hrs hrs\"\n  by (simp add: states_all_but_typs_eq_def)\n\nlemma states_all_but_typs_eq_trans:\n  \"states_all_but_typs_eq names hrs hrs'\n     \\<Longrightarrow> states_all_but_typs_eq names hrs' hrs''\n     \\<Longrightarrow> states_all_but_typs_eq names hrs hrs''\"\n  apply (clarsimp simp add: states_all_but_typs_eq_def\n                  del: disjCI)\n  apply (drule_tac x=x in spec)+\n  apply clarsimp\n  done\n\nlemma states_all_but_typs_eq_update:\n  \"\\<lbrakk> hrs_htd hrs \\<Turnstile>\\<^sub>t (ptr :: ('a :: c_type) ptr);\n      td_names (typ_info_t TYPE('a)) \\<subseteq> names;\n      typ_name (typ_info_t TYPE('a)) \\<noteq> pad_typ_name;\n      wf_fd (typ_info_t TYPE('a)) \\<rbrakk>\n        \\<Longrightarrow>\n   states_all_but_typs_eq names hrs\n    (hrs_mem_update (heap_update ptr v) hrs)\"\n  apply (clarsimp simp: states_all_but_typs_eq_def hrs_mem_update\n                   del: disjCI)\n  apply (subst disj_commute, rule disjCI)\n  apply (rule_tac x=\"ptr_val ptr\" in exI)\n  apply (rule_tac x=\"typ_uinfo_t TYPE('a)\" in exI)\n  apply (simp add: typ_uinfo_t_def h_t_valid_def heap_update_def)\n  apply (rule ccontr)\n  apply (subst(asm) heap_update_nmem_same)\n   apply (simp add: to_bytes_def length_fa_ti)\n   apply (subst length_fa_ti, simp_all add: size_of_def)\n  done\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Definitions and Abbreviations: Defines types for C pointers, commands, bodies, and states, and provides an abbreviation for lifting a C state to a higher-level representation. This ensures that the system can handle and manipulate C-level data structures in a type-safe and consistent manner.",
    "input": "",
    "output": "(* The base theory for generated bitfield proofs about the kernel *)\n\ntheory KernelState_C\nimports\n  \"Word_Lib.WordSetup\"\n  \"CLib.BitFieldProofsLib\"\n  \"Substitute\"\nbegin\n\ntype_synonym c_ptr_name = int\ntype_synonym 't c_com = \"('t, c_ptr_name, strictc_errortype) com\"\ntype_synonym 't c_body = \"('t, c_ptr_name, strictc_errortype) body\"\ntype_synonym 't c_xstate = \"('t, strictc_errortype) xstate\"\n\ntype_synonym cstate = \"globals myvars\"\ntype_synonym rf_com = \"cstate c_com\"\n\nabbreviation\n  \"cslift (s :: cstate) \\<equiv> clift (t_hrs_' (globals s))\"\n\nlemma cslift_def: \"is_an_abbreviation\" by (simp add: is_an_abbreviation_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Memory Access Validity: Ensures that a given pointer is valid within the context of the current state, according to the combined constraints of the hardware and capability guard.",
    "input": "",
    "output": "abbreviation\n  \"c_h_t_valid\" :: \"cstate \\<Rightarrow> 'a::c_type ptr \\<Rightarrow> bool\"  (\"_ \\<Turnstile>\\<^sub>c _\" [99,99] 100)\nwhere\n  \"s \\<Turnstile>\\<^sub>c p == hrs_htd (t_hrs_' (globals s)),c_guard \\<Turnstile>\\<^sub>t p\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hoare Logic Theorems: Utilize the HoarePartialDef theorems, particularly `conseqPre` and `conseqPost`, for reasoning about partial correctness in the system. These theorems are extensively used to establish the correctness of program segments under various preconditions and postconditions.",
    "input": "",
    "output": "lemmas conseqPre = HoarePartialDef.conseqPre\nlemmas conseqPost = HoarePartialDef.conseqPost",
    "system": "",
    "history": []
  },
  {
    "instruction": "Conjunction Congruence: Establishes a congruence rule for conjunction, allowing the substitution of equivalent propositions within a conjunction.",
    "input": "",
    "output": "lemmas conj_cong = HOL.conj_cong",
    "system": "",
    "history": []
  },
  {
    "instruction": "Remove Eager Bitfield Proof Rules: Eliminate specific simplification rules for bit shifting operations to prevent over-eager simplification during bitfield proofs.",
    "input": "",
    "output": "declare bit_shiftr_eq[simp del]\ndeclare shiftl_of_Suc[simp del]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "No specific properties can be derived from the provided code, as it only contains theory imports and no actual definitions or specifications.",
    "input": "",
    "output": "theory KernelInc_C\nimports\n  \"Substitute\"\n  \"structures_defs\"\n  \"structures_proofs\"\n  \"shared_types_defs\"\n  \"shared_types_proofs\"\nbegin\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Term Conversion and Guard Addition: The code defines a mechanism for converting terms and adding guards to commands. It processes constant terms, retrieves their definitions, and recursively converts sub-terms. Additionally, it adds guards to sequences, while loops, and calls, ensuring that the modified commands are properly guarded and sequenced.",
    "input": "",
    "output": "theory Substitute\n\nimports\n  \"CKernel.Kernel_C\"\n  \"AsmRefine.GlobalsSwap\"\nbegin\n\nML \\<open>\n\nstructure SubstituteSpecs = struct\n\nval list_abs = uncurry (fold_rev (fn (x, T) => fn t => Abs (x, T, t)));\n\nfun get_rhs thm =\n    snd (Logic.dest_equals (Thm.concl_of thm))\n    handle TYPE _ =>\n      snd (HOLogic.dest_eq (Thm.concl_of thm));\n\nfun get_lhs thm =\n    fst (Logic.dest_equals (Thm.concl_of thm))\n    handle TYPE _ =>\n      fst (HOLogic.dest_eq (Thm.concl_of thm));\n\nfun term_convert prefix convs (tm as Const (name, _)) =\n    if not (String.isPrefix prefix name) then tm\n    else the (Termtab.lookup convs tm)\n  | term_convert _ _ tm = tm;\n\nfun suspicious_term ctxt s t = if Term.add_var_names t [] = [] then ()\n  else (tracing (\"suspicious \" ^ s);\n    Syntax.pretty_term ctxt t |> Pretty.string_of |> tracing;\n    ())\n\nval debug_trace = ref (Bound 0);\n\nfun convert prefix src_ctxt proc (tm as Const (name, _)) (convs, ctxt) =\n  ((term_convert prefix convs tm; (convs, ctxt))\n  handle Option =>\n let\n    val cname = unprefix prefix name;\n    val def_thm = Proof_Context.get_thm src_ctxt (cname ^ \"_def\")\n    val rhs = get_rhs def_thm;\n    val _ = suspicious_term ctxt \"init rhs\" rhs;\n    val consts = Term.add_consts rhs [];\n    val (convs, ctxt) = fold (convert prefix src_ctxt proc o Const)\n        consts (convs, ctxt);\n    val rhs' = map_aterms (term_convert prefix convs) rhs;\n    val rhs'' = proc ctxt cname rhs';\n    val _ = suspicious_term ctxt \"adjusted rhs\" rhs'';\n\n  in if rhs'' aconv rhs\n    then (Termtab.insert (K true) (tm, tm) convs,\n        ctxt\n        |> Local_Theory.begin_nested |> snd\n        |> Local_Theory.abbrev Syntax.mode_default ((Binding.name cname, NoSyn), get_lhs def_thm)\n        |> snd |> Local_Theory.note ((Binding.name (cname ^ \"_def\"), []), [def_thm])\n        |> snd |> Local_Theory.end_nested\n    )\n\n  else let\n      val _ = tracing (\"Defining \" ^ cname);\n\n      val pre_def_ctxt = ctxt\n      val b = Binding.name cname\n      val ctxt = Local_Theory.begin_nested ctxt |> snd\n      val ((tm', _), ctxt) = Local_Theory.define\n          ((b, NoSyn), ((Thm.def_binding b, []), rhs'')) ctxt\n      val tm'' = Morphism.term (Proof_Context.export_morphism ctxt pre_def_ctxt) tm'\n      val ctxt = Local_Theory.end_nested ctxt\n\n      val lhs_argTs = get_lhs def_thm |> strip_comb |> snd |> map fastype_of;\n      val abs_tm = list_abs (map (pair \"_\") lhs_argTs, tm'')\n\n    in (Termtab.insert (K true) (tm, abs_tm) convs, ctxt) end\n  end)\n  | convert _ _ _ (tm) _ = raise TERM (\"convert: not Const\", [tm])\n\n\nfun prove_impl_tac ctxt ss =\n    SUBGOAL (fn (t, n) => let\n        val lhs = t |> HOLogic.dest_Trueprop |> HOLogic.dest_eq |> fst;\n        val cnames = Term.add_const_names lhs []\n          |> filter (String.isSuffix \"_'proc\");\n        val unfolds = map (Proof_Context.get_thm ctxt o suffix \"_def\"\n          o Long_Name.base_name) cnames;\n      in simp_tac (put_simpset ss ctxt addsimps unfolds) n\n      end);\n\nfun convert_impls ctxt = let\n\n    val thm = Proof_Context.get_thm ctxt \"\\<Gamma>_def\"\n\n    val proc_defs = (Term.add_const_names (Thm.concl_of thm) [])\n      |> filter (String.isSuffix Hoare.proc_deco)\n      |> map (suffix \"_def\" #> Proof_Context.get_thm ctxt)\n\n    val tree_lemmata = StaticFun.prove_partial_map_thms thm\n        (ctxt addsimps proc_defs)\n\n    fun impl_name_from_proc (Const (s, _)) = s\n            |> Long_Name.base_name\n            |> unsuffix Hoare.proc_deco\n            |> suffix HoarePackage.implementationN\n      | impl_name_from_proc t = raise TERM (\"impl_name_from_proc\", [t])\n\n    val saves = tree_lemmata |> map (apfst (fst #> impl_name_from_proc))\n\n  in Local_Theory.notes (map (fn (n, t) => ((Binding.name n, []), [([t], [])])) saves)\n    ctxt |> snd end\n\nfun take_all_actions prefix src_ctxt proc tm csenv\n      styargs ctxt = let\n    val (_, ctxt) = convert prefix src_ctxt proc tm (Termtab.empty, ctxt);\n  in ctxt\n    |> convert_impls\n    |> Modifies_Proofs.prove_all_modifies_goals_local csenv (fn _ => true) styargs\n  end\n\nend\n\n\\<close>\n\nML \\<open>\nfun com_rewrite f t = case fastype_of t of\n    (comT as Type (@{type_name com}, [s, _, ft]))\n      => let\n    val gd = Const (@{const_name Guard},\n                ft --> (HOLogic.mk_setT s) --> comT --> comT)\n    fun add_guard ((f, gd_s), c) = gd $ f $ gd_s $ c;\n\n    val seq = Const (@{const_name Seq}, comT --> comT --> comT);\n    val skip = Const (@{const_name Skip}, comT);\n    fun add_guards_to_seq gs (Const (@{const_name Seq}, _) $ a $ b)\n        = seq $ add_guards_to_seq gs a $ b\n      | add_guards_to_seq gs c\n        = seq $ foldr add_guard skip gs $ c;\n\n    fun add_guards c [] = c\n      | add_guards ((w as Const (@{const_name While}, _)) $ S $ c) gs\n        = seq $ (w $ S $ add_guards_to_seq gs c) $ foldr add_guard skip gs\n      | add_guards (call as (Const (@{const_name call}, _) $ _ $ _ $ _ $ _)) gs\n        = foldr add_guard (seq $ call $ foldr add_guard skip gs) gs\n      | add_guards c gs = foldr add_guard c gs;\n\n    fun inner t = case t of\n      (Const (@{const_name \"switch\"}, T) $ v $ set_com_list) => let\n        val (ss, cs) = map_split HOLogic.dest_prod\n          (HOLogic.dest_list set_com_list);\n        val cs' = map inner cs;\n        val (v', gs) = f v;\n        val (ss', gss) = map_split f ss;\n        val listT = HOLogic.mk_prodT\n          (HOLogic.mk_setT (range_type (domain_type T)), comT);\n      in foldr add_guard (head_of t $ v' $ HOLogic.mk_list listT\n            (map HOLogic.mk_prod (ss' ~~ cs')))\n          (gs @ flat gss)\n      end\n      | _ => let\n        val (h, xs) = strip_comb t;",
    "system": "",
    "history": []
  },
  {
    "instruction": "Strengthen C Guards: Modify the guards in the term by rewriting them to include additional conditions. The rewrite rules ensure that the guards are strengthened with `h_t_valid` or `ptr_safe` and `c_guard` conditions, depending on the specified set of symbols.",
    "input": "",
    "output": "val xTs = xs ~~ (fastype_of h |> strip_type |> fst);\n        fun upd_arg (x, T) = if T = comT then (inner x, []) else f x;\n        val (ys, gss) = map_split upd_arg xTs;\n      in add_guards (list_comb (h, ys)) (flat gss) end\n  in inner (Envir.beta_eta_contract t) end\n  | _ => t;\n\n\\<close>\n\nsetup \\<open>DefineGlobalsList.define_globals_list_i\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\" @{typ globals}\\<close>\n\n\nlocale substitute_pre\n  = fixes symbol_table :: \"string \\<Rightarrow> addr\"\n      and domain :: \"addr set\"\n\nbegin\n\nabbreviation\n \"globals_list \\<equiv> kernel_all_global_addresses.global_data_list\"\n\nend\n\nlocale kernel_all_substitute = substitute_pre\nbegin\n\nML \\<open>\nfun mk_rew (t as Abs (s, T, _)) = mk_rew (betapply (t, Var ((s, 0), T)))\n  | mk_rew t = HOLogic.dest_eq t\n\nval mk_varifyT = Term.map_types Logic.varifyT_global\n\nlocal\nval c_guard_rew =\n  @{term \"\\<lambda>p b. Guard C_Guard {s. c_guard (p s)} b\n     = Guard C_Guard {s. h_t_valid (hrs_htd (t_hrs_' (globals s))) c_guard (p s)} b\"}\n  |> mk_varifyT |> mk_rew\n\nval c_guard_rew_weak =\n  @{term \"\\<lambda>p b. Guard C_Guard {s. c_guard (p s)} b\n         = Guard C_Guard {s. ptr_safe (p s) (hrs_htd (t_hrs_' (globals s)))\n            \\<and> c_guard (p s)} b\"}\n      |> mk_varifyT |> mk_rew\n\nin\nfun strengthen_c_guards ss thy s =\n  if (exists (curry (=) s) ss)\n  then Pattern.rewrite_term thy [c_guard_rew_weak] []\n  else Pattern.rewrite_term thy [c_guard_rew] []\nend;\n\\<close>\n\nlemmas global_data_defs\n    = kernel_all_global_addresses.global_data_defs\n\nlemmas globals_list_def\n    = kernel_all_global_addresses.global_data_list_def\n\nML \\<open>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Guarded Memory and State Updates: Ensures that memory and state updates, such as those involving the heap and global variables, are performed safely by applying guards and assertions. This includes verifying the safety of heap table descriptor (HTD) updates, handling pointer arithmetic, and ensuring that certain operations do not reach a halt state.",
    "input": "",
    "output": "val global_datas = @{thms global_data_defs}\n  |> map (Thm.concl_of #> Logic.unvarify_global\n        #> Logic.dest_equals #> snd #> Envir.beta_eta_contract)\n\nval const_globals = map_filter\n    (fn (Const (@{const_name const_global_data}, _) $ nm $ t)\n        => SOME (HOLogic.dest_string nm, t)\n        | _ => NONE) global_datas\n\nlocal\n\nval hrs_htd_update_guard_rew1 =\n    @{term \"\\<lambda>u. Basic (\\<lambda>s. globals_update (t_hrs_'_update (hrs_htd_update (u s))) s)\n         = Guard C_Guard {s. globals_list_distinct (fst ` dom_s (u s (hrs_htd (t_hrs_' (globals s)))))\n                         symbol_table globals_list}\n           (Basic (\\<lambda>s. globals_update (t_hrs_'_update (id hrs_htd_update (u s))) s))\"}\n        |> mk_rew\n\nval hrs_htd_update_guard_rew2 =\n  @{term \"t_hrs_'_update (id hrs_htd_update f) = t_hrs_'_update (hrs_htd_update f)\"}\n  |> Logic.varify_global |> HOLogic.dest_eq;\n\nval consts = map snd const_globals\n\nval index_eq_set_helper\n  = Syntax.parse_term @{context} (String.concat\n    [\"\\<lambda>str t n c. {s :: globals myvars. c \\<longrightarrow>\",\n        \"h_val (hrs_mem (t_hrs_' (globals s)))\",\n        \" (CTypesDefs.ptr_add (Ptr (symbol_table str)) (of_nat (n s)))\",\n        \" = t s}\"])\n\nval eq_set_helper\n  = Syntax.parse_term @{context} (String.concat\n    [\"\\<lambda>str t c. {s :: globals myvars. c \\<longrightarrow>\",\n        \"h_val (hrs_mem (t_hrs_' (globals s)))\",\n        \" (Ptr (symbol_table str)) = t}\"])\n\nval s = @{term \"s :: globals myvars\"}\n\nval grab_name_str = head_of #> dest_Const #> fst #> Long_Name.base_name\n    #> HOLogic.mk_string\n\nin\n\nfun const_global_asserts ctxt cond\n  (t as (Const (@{const_name index}, _) $ arr $ n)) = if member (=) consts arr\n    then [(index_eq_set_helper $ grab_name_str arr\n        $ lambda s t $ lambda s n $ cond) |> Syntax.check_term ctxt]\n    else []\n  | const_global_asserts ctxt cond (Const c) = if member (=) consts (Const c)\n    then [(eq_set_helper $ grab_name_str (Const c) $ Const c $ cond)\n        |> Syntax.check_term ctxt]\n    else []\n  | const_global_asserts ctxt cond (f $ x) = if member (=) consts (f $ x)\n    then [(eq_set_helper $ grab_name_str (f $ x) $ (f $ x) $ cond)\n        |> Syntax.check_term ctxt]\n    else const_global_asserts ctxt cond f @ const_global_asserts ctxt cond x\n  | const_global_asserts ctxt cond (a as Abs (_, @{typ \"globals myvars\"}, _))\n    = const_global_asserts ctxt cond (betapply (a, s))\n  | const_global_asserts ctxt cond (Abs (_, _, t))\n    = const_global_asserts ctxt cond t\n  | const_global_asserts _ _ _ = []\n\nfun guard_rewritable_globals const_cond ctxt =\n  Pattern.rewrite_term @{theory} [hrs_htd_update_guard_rew2] []\n  o Pattern.rewrite_term @{theory} [hrs_htd_update_guard_rew1] []\n  o com_rewrite (fn t =>\n     (t, map (pair @{term C_Guard})\n        (case const_cond of SOME cond => const_global_asserts ctxt cond t\n                | NONE => [])))\n\nval guard_htd_updates_with_domain = com_rewrite\n  (fn t => if fastype_of t = @{typ \"globals myvars \\<Rightarrow> globals myvars\"}\n        andalso Term.exists_Const (fn (s, _) => s = @{const_name \"hrs_htd_update\"}) t\n        then (t, [(@{term MemorySafety}, betapply (@{term \"\\<lambda>f :: globals myvars \\<Rightarrow> globals myvars.\n                {s. htd_safe domain (hrs_htd (t_hrs_' (globals s)))\n              \\<and> htd_safe domain (hrs_htd (t_hrs_' (globals (f s))))}\"}, t))])\n        else (t, []))\n\nval guard_halt = com_rewrite\n  (fn t => if t = @{term \"halt_'proc\"}\n    then (t, [(@{term DontReach}, @{term \"{} :: globals myvars set\"})])\n    else (t, []))\n\nfun acc_ptr_adds (Const (@{const_name h_val}, _) $ m $ (Const (@{const_name ptr_add}, _) $ p $ n))\n    = [(p, n, true)] @ maps acc_ptr_adds [m, p, n]\n  | acc_ptr_adds (Const (@{const_name heap_update}, _) $ (Const (@{const_name ptr_add}, _) $ p $ n))\n    = [(p, n, true)] @ maps acc_ptr_adds [p, n]\n  | acc_ptr_adds (Const (@{const_name ptr_add}, _) $ p $ n)\n    = [(p, n, false)] @ maps acc_ptr_adds [p, n]\n  | acc_ptr_adds (f $ x) = maps acc_ptr_adds [f, x]\n  | acc_ptr_adds (abs as Abs (_, T, t)) = if T = @{typ \"globals myvars\"}\n    then acc_ptr_adds (betapply (abs, @{term \"s :: globals myvars\"}))\n    else acc_ptr_adds t\n  | acc_ptr_adds _ = []\n\nfun mk_bool true = @{term True} | mk_bool false = @{term False}\n\nval guard_acc_ptr_adds = com_rewrite\n  (fn t => (t, acc_ptr_adds t |> map (fn (p, n, strong) => let\n    val assn = Const (@{const_name ptr_add_assertion'},\n            fastype_of p --> @{typ \"int \\<Rightarrow> bool \\<Rightarrow> heap_typ_desc \\<Rightarrow> bool\"})\n        $ p $ n $ mk_bool strong\n        $ @{term \"hrs_htd (t_hrs_' (globals (s :: globals myvars)))\"}\n    val gd = HOLogic.mk_Collect (\"s\", @{typ \"globals myvars\"}, assn)\n  in (@{term MemorySafety}, gd) end)))\n\nend\n\n\\<close>\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\nML \\<open>\n  Feedback.verbosity_level := ~1;\n\\<close>\n\nlocal_setup \\<open>\nSubstituteSpecs.take_all_actions\n  \"Kernel_C.kernel_all_global_addresses.\"\n  (Locale.init \"Kernel_C.kernel_all_global_addresses\" @{theory})\n  (fn ctxt => fn s => guard_rewritable_globals NONE ctxt\n    o (strengthen_c_guards [\"memset_body\", \"memcpy_body\", \"memzero_body\"]\n          (Proof_Context.theory_of ctxt) s)\n    o guard_halt\n    o guard_htd_updates_with_domain\n    o guard_acc_ptr_adds)\n  @{term kernel_all_global_addresses.\\<Gamma>}\n  (CalculateState.get_csenv @{theory} \"../c/build/$L4V_ARCH/kernel_all.c_pp\" |> the)\n  [@{typ \"globals myvars\"}, @{typ int}, @{typ strictc_errortype}]\n\\<close>\n\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ghost State Management: Manipulates the ghost state to manage memory regions, virtual memory frames, and capability node (cnode) allocations. It allows for clearing regions, setting up new frames, and creating new cnodes, ensuring that the ghost state accurately reflects the system's memory and capability structure.",
    "input": "",
    "output": "theory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . \n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> word32\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> word32 \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Qualified Aliases: Define and qualify constants for ARM page sizes and TCB-related values, ensuring that they are appropriately named and accessible within the context.",
    "input": "",
    "output": "context begin interpretation Arch . global_naming vmpage_size\n\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 8\"\n\ndefinition\n  ctcb_offset :: \"32 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide Unqualified Names: Ensures that unqualified names conflicting with Kernel_Config names are hidden, requiring the use of the Kernel_C prefix to access these names.",
    "input": "",
    "output": "hide_const (open)\n  numDomains",
    "system": "",
    "history": []
  },
  {
    "instruction": "ThreadState Definitions: Provides a collection of definitions for various thread states, making them more accessible and usable within the system.",
    "input": "",
    "output": "lemmas ThreadState_defs = StrictC'_thread_state_defs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide VMPage Sizes: Conceal the specific constants related to different ARM virtual memory page sizes, ensuring they are not directly accessible or visible in the specification.",
    "input": "",
    "output": "hide_const\n vmpage_size.ARMSmallPage\n vmpage_size.ARMLargePage\n vmpage_size.ARMSection\n vmpage_size.ARMSuperSection",
    "system": "",
    "history": []
  },
  {
    "instruction": "Re-allow Fully Qualified Accesses: Ensure that fully qualified accesses are re-enabled for consistency, allowing the use of specific constants such as ARMSmallPage, ARMLargePage, ARMSection, and ARMSuperSection.",
    "input": "",
    "output": "context Arch begin\n\nglobal_naming \"ARM.vmpage_size\"\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nglobal_naming ARM\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ghost State Management: Manages the ghost state by clearing regions, adding new frames, and creating new capability nodes. It ensures that specific memory regions are updated or cleared based on the provided parameters, maintaining the integrity of the ghost state for tracking and verification purposes.",
    "input": "",
    "output": "theory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . \n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> machine_word\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> machine_word \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ignore x86-64 Assembly Statements: The system is configured to ignore x86-64 assembly statements, ensuring that they do not affect the parsing and processing of the code.",
    "input": "",
    "output": "setup \\<open>Context.theory_map (ASM_Ignore_Hooks.add_hook (fn _ => true))\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Qualified Aliases: Define and qualify constants for different page sizes and calculate the size and offset for the control thread control block (CTCB). This ensures that the system uses consistent and appropriately sized memory allocations for thread control blocks.",
    "input": "",
    "output": "context begin interpretation Arch . global_naming vmpage_size\nrequalify_consts X64SmallPage X64LargePage X64HugePage\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 10\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide Unqualified Names: Ensures that unqualified names conflicting with Kernel_Config names are hidden, requiring the use of the Kernel_C prefix to avoid naming conflicts.",
    "input": "",
    "output": "hide_const (open)\n  numDomains",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread State Definitions: Consolidates the definitions related to thread states, providing a more usable and accessible name for referencing these definitions.",
    "input": "",
    "output": "lemmas ThreadState_defs = StrictC'_thread_state_defs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide VMPage Sizes: Conceal the specific sizes of different types of virtual memory pages (small, large, and huge) to prevent direct access or manipulation.",
    "input": "",
    "output": "hide_const\n  vmpage_size.X64SmallPage\n  vmpage_size.X64LargePage\n  vmpage_size.X64HugePage",
    "system": "",
    "history": []
  },
  {
    "instruction": "Requalification of Constants: Re-allow fully qualified accesses to constants related to page sizes (X64SmallPage, X64LargePage, X64HugePage) for consistency, ensuring that these constants can be referenced with their full qualification.",
    "input": "",
    "output": "context Arch begin\nglobal_naming \"X64.vmpage_size\" requalify_consts X64SmallPage X64LargePage X64HugePage\nglobal_naming \"X64\" requalify_consts X64SmallPage X64LargePage X64HugePage\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ghost State Management: Manipulates the ghost state to manage memory regions, including clearing regions, adding new frames, and adding new capability nodes. These operations ensure that the ghost state accurately reflects the system's memory layout and capabilities, supporting verification and analysis.",
    "input": "",
    "output": "theory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . \n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> machine_word\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> machine_word \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Qualified Aliases: Define and qualify constants for different page sizes and TCB-related values, ensuring consistent and appropriately scoped naming within the architecture context.",
    "input": "",
    "output": "context begin interpretation Arch . global_naming vmpage_size\nrequalify_consts RISCVSmallPage RISCVLargePage RISCVHugePage\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 9\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide Conflicting Names: Conceal unqualified names that conflict with those in Kernel_Config, enforcing the use of the Kernel_C prefix for these names to avoid naming conflicts and ensure clarity.",
    "input": "",
    "output": "hide_const (open)\n  numDomains",
    "system": "",
    "history": []
  },
  {
    "instruction": "ThreadState Definitions: Consolidates the definitions related to thread states, providing a more usable and accessible name for referencing these definitions.",
    "input": "",
    "output": "lemmas ThreadState_defs = StrictC'_thread_state_defs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide VM Page Sizes: Conceal the definitions of RISCV small, large, and huge page sizes to prevent direct access and manipulation.",
    "input": "",
    "output": "hide_const\n  vmpage_size.RISCVSmallPage\n  vmpage_size.RISCVLargePage\n  vmpage_size.RISCVHugePage",
    "system": "",
    "history": []
  },
  {
    "instruction": "Re-allow Fully Qualified Accesses: Re-enable fully qualified accesses for consistency, allowing the use of specific constants (RISCVSmallPage, RISCVLargePage, RISCVHugePage) in the context of the RISCV architecture.",
    "input": "",
    "output": "context Arch begin\nglobal_naming \"RISCV.vmpage_size\" requalify_consts RISCVSmallPage RISCVLargePage RISCVHugePage\nglobal_naming \"RISCV\" requalify_consts RISCVSmallPage RISCVLargePage RISCVHugePage\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ghost State Management: Manages the ghost state, including frame sizes, CNode sizes, PT types, and assertions. It provides operations to clear regions, add new frames, add new CNodes, and set PT types, ensuring that the ghost state accurately reflects the system's memory and capability configurations.",
    "input": "",
    "output": "theory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n  pt_array_len\n  vs_array_len\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . \n\n\nlemma ptTranslationBits_vs_array_len':\n  \"2 ^ ptTranslationBits VSRootPT_T = vs_array_len\"\n  by (simp add: vs_array_len_val ptTranslationBits_vs_index_bits vs_index_bits_def\n                Kernel_Config.config_ARM_PA_SIZE_BITS_40_def)\n\nlemmas ptTranslationBits_vs_array_len = ptTranslationBits_vs_array_len'[unfolded vs_array_len_val]\n\ntype_synonym cghost_state =\n  \"(machine_word \\<rightharpoonup> vmpage_size) \\<times>   \\<comment> \\<open>Frame sizes\\<close>\n   (machine_word \\<rightharpoonup> nat) \\<times>           \\<comment> \\<open>CNode sizes\\<close>\n   (machine_word \\<rightharpoonup> pt_type) \\<times>       \\<comment> \\<open>PT types\\<close>\n   ghost_assertions\"                 \\<comment> \\<open>ASMRefine assertions\\<close>\n\ndefinition gs_clear_region :: \"addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n     (\\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n      \\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x,\n      \\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd (snd gs)) x,\n      snd (snd (snd gs)))\"\n\ndefinition gs_new_frames:: \"vmpage_size \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n     if bits < pageBitsForSize sz then gs\n     else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                    x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n               else fst gs x, snd gs)\"\n\ndefinition gs_new_cnodes:: \"nat \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n     if bits < sz + 4 then gs\n     else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                       then Some sz\n                       else fst (snd gs) x, snd (snd gs))\"\n\ndefinition gs_new_pt_t:: \"pt_type \\<Rightarrow> addr \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_pt_t pt_t ptr \\<equiv>\n     \\<lambda>gs. (fst gs, fst (snd gs), (fst (snd (snd gs))) (ptr \\<mapsto> pt_t), snd (snd (snd gs)))\"\n\nabbreviation gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> machine_word\" where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd \\<circ> snd \\<circ> snd)\"\n\nabbreviation gs_set_assn :: \"int \\<Rightarrow> machine_word \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd \\<circ> apsnd \\<circ> apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Qualified Aliases: Generate appropriately qualified aliases for specific constants, ensuring they are correctly scoped and accessible within the current context.",
    "input": "",
    "output": "context begin interpretation Arch . global_naming vmpage_size\nrequalify_consts ARMSmallPage ARMLargePage ARMHugePage\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Page Table Type Constructors: Define constructors for retype annotations, specifically for normal page tables and virtual space root page tables, to be used globally in the C code.",
    "input": "",
    "output": "context begin interpretation Arch .\nrequalify_consts NormalPT_T VSRootPT_T\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 10\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide Conflicting Names: Conceal unqualified names that conflict with those in Kernel_Config, ensuring the use of the Kernel_C prefix for these names to avoid naming conflicts.",
    "input": "",
    "output": "hide_const (open)\n  numDomains",
    "system": "",
    "history": []
  },
  {
    "instruction": "ThreadState Definitions: Consolidates the definitions related to thread states, providing a more usable and accessible name for referencing these definitions.",
    "input": "",
    "output": "lemmas ThreadState_defs = StrictC'_thread_state_defs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide VMPage Sizes: Conceal the specific constants for ARM small, large, and huge page sizes.",
    "input": "",
    "output": "hide_const\n  vmpage_size.ARMSmallPage\n  vmpage_size.ARMLargePage\n  vmpage_size.ARMHugePage",
    "system": "",
    "history": []
  },
  {
    "instruction": "Re-allow Fully Qualified Accesses: Re-enables fully qualified accesses for consistency, specifically for ARM page sizes (small, large, and huge) and the AARCH64 architecture.",
    "input": "",
    "output": "context Arch begin\nglobal_naming \"AARCH64.vmpage_size\" requalify_consts ARMSmallPage ARMLargePage ARMHugePage\nglobal_naming \"AARCH64\" requalify_consts ARMSmallPage ARMLargePage ARMHugePage\nend\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Ghost State Management: Manipulate the ghost state to manage memory regions, frames, and capability nodes. Clear specific regions, allocate new frames, and create new capability nodes within the ghost state, ensuring that the system maintains a consistent and accurate representation of memory and capabilities.",
    "input": "",
    "output": "theory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . \n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> word32\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> word32 \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Create Qualified Aliases: Define and qualify constants for specific architecture page sizes and TCB-related values, ensuring consistent and accessible naming within the system.",
    "input": "",
    "output": "context begin interpretation Arch . global_naming vmpage_size\n\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 8\"\n\ndefinition\n  ctcb_offset :: \"32 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide Unqualified Names: Ensures that unqualified names conflicting with Kernel_Config names are hidden, requiring the use of the Kernel_C prefix for these names to avoid conflicts and maintain clarity.",
    "input": "",
    "output": "hide_const (open)\n  numDomains",
    "system": "",
    "history": []
  },
  {
    "instruction": "Thread State Definitions: Consolidates the definitions related to thread states, providing a more usable and accessible reference for thread state management.",
    "input": "",
    "output": "lemmas ThreadState_defs = StrictC'_thread_state_defs",
    "system": "",
    "history": []
  },
  {
    "instruction": "Hide VMPage Sizes: Conceal the specific constants related to various virtual memory page sizes, ensuring they are not directly accessible or visible in the code.",
    "input": "",
    "output": "hide_const\n vmpage_size.ARMSmallPage\n vmpage_size.ARMLargePage\n vmpage_size.ARMSection\n vmpage_size.ARMSuperSection",
    "system": "",
    "history": []
  },
  {
    "instruction": "Re-allow Fully Qualified Accesses: Enable fully qualified accesses for consistency, allowing the use of specific constants such as ARMSmallPage, ARMLargePage, ARMSection, and ARMSuperSection in the context.",
    "input": "",
    "output": "context Arch begin\n\nglobal_naming \"ARM.vmpage_size\"\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nglobal_naming ARM\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\nend\n\n\nend",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic State Monad with Failure: Represents a computation that can produce a set of possible results and states, along with a failure flag. The failure flag indicates whether any execution path in the computation may have failed. If the flag is false, all potential results are guaranteed to be successful.",
    "input": "",
    "output": "text \\<open>\n  The basic type of the nondeterministic state monad with failure is\n  very similar to the normal state monad. Instead of a pair consisting\n  of result and new state, we return a set of these pairs coupled with\n  a failure flag. Each element in the set is a potential result of the\n  computation. The flag is @{const True} if there is an execution path\n  in the computation that may have failed. Conversely, if the flag is\n  @{const False}, none of the computations resulting in the returned\n  set can have failed.\\<close>\ntype_synonym ('s, 'a) nondet_monad = \"'s \\<Rightarrow> ('a \\<times> 's) set \\<times> bool\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Type Abbreviation for Nondeterministic State Monad with Failure: Provides a more readable and concise type syntax for the nondeterministic state monad with failure, ensuring that the state variable occurs twice in the type.",
    "input": "",
    "output": "print_ast_translation \\<open>\n  let\n    fun monad_tr _ [t1, Ast.Appl [Ast.Constant @{type_syntax prod},\n                          Ast.Appl [Ast.Constant @{type_syntax set},\n                            Ast.Appl [Ast.Constant @{type_syntax prod}, t2, t3]],\n                          Ast.Constant @{type_syntax bool}]] =\n      if t3 = t1\n      then Ast.Appl [Ast.Constant @{type_syntax \"nondet_monad\"}, t1, t2]\n      else raise Match\n  in [(@{type_syntax \"fun\"}, monad_tr)] end\n\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Return Function: The return function in the nondeterministic state monad with failure does not alter the state, does not fail, and returns the specified value.",
    "input": "",
    "output": "definition return :: \"'a \\<Rightarrow> ('s,'a) nondet_monad\" where\n  \"return a \\<equiv> \\<lambda>s. ({(a,s)},False)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Binding with Failure: The bind operation combines two monadic actions, where the second action is dependent on the result of the first. The combined operation's result is the union of all possible outcomes from applying the second action to each outcome of the first. The combined operation may fail if either the first action fails or the second action fails for any of the results of the first.",
    "input": "",
    "output": "definition bind ::\n  \"('s, 'a) nondet_monad \\<Rightarrow> ('a \\<Rightarrow> ('s, 'b) nondet_monad) \\<Rightarrow> ('s, 'b) nondet_monad\" (infixl \">>=\" 60)\n  where\n  \"bind f g \\<equiv> \\<lambda>s. (\\<Union>(fst ` case_prod g ` fst (f s)),\n                   True \\<in> snd ` case_prod g ` fst (f s) \\<or> snd (f s))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Reversed Bind Operation: Allows the composition of monadic actions in a reversed order, providing flexibility in writing and understanding monadic bindings.",
    "input": "",
    "output": "abbreviation (input) bind_rev ::\n  \"('c \\<Rightarrow> ('a, 'b) nondet_monad) \\<Rightarrow> ('a, 'c) nondet_monad \\<Rightarrow> ('a, 'b) nondet_monad\" (infixl \"=<<\" 60)\n  where\n  \"g =<< f \\<equiv> f >>= g\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "State Access and Modification: The `get` function retrieves the current state without modifying it or causing failure, while the `put` function updates the state to a specified value without returning any result and without causing failure.",
    "input": "",
    "output": "definition get :: \"('s,'s) nondet_monad\" where\n  \"get \\<equiv> \\<lambda>s. ({(s,s)}, False)\"\n\ndefinition put :: \"'s \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"put s \\<equiv> \\<lambda>_. ({((),s)}, False)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Choice with Failure: The system allows for the selection of an element from a set and the nondeterministic choice between two operations. The selection does not change the state and does not fail, even if the set is empty. The alternative operation returns the union of the results of the two operations and may fail if either operation can fail.",
    "input": "",
    "output": "text \\<open>\n  Basic nondeterministic functions. @{text \"select A\"} chooses an element\n  of the set @{text A}, does not change the state, and does not fail\n  (even if the set is empty). @{text \"f \\<sqinter> g\"} executes @{text f} or\n  executes @{text g}. It retuns the union of results of @{text f} and\n  @{text g}, and may have failed if either may have failed.\\<close>\ndefinition select :: \"'a set \\<Rightarrow> ('s,'a) nondet_monad\" where\n  \"select A \\<equiv> \\<lambda>s. (A \\<times> {s}, False)\"\n\ndefinition alternative ::\n  \"('s, 'a) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad\" (infixl \"\\<sqinter>\" 20)\n  where\n  \"f \\<sqinter> g \\<equiv> \\<lambda>s. (fst (f s) \\<union> fst (g s), snd (f s) \\<or> snd (g s))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Selection with Failure: Allows the selection of a value from a set, paired with a boolean indicating whether the execution has failed. This enables the lifting of monads between different state spaces while preserving failure information.",
    "input": "",
    "output": "definition select_f :: \"'a set \\<times> bool  \\<Rightarrow> ('s,'a) nondet_monad\" where\n  \"select_f S \\<equiv> \\<lambda>s. (fst S \\<times> {s}, snd S)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic State Selection: Selects a state nondeterministically from a set of states related to the input state according to a given relationship. Fails if no such related state exists.",
    "input": "",
    "output": "definition state_select :: \"('s \\<times> 's) set \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"state_select r \\<equiv> \\<lambda>s. ((\\<lambda>x. ((), x)) ` {s'. (s, s') \\<in> r}, \\<not> (\\<exists>s'. (s, s') \\<in> r))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Failure Handling: The monad function `fail` always results in an empty set of outcomes and sets the failure flag, indicating an unsuccessful computation.",
    "input": "",
    "output": "text \\<open>\n  The monad function that always fails. Returns an empty set of results and sets the failure flag.\\<close>\ndefinition fail :: \"('s, 'a) nondet_monad\" where\n  \"fail \\<equiv> \\<lambda>s. ({}, True)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Property: Assertion Validation: Ensures that a given property \\( P \\) holds, failing the computation if \\( P \\) is not true.",
    "input": "",
    "output": "definition assert :: \"bool \\<Rightarrow> ('a, unit) nondet_monad\" where\n  \"assert P \\<equiv> if P then return () else fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Assertion with Optional Values: Ensures that the computation fails if the value is `None`, and returns the result `v` if the value is `Some v`.",
    "input": "",
    "output": "definition assert_opt :: \"'a option \\<Rightarrow> ('b, 'a) nondet_monad\" where\n  \"assert_opt v \\<equiv> case v of None \\<Rightarrow> fail | Some v \\<Rightarrow> return v\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "State Assertion with Introspection: Allows for the introspection of the current state and asserts a condition based on that state.",
    "input": "",
    "output": "definition state_assert :: \"('s \\<Rightarrow> bool) \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"state_assert P \\<equiv> get >>= (\\<lambda>s. assert (P s))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "State Retrieval: Retrieve the current state and apply a function to it, returning the result without modifying the state.",
    "input": "",
    "output": "text \\<open>Apply a function to the current state and return the result without changing the state.\\<close>\ndefinition gets :: \"('s \\<Rightarrow> 'a) \\<Rightarrow> ('s, 'a) nondet_monad\" where\n  \"gets f \\<equiv> get >>= (\\<lambda>s. return (f s))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "State Modification: Allows the current state to be updated using a provided function, ensuring that the state transformation is encapsulated and applied atomically.",
    "input": "",
    "output": "definition modify :: \"('s \\<Rightarrow> 's) \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"modify f \\<equiv> get >>= (\\<lambda>s. put (f s))\"\n\nlemma simpler_gets_def:\n  \"gets f = (\\<lambda>s. ({(f s, s)}, False))\"\n  by (simp add: gets_def return_def bind_def get_def)\n\nlemma simpler_modify_def:\n  \"modify f = (\\<lambda>s. ({((), f s)}, False))\"\n  by (simp add: modify_def bind_def get_def put_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Conditional Execution: Execute the given monadic action only if the specified condition is true, otherwise return a unit value.",
    "input": "",
    "output": "definition \"when\" :: \"bool \\<Rightarrow> ('s, unit) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"when P m \\<equiv> if P then m else return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Conditional Execution: Execute the given monadic action only if the specified condition is false, otherwise return a unit value.",
    "input": "",
    "output": "definition unless :: \"bool \\<Rightarrow> ('s, unit) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"unless P m \\<equiv> when (\\<not>P) m\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Conditional Execution: Execute one of two monadic actions based on a condition. If the condition is true, the left action is performed; otherwise, the right action is executed.",
    "input": "",
    "output": "definition condition ::\n  \"('s \\<Rightarrow> bool) \\<Rightarrow> ('s, 'r) nondet_monad \\<Rightarrow> ('s, 'r) nondet_monad \\<Rightarrow> ('s, 'r) nondet_monad\"\n  where\n  \"condition P L R \\<equiv> \\<lambda>s. if (P s) then (L s) else (R s)\"\n\nnotation (output)\n  condition  (\"(condition (_)//  (_)//  (_))\" [1000,1000,1000] 1000)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Apply Option-Valued Function: Execute an option-valued function on the current state, failing if the result is `None` and returning the value `v` if the result is `Some v`.",
    "input": "",
    "output": "definition gets_the :: \"('s \\<Rightarrow> 'a option) \\<Rightarrow> ('s, 'a) nondet_monad\" where\n  \"gets_the f \\<equiv> gets f >>= assert_opt\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Retrieve Map Value: Access a map from the current state and apply a given argument to retrieve a value. If the map returns `None`, the operation fails; otherwise, it returns the retrieved value.",
    "input": "",
    "output": "definition gets_map :: \"('s \\<Rightarrow> 'a \\<Rightarrow> 'b option) \\<Rightarrow> 'a \\<Rightarrow> ('s, 'b) nondet_monad\" where\n  \"gets_map f p \\<equiv> gets f >>= (\\<lambda>m. assert_opt (m p))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic State Monad with Failure: The bind operation for the monad is defined in a way that it combines the results and failures of two monadic actions, ensuring that the overall computation reflects both the possible outcomes and the potential for failure.",
    "input": "",
    "output": "text \\<open>An alternative definition of @{term bind}, sometimes more convenient.\\<close>\nlemma bind_def':\n  \"(f >>= g) \\<equiv>\n       \\<lambda>s. ({(r'', s''). \\<exists>(r', s') \\<in> fst (f s). (r'', s'') \\<in> fst (g r' s') },\n                     snd (f s) \\<or> (\\<exists>(r', s') \\<in> fst (f s). snd (g r' s')))\"\n  by (rule eq_reflection)\n     (auto simp add: bind_def split_def Let_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Return Absorption: The `return` function, when bound to another function `f`, directly applies the return value to `f`, effectively absorbing the `return` operation.",
    "input": "",
    "output": "lemma return_bind[simp]:\n  \"(return x >>= f) = f x\"\n  by (simp add: return_def bind_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Monad Absorption: The bind operation with the return function on the right is equivalent to the original monad value, ensuring that the monad's structure is preserved.",
    "input": "",
    "output": "lemma bind_return[simp]:\n  \"(m >>= return) = m\"\n  by (simp add: bind_def return_def split_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Bind Associativity: The bind operation in the nondeterministic state monad with failure is associative, ensuring that the order of operations does not affect the final result.",
    "input": "",
    "output": "lemma bind_assoc:\n  fixes m :: \"('a,'b) nondet_monad\"\n  fixes f :: \"'b \\<Rightarrow> ('a,'c) nondet_monad\"\n  fixes g :: \"'c \\<Rightarrow> ('a,'d) nondet_monad\"\n  shows \"(m >>= f) >>= g  =  m >>= (\\<lambda>x. f x >>= g)\"\n  unfolding bind_def Let_def split_def\n  by (auto intro: rev_image_eqI)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling in Nondeterministic State Monad: The monad supports both normal and exceptional return values, allowing for explicit handling of exceptions. Normal return values are wrapped using `returnOk`, while exceptions are thrown using `throwError`.",
    "input": "",
    "output": "text \\<open>\n  The type @{typ \"('s,'a) nondet_monad\"} gives us nondeterminism and\n  failure. We now extend this monad with exceptional return values\n  that abort normal execution, but can be handled explicitly.\n  We use the sum type to indicate exceptions.\n\n  In @{typ \"('s, 'e + 'a) nondet_monad\"}, @{typ \"'s\"} is the state,\n  @{typ 'e} is an exception, and @{typ 'a} is a normal return value.\n\n  This new type itself forms a monad again. Since type classes in\n  Isabelle are not powerful enough to express the class of monads,\n  we provide new names for the @{term return} and @{term bind} functions\n  in this monad. We call them @{text returnOk} (for normal return values)\n  and @{text bindE} (for composition). We also define @{text throwError}\n  to return an exceptional value.\\<close>\ndefinition returnOk :: \"'a \\<Rightarrow> ('s, 'e + 'a) nondet_monad\" where\n  \"returnOk \\<equiv> return o Inr\"\n\ndefinition throwError :: \"'e \\<Rightarrow> ('s, 'e + 'a) nondet_monad\" where\n  \"throwError \\<equiv> return o Inl\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lifting with Exception Handling: Lifts a function to handle exceptions, where if the input is an exception, it returns that exception; otherwise, it continues with the function execution.",
    "input": "",
    "output": "definition lift :: \"('a \\<Rightarrow> ('s, 'e + 'b) nondet_monad) \\<Rightarrow> 'e +'a \\<Rightarrow> ('s, 'e + 'b) nondet_monad\" where\n  \"lift f v \\<equiv> case v of Inl e \\<Rightarrow> throwError e | Inr v' \\<Rightarrow> f v'\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling in Bind: The bind operation in the exception monad, denoted as `>>=E`, behaves like a standard bind but skips the execution of the right-hand side if the left-hand side produces an exception. This ensures that exceptions are properly propagated and handled within the monadic computation.",
    "input": "",
    "output": "definition bindE ::\n  \"('s, 'e + 'a) nondet_monad \\<Rightarrow> ('a \\<Rightarrow> ('s, 'e + 'b) nondet_monad) \\<Rightarrow> ('s, 'e + 'b) nondet_monad\"\n  (infixl \">>=E\" 60) where\n  \"f >>=E g \\<equiv> f >>= lift g\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lifting Nondeterministic Monad: Transforms a nondeterministic monad into an exception monad by wrapping its result in a normal result constructor, ensuring that no exceptions are thrown.",
    "input": "",
    "output": "definition liftE :: \"('s,'a) nondet_monad \\<Rightarrow> ('s, 'e+'a) nondet_monad\" where\n  \"liftE f \\<equiv> f >>= (\\<lambda>r. return (Inr r))\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Conditional Execution in Nondeterministic Monad:\n- `whenE` executes a given monadic action if a condition is true, otherwise it returns a successful result.\n- `unlessE` executes a given monadic action if a condition is false, otherwise it returns a successful result.",
    "input": "",
    "output": "definition whenE :: \"bool \\<Rightarrow> ('s, 'e + unit) nondet_monad \\<Rightarrow> ('s, 'e + unit) nondet_monad\" where\n  \"whenE P f \\<equiv> if P then f else returnOk ()\"\n\ndefinition unlessE :: \"bool \\<Rightarrow> ('s, 'e + unit) nondet_monad \\<Rightarrow> ('s, 'e + unit) nondet_monad\" where\n  \"unlessE P f \\<equiv> if P then returnOk () else f\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling with Optional Values: Throws an exception if the input is `None`, otherwise returns the value wrapped in `Some`.",
    "input": "",
    "output": "definition throw_opt :: \"'e \\<Rightarrow> 'a option \\<Rightarrow> ('s, 'e + 'a) nondet_monad\" where\n  \"throw_opt ex x \\<equiv> case x of None \\<Rightarrow> throwError ex | Some v \\<Rightarrow> returnOk v\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Assertion with Exceptional Failure: The `assertE` function checks a boolean condition and returns `returnOk ()` if the condition is true, otherwise it fails with an exception.",
    "input": "",
    "output": "definition assertE :: \"bool \\<Rightarrow> ('a, 'e + unit) nondet_monad\" where\n  \"assertE P \\<equiv> if P then returnOk () else fail\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lift Exception: The `liftE` function transforms a computation that may fail into a computation in the exception monad, wrapping the result in a right constructor and preserving the state.",
    "input": "",
    "output": "text \\<open>More direct definition of @{const liftE}:\\<close>\nlemma liftE_def2:\n  \"liftE f = (\\<lambda>s. ((\\<lambda>(v,s'). (Inr v, s')) ` fst (f s), snd (f s)))\"\n  by (auto simp: liftE_def return_def split_def bind_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Left Return Absorption: The `returnOk` function, when bound with another function `f` using the `bindE` operator, is equivalent to simply applying `f` to the value. This property ensures that `returnOk` acts as a left identity for the `bindE` operation, maintaining the integrity and consistency of the monadic computation.",
    "input": "",
    "output": "lemma returnOk_bindE[simp]: \"(returnOk x >>=E f) = f x\"\n  unfolding bindE_def returnOk_def\n  by (clarsimp simp: lift_def)\n\nlemma lift_return[simp]:\n  \"lift (return \\<circ> Inr) = return\"\n  by (auto simp: lift_def throwError_def split: sum.splits)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Right Absorption Law: The bind operation with the returnOk function on the right side is equivalent to the original monadic value, ensuring that the structure and behavior of the monad are preserved.",
    "input": "",
    "output": "lemma bindE_returnOk[simp]:\n  \"(m >>=E returnOk) = m\"\n  by (simp add: bindE_def returnOk_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Associativity of Bind with Exception Handling: The bind operation with exception handling (bindE) is associative, ensuring that the order in which operations are composed does not affect the final result.",
    "input": "",
    "output": "lemma bindE_assoc:\n  \"(m >>=E f) >>=E g = m >>=E (\\<lambda>x. f x >>=E g)\"\n  unfolding bindE_def\n  by (fastforce simp: bind_assoc lift_def throwError_def\n                split: sum.splits\n                intro: arg_cong[where f=\"\\<lambda>x. m >>= x\"])",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic State Monad with Failure: The `returnOk` function can be equivalently defined using the `liftE` function, ensuring that both functions behave identically in the context of the monad.",
    "input": "",
    "output": "lemma returnOk_liftE:\n  \"returnOk x = liftE (return x)\"\n  by (simp add: liftE_def returnOk_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Propagation: Throwing an exception causes the subsequent execution to be skipped, ensuring that no further operations are performed after an exception is thrown.",
    "input": "",
    "output": "lemma throwError_bindE[simp]:\n  \"(throwError E >>=E f) = throwError E\"\n  by (simp add: bindE_def bind_def throwError_def lift_def return_def)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic State Monad with Failure: Ensures that the monad operations adhere to the traditional monad laws, providing a consistent and predictable behavior for stateful computations with the possibility of failure.",
    "input": "",
    "output": "text \\<open>This section defines traditional Haskell-like do-syntax\n  for the state monad in Isabelle.\\<close>",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic State Monad with Failure: Provides syntax for the exception monad, including binding and sequencing operations. The `K_bind` function is used to ignore the return value of the left side of a bind operation, allowing for more flexible and concise do-notation in the monad.",
    "input": "",
    "output": "text \\<open>\n  We use @{text K_bind} to syntactically indicate the case where the return argument\n  of the left side of a @{term bind} is ignored\\<close>\ndefinition K_bind :: \"'a \\<Rightarrow> 'b \\<Rightarrow> 'a\" where\n  K_bind_def[iff]: \"K_bind \\<equiv> \\<lambda>x y. x\"\n\nnonterminal\n  dobinds and dobind and nobind\n\nsyntax\n  \"_dobind\"    :: \"[pttrn, 'a] => dobind\"             (\"(_ <-/ _)\" 10)\n  \"\"           :: \"dobind => dobinds\"                 (\"_\")\n  \"_nobind\"    :: \"'a => dobind\"                      (\"_\")\n  \"_dobinds\"   :: \"[dobind, dobinds] => dobinds\"      (\"(_);//(_)\")\n\n  \"_do\"        :: \"[dobinds, 'a] => 'a\"               (\"(do ((_);//(_))//od)\" 100)\nsyntax (xsymbols)\n  \"_dobind\"    :: \"[pttrn, 'a] => dobind\"             (\"(_ \\<leftarrow>/ _)\" 10)\n\ntranslations\n  \"_do (_dobinds b bs) e\"  == \"_do b (_do bs e)\"\n  \"_do (_nobind b) e\"      == \"b >>= (CONST K_bind e)\"\n  \"do x <- a; e od\"        == \"a >>= (\\<lambda>x. e)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic State Monad with Failure: The monad allows for sequencing of operations, where the result of one operation can be used in subsequent operations. The final result is determined by the last return value, and intermediate return values are discarded.",
    "input": "",
    "output": "lemma \"do x \\<leftarrow> return 1;\n          return (2::nat);\n          return x\n       od =\n       return 1 >>=\n       (\\<lambda>x. return (2::nat) >>=\n            K_bind (return x))\"\n  by (rule refl)\n\nlemma \"do x \\<leftarrow> return 1;\n          return 2;\n          return x\n       od = return 1\"\n  by simp",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling in Nondeterministic State Monad: Provides a syntax for handling exceptions within a monadic context, using the @{text doE}/@{text odE} notation to sequence operations and handle failures.",
    "input": "",
    "output": "text \\<open>\n  Since the exception monad is a different type, we need to distinguish it in the syntax\n  if we want to avoid ambiguous terms. We use @{text doE}/@{text odE} for this, but can\n  re-use most of the productions from @{text do}/@{text od} above. \\<close>\nsyntax\n  \"_doE\" :: \"[dobinds, 'a] => 'a\"  (\"(doE ((_);//(_))//odE)\" 100)\n\ntranslations\n  \"_doE (_dobinds b bs) e\"  == \"_doE b (_doE bs e)\"\n  \"_doE (_nobind b) e\"      == \"b >>=E (CONST K_bind e)\"\n  \"doE x <- a; e odE\"       == \"a >>=E (\\<lambda>x. e)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic State Monad with Failure: The monad supports sequencing of operations, where the result of one operation can be used in subsequent operations. If an operation fails, the entire sequence fails, and the final result is determined by the last successful operation in the sequence.",
    "input": "",
    "output": "lemma \"doE x \\<leftarrow> returnOk 1;\n           returnOk (2::nat);\n           returnOk x\n       odE =\n       returnOk 1 >>=E\n       (\\<lambda>x. returnOk (2::nat) >>=E\n            K_bind (returnOk x))\"\n  by (rule refl)\n\nlemma \"doE x \\<leftarrow> returnOk 1;\n           returnOk 2;\n           returnOk x\n       odE = returnOk 1\"\n  by simp",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lift Function into Monad: Elevates a pure function into the nondeterministic monad, allowing it to operate on values within the monadic context.",
    "input": "",
    "output": "text \\<open>Lifting a normal function into the monad type:\\<close>\ndefinition liftM :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> ('s,'a) nondet_monad \\<Rightarrow> ('s, 'b) nondet_monad\" where\n  \"liftM f m \\<equiv> do x \\<leftarrow> m; return (f x) od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Lift Function in Exception Monad: Applies a function to the result of a monadic computation, wrapping the result in an `Ok` value within the exception monad.",
    "input": "",
    "output": "definition liftME :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> ('s,'e+'a) nondet_monad \\<Rightarrow> ('s,'e+'b) nondet_monad\" where\n  \"liftME f m \\<equiv> doE x \\<leftarrow> m; returnOk (f x) odE\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Conditional Execution: Execute a given function for a provided value if it is present, otherwise do nothing.",
    "input": "",
    "output": "definition maybeM :: \"('a \\<Rightarrow> ('s, unit) nondet_monad) \\<Rightarrow> 'a option \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"maybeM f y \\<equiv> case y of Some x \\<Rightarrow> f x | None \\<Rightarrow> return ()\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Sequential Execution of Monads: Execute a list of monadic actions in sequence from left to right, discarding their return values.",
    "input": "",
    "output": "definition sequence_x :: \"('s, 'a) nondet_monad list \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"sequence_x xs \\<equiv> foldr (\\<lambda>x y. x >>= (\\<lambda>_. y)) xs (return ())\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Map Monadic Function Over List: Apply a monadic function to each element of a list from left to right, ignoring the return values.",
    "input": "",
    "output": "definition mapM_x :: \"('a \\<Rightarrow> ('s,'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"mapM_x f xs \\<equiv> sequence_x (map f xs)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Zip With Monad: Apply a monadic function to pairs of elements from two lists simultaneously, ignoring the return values. This ensures that the function is applied in a left-to-right order, and any side effects are executed, but the results are not collected.",
    "input": "",
    "output": "definition zipWithM_x ::\n  \"('a \\<Rightarrow> 'b \\<Rightarrow> ('s,'c) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> 'b list \\<Rightarrow> ('s, unit) nondet_monad\"\n  where\n  \"zipWithM_x f xs ys \\<equiv> sequence_x (zipWith f xs ys)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Monadic Combinators for Nondeterministic Computations: Provide functions to sequence, map, and fold over lists in a nondeterministic monad, allowing for the execution of multiple monadic actions and accumulation of results. These combinators enable the construction of complex monadic operations from simpler ones, supporting both successful and error-handling scenarios.",
    "input": "",
    "output": "definition sequence :: \"('s, 'a) nondet_monad list \\<Rightarrow> ('s, 'a list) nondet_monad\" where\n  \"sequence xs \\<equiv> let mcons = (\\<lambda>p q. p >>= (\\<lambda>x. q >>= (\\<lambda>y. return (x#y))))\n                 in foldr mcons xs (return [])\"\n\ndefinition mapM :: \"('a \\<Rightarrow> ('s,'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s, 'b list) nondet_monad\" where\n  \"mapM f xs \\<equiv> sequence (map f xs)\"\n\ndefinition zipWithM ::\n  \"('a \\<Rightarrow> 'b \\<Rightarrow> ('s,'c) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> 'b list \\<Rightarrow> ('s, 'c list) nondet_monad\"\n  where\n  \"zipWithM f xs ys \\<equiv> sequence (zipWith f xs ys)\"\n\ndefinition foldM ::\n  \"('b \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad) \\<Rightarrow> 'b list \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad\"\n  where\n  \"foldM m xs a \\<equiv> foldr (\\<lambda>p q. q >>= m p) xs (return a) \"\n\ndefinition foldME ::\n  \"('b \\<Rightarrow> 'a \\<Rightarrow> ('s,('e + 'b)) nondet_monad) \\<Rightarrow> 'b \\<Rightarrow> 'a list \\<Rightarrow> ('s, ('e + 'b)) nondet_monad\"\n  where\n  \"foldME m a xs \\<equiv> foldr (\\<lambda>p q. q >>=E swp m p) xs (returnOk a)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Nondeterministic Monad Sequencing: Provides functions to sequence and map monadic operations, handling both unit and list return values. The `sequenceE_x` and `mapME_x` functions execute a list of monadic actions, discarding their results, while `sequenceE` and `mapME` collect the results into a list.",
    "input": "",
    "output": "definition sequenceE_x :: \"('s, 'e+'a) nondet_monad list \\<Rightarrow> ('s, 'e+unit) nondet_monad\" where\n  \"sequenceE_x xs \\<equiv> foldr (\\<lambda>x y. doE _ <- x; y odE) xs (returnOk ())\"\n\ndefinition mapME_x :: \"('a \\<Rightarrow> ('s,'e+'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s,'e+unit) nondet_monad\" where\n  \"mapME_x f xs \\<equiv> sequenceE_x (map f xs)\"\n\ndefinition sequenceE :: \"('s, 'e+'a) nondet_monad list \\<Rightarrow> ('s, 'e+'a list) nondet_monad\" where\n  \"sequenceE xs \\<equiv> let mcons = (\\<lambda>p q. p >>=E (\\<lambda>x. q >>=E (\\<lambda>y. returnOk (x#y))))\n                   in foldr mcons xs (returnOk [])\"\n\ndefinition mapME ::\n  \"('a \\<Rightarrow> ('s,'e+'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s,'e+'b list) nondet_monad\"\n  where\n  \"mapME f xs \\<equiv> sequenceE (map f xs)\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Filtering with Monadic Predicate: Recursively filter a list by applying a monadic predicate to each element, including the element in the result if the predicate returns true, and excluding it otherwise.",
    "input": "",
    "output": "primrec filterM :: \"('a \\<Rightarrow> ('s, bool) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s, 'a list) nondet_monad\" where\n  \"filterM P []       = return []\"\n| \"filterM P (x # xs) = do\n     b  <- P x;\n     ys <- filterM P xs;\n     return (if b then (x # ys) else ys)\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "State Selection with Relation: Select a new state based on a given relation, ensuring that the set of possible new states is non-empty before making the selection.",
    "input": "",
    "output": "lemma state_select_def2:\n  \"state_select r \\<equiv> (do\n    s \\<leftarrow> get;\n    S \\<leftarrow> return {s'. (s, s') \\<in> r};\n    assert (S \\<noteq> {});\n    s' \\<leftarrow> select S;\n    put s'\n  od)\"\n  apply (clarsimp simp add: state_select_def get_def return_def assert_def fail_def select_def\n                            put_def bind_def fun_eq_iff\n                    intro!: eq_reflection)\n  apply fastforce\n  done",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling in Nondeterministic State Monad: Transforms an exception monad into a normal state monad by catching and handling any potential exceptions. If the computation succeeds, it returns the result; if it fails, it invokes a handler to process the exception.",
    "input": "",
    "output": "text \\<open>\n  Turning an exception monad into a normal state monad\n  by catching and handling any potential exceptions:\\<close>\ndefinition catch ::\n  \"('s, 'e + 'a) nondet_monad \\<Rightarrow> ('e \\<Rightarrow> ('s, 'a) nondet_monad) \\<Rightarrow> ('s, 'a) nondet_monad\"\n  (infix \"<catch>\" 10) where\n  \"f <catch> handler \\<equiv>\n     do x \\<leftarrow> f;\n        case x of\n          Inr b \\<Rightarrow> return b\n        | Inl e \\<Rightarrow> handler e\n     od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling in Nondeterministic Monad: Allows for the handling of exceptions within a nondeterministic monad, where the handler can throw a different type of exception than the original. The function continues with the returned value if no exception occurs, or invokes the handler if an exception is caught.",
    "input": "",
    "output": "definition handleE' ::\n  \"('s, 'e1 + 'a) nondet_monad \\<Rightarrow> ('e1 \\<Rightarrow> ('s, 'e2 + 'a) nondet_monad) \\<Rightarrow> ('s, 'e2 + 'a) nondet_monad\"\n  (infix \"<handle2>\" 10) where\n  \"f <handle2> handler \\<equiv>\n   do\n      v \\<leftarrow> f;\n      case v of\n        Inl e \\<Rightarrow> handler e\n      | Inr v' \\<Rightarrow> return (Inr v')\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling: Allows for the catching and handling of exceptions within a nondeterministic state monad, where the exception handler can potentially throw an exception of the same type as the original.",
    "input": "",
    "output": "definition handleE ::\n  \"('s, 'x + 'a) nondet_monad \\<Rightarrow> ('x \\<Rightarrow> ('s, 'x + 'a) nondet_monad) \\<Rightarrow> ('s, 'x + 'a) nondet_monad\"\n  (infix \"<handle>\" 10) where\n  \"handleE \\<equiv> handleE'\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Exception Handling with Continuation: Manages exceptions by applying a handler if an exception is thrown, and a continuation if no exception occurs. This ensures that both error handling and normal flow are appropriately addressed.",
    "input": "",
    "output": "definition handle_elseE ::\n  \"('s, 'e + 'a) nondet_monad \\<Rightarrow> ('e \\<Rightarrow> ('s, 'ee + 'b) nondet_monad) \\<Rightarrow>\n   ('a \\<Rightarrow> ('s, 'ee + 'b) nondet_monad) \\<Rightarrow> ('s, 'ee + 'b) nondet_monad\" (\"_ <handle> _ <else> _\" 10)\n  where\n  \"f <handle> handler <else> continue \\<equiv>\n   do v \\<leftarrow> f;\n      case v of Inl e  \\<Rightarrow> handler e\n              | Inr v' \\<Rightarrow> continue v'\n   od\"",
    "system": "",
    "history": []
  },
  {
    "instruction": "Loop Execution with Exception Handling: The while loop executes as long as the condition is true, and it handles non-termination and exceptions using a nondeterministic monad. The loop terminates if the condition is false or if all possible next states lead to termination. If the loop fails to terminate, it returns a failure flag.",
    "input": "",
    "output": "text \\<open>\n  Loops are handled using the following inductive predicate;\n  non-termination is represented using the failure flag of the\n  monad.\\<close>\n\ninductive_set whileLoop_results ::\n  \"('r \\<Rightarrow> 's \\<Rightarrow> bool) \\<Rightarrow> ('r \\<Rightarrow> ('s, 'r) nondet_monad) \\<Rightarrow> ((('r \\<times> 's) option) \\<times> (('r \\<times> 's) option)) set\"\n  for C B where\n    \"\\<lbrakk> \\<not> C r s \\<rbrakk> \\<Longrightarrow> (Some (r, s), Some (r, s)) \\<in> whileLoop_results C B\"\n  | \"\\<lbrakk> C r s; snd (B r s) \\<rbrakk> \\<Longrightarrow> (Some (r, s), None) \\<in> whileLoop_results C B\"\n  | \"\\<lbrakk> C r s; (r', s') \\<in> fst (B r s); (Some (r', s'), z) \\<in> whileLoop_results C B  \\<rbrakk>\n       \\<Longrightarrow> (Some (r, s), z) \\<in> whileLoop_results C B\"\n\ninductive_cases whileLoop_results_cases_valid: \"(Some x, Some y) \\<in> whileLoop_results C B\"\ninductive_cases whileLoop_results_cases_fail: \"(Some x, None) \\<in> whileLoop_results C B\"\ninductive_simps whileLoop_results_simps: \"(Some x, y) \\<in> whileLoop_results C B\"\ninductive_simps whileLoop_results_simps_valid: \"(Some x, Some y) \\<in> whileLoop_results C B\"\ninductive_simps whileLoop_results_simps_start_fail[simp]: \"(None, x) \\<in> whileLoop_results C B\"\n\ninductive whileLoop_terminates ::\n  \"('r \\<Rightarrow> 's \\<Rightarrow> bool) \\<Rightarrow> ('r \\<Rightarrow> ('s, 'r) nondet_monad) \\<Rightarrow> 'r \\<Rightarrow> 's \\<Rightarrow> bool\"\n  for C B where\n    \"\\<not> C r s \\<Longrightarrow> whileLoop_terminates C B r s\"\n  | \"\\<lbrakk> C r s; \\<forall>(r', s') \\<in> fst (B r s). whileLoop_terminates C B r' s' \\<rbrakk>\n        \\<Longrightarrow> whileLoop_terminates C B r s\"\n\ninductive_cases whileLoop_terminates_cases: \"whileLoop_terminates C B r s\"\ninductive_simps whileLoop_terminates_simps: \"whileLoop_terminates C B r s\"\n\ndefinition whileLoop ::\n  \"('a \\<Rightarrow> 'b \\<Rightarrow> bool) \\<Rightarrow> ('a \\<Rightarrow> ('b, 'a) nondet_monad) \\<Rightarrow> 'a \\<Rightarrow> ('b, 'a) nondet_monad\"\n  where\n  \"whileLoop C B \\<equiv> \\<lambda>r s.\n     ({(r',s'). (Some (r, s), Some (r', s')) \\<in> whileLoop_results C B},\n      (Some (r, s), None) \\<in> whileLoop_results C B \\<or> \\<not>whileLoop_terminates C B r s)\"\n\nnotation (output)\n  whileLoop  (\"(whileLoop (_)//  (_))\" [1000, 1000] 1000)\n\ndefinition whileLoopE ::\n  \"('r \\<Rightarrow> 's \\<Rightarrow> bool) \\<Rightarrow> ('r \\<Rightarrow> ('s, 'e + 'r) nondet_monad) \\<Rightarrow> 'r \\<Rightarrow> 's \\<Rightarrow> (('e + 'r) \\<times> 's) set \\<times> bool\"\n  where\n  \"whileLoopE C body \\<equiv>\n     \\<lambda>r. whileLoop (\\<lambda>r s. (case r of Inr v \\<Rightarrow> C v s | _ \\<Rightarrow> False)) (lift body) (Inr r)\"\n\nnotation (output)\n  whileLoopE  (\"(whileLoopE (_)//  (_))\" [1000, 1000] 1000)",
    "system": "",
    "history": []
  },
  {
    "instruction": "Control Flow with Conditions: Provides combinators for conditional and repetitive execution within a nondeterministic state monad, enabling the evaluation of conditions with side effects and the execution of corresponding actions. These combinators include negation, while loops, if-then-else statements, and logical operations, allowing for flexible and expressive control flow in the presence of nondeterminism.",
    "input": "",
    "output": "definition notM :: \"('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad\" where\n  \"notM m = do c \\<leftarrow> m; return (\\<not> c) od\"\n\ndefinition whileM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad\"\n  where\n  \"whileM C B \\<equiv> do\n    c \\<leftarrow> C;\n    whileLoop (\\<lambda>c s. c) (\\<lambda>_. do B; C od) c;\n    return ()\n  od\"\n\ndefinition ifM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad\"\n  where\n  \"ifM test t f = do\n    c \\<leftarrow> test;\n    if c then t else f\n   od\"\n\ndefinition ifME ::\n  \"('a, 'b + bool) nondet_monad \\<Rightarrow> ('a, 'b + 'c) nondet_monad \\<Rightarrow> ('a, 'b + 'c) nondet_monad\n   \\<Rightarrow> ('a, 'b + 'c) nondet_monad\"\n  where\n  \"ifME test t f = doE\n    c \\<leftarrow> test;\n    if c then t else f\n   odE\"\n\ndefinition whenM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad\"\n  where\n  \"whenM t m = ifM t m (return ())\"\n\ndefinition orM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad\"\n  where\n  \"orM a b = ifM a (return True) b\"\n\ndefinition andM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad\"\n  where\n  \"andM a b = ifM a b (return False)\"\n\nend",
    "system": "",
    "history": []
  }
]