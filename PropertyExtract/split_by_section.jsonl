{"title": "./spec/sep-abstract/Syscall_SA.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  Top-level system call interface of reduced kernel API.\n*)\n\nchapter \"Separation Kernel Abstract Specification\"\n\ntheory Syscall_SA\nimports Decode_SA\nbegin"}
{"title": "./spec/sep-abstract/Syscall_SA.thy", "section": "Generic system call structure\\label{s:spec_syscall}", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n\n  The Separation Kernel maintains separation between processes by limiting the capabilities that are\n  present in the system. We call these the \"restricted capabilities\" in the documentation that\n  follows.\n\n  The specification described here, the Separation Kernel Abstract Specification (abbreviated\n  \\texttt{sep-abstract} from here on in), is identical to the Abstract Specification\n  (aka. \\texttt{abstract}), except that the following system calls have been overridden to\n  provide reduced (fully static) functionality only.\n\n  \\begin{itemize}\n  \\item{handle_fault}\n  \\item{invoke_irq_handler}\n  \\item{decode_invocation}\n  \\item{perform_invocation}\n  \\item{handle_invocation}\n  \\item{handle_reply}\n  \\item{handle_event}\n  \\item{call_kernel}\n  \\end{itemize}\n\n  The resulting kernel API is simplified significantly compared to full seL4.\n  The changes to the original abstract specification are minimal, except that it contains\n  much fewer system calls.\n\n  We achieve this by modifying the cases distinctions that determine which API call is\n  to by executed. The new case distinctions\n  on capabilities only provide code for the restricted capabilities in our reduced setup,\n  otherwise they fail (i.e. throw an exception).\n\n  We then prove that \\texttt{sep-abstract} and \\texttt{abstract} have the same behaviour under the\n  restricted capabilities of the separation kernel via bi-simulation. This simply requires that we\n  prove refinement in both directions. This proof implies that the missing (failing) code branches\n  in the reduced specification can never be executed.\n\n  It is clear that the behaviour will be the same for the \"mostly identical\" overridden\n  definitions. In a few cases, which are documented below, the definitions have bigger differencess.\n  We provide ab informal explanation at the site of the overriden definition in each of these\n  cases. (The bi-simulation proof provides the formal demonstration.)\n\n\\<close>"}
{"title": "./spec/sep-abstract/Syscall_SA.thy", "section": "System call entry point", "subsection": "", "subsubsection": "", "code": "\nfun\n  perform_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\nwhere\n  \"perform_invocation block call (InvokeNotification ep badge) =\n    doE\n      without_preemption $ send_signal ep badge;\n      returnOk []\n    odE\"\n| \"perform_invocation _ _ _ = fail\"\n\ndefinition\n  handle_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"handle_invocation calling blocking \\<equiv> doE\n    thread \\<leftarrow> liftE $ gets cur_thread;\n    info \\<leftarrow> without_preemption $ get_message_info thread;\n    ptr \\<leftarrow> without_preemption $ liftM data_to_cptr $\n          as_user thread $ getRegister cap_register;\n    syscall\n      (doE\n         (cap, slot) \\<leftarrow> cap_fault_on_failure (of_bl ptr) False $ lookup_cap_and_slot thread ptr;\n         buffer \\<leftarrow> liftE $ lookup_ipc_buffer False thread;\n         extracaps \\<leftarrow> lookup_extra_caps thread buffer info;\n         returnOk (slot, cap, extracaps, buffer)\n       odE)\n      (\\<lambda>fault. when blocking $ handle_fault thread fault)\n      (\\<lambda>(slot,cap,extracaps,buffer). doE\n            args \\<leftarrow> liftE $ get_mrs thread buffer info;\n            decode_invocation (mi_label info) args ptr slot cap extracaps\n       odE)\n      (\\<lambda>err. when calling $\n            reply_from_kernel thread $ msg_from_syscall_error err)\n      (\\<lambda>oper. doE\n            without_preemption $ set_thread_state thread Restart;\n            reply \\<leftarrow> perform_invocation blocking calling oper;\n            without_preemption $ do\n                state \\<leftarrow> get_thread_state thread;\n                case state of\n                      Restart \\<Rightarrow> do\n                          when calling $\n                              reply_from_kernel thread (0, reply);\n                          set_thread_state thread Running\n                      od\n                    | _ \\<Rightarrow>  return ()\n            od\n       odE)\n  odE\"\n\ndefinition\n  handle_yield :: \"(unit,'z::state_ext) s_monad\" where\n  \"handle_yield \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n     do_extended_op (tcb_sched_action (tcb_sched_dequeue) thread);\n     do_extended_op (tcb_sched_action (tcb_sched_append) thread);\n     do_extended_op reschedule_required\n   od\"\n\ndefinition\n  handle_send :: \"bool \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n  \"handle_send bl \\<equiv> handle_invocation False bl\"\n\ndefinition\n  handle_call :: \"(unit,'z::state_ext) p_monad\" where\n \"handle_call \\<equiv> handle_invocation True True\"\n\ntext \\<open>\n\n  This definition of \\texttt{handle_recv} is almost identical to the abstract specification's definition\n  for the restricted capabilities. Also, a call to \\texttt{delete_caller_cap} has been removed. They have\n  the same behaviour under the restricted capabilities since there are no caller capabilities in\n  \\texttt{sep-abstract}.\n\n\\<close>\n\ndefinition\n  handle_recv :: \"bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"handle_recv is_blocking \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n\n     ep_cptr \\<leftarrow> liftM data_to_cptr $ as_user thread $\n                 getRegister cap_register;\n\n     (cap_fault_on_failure (of_bl ep_cptr) True $ doE\n        ep_cap \\<leftarrow> lookup_cap thread ep_cptr;\n\n        let flt = (throwError $ MissingCapability 0)\n        in\n        case ep_cap\n          of\n            NotificationCap ref badge rights \\<Rightarrow>\n             (if AllowRecv \\<in> rights\n              then doE\n                ntfn \\<leftarrow> liftE $ get_notification ref;\n                boundTCB \\<leftarrow> returnOk $ ntfn_bound_tcb ntfn;\n                if boundTCB = Some thread \\<or> boundTCB = None\n                then liftE $ receive_signal thread ep_cap is_blocking\n                else flt\n               odE\n              else flt)\n           | _ \\<Rightarrow> flt\n      odE)\n      <catch> handle_fault thread\n   od\"\n\ntext \\<open>\n\n  The definition here has been specialised to \\texttt{return ()}. The behaviour\n  is identical with the abstract specification under restricted capabilities because there\n  are no \\texttt{Reply} capabilities in \\texttt{sep-abstract}.\n\n\\<close>\n\ndefinition\n  handle_reply :: \"(unit,'z::state_ext) s_monad\" where\n \"handle_reply \\<equiv> return ()\""}
{"title": "./spec/sep-abstract/Syscall_SA.thy", "section": "Top-level event handling", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n\n  The definition here is almost identical to that of the abstract specification (for the restricted\n  capablities), except that a call to \\texttt{handle_reply} has been removed. Since there\n  are no \\texttt{Reply}s in the restricted capabilities the behaviour is the same.\n\n\\<close>\n\n\nfun\n  handle_event :: \"event \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"handle_event (SyscallEvent call) =\n   (case call of\n          SysSend \\<Rightarrow> handle_send True\n        | SysNBSend \\<Rightarrow> handle_send False\n        | SysCall \\<Rightarrow> handle_call\n        | SysRecv \\<Rightarrow> without_preemption $ handle_recv True\n        | SysYield \\<Rightarrow> without_preemption handle_yield\n        | SysReply \\<Rightarrow> without_preemption handle_reply\n        | SysReplyRecv \\<Rightarrow> without_preemption $ handle_recv True\n        | SysNBRecv \\<Rightarrow> without_preemption $ handle_recv False)\"\n\n| \"handle_event (UnknownSyscall n) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_fault thread $ UnknownSyscallException $ of_nat n;\n    return ()\n  od)\"\n\n| \"handle_event (UserLevelFault w1 w2) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_fault thread $ UserException w1 (w2 && mask 28);\n    return ()\n  od)\"\n\n| \"handle_event Interrupt = (without_preemption $ do\n    active \\<leftarrow> do_machine_op (getActiveIRQ False);\n    case active of\n       Some irq \\<Rightarrow> handle_interrupt irq\n     | None \\<Rightarrow> return ()\n  od)\"\n\n| \"handle_event (VMFaultEvent fault_type) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_vm_fault thread fault_type <catch> handle_fault thread;\n    return ()\n  od)\"\n\n| \"handle_event (HypervisorEvent fault_type) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_hypervisor_fault thread fault_type;\n    return ()\n  od)\""}
{"title": "./spec/sep-abstract/Syscall_SA.thy", "section": "Kernel entry point", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  This function is the main kernel entry point. The main event loop of the\n  kernel handles events, handles a potential preemption interrupt, schedules\n  and switches back to the active thread.\n\\<close>\n\ndefinition\n  call_kernel :: \"event \\<Rightarrow> (unit,'z::state_ext_sched) s_monad\" where\n  \"call_kernel ev \\<equiv> do\n       handle_event ev <handle>\n           (\\<lambda>_. without_preemption $ do\n                  irq \\<leftarrow> do_machine_op (getActiveIRQ True);\n                  when (irq \\<noteq> None) $ handle_interrupt (the irq)\n                od);\n       schedule;\n       activate_thread\n   od\"\n\nend"}
{"title": "./spec/sep-abstract/Decode_SA.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDecoding system calls\n*)\n\nchapter \"Decoding System Calls\"\n\ntheory Decode_SA\nimports    \"Ipc_SA\"\n\nbegin"}
{"title": "./spec/sep-abstract/Decode_SA.thy", "section": "Toplevel invocation decode.", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition is the toplevel decoding definition; it dispatches\nto the above definitions, after checking, in some cases, whether the\ninvocation is allowed.\n\\<close>\n\ndefinition\n  decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_invocation label args cap_index slot cap excaps \\<equiv>\n  case cap of\n    NotificationCap ptr badge rights \\<Rightarrow>\n      if AllowSend \\<in> rights then\n        returnOk $ InvokeNotification ptr badge\n      else throwError $ InvalidCapability 0\n  | _ \\<Rightarrow>\n      throwError $ InvalidCapability 0\"\n\nend"}
{"title": "./spec/sep-abstract/Ipc_SA.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nSpecification of Inter-Process Communication.\n*)\n\nchapter \"IPC\"\n\ntheory Ipc_SA\nimports \"ASpec.Syscall_A\"\nbegin"}
{"title": "./spec/sep-abstract/Ipc_SA.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n\n  \\texttt{handle_fault} in \\texttt{sep-abstract} always sets the thread state to\n  \\texttt{Inactive}. This is the same behaviour as \\texttt{handle_double_fault} in the abstract\n  specification.\n\n  The two \\texttt{handle_fault}s have the same behaviour under restricted capabilities because in\n  the abstract specification \\texttt{handle_fault} will call \\texttt{handle_double_fault} in all\n  cases except when the thread has an \\texttt{EndpointCap}. Since \\texttt{EndpointCap} is not part\n  of the restricted capabilities their behaviour is the same. This means, the system assumes\n  fully static virtual memory and no dynamic paging of any kind.\n  Faulting threads will be disabled by the kernel.\n\\<close>\n\ndefinition\n  handle_fault :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_fault tptr ex \\<equiv> set_thread_state tptr Inactive\"\n\nend"}
{"title": "./spec/machine/MachineMonad.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n\ntheory MachineMonad\nimports MachineTypes\nbegin\n\narch_requalify_types\n  machine_state\n  machine_state_rest\n\narch_requalify_consts\n  underlying_memory\n  underlying_memory_update\n  device_state\n  device_state_update\n  irq_masks\n  machine_state_rest\n  machine_state_rest_update\n\ntext \\<open>\n  The machine monad is used for operations on the state defined above.\n\\<close>\ntype_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\ntranslations\n  (type) \"'c machine_monad\" <= (type) \"machine_state \\<Rightarrow> ('c \\<times> machine_state) set \\<times> bool\"\n\ntype_synonym 'a machine_rest_monad = \"(machine_state_rest, 'a) nondet_monad\"\n\ndefinition\n  machine_rest_lift :: \"'a machine_rest_monad \\<Rightarrow> 'a machine_monad\"\nwhere\n  \"machine_rest_lift f \\<equiv> do\n    mr \\<leftarrow> gets machine_state_rest;\n    (r, mr') \\<leftarrow> select_f (f mr);\n    modify (\\<lambda>s. s \\<lparr> machine_state_rest := mr' \\<rparr>);\n    return r\n  od\"\n\n\ndefinition\n  ignore_failure :: \"('s,unit) nondet_monad \\<Rightarrow> ('s,unit) nondet_monad\"\n  where\n  \"ignore_failure f \\<equiv>\n  \\<lambda>s. if fst (f s) = {} then ({((),s)},False) else (fst (f s), False)\"\n\ntext \\<open>The wrapper doesn't do anything for usual operations:\\<close>\nlemma failure_consistent:\n  \"\\<lbrakk> empty_fail f; no_fail \\<top> f \\<rbrakk> \\<Longrightarrow> ignore_failure f = f\"\n  apply (simp add: ignore_failure_def empty_fail_def no_fail_def)\n  apply (rule ext)\n  apply (auto intro: prod_eqI)\n  done\n\ntext \\<open>And it has the desired properties\\<close>\nlemma ef_ignore_failure [simp]:\n  \"empty_fail (ignore_failure f)\"\n  by (simp add: empty_fail_def ignore_failure_def)\n\nlemma no_fail_ignore_failure [simp, intro!]:\n  \"no_fail \\<top> (ignore_failure f)\"\n  by (simp add: no_fail_def ignore_failure_def)\n\n\nlemma ef_machine_rest_lift [simp, intro!]:\n  \"empty_fail f \\<Longrightarrow> empty_fail (machine_rest_lift f)\"\n  apply (clarsimp simp: empty_fail_def machine_rest_lift_def simpler_gets_def\n                        select_f_def bind_def simpler_modify_def return_def)\n  apply force\n  done\n\nlemma no_fail_machine_state_rest [intro!]:\n  \"no_fail P f \\<Longrightarrow> no_fail (P o machine_state_rest) (machine_rest_lift f)\"\n  apply (simp add: no_fail_def machine_rest_lift_def simpler_gets_def\n                        select_f_def bind_def simpler_modify_def return_def)\n  apply force\n  done\n\nlemma no_fail_machine_state_rest_T [simp, intro!]:\n  \"no_fail \\<top> f \\<Longrightarrow> no_fail \\<top> (machine_rest_lift f)\"\n  apply (drule no_fail_machine_state_rest)\n  apply (simp add: o_def)\n  done\n\ndefinition\n  \"machine_op_lift \\<equiv> machine_rest_lift o ignore_failure\"\n\n\nend"}
{"title": "./spec/machine/Kernel_Config_Lemmas.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2021, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-independent lemmas constraining Kernel_Config definitions *)\n\ntheory Kernel_Config_Lemmas\nimports \"$L4V_ARCH/Kernel_Config\"\nbegin\n\ntext \\<open>\n  seL4's build system allows configuration of some architecture-independent constants, such as the\n  number of domains.\n\n  The long-term goal is to make the proofs resilient in the face of changes of these configuration\n  options. To this end this theory contains properties of these constants, to avoid unfolding\n  their values later in the proofs.\\<close>\n\nlemma numDomains_not_zero:\n  \"numDomains > 0\"\n  unfolding Kernel_Config.numDomains_def\n  by simp\n\nlemma numDomains_machine_word_safe:\n  \"unat (of_nat numDomains :: machine_word) = numDomains\"\n  unfolding Kernel_Config.numDomains_def by simp\n\nend"}
{"title": "./spec/machine/MachineExports.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n\ntheory MachineExports\nimports MachineOps\nbegin\n\n(* Check consistency of machine_word and machine_word_len. *)\nterm \"id :: machine_word \\<Rightarrow> machine_word_len word\"\n\narch_requalify_types\n  vmfault_type\n  hyp_fault_type\n  irq\n  user_monad\n  user_context\n\narch_requalify_consts\n  getActiveIRQ\n  maskInterrupt\n  freeMemory\n  loadWord\n  storeWord\n  storeWordVM\n  setNextPC\n  getRestartPC\n  setRegister\n  getRegister\n  initContext\n  exceptionMessage\n  syscallMessage\n  gpRegisters\n  frameRegisters\n  ackInterrupt\n  resetTimer\n  minIRQ\n  clearMemory\n  non_kernel_IRQs\n  tlsBaseRegister\n  debugPrint\n  configureTimer\n  initL2Cache\n  ptrFromPAddr\n  pageBits\n\n(* HERE IS THE PLACE FOR GENERIC WORD LEMMAS FOR ALL ARCHITECTURES *)\n\nlemma Suc_unat_mask_div_obfuscated:\n  \"Suc (unat (mask sz div (word_size::machine_word))) = 2 ^ (min sz word_bits - word_size_bits)\"\n  by (rule Suc_unat_mask_div)\n\nlemma word_size_size_bits_nat:\n  \"2^word_size_bits = (word_size :: nat)\"\n  by (simp add: word_size_bits_def word_size_def)\n\nlemma word_size_size_bits_word:\n  \"2^word_size_bits = (word_size :: 'a :: len word)\"\n  by (simp add: word_size_bits_def word_size_def)\n\nend"}
{"title": "./spec/machine/Setup_Locale.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n\ntheory Setup_Locale\nimports \"Lib.Qualify\" \"Lib.Requalify\"\nbegin\n\n(*\n   We use a locale for namespacing architecture-specific definitions.\n\n   The global_naming command changes the underlying naming of the locale. The intention is that\n   we liberally put everything into the \"ARM\" namespace, and then carefully unqualify (put into global namespace)\n   or requalify (change qualifier to \"Arch\" instead of \"ARM\") in order to refer to entities in\n   generic proofs.\n\n*)\n\nlocale Arch\n\nend"}
{"title": "./spec/machine/ARM/MachineOps.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Machine Operations\"\n\ntheory MachineOps\nimports\n  MachineMonad\nbegin"}
{"title": "./spec/machine/ARM/MachineOps.thy", "section": "The Operations", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine operations below work on the underspecified\n  part of the machine state @{typ machine_state_rest} and cannot fail.\n  We could express the latter by type (leaving out the failure flag),\n  but if we later wanted to implement them,\n  we'd have to set up a new hoare-logic\n  framework for that type. So instead, we provide a wrapper for these\n  operations that explicitly ignores the fail flag and sets it to\n  False. Similarly, these operations never return an empty set of\n  follow-on states, which would require the operation to fail.\n  So we explicitly make this (non-existing) case a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\n\\<close>\n\ncontext Arch begin global_naming ARM"}
{"title": "./spec/machine/ARM/MachineOps.thy", "section": "The Operations", "subsection": "", "subsubsection": "", "code": "\nconsts'\n  memory_regions :: \"(paddr \\<times> paddr) list\" (* avail_p_regs *)\n  device_regions :: \"(paddr \\<times> paddr) list\" (* dev_p_regs *)\n\ndefinition\n  getMemoryRegions :: \"(paddr * paddr) list machine_monad\"\n  where \"getMemoryRegions \\<equiv> return memory_regions\"\n\nconsts'\n  getDeviceRegions_impl :: \"unit machine_rest_monad\"\n  getDeviceRegions_val :: \"machine_state \\<Rightarrow> (paddr * paddr) list\"\n\ndefinition\n  getDeviceRegions :: \"(paddr * paddr) list machine_monad\"\nwhere\n  \"getDeviceRegions \\<equiv> return device_regions\"\n\nconsts'\n  getKernelDevices_impl :: \"unit machine_rest_monad\"\n  getKernelDevices_val :: \"machine_state \\<Rightarrow> (paddr * machine_word) list\"\n\ndefinition\n  getKernelDevices :: \"(paddr * machine_word) list machine_monad\"\nwhere\n  \"getKernelDevices \\<equiv> do\n    machine_op_lift getKernelDevices_impl;\n    gets getKernelDevices_val\n  od\"\n\nconsts'\n  setIRQTrigger_impl :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  setIRQTrigger :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setIRQTrigger irq trigger \\<equiv> machine_op_lift (setIRQTrigger_impl irq trigger)\"\n\ndefinition\n  loadWord :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\n  where \"loadWord p \\<equiv> do m \\<leftarrow> gets underlying_memory;\n                         assert (p && mask 2 = 0);\n                         return (word_rcat [m (p + 3), m (p + 2), m (p + 1), m p])\n                      od\"\n\ndefinition\n  storeWord :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where \"storeWord p w \\<equiv> do\n                            assert (p && mask 2 = 0);\n                            modify (underlying_memory_update (\\<lambda>m.\n                                      m(p := word_rsplit w ! 3,\n                                        p + 1 := word_rsplit w ! 2,\n                                        p + 2 := word_rsplit w ! 1,\n                                        p + 3 := word_rsplit w ! 0)))\n                         od\"\n\nlemma loadWord_storeWord_is_return:\n  \"p && mask 2 = 0 \\<Longrightarrow> (do w \\<leftarrow> loadWord p; storeWord p w od) = return ()\"\n  apply (rule ext)\n  apply (simp add: loadWord_def storeWord_def bind_def assert_def return_def\n    modify_def gets_def get_def eval_nat_numeral put_def)\n  apply (simp add: word_rsplit_rcat_size word_size)\n  done\n\ntext \\<open>This instruction is required in the simulator, only.\\<close>\ndefinition\n  storeWordVM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where \"storeWordVM w p \\<equiv> return ()\"\n\nconsts'\n  configureTimer_impl :: \"unit machine_rest_monad\"\n  configureTimer_val :: \"machine_state \\<Rightarrow> irq\"\n\ndefinition\n  configureTimer :: \"irq machine_monad\"\nwhere\n  \"configureTimer \\<equiv> do\n    machine_op_lift configureTimer_impl;\n    gets configureTimer_val\n  od\"\n\nconsts' (* XXX: replaces configureTimer in new boot code\n          TODO: remove configureTimer when haskell updated *)\n  initTimer_impl :: \"unit machine_rest_monad\"\ndefinition\n  initTimer :: \"unit machine_monad\"\nwhere \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts'\n  resetTimer_impl :: \"unit machine_rest_monad\"\n\ndefinition\n  resetTimer :: \"unit machine_monad\"\nwhere \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"\n\nconsts'\n  writeTTBR0_impl :: \"paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeTTBR0 :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere \"writeTTBR0 pd \\<equiv> machine_op_lift (writeTTBR0_impl pd)\"\n\n\nconsts'\n  setHardwareASID_impl :: \"hardware_asid \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setHardwareASID:: \"hardware_asid \\<Rightarrow> unit machine_monad\"\nwhere \"setHardwareASID a \\<equiv> machine_op_lift (setHardwareASID_impl a)\"\n\n\n(* Memory Barriers *)\n\n\nconsts'\n  isb_impl :: \"unit machine_rest_monad\"\ndefinition\n  isb :: \"unit machine_monad\"\nwhere \"isb \\<equiv> machine_op_lift isb_impl\"\n\nconsts'\n  dsb_impl :: \"unit machine_rest_monad\"\ndefinition\n  dsb :: \"unit machine_monad\"\nwhere \"dsb \\<equiv> machine_op_lift dsb_impl\"\n\nconsts'\n  dmb_impl :: \"unit machine_rest_monad\"\ndefinition\n  dmb :: \"unit machine_monad\"\nwhere \"dmb \\<equiv> machine_op_lift dmb_impl\"\n\nconsts'\n  invalidateLocalTLB_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB :: \"unit machine_monad\"\nwhere \"invalidateLocalTLB \\<equiv> machine_op_lift invalidateLocalTLB_impl\"\n\n\nconsts'\n  invalidateLocalTLB_ASID_impl :: \"hardware_asid \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB_ASID :: \"hardware_asid \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateLocalTLB_ASID a \\<equiv> machine_op_lift (invalidateLocalTLB_ASID_impl a)\"\n\n\n(* C implementation takes one argument, which is w || a *)\nconsts'\n  invalidateLocalTLB_VAASID_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB_VAASID :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateLocalTLB_VAASID w \\<equiv> machine_op_lift (invalidateLocalTLB_VAASID_impl w)\"\n\nconsts'\n  cleanByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanByVA w p \\<equiv> machine_op_lift (cleanByVA_impl w p)\"\n\nconsts'\n  cleanByVA_PoU_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanByVA_PoU :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanByVA_PoU w p \\<equiv> machine_op_lift (cleanByVA_PoU_impl w p)\"\n\nconsts'\n  invalidateByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateByVA w p \\<equiv> machine_op_lift (invalidateByVA_impl w p)\"\n\nconsts'\n  invalidateByVA_I_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateByVA_I :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateByVA_I w p \\<equiv> machine_op_lift (invalidateByVA_I_impl w p)\"\n\nconsts'\n  invalidate_I_PoU_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidate_I_PoU :: \"unit machine_monad\"\nwhere \"invalidate_I_PoU \\<equiv> machine_op_lift invalidate_I_PoU_impl\"\n\nconsts'\n  cleanInvalByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanInvalByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanInvalByVA w p \\<equiv> machine_op_lift (cleanInvalByVA_impl w p)\"\n\nconsts'\n  branchFlush_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  branchFlush :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"branchFlush w p \\<equiv> machine_op_lift (branchFlush_impl w p)\"\n\nconsts'\n  clean_D_PoU_impl :: \"unit machine_rest_monad\"\ndefinition\n  clean_D_PoU :: \"unit machine_monad\"\nwhere \"clean_D_PoU \\<equiv> machine_op_lift clean_D_PoU_impl\"\n\nconsts'\n  cleanInvalidate_D_PoC_impl :: \"unit machine_rest_monad\"\ndefinition\n  cleanInvalidate_D_PoC :: \"unit machine_monad\"\nwhere \"cleanInvalidate_D_PoC \\<equiv> machine_op_lift cleanInvalidate_D_PoC_impl\"\n\nconsts'\n  cleanInvalidateL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanInvalidateL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanInvalidateL2Range w p \\<equiv> machine_op_lift (cleanInvalidateL2Range_impl w p)\"\n\nconsts'\n  invalidateL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateL2Range w p \\<equiv> machine_op_lift (invalidateL2Range_impl w p)\"\n\nconsts'\n  cleanL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanL2Range w p \\<equiv> machine_op_lift (cleanL2Range_impl w p)\"\n\nconsts'\n  initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition\n  initL2Cache :: \"unit machine_monad\"\nwhere \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\ndefinition\n  clearExMonitor :: \"unit machine_monad\"\nwhere \"clearExMonitor \\<equiv> modify (\\<lambda>s. s \\<lparr> exclusive_state := default_exclusive_state \\<rparr>)\"\n\nconsts'\n  flushBTAC_impl :: \"unit machine_rest_monad\"\ndefinition\n  flushBTAC :: \"unit machine_monad\"\nwhere \"flushBTAC \\<equiv> machine_op_lift flushBTAC_impl\"\n\nconsts'\n  initIRQController_impl :: \"unit machine_rest_monad\"\ndefinition\n  initIRQController :: \"unit machine_monad\"\nwhere \"initIRQController \\<equiv> machine_op_lift initIRQController_impl\"\n\ndefinition\n  IRQ :: \"irq \\<Rightarrow> irq\"\nwhere \"IRQ \\<equiv> id\"\n\nconsts'\n  writeContextID_impl :: \"unit machine_rest_monad\"\ndefinition\n  writeContextID :: \"unit machine_monad\"\nwhere \"writeContextID \\<equiv> machine_op_lift writeContextID_impl\"\n\nlemmas cache_machine_op_defs = isb_def dsb_def dmb_def writeContextID_def flushBTAC_def\n                               clearExMonitor_def cleanL2Range_def invalidateL2Range_def\n                               cleanInvalidateL2Range_def cleanInvalidate_D_PoC_def\n                               clean_D_PoU_def branchFlush_def cleanInvalByVA_def\n                               invalidate_I_PoU_def invalidateByVA_I_def invalidateByVA_def\n                               cleanByVA_PoU_def cleanByVA_def invalidateLocalTLB_VAASID_def\n                               invalidateLocalTLB_ASID_def invalidateLocalTLB_def\nconsts'\n  IFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  DFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  FAR_val :: \"machine_state \\<Rightarrow> machine_word\"\n\ndefinition\n  getIFSR :: \"machine_word machine_monad\"\n  where \"getIFSR \\<equiv> gets IFSR_val\"\n\ndefinition\n  getDFSR :: \"machine_word machine_monad\"\n  where \"getDFSR \\<equiv> gets DFSR_val\"\n\ndefinition\n  getFAR :: \"machine_word machine_monad\"\n  where \"getFAR \\<equiv> gets FAR_val\"\n\ndefinition\n  debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\"\nwhere\n  debugPrint_def[simp]:\n \"debugPrint \\<equiv> \\<lambda>message. return ()\"\n\nconsts'\n  ackInterrupt_impl :: \"irq \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ackInterrupt irq \\<equiv> machine_op_lift (ackInterrupt_impl irq)\"\n\n\n\\<comment> \\<open>Interrupt controller operations\\<close>\n\ntext \\<open>\n  Interrupts that cannot occur while the kernel is running (e.g. at preemption points),\n  but that can occur from user mode. Empty on plain ARMv7.\n\\<close>\ndefinition\n  \"non_kernel_IRQs = {}\"\n\ntext \\<open>\n  @{term getActiveIRQ} is now derministic.\n  It 'updates' the irq state to the reflect the passage of\n  time since last the irq was gotten, then it gets the active\n  IRQ (if there is one).\n\\<close>\ndefinition\n  getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\nwhere\n  \"getActiveIRQ in_kernel \\<equiv> do\n    is_masked \\<leftarrow> gets $ irq_masks;\n    modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n    active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n    if is_masked active_irq \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n    then return None\n    else return (Some active_irq)\n  od\"\n\ndefinition\n  maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"maskInterrupt m irq \\<equiv>\n  modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition\n  lineStart :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"lineStart addr = (addr >> cacheLineBits) << cacheLineBits\"\n\ntext \\<open>\n  Performs the given operation on every cache line that intersects the\n  supplied range.\n\\<close>\ndefinition\n  cacheRangeOp :: \"(machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad)\n                 \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cacheRangeOp operation vstart vend pstart \\<equiv>\n    let pend = pstart + (vend - vstart);\n        vptrs = [lineStart vstart, lineStart vstart + of_nat cacheLine .e. lineStart vend];\n        pptrs = [lineStart pstart, lineStart pstart + of_nat cacheLine .e. lineStart pend]\n    in mapM_x (\\<lambda>(v, p). operation v p) (zip vptrs pptrs)\"\n\ndefinition\n  cleanCacheRange_PoC :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoC vstart vend pstart \\<equiv> cacheRangeOp cleanByVA vstart vend pstart\"\n\ndefinition\n  cleanInvalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanInvalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanInvalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp cleanInvalByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  cleanCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanL2Range pstart (pstart + (vend - vstart))\n  od\"\n\ndefinition\n  cleanCacheRange_PoU :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoU vstart vend pstart \\<equiv> cacheRangeOp cleanByVA_PoU vstart vend pstart\"\n\ndefinition\n  invalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    when (vstart \\<noteq> lineStart vstart) $\n        cleanCacheRange_RAM vstart vstart pstart;\n    when (vend + 1 \\<noteq> lineStart (vend + 1)) $\n        cleanCacheRange_RAM (lineStart vend) (lineStart vend)\n           (pstart + ((lineStart vend) - vstart));\n    invalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp invalidateByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  invalidateCacheRange_I :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_I vstart vend pstart \\<equiv> cacheRangeOp invalidateByVA_I vstart vend pstart\"\n\ndefinition\n  branchFlushRange :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"branchFlushRange vstart vend pstart \\<equiv> cacheRangeOp branchFlush vstart vend pstart\"\n\ndefinition\n  cleanCaches_PoU :: \"unit machine_monad\"\nwhere\n  \"cleanCaches_PoU \\<equiv> do\n    dsb;\n    clean_D_PoU;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\"\n\ndefinition\n  cleanInvalidateL1Caches :: \"unit machine_monad\"\nwhere\n  \"cleanInvalidateL1Caches \\<equiv> do\n    dsb;\n    cleanInvalidate_D_PoC;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\""}
{"title": "./spec/machine/ARM/MachineOps.thy", "section": "Memory Clearance", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Clear memory contents to recycle it as user memory. Do not yet flush the cache.\\<close>\ndefinition\n  clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"clearMemory ptr bytelength \\<equiv>\n    mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"\n\ndefinition\n  clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"\n\ntext \\<open>\n  Initialize memory to be used as user memory.\n  Note that zeroing out the memory is redundant in the specifications.\n  In any case, we cannot abstract from the call to cleanCacheRange,\n  which appears in the implementation.\n\\<close>\nabbreviation (input) \"initMemory == clearMemory\"\n\ntext \\<open>\n  Free memory that had been initialized as user memory.\n  While freeing memory is a no-(in) the implementation,\n  we zero out the underlying memory in the specifications to avoid garbage.\n  If we know that there is no garbage,\n  we can compute from the implementation state\n  what the exact memory content in the specifications is.\n\\<close>\ndefinition\n  freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"freeMemory ptr bits \\<equiv>\n  mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\""}
{"title": "./spec/machine/ARM/MachineOps.thy", "section": "User Monad", "subsection": "", "subsubsection": "", "code": "\ntype_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ndatatype user_context = UserContext (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\ndefinition getRegister :: \"register \\<Rightarrow> machine_word user_monad\" where\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition modify_registers :: \"(user_regs \\<Rightarrow> user_regs) \\<Rightarrow> user_context \\<Rightarrow> user_context\" where\n  \"modify_registers f uc \\<equiv> UserContext (f (user_regs uc))\"\n\ndefinition setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\" where\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext ((user_regs s) (r := v)))\"\n\ndefinition\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition\n  \"setNextPC \\<equiv> setRegister NextIP\"\n\nend\n\ntranslations\n  (type) \"'a ARM.user_monad\" <= (type) \"(ARM.register \\<Rightarrow> machine_word, 'a) nondet_monad\"\n\n\nend"}
{"title": "./spec/machine/ARM/Platform.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Platform Definitions\"\n\ntheory Platform\nimports\n  \"Lib.Defs\"\n  \"Lib.Lib\"\n  \"Word_Lib.WordSetup\"\n  Setup_Locale\n  Kernel_Config\nbegin\n\ntext \\<open>\n  This theory lists platform-specific types and basic constants, in particular\n  the types of interrupts and physical addresses, constants for the\n  kernel location, the offsets between physical and virtual kernel\n  addresses, as well as the range of IRQs on the platform.\n\\<close>"}
{"title": "./spec/machine/ARM/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\n(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\""}
{"title": "./spec/machine/ARM/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\ncontext Arch begin global_naming ARM\n\nvalue_type irq_len = Kernel_Config.irqBits (* IRQ_CNODE_SLOT_BITS *)\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = word32\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\ndefinition pageColourBits :: nat where\n  \"pageColourBits \\<equiv> 2\"\n\ndefinition cacheLineBits :: nat where\n  \"cacheLineBits = CONFIG_L1_CACHE_LINE_SIZE_BITS\"\n\ndefinition cacheLine :: nat where\n  \"cacheLine = 2^cacheLineBits\"\n\n(* The first virtual address of the kernel's physical memory window *)\ndefinition pptrBase :: word32 where\n  \"pptrBase \\<equiv> 0xe0000000\"\n\nabbreviation (input) \"paddrBase \\<equiv> physBase\"\n\ndefinition pptrBaseOffset :: word32 where\n  \"pptrBaseOffset \\<equiv> pptrBase - paddrBase\"\n\ndefinition kernelELFPAddrBase :: word32 where\n  \"kernelELFPAddrBase \\<equiv> physBase\"\n\ndefinition kernelELFBase :: word32 where\n  \"kernelELFBase \\<equiv> pptrBase + (kernelELFPAddrBase && mask 22)\"\n\ndefinition kernelELFBaseOffset :: word32 where\n  \"kernelELFBaseOffset \\<equiv> kernelELFBase - kernelELFPAddrBase\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> word32\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"word32 \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"word32 \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr kpptr \\<equiv> kpptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\nend\n\nend"}
{"title": "./spec/machine/ARM/Arch_Kernel_Config_Lemmas.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming ARM\n\n(* note: 24 = pageBitsForSize ARMSuperSection, we do not have access to ASpec at this point *)\nlemma physBase_aligned:\n  \"is_aligned physBase 24\"\n  by (simp add: is_aligned_def Kernel_Config.physBase_def)\n\n\n(* maxIRQ conditions *)\n\nlemma maxIRQ_less_2p_irqBits:\n  \"(maxIRQ::nat) < 2^irqBits\"\n  by (simp add: Kernel_Config.maxIRQ_def Kernel_Config.irqBits_def)\n\n(* follows from value_type definition of irq_len *)\nlemma LENGTH_irq_len_irqBits[simp]: (* [simp] will fire only for simp del: len_of_numeral_defs *)\n  \"LENGTH(irq_len) = irqBits\"\n  using irq_len_def irq_len_val\n  by simp\n\nlemma maxIRQ_less_2p_irq_len:\n  \"(maxIRQ::nat) < 2^LENGTH(irq_len)\"\n  using maxIRQ_less_2p_irqBits\n  by (simp del: len_of_numeral_defs)\n\n(* maxIRQ as a generic numeral allows us to write rules about casts/unat/uint etc without\n   mentioning numbers: *)\n\nlemma of_nat_maxIRQ[simp]:\n  \"of_nat maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma of_int_maxIRQ[simp]:\n  \"of_int maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma unat_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> unat (maxIRQ::'a word) = maxIRQ\"\n  by (metis maxIRQ_less_2p_irq_len Word.of_nat_unat of_nat_inverse of_nat_maxIRQ unat_ucast_up_simp)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma uint_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> uint (maxIRQ::'a word) = maxIRQ\"\n  by (metis Kernel_Config.maxIRQ_def of_nat_numeral uint_nat unat_maxIRQ)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma ucast_maxIRQ[simp]:\n  \"\\<lbrakk> LENGTH(irq_len) \\<le> LENGTH('a::len); LENGTH(irq_len) \\<le> LENGTH('b::len) \\<rbrakk> \\<Longrightarrow>\n   UCAST ('a \\<rightarrow> 'b) maxIRQ = maxIRQ\"\n  by (metis of_nat_maxIRQ ucast_nat_def unat_maxIRQ)\n\n(* Safe for [simp] because we don't cast down from irq type *)\nlemma maxIRQ_less_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   (maxIRQ < (ucast irq :: 'a word)) = (maxIRQ < irq)\" for irq::irq\n  by (simp add: word_less_nat_alt unat_ucast_up_simp)\n\n(* Safe for [simp] because we don't cast down from irq type *)\nlemma maxIRQ_le_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   ((ucast irq :: 'a word) \\<le> Kernel_Config.maxIRQ) = (irq \\<le> Kernel_Config.maxIRQ)\" for irq::irq\n  by (simp add: word_le_nat_alt unat_ucast_up_simp)\n\n(* The following are instances -- for some we could derive general rules, but the number of\n   instances is limited and the concrete proofs are much simpler: *)\n\nlemma le_maxIRQ_machine_less_irqBits_val[simplified]:\n  \"w \\<le> maxIRQ \\<Longrightarrow> unat w < 2^LENGTH(irq_len)\" for w::machine_word\n  using maxIRQ_less_2p_irq_len\n  by (simp add: word_le_nat_alt)\n\nlemma irq_machine_le_maxIRQ_irq:\n  \"irq \\<le> Kernel_Config.maxIRQ \\<Longrightarrow> (ucast irq::irq) \\<le> maxIRQ\" for irq::machine_word\n  by (simp add: Kernel_Config.maxIRQ_def word_le_nat_alt unat_ucast)\n\nlemma maxIRQ_eq_ucast_irq_32_signed_uint:\n  \"(maxIRQ = (ucast b :: int_word)) = (uint b = maxIRQ)\" for b::irq\n  unfolding Kernel_Config.maxIRQ_def\n  apply uint_arith\n  apply (simp add: uint_up_ucast is_up)\n  done\n\nlemma sint_maxIRQ_32[simp]:\n  \"sint (maxIRQ :: int_word) = maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_machine[simp]:\n  \"scast (maxIRQ :: int_word) = (maxIRQ::machine_word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_irq[simp]:\n  \"scast (maxIRQ :: int_word) = (maxIRQ::irq)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_machine:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = x\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_irq:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = (ucast x :: irq)\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_1_plus_eq_Suc_machine[simp]:\n  \"unat (1 + maxIRQ :: machine_word) = Suc Kernel_Config.maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\n\n(* cacheLineBits conditions *)\n\n(* Folding cacheLineBits_val in C functions only works reliably if cacheLineBits is not 1 and\n   not too large to conflict with other values used inside cache ops.\n   10 is ptBits, which is only available after ExecSpec. Anything > 1 and smaller than ptBits\n   works. *)\nlemma cacheLineBits_sanity:\n  \"cacheLineBits \\<in> {2..10}\"\n  by (simp add: cacheLineBits_def Kernel_Config.CONFIG_L1_CACHE_LINE_SIZE_BITS_def)\n\nend\nend"}
{"title": "./spec/machine/X64/MachineOps.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Machine Operations\"\n\ntheory MachineOps\nimports\n  \"Word_Lib.WordSetup\"\n  \"Monads.Nondet_Monad\"\n  MachineMonad\nbegin"}
{"title": "./spec/machine/X64/MachineOps.thy", "section": "The Operations", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine operations below work on the underspecified\n  part of the machine state @{typ machine_state_rest} and cannot fail.\n  We could express the latter by type (leaving out the failure flag),\n  but if we later wanted to implement them,\n  we'd have to set up a new hoare-logic\n  framework for that type. So instead, we provide a wrapper for these\n  operations that explicitly ignores the fail flag and sets it to\n  False. Similarly, these operations never return an empty set of\n  follow-on states, which would require the operation to fail.\n  So we explicitly make this (non-existing) case a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\n\\<close>\n\ncontext Arch begin global_naming X64"}
{"title": "./spec/machine/X64/MachineOps.thy", "section": "The Operations", "subsection": "", "subsubsection": "", "code": "\nconsts'\n  memory_regions :: \"(paddr \\<times> paddr) list\" (* avail_p_regs *)\n  device_regions :: \"(paddr \\<times> paddr) list\" (* dev_p_regs *)\n\ndefinition\n  getMemoryRegions :: \"(paddr * paddr) list machine_monad\"\n  where \"getMemoryRegions \\<equiv> return memory_regions\"\n\nconsts'\n  getDeviceRegions_impl :: \"unit machine_rest_monad\"\n  getDeviceRegions_val :: \"machine_state \\<Rightarrow> (paddr * paddr) list\"\n\ndefinition\n  getDeviceRegions :: \"(paddr * paddr) list machine_monad\"\nwhere\n  \"getDeviceRegions \\<equiv> return device_regions\"\n\nconsts'\n  getKernelDevices_impl :: \"unit machine_rest_monad\"\n  getKernelDevices_val :: \"machine_state \\<Rightarrow> (paddr * machine_word) list\"\n\ndefinition\n  getKernelDevices :: \"(paddr * machine_word) list machine_monad\"\nwhere\n  \"getKernelDevices \\<equiv> do\n    machine_op_lift getKernelDevices_impl;\n    gets getKernelDevices_val\n  od\"\n\n\ndefinition\n  loadWord :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\n  where \"loadWord p \\<equiv> do m \\<leftarrow> gets underlying_memory;\n                         assert (p && mask 3 = 0);\n                         return (word_rcat (map (\\<lambda>i. m (p + (7 - of_int i))) [0 .. 7]))\n                      od\"\n\ndefinition\n  storeWord :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where \"storeWord p w \\<equiv> do\n                            assert (p && mask 3 = 0);\n                            modify (underlying_memory_update (\n                                      fold (\\<lambda>i m. m((p + (of_int i)) := word_rsplit w ! (7 - nat i))) [0 .. 7]))\n                         od\"\n\nlemma upto0_7_def:\n  \"[0..7] = [0,1,2,3,4,5,6,7]\" by eval\n\nlemma loadWord_storeWord_is_return:\n  \"p && mask 3 = 0 \\<Longrightarrow> (do w \\<leftarrow> loadWord p; storeWord p w od) = return ()\"\n  apply (rule ext)\n  by (simp add: loadWord_def storeWord_def bind_def assert_def return_def\n    modify_def gets_def get_def eval_nat_numeral put_def upto0_7_def\n    word_rsplit_rcat_size word_size)\n\n\ntext \\<open>This instruction is required in the simulator, only.\\<close>\ndefinition\n  storeWordVM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where \"storeWordVM w p \\<equiv> return ()\"\n\nconsts'\n  configureTimer_impl :: \"unit machine_rest_monad\"\n  configureTimer_val :: \"machine_state \\<Rightarrow> irq\"\n\ndefinition\n  configureTimer :: \"irq machine_monad\"\nwhere\n  \"configureTimer \\<equiv> do\n    machine_op_lift configureTimer_impl;\n    gets configureTimer_val\n  od\"\n\nconsts' (* XXX: replaces configureTimer in new boot code\n          TODO: remove configureTimer when haskell updated *)\n  initTimer_impl :: \"unit machine_rest_monad\"\ndefinition\n  initTimer :: \"unit machine_monad\"\nwhere \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts'\n  resetTimer_impl :: \"unit machine_rest_monad\"\n\ndefinition\n  resetTimer :: \"unit machine_monad\"\nwhere \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"\n\nconsts'\n  invalidateTLB_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidateTLB :: \"unit machine_monad\"\nwhere \"invalidateTLB \\<equiv> machine_op_lift invalidateTLB_impl\"\n\nlemmas cache_machine_op_defs = invalidateTLB_def\n\ndefinition\n  debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\"\nwhere\n  debugPrint_def[simp]:\n \"debugPrint \\<equiv> \\<lambda>message. return ()\"\n\n\n\\<comment> \\<open>Interrupt controller operations\\<close>\n\ntext \\<open>\n  Interrupts that cannot occur while the kernel is running (e.g. at preemption points),\n  but that can occur from user mode. Empty on plain x86-64.\n\\<close>\ndefinition\n  \"non_kernel_IRQs = {}\"\n\ntext \\<open>\n  @{term getActiveIRQ} is now derministic.\n  It 'updates' the irq state to the reflect the passage of\n  time since last the irq was gotten, then it gets the active\n  IRQ (if there is one).\n\\<close>\ndefinition\n  getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\nwhere\n  \"getActiveIRQ in_kernel \\<equiv> do\n    is_masked \\<leftarrow> gets $ irq_masks;\n    modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n    active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n    if is_masked active_irq \\<or> active_irq = 0xFF \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n    then return None\n    else return ((Some active_irq) :: irq option)\n  od\"\n\ndefinition\n  maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"maskInterrupt m irq \\<equiv>\n  modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ntext \\<open>Does nothing on imx31\\<close>\ndefinition\n  ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ackInterrupt \\<equiv> \\<lambda>irq. return ()\"\n\ntext \\<open>Does nothing on imx31\\<close>\ndefinition\n  setInterruptMode :: \"irq \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setInterruptMode \\<equiv> \\<lambda>irq levelTrigger polarityLow. return ()\""}
{"title": "./spec/machine/X64/MachineOps.thy", "section": "Memory Clearance", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Clear memory contents to recycle it as user memory\\<close>\ndefinition\n  clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"clearMemory ptr bytelength \\<equiv> mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"\n\ndefinition\n  clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"\n\ntext \\<open>\n  Initialize memory to be used as user memory.\n  Note that zeroing out the memory is redundant in the specifications.\n  In any case, we cannot abstract from the call to cleanCacheRange,\n  which appears in the implementation.\n\\<close>\nabbreviation (input) \"initMemory == clearMemory\"\n\ntext \\<open>\n  Free memory that had been initialized as user memory.\n  While freeing memory is a no-(in) the implementation,\n  we zero out the underlying memory in the specifications to avoid garbage.\n  If we know that there is no garbage,\n  we can compute from the implementation state\n  what the exact memory content in the specifications is.\n\\<close>\ndefinition\n  freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"freeMemory ptr bits \\<equiv>\n  mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\""}
{"title": "./spec/machine/X64/MachineOps.thy", "section": "User Monad", "subsection": "", "subsubsection": "", "code": "\ntext \\<open> There are 576 bytes of FPU state. Since there are no operations on this state apart from bulk\nsave/restore, we abstract from names and just say how many bytes there are. \\<close>\ntype_synonym fpu_bytes = 576\ntype_synonym fpu_state = \"fpu_bytes \\<Rightarrow> 8 word\"\n\ntype_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ndatatype user_context = UserContext (fpu_state : fpu_state) (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\ndefinition\n  getRegister :: \"register \\<Rightarrow> machine_word user_monad\"\nwhere\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition\n  \"modify_registers f uc \\<equiv> UserContext (fpu_state uc) (f (user_regs uc))\"\n\ndefinition\n  setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\"\nwhere\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext (fpu_state s) ((user_regs s) (r := v)))\"\n\ndefinition\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition\n  \"setNextPC \\<equiv> setRegister NextIP\"\n\n\ndefinition\n  getFPUState :: \"fpu_state user_monad\"\nwhere\n  \"getFPUState \\<equiv> gets fpu_state\"\n\ndefinition\n  setFPUState :: \"fpu_state \\<Rightarrow> unit user_monad\"\nwhere\n  \"setFPUState fc \\<equiv> modify (\\<lambda>s. UserContext fc (user_regs s))\"\n\n(* The FPU state is opaque; the null state is a constant snapshot taken after initialisation *)\nconsts'\n  FPUNullState :: fpu_state\n\nconsts'\n  nativeThreadUsingFPU_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\n  nativeThreadUsingFPU_val :: \"machine_state \\<Rightarrow> bool\"\ndefinition\n  nativeThreadUsingFPU :: \"machine_word \\<Rightarrow> bool machine_monad\"\nwhere\n  \"nativeThreadUsingFPU thread_ptr \\<equiv> do\n       machine_op_lift (nativeThreadUsingFPU_impl thread_ptr);\n       gets nativeThreadUsingFPU_val\n  od\"\n\nconsts'\n  switchFpuOwner_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  switchFpuOwner :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"switchFpuOwner new_owner cpu \\<equiv> machine_op_lift (switchFpuOwner_impl new_owner cpu)\"\n\nconsts'\n  initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition\n  initL2Cache :: \"unit machine_monad\"\nwhere \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\nconsts'\n  writeCR3_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition writeCR3 :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"writeCR3 vspace pcid \\<equiv> machine_op_lift (writeCR3_impl vspace pcid)\"\n\nconsts'\n  mfence_impl :: \"unit machine_rest_monad\"\ndefinition\nmfence :: \"unit machine_monad\"\nwhere\n\"mfence \\<equiv> machine_op_lift mfence_impl\"\n\nconsts'\n  invalidateTLBEntry_impl :: \"word64 \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\ninvalidateTLBEntry :: \"word64 \\<Rightarrow> unit machine_monad\"\nwhere\n\"invalidateTLBEntry vptr \\<equiv> machine_op_lift (invalidateTLBEntry_impl vptr)\"\n\nconsts'\n  invalidateTranslationSingleASID_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  invalidateTranslationSingleASID :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateTranslationSingleASID vptr asid \\<equiv> machine_op_lift (invalidateTranslationSingleASID_impl vptr asid)\"\n\nconsts'\n  invalidateASID_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  invalidateASID :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateASID vspace asid \\<equiv> machine_op_lift (invalidateASID_impl vspace asid)\"\n\nconsts'\n  invalidateLocalPageStructureCacheASID_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  invalidateLocalPageStructureCacheASID :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateLocalPageStructureCacheASID vspace asid \\<equiv>\n     machine_op_lift (invalidateLocalPageStructureCacheASID_impl vspace asid)\"\n\n(* FIXME x64: VT-d\ndefinition\nfirstValidIODomain :: \"word16\"\nwhere\n\"firstValidIODomain \\<equiv> undefined\"\n\ndefinition\nnumIODomainIDBits :: \"nat\"\nwhere\n\"numIODomainIDBits \\<equiv> undefined\"\n*)\n\ndefinition\n  hwASIDInvalidate :: \"word64 \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"hwASIDInvalidate \\<equiv> invalidateASID\"\n\nconsts'\n  getFaultAddress_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\ngetFaultAddress :: \"word64 machine_monad\"\nwhere\n\"getFaultAddress \\<equiv> gets getFaultAddress_val\"\n\nconsts'\n  irqIntOffset_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\nirqIntOffset :: \"machine_word\"\nwhere\n\"irqIntOffset \\<equiv> 0x20\"\n\ndefinition\nmaxPCIBus :: \"machine_word\"\nwhere\n\"maxPCIBus \\<equiv> 0xFF\"\n\ndefinition\nmaxPCIDev :: \"machine_word\"\nwhere\n\"maxPCIDev \\<equiv> 31\"\n\ndefinition\nmaxPCIFunc :: \"machine_word\"\nwhere\n\"maxPCIFunc \\<equiv> 7\"\n\ndefinition\nioapicIRQLines :: \"machine_word\"\nwhere\n\"ioapicIRQLines \\<equiv> 24\"\n\nconsts'\n  ioapicMapPinToVector_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow>\n    machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  ioapicMapPinToVector :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow>\n    machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ioapicMapPinToVector ioapic pin level polarity vector \\<equiv>\n    machine_op_lift (ioapicMapPinToVector_impl ioapic pin level polarity vector)\"\n\ndefinition IRQ :: \"word8 \\<Rightarrow> irq\"\nwhere\n  \"IRQ \\<equiv> id\"\n\nconsts'\n  in8_impl :: \"word16 \\<Rightarrow> unit machine_rest_monad\"\n  in8_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  in8 :: \"word16 \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"in8 port \\<equiv> do machine_op_lift $ in8_impl port; gets in8_val od\"\n\nconsts'\n  in16_impl :: \"word16 \\<Rightarrow> unit machine_rest_monad\"\n  in16_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  in16 :: \"word16 \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"in16 port \\<equiv> do machine_op_lift $ in16_impl port; gets in16_val od\"\n\nconsts'\n  in32_impl :: \"word16 \\<Rightarrow> unit machine_rest_monad\"\n  in32_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  in32 :: \"word16 \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"in32 port \\<equiv> do machine_op_lift $ in32_impl port; gets in32_val od\"\n\nconsts'\n  out8_impl :: \"word16 \\<Rightarrow> word8 \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  out8 :: \"word16 \\<Rightarrow> word8 \\<Rightarrow> unit machine_monad\"\nwhere\n  \"out8 port dat \\<equiv> machine_op_lift $ out8_impl port dat\"\n\nconsts'\n  out16_impl :: \"word16 \\<Rightarrow> word16 \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  out16 :: \"word16 \\<Rightarrow> word16 \\<Rightarrow> unit machine_monad\"\nwhere\n  \"out16 port dat \\<equiv> machine_op_lift $ out16_impl port dat\"\n\nconsts'\n  out32_impl :: \"word16 \\<Rightarrow> word32 \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  out32 :: \"word16 \\<Rightarrow> word32 \\<Rightarrow> unit machine_monad\"\nwhere\n  \"out32 port dat \\<equiv> machine_op_lift $ out32_impl port dat\"\n\nend\n\n\nend"}
{"title": "./spec/machine/X64/Platform.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Platform Definitions\"\n\ntheory Platform\nimports\n  \"Lib.Lib\"\n  \"Word_Lib.WordSetup\"\n  \"Lib.Defs\"\n  Setup_Locale\n  Kernel_Config\nbegin"}
{"title": "./spec/machine/X64/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\n(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\""}
{"title": "./spec/machine/X64/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\ncontext Arch begin global_naming X64\n\ntype_synonym irq_len = 8\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = word64\n\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\ndefinition\n  pptrBase :: word64 where\n  \"pptrBase = 0xffffff8000000000\"\n\ndefinition\n  kernelELFBaseOffset :: word64 where\n  \"kernelELFBaseOffset = 0xffffffff80000000\"\n\ndefinition\n  pptrUserTop :: word64 where\n  \"pptrUserTop = 0x00007fffffffffff\"\n\ndefinition\n  ptrFromPAddr :: \"paddr \\<Rightarrow> word64\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBase\"\n\ndefinition\n  addrFromPPtr :: \"word64 \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBase\"\n\ndefinition\n  addrFromKPPtr :: \"word64 \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr pptr \\<equiv> pptr - kernelELFBaseOffset\"\n\ndefinition\n  pageColourBits :: \"nat\" where\n  \"pageColourBits \\<equiv> undefined\"\n\ndefinition\n  minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition\n  maxIRQ :: \"irq\" where\n  \"maxIRQ \\<equiv> 125\"\n\ndefinition\n  minUserIRQ :: \"irq\" where\n  \"minUserIRQ \\<equiv> 16\"\n\ndefinition\n  maxUserIRQ :: \"irq\" where\n  \"maxUserIRQ \\<equiv> 123\"\n\ndatatype cr3 = X64CR3 (CR3BaseAddress: word64) (cr3pcid: word64)\n\nprimrec cr3BaseAddress_update :: \"(word64 \\<Rightarrow> word64) \\<Rightarrow> cr3 \\<Rightarrow> cr3\"\nwhere\n  \"cr3BaseAddress_update f (X64CR3 v0 v1) = (X64CR3 (f v0) v1)\"\n\nprimrec cr3pcid_update :: \"(word64 \\<Rightarrow> word64) \\<Rightarrow> cr3 \\<Rightarrow> cr3\"\nwhere\n  \"cr3pcid_update f (X64CR3 v0 v1) = (X64CR3 v0 (f v1))\"\n\n\nend\nend"}
{"title": "./spec/machine/X64/Arch_Kernel_Config_Lemmas.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming X64\n\nend\nend"}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Machine Operations\"\n\ntheory MachineOps\nimports\n  \"Word_Lib.WordSetup\"\n  \"Monads.Nondet_Monad\"\n  MachineMonad\nbegin"}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine operations below work on the underspecified part of the machine state @{typ\n  machine_state_rest} and cannot fail. We could express the latter by type (leaving out the failure\n  flag), but if we later wanted to implement them, we'd have to set up a new Hoare logic framework\n  for that type. So instead, we provide a wrapper for these operations that explicitly ignores the\n  fail flag and sets it to False. Similarly, these operations never return an empty set of follow-on\n  states, which would require the operation to fail. So we explicitly make this (non-existing) case\n  a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\n\\<close>\n\ncontext Arch begin global_naming RISCV64"}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "Timer", "subsubsection": "", "code": "\ndefinition loadWord :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\n  where\n  \"loadWord p \\<equiv> do\n     m \\<leftarrow> gets underlying_memory;\n     assert (p && mask 3 = 0);\n     return (word_rcat (map (\\<lambda>i. m (p + (7 - of_int i))) [0 .. 7]))\n   od\"\n\ndefinition storeWord :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"storeWord p w \\<equiv> do\n     assert (p && mask 3 = 0);\n     modify (underlying_memory_update\n              (fold (\\<lambda>i m. m((p + (of_int i)) := word_rsplit w ! (7 - nat i))) [0 .. 7]))\n   od\"\n\nlemma upto0_7_def:\n  \"[0..7] = [0,1,2,3,4,5,6,7]\" by eval\n\nlemma loadWord_storeWord_is_return:\n  \"p && mask 3 = 0 \\<Longrightarrow> (do w \\<leftarrow> loadWord p; storeWord p w od) = return ()\"\n  by (auto simp: loadWord_def storeWord_def bind_def assert_def return_def word_rsplit_rcat_size\n                 modify_def gets_def get_def eval_nat_numeral put_def upto0_7_def word_size)\n\nconsts' memory_regions :: \"(paddr \\<times> paddr) list\"\ndefinition getMemoryRegions :: \"(paddr * paddr) list machine_monad\"\n  where\n  \"getMemoryRegions \\<equiv> return memory_regions\"\n\ntext \\<open>This instruction is required in the simulator, only.\\<close>\ndefinition storeWordVM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"storeWordVM w p \\<equiv> return ()\""}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "Timer", "subsubsection": "", "code": "\nconsts' configureTimer_impl :: \"unit machine_rest_monad\"\nconsts' configureTimer_val :: \"machine_state \\<Rightarrow> irq\"\ndefinition configureTimer :: \"irq machine_monad\"\n  where\n  \"configureTimer \\<equiv> do\n     machine_op_lift configureTimer_impl;\n     gets configureTimer_val\n   od\"\n\nconsts' initTimer_impl :: \"unit machine_rest_monad\"\ndefinition initTimer :: \"unit machine_monad\"\n  where\n  \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts' resetTimer_impl :: \"unit machine_rest_monad\"\ndefinition resetTimer :: \"unit machine_monad\"\n  where\n  \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\""}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "Debug", "subsubsection": "", "code": "\ndefinition debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\"\n  where\n  debugPrint_def[simp]:\n  \"debugPrint \\<equiv> \\<lambda>message. return ()\""}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "Interrupt Controller", "subsubsection": "", "code": "\ndefinition\n  IRQ :: \"irq \\<Rightarrow> irq\"\nwhere \"IRQ \\<equiv> id\"\n\nconsts'\n  setIRQTrigger_impl :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  setIRQTrigger :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setIRQTrigger irq trigger \\<equiv> machine_op_lift (setIRQTrigger_impl irq trigger)\"\n\nconsts'\n  plic_complete_claim_impl :: \"irq \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  plic_complete_claim :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"plic_complete_claim irq \\<equiv> machine_op_lift (plic_complete_claim_impl irq)\"\n\ntext \\<open>Interrupts that cannot occur while the kernel is running (e.g. at preemption points), but\nthat can occur from user mode. Empty on RISCV64.\\<close>\ndefinition non_kernel_IRQs :: \"irq set\"\n  where\n  \"non_kernel_IRQs = {}\"\n\ntext \\<open>@{term getActiveIRQ} is oracle-based and deterministic to allow information flow proofs. It\nupdates the IRQ state to the reflect the passage of time since last the IRQ, then it gets the active\nIRQ (if there is one).\\<close>\ndefinition getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\n  where\n  \"getActiveIRQ in_kernel \\<equiv> do\n     is_masked \\<leftarrow> gets $ irq_masks;\n     modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n     active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n     if is_masked active_irq \\<or> active_irq = 0xFF \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n     then return None\n     else return ((Some active_irq) :: irq option)\n   od\"\n\ndefinition maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\n  where\n  \"maskInterrupt m irq \\<equiv> modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\n  where\n  \"ackInterrupt \\<equiv> \\<lambda>irq. return ()\"\n\ndefinition setInterruptMode :: \"irq \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\"\n  where\n  \"setInterruptMode \\<equiv> \\<lambda>irq levelTrigger polarityLow. return ()\""}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "Clearing Memory", "subsubsection": "", "code": "\ntext \\<open>Clear memory contents to recycle it as user memory\\<close>\ndefinition clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemory ptr bytelength \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"\n\ntext \\<open>Haskell simulator interface stub.\\<close>\ndefinition clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"\n\ntext \\<open>\n  Initialize memory to be used as user memory. Note that zeroing out the memory is redundant\n  in the specifications. In any case, we cannot abstract from the call to cleanCacheRange, which\n  appears in the implementation.\n\\<close>\nabbreviation (input) \"initMemory == clearMemory\"\n\ntext \\<open>\n  Free memory that had been initialized as user memory. While freeing memory is a no-op in the\n  implementation, we zero out the underlying memory in the specifications to avoid garbage. If we\n  know that there is no garbage, we can compute from the implementation state what the exact memory\n  content in the specifications is.\n\\<close>\ndefinition freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"freeMemory ptr bits \\<equiv>\n   mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\""}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "User Monad and Registers", "subsubsection": "", "code": "\ntype_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ndatatype user_context = UserContext (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\n\ndefinition getRegister :: \"register \\<Rightarrow> machine_word user_monad\"\n  where\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition modify_registers :: \"(user_regs \\<Rightarrow> user_regs) \\<Rightarrow> user_context \\<Rightarrow> user_context\"\n  where\n  \"modify_registers f uc \\<equiv> UserContext (f (user_regs uc))\"\n\ndefinition setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\"\n  where\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext ((user_regs s) (r := v)))\"\n\ndefinition getRestartPC :: \"machine_word user_monad\"\n  where\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition setNextPC :: \"machine_word \\<Rightarrow> unit user_monad\"\n  where\n  \"setNextPC \\<equiv> setRegister NextIP\""}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "Caches, Barriers, and Flushing", "subsubsection": "", "code": "\nconsts' initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition initL2Cache :: \"unit machine_monad\"\n  where\n  \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\nconsts' hwASIDFlush_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition hwASIDFlush :: \"machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"hwASIDFlush asid \\<equiv> machine_op_lift (hwASIDFlush_impl asid)\"\n\nconsts' sfence_impl :: \"unit machine_rest_monad\"\ndefinition sfence :: \"unit machine_monad\"\n  where\n  \"sfence \\<equiv> machine_op_lift sfence_impl\"\n\nlemmas cache_machine_op_defs = sfence_def hwASIDFlush_def"}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "Faults", "subsubsection": "", "code": "\nconsts' stval_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition read_stval :: \"machine_word machine_monad\"\n  where\n  \"read_stval = gets stval_val\""}
{"title": "./spec/machine/RISCV64/MachineOps.thy", "section": "The Operations", "subsection": "Virtual Memory", "subsubsection": "", "code": "\nconsts' setVSpaceRoot_impl :: \"paddr \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition setVSpaceRoot :: \"paddr \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where\n  \"setVSpaceRoot pt asid \\<equiv> machine_op_lift $ setVSpaceRoot_impl pt asid\"\n\nend\nend"}
{"title": "./spec/machine/RISCV64/Platform.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Platform Definitions\"\n\ntheory Platform\nimports\n  \"Lib.Lib\"\n  \"Word_Lib.WordSetup\"\n  \"Lib.Defs\"\n  Setup_Locale\n  Kernel_Config\nbegin"}
{"title": "./spec/machine/RISCV64/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\n(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\""}
{"title": "./spec/machine/RISCV64/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\ncontext Arch begin global_naming RISCV64\n\nvalue_type irq_len = Kernel_Config.irqBits (* IRQ_CNODE_SLOT_BITS *)\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = machine_word\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\n(* Address space layout (from seL4/include/arch/riscv/arch/64/mode/hardware.h):\n\nThe top half of the address space is reserved for the kernel. This means that 256 top level\nentries are for the user, and 256 are for the kernel. This will be further split into the\n'regular' kernel window, which contains mappings to physical memory, a small (1GiB) higher\nkernel image window that we use for running the actual kernel from and a top 1GiB window for\nkernel device mappings. This means that between PPTR_BASE and\nKERNEL_ELF_BASE there are 254 entries remaining, which represents how much physical memory\ncan be used.\n\nAlmost all of the top 256 kernel entries will contain 1GiB page mappings. The only 2 entries\nthat contain a 2nd level PageTable consisting of 2MiB page entries is the entry\nfor the 1GiB Kernel ELF region and the 1GiB region corresponding to the physical memory\nof the kernel ELF in the kernel window.  The same 2nd level PageTable is used and so both\nentries refer to the same 1GiB of physical memory.\nThis means that the 1GiB kernel ELF mapping will correspond to physical memory with a 1GiB\nalignment.\n\n                  +-----------------------------+ 2^64\n                  |        Kernel Devices       |\n               -> +-------------------KDEV_BASE-+ 2^64 - 1GiB\n               |  |         Kernel ELF          |\n           ----|  +-------------KERNEL_ELF_BASE-+ --+ 2^64 - 2GiB + (KERNEL_ELF_PADDR_BASE % 1GiB)\n           |   |  |                             |\n           |   -> +-----------------------------+ --+ 2^64 - 2GiB = (KERNEL_ELF_BASE % 1GiB)\nShared 1GiB|      |                             |   |\ntable entry|      |           PSpace            |   |\n           |      |  (direct kernel mappings)   |   +----+\n           ------>|                             |   |    |\n                  |                             |   |    |\n                  +-------------------PPTR_BASE-+ --+ 2^64 - 2^b\n                  |                             |        |         +-------------------------+\n                  |                             |        |         |                         |\n                  |                             |        |         |                         |\n                  |          Invalid            |        |         |                         |\n                  |                             |        |         |           not           |\n                  |                             |        |         |         kernel          |\n                  |                             |        |         |       addressable       |\n                  +--------------------USER_TOP-+  2^c   |         |                         |\n                  |                             |        |         |                         |\n                  |                             |        |         |                         |\n                  |                             |        |      +- --------------------------+  PADDR_TOP =\n                  |                             |        |      |  |                         |    PPTR_TOP - PPTR_BASE\n                  |                             |        |      |  |                         |\n                  |                             |        |      |  |                         |\n                  |            User             |        |      |  |                         |\n                  |                             |        |      |  |                         |\n                  |                             |        +------+  +-------------------------+  KDEV_BASE - KERNEL_ELF_BASE + PADDR_LOAD\n                  |                             |     kernel    |  |        Kernel ELF       |\n                  |                             |   addressable |  +-------------------------+  KERNEL_ELF_PADDR_BASE\n                  |                             |               |  |                         |\n                  |                             |               |  |                         |\n                  +-----------------------------+  0            +- +-------------------------+  0 PADDR_BASE\n\n                     virtual address space                          physical address space\n\n c = one less than number of bits the page tables can translate\n   = sign extension bit for canonical addresses\n   (= 47 on x64, 38 on RISCV64 sv39, 47 on RISCV64 sv48)\n b = The number of bits used by kernel mapping.\n   = 38 (half of the 1 level page table) on RISCV64 sc39\n   = 39 (entire second level page table) on aarch64 / X64 / sv48\n*)\n\n(* NOTE: a number of these constants appear in the Haskell, but are shadowed\n   here due to more convenient formulation.\n   Examples: kernelELFBase, kernelELFBaseOffset, kernelELFAddressBase, pptrBase\n   Ideally and in future, we should converge on a single authoritative source\n   of these constants.\n*)\n\ndefinition canonical_bit :: nat\n  where\n  \"canonical_bit = 38\"\n\ndefinition kdevBase :: machine_word\n  where\n  \"kdevBase = - (1 << 30)\" (* 2^64 - 1 GiB *)\n\nlemma \"kdevBase = 0xFFFFFFFFC0000000\" (* Sanity check with C *)\n  by (simp add: kdevBase_def)\n\ndefinition kernelELFPAddrBase :: machine_word\n  where\n  \"kernelELFPAddrBase = physBase + 0x4000000\"\n\ndefinition pptrTop :: machine_word\n  where\n  \"pptrTop \\<equiv> - (1 << 31)\"\n\ndefinition kernelELFBase :: machine_word\n  where\n  \"kernelELFBase = pptrTop + (kernelELFPAddrBase && mask 30)\" (* 2^64 - 2 GiB + ... *)\n\ndefinition kernelELFBaseOffset :: machine_word\n  where\n  \"kernelELFBaseOffset = kernelELFBase - kernelELFPAddrBase\"\n\ndefinition pptrBase :: machine_word\n  where\n  \"pptrBase = - (1 << canonical_bit)\"\n\nlemma \"pptrBase = 0xFFFFFFC000000000\" (* Sanity check with C *)\n  by (simp add: pptrBase_def canonical_bit_def)\n\ndefinition pptrUserTop :: machine_word\n  where\n  \"pptrUserTop \\<equiv> mask canonical_bit && ~~mask 12\" (* for page boundary alignment *)\n\nlemma \"pptrUserTop = 0x0000003ffffff000\" (* Sanity check with C *)\n  by (simp add: pptrUserTop_def canonical_bit_def mask_def)\n\nschematic_goal pptrUserTop_def': (* direct constant definition *)\n  \"RISCV64.pptrUserTop = numeral ?x\"\n  by (simp add: RISCV64.pptrUserTop_def canonical_bit_def mask_def del: word_eq_numeral_iff_iszero)\n\ndefinition paddrBase :: machine_word\n  where\n  \"paddrBase \\<equiv> 0\"\n\ndefinition pptrBaseOffset :: machine_word\n  where\n  \"pptrBaseOffset = pptrBase - paddrBase\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> machine_word\"\n  where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"machine_word \\<Rightarrow> paddr\"\n  where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"machine_word \\<Rightarrow> paddr\"\n  where\n  \"addrFromKPPtr pptr \\<equiv> pptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\"\n  where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition maxIRQ :: \"irq\"\n  where\n  \"maxIRQ \\<equiv> 54\"\n\n(* Reserved by C to represent \"not an IRQ\" *)\ndefinition irqInvalid :: \"irq\"\n  where\n  \"irqInvalid \\<equiv> 0\"\n\ndefinition pageColourBits :: nat\n  where\n  \"pageColourBits \\<equiv> undefined\" \\<comment> \\<open>not implemented on this platform\\<close>\n\nend\nend"}
{"title": "./spec/machine/RISCV64/Arch_Kernel_Config_Lemmas.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming RISCV64\n\nlemma pptrBase_kernelELFBase:\n  \"pptrBase < kernelELFBase\"\n  by (simp add: pptrBase_def canonical_bit_def kernelELFBase_def kernelELFPAddrBase_def pptrTop_def\n                Kernel_Config.physBase_def mask_def)\n\n(* 12 in this lemma and below is pageBits, which is not yet defined in this theory.\n   Definition will be folded and the lemmas shadowed in AInvs. *)\nlemma is_page_aligned_physBase:\n  \"is_aligned physBase 12\"\n  by (simp add: Kernel_Config.physBase_def is_aligned_def)\n\n(* 22 is kernel_window_bits, defined in Init_A. To be folded in AInvs. *)\nlemma kernel_window_sufficient:\n  \"pptrBase + (1 << 22) \\<le> kernelELFBase\"\n  unfolding pptrBase_def canonical_bit_def kernelELFBase_def kernelELFPAddrBase_def pptrTop_def\n  by (simp add: mask_def Kernel_Config.physBase_def)\n\nlemma kernel_elf_window_at_least_page:\n  \"kernelELFBase + 2 ^ 12 \\<le> kdevBase\"\n  unfolding kernelELFBase_def kernelELFPAddrBase_def kdevBase_def pptrTop_def\n  by (simp add: mask_def Kernel_Config.physBase_def)\n\n(* This doesn't follow from alignment, because we need <, not \\<le> *)\nlemma kernelELFBase_no_overflow:\n  \"kernelELFBase < kernelELFBase + 2 ^ 12\"\n  unfolding kernelELFBase_def kernelELFPAddrBase_def pptrTop_def\n  by (simp add: mask_def Kernel_Config.physBase_def)\n\nend\nend"}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Machine Operations\"\n\ntheory MachineOps\nimports\n  Word_Lib.WordSetup\n  Monads.Nondet_Monad\n  MachineMonad\nbegin"}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine operations below work on the underspecified part of the machine state @{typ\n  machine_state_rest} and cannot fail. We could express the latter by type (leaving out the failure\n  flag), but if we later wanted to implement them, we'd have to set up a new Hoare logic framework\n  for that type. So instead, we provide a wrapper for these operations that explicitly ignores the\n  fail flag and sets it to False. Similarly, these operations never return an empty set of follow-on\n  states, which would require the operation to fail. So we explicitly make this (non-existing) case\n  a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\\<close>\n\ncontext Arch begin global_naming AARCH64"}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Timer", "subsubsection": "", "code": "\ndefinition loadWord :: \"machine_word \\<Rightarrow> machine_word machine_monad\" where\n  \"loadWord p \\<equiv> do\n     m \\<leftarrow> gets underlying_memory;\n     assert (p && mask 3 = 0);\n     return (word_rcat (map (\\<lambda>i. m (p + (7 - of_int i))) [0 .. 7]))\n   od\"\n\ndefinition storeWord :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"storeWord p w \\<equiv> do\n     assert (p && mask 3 = 0);\n     modify (underlying_memory_update\n              (fold (\\<lambda>i m. m((p + (of_int i)) := word_rsplit w ! (7 - nat i))) [0 .. 7]))\n   od\"\n\nlemma upto0_7_def:\n  \"[0..7] = [0,1,2,3,4,5,6,7]\" by eval\n\nlemma loadWord_storeWord_is_return:\n  \"p && mask 3 = 0 \\<Longrightarrow> (do w \\<leftarrow> loadWord p; storeWord p w od) = return ()\"\n  by (auto simp: loadWord_def storeWord_def bind_def assert_def return_def word_rsplit_rcat_size\n                 modify_def gets_def get_def eval_nat_numeral put_def upto0_7_def word_size)\n\nconsts' memory_regions :: \"(paddr \\<times> paddr) list\"\ndefinition getMemoryRegions :: \"(paddr * paddr) list machine_monad\" where\n  \"getMemoryRegions \\<equiv> return memory_regions\"\n\ntext \\<open>This instruction is required in the simulator, only.\\<close>\ndefinition storeWordVM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"storeWordVM w p \\<equiv> return ()\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Timer", "subsubsection": "", "code": "\nconsts' configureTimer_impl :: \"unit machine_rest_monad\"\nconsts' configureTimer_val :: \"machine_state \\<Rightarrow> irq\"\ndefinition configureTimer :: \"irq machine_monad\" where\n  \"configureTimer \\<equiv> do\n     machine_op_lift configureTimer_impl;\n     gets configureTimer_val\n   od\"\n\nconsts' initTimer_impl :: \"unit machine_rest_monad\"\ndefinition initTimer :: \"unit machine_monad\" where\n  \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts' resetTimer_impl :: \"unit machine_rest_monad\"\ndefinition resetTimer :: \"unit machine_monad\" where\n  \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Debug", "subsubsection": "", "code": "\ndefinition debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\" where\n  debugPrint_def[simp]:\n  \"debugPrint \\<equiv> \\<lambda>message. return ()\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Interrupt Controller", "subsubsection": "", "code": "\ndefinition IRQ :: \"irq \\<Rightarrow> irq\" where\n  \"IRQ \\<equiv> id\"\n\nconsts' setIRQTrigger_impl :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_rest_monad\"\ndefinition setIRQTrigger :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\" where\n  \"setIRQTrigger irq trigger \\<equiv> machine_op_lift (setIRQTrigger_impl irq trigger)\"\n\nconsts' plic_complete_claim_impl :: \"irq \\<Rightarrow> unit machine_rest_monad\"\ndefinition plic_complete_claim :: \"irq \\<Rightarrow> unit machine_monad\" where\n  \"plic_complete_claim irq \\<equiv> machine_op_lift (plic_complete_claim_impl irq)\"\n\ntext \\<open>\n  Interrupts that cannot occur while the kernel is running (e.g. at preemption points),\n  but that can occur from user mode.\\<close>\ndefinition non_kernel_IRQs :: \"irq set\" where\n  \"non_kernel_IRQs = {irqVGICMaintenance, irqVTimerEvent}\"\n\ntext \\<open>@{term getActiveIRQ} is oracle-based and deterministic to allow information flow proofs. It\nupdates the IRQ state to the reflect the passage of time since last the IRQ, then it gets the active\nIRQ (if there is one).\\<close>\ndefinition getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\" where\n  \"getActiveIRQ in_kernel \\<equiv> do\n     is_masked \\<leftarrow> gets $ irq_masks;\n     modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n     active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n     if is_masked active_irq \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n     then return None\n     else return (Some active_irq)\n   od\"\n\ndefinition maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\" where\n  \"maskInterrupt m irq \\<equiv> modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\" where\n  \"ackInterrupt \\<equiv> \\<lambda>irq. return ()\"\n\ndefinition setInterruptMode :: \"irq \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\" where\n  \"setInterruptMode \\<equiv> \\<lambda>irq levelTrigger polarityLow. return ()\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "User Monad and Registers", "subsubsection": "", "code": "\ntype_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ntext \\<open> There are 64 general FPU registers saved. \\<close>\ntype_synonym fpu_regs = 64\n\ntext \\<open>\n  We use Haskell naming convention here, as we translate the Haskell FPUState directly\n  to this one for use in the abstract and executable specs.\\<close>\ndatatype fpu_state = FPUState (fpuRegs : \"fpu_regs \\<Rightarrow> 64 word\")\n                              (fpuSr : \"32 word\")\n                              (fpuCr : \"32 word\")\n\ndatatype user_context = UserContext (fpu_state : fpu_state) (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\ndefinition getRegister :: \"register \\<Rightarrow> machine_word user_monad\" where\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition modify_registers :: \"(user_regs \\<Rightarrow> user_regs) \\<Rightarrow> user_context \\<Rightarrow> user_context\" where\n  \"modify_registers f uc \\<equiv> UserContext (fpu_state uc) (f (user_regs uc))\"\n\ndefinition setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\" where\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext (fpu_state s) ((user_regs s) (r := v)))\"\n\ndefinition getRestartPC :: \"machine_word user_monad\" where\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition setNextPC :: \"machine_word \\<Rightarrow> unit user_monad\" where\n  \"setNextPC \\<equiv> setRegister NextIP\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "FPU-related", "subsubsection": "", "code": "\nconsts' enableFpuEL01_impl :: \"unit machine_rest_monad\"\ndefinition enableFpuEL01 :: \"unit machine_monad\" where\n  \"enableFpuEL01 \\<equiv> machine_op_lift enableFpuEL01_impl\"\n\ndefinition getFPUState :: \"fpu_state user_monad\" where\n  \"getFPUState \\<equiv> gets fpu_state\"\n\ndefinition setFPUState :: \"fpu_state \\<Rightarrow> unit user_monad\" where\n  \"setFPUState fc \\<equiv> modify (\\<lambda>s. UserContext fc (user_regs s))\"\n\nconsts' nativeThreadUsingFPU_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\nconsts' nativeThreadUsingFPU_val :: \"machine_state \\<Rightarrow> bool\"\ndefinition nativeThreadUsingFPU :: \"machine_word \\<Rightarrow> bool machine_monad\" where\n  \"nativeThreadUsingFPU thread_ptr \\<equiv> do\n       machine_op_lift (nativeThreadUsingFPU_impl thread_ptr);\n       gets nativeThreadUsingFPU_val\n  od\"\n\nconsts' switchFpuOwner_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition switchFpuOwner :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"switchFpuOwner new_owner cpu \\<equiv> machine_op_lift (switchFpuOwner_impl new_owner cpu)\"\n\n(* FIXME this is a very high-level FPU abstraction *)\nconsts' fpuThreadDeleteOp_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition fpuThreadDeleteOp :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"fpuThreadDeleteOp thread_ptr \\<equiv> machine_op_lift (fpuThreadDeleteOp_impl thread_ptr)\"\n\n(* FIXME this machine op is used to abstract the entire lazy FPU switch interrupt mechanism,\n   which can only trigger when the current thread's FPU is disabled and it performs an FPU\n   operation. We have no model for this mechanism or the state that it caches, so for\n   verification purposes we act as if the FPU is always enabled.\n   Future lazy FPU switch overhaul will involve the state that this operation reads, at which\n   point it should become a normal function. *)\ndefinition isFpuEnable :: \"bool machine_monad\" where\n  \"isFpuEnable \\<equiv> return True\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Fault Registers", "subsubsection": "", "code": "\nconsts' FAR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getFAR :: \"machine_word machine_monad\" where\n  \"getFAR \\<equiv> gets FAR_val\"\n\nconsts' DFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getDFSR :: \"machine_word machine_monad\" where\n  \"getDFSR \\<equiv> gets DFSR_val\"\n\nconsts' IFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getIFSR :: \"machine_word machine_monad\" where\n  \"getIFSR \\<equiv> gets IFSR_val\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Control Registers", "subsubsection": "", "code": "\nconsts' HSR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getHSR :: \"machine_word machine_monad\" where\n  \"getHSR \\<equiv> gets HSR_val\"\n\nconsts' ESR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getESR :: \"machine_word machine_monad\" where\n  \"getESR \\<equiv> gets ESR_val\"\n\nconsts' SCTLR_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition getSCTLR :: \"machine_word machine_monad\" where\n  \"getSCTLR \\<equiv> gets SCTLR_val\"\n\nconsts' setHCR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition setHCR :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"setHCR w \\<equiv> machine_op_lift (setHCR_impl w)\"\n\nconsts' setSCTLR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition setSCTLR :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"setSCTLR w \\<equiv> machine_op_lift (setSCTLR_impl w)\"\n\nconsts' addressTranslateS1_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\nconsts' addressTranslateS1_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition addressTranslateS1 :: \"machine_word \\<Rightarrow> machine_word machine_monad\" where\n  \"addressTranslateS1 w \\<equiv> do\n    machine_op_lift (addressTranslateS1_impl w);\n    gets (addressTranslateS1_val w)\n  od\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "GIC VCPU Interface", "subsubsection": "", "code": "\nconsts' gic_vcpu_ctrl_hcr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_hcr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_hcr \\<equiv> gets gic_vcpu_ctrl_hcr_val\"\n\nconsts' set_gic_vcpu_ctrl_hcr_impl :: \"32 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_hcr :: \"32 word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_hcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_hcr_impl w)\"\n\nconsts' gic_vcpu_ctrl_vmcr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_vmcr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_vmcr \\<equiv> gets gic_vcpu_ctrl_vmcr_val\"\n\nconsts' set_gic_vcpu_ctrl_vmcr_impl :: \"32 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_vmcr :: \"32 word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_vmcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vmcr_impl w)\"\n\nconsts' gic_vcpu_ctrl_apr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_apr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_apr \\<equiv> gets gic_vcpu_ctrl_apr_val\"\n\nconsts' set_gic_vcpu_ctrl_apr_impl :: \"32 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_apr :: \"32 word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_apr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_apr_impl w)\"\n\nconsts' gic_vcpu_ctrl_vtr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_vtr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_vtr \\<equiv> gets gic_vcpu_ctrl_vtr_val\"\n\nconsts' set_gic_vcpu_ctrl_vtr_impl :: \"32 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_vtr :: \"32 word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_vtr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vtr_impl w)\"\n\nconsts' gic_vcpu_ctrl_misr_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_misr :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_misr \\<equiv> gets gic_vcpu_ctrl_misr_val\"\n\nconsts' gic_vcpu_ctrl_eisr0_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_eisr0 :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_eisr0 \\<equiv> gets gic_vcpu_ctrl_eisr0_val\"\n\nconsts' gic_vcpu_ctrl_eisr1_val :: \"machine_state \\<Rightarrow> 32 word\"\ndefinition get_gic_vcpu_ctrl_eisr1 :: \"32 word machine_monad\" where\n  \"get_gic_vcpu_ctrl_eisr1 \\<equiv> gets gic_vcpu_ctrl_eisr1_val\"\n\nconsts' get_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\nconsts' gic_vcpu_ctrl_lr_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition get_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word machine_monad\" where\n  \"get_gic_vcpu_ctrl_lr n \\<equiv> do\n     machine_op_lift (get_gic_vcpu_ctrl_lr_impl n);\n     gets (gic_vcpu_ctrl_lr_val n)\n   od\"\n\nconsts' set_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition set_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"set_gic_vcpu_ctrl_lr n w  \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_lr_impl n w)\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Virtual Timer Interface", "subsubsection": "", "code": "\nconsts' check_export_arch_timer_impl :: \"unit machine_rest_monad\"\ndefinition check_export_arch_timer :: \"unit machine_monad\" where\n  \"check_export_arch_timer \\<equiv> machine_op_lift check_export_arch_timer_impl\"\n\nconsts' read_cntpct_val :: \"machine_state \\<Rightarrow> 64 word\"\ndefinition read_cntpct :: \"64 word machine_monad\" where\n  \"read_cntpct \\<equiv> gets read_cntpct_val\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Hypervisor Banked Registers", "subsubsection": "", "code": "\nconsts' vcpuHardwareReg_val :: \"vcpureg \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition readVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word machine_monad\" where\n  \"readVCPUHardwareReg reg \\<equiv> gets (vcpuHardwareReg_val reg)\"\n\nconsts' writeVCPUHardwareReg_impl :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition writeVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"writeVCPUHardwareReg reg val \\<equiv> machine_op_lift (writeVCPUHardwareReg_impl reg val)\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Caches, Barriers, and Flushing", "subsubsection": "", "code": "\nconsts' initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition initL2Cache :: \"unit machine_monad\" where\n  \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\nconsts' isb_impl :: \"unit machine_rest_monad\"\ndefinition isb :: \"unit machine_monad\" where\n  \"isb \\<equiv> machine_op_lift isb_impl\"\n\nconsts' dsb_impl :: \"unit machine_rest_monad\"\ndefinition dsb :: \"unit machine_monad\" where\n  \"dsb \\<equiv> machine_op_lift dsb_impl\"\n\nconsts' invalidateTranslationASID_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition invalidateTranslationASID :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"invalidateTranslationASID asid \\<equiv> machine_op_lift (invalidateTranslationASID_impl asid)\"\n\nconsts' invalidateTranslationSingle_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition invalidateTranslationSingle :: \"machine_word \\<Rightarrow> unit machine_monad\" where\n  \"invalidateTranslationSingle r \\<equiv> machine_op_lift (invalidateTranslationSingle_impl r)\"\n\nconsts' cleanByVA_PoU_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition cleanByVA_PoU :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"cleanByVA_PoU vaddr paddr = machine_op_lift (cleanByVA_PoU_impl vaddr paddr)\"\n\nconsts' cleanInvalidateCacheRange_RAM_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition cleanInvalidateCacheRange_RAM ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"cleanInvalidateCacheRange_RAM vstart vend pstart =\n     machine_op_lift (cleanInvalidateCacheRange_RAM_impl vstart vend pstart)\"\n\nconsts' cleanCacheRange_RAM_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition cleanCacheRange_RAM ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"cleanCacheRange_RAM vstart vend pstart =\n     machine_op_lift (cleanCacheRange_RAM_impl vstart vend pstart)\"\n\nconsts' cleanCacheRange_PoU_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition cleanCacheRange_PoU ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"cleanCacheRange_PoU vstart vend pstart =\n     machine_op_lift (cleanCacheRange_PoU_impl vstart vend pstart)\"\n\nconsts' invalidateCacheRange_RAM_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition invalidateCacheRange_RAM ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"invalidateCacheRange_RAM vstart vend pstart =\n     machine_op_lift (invalidateCacheRange_RAM_impl vstart vend pstart)\"\n\nconsts' invalidateCacheRange_I_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition invalidateCacheRange_I ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"invalidateCacheRange_I vstart vend pstart =\n     machine_op_lift (invalidateCacheRange_I_impl vstart vend pstart)\"\n\nconsts' branchFlushRange_impl ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition branchFlushRange ::\n  \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"branchFlushRange vstart vend pstart = machine_op_lift (branchFlushRange_impl vstart vend pstart)\"\n\nlemmas cache_machine_op_defs =\n  invalidateTranslationASID_def\n  invalidateTranslationSingle_def\n  cleanByVA_PoU_def\n  cleanInvalidateCacheRange_RAM_def\n  cleanCacheRange_RAM_def\n  cleanCacheRange_PoU_def\n  invalidateCacheRange_RAM_def\n  invalidateCacheRange_I_def\n  branchFlushRange_def"}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Clearing Memory", "subsubsection": "", "code": "\ntext \\<open>Clear memory contents to recycle it as user memory. Do not yet flush the cache.\\<close>\ndefinition clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"clearMemory ptr bytelength \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"\n\ntext \\<open>Haskell simulator interface stub.\\<close>\ndefinition clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"\n\ntext \\<open>\n  Initialize memory to be used as user memory. Note that zeroing out the memory is redundant\n  in the specifications. In any case, we cannot abstract from the call to cleanCacheRange, which\n  appears in the implementation.\\<close>\nabbreviation (input) \"initMemory == clearMemory\"\n\ntext \\<open>\n  Free memory that had been initialized as user memory. While freeing memory is a no-op in the\n  implementation, we zero out the underlying memory in the specifications to avoid garbage. If we\n  know that there is no garbage, we can compute from the implementation state what the exact memory\n  content in the specifications is.\\<close>\ndefinition freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\" where\n  \"freeMemory ptr bits \\<equiv>\n     mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\""}
{"title": "./spec/machine/AARCH64/MachineOps.thy", "section": "The Operations", "subsection": "Virtual Memory", "subsubsection": "", "code": "\nconsts' setVSpaceRoot_impl :: \"paddr \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition setVSpaceRoot :: \"paddr \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\" where\n  \"setVSpaceRoot pt asid \\<equiv> machine_op_lift $ setVSpaceRoot_impl pt asid\"\n\nend\nend"}
{"title": "./spec/machine/AARCH64/Platform.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Platform Definitions\"\n\ntheory Platform\nimports\n  \"Lib.Lib\"\n  \"Word_Lib.WordSetup\"\n  \"Lib.Defs\"\n  Setup_Locale\n  Kernel_Config\nbegin"}
{"title": "./spec/machine/AARCH64/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\n(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\""}
{"title": "./spec/machine/AARCH64/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\ncontext Arch begin global_naming AARCH64\n\nvalue_type irq_len = Kernel_Config.irqBits (* IRQ_CNODE_SLOT_BITS *)\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = machine_word\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\n(* For address space layout with hypervisor enabled see:\n   seL4/include/arch/arm/arch/64/mode/hardware.h\n   FIXME AARCH64 include diagram here after C revisions are done\n*)\n\n(* NOTE: a number of these constants appear in the Haskell, but are shadowed\n   here due to more convenient formulation.\n   Examples: kernelELFBase, kernelELFBaseOffset, kernelELFAddressBase, pptrBase\n   Ideally and in future, we should converge on a single authoritative source\n   of these constants.\n*)\n\n(* The canonical bit is the highest bit that can be set in a virtual address and still accepted\n   by the hardware. Any bit higher than that will be overwritten by sign extension, zero extension,\n   or result in a fault.\n   For AArch64 with hyp, addresses >= 2^48 are invalid, and sign-extension is not used by the\n   hardware. *)\ndefinition canonical_bit :: nat where\n  \"canonical_bit = 47\"\n\ndefinition cacheLineBits :: nat where\n  \"cacheLineBits = CONFIG_L1_CACHE_LINE_SIZE_BITS\"\n\ndefinition kdevBase :: machine_word where\n  \"kdevBase = 0x000000FFFFE00000\"\n\ndefinition kernelELFBase :: machine_word where\n  \"kernelELFBase = 2^39 + physBase\"\n\ndefinition kernelELFPAddrBase :: machine_word where\n  \"kernelELFPAddrBase = physBase\"\n\ndefinition kernelELFBaseOffset :: machine_word where\n  \"kernelELFBaseOffset = kernelELFBase - kernelELFPAddrBase\"\n\ndefinition pptrBase :: machine_word where\n  \"pptrBase = 0x8000000000\" (* 2^39 *)\n\ndefinition pptrUserTop :: machine_word where\n  \"pptrUserTop \\<equiv> mask (if config_ARM_PA_SIZE_BITS_40 then 40 else 44)\"\n\nlemma \"pptrUserTop = (if config_ARM_PA_SIZE_BITS_40 then 0xFFFFFFFFFF else 0xFFFFFFFFFFF)\" (* Sanity check with C *)\n  by (simp add: pptrUserTop_def mask_def)\n\ndefinition pptrTop :: machine_word where\n  \"pptrTop = 2^40 - 2^30\" (* FIXME AARCH64: see also seL4/seL4#957 *)\n\ndefinition paddrBase :: machine_word where\n  \"paddrBase \\<equiv> 0\"\n\ndefinition pptrBaseOffset :: machine_word where\n  \"pptrBaseOffset = pptrBase - paddrBase\"\n\ndefinition paddrTop :: machine_word where\n  \"paddrTop = pptrTop - pptrBaseOffset\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> machine_word\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"machine_word \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"machine_word \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr pptr \\<equiv> pptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition irqVGICMaintenance :: irq where\n  \"irqVGICMaintenance \\<equiv> 25\"\n\ndefinition irqVTimerEvent :: irq where\n  \"irqVTimerEvent \\<equiv> 27\"\n\ndefinition pageColourBits :: nat where\n  \"pageColourBits \\<equiv> undefined\" \\<comment> \\<open>not implemented on this platform\\<close>"}
{"title": "./spec/machine/AARCH64/Platform.thy", "section": "Page table sizes", "subsection": "", "subsubsection": "", "code": "\ndefinition vs_index_bits :: nat where\n  \"vs_index_bits \\<equiv> if config_ARM_PA_SIZE_BITS_40 then 10 else (9::nat)\"\n\nend\n\n(* Need to declare code equation outside Arch locale *)\ndeclare AARCH64.vs_index_bits_def[code]\n\ncontext Arch begin global_naming AARCH64\n\nlemma vs_index_bits_ge0[simp, intro!]: \"0 < vs_index_bits\"\n  by (simp add: vs_index_bits_def)\n\n(* A dependent-ish type in Isabelle. We use typedef here instead of value_type so that we can\n   retain a symbolic value (vs_index_bits) for the size of the type instead of getting a plain\n   number such as 9 or 10. *)\ntypedef vs_index_len = \"{n :: nat. n < vs_index_bits}\" by auto\n\nend\n\ninstantiation AARCH64.vs_index_len :: len0\nbegin\n  interpretation Arch .\n  definition len_of_vs_index_len: \"len_of (x::vs_index_len itself) \\<equiv> CARD(vs_index_len)\"\n  instance ..\nend\n\ninstantiation AARCH64.vs_index_len :: len\nbegin\n  interpretation Arch .\n  instance\n  proof\n   show \"0 < LENGTH(vs_index_len)\"\n     by (simp add: len_of_vs_index_len type_definition.card[OF type_definition_vs_index_len])\n  qed\nend\n\ncontext Arch begin global_naming AARCH64\n\ntype_synonym vs_index = \"vs_index_len word\"\n\ntype_synonym pt_index_len = 9\ntype_synonym pt_index = \"pt_index_len word\"\n\ntext \\<open>Sanity check:\\<close>\nlemma length_vs_index_len[simp]:\n  \"LENGTH(vs_index_len) = vs_index_bits\"\n  by (simp add: len_of_vs_index_len type_definition.card[OF type_definition_vs_index_len])"}
{"title": "./spec/machine/AARCH64/Platform.thy", "section": "C array sizes corresponding to page table sizes", "subsection": "", "subsubsection": "", "code": "\nvalue_type pt_array_len = \"(2::nat) ^ LENGTH(pt_index_len)\"\nvalue_type vs_array_len = \"(2::nat) ^ vs_index_bits\"\n\nend\n\nend"}
{"title": "./spec/machine/AARCH64/Arch_Kernel_Config_Lemmas.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2024, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming AARCH64\n\n(* maxIRQ conditions *)\n\nlemma irqVTimerEvent_le_maxIRQ[simp, intro!]:\n  \"irqVTimerEvent \\<le> maxIRQ\"\n  by (simp add: irqVTimerEvent_def Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_less_2p_irqBits:\n  \"(maxIRQ::nat) < 2^irqBits\"\n  by (simp add: Kernel_Config.maxIRQ_def Kernel_Config.irqBits_def)\n\n(* follows from value_type definition of irq_len *)\nlemma LENGTH_irq_len_irqBits[simp]: (* [simp] will fire only for simp del: len_of_numeral_defs *)\n  \"LENGTH(irq_len) = irqBits\"\n  using irq_len_def irq_len_val\n  by simp\n\nlemma maxIRQ_less_2p_irq_len:\n  \"(maxIRQ::nat) < 2^LENGTH(irq_len)\"\n  using maxIRQ_less_2p_irqBits\n  by (simp del: len_of_numeral_defs)\n\n(* maxIRQ as a generic numeral allows us to write rules about casts/unat/uint etc without\n   mentioning numbers: *)\n\nlemma of_nat_maxIRQ[simp]:\n  \"of_nat maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma of_int_maxIRQ[simp]:\n  \"of_int maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma unat_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> unat (maxIRQ::'a word) = maxIRQ\"\n  by (metis maxIRQ_less_2p_irq_len Word.of_nat_unat of_nat_inverse of_nat_maxIRQ unat_ucast_up_simp)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma uint_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> uint (maxIRQ::'a word) = maxIRQ\"\n  by (metis Kernel_Config.maxIRQ_def of_nat_numeral uint_nat unat_maxIRQ)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma ucast_maxIRQ[simp]:\n  \"\\<lbrakk> LENGTH(irq_len) \\<le> LENGTH('a::len); LENGTH(irq_len) \\<le> LENGTH('b::len) \\<rbrakk> \\<Longrightarrow>\n   UCAST ('a \\<rightarrow> 'b) maxIRQ = maxIRQ\"\n  by (metis of_nat_maxIRQ ucast_nat_def unat_maxIRQ)\n\n(* Safe for [simp] because we don't cast down from irq type *)\nlemma maxIRQ_less_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   (maxIRQ < (ucast irq :: 'a word)) = (maxIRQ < irq)\" for irq::irq\n  by (simp add: word_less_nat_alt unat_ucast_up_simp)\n\n(* Safe for [simp] because we don't cast down from irq type *)\nlemma maxIRQ_le_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   ((ucast irq :: 'a word) \\<le> Kernel_Config.maxIRQ) = (irq \\<le> Kernel_Config.maxIRQ)\" for irq::irq\n  by (simp add: word_le_nat_alt unat_ucast_up_simp)\n\n(* The following are instances -- for some we could derive general rules, but the number of\n   instances is limited and the concrete proofs are much simpler: *)\n\nlemma le_maxIRQ_machine_less_irqBits_val[simplified]:\n  \"w \\<le> maxIRQ \\<Longrightarrow> unat w < 2^LENGTH(irq_len)\" for w::machine_word\n  using maxIRQ_less_2p_irq_len\n  by (simp add: word_le_nat_alt)\n\nlemma irq_machine_le_maxIRQ_irq:\n  \"irq \\<le> Kernel_Config.maxIRQ \\<Longrightarrow> (ucast irq::irq) \\<le> maxIRQ\" for irq::machine_word\n  by (simp add: Kernel_Config.maxIRQ_def word_le_nat_alt unat_ucast)\n\nlemma maxIRQ_eq_ucast_irq_32_signed_uint:\n  \"(maxIRQ = (ucast b :: 32 signed word)) = (uint b = maxIRQ)\" for b::irq\n  unfolding Kernel_Config.maxIRQ_def\n  apply uint_arith\n  apply (simp add: uint_up_ucast is_up)\n  done\n\nlemma sint_maxIRQ_32[simp]:\n  \"sint (maxIRQ :: 32 signed word) = maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_machine[simp]:\n  \"scast (maxIRQ::32 signed word) = (maxIRQ::machine_word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_irq[simp]:\n  \"scast (maxIRQ :: 32 signed word) = (maxIRQ::irq)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_machine:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = x\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_irq:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = (ucast x :: irq)\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_1_plus_eq_Suc_machine[simp]:\n  \"unat (1 + Kernel_Config.maxIRQ :: machine_word) = Suc Kernel_Config.maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\n\n(* cacheLineBits conditions *)\n\n(* Folding cacheLineBits_val in C functions only works reliably if cacheLineBits is not 1 and\n   not too large to conflict with other values used inside cache ops.\n   12 is ptBits, which is only available after ExecSpec. Anything > 1 and smaller than ptBits\n   works. *)\nlemma cacheLineBits_sanity:\n  \"cacheLineBits \\<in> {2..12}\"\n  by (simp add: cacheLineBits_def Kernel_Config.CONFIG_L1_CACHE_LINE_SIZE_BITS_def)\n\nend\nend"}
{"title": "./spec/machine/ARM_HYP/MachineOps.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Machine Operations\"\n\ntheory MachineOps\nimports\n  MachineMonad\nbegin"}
{"title": "./spec/machine/ARM_HYP/MachineOps.thy", "section": "The Operations", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine operations below work on the underspecified\n  part of the machine state @{typ machine_state_rest} and cannot fail.\n  We could express the latter by type (leaving out the failure flag),\n  but if we later wanted to implement them,\n  we'd have to set up a new hoare-logic\n  framework for that type. So instead, we provide a wrapper for these\n  operations that explicitly ignores the fail flag and sets it to\n  False. Similarly, these operations never return an empty set of\n  follow-on states, which would require the operation to fail.\n  So we explicitly make this (non-existing) case a null operation.\n\n  All this is done only to avoid a large number of axioms (2 for each operation).\n\\<close>\n\ncontext Arch begin global_naming ARM_HYP"}
{"title": "./spec/machine/ARM_HYP/MachineOps.thy", "section": "The Operations", "subsection": "", "subsubsection": "", "code": "\nconsts'\n  memory_regions :: \"(paddr \\<times> paddr) list\" (* avail_p_regs *)\n  device_regions :: \"(paddr \\<times> paddr) list\" (* dev_p_regs *)\n\ndefinition\n  getMemoryRegions :: \"(paddr * paddr) list machine_monad\"\n  where \"getMemoryRegions \\<equiv> return memory_regions\"\n\nconsts'\n  getDeviceRegions_impl :: \"unit machine_rest_monad\"\n  getDeviceRegions_val :: \"machine_state \\<Rightarrow> (paddr * paddr) list\"\n\ndefinition\n  getDeviceRegions :: \"(paddr * paddr) list machine_monad\"\nwhere\n  \"getDeviceRegions \\<equiv> return device_regions\"\n\nconsts'\n  getKernelDevices_impl :: \"unit machine_rest_monad\"\n  getKernelDevices_val :: \"machine_state \\<Rightarrow> (paddr * machine_word) list\"\n\ndefinition\n  getKernelDevices :: \"(paddr * machine_word) list machine_monad\"\nwhere\n  \"getKernelDevices \\<equiv> do\n    machine_op_lift getKernelDevices_impl;\n    gets getKernelDevices_val\n  od\"\n\nconsts'\n  setIRQTrigger_impl :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_rest_monad\"\n\ndefinition\n  setIRQTrigger :: \"irq \\<Rightarrow> bool \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setIRQTrigger irq trigger \\<equiv> machine_op_lift (setIRQTrigger_impl irq trigger)\"\n\ndefinition\n  loadWord :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\n  where \"loadWord p \\<equiv> do m \\<leftarrow> gets underlying_memory;\n                         assert (p && mask 2 = 0);\n                         return (word_rcat [m (p + 3), m (p + 2), m (p + 1), m p])\n                      od\"\n\ndefinition\n  storeWord :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where \"storeWord p w \\<equiv> do\n                            assert (p && mask 2 = 0);\n                            modify (underlying_memory_update (\\<lambda>m.\n                                      m(p := word_rsplit w ! 3,\n                                        p + 1 := word_rsplit w ! 2,\n                                        p + 2 := word_rsplit w ! 1,\n                                        p + 3 := word_rsplit w ! 0)))\n                         od\"\n\nlemma loadWord_storeWord_is_return:\n  \"p && mask 2 = 0 \\<Longrightarrow> (do w \\<leftarrow> loadWord p; storeWord p w od) = return ()\"\n  apply (rule ext)\n  apply (simp add: loadWord_def storeWord_def bind_def assert_def return_def\n    modify_def gets_def get_def eval_nat_numeral put_def)\n  apply (simp add: word_rsplit_rcat_size word_size)\n  done\n\ntext \\<open>This instruction is required in the simulator, only.\\<close>\ndefinition\n  storeWordVM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\n  where \"storeWordVM w p \\<equiv> return ()\"\n\nconsts'\n  configureTimer_impl :: \"unit machine_rest_monad\"\n  configureTimer_val :: \"machine_state \\<Rightarrow> irq\"\n\ndefinition\n  configureTimer :: \"irq machine_monad\"\nwhere\n  \"configureTimer \\<equiv> do\n    machine_op_lift configureTimer_impl;\n    gets configureTimer_val\n  od\"\n\nconsts' (* XXX: replaces configureTimer in new boot code\n          TODO: remove configureTimer when haskell updated *)\n  initTimer_impl :: \"unit machine_rest_monad\"\ndefinition\n  initTimer :: \"unit machine_monad\"\nwhere \"initTimer \\<equiv> machine_op_lift initTimer_impl\"\n\nconsts'\n  resetTimer_impl :: \"unit machine_rest_monad\"\n\ndefinition\n  resetTimer :: \"unit machine_monad\"\nwhere \"resetTimer \\<equiv> machine_op_lift resetTimer_impl\"\n\nconsts'\n  writeTTBR0_impl :: \"paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeTTBR0 :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere \"writeTTBR0 pd \\<equiv> machine_op_lift (writeTTBR0_impl pd)\"\n\n\nconsts'\n  setHardwareASID_impl :: \"hardware_asid \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setHardwareASID:: \"hardware_asid \\<Rightarrow> unit machine_monad\"\nwhere \"setHardwareASID a \\<equiv> machine_op_lift (setHardwareASID_impl a)\"\n\n\n(* Memory Barriers *)\n\n\nconsts'\n  isb_impl :: \"unit machine_rest_monad\"\ndefinition\n  isb :: \"unit machine_monad\"\nwhere \"isb \\<equiv> machine_op_lift isb_impl\"\n\nconsts'\n  dsb_impl :: \"unit machine_rest_monad\"\ndefinition\n  dsb :: \"unit machine_monad\"\nwhere \"dsb \\<equiv> machine_op_lift dsb_impl\"\n\nconsts'\n  dmb_impl :: \"unit machine_rest_monad\"\ndefinition\n  dmb :: \"unit machine_monad\"\nwhere \"dmb \\<equiv> machine_op_lift dmb_impl\"\n\nconsts'\n  setCurrentPDPL2_impl :: \"paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setCurrentPDPL2 :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere \"setCurrentPDPL2 pd \\<equiv> machine_op_lift (setCurrentPDPL2_impl pd)\"\n\nconsts'\n  invalidateLocalTLB_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB :: \"unit machine_monad\"\nwhere \"invalidateLocalTLB \\<equiv> machine_op_lift invalidateLocalTLB_impl\"\n\n\nconsts'\n  invalidateLocalTLB_ASID_impl :: \"hardware_asid \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB_ASID :: \"hardware_asid \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateLocalTLB_ASID a \\<equiv> machine_op_lift (invalidateLocalTLB_ASID_impl a)\"\n\n\n(* C implementation takes one argument, which is w || a *)\nconsts'\n  invalidateLocalTLB_VAASID_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateLocalTLB_VAASID :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateLocalTLB_VAASID w \\<equiv> machine_op_lift (invalidateLocalTLB_VAASID_impl w)\"\n\nconsts'\n  cleanByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanByVA w p \\<equiv> machine_op_lift (cleanByVA_impl w p)\"\n\nconsts'\n  cleanByVA_PoU_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanByVA_PoU :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanByVA_PoU w p \\<equiv> machine_op_lift (cleanByVA_PoU_impl w p)\"\n\nconsts'\n  invalidateByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateByVA w p \\<equiv> machine_op_lift (invalidateByVA_impl w p)\"\n\nconsts'\n  invalidateByVA_I_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateByVA_I :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateByVA_I w p \\<equiv> machine_op_lift (invalidateByVA_I_impl w p)\"\n\nconsts'\n  invalidate_I_PoU_impl :: \"unit machine_rest_monad\"\ndefinition\n  invalidate_I_PoU :: \"unit machine_monad\"\nwhere \"invalidate_I_PoU \\<equiv> machine_op_lift invalidate_I_PoU_impl\"\n\nconsts'\n  cleanInvalByVA_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanInvalByVA :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanInvalByVA w p \\<equiv> machine_op_lift (cleanInvalByVA_impl w p)\"\n\nconsts'\n  branchFlush_impl :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  branchFlush :: \"machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"branchFlush w p \\<equiv> machine_op_lift (branchFlush_impl w p)\"\n\nconsts'\n  clean_D_PoU_impl :: \"unit machine_rest_monad\"\ndefinition\n  clean_D_PoU :: \"unit machine_monad\"\nwhere \"clean_D_PoU \\<equiv> machine_op_lift clean_D_PoU_impl\"\n\nconsts'\n  cleanInvalidate_D_PoC_impl :: \"unit machine_rest_monad\"\ndefinition\n  cleanInvalidate_D_PoC :: \"unit machine_monad\"\nwhere \"cleanInvalidate_D_PoC \\<equiv> machine_op_lift cleanInvalidate_D_PoC_impl\"\n\nconsts'\n  cleanInvalidateL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanInvalidateL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanInvalidateL2Range w p \\<equiv> machine_op_lift (cleanInvalidateL2Range_impl w p)\"\n\nconsts'\n  invalidateL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  invalidateL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"invalidateL2Range w p \\<equiv> machine_op_lift (invalidateL2Range_impl w p)\"\n\nconsts'\n  cleanL2Range_impl :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  cleanL2Range :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere \"cleanL2Range w p \\<equiv> machine_op_lift (cleanL2Range_impl w p)\"\n\nconsts'\n  initL2Cache_impl :: \"unit machine_rest_monad\"\ndefinition\n  initL2Cache :: \"unit machine_monad\"\nwhere \"initL2Cache \\<equiv> machine_op_lift initL2Cache_impl\"\n\ndefinition\n  clearExMonitor :: \"unit machine_monad\"\nwhere \"clearExMonitor \\<equiv> modify (\\<lambda>s. s \\<lparr> exclusive_state := default_exclusive_state \\<rparr>)\"\n\nconsts'\n  flushBTAC_impl :: \"unit machine_rest_monad\"\ndefinition\n  flushBTAC :: \"unit machine_monad\"\nwhere \"flushBTAC \\<equiv> machine_op_lift flushBTAC_impl\"\n\nconsts'\n  initIRQController_impl :: \"unit machine_rest_monad\"\ndefinition\n  initIRQController :: \"unit machine_monad\"\nwhere \"initIRQController \\<equiv> machine_op_lift initIRQController_impl\"\n\ndefinition\n  IRQ :: \"irq \\<Rightarrow> irq\"\nwhere \"IRQ \\<equiv> id\"\n\nconsts'\n  writeContextID_impl :: \"unit machine_rest_monad\"\ndefinition\n  writeContextID :: \"unit machine_monad\"\nwhere \"writeContextID \\<equiv> machine_op_lift writeContextID_impl\"\n\nlemmas cache_machine_op_defs = isb_def dsb_def dmb_def writeContextID_def flushBTAC_def\n                               clearExMonitor_def cleanL2Range_def invalidateL2Range_def\n                               cleanInvalidateL2Range_def cleanInvalidate_D_PoC_def\n                               clean_D_PoU_def branchFlush_def cleanInvalByVA_def\n                               invalidate_I_PoU_def invalidateByVA_I_def invalidateByVA_def\n                               cleanByVA_PoU_def cleanByVA_def invalidateLocalTLB_VAASID_def\n                               invalidateLocalTLB_ASID_def invalidateLocalTLB_def\nconsts'\n  IFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  DFSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  FAR_val :: \"machine_state \\<Rightarrow> machine_word\"\n\ndefinition\n  getIFSR :: \"machine_word machine_monad\"\n  where \"getIFSR \\<equiv> gets IFSR_val\"\n\ndefinition\n  getDFSR :: \"machine_word machine_monad\"\n  where \"getDFSR \\<equiv> gets DFSR_val\"\n\ndefinition\n  getFAR :: \"machine_word machine_monad\"\n  where \"getFAR \\<equiv> gets FAR_val\"\n\ndefinition\n  debugPrint :: \"unit list \\<Rightarrow> unit machine_monad\"\nwhere\n  debugPrint_def[simp]:\n \"debugPrint \\<equiv> \\<lambda>message. return ()\"\n\nconsts'\n  ackInterrupt_impl :: \"irq \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  ackInterrupt :: \"irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"ackInterrupt irq \\<equiv> machine_op_lift (ackInterrupt_impl irq)\"\n\nconsts'\n  TPIDRURO_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  getTPIDRURO :: \"machine_word machine_monad\"\nwhere \"getTPIDRURO \\<equiv> gets TPIDRURO_val\"\n\nconsts'\n  setTPIDRURO_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setTPIDRURO :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setTPIDRURO w \\<equiv> machine_op_lift (setTPIDRURO_impl w)\"\n\n\\<comment> \\<open>Interrupt controller operations\\<close>\n\ntext \\<open>\n  Interrupts that cannot occur while the kernel is running (e.g. at preemption points),\n  but that can occur from user mode.\n\\<close>\ndefinition\n  \"non_kernel_IRQs = {irqVGICMaintenance, irqVTimerEvent}\"\n\ntext \\<open>\n  @{term getActiveIRQ} is now derministic.\n  It 'updates' the irq state to the reflect the passage of\n  time since last the irq was gotten, then it gets the active\n  IRQ (if there is one).\n\\<close>\ndefinition\n  getActiveIRQ :: \"bool \\<Rightarrow> (irq option) machine_monad\"\nwhere\n  \"getActiveIRQ in_kernel \\<equiv> do\n    is_masked \\<leftarrow> gets $ irq_masks;\n    modify (\\<lambda>s. s \\<lparr> irq_state := irq_state s + 1 \\<rparr>);\n    active_irq \\<leftarrow> gets $ irq_oracle \\<circ> irq_state;\n    if is_masked active_irq \\<or> (in_kernel \\<and> active_irq \\<in> non_kernel_IRQs)\n    then return None\n    else return (Some active_irq)\n  od\"\n\ndefinition\n  maskInterrupt :: \"bool \\<Rightarrow> irq \\<Rightarrow> unit machine_monad\"\nwhere\n  \"maskInterrupt m irq \\<equiv>\n  modify (\\<lambda>s. s \\<lparr> irq_masks := (irq_masks s) (irq := m) \\<rparr>)\"\n\ndefinition\n  lineStart :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"lineStart addr = (addr >> cacheLineBits) << cacheLineBits\"\n\ntext \\<open>\n  Performs the given operation on every cache line that intersects the\n  supplied range.\n\\<close>\ndefinition\n  cacheRangeOp :: \"(machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad)\n                 \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cacheRangeOp operation vstart vend pstart \\<equiv>\n    let pend = pstart + (vend - vstart);\n        vptrs = [lineStart vstart, lineStart vstart + of_nat cacheLine .e. lineStart vend];\n        pptrs = [lineStart pstart, lineStart pstart + of_nat cacheLine .e. lineStart pend]\n    in mapM_x (\\<lambda>(v, p). operation v p) (zip vptrs pptrs)\"\n\ndefinition\n  cleanCacheRange_PoC :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoC vstart vend pstart \\<equiv> cacheRangeOp cleanByVA vstart vend pstart\"\n\ndefinition\n  cleanInvalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanInvalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanInvalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp cleanInvalByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  cleanCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_RAM vstart vend pstart \\<equiv> do\n    cleanCacheRange_PoC vstart vend pstart;\n    dsb;\n    cleanL2Range pstart (pstart + (vend - vstart))\n  od\"\n\ndefinition\n  cleanCacheRange_PoU :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"cleanCacheRange_PoU vstart vend pstart \\<equiv> cacheRangeOp cleanByVA_PoU vstart vend pstart\"\n\ndefinition\n  invalidateCacheRange_RAM :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_RAM vstart vend pstart \\<equiv> do\n    when (vstart \\<noteq> lineStart vstart) $\n        cleanCacheRange_RAM vstart vstart pstart;\n    when (vend + 1 \\<noteq> lineStart (vend + 1)) $\n        cleanCacheRange_RAM (lineStart vend) (lineStart vend)\n           (pstart + ((lineStart vend) - vstart));\n    invalidateL2Range pstart (pstart + (vend - vstart));\n    cacheRangeOp invalidateByVA vstart vend pstart;\n    dsb\n  od\"\n\ndefinition\n  invalidateCacheRange_I :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"invalidateCacheRange_I vstart vend pstart \\<equiv> invalidate_I_PoU\"\n  (* for other than A53 and A35: \"cacheRangeOp invalidateByVA_I vstart vend pstart\" *)\n\ndefinition\n  branchFlushRange :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"branchFlushRange vstart vend pstart \\<equiv> cacheRangeOp branchFlush vstart vend pstart\"\n\ndefinition\n  cleanCaches_PoU :: \"unit machine_monad\"\nwhere\n  \"cleanCaches_PoU \\<equiv> do\n    dsb;\n    clean_D_PoU;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\"\n\ndefinition\n  cleanInvalidateL1Caches :: \"unit machine_monad\"\nwhere\n  \"cleanInvalidateL1Caches \\<equiv> do\n    dsb;\n    cleanInvalidate_D_PoC;\n    dsb;\n    invalidate_I_PoU;\n    dsb\n  od\""}
{"title": "./spec/machine/ARM_HYP/MachineOps.thy", "section": "Memory Clearance", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Clear memory contents to recycle it as user memory. Do not yet flush the cache.\\<close>\ndefinition\n  clearMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"clearMemory ptr bytelength \\<equiv>\n    mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size .e. ptr + (of_nat bytelength) - 1]\"\n\ndefinition\n  clearMemoryVM :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n  \"clearMemoryVM ptr bits \\<equiv> return ()\"\n\ntext \\<open>\n  Initialize memory to be used as user memory.\n  Note that zeroing out the memory is redundant in the specifications.\n  In any case, we cannot abstract from the call to cleanCacheRange,\n  which appears in the implementation.\n\\<close>\nabbreviation (input) \"initMemory == clearMemory\"\n\ntext \\<open>\n  Free memory that had been initialized as user memory.\n  While freeing memory is a no-(in) the implementation,\n  we zero out the underlying memory in the specifications to avoid garbage.\n  If we know that there is no garbage,\n  we can compute from the implementation state\n  what the exact memory content in the specifications is.\n\\<close>\ndefinition\n  freeMemory :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit machine_monad\"\n  where\n \"freeMemory ptr bits \\<equiv>\n  mapM_x (\\<lambda>p. storeWord p 0) [ptr, ptr + word_size  .e.  ptr + 2 ^ bits - 1]\""}
{"title": "./spec/machine/ARM_HYP/MachineOps.thy", "section": "User Monad", "subsection": "", "subsubsection": "", "code": "\nconsts'\n  writeContextIDAndPD_impl :: \"hardware_asid \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeContextIDAndPD :: \"hardware_asid \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere \"writeContextIDAndPD a b \\<equiv> machine_op_lift (writeContextIDAndPD_impl a b)\"\n\nconsts'\n  HSR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  HDFAR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  SCTLR_val :: \"machine_state \\<Rightarrow> machine_word\"\n  ACTLR_val :: \"machine_state \\<Rightarrow> machine_word\"\n\ndefinition\n  getHSR :: \"machine_word machine_monad\"\nwhere \"getHSR \\<equiv> gets HSR_val\"\n\ndefinition\n  getHDFAR :: \"machine_word machine_monad\"\nwhere \"getHDFAR \\<equiv> gets HDFAR_val\"\n\nconsts'\n  setHCR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setHCR :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setHCR w \\<equiv> machine_op_lift (setHCR_impl w)\"\n\nconsts'\n  addressTranslateS1_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\n  addressTranslateS1_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  addressTranslateS1 :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"addressTranslateS1 w \\<equiv> do\n    machine_op_lift (addressTranslateS1_impl w);\n    gets (addressTranslateS1_val w)\n  od\"\n\ndefinition\n  getSCTLR :: \"machine_word machine_monad\"\nwhere \"getSCTLR \\<equiv> gets SCTLR_val\"\n\nconsts'\n  setSCTLR_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  setSCTLR :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"setSCTLR w \\<equiv> machine_op_lift (setSCTLR_impl w)\"\n\ndefinition\n  vgic_irq_active :: \"machine_word\"\nwhere\n  \"vgic_irq_active \\<equiv> 2 << 28\"\n\ndefinition\n  vgic_irq_mask :: \"machine_word\"\nwhere\n  \"vgic_irq_mask \\<equiv> 3 << 28\"\n\nconsts'\n  gic_vcpu_ctrl_hcr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_hcr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_hcr \\<equiv> gets gic_vcpu_ctrl_hcr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_hcr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_hcr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_hcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_hcr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_vmcr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_vmcr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_vmcr \\<equiv> gets gic_vcpu_ctrl_vmcr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_vmcr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_vmcr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_vmcr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vmcr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_apr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_apr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_apr \\<equiv> gets gic_vcpu_ctrl_apr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_apr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_apr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_apr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_apr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_vtr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_vtr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_vtr \\<equiv> gets gic_vcpu_ctrl_vtr_val\"\n\nconsts'\n  set_gic_vcpu_ctrl_vtr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_vtr :: \"machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_vtr w \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_vtr_impl w)\"\n\nconsts'\n  gic_vcpu_ctrl_misr_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_misr :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_misr \\<equiv> gets gic_vcpu_ctrl_misr_val\"\n\nconsts'\n  gic_vcpu_ctrl_eisr0_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_eisr0 :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_eisr0 \\<equiv> gets gic_vcpu_ctrl_eisr0_val\"\n\nconsts'\n  gic_vcpu_ctrl_eisr1_val :: \"machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_eisr1 :: \"machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_eisr1 \\<equiv> gets gic_vcpu_ctrl_eisr1_val\"\n\nconsts'\n  get_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> unit machine_rest_monad\"\n  gic_vcpu_ctrl_lr_val :: \"machine_word \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  get_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"get_gic_vcpu_ctrl_lr n \\<equiv> do\n      machine_op_lift (get_gic_vcpu_ctrl_lr_impl n);\n      gets (gic_vcpu_ctrl_lr_val n)\n    od\"\n\nconsts'\n  set_gic_vcpu_ctrl_lr_impl :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_gic_vcpu_ctrl_lr :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_gic_vcpu_ctrl_lr n w  \\<equiv> machine_op_lift (set_gic_vcpu_ctrl_lr_impl n w)\""}
{"title": "./spec/machine/ARM_HYP/MachineOps.thy", "section": "User Monad", "subsection": "Hypervisor Banked Registers", "subsubsection": "", "code": "\nconsts'\n  cntv_cval_64_val :: \"machine_state \\<Rightarrow> 64 word\"\ndefinition\n  get_cntv_cval_64 :: \"64 word machine_monad\"\nwhere\n  \"get_cntv_cval_64 \\<equiv> gets cntv_cval_64_val\"\n\nconsts'\n  set_cntv_cval_64_impl :: \"64 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_cntv_cval_64 :: \"64 word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_cntv_cval_64 w \\<equiv> machine_op_lift (set_cntv_cval_64_impl w)\"\n\nconsts'\n  cntv_off_64_val :: \"machine_state \\<Rightarrow> 64 word\"\ndefinition\n  get_cntv_off_64 :: \"64 word machine_monad\"\nwhere\n  \"get_cntv_off_64 \\<equiv> gets cntv_off_64_val\"\n\nconsts'\n  set_cntv_off_64_impl :: \"64 word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  set_cntv_off_64 :: \"64 word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_cntv_off_64 w \\<equiv> machine_op_lift (set_cntv_off_64_impl w)\"\n\nconsts'\n  read_cntpct_val :: \"machine_state \\<Rightarrow> 64 word\"\ndefinition\n  read_cntpct :: \"64 word machine_monad\"\nwhere\n  \"read_cntpct \\<equiv> gets read_cntpct_val\""}
{"title": "./spec/machine/ARM_HYP/MachineOps.thy", "section": "User Monad", "subsection": "Hypervisor Banked Registers", "subsubsection": "", "code": "\nconsts'\n  vcpuHardwareReg_val :: \"vcpureg \\<Rightarrow> machine_state \\<Rightarrow> machine_word\"\ndefinition\n  readVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word machine_monad\"\nwhere\n  \"readVCPUHardwareReg reg \\<equiv> gets (vcpuHardwareReg_val reg)\"\n\nconsts'\n  writeVCPUHardwareReg_impl :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_rest_monad\"\ndefinition\n  writeVCPUHardwareReg :: \"vcpureg \\<Rightarrow> machine_word \\<Rightarrow> unit machine_monad\"\nwhere\n  \"writeVCPUHardwareReg reg val \\<equiv> machine_op_lift (writeVCPUHardwareReg_impl reg val)\""}
{"title": "./spec/machine/ARM_HYP/MachineOps.thy", "section": "User Monad", "subsection": "Hypervisor Banked Registers", "subsubsection": "", "code": "\ntype_synonym user_regs = \"register \\<Rightarrow> machine_word\"\n\ndatatype user_context = UserContext (user_regs : user_regs)\n\ntype_synonym 'a user_monad = \"(user_context, 'a) nondet_monad\"\n\ndefinition getRegister :: \"register \\<Rightarrow> machine_word user_monad\" where\n  \"getRegister r \\<equiv> gets (\\<lambda>s. user_regs s r)\"\n\ndefinition modify_registers :: \"(user_regs \\<Rightarrow> user_regs) \\<Rightarrow> user_context \\<Rightarrow> user_context\" where\n  \"modify_registers f uc \\<equiv> UserContext (f (user_regs uc))\"\n\ndefinition setRegister :: \"register \\<Rightarrow> machine_word \\<Rightarrow> unit user_monad\" where\n  \"setRegister r v \\<equiv> modify (\\<lambda>s. UserContext ((user_regs s) (r := v)))\"\n\ndefinition\n  \"getRestartPC \\<equiv> getRegister FaultIP\"\n\ndefinition\n  \"setNextPC \\<equiv> setRegister NextIP\"\n\nend\n\ntranslations\n  (type) \"'a ARM_HYP.user_monad\" <= (type) \"(ARM_HYP.register \\<Rightarrow> machine_word, 'a) nondet_monad\"\n\n\nend"}
{"title": "./spec/machine/ARM_HYP/Platform.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Platform Definitions\"\n\ntheory Platform\nimports\n  \"Lib.Defs\"\n  \"Lib.Lib\"\n  \"Word_Lib.WordSetup\"\n  Setup_Locale\n  Kernel_Config\nbegin\n\ntext \\<open>\n  This theory lists platform-specific types and basic constants, in particular\n  the types of interrupts and physical addresses, constants for the\n  kernel location, the offsets between physical and virtual kernel\n  addresses, as well as the range of IRQs on the platform.\n\\<close>"}
{"title": "./spec/machine/ARM_HYP/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\n(* representation of C int literals, the default for any unadorned numeral *)\ntype_synonym int_literal_len = \"32 signed\"\ntype_synonym int_word = \"int_literal_len word\""}
{"title": "./spec/machine/ARM_HYP/Platform.thy", "section": "Platform Constants", "subsection": "", "subsubsection": "", "code": "\ncontext Arch begin global_naming ARM_HYP\n\nvalue_type irq_len = Kernel_Config.irqBits (* IRQ_CNODE_SLOT_BITS *)\ntype_synonym irq = \"irq_len word\"\ntype_synonym paddr = word32\n\nabbreviation (input) \"toPAddr \\<equiv> id\"\nabbreviation (input) \"fromPAddr \\<equiv> id\"\n\ndefinition pageColourBits :: nat where\n  \"pageColourBits \\<equiv> 2\"\n\ndefinition cacheLineBits :: nat where\n  \"cacheLineBits = CONFIG_L1_CACHE_LINE_SIZE_BITS\"\n\ndefinition cacheLine :: nat where\n  \"cacheLine = 2^cacheLineBits\"\n\n(* The first virtual address of the kernel's physical memory window *)\ndefinition pptrBase :: word32 where\n  \"pptrBase \\<equiv> 0xe0000000\"\n\nabbreviation (input) \"paddrBase \\<equiv> physBase\"\n\ndefinition pptrBaseOffset :: machine_word where\n  \"pptrBaseOffset = pptrBase - paddrBase\"\n\ndefinition pptrTop :: \"32 word\" where\n  \"pptrTop \\<equiv> 0xfff00000\"\n\ndefinition paddrTop :: \"32 word\" where\n  \"paddrTop \\<equiv> pptrTop - pptrBaseOffset\"\n\ndefinition kernelELFPAddrBase :: word32 where\n  \"kernelELFPAddrBase \\<equiv> physBase\"\n\ndefinition kernelELFBase :: word32 where\n  \"kernelELFBase \\<equiv> pptrBase + (kernelELFPAddrBase && mask 22)\"\n\ndefinition kernelELFBaseOffset :: word32 where\n  \"kernelELFBaseOffset \\<equiv> kernelELFBase - kernelELFPAddrBase\"\n\ndefinition ptrFromPAddr :: \"paddr \\<Rightarrow> word32\" where\n  \"ptrFromPAddr paddr \\<equiv> paddr + pptrBaseOffset\"\n\ndefinition addrFromPPtr :: \"word32 \\<Rightarrow> paddr\" where\n  \"addrFromPPtr pptr \\<equiv> pptr - pptrBaseOffset\"\n\ndefinition addrFromKPPtr :: \"word32 \\<Rightarrow> paddr\" where\n  \"addrFromKPPtr kpptr \\<equiv> kpptr - kernelELFBaseOffset\"\n\ndefinition minIRQ :: \"irq\" where\n  \"minIRQ \\<equiv> 0\"\n\ndefinition irqVGICMaintenance :: \"irq\" where\n  \"irqVGICMaintenance \\<equiv> 25\"\n\ndefinition irqVTimerEvent :: \"irq\" where\n  \"irqVTimerEvent  \\<equiv> 27\"\n\nend\n\nend"}
{"title": "./spec/machine/ARM_HYP/Arch_Kernel_Config_Lemmas.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific lemmas constraining Kernel_Config definitions *)\n\ntheory Arch_Kernel_Config_Lemmas\nimports\n  Kernel_Config_Lemmas\n  Platform\nbegin\n\ncontext Arch begin global_naming ARM_HYP\n\n(* note: 25 = pageBitsForSize ARMSuperSection, we do not have access to ASpec at this point *)\nlemma physBase_aligned:\n  \"is_aligned physBase 25\"\n  by (simp add: is_aligned_def Kernel_Config.physBase_def)\n\n(* maxIRQ conditions *)\n\nlemma irqVTimerEvent_le_maxIRQ[simp, intro!]:\n  \"irqVTimerEvent \\<le> maxIRQ\"\n  by (simp add: irqVTimerEvent_def Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_less_2p_irqBits:\n  \"(maxIRQ::nat) < 2^irqBits\"\n  by (simp add: Kernel_Config.maxIRQ_def Kernel_Config.irqBits_def)\n\n(* follows from value_type definition of irq_len *)\nlemma LENGTH_irq_len_irqBits[simp]: (* [simp] will fire only for simp del: len_of_numeral_defs *)\n  \"LENGTH(irq_len) = irqBits\"\n  using irq_len_def irq_len_val\n  by simp\n\nlemma maxIRQ_less_2p_irq_len:\n  \"(maxIRQ::nat) < 2^LENGTH(irq_len)\"\n  using maxIRQ_less_2p_irqBits\n  by (simp del: len_of_numeral_defs)\n\nlemma unat_2p_irqBits_machine[simp]:\n  \"unat (2 ^ irqBits :: machine_word) = 2 ^ irqBits\"\n  by (simp add: Kernel_Config.irqBits_def)\n\n(* maxIRQ as a generic numeral allows us to write rules about casts/unat/uint etc without\n   mentioning numbers: *)\n\nlemma of_nat_maxIRQ[simp]:\n  \"of_nat maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma of_int_maxIRQ[simp]:\n  \"of_int maxIRQ = (maxIRQ::'a::len word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma unat_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> unat (maxIRQ::'a word) = maxIRQ\"\n  by (metis maxIRQ_less_2p_irq_len Word.of_nat_unat of_nat_inverse of_nat_maxIRQ unat_ucast_up_simp)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma uint_maxIRQ[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow> uint (maxIRQ::'a word) = maxIRQ\"\n  by (metis Kernel_Config.maxIRQ_def of_nat_numeral uint_nat unat_maxIRQ)\n\n(* Safe for [simp] because we don't use maxIRQ at lower than irq_len *)\nlemma ucast_maxIRQ[simp]:\n  \"\\<lbrakk> LENGTH(irq_len) \\<le> LENGTH('a::len); LENGTH(irq_len) \\<le> LENGTH('b::len) \\<rbrakk> \\<Longrightarrow>\n   UCAST ('a \\<rightarrow> 'b) maxIRQ = maxIRQ\"\n  by (metis of_nat_maxIRQ ucast_nat_def unat_maxIRQ)\n\n(* Safe for [simp] because we don't cast down from irq type *)\nlemma maxIRQ_less_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   (maxIRQ < (ucast irq :: 'a word)) = (maxIRQ < irq)\" for irq::irq\n  by (simp add: word_less_nat_alt unat_ucast_up_simp)\n\n(* Safe for [simp] because we don't cast down from irq type *)\nlemma maxIRQ_le_upcast[simp]:\n  \"LENGTH(irq_len) \\<le> LENGTH('a::len) \\<Longrightarrow>\n   ((ucast irq :: 'a word) \\<le> Kernel_Config.maxIRQ) = (irq \\<le> Kernel_Config.maxIRQ)\" for irq::irq\n  by (simp add: word_le_nat_alt unat_ucast_up_simp)\n\n(* The following are instances -- for some we could derive general rules, but the number of\n   instances is limited and the concrete proofs are much simpler: *)\n\nlemma le_maxIRQ_machine_less_irqBits_val[simplified]:\n  \"w \\<le> maxIRQ \\<Longrightarrow> unat w < 2^LENGTH(irq_len)\" for w::machine_word\n  using maxIRQ_less_2p_irq_len\n  by (simp add: word_le_nat_alt)\n\nlemma irq_machine_le_maxIRQ_irq:\n  \"irq \\<le> Kernel_Config.maxIRQ \\<Longrightarrow> (ucast irq::irq) \\<le> maxIRQ\" for irq::machine_word\n  by (simp add: Kernel_Config.maxIRQ_def word_le_nat_alt unat_ucast)\n\nlemma maxIRQ_eq_ucast_irq_32_signed_uint:\n  \"(maxIRQ = (ucast b :: 32 signed word)) = (uint b = maxIRQ)\" for b::irq\n  unfolding Kernel_Config.maxIRQ_def\n  apply uint_arith\n  apply (simp add: uint_up_ucast is_up)\n  done\n\nlemma sint_maxIRQ_32[simp]:\n  \"sint (maxIRQ :: 32 signed word) = maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_machine[simp]:\n  \"scast (maxIRQ::32 signed word) = (maxIRQ::machine_word)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma scast_maxIRQ_32_irq[simp]:\n  \"scast (maxIRQ :: 32 signed word) = (maxIRQ::irq)\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_machine:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = x\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_ucast_toEnum_eq_irq:\n  \"x \\<le> maxIRQ \\<Longrightarrow> toEnum (unat x) = (ucast x :: irq)\" for x::machine_word\n  by (simp add: word_le_nat_alt Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_1_plus_eq_Suc_machine[simp]:\n  \"unat (1 + maxIRQ :: machine_word) = Suc Kernel_Config.maxIRQ\"\n  by (simp add: Kernel_Config.maxIRQ_def)\n\nlemma maxIRQ_le_mask_irq_len:\n  \"x \\<le> maxIRQ \\<longrightarrow> x \\<le> mask irq_len\" for x :: machine_word\n  using le_maxIRQ_machine_less_irqBits_val\n  by (fastforce simp add: word_le_nat_alt word_less_nat_alt irq_len_val mask_def)\n\n\n(* cacheLineBits conditions *)\n\n(* Folding cacheLineBits_val in C functions only works reliably if cacheLineBits is not 1 and\n   not too large to conflict with other values used inside cache ops.\n   12 is ptBits, which is only available after ExecSpec. Anything > 1 and smaller than ptBits\n   works. *)\nlemma cacheLineBits_sanity:\n  \"cacheLineBits \\<in> {2..12}\"\n  by (simp add: cacheLineBits_def Kernel_Config.CONFIG_L1_CACHE_LINE_SIZE_BITS_def)\n\nend\nend"}
{"title": "./spec/take-grant/Example2.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Example2\nimports Isolation_S\nbegin\n\nlemma direct_caps_of_update [simp]:\n  \"direct_caps_of (s(x := y)) =\n  (direct_caps_of s)(x:= case y of None \\<Rightarrow> {} | Some (Entity c) \\<Rightarrow> c)\"\n  by (rule ext, simp add: direct_caps_of_def split:option.splits)\n\nlemma direct_caps_of_empty [simp]:\n  \"direct_caps_of Map.empty = ( \\<lambda> x. {})\"\n  by (simp add: direct_caps_of_def fun_eq_iff)\n\ndefinition \"id\\<^sub>0 \\<equiv> 0\"\ndefinition \"id\\<^sub>1 \\<equiv> 1\"\ndefinition \"id\\<^sub>2 \\<equiv> 2\"\ndefinition \"id\\<^sub>3 \\<equiv> 3\"\ndefinition \"id\\<^sub>4 \\<equiv> 4\"\ndefinition \"id\\<^sub>5 \\<equiv> 5\"\n\n(* e0 has create caps to all of memory, and full rights to itself. *)\ndefinition\n  e0_caps :: \"cap set\"\nwhere\n  \"e0_caps \\<equiv> range create_cap \\<union> {full_cap 0}\"\n\ndefinition\n  s0  :: \"state\"\nwhere\n  \"s0  \\<equiv> [0 \\<mapsto> Entity e0_caps]\"\n\ndefinition\n  s1  :: \"state\"\nwhere\n  \"s1  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> null_entity]\"\n\ndefinition\n  s2  :: \"state\" where\n  \"s2  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> Entity {create_cap 2}]\"\n\ndefinition\n  s3  :: \"state\" where\n  \"s3  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>}]\"\n\ndefinition\n  s4  :: \"state\" where\n  \"s4  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity]\"\n\ndefinition\n  s5  :: \"state\" where\n  \"s5  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1, write_cap 2}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity]\"\n\ndefinition\n  s6  :: \"state\" where\n  \"s6  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1, write_cap 2}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2, read_cap 2},\n          2 \\<mapsto> null_entity]\"\n\ndefinition\n  s7  :: \"state\" where \"s7  \\<equiv> s4\"\n\ndefinition\n  s8  :: \"state\" where\n  \"s8  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1, full_cap 3}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity,\n          3 \\<mapsto> null_entity]\"\n\ndefinition\n  s9  :: \"state\" where\n  \"s9  \\<equiv> [0 \\<mapsto> Entity (e0_caps \\<union> {full_cap 1}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity,\n          3 \\<mapsto> null_entity]\"\n\ndefinition\n  s10 :: \"state\" where \"s10 \\<equiv> s4\"\n\ndefinition\n  s   :: \"state\" where\n  \"s   \\<equiv> [0 \\<mapsto> Entity (e0_caps - {create_cap 1, create_cap 2}),\n          1 \\<mapsto> Entity {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2},\n          2 \\<mapsto> null_entity]\"\n\ndefinition\n  op0  :: \"sysOPs\" where\n  \"op0  \\<equiv> SysCreate  0 (full_cap 0) (create_cap 1)\"\ndefinition\n  op1  :: \"sysOPs\" where\n  \"op1  \\<equiv> SysGrant   0 (full_cap 1) (create_cap 2) UNIV\"\ndefinition\n  op2  :: \"sysOPs\" where\n  \"op2  \\<equiv> SysGrant   0 (full_cap 1) (full_cap   1) {Write, Store}\"\ndefinition\n  op3  :: \"sysOPs\" where\n  \"op3  \\<equiv> SysCreate  1 \\<lparr>target = 1, rights = {Write, Store}\\<rparr> (create_cap 2)\"\ndefinition\n  op4  :: \"sysOPs\" where\n  \"op4  \\<equiv> SysTake    0 (full_cap 1) (full_cap   2) {Write}\"\ndefinition\n  op5  :: \"sysOPs\" where\n  \"op5  \\<equiv> SysCopy    1 \\<lparr>target = 1, rights = {Write, Store}\\<rparr> (full_cap   2) {Read}\"\ndefinition\n  op6  :: \"sysOPs\" where\n  \"op6  \\<equiv> SysRevoke  0 (write_cap 2)\"\ndefinition\n  op7  :: \"sysOPs\" where\n  \"op7  \\<equiv> SysCreate  0 (full_cap 0) (create_cap 3)\"\ndefinition\n  op8  :: \"sysOPs\" where\n  \"op8  \\<equiv> SysRemove  0 (full_cap 0) (full_cap 3)\"\ndefinition\n  op9  :: \"sysOPs\" where\n  \"op9  \\<equiv> SysDestroy  0 (create_cap 3)\"\ndefinition\n  op10 :: \"sysOPs\" where\n  \"op10 \\<equiv> SysRemoveSet 0 (full_cap 0) {full_cap 1, create_cap 1, create_cap 2}\"\n\ndefinition ops :: \"sysOPs list\" where\n(* since the CDT isn't defined, op6 is skipped\n  \"ops \\<equiv> [op10, op9, op8, op7, op6, op5, op4, op3, op2, op1, op0]\"\n*)\n  \"ops \\<equiv> [op10, op9, op8, op7, op3, op2, op1, op0]\"\n\n\n(* is_entity lemmas *)\n\nlemma is_entity_s0_e0 [simp]:\n  \"is_entity s0 0\"\n  by (simp add: is_entity_def s0_def)\n\nlemma is_entity_s1_e0 [simp]:\n  \"is_entity s1 0\"\n  by (simp add: is_entity_def s1_def)\n\nlemma is_entity_s2_e0 [simp]:\n  \"is_entity s2 0\"\n  by (simp add: is_entity_def s2_def)\n\nlemma is_entity_s3_e0 [simp]:\n  \"is_entity s3 0\"\n  by (simp add: is_entity_def s3_def)\n\nlemma is_entity_s4_e0 [simp]:\n  \"is_entity s4 0\"\n  by (simp add: is_entity_def s4_def)\n\nlemma is_entity_s5_e0 [simp]:\n  \"is_entity s5 0\"\n  by (simp add: is_entity_def s5_def)\n\nlemma is_entity_s6_e0 [simp]:\n  \"is_entity s6 0\"\n  by (simp add: is_entity_def s6_def)\n\nlemma is_entity_s8_e0 [simp]:\n  \"is_entity s8 0\"\n  by (simp add: is_entity_def s8_def)\n\nlemma is_entity_s9_e0 [simp]:\n  \"is_entity s9 0\"\n  by (simp add: is_entity_def s9_def)\n\nlemma is_entity_s_e0 [simp]:\n  \"is_entity s 0\"\n  by (simp add: is_entity_def s_def)\n\n\nlemma is_entity_s0_e1 [simp]:\n  \"\\<not> is_entity s0 1\"\n  by (simp add: is_entity_def s0_def)\n\nlemma is_entity_s1_e1 [simp]:\n  \"is_entity s1 1\"\n  by (simp add: is_entity_def s1_def)\n\nlemma is_entity_s2_e1 [simp]:\n  \"is_entity s2 1\"\n  by (simp add: is_entity_def s2_def)\n\nlemma is_entity_s3_e1 [simp]:\n  \"is_entity s3 1\"\n  by (simp add: is_entity_def s3_def)\n\nlemma is_entity_s4_e1 [simp]:\n  \"is_entity s4 1\"\n  by (simp add: is_entity_def s4_def)\n\nlemma is_entity_s5_e1 [simp]:\n  \"is_entity s5 1\"\n  by (simp add: is_entity_def s5_def)\n\n\nlemma is_entity_s3_e2 [simp]:\n  \"\\<not> is_entity s3 2\"\n  by (simp add: is_entity_def s3_def)\n\nlemma is_entity_s4_e3 [simp]:\n  \"\\<not> is_entity s4 3\"\n  by (simp add: is_entity_def s4_def)\n\n\n\n(* direct_caps_of, caps_of and similar lemmas *)\n\nlemma direct_caps_of_s0_e0_caps [simp]:\n  \"direct_caps_of s0 0 = e0_caps\"\n  by (simp add: direct_caps_of_def s0_def e0_caps_def)\n\nlemma direct_caps_of_s1_e0_caps [simp]:\n  \"direct_caps_of s1 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s1_def e0_caps_def)\n\nlemma direct_caps_of_s2_e0_caps [simp]:\n  \"direct_caps_of s2 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s2_def e0_caps_def)\n\nlemma direct_caps_of_s4_e0_caps [simp]:\n  \"direct_caps_of s4 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s4_def e0_caps_def)\n\nlemma direct_caps_of_s5_e0_caps [simp]:\n  \"direct_caps_of s5 0 = e0_caps \\<union> {full_cap 1, write_cap 2}\"\n  by (simp add: direct_caps_of_def s5_def e0_caps_def)\n\nlemma direct_caps_of_s6_e0_caps [simp]:\n  \"direct_caps_of s6 0 = e0_caps \\<union> {full_cap 1, write_cap 2}\"\n  by (simp add: direct_caps_of_def s6_def e0_caps_def)\n\nlemma direct_caps_of_s8_e0_caps [simp]:\n  \"direct_caps_of s8 0 = e0_caps \\<union> {full_cap 1, full_cap 3}\"\n  by (simp add: direct_caps_of_def s8_def e0_caps_def)\n\nlemma direct_caps_of_s9_e0_caps [simp]:\n  \"direct_caps_of s9 0 = e0_caps \\<union> {full_cap 1}\"\n  by (simp add: direct_caps_of_def s9_def e0_caps_def)\n\n\nlemma direct_caps_of_s2_e1 [simp]:\n  \"direct_caps_of s2 1 = {create_cap 2}\"\n  by (simp add: direct_caps_of_def s2_def)\n\nlemma direct_caps_of_s3_e1 [simp]:\n  \"direct_caps_of s3 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>}\"\n  by (simp add: direct_caps_of_def s3_def)\n\nlemma direct_caps_of_s4_e1 [simp]:\n  \"direct_caps_of s4 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s4_def)\n\nlemma direct_caps_of_s6_e1 [simp]:\n  \"direct_caps_of s5 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s5_def)\n\nlemma direct_caps_of_s9_e1 [simp]:\n  \"direct_caps_of s9 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (simp add: direct_caps_of_def s9_def)\n\n\nlemma full_cap_e0_caps_in_caps_of_s0_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s0 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e1_in_caps_of_s1_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s1 0\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e1_in_caps_of_s2_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s2 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e0_caps_in_caps_of_s4_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e1_in_caps_of_s4_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e2_in_caps_of_s4_e1 [simp]:\n  \"full_cap 2 \\<in> caps_of s4 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e1_in_caps_of_s5_e0_caps [simp]:\n  \"full_cap 1 \\<in> caps_of s5 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma full_cap_e2_in_caps_of_s5_e0_caps [simp]:\n  \"full_cap 2 \\<in> caps_of s5 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma full_cap_e0_caps_in_caps_of_s8_e0_caps [simp]:\n  \"full_cap 0 \\<in> caps_of s8 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s0_e0_caps [simp]:\n  \"create_cap i \\<in> caps_of s0 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s1_e0_caps [simp]:\n  \"create_cap i \\<in> caps_of s1 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s2_e1 [simp]:\n  \"create_cap 2 \\<in> caps_of s2 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma create_cap_in_caps_of_s3_e1 [simp]:\n  \"create_cap 2 \\<in> caps_of s3 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma create_cap_in_caps_of_s4_e3 [simp]:\n  \"create_cap 3 \\<in> caps_of s4 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma create_cap_in_caps_of_s9_e3 [simp]:\n  \"create_cap 3 \\<in> caps_of s9 0\"\n  by (rule direct_cap_in_cap, simp add: e0_caps_def)\n\nlemma write_store_e1_in_caps_of_s3_e1 [simp]:\n  \"\\<lparr>target = 1, rights = {Write, Store}\\<rparr>  \\<in> caps_of s3 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma write_store_e1_in_caps_of_s5_e1 [simp]:\n  \"\\<lparr>target = 1, rights = {Write, Store}\\<rparr> \\<in> caps_of s5 1\"\n  by (rule direct_cap_in_cap, simp)\n\nlemma write_cap_e2_in_caps_of_s6_e0_caps [simp]:\n  \"write_cap 2 \\<in> caps_of s6 0\"\n  by (rule direct_cap_in_cap, simp)\n\n\n\n(*********************************)\n(*  State after the opeartions   *)\n(*********************************)\n\n(* \"op0 \\<equiv> SysCreate 0 (full_cap 0) (create_cap 1)\" *)\nlemma op0_legal:\n  \"legal op0 s0\"\n  by  (clarsimp simp: op0_def all_rights_def)\n\nlemma execute_op0_safe:\n  \"step op0 s0 \\<subseteq> ({s0, s1})\"\n  by (fastforce simp: op0_def step_def createOperation_def s0_def s1_def\n                 split: if_split_asm)\n\nlemma execute_op0_live:\n  \"step op0 s0 \\<supseteq> ({s0, s1})\"\n  apply clarsimp\n  apply (rule conjI)\n   apply (simp add: step_def)\n  apply (simp add: step_def op0_legal)\n  apply (rule disjI2)\n  apply (clarsimp simp: op0_def createOperation_def)\n  apply (rule ext)\n  apply (clarsimp simp: s0_def s1_def)\n  done\n\nlemma execute_op0:\n  \"step op0 s0 = ({s0, s1})\"\n  apply rule\n   apply (rule execute_op0_safe)\n  apply (rule execute_op0_live)\n  done\n\n\n(* \"op1 \\<equiv> SysGrant  0 (full_cap 1) (create_cap 2) UNIV\" *)\nlemma op1_legal:\n  \"legal op1 s1\"\n  by  (clarsimp simp: op1_def all_rights_def)\n\nlemma execute_op1_safe:\n  \"step op1 s1 \\<subseteq> ({s1, s2})\"\n  by (clarsimp simp: op1_def step_def grantOperation_def diminish_def\n                     s1_def s2_def create_cap_def null_entity_def\n              split: if_split_asm)\n\nlemma execute_op1_live:\n  \"step op1 s1 \\<supseteq> ({s1, s2})\"\n  apply clarsimp\n  apply (rule conjI)\n   apply (simp add: step_def)\n  apply (simp add: step_def op1_legal)\n  apply (rule disjI2)\n  apply (clarsimp simp: op1_def grantOperation_def)\n  apply (rule ext)\n  apply (clarsimp simp: s1_def s2_def null_entity_def)\n  done\n\nlemma execute_op1:\n  \"step op1 s1 = ({s1, s2})\"\n  apply rule\n   apply (rule execute_op1_safe)\n  apply (rule execute_op1_live)\n  done\n\n\n(* \"op2 \\<equiv> SysGrant  0 (full_cap 1) (full_cap   1) {Write, Store}\" *)\nlemma op2_legal:\n  \"legal op2 s2\"\n  by  (clarsimp simp: op2_def all_rights_def)\n\nlemma execute_op2_safe:\n  \"step op2 s2 \\<subseteq> ({s2, s3})\"\n  apply clarsimp\n  apply (rule ext)\n  apply (auto simp: op2_def step_def grantOperation_def diminish_def s2_def s3_def full_cap_def all_rights_def\n             split: if_split_asm)\n  done\n\nlemma execute_op2_live:\n  \"step op2 s2 \\<supseteq> ({s2, s3})\"\n  apply clarsimp\n  apply (simp add: step_def op2_legal)\n  apply (rule disjI2)\n  apply (simp add: op2_def)\n  apply (rule ext)\n  apply (fastforce simp: s2_def s3_def grantOperation_def diminish_def all_rights_def full_cap_def)\n  done\n\nlemma execute_op2:\n  \"step op2 s2 = ({s2, s3})\"\n  apply rule\n   apply (rule execute_op2_safe)\n  apply (rule execute_op2_live)\n  done\n\n\n(* \"op3 \\<equiv> SysCreate 1 (full_cap 1) (create_cap 2)\" *)\nlemma op3_legal:\n  \"legal op3 s3\"\n  by  (clarsimp simp: op3_def all_rights_def)\n\nlemma execute_op3_safe:\n  \"step op3 s3 \\<subseteq> ({s3, s4})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: op3_def step_def createOperation_def s3_def s4_def\n             split: if_split_asm)\n  done\n\nlemma execute_op3_live:\n  \"step op3 s3 \\<supseteq> ({s3, s4})\"\n  apply clarsimp\n  apply (simp add: step_def op3_legal)\n  apply (rule disjI2)\n  apply (clarsimp simp: op3_def createOperation_def)\n  apply (rule ext)\n  apply (fastforce simp: s3_def s4_def)\n  done\n\nlemma execute_op3:\n  \"step op3 s3 = ({s3, s4})\"\n  apply rule\n   apply (rule execute_op3_safe)\n  apply (rule execute_op3_live)\n  done\n\n(* op4 \\<equiv> SysTake    0 (full_cap 1) (full_cap   2) {Write} *)\nlemma op4_legal:\n  \"legal op4 s4\"\n  by  (clarsimp simp: op4_def all_rights_def)\n\nlemma execute_op4_safe:\n  \"step op4 s4 \\<subseteq> ({s4, s5})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s4_def s5_def op4_def step_def takeOperation_def\n                    diminish_def all_rights_def write_cap_def\n             split: if_split_asm)\n  done\n\nlemma execute_op4_live:\n  \"step op4 s4 \\<supseteq> ({s4, s5})\"\n  apply clarsimp\n  apply (simp add: op4_legal step_def)\n  apply (rule disjI2)\n  apply (simp add: op4_def)\n  apply (rule ext)\n  apply (fastforce simp: s4_def s5_def takeOperation_def diminish_def all_rights_def write_cap_def)\n  done\n\nlemma execute_op4:\n  \"step op4 s4 = ({s4, s5})\"\n  apply rule\n   apply (rule execute_op4_safe)\n  apply (rule execute_op4_live)\n  done\n\n\n(* op5  \\<equiv> SysCopy    1 (full_cap 1) (full_cap   2) {Read} *)\nlemma op5_legal:\n  \"legal op5 s5\"\n  by  (clarsimp simp: op5_def all_rights_def)\n\nlemma execute_op5_safe:\n  \"step op5 s5 \\<subseteq> ({s5, s6})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s5_def s6_def op5_def step_def copyOperation_def diminish_def all_rights_def read_cap_def\n             split: if_split_asm)\n  done\n\nlemma execute_op5_live:\n  \"step op5 s5 \\<supseteq> ({s5, s6})\"\n  apply clarsimp\n  apply (simp add: step_def op5_legal)\n  apply (rule disjI2)\n  apply (simp add: op5_def)\n  apply (rule ext)\n  apply (fastforce simp: s5_def s6_def copyOperation_def diminish_def all_rights_def read_cap_def)\n  done\n\nlemma execute_op5:\n  \"step op5 s5 = ({s5, s6})\"\n  apply rule\n   apply (rule execute_op5_safe)\n  apply (rule execute_op5_live)\n  done\n\n(* op6  \\<equiv> SysRevoke  0 (read_cap 2) *)\nlemma op6_legal:\n  \"legal op6 s6\"\n  by  (clarsimp simp: op6_def all_rights_def)\n\nlemma execute_op6_safe:\n  \"step op6 s6 \\<subseteq> ({s6, s7})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s6_def s7_def s4_def op7_def step_def revokeOperation_def\n          split: if_split_asm)\n  oops\n\nlemma execute_op6_live:\n  \"step op6 s6 \\<supseteq> ({s6, s7})\"\n  apply (insert op6_legal)\n  oops (*\n  apply (auto simp: step_def op6_legal op6_def s6_def s7_def s4_def revokeOperation_def fun_eq_iff)\n  done*)\n\n(* Since cdt is not defined, this proof can't be done *)\nlemma execute_op6_live:\n  \"s7 \\<in> step op6 s6\"\n  oops\n\nlemma execute_op6:\n  \"step op6 s6 = ({s6, s7})\"\n  oops\n\n\n(* op7  \\<equiv> SysCreate  0 (full_cap 0) (create_cap 3) *)\nlemma op7_legal:\n  \"legal op7 s7\"\n  by  (clarsimp simp: s7_def op7_def all_rights_def)\n\nlemma execute_op7_safe:\n  \"step op7 s7 \\<subseteq> ({s7, s8})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s7_def s8_def s4_def op7_def step_def createOperation_def\n             split: if_split_asm)\n  done\n\nlemma execute_op7_live:\n  \"step op7 s7 \\<supseteq> ({s7, s8})\"\n  apply clarsimp\n  apply (simp add: step_def op7_legal)\n  apply (rule disjI2)\n  apply (simp add: op7_def)\n  apply (rule ext)\n  apply (fastforce simp: s7_def s8_def s4_def createOperation_def)\n  done\n\nlemma execute_op7:\n  \"step op7 s7 = ({s7, s8})\"\n  apply rule\n   apply (rule execute_op7_safe)\n  apply (rule execute_op7_live)\n  done\n\n\n(* op8  \\<equiv> SysRemove  0 (full_cap 0) (full_cap 3) *)\nlemma op8_legal:\n  \"legal op8 s8\"\n  by  (clarsimp simp: op8_def)\n\nlemma execute_op8_safe:\n  \"step op8 s8 \\<subseteq> ({s8, s9})\"\n  apply clarsimp\n  apply (rule ext)\n  apply (insert op8_legal)\n  apply (fastforce simp: step_def op8_def s8_def s9_def removeOperation_def\n                        full_cap_def create_cap_def all_rights_def e0_caps_def)\n  done\n\nlemma execute_op8_live:\n  \"step op8 s8 \\<supseteq> ({s8, s9})\"\n  apply (simp add: step_def op8_legal op8_def)\n  apply (rule disjI2)\n  apply (rule ext)\n  apply (clarsimp simp: removeOperation_def)\n  apply (fastforce simp: s8_def s9_def full_cap_def create_cap_def all_rights_def e0_caps_def)\n  done\n\nlemma execute_op8:\n  \"step op8 s8 = ({s8, s9})\"\n  apply rule\n   apply (rule execute_op8_safe)\n  apply (rule execute_op8_live)\n  done\n\n(* op9  \\<equiv> SysDelete  0 (create_cap 3) *)\n\nlemma op9_legal:\n  \"legal op9 s9\"\n  apply (simp add: op9_def)\n  apply (fastforce simp: s9_def e0_caps_def null_entity_def split:if_split_asm)\n  done\n\nlemma execute_op9_safe:\n  \"step op9 s9 \\<subseteq> ({s9, s10})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s9_def s10_def s4_def op9_def step_def destroyOperation_def\n             split: if_split_asm)\n  done\n\nlemma execute_op9_live:\n  \"step op9 s9 \\<supseteq> ({s9, s10})\"\n  apply (simp add: step_def op9_legal)\n  apply (rule disjI2)\n  apply (simp add: op9_def)\n  apply (rule ext)\n  apply (clarsimp simp: destroyOperation_def step_def op9_def s9_def s10_def s4_def)\n  done\n\nlemma execute_op9:\n  \"step op9 s9 = ({s9, s10})\"\n  apply rule\n   apply (rule execute_op9_safe)\n  apply (rule execute_op9_live)\n  done\n\n(* op10 \\<equiv> SysRemoveSet 0 (full_cap 0) {full_cap 1, create_cap 1, create_cap 2} *)\nlemma op10_legal:\n  \"legal op10 s10\"\n  by  (clarsimp simp: s10_def op10_def all_rights_def)\n\nlemma e0_caps_diminished [simp]:\n  \"e0_caps - {full_cap 1, create_cap 1, create_cap 2} = e0_caps - {create_cap 1, create_cap 2}\"\n  by (fastforce simp: e0_caps_def create_cap_def full_cap_def all_rights_def)\n\n\nlemma execute_op10_safe:\n  \"step op10 s10 \\<subseteq> ({s10, s})\"\n  apply (clarsimp, rule ext)\n  apply (auto simp: s10_def op10_def step_def removeSetOperation_def s4_def s_def\n              split: if_split_asm)\n  done\n\nlemma execute_op10_live:\n  \"step op10 s10 \\<supseteq> ({s10, s})\"\n  apply clarsimp\n  apply (rule conjI)\n   apply (simp add: step_def)\n  apply (simp add: step_def op10_legal)\n  apply (rule disjI2)\n  apply (clarsimp simp: s10_def op10_def removeSetOperation_def)\n  apply (rule ext)\n  apply (fastforce simp: s4_def s_def)\n  done\n\nlemma execute_op10:\n  \"step op10 s10 = ({s10, s})\"\n  apply rule\n   apply (rule execute_op10_safe)\n  apply (rule execute_op10_live)\n  done\n\n\nlemma execute_ops:\n  \"s \\<in> execute ops s0\"\n  apply (clarsimp simp: ops_def)\n  apply (insert execute_op0_live execute_op1_live execute_op2_live execute_op3_live\n                execute_op4_live execute_op5_live                  execute_op7_live\n                execute_op8_live execute_op9_live execute_op10_live)\n  apply (simp add: s7_def)\n  apply fastforce\n  done\n\n\n\n(*********************************)\n(* Results about the final state *)\n(*********************************)\n\nlemma store_not_in_create_cap [simp]:\n  \"Store \\<notin> rights (create_cap i)\"\n  by (simp add: create_cap_def)\n\nlemma store_not_in_create_cap2 [simp]:\n  \"Store \\<in> rights c \\<Longrightarrow> c \\<noteq> create_cap i\"\n  by (clarsimp simp: create_cap_def)\n\n\n(*********************************)\n(*    store_connected_direct     *)\n(*********************************)\n\nlemma store_connected_direct_s_helper1:\n  \"{c'.(c' = \\<lparr>target = 0, rights = UNIV\\<rparr> \\<or> c' \\<in> range create_cap) \\<and>\n        c' \\<noteq> \\<lparr>target = 1, rights = {Create}\\<rparr> \\<and> c' \\<noteq> \\<lparr>target = 2, rights = {Create}\\<rparr> \\<and>\n        Store \\<in> rights c'} = {full_cap 0}\"\n by (auto simp: create_cap_def full_cap_def all_rights_def e0_caps_def)\n\nlemma store_connected_direct_s_helper2:\n  \"{c'. (c' = \\<lparr>target = 2, rights = {Create}\\<rparr> \\<or> c' = \\<lparr>target = 1, rights = {Write, Store}\\<rparr> \\<or>\n         c' = \\<lparr>target = 2, rights = UNIV\\<rparr>)    \\<and>  Store \\<in> rights c'}\n   = {\\<lparr>target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  by (auto simp: create_cap_def full_cap_def all_rights_def e0_caps_def)\n\n\nlemma store_connected_direct_s:\n  \"store_connected_direct s = {(0,0), (1,1), (1,2)}\"\n  by (fastforce simp: store_connected_direct_def s_def e0_caps_def\n                      full_cap_def all_rights_def create_cap_def null_entity_def\n                      store_connected_direct_s_helper1 store_connected_direct_s_helper2\n               split: if_split_asm)\n\n(*********************************)\n(*        store_connected        *)\n(*********************************)\n\nlemma into_rtrancl [rule_format]:\n  \"(a,b) \\<in> r^* \\<Longrightarrow> (\\<forall>x. (x,b) \\<in> r \\<longrightarrow> x = b) \\<longrightarrow> a = b\"\n  apply (erule converse_rtrancl_induct)\n   apply simp\n  apply clarsimp\n  done\n\nlemma into_rtrancl2 [rule_format]:\n  \" \\<And> B. \\<lbrakk>(a,b) \\<in> r^*; b \\<in> B\\<rbrakk> \\<Longrightarrow> (\\<forall>x.(x,b) \\<in> r \\<longrightarrow> x \\<in> B) \\<longrightarrow> a \\<in> B\"\n  thm rtrancl_induct converse_rtrancl_induct\n  apply (erule converse_rtrancl_induct)\n   apply clarsimp\n  apply clarsimp\n  oops\n\nlemma store_connected_id:\n \"{(0::word32, 0), (1, 1), (1, 2)}\\<^sup>* = {(1, 2)}\\<^sup>* \"\n  apply rule\n   apply clarsimp\n   apply (erule rtranclE)\n    apply simp\n   apply (fastforce dest: into_rtrancl)\n  apply clarsimp\n  apply (erule rtranclE)\n   apply simp\n  apply (fastforce dest: into_rtrancl)\n  done\n\nlemma store_connected_s: \"store_connected s = {(1,2)} \\<union> Id\"\n  apply simp\n  apply (rule equalityI)\n  apply (insert store_connected_direct_s)\n   apply (simp add: store_connected_def)\n   apply clarsimp\n   apply (erule converse_rtranclE)\n    apply simp\n   apply clarsimp\n   apply (erule rtranclE)\n    apply fastforce\n   apply (simp add: store_connected_id)\n   apply (drule rtranclD)\n   apply (safe, simp_all, (erule tranclE, simp, fastforce)+)\n  apply (fastforce simp: store_connected_def)\n  done\n\n(*********************************)\n(*            caps_of            *)\n(*********************************)\n\nlemma caps_of_s_e0_caps: \"caps_of s 0 = e0_caps - {create_cap 1, create_cap 2}\"\n  apply (clarsimp simp: caps_of_def store_connected_s Collect_disj_eq)\n  apply (simp add: s_def)\n  done\n\nlemma caps_of_s_e0_caps_2: \"caps_of s 0 = {full_cap 0} \\<union> ( range create_cap - {create_cap 1, create_cap 2})\"\n  by (fastforce simp: caps_of_s_e0_caps e0_caps_def full_cap_def create_cap_def)\n\n\nlemma caps_of_s_e1: \"caps_of s 1 = {create_cap 2, \\<lparr> target = 1, rights = {Write, Store}\\<rparr>, full_cap 2}\"\n  apply (clarsimp simp: caps_of_def store_connected_s Collect_disj_eq)\n  apply (simp add: s_def null_entity_def)\n  done\n\nlemma caps_of_s_e2: \"caps_of s 2 = {}\"\n  apply (simp add: caps_of_def store_connected_s)\n  apply (simp add: s_def null_entity_def)\n  done\n\nlemma caps_of_s_e3: \"\\<lbrakk>e \\<noteq> 0; e \\<noteq> 1\\<rbrakk> \\<Longrightarrow> caps_of s e = {}\"\n  apply (simp add: caps_of_def store_connected_s)\n  apply (simp add: s_def null_entity_def)\n  done\n\n\n(*********************************)\n(*            caps_of'             *)\n(*********************************)\n\nlemma extra_rights_create_cap:\n  \"extra_rights (create_cap i) = full_cap i\"\n  by (simp add: create_cap_def full_cap_def extra_rights_def)\n\n\nlemma extra_rights_full_cap:\n  \"extra_rights (full_cap i) = full_cap i\"\n  by (simp add: full_cap_def extra_rights_def)\n\nlemma extra_rights_take_cap:\n  \"extra_rights (take_cap i) = take_cap i\"\n  by (simp add: take_cap_def extra_rights_def)\n\nlemma extra_rights_grant_cap:\n  \"extra_rights (grant_cap i) = grant_cap i\"\n  by (simp add: take_cap_def extra_rights_def)\n\nlemma caps_of'_s_e0_caps_helper:\n  \"extra_rights ` (range create_cap - {create_cap 1, create_cap 2}) =\n  range full_cap - {full_cap 1, full_cap 2}\"\n  apply rule\n   apply (fastforce simp: create_cap_def extra_rights_def all_rights_def full_cap_def)\n  apply rule\n  apply (erule DiffE)\n  apply clarsimp\n  apply (rule image_eqI)\n   apply (rule extra_rights_create_cap [THEN sym])\n  apply (simp add: full_cap_def create_cap_def)\n  done\n\n\n\n(*********************************)\n(*          connected            *)\n(*********************************)\n\nlemma extra_rights_increases_rights:\n  \"rights c \\<subseteq> rights (extra_rights c)\"\n  by (simp add: extra_rights_def all_rights_def)\n\nlemma cap_in_caps_take_cap:\n  \"\\<lbrakk>create_cap x \\<in> caps_of s y\\<rbrakk> \\<Longrightarrow> take_cap x \\<in>cap caps_of s y\"\n  apply (auto simp: cap_in_caps_def caps_of_def extra_rights_take_cap)\n  apply (rule exI, rule conjI, assumption)\n  apply (rule rev_bexI, simp)\n  apply (rule conjI)\n   apply (subgoal_tac \"target (full_cap x) = x\", simp+)\n  apply (simp add: extra_rights_create_cap all_rights_def)\n  done\n\n\nlemma e0_connected_to:\n  \"\\<lbrakk>x \\<noteq> 1; x \\<noteq> 2\\<rbrakk> \\<Longrightarrow> s \\<turnstile> 0 \\<leftrightarrow> x\"\n  apply (rule directly_tgs_connected_comm)\n  apply (simp add: directly_tgs_connected_def4)\n  apply (rule disjI1)\n  apply (rule cap_in_caps_take_cap)\n  apply (simp add: caps_of_s_e0_caps e0_caps_def create_cap_def)\n  done\n\nlemma e1_connected_to_e2:\n  \"s \\<turnstile> 1 \\<leftrightarrow> 2\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (rule disjI2)+\n  apply (simp add: shares_caps_def)\n  apply (simp add: store_connected_s)\n  done\n\nlemma e0_caps_not_connected_to_e1:\n  \"\\<not> (s \\<turnstile> 0 \\<leftrightarrow> 1)\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (rule conjI)\n   apply (simp add: cap_in_caps_def caps_of_s_e1)\n  apply (rule conjI)\n   apply (clarsimp simp add: cap_in_caps_def caps_of_s_e0_caps e0_caps_def)\n   apply (erule disjE)\n    apply (simp add: full_cap_def)\n   apply clarsimp\n  apply (rule conjI)\n     apply (clarsimp simp add: cap_in_caps_def caps_of_s_e0_caps e0_caps_def)\n   apply (erule disjE)\n    apply (simp add: full_cap_def)\n   apply clarsimp\n  apply (rule conjI)\n   apply (simp add: cap_in_caps_def caps_of_s_e1)\n  apply (simp add: shares_caps_def)\n  apply (simp add: store_connected_s)\n  done\n\nlemma e0_caps_not_connected_to_e2:\n  \"\\<not> (s \\<turnstile> 0 \\<leftrightarrow> 2)\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (rule conjI)\n   apply (simp add: cap_in_caps_def caps_of_s_e2)\n  apply (rule conjI)\n   apply (clarsimp simp add: cap_in_caps_def caps_of_s_e0_caps e0_caps_def)\n   apply (erule disjE)\n    apply (simp add: full_cap_def)\n   apply clarsimp\n  apply (rule conjI)\n     apply (clarsimp simp add: cap_in_caps_def caps_of_s_e0_caps e0_caps_def)\n   apply (erule disjE)\n    apply (simp add: full_cap_def)\n   apply clarsimp\n  apply (rule conjI)\n   apply (simp add: cap_in_caps_def caps_of_s_e2)\n  apply (simp add: shares_caps_def)\n  apply (simp add: store_connected_s)\n  done\n\n\n\n\n(*********************************)\n(*       connected_trans         *)\n(*********************************)\n\n\nlemma e1_connected_trans_to_e2:\n  \"s \\<turnstile> 1 \\<leftrightarrow>* 2\"\n  apply (insert e1_connected_to_e2)\n  apply (simp add: tgs_connected_def)\n  done\n\n\nlemma caps_of_to_e1:\n  \"\\<lbrakk>c \\<in> caps_of s x; target c = 1\\<rbrakk> \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (case_tac \"x = 0\")\n   apply (fastforce simp: caps_of_s_e0_caps_2)\n  apply (case_tac \"x = 1\")\n   apply (fastforce simp: caps_of_s_e1)\n  apply (fastforce simp: caps_of_s_e3)\n  done\n\nlemma caps_of_to_e2:\n  \"\\<lbrakk>c \\<in> caps_of s x; target c = 2\\<rbrakk> \\<Longrightarrow> x = 1\"\n  apply (case_tac \"x = 0\")\n   apply (fastforce simp: caps_of_s_e0_caps_2)\n  apply (case_tac \"x = 1\")\n   apply (fastforce simp: caps_of_s_e1)\n  apply (fastforce simp: caps_of_s_e3)\n  done\n\nlemma cap_in_caps_caps_of_e1:\n  \"c \\<in>cap caps_of s 1 \\<Longrightarrow> target c = 1 \\<or> target c = 2\"\n  by (clarsimp simp: cap_in_caps_def caps_of_s_e1)\n\nlemma cap_in_caps_caps_of_e2:\n  \"c \\<in>cap caps_of s 2 \\<Longrightarrow> False\"\n  by (clarsimp simp: cap_in_caps_def caps_of_s_e2)\n\nlemma cap_in_caps_caps_of_to_e1:\n  \"\\<lbrakk>c \\<in>cap caps_of s x; target c = 1\\<rbrakk> \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (drule (1) caps_of_to_e1, simp)\n  done\n\nlemma cap_in_caps_caps_of_to_e2:\n  \"\\<lbrakk>c \\<in>cap caps_of s x; target c = 2\\<rbrakk> \\<Longrightarrow> x = 1\"\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (erule (1) caps_of_to_e2)\n  done\n\nlemma e1_connected_to:\n  \"s \\<turnstile> 1 \\<leftrightarrow> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (erule disjE)\n   apply (erule cap_in_caps_caps_of_to_e1, simp)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, simp)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, simp)\n  apply (erule disjE)\n   apply (erule cap_in_caps_caps_of_to_e1, simp)\n  apply (fastforce simp: shares_caps_def store_connected_s)\n  done\n\n\nlemma e2_connected_to:\n  \"s \\<turnstile> 2 \\<leftrightarrow> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (simp add: directly_tgs_connected_def4)\n  apply (erule disjE, rule disjI1)\n   apply (erule cap_in_caps_caps_of_to_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (drule cap_in_caps_caps_of_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (drule cap_in_caps_caps_of_e2, simp)\n  apply (erule disjE, rule disjI1)\n   apply (erule cap_in_caps_caps_of_to_e2, simp)\n  apply (clarsimp simp: shares_caps_def store_connected_s)\n  done\n\n\nlemma directly_tgs_connected_in_inv_image:\n  \"(directly_tgs_connected s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  by (fastforce simp: inv_image_def\n              dest!: e1_connected_to e1_connected_to [OF directly_tgs_connected_comm]\n                     e2_connected_to e2_connected_to [OF directly_tgs_connected_comm])\n\nlemma connected_inv_image_trans:\n  \"trans (inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\"\n  by (rule trans_inv_image [OF trans_Id])\n\nlemma eq_inv_image_connected:\n  \"(inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\\<^sup>= = inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  by (fastforce simp: inv_image_def)\n\nlemma rtrancl_inv_image_connected:\n  \"(inv_image Id (\\<lambda> x. x=1 \\<or> x=2))\\<^sup>* = inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  apply (subst trancl_reflcl [symmetric])\n  apply (subst eq_inv_image_connected)\n  apply (rule trancl_id)\n  apply (rule connected_inv_image_trans)\n  done\n\nlemma tgs_connected_in_inv_image:\n  \"(tgs_connected s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  apply (simp add: tgs_connected_def)\n  apply (subst rtrancl_inv_image_connected [symmetric])\n  apply (rule rtrancl_mono)\n  apply (rule directly_tgs_connected_in_inv_image)\n  done\n\nlemma e0_not_connected_trans_e1:\n  \"\\<not> s \\<turnstile> 0 \\<leftrightarrow>* 1\"\n  apply clarsimp\n  apply (drule set_mp [OF tgs_connected_in_inv_image])\n  apply (simp add: inv_image_def)\n  done\n\nlemma e0_not_ever_connected_trans_e1:\n  \"s' \\<in> execute cmds s \\<Longrightarrow> \\<not> s' \\<turnstile> 0 \\<leftrightarrow>* 1\"\n  apply clarsimp\n  apply (drule (1) tgs_connected_preserved)\n  apply (simp add: e0_not_connected_trans_e1)\n  done\n\n\nlemma e0_e1_leakage:\n  \"s' \\<in> execute cmds s \\<Longrightarrow> \\<not> leak s' 0 1\"\n  apply (insert e0_not_connected_trans_e1)\n  apply (drule (2) leakage_rule)\n  done\n\n\n\n\n\n(*********************************)\n(*         islandtems            *)\n(*********************************)\nlemma island_e0:\n  \"island s 0 = {i. i \\<noteq> 1 \\<and> i \\<noteq> 2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (drule (1) e0_connected_to)\n  apply (drule directly_tgs_connected_comm)\n  by (metis directly_tgs_connected_def2 tgs_connected_comm leakImplyConnectedTrans)\n\nlemma island_e1:\n  \"island s 1 = {1,2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (rule e1_connected_trans_to_e2)\n  done\n\nlemma island_e2:\n  \"island s 2 = {1,2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (rule e1_connected_trans_to_e2  [THEN tgs_connected_comm])\n  done\n\nlemma island_e3:\n  \"\\<lbrakk>x \\<noteq> 1; x \\<noteq> 2\\<rbrakk> \\<Longrightarrow> island s x =  {i. i \\<noteq> 1 \\<and> i \\<noteq> 2}\"\n  apply rule\n   apply (clarsimp simp: island_def)\n   apply (insert tgs_connected_in_inv_image)[1]\n   apply fastforce\n  apply (clarsimp simp: island_def)\n  apply (frule_tac x=x  in e0_connected_to, simp)\n  apply (frule_tac x=xa in e0_connected_to, simp)\n  apply (drule_tac x=0 and y=xa in directly_tgs_connected_comm)\n  apply (rule tgs_connected_comm)\n  apply (simp add: tgs_connected_def)\n  done\n\n\n(*********************************)\n(*          isolation            *)\n(*********************************)\n\nlemma e1_flow_to:\n  \"s \\<turnstile> 1 \\<leadsto> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (rule ccontr)\n  apply (clarsimp simp: flow_def set_flow_def island_e1 island_e3)\n  apply (erule disjE, clarsimp)\n   apply (erule disjE)\n    apply (drule cap_in_caps_caps_of_to_e1, clarsimp+)\n   apply (drule cap_in_caps_caps_of_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_to_e2, clarsimp+)\n  apply (drule cap_in_caps_caps_of_e2, clarsimp+)\n  done\n\nlemma e2_flow_to:\n  \"s \\<turnstile> 2 \\<leadsto> x \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (rule ccontr)\n  apply (clarsimp simp: flow_def set_flow_def island_e2 island_e3)\n  apply (erule disjE, clarsimp)\n   apply (erule disjE)\n    apply (drule cap_in_caps_caps_of_to_e1, clarsimp+)\n   apply (drule cap_in_caps_caps_of_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_to_e2, clarsimp+)\n  apply (drule cap_in_caps_caps_of_e2, clarsimp+)\n  done\n\nlemma flow_to_e1:\n  \"s \\<turnstile> x \\<leadsto> 1 \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (rule ccontr)\n  apply (clarsimp simp: flow_def set_flow_def island_e1 island_e3)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_to_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e2, clarsimp+)\n  apply (drule cap_in_caps_caps_of_to_e2, clarsimp+)\n  done\n\nlemma flow_to_e2:\n  \"s \\<turnstile> x \\<leadsto> 2 \\<Longrightarrow> x = 1 \\<or> x = 2\"\n  apply (rule ccontr)\n  apply (clarsimp simp: flow_def set_flow_def island_e2 island_e3)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_to_e1, clarsimp+)\n  apply (erule disjE)\n   apply (drule cap_in_caps_caps_of_e2, clarsimp+)\n  apply (drule cap_in_caps_caps_of_to_e2, clarsimp+)\n  done\n\n\nlemma flow_in_inv_image:\n  \"(flow s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  by (fastforce simp: inv_image_def\n              dest!: e1_flow_to flow_to_e1\n                     e2_flow_to flow_to_e2)\n\n\nlemma flow_trans_in_inv_image:\n  \"(flow_trans s) \\<subseteq> inv_image Id (\\<lambda> x. x=1 \\<or> x=2)\"\n  apply (simp add: flow_trans_def)\n  apply (subst rtrancl_inv_image_connected [symmetric])\n  apply (rule rtrancl_mono)\n  apply (rule flow_in_inv_image)\n  done\n\nlemma e0_not_flow_trans_e1:\n  \"\\<not> s \\<turnstile> 0 \\<leadsto>* 1\"\n  apply clarsimp\n  apply (drule set_mp [OF flow_trans_in_inv_image])\n  apply (simp add: inv_image_def)\n  done\n\nlemma e1_not_flow_trans_e0:\n  \"\\<not> s \\<turnstile> 1 \\<leadsto>* 0\"\n  apply clarsimp\n  apply (drule set_mp [OF flow_trans_in_inv_image])\n  apply (simp add: inv_image_def)\n  done\n\nlemma e0_e1_isolated:\n  \"s' \\<in> execute cmds s \\<Longrightarrow> \\<not> s' \\<turnstile> 0 \\<leadsto>* 1 \\<and> \\<not> s' \\<turnstile> 1 \\<leadsto>* 0\"\n  apply (rule conjI)\n   apply (erule information_flow)\n   apply (rule e0_not_flow_trans_e1)\n  apply (erule information_flow)\n  apply (rule e1_not_flow_trans_e0)\n  done\n\nend"}
{"title": "./spec/take-grant/Confine_S.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Title:   Confinement_S\n * Description: confinement proof of the security model\n *)\n\ntheory Confine_S\nimports System_S\nbegin\n\n(* These translate Create into all_rights *)\ndefinition\n  extra_rights :: \"cap \\<Rightarrow> cap\" where\n  \"extra_rights c \\<equiv>\n  if (Create \\<in> rights c)\n  then c\\<lparr>rights := all_rights\\<rparr>\n  else c\"\n\n\nlemma extra_rights_idem [simp]:\n  \"(extra_rights (extra_rights c)) = (extra_rights c)\"\n  apply (clarsimp simp add: extra_rights_def)\n  done\n\nlemma extra_rights_image_idem [simp]:\n  \"(extra_rights ` (extra_rights ` S)) = (extra_rights ` S)\"\n  by (rule set_eqI) (simp add: image_iff)\n\nlemma extra_rights_empty_rights_ident [simp]:\n   \"extra_rights \\<lparr> target = e, rights = {} \\<rparr> = \\<lparr> target = e, rights = {} \\<rparr>\"\n  by (simp add: extra_rights_def)\n\nlemma entity_extra_rights [simp]:\n  \"target (extra_rights c) = target c\"\n  by (simp add: extra_rights_def)\n\nlemma rights_extra_rights:\n  \"rights (extra_rights c) =\n   (if Create \\<in> (rights c)\n    then all_rights\n    else rights c)\"\n  by (simp add: extra_rights_def)\n\n(* The following two definitions both translate Create into all_rights *)\n\n(* A cap is in a set, or a cap with more access is. *)\ndefinition\n  cap_in_caps :: \"cap \\<Rightarrow> cap set \\<Rightarrow> bool\" (infix \"\\<in>cap\" 50) where\n  \"c \\<in>cap C \\<equiv> \\<exists>c' \\<in> C. target c = target c' \\<and> rights (extra_rights c) \\<subseteq> rights (extra_rights c')\"\n\nabbreviation not_cap_in_caps where\n  \"not_cap_in_caps x A \\<equiv> ~ (x \\<in>cap A)\" \\<comment> \\<open>non-membership\\<close>\n\nnotation (input) cap_in_caps (infix \":cap\" 50)\nnotation (latex output)  cap_in_caps (infix \"\\<in>\\<^sub>c\\<^sub>a\\<^sub>p\" 50)\n\nnotation\n  not_cap_in_caps  (\"(\\<notin>cap)\") and\n  not_cap_in_caps  (\"(_/ \\<notin>cap _)\" [51, 51] 50)\n\nnotation (latex output)\n  not_cap_in_caps  (\"(\\<notin>\\<^sub>c\\<^sub>a\\<^sub>p)\") and\n  not_cap_in_caps  (infix \"\\<notin>\\<^sub>c\\<^sub>a\\<^sub>p\" 50)\n\n(* A set of caps \"caps\" have less (or equal) access to an entity as \"cap\" does. *)\ndefinition\n  caps_dominated_by :: \"cap set \\<Rightarrow> cap \\<Rightarrow> bool\" (infix \"\\<le>cap\" 50) where\n  \"caps \\<le>cap cap \\<equiv> \\<forall>cap' \\<in> caps. target cap' = target cap \\<longrightarrow> rights (extra_rights cap') \\<subseteq> rights (extra_rights cap)\"\n\nnotation (input) caps_dominated_by (infix \"<=cap\" 50)\nnotation (latex output) caps_dominated_by (infix \"\\<unlhd>\\<^sub>c\\<^sub>a\\<^sub>p\" 50)\n\ndefinition\n  shares_caps :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" where\n  \"shares_caps s e\\<^sub>x e\\<^sub>y \\<equiv> \\<exists>e\\<^sub>i . (e\\<^sub>x, e\\<^sub>i) \\<in> store_connected s \\<and> (e\\<^sub>y, e\\<^sub>i) \\<in> store_connected s\"\n\ndefinition\n  leak :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<rightarrow> _\") where\n  \"leak s e\\<^sub>x e\\<^sub>y \\<equiv> take_cap e\\<^sub>x \\<in>cap caps_of s e\\<^sub>y \\<or> grant_cap e\\<^sub>y \\<in>cap caps_of s e\\<^sub>x \\<or> shares_caps s e\\<^sub>x e\\<^sub>y\"\n\n\ndefinition\n  directly_tgs_connected :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"directly_tgs_connected s \\<equiv> {(e\\<^sub>x, e\\<^sub>y). leak s e\\<^sub>x e\\<^sub>y \\<or> leak s e\\<^sub>y e\\<^sub>x}\"\n\nlemma directly_tgs_connected_def2:\n  \"(e\\<^sub>x, e\\<^sub>y) \\<in> directly_tgs_connected s = (leak s e\\<^sub>x e\\<^sub>y \\<or> leak s e\\<^sub>y e\\<^sub>x)\"\n  by (simp add: directly_tgs_connected_def)\n\nabbreviation\n  in_directly_tgs_connected :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<leftrightarrow> _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x \\<leftrightarrow> y \\<equiv> (x,y) \\<in> directly_tgs_connected s\"\n\ndefinition\n  tgs_connected :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"tgs_connected s \\<equiv> (directly_tgs_connected s)\\<^sup>*\"\n\nabbreviation\n  in_tgs_connected :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<leftrightarrow>* _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x \\<leftrightarrow>* y == (x,y) \\<in> tgs_connected s\"\n\nnotation (latex output)\n  in_tgs_connected (\"_ \\<turnstile> _ \\<leftrightarrow>\\<^sup>* _\" [60,0,60] 61)\n\ntranslations\n  \"\\<not> (s \\<turnstile> x \\<leftrightarrow> y)\" <= \"(x,y) \\<notin> CONST directly_tgs_connected s\"\n  \"\\<not> (s \\<turnstile> x \\<leftrightarrow>* y)\" <= \"(x,y) \\<notin> CONST tgs_connected s\"\n\nlemma shares_caps_sym [simp]:\n \"shares_caps s y x = shares_caps s x y\"\n  by (auto simp: shares_caps_def)\n\nlemma directly_tgs_connected_def4:\n  \"s \\<turnstile> e\\<^sub>x \\<leftrightarrow> e\\<^sub>y = (take_cap e\\<^sub>x \\<in>cap caps_of s e\\<^sub>y \\<or> take_cap e\\<^sub>y \\<in>cap caps_of s e\\<^sub>x \\<or>\n                  grant_cap e\\<^sub>y \\<in>cap caps_of s e\\<^sub>x \\<or> grant_cap e\\<^sub>x \\<in>cap caps_of s e\\<^sub>y \\<or>\n                  shares_caps s e\\<^sub>x e\\<^sub>y)\"\n  by (auto simp: directly_tgs_connected_def leak_def)\n\n(* Note: e\\<^sub>0 is unused. *)\ndefinition\n  generalOperation ::\n  \"entity_id \\<Rightarrow> entity_id \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"generalOperation e\\<^sub>0 e\\<^sub>1 c r s \\<equiv>\n  s (e\\<^sub>1 \\<mapsto> Entity ( insert (diminish r (extra_rights c)) (direct_caps_of s e\\<^sub>1) ))\"\n\nlemma is_entity_general [simp]:\n  \"is_entity s e\\<^sub>1 \\<Longrightarrow> is_entity (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) e' = is_entity s e'\"\n  by (simp add: is_entity_def generalOperation_def)\n\ndefinition\n  make_entity :: \"entity_id \\<Rightarrow> modify_state\" where\n  \"make_entity n s \\<equiv>\n  s (n \\<mapsto> null_entity)\"\n\nlemma direct_caps_of_store_connected_eq:\n  \"\\<forall> e. direct_caps_of s e = direct_caps_of s' e\n  \\<Longrightarrow> store_connected s = store_connected s'\"\n  by (simp add: store_connected_def store_connected_direct_def\n                direct_caps_of_def)\n\nlemma direct_caps_of_caps_of_eq:\n  \"\\<forall> e. direct_caps_of s e = direct_caps_of s' e \\<Longrightarrow> caps_of s e = caps_of s' e\"\n  by (simp add: caps_of_def store_connected_def store_connected_direct_def\n                direct_caps_of_def)\n\nlemma direct_caps_of_caps_of_eq2:\n  \"\\<lbrakk>\\<forall> e. direct_caps_of s e = direct_caps_of s' e; c \\<in>cap caps_of s e\\<rbrakk> \\<Longrightarrow> c \\<in>cap caps_of s' e\"\n  apply (drule direct_caps_of_caps_of_eq)\n  apply (simp add: cap_in_caps_def)\n  by auto\n\nlemma direct_caps_of_directly_tgs_connected_eq:\n  \"\\<forall> e. direct_caps_of s e = direct_caps_of s' e \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y = s' \\<turnstile> x \\<leftrightarrow> y\"\n  apply (simp add: directly_tgs_connected_def4 shares_caps_def)\n  apply rule\n   apply (erule disjE, drule (1) direct_caps_of_caps_of_eq2, clarsimp)+\n   apply (drule direct_caps_of_store_connected_eq, clarsimp)\n  apply (erule disjE, drule direct_caps_of_caps_of_eq2 [rotated, where s=s' and s'=s], simp+)+\n  apply (drule direct_caps_of_store_connected_eq, simp)\n  done\n\nlemma direct_caps_of_make_entity:\n  \"\\<not> is_entity s n \\<Longrightarrow> direct_caps_of (make_entity n s) e = direct_caps_of s e\"\n  by (simp add: direct_caps_of_def make_entity_def is_entity_def\n                null_entity_def)\n\nlemma caps_of_make_entity:\n  \"\\<not> is_entity s n \\<Longrightarrow> caps_of (make_entity n s) e = caps_of s e\"\n  apply (rule direct_caps_of_caps_of_eq)\n  apply clarsimp\n  apply (erule direct_caps_of_make_entity)\n  done\n\nlemma caps_of_make_entity2:\n  \"\\<lbrakk>\\<not> is_entity s n; c \\<in> caps_of (make_entity n s) e\\<rbrakk> \\<Longrightarrow> c \\<in> caps_of s e\"\n  apply (drule caps_of_make_entity)\n  apply fastforce\n  done\n\nlemma directly_tgs_connected_make_entity:\n \"\\<not> is_entity s n \\<Longrightarrow> make_entity n s \\<turnstile> x \\<leftrightarrow> y = s \\<turnstile> x \\<leftrightarrow> y\"\n  apply (rule direct_caps_of_directly_tgs_connected_eq)\n  apply clarsimp\n  apply (drule (1) direct_caps_of_make_entity)\n  done\n\nlemma directly_tgs_connected_make_entity2:\n \"\\<lbrakk>\\<not> is_entity s n; make_entity n s \\<turnstile> x \\<leftrightarrow> y\\<rbrakk> \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y\"\n  apply (drule directly_tgs_connected_make_entity)\n  apply fastforce\n  done\n\nlemma diminish_extra_rights [simp]:\n  \"diminish (rights c) (extra_rights c) = c\"\n  by (simp add: diminish_def all_rights_def rights_extra_rights)\n\nlemma diminish_extra_rights2 [simp]:\n  \"diminish (r \\<inter> rights c) (extra_rights c) = diminish r c\"\n  apply (simp add: diminish_def extra_rights_def all_rights_def)\n  apply (simp add: Int_commute)\n  apply (subgoal_tac \"rights c \\<inter> (r \\<inter> rights c) = r \\<inter> rights c\")\n   apply simp\n  apply fastforce\n  done\n\nlemma create_general_helper:\n  \"Create \\<in> rights c\\<^sub>2 \\<Longrightarrow>\n   \\<lparr>target = target c\\<^sub>2, rights = UNIV\\<rparr> = c\\<^sub>2\\<lparr>rights := UNIV\\<rparr>\"\n  by auto\n\nlemma extra_rights_full_cap [simp]:\n  \"extra_rights (full_cap e) = full_cap e\"\n  by (simp add: extra_rights_def)\n\nlemma create_general_alt:\n  \"createOperation e c\\<^sub>1 c\\<^sub>2 s =\n   make_entity (target c\\<^sub>2)\n               (generalOperation  e (target c\\<^sub>1) (full_cap (target c\\<^sub>2)) (all_rights) s)\"\n  by (simp add: createOperation_def generalOperation_def make_entity_def)\n\nlemma create_general:\n  \"Create \\<in> rights c\\<^sub>2 \\<Longrightarrow> createOperation e c\\<^sub>1 c\\<^sub>2 s =\n   make_entity (target c\\<^sub>2)\n               (generalOperation  e (target c\\<^sub>1) c\\<^sub>2 (all_rights) s)\"\n  by (simp add: createOperation_def generalOperation_def make_entity_def\n                full_cap_def all_rights_def diminish_def\n                extra_rights_def create_general_helper null_entity_def)\n\nlemma take_general:\n  \"takeOperation e c\\<^sub>1 c\\<^sub>2 r s =\n   generalOperation (target c\\<^sub>1) e c\\<^sub>2 (r \\<inter> rights c\\<^sub>2) s\"\n  by (simp add: takeOperation_def generalOperation_def)\n\nlemma grant_general:\n  \"grantOperation e c\\<^sub>1 c\\<^sub>2 r s =\n   generalOperation e (target c\\<^sub>1) c\\<^sub>2 (r \\<inter> rights c\\<^sub>2) s\"\n  by (simp add: grantOperation_def generalOperation_def)\n\nlemma copy_general:\n  \"copyOperation e c\\<^sub>1 c\\<^sub>2 r s =\n   generalOperation e (target c\\<^sub>1) c\\<^sub>2 (r \\<inter> rights c\\<^sub>2) s\"\n  by (simp add: copyOperation_def generalOperation_def)\n\n(* Lemmas on the directly_tgs_connected predicate *)\nlemma directly_tgs_connected_comm:\n  \"s \\<turnstile> x \\<leftrightarrow> y \\<Longrightarrow> s \\<turnstile> y \\<leftrightarrow> x\"\n  by(auto simp: directly_tgs_connected_def)\n\nlemma tgs_connected_refl [simp]:\n  \"s \\<turnstile> x \\<leftrightarrow>* x\"\n  by (metis tgs_connected_def rtrancl.rtrancl_refl)\n\nlemma tgs_connected_comm:\n  \"s \\<turnstile> x \\<leftrightarrow>* y \\<Longrightarrow> s \\<turnstile> y \\<leftrightarrow>* x\"\n  apply(simp add: tgs_connected_def)\n  apply(erule rtrancl_induct, simp)\n  apply(case_tac \"s \\<turnstile> z \\<leftrightarrow> y\")\n   apply(simp add: directly_tgs_connected_comm)\n  apply(simp add: directly_tgs_connected_comm)\n  done\n\nlemma tgs_connected_comm_eq:\n  \"s \\<turnstile> x \\<leftrightarrow>* y = s \\<turnstile> y \\<leftrightarrow>* x\"\n  by (metis tgs_connected_comm)\n\nlemmas tgs_connected_trans =\n       rtrancl_trans [where r=\"directly_tgs_connected s\"  for s, simplified tgs_connected_def[symmetric]]\n\nlemmas directly_tgs_connected_rtrancl_into_rtrancl =\n       rtrancl_into_rtrancl [where r=\"directly_tgs_connected s\" for s, simplified tgs_connected_def[symmetric]]\n\nlemma take_caps_directly_tgs_connected:\n  \"\\<lbrakk>c \\<in> caps_of s e; Take \\<in> rights c\\<rbrakk> \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\"\n  by (auto simp: directly_tgs_connected_def leak_def take_cap_def cap_in_caps_def extra_rights_def all_rights_def)\n\nlemma grant_caps_directly_tgs_connected:\n  \"\\<lbrakk>c \\<in> caps_of s e; Grant \\<in> rights c\\<rbrakk> \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\"\n  by (auto simp: directly_tgs_connected_def leak_def grant_cap_def cap_in_caps_def extra_rights_def all_rights_def)\n\nlemma create_caps_directly_tgs_connected:\n  \"\\<lbrakk>c \\<in> caps_of s e; Create \\<in> rights c\\<rbrakk> \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\"\n  by (auto simp: directly_tgs_connected_def leak_def cap_in_caps_def rights_extra_rights all_rights_def)\n\nlemma store_connected_directly_tgs_connected:\n  \"(x, y) \\<in> store_connected s \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y\"\n  by (auto simp: directly_tgs_connected_def leak_def shares_caps_def store_connected_def)\n\n(* Lemmas on caps *)\n\nlemma cap_in_caps_insert [simp]:\n  \"c \\<in>cap insert c' S = (target c = target c' \\<and>\n  rights (extra_rights c) \\<subseteq> rights (extra_rights c') \\<or> c \\<in>cap S)\"\n  by (simp add: cap_in_caps_def)\n\nlemma cap_in_caps_singleton [simp]:\n  \"c \\<in>cap {c'} = (target c = target c' \\<and> rights (extra_rights c) \\<subseteq> rights (extra_rights c'))\"\n  by (simp add: cap_in_caps_def)\n\nlemma not_in [simp]:\n  \"{} \\<le>cap c\"\n  by(simp add: caps_dominated_by_def)\n\nlemma extra_rights_diminish:\n  \"x \\<in> rights (extra_rights (diminish r c))\n   \\<Longrightarrow> x \\<in> rights (extra_rights c)\"\n  by (auto simp: rights_extra_rights all_rights_def split:if_split_asm)\n\n(* Lemmas on system operations *)\n\ndefinition\n  in_store_connected :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" where\n  \"in_store_connected s x y \\<equiv> (x, y) \\<in> store_connected s\"\n\n(* Lemmas about the general operation *)\n\nlemma direct_caps_of_generalOp:\n  \"direct_caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) e =\n  (if e = e\\<^sub>1\n   then insert (diminish r (extra_rights c)) (direct_caps_of s (e\\<^sub>1))\n   else direct_caps_of s e)\"\n  by (clarsimp simp: generalOperation_def direct_caps_of_def split:option.splits)\n\nlemma direct_caps_of_generalOp2:\n  \"\\<lbrakk>c' \\<in> direct_caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x\\<rbrakk> \\<Longrightarrow>\n   c' \\<in> direct_caps_of s x \\<or> (c' \\<in>cap {c} \\<and> x = e\\<^sub>1)\"\n  apply (clarsimp simp: direct_caps_of_generalOp extra_rights_diminish\n           split:if_split_asm)\n  apply (drule extra_rights_diminish)\n  by simp\n\nlemma store_connected_direct_generalOp:\n  \"\\<lbrakk>(x, y) \\<in> store_connected_direct (generalOperation e\\<^sub>0 e\\<^sub>1 c r s)\\<rbrakk> \\<Longrightarrow>\n   (x, y) \\<in> store_connected_direct s \\<or>\n   (x = e\\<^sub>1 \\<and> y = target c \\<and> Store \\<in> rights (extra_rights c))\"\n  by (auto simp: store_connected_direct_def direct_caps_of_generalOp all_rights_def\n          split: if_split_asm)\n\nlemma store_connected_generalOp:\n  \"\\<lbrakk>(x, y) \\<in> store_connected (generalOperation e\\<^sub>0 e\\<^sub>1 c r s)\\<rbrakk> \\<Longrightarrow>\n   (x, y) \\<in> store_connected s \\<or>\n   ((x, e\\<^sub>1) \\<in> store_connected s \\<and>\n   (e\\<^sub>1, target c) \\<in> store_connected_direct (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) \\<and>\n   (target c, y) \\<in> store_connected s)\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl_induct)\n   apply clarsimp\n  apply (clarsimp)\n  apply (fold store_connected_def)\n  apply (subgoal_tac \"(y, z) \\<in> store_connected_direct s\")\n   apply (clarsimp simp: store_connected_def)\n   apply (erule disjE)\n    apply fastforce\n   apply clarsimp\n   apply (erule notE)\n   apply fastforce\n  apply (frule store_connected_direct_generalOp)\n  apply (clarsimp simp: store_connected_def)\n  done\n\n\nlemma store_connected_generalOp_not_new:\n  \"\\<lbrakk>(e\\<^sub>1, target c) \\<in> store_connected_direct (generalOperation e\\<^sub>0 e\\<^sub>1 c r s);\n   c \\<in> caps_of s e\\<^sub>0\\<rbrakk> \\<Longrightarrow>\n   (e\\<^sub>1, target c) \\<in> store_connected_direct s \\<or>\n   (e\\<^sub>0, target c) \\<in> store_connected s \\<or>\n   Create \\<in> rights c\"\n  apply (drule store_connected_direct_generalOp)\n  apply (clarsimp simp: rights_extra_rights split:if_split_asm)\n   apply (drule (1) store_caps_store_connected, simp)\n  done\n\nlemma store_connected_generalOp2:\n  \"\\<lbrakk>(x, y) \\<in> store_connected (generalOperation e\\<^sub>0 e\\<^sub>1 c r s);\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk> \\<Longrightarrow>\n   s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (drule store_connected_generalOp)\n  apply (erule disjE)\n   apply (simp add: tgs_connected_def)\n   apply (drule store_connected_directly_tgs_connected, simp)\n  apply clarsimp\n  apply (drule store_connected_directly_tgs_connected [where x=x and y=e\\<^sub>1])\n  apply (drule store_connected_directly_tgs_connected [where x=\"target c\" and y=y])\n  apply (drule (1) store_connected_generalOp_not_new)\n  apply (erule disjE)\n   apply (drule store_connected_direct_in_store_connected)\n   apply (drule store_connected_directly_tgs_connected [where x=e\\<^sub>1 and y=\"target c\"])\n   apply (simp add: tgs_connected_def)\n  apply (drule directly_tgs_connected_comm [where x=\"e\\<^sub>0\" and y=\"e\\<^sub>1\"])\n  apply (erule disjE)\n   apply (drule store_connected_directly_tgs_connected [where x=e\\<^sub>0 and y=\"target c\"])\n   apply (simp add: tgs_connected_def)\n  apply (drule (1) create_caps_directly_tgs_connected)\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma shares_caps_of_generalOp:\n  \"\\<lbrakk>shares_caps (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x y;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (clarsimp simp: shares_caps_def)\n  apply (frule (2) store_connected_generalOp2 [where x=x])\n  apply (drule (2) store_connected_generalOp2 [where x=y])\n  apply (drule tgs_connected_comm [where x=y])\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma caps_of_generalOp:\n  \"\\<lbrakk>c' \\<in> caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (simp add: caps_of_def[where e=x])\n  apply clarsimp\n  apply (frule (2) store_connected_generalOp2)\n  apply (drule direct_caps_of_generalOp2)\n  apply (erule disjE)\n   apply (drule direct_cap_in_cap)\n   apply (fastforce simp: cap_in_caps_def)\n  apply (subgoal_tac \"s \\<turnstile> x \\<leftrightarrow>* e\\<^sub>0\")\n   apply (subgoal_tac \"c' \\<in>cap caps_of s e\\<^sub>0\")\n    apply fastforce\n   apply (fastforce simp: cap_in_caps_def)\n  apply clarsimp\n  apply (drule directly_tgs_connected_comm [where x=\"e\\<^sub>0\" and y=\"e\\<^sub>1\"])\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma take_cap_generalOp:\n  \"\\<lbrakk>take_cap y \\<in>cap caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z.  s \\<turnstile> x \\<leftrightarrow>* z \\<and> take_cap y \\<in>cap caps_of s z\"\n  apply (simp add: cap_in_caps_def)\n  apply clarsimp\n  apply (drule (2) caps_of_generalOp)\n  apply (fastforce simp: cap_in_caps_def)\n  done\n\nlemma grant_cap_generalOp:\n  \"\\<lbrakk>grant_cap y \\<in>cap caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z.  s \\<turnstile> x \\<leftrightarrow>* z \\<and> grant_cap y \\<in>cap caps_of s z\"\n  apply (simp add: cap_in_caps_def)\n  apply clarsimp\n  apply (drule (2) caps_of_generalOp)\n  apply (fastforce simp: cap_in_caps_def)\n  done\n\nlemma take_cap_generalOp2:\n  \"\\<lbrakk>take_cap y \\<in>cap caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply (drule (2) take_cap_generalOp)\n  apply clarsimp\n  apply (subgoal_tac \"s \\<turnstile> z \\<leftrightarrow> y\")\n   apply (simp add: tgs_connected_def)\n  apply (simp add: directly_tgs_connected_def leak_def)\n  done\n\nlemma grant_cap_generalOp2:\n  \"\\<lbrakk>grant_cap y \\<in>cap caps_of (generalOperation e\\<^sub>0 e\\<^sub>1 c r s) x;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply (drule (2) grant_cap_generalOp)\n  apply clarsimp\n  apply (subgoal_tac \"s \\<turnstile> z \\<leftrightarrow> y\")\n   apply (simp add: tgs_connected_def)\n  apply (simp add: directly_tgs_connected_def leak_def)\n  done\n\nlemma generalOp_directly_tgs_connected:\n \"\\<lbrakk>generalOperation e\\<^sub>0 e\\<^sub>1 c r s \\<turnstile> x \\<leftrightarrow> y;\n   c \\<in> caps_of s e\\<^sub>0; s \\<turnstile> e\\<^sub>0 \\<leftrightarrow> e\\<^sub>1\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (simp add: directly_tgs_connected_def [where s=\"generalOperation e\\<^sub>0 e\\<^sub>1 c r s\"] leak_def)\n  apply safe\n       apply (rule tgs_connected_comm)\n       apply (drule (3) take_cap_generalOp2)\n      apply (drule (3) grant_cap_generalOp2)\n     apply (erule (2) shares_caps_of_generalOp)\n    apply (drule (3) take_cap_generalOp2)\n   apply (rule tgs_connected_comm)\n   apply (drule (3) grant_cap_generalOp2)\n  apply (erule (2) shares_caps_of_generalOp)\n  done\n\n\n\n(* results from general operation *)\n\nlemma create_legal_directly_tgs_connected:\n  \"legal (SysCreate e c\\<^sub>1 c\\<^sub>2) s \\<Longrightarrow> s  \\<turnstile> target c\\<^sub>1 \\<leftrightarrow> e\"\n  apply clarsimp\n  apply (rule directly_tgs_connected_comm)\n  apply (drule (1) create_caps_directly_tgs_connected)\n  apply (drule (1) store_caps_store_connected)\n  apply (drule (1) store_connected_directly_tgs_connected)\n  done\n\nlemma take_legal_directly_tgs_connected:\n  \"legal (SysTake e c\\<^sub>1 c\\<^sub>2 r) s \\<Longrightarrow> s  \\<turnstile> target c\\<^sub>1 \\<leftrightarrow> e\"\n  apply clarsimp\n  apply (rule directly_tgs_connected_comm)\n  apply (drule (2) take_caps_directly_tgs_connected)\n  done\n\nlemma grant_legal_directly_tgs_connected:\n  \"legal (SysGrant e c\\<^sub>1 c\\<^sub>2 r) s \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\\<^sub>1\"\n  apply clarsimp\n  apply (drule (2) grant_caps_directly_tgs_connected)\n  done\n\nlemma copy_legal_directly_tgs_connected:\n  \"legal (SysCopy e c\\<^sub>1 c\\<^sub>2 r) s \\<Longrightarrow> s \\<turnstile> e \\<leftrightarrow> target c\\<^sub>1\"\n  apply clarsimp\n  apply (drule (1) store_caps_store_connected)\n  apply (drule (1) store_connected_directly_tgs_connected)\n  done\n\nlemma caps_of_create:\n  \"\\<lbrakk>c' \\<in> caps_of (createOperation e c\\<^sub>1 c\\<^sub>2 s) x; legal (SysCreate e c\\<^sub>1 c\\<^sub>2) s\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (frule create_legal_directly_tgs_connected)\n  apply (clarsimp simp: create_general)\n  apply (drule caps_of_make_entity2 [rotated], clarsimp)\n  apply (drule (1) caps_of_generalOp)\n   apply (drule (2) directly_tgs_connected_comm)\n  done\n\nlemma caps_of_take:\n  \"\\<lbrakk>c' \\<in> caps_of (takeOperation e c\\<^sub>1 c\\<^sub>2 r s) x; legal (SysTake e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (frule take_legal_directly_tgs_connected)\n  apply (clarsimp simp: take_general)\n  apply (drule (2) caps_of_generalOp)\n   apply (drule (1) directly_tgs_connected_comm)\n  done\n\nlemma caps_of_grant:\n  \"\\<lbrakk>c' \\<in> caps_of (grantOperation e c\\<^sub>1 c\\<^sub>2 r s) x; legal (SysGrant e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (frule grant_legal_directly_tgs_connected)\n  apply (clarsimp simp: grant_general)\n  apply (drule (2) caps_of_generalOp)\n   apply (drule (1) directly_tgs_connected_comm)\n  done\n\nlemma caps_of_copy:\n  \"\\<lbrakk>c' \\<in> caps_of (copyOperation e c\\<^sub>1 c\\<^sub>2 r s) x; legal (SysCopy e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. (x,z) \\<in> tgs_connected s \\<and> c' \\<in>cap caps_of s z\"\n  apply (frule copy_legal_directly_tgs_connected)\n  apply (clarsimp simp: copy_general)\n  apply (drule (2) caps_of_generalOp)\n   apply (drule (1) directly_tgs_connected_comm)\n  done\n\nlemma create_directly_tgs_connected:\n \"\\<lbrakk>createOperation e c\\<^sub>1 c\\<^sub>2 s \\<turnstile> x \\<leftrightarrow> y; legal (SysCreate e c\\<^sub>1 c\\<^sub>2) s\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (frule create_legal_directly_tgs_connected)\n  apply (clarsimp simp: create_general)\n  apply (drule directly_tgs_connected_make_entity2 [rotated], clarsimp)\n  apply (drule (1) generalOp_directly_tgs_connected)\n   apply (drule (2) directly_tgs_connected_comm)\n  done\n\nlemma take_directly_tgs_connected:\n \"\\<lbrakk>takeOperation e c\\<^sub>1 c\\<^sub>2 r s \\<turnstile> x \\<leftrightarrow> y; legal (SysTake e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (frule take_legal_directly_tgs_connected)\n  apply (clarsimp simp: take_general)\n  apply (drule (3) generalOp_directly_tgs_connected)\n  done\n\nlemma grant_directly_tgs_connected:\n \"\\<lbrakk>grantOperation e c\\<^sub>1 c\\<^sub>2 r s \\<turnstile> x \\<leftrightarrow> y; legal (SysGrant e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (frule grant_legal_directly_tgs_connected)\n  apply (clarsimp simp: grant_general)\n  apply (drule (3) generalOp_directly_tgs_connected)\n  done\n\nlemma copy_directly_tgs_connected:\n \"\\<lbrakk>copyOperation e c\\<^sub>1 c\\<^sub>2 r s \\<turnstile> x \\<leftrightarrow> y; legal (SysCopy e c\\<^sub>1 c\\<^sub>2 r) s\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply (frule copy_legal_directly_tgs_connected)\n  apply (clarsimp simp: copy_general)\n  apply (drule (3) generalOp_directly_tgs_connected)\n  done\n\n\n\nlemma create_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysCreate e c\\<^sub>1 c\\<^sub>2)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n   apply (erule disjE, fastforce simp: tgs_connected_def, clarsimp)\n   apply (drule create_directly_tgs_connected, clarsimp, assumption)\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma take_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysTake e c\\<^sub>1 c\\<^sub>2 r)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n   apply (erule disjE, fastforce simp: tgs_connected_def, clarsimp)\n   apply (drule take_directly_tgs_connected, clarsimp, assumption)\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma grant_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysGrant e c\\<^sub>1 c\\<^sub>2 r)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n   apply (erule disjE, fastforce simp: tgs_connected_def, clarsimp)\n   apply (drule grant_directly_tgs_connected, clarsimp, assumption)\n  apply (simp add: tgs_connected_def)\n  done\n\nlemma copy_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysCopy e c\\<^sub>1 c\\<^sub>2 r)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n   apply (erule disjE, fastforce simp: tgs_connected_def, clarsimp)\n   apply (drule copy_directly_tgs_connected, clarsimp, assumption)\n  apply (simp add: tgs_connected_def)\n  done\n\n(* Lemmas about destroy *)\n\nlemma direct_caps_of_destroy:\n  \"c \\<in> direct_caps_of (s(e := None)) x \\<Longrightarrow> c \\<in> direct_caps_of s x\"\n  by (simp add: direct_caps_of_def split: option.splits split: if_split_asm)\n\nlemma store_connected_destroy:\n \"(x, y) \\<in> store_connected (s(e := None)) \\<Longrightarrow> (x, y) \\<in> store_connected s\"\n  apply (simp add: store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply (fold store_connected_def)\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (fastforce simp: store_connected_def)\n  apply (simp add: store_connected_direct_def)\n  apply clarsimp\n  by (metis direct_caps_of_destroy)\n\nlemma shares_caps_destroy:\n  \"shares_caps (destroyOperation e c s) x y\n  \\<Longrightarrow> shares_caps s x y\"\n  apply (clarsimp simp: shares_caps_def destroyOperation_def)\n  apply (frule store_connected_destroy [where x=x])\n  apply (drule store_connected_destroy [where x=y])\n  by auto\n\nlemma caps_of_destroy:\n  \"c \\<in> caps_of (destroyOperation e' c' s) e \\<Longrightarrow>\n  c \\<in> caps_of s e\"\n  apply (clarsimp simp add: destroyOperation_def caps_of_def)\n  apply (rule_tac x=x in exI)\n  apply (drule direct_caps_of_destroy)\n  apply simp\n  apply (erule store_connected_destroy)\n  done\n\nlemma destroy_directly_tgs_connected:\n  \"\\<lbrakk>s' \\<in> step (SysDestroy e c) s; (x, y) \\<in> directly_tgs_connected s'\\<rbrakk> \\<Longrightarrow>\n  (x, y) \\<in> directly_tgs_connected s\"\n  apply(clarsimp simp: step_def split: if_split_asm)\n  apply(erule disjE, simp)\n  apply(simp add: directly_tgs_connected_def leak_def)\n  apply (erule disjE)\n   apply(fastforce simp add: cap_in_caps_def dest!: caps_of_destroy)\n  apply (erule disjE)\n   apply(fastforce simp add: cap_in_caps_def dest!: caps_of_destroy)\n  apply (erule disjE)\n   apply (drule shares_caps_destroy, simp)\n  apply (erule disjE)\n   apply(fastforce simp add: cap_in_caps_def dest!: caps_of_destroy)\n  apply (erule disjE)\n   apply(fastforce simp add: cap_in_caps_def dest!: caps_of_destroy)\n  apply (drule shares_caps_destroy, simp)\n  done\n\nlemma destroy_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysDestroy e c)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in>  directly_tgs_connected s\"\n  by(auto dest!: destroy_directly_tgs_connected)\n\n\n(* lemmas about remove *)\n\nlemma direct_caps_of_remove:\n  \"c \\<in> direct_caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x \\<Longrightarrow>\n  c \\<in> direct_caps_of s x\"\n  by (clarsimp simp: removeOperation_simpler direct_caps_of_def\n              split: option.splits if_split_asm)\n\nlemma direct_caps_of_remove_eq:\n  \"direct_caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x =\n  ( if   is_entity s (target c\\<^sub>1) \\<and> x = target c\\<^sub>1\n   then  direct_caps_of s (target c\\<^sub>1) - {c\\<^sub>2}\n   else  direct_caps_of s x )\"\n  by(simp add: direct_caps_of_def is_entity_def removeOperation_def)\n\nlemma store_connected_remove [rule_format]:\n  \"(x, y) \\<in> store_connected (s(e \\<mapsto> Entity C')) \\<Longrightarrow>\n  s e = Some (Entity C) \\<longrightarrow> C' \\<subseteq> C \\<longrightarrow> (x, y) \\<in> store_connected s\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply clarsimp\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (erule rtrancl_trans)\n   apply fastforce\n  apply (fold store_connected_def)\n  apply (clarsimp simp add: store_connected_direct_def)\n  apply (fastforce simp: direct_caps_of_def\n                  split: option.splits if_split_asm)\n  done\n\nlemma caps_of_remove:\n  \"c \\<in> caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x \\<Longrightarrow>\n  c \\<in> caps_of s x\"\n  apply (clarsimp simp: caps_of_def)\n  apply (rule_tac x=xa in exI)\n  apply (drule direct_caps_of_remove)\n  apply (simp add: removeOperation_simpler\n            split: option.splits)\n  apply (erule (1) store_connected_remove)\n  apply blast\n  done\n\n(* Might equal either  \"caps s (target c\\<^sub>1) - {c\\<^sub>2}\" or \"caps s x\" depending if the caps are duplicated.*)\nlemma caps_of_remove2:\n  \"caps_of (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x \\<subseteq> caps_of s x\"\n  apply(simp add: caps_of_def is_entity_def removeOperation_def direct_caps_of_def)\n  apply (clarsimp split: if_split_asm)\n   apply (auto dest!: store_connected_remove)\n  done\n\nlemma shares_caps_remove:\n  \"shares_caps (removeOperation e c\\<^sub>1 c\\<^sub>2 s) x y\n  \\<Longrightarrow> shares_caps s x y\"\n  apply (clarsimp simp: shares_caps_def removeOperation_simpler\n                 split:option.splits)\n  apply (frule (1) store_connected_remove [where x=x], clarsimp)\n  apply (drule (1) store_connected_remove [where x=y], clarsimp)\n  by auto\n\nlemma remove_directly_tgs_connected:\n  \"\\<lbrakk>s' \\<in> step (SysRemove e c\\<^sub>1 c\\<^sub>2) s; (x, y) \\<in> directly_tgs_connected s'\\<rbrakk> \\<Longrightarrow>\n  (x, y) \\<in> directly_tgs_connected s\"\n  apply(simp add: step_def split: if_split_asm)\n  apply(erule disjE, simp)\n  apply(simp add: directly_tgs_connected_def leak_def)\n  apply(simp add: cap_in_caps_def)\n  apply(clarsimp)\n  apply safe\n     prefer 3\n     apply (drule shares_caps_remove, simp)\n    prefer 5\n    apply (drule shares_caps_remove, simp)\n   apply(auto dest!: caps_of_remove)\n  done\n\nlemma remove_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysRemove e c\\<^sub>1 c\\<^sub>2)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in>  directly_tgs_connected s\"\n  by(auto dest!: remove_directly_tgs_connected)\n\nlemma direct_caps_of_removeSet:\n  \"c' \\<in> direct_caps_of (removeSetOperation e c C s) x \\<Longrightarrow>\n  c' \\<in> direct_caps_of s x\"\n  by (clarsimp simp: removeSetOperation_simpler direct_caps_of_def\n              split: option.splits if_split_asm)\n\nlemma caps_of_removeSet:\n  \"c' \\<in> caps_of (removeSetOperation e c C s) x \\<Longrightarrow>\n  c' \\<in> caps_of s x\"\n  apply (clarsimp simp: caps_of_def)\n  apply (rule_tac x=xa in exI)\n  apply (drule direct_caps_of_removeSet)\n  apply (simp add: removeSetOperation_simpler split: option.splits)\n  apply (erule (1) store_connected_remove)\n  apply blast\n  done\n\nlemma shares_caps_removeSet:\n  \"shares_caps (removeSetOperation e c C s) x y\n  \\<Longrightarrow> shares_caps s x y\"\n  apply (clarsimp simp: shares_caps_def removeSetOperation_simpler split:option.splits)\n  apply (frule (1) store_connected_remove [where x=x], clarsimp)\n  apply (drule (1) store_connected_remove [where x=y], clarsimp)\n  by auto\n\nlemma removeSet_connected:\n  \" \\<lbrakk>s' \\<in> step (SysRemoveSet e c C) s; s' \\<turnstile> x \\<leftrightarrow> y\\<rbrakk> \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y\"\n  apply(simp add: step_def split: if_split_asm)\n  apply(erule disjE, simp)\n  apply(simp add: directly_tgs_connected_def leak_def)\n  apply(simp add: cap_in_caps_def)\n  apply(clarsimp)\n  apply safe\n     prefer 3\n     apply (drule shares_caps_removeSet, simp)\n    prefer 5\n    apply (drule shares_caps_removeSet, simp)\n   apply (auto dest!: caps_of_removeSet)\n  done\n\nlemma removeSet_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; s' \\<turnstile> x \\<leftrightarrow> y; cmd = (SysRemoveSet n c C)\\<rbrakk>\n  \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow> y\"\n  by(auto dest!: removeSet_connected)\n\n(* lemmas about revoke *)\nlemma direct_caps_of_removeSetOfCaps:\n  \"c' \\<in> direct_caps_of (removeSetOfCaps cap_map s) x \\<Longrightarrow>\n  c' \\<in> direct_caps_of s x\"\n  by (clarsimp simp: removeSetOfCaps_def direct_caps_of_def\n              split: option.splits if_split_asm)\nthm store_connected_remove\n\nlemma store_connected_removeSetOfCaps:\n  \"(x, y) \\<in> store_connected (\\<lambda>e. if is_entity s e\n                                 then Some (Entity (direct_caps_of s e - cap_map e))\n                                 else None) \\<Longrightarrow>\n    (x, y) \\<in> store_connected s\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (erule rtrancl_trans)\n   apply fastforce\n  apply (fold store_connected_def)\n  apply (clarsimp simp add: store_connected_direct_def)\n  apply (fastforce simp: direct_caps_of_def\n                  split: option.splits if_split_asm)\n  done\n\nlemma caps_of_removeSetOfCaps:\n  \"c' \\<in> caps_of (removeSetOfCaps cap_map s) x \\<Longrightarrow>\n  c' \\<in> caps_of s x\"\n  apply (clarsimp simp: caps_of_def)\n  apply (rule_tac x=xa in exI)\n  apply (drule direct_caps_of_removeSetOfCaps)\n  apply (simp add: removeSetOfCaps_def split: option.splits)\n  apply (erule store_connected_removeSetOfCaps)\n  done\n\nlemma caps_of_revoke:\n  \"\\<lbrakk>s' \\<in> revokeOperation sub c\\<^sub>1 s ;  c \\<in> caps_of s' e \\<rbrakk>\n  \\<Longrightarrow> c \\<in> caps_of s e\"\n  apply (clarsimp simp: revokeOperation_def\n                 split: if_split_asm)\n  apply (drule (1) caps_of_removeSetOfCaps)\n  done\n\nlemma direct_caps_of_revoke:\n  \"\\<lbrakk>s' \\<in> revokeOperation e c s; c' \\<in> direct_caps_of s' x\\<rbrakk>\n   \\<Longrightarrow> c' \\<in> direct_caps_of s x\"\n  apply (clarsimp simp: revokeOperation_def\n                 split: if_split_asm)\n  apply (drule (1) direct_caps_of_removeSetOfCaps)\n  done\n\nlemma store_connected_revoke:\n \"\\<lbrakk>(x, y) \\<in> store_connected s'; s' \\<in> revokeOperation e c s\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> store_connected s\"\n  apply (simp add: store_connected_def)\n  apply (erule rtrancl_induct)\n   apply simp\n  apply (fold store_connected_def)\n  apply (subgoal_tac \"(y,z) \\<in> store_connected_direct s\")\n   apply (fastforce simp: store_connected_def)\n  apply (clarsimp simp: store_connected_direct_def)\n  apply (metis direct_caps_of_revoke)\n  done\n\nlemma shares_caps_revoke:\n  \"\\<lbrakk>shares_caps s' x y; s' \\<in> revokeOperation e c s\\<rbrakk>\n  \\<Longrightarrow> shares_caps s x y\"\n  apply (clarsimp simp: shares_caps_def)\n  apply (frule (1) store_connected_revoke [where x=x])\n  apply (drule (1) store_connected_revoke [where x=y])\n  by auto\n\nlemma removeOperation_entity_ids [simp]:\n  \"is_entity (removeOperation e c c' s) e' = is_entity s e'\"\n  by (simp add: is_entity_def removeOperation_def)\n\nlemma removeSetOfCaps_entity_ids [simp]:\n  \"is_entity (removeSetOfCaps cap_map s) e' = is_entity s e'\"\n  by (simp add: is_entity_def removeSetOfCaps_def)\n\nlemma revoke_entities:\n  \"s' \\<in> revokeOperation sub c\\<^sub>1 s \\<Longrightarrow> is_entity s' e = is_entity s e\"\n  by (clarsimp simp: revokeOperation_def split: if_split_asm)\n\nlemma revoke_directly_tgs_connected:\n  \"\\<lbrakk>s' \\<in> step (SysRevoke n c\\<^sub>1) s; (x, y) \\<in> directly_tgs_connected s'\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in>  directly_tgs_connected s\"\n  apply (simp add: step_def split: if_split_asm)\n  apply (erule disjE, simp)\n  apply (simp add: directly_tgs_connected_def leak_def)\n  apply (erule disjE)\n   apply(auto simp add: cap_in_caps_def dest!: caps_of_revoke)[1]\n  apply (erule disjE)\n   apply(auto simp add: cap_in_caps_def dest!: caps_of_revoke)[1]\n  apply (erule disjE)\n   apply (drule (1) shares_caps_revoke, simp)\n  apply (erule disjE)\n   apply(auto simp add: cap_in_caps_def dest!: caps_of_revoke)[1]\n  apply (erule disjE)\n   apply(auto simp add: cap_in_caps_def dest!: caps_of_revoke)[1]\n  apply (drule (1) shares_caps_revoke, simp)\n  done\n\nlemma revoke_conTrans:\n  \"\\<lbrakk>s' \\<in> step cmd s; (x, y) \\<in> directly_tgs_connected s'; cmd = (SysRevoke n c\\<^sub>1)\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in>  directly_tgs_connected s\"\n  by(auto dest!: revoke_directly_tgs_connected)\n\n\n\n(* lemmas about grant *)\n\nlemma is_entity_grant [simp]:\n  \"is_entity s (target c\\<^sub>1) \\<Longrightarrow>\n  is_entity (grantOperation e c\\<^sub>1 c\\<^sub>2 r s) e' = is_entity s e'\"\n  by (simp add: is_entity_def grantOperation_def)\n\nlemma is_entity_destroy:\n  \"is_entity (destroyOperation e' c s) e \\<Longrightarrow> is_entity s e\"\n  by (simp add: destroyOperation_def is_entity_def split: if_split_asm)\n\n\n(********************************************\n ********************************************\n ***** Connected transitively preserved *****\n ********************************************\n ********************************************)\n\nlemma connected_tgs_connected:\n  \"\\<lbrakk>s' \\<in> step cmd s; (e\\<^sub>x, e\\<^sub>y) \\<in> directly_tgs_connected s'\\<rbrakk> \\<Longrightarrow>\n  (e\\<^sub>x, e\\<^sub>y) \\<in> tgs_connected s\"\n  apply(case_tac \"(e\\<^sub>x, e\\<^sub>y) \\<in> directly_tgs_connected s\")\n   apply(simp add: tgs_connected_def)\n   apply(case_tac cmd)\n         apply(rule create_conTrans, fastforce+)\n        apply(rule take_conTrans, fastforce+)\n       apply(rule grant_conTrans, fastforce+)\n      apply(frule copy_conTrans, fastforce+)\n     apply(frule remove_conTrans, fastforce+)\n    apply(frule removeSet_conTrans, fastforce+)\n   apply(frule revoke_conTrans, fastforce+)\n  apply(frule destroy_conTrans, fastforce+)\n  done\n\nlemma tgs_connected_preserved_step:\n  \"\\<lbrakk>s' \\<in> step cmd s; s' \\<turnstile> x \\<leftrightarrow>* z\\<rbrakk> \\<Longrightarrow> s \\<turnstile> x \\<leftrightarrow>* z\"\n  thm rtrancl_induct [where r=\"directly_tgs_connected s'\" and a=x and b=z and P=\"\\<lambda>z. (x, z) \\<in> (directly_tgs_connected s)\\<^sup>*\", simplified,\n                      simplified tgs_connected_def [symmetric]]\n  apply(erule rtrancl_induct [where r=\"directly_tgs_connected s'\",\n                              simplified tgs_connected_def [symmetric]], simp)\n  apply(case_tac \"s \\<turnstile> y \\<leftrightarrow>* z\")\n   apply (erule (1) tgs_connected_trans)\n  apply (simp add: connected_tgs_connected)\n  done\n\nlemma leakImplyConnected:\n  \"leak s\\<^sub>i e\\<^sub>x e\\<^sub>i \\<Longrightarrow> (e\\<^sub>x, e\\<^sub>i) \\<in> directly_tgs_connected s\\<^sub>i\"\n by(simp add: directly_tgs_connected_def)\n\nlemma leakImplyConnectedTrans:\n  \"leak s\\<^sub>i e\\<^sub>x e\\<^sub>i \\<Longrightarrow> (e\\<^sub>x, e\\<^sub>i) \\<in> tgs_connected s\\<^sub>i\"\n  by(simp add: tgs_connected_def, frule leakImplyConnected, auto)\n\n\nlemma tgs_connected_preserved [rule_format]:\n  \"\\<forall>s'. s' \\<in> execute cmds s \\<longrightarrow>\n    s' \\<turnstile> x \\<leftrightarrow>* y \\<longrightarrow>\n    s \\<turnstile> x \\<leftrightarrow>* y\"\n  apply(induct_tac cmds, simp)\n  apply clarsimp\n  apply(rename_tac cmd cmds s'' s')\n  apply(erule_tac x=s' in allE)\n  apply(simp add: tgs_connected_preserved_step)\n  done\n\nlemma leak_conTrans [rule_format]:\n  \"\\<lbrakk>s \\<in> execute cmds s\\<^sub>0; leak s x y\\<rbrakk>\n  \\<Longrightarrow> (x, y) \\<in> tgs_connected s\\<^sub>0\"\n  by (auto intro: leakImplyConnectedTrans tgs_connected_preserved)\n\nlemma leakage_rule:\n  \"\\<lbrakk>s' \\<in> execute cmds s; \\<not> s \\<turnstile> x \\<leftrightarrow>* y\\<rbrakk> \\<Longrightarrow> \\<not> (s' \\<turnstile> x \\<rightarrow> y)\"\n  by(auto simp add: leak_conTrans)\n\n\n\n\n(*******************************************\n *******************************************\n *****      Authority confinement     *****\n *******************************************\n *******************************************)\n\nlemma caps_of_op:\n  \"\\<lbrakk>s' \\<in> step cmd s; c' \\<in> caps_of s' x\\<rbrakk>\n  \\<Longrightarrow> \\<exists>z. s \\<turnstile> x \\<leftrightarrow>* z \\<and> c' \\<in>cap caps_of s z\"\n  apply (simp add: step_def split:if_split_asm)\n   prefer 2\n   apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n  apply (erule disjE)\n   apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n  apply (case_tac cmd)\n         apply (simp add: caps_of_create)\n        apply (simp add: caps_of_take)\n       apply (simp add: caps_of_grant)\n      apply (simp add: caps_of_copy)\n     apply (clarsimp, drule caps_of_remove)\n     apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n    apply (clarsimp, drule caps_of_removeSet)\n    apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n   apply (clarsimp, drule (1) caps_of_revoke)\n   apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n  apply (clarsimp, drule caps_of_destroy)\n  apply (fastforce simp: cap_in_caps_def tgs_connected_def rights_extra_rights)\n  done\n\nlemma authority_confinement_induct_step:\n  \"\\<lbrakk>s' \\<in> step cmd s;\n    \\<forall>e\\<^sub>i. s \\<turnstile> e\\<^sub>x \\<leftrightarrow>* e\\<^sub>i \\<longrightarrow> caps_of s e\\<^sub>i \\<le>cap c\\<rbrakk>\n  \\<Longrightarrow> caps_of s' e\\<^sub>x \\<le>cap c\"\n  apply (clarsimp simp: caps_dominated_by_def)\n  apply (drule (1) caps_of_op)\n  apply (fastforce simp: cap_in_caps_def)\n  done\n\nlemma authority_confinement_helper:\n  \"s' \\<in> execute cmds s \\<longrightarrow>\n   (\\<forall>e\\<^sub>i. s \\<turnstile> e\\<^sub>x \\<leftrightarrow>* e\\<^sub>i \\<longrightarrow> caps_of s e\\<^sub>i \\<le>cap c) \\<longrightarrow>\n   (\\<forall>e\\<^sub>i. s' \\<turnstile> e\\<^sub>x \\<leftrightarrow>* e\\<^sub>i \\<longrightarrow> caps_of s' e\\<^sub>i \\<le>cap c)\"\nproof (induct cmds arbitrary: s')\ncase Nil\n  show ?case by clarsimp\nnext\ncase (Cons cmd cmds s')\nshow ?case\n  apply clarsimp\n  apply (rule authority_confinement_induct_step, assumption)\n  apply clarsimp\n  apply (rule Cons.hyps[rule_format], simp_all)\n  apply (drule(1) tgs_connected_preserved_step)\n  apply (simp add: tgs_connected_def)\n  done\nqed\n\nlemma authority_confinement:\n  \"\\<lbrakk>s' \\<in> execute cmds s;\n    \\<forall>e\\<^sub>i. s \\<turnstile> e\\<^sub>x \\<leftrightarrow>* e\\<^sub>i \\<longrightarrow> caps_of s e\\<^sub>i \\<le>cap c\\<rbrakk>\n  \\<Longrightarrow> caps_of s' e\\<^sub>x \\<le>cap c\"\n  by (erule authority_confinement_helper [rule_format, where e\\<^sub>x=e\\<^sub>x], simp_all)\n\nend"}
{"title": "./spec/take-grant/System_S.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Title:   System_S\n * Description: High-level security model of the kernel.\n *)\n\n(*\n  Naming conventions:\n  - Names of sets end with an `s'.\n    Hence `rights', `caps', `states'.\n    Try to avoid other names that end in `s'.\n *)\n\ntheory System_S\nimports \"Word_Lib.WordSetup\"\nbegin\n\n(* System entities: Definition of entities that constitute the system\n *)\n\ntype_synonym entity_id = word32 (* kernel objects - identified by a UID *)\n\ndatatype\n  right = Read      (* Authorise reading of information *)\n         | Write    (* Authorise writing of information *)\n         | Take     (* Having sufficient authority to take a capability from another entity *)\n         | Grant    (* Having sufficient authority to propagate a capability to another entity *)\n         | Create   (* Confers the authority to create new entities *)\n         | Store    (* Simulates CNodeCap - get caps of said entity *)\n\nrecord cap =\n  target :: entity_id      (* The entity over which it has control *)\n  rights :: \"right set\"    (* The control it has over that entity  *)\n\ndatatype entity = Entity \"cap set\"\ndeclare entity.splits [split]\n\ntype_synonym state = \"entity_id \\<Rightarrow> entity option\"\n\ntype_synonym modify_state   = \"state \\<Rightarrow> state\"\ntype_synonym modify_state_n = \"state \\<Rightarrow> state set\"\ntype_synonym mask = \"right set\"\n\ndefinition\n  null_entity :: \"entity\" where\n  \"null_entity \\<equiv> Entity {}\"\n\ndefinition\n  all_rights :: \"right set\" where\n  \"all_rights \\<equiv> UNIV\"\n\nlemma all_rights_def2:\n  \"all_rights = {Read, Write, Take, Grant, Create, Store}\"\n  apply (clarsimp simp: all_rights_def, rule, simp_all, rule, simp)\n  apply (metis right.exhaust)\n  done\n\ndefinition\n  entity_ids :: \"state \\<Rightarrow> entity_id set\" where\n  \"entity_ids s \\<equiv> dom s\"\n\ndefinition\n  is_entity :: \"state \\<Rightarrow> entity_id \\<Rightarrow> bool\" where\n  \"is_entity s e \\<equiv> s e \\<noteq> None\"\n\ndefinition\n  exist :: \"state \\<Rightarrow> cap \\<Rightarrow> bool\" where\n  \"exist s c \\<equiv> is_entity s (target c)\"\n\n(* Manipulating entities. *)\ndefinition\n  direct_caps :: \"entity \\<Rightarrow> cap set\"\nwhere\n  \"direct_caps e \\<equiv> case e of (Entity c) \\<Rightarrow> c\"\n\ndefinition\n  direct_caps_of :: \"state \\<Rightarrow> entity_id \\<Rightarrow> cap set\"\nwhere\n  \"direct_caps_of s p \\<equiv>\n  case s p of\n    None \\<Rightarrow> {}\n  | Some (Entity e) \\<Rightarrow> e\"\n\ndefinition\n  store_connected_direct :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"store_connected_direct s \\<equiv> {(e\\<^sub>x, e\\<^sub>y). \\<exists>cap. cap \\<in> direct_caps_of s e\\<^sub>x \\<and>\n                                               Store \\<in> rights cap \\<and>\n                                               target cap = e\\<^sub>y}\"\n\ndefinition\n  store_connected :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"store_connected s \\<equiv> (store_connected_direct s)^*\"\n\ndefinition\n  (* returns all capabilities an entity has access to\n    (via store or directly) *)\n  caps_of :: \"state \\<Rightarrow> entity_id \\<Rightarrow> cap set\" where\n  \"caps_of s e  \\<equiv> \\<Union>(direct_caps_of s ` {e' . (e,e') \\<in> store_connected s})\"\n\nlemma caps_rel:\n  \"caps_of s e = \\<Union>(direct_caps_of s ` store_connected s `` {e})\"\n  by (simp add: caps_of_def Image_def)\n\ndefinition  (* All the different capabilities of the system *)\n  all_caps_of :: \"state \\<Rightarrow> cap set\" where\n  \"all_caps_of s \\<equiv> \\<Union>e. direct_caps_of s e\"\n\ndefinition\n  read_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"read_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Read}\\<rparr>\"\n\ndefinition\n  write_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"write_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Write}\\<rparr>\"\n\ndefinition\n  take_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"take_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Take}\\<rparr>\"\n\ndefinition\n  grant_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"grant_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Grant}\\<rparr>\"\n\ndefinition\n  create_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"create_cap e\\<^sub>x \\<equiv> \\<lparr>target = e\\<^sub>x, rights = {Create}\\<rparr>\"\n\ndefinition\n  store_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"store_cap e \\<equiv> \\<lparr>target = e, rights = {Store}\\<rparr>\"\n\ndefinition\n  full_cap :: \"entity_id \\<Rightarrow> cap\" where\n  \"full_cap e \\<equiv> \\<lparr>target = e, rights = all_rights \\<rparr>\"\n\n\n\n(* System operations: primitive kernel operations *)\n\ndatatype sysOPs =\n    SysCreate entity_id cap cap\n  | SysTake   entity_id cap cap mask\n  | SysGrant  entity_id cap cap mask\n  | SysCopy   entity_id cap cap mask\n  | SysRemove entity_id cap cap\n  | SysRemoveSet entity_id cap \"cap set\"\n  | SysRevoke entity_id cap\n  | SysDestroy entity_id cap\n\n\n(* determine if an operation is allowed in the given state_s *)\nprimrec\n  legal :: \"sysOPs \\<Rightarrow> state \\<Rightarrow> bool\"\nwhere\n  \"legal (SysCreate e c\\<^sub>1 c\\<^sub>2) s = (is_entity s e \\<and> is_entity s (target c\\<^sub>1) \\<and> \\<not> (is_entity s (target c\\<^sub>2)) \\<and>\n                                   {c\\<^sub>1, c\\<^sub>2} \\<subseteq> caps_of s e \\<and>\n                                   Write \\<in> rights c\\<^sub>1 \\<and> Store \\<in> rights c\\<^sub>1 \\<and> Create \\<in> rights c\\<^sub>2)\"\n\n| \"legal (SysTake  e c\\<^sub>1 c\\<^sub>2 r) s = (is_entity s e \\<and>  is_entity s (target c\\<^sub>1) \\<and>\n                                  c\\<^sub>1 \\<in> caps_of s e \\<and> c\\<^sub>2 \\<in> caps_of s (target c\\<^sub>1) \\<and> Take \\<in> rights c\\<^sub>1)\"\n\n| \"legal (SysGrant e c\\<^sub>1 c\\<^sub>2 r) s = (is_entity s e \\<and>  is_entity s (target c\\<^sub>1) \\<and>\n                                  {c\\<^sub>1,c\\<^sub>2} \\<subseteq> caps_of s e \\<and> Grant \\<in> rights c\\<^sub>1)\"\n\n| \"legal (SysCopy  e c\\<^sub>1 c\\<^sub>2 r) s   = (is_entity s e \\<and>  is_entity s (target c\\<^sub>1) \\<and>\n                                  {c\\<^sub>1,c\\<^sub>2} \\<subseteq> caps_of s e \\<and> Store \\<in> rights c\\<^sub>1)\"\n\n| \"legal (SysRemove e c\\<^sub>1 c\\<^sub>2) s = (is_entity s e \\<and> c\\<^sub>1 \\<in> caps_of s e)\"\n\n| \"legal (SysRemoveSet e c C) s = (is_entity s e \\<and> c \\<in> caps_of s e)\"\n\n| \"legal (SysRevoke e c) s = (is_entity s e \\<and> c \\<in> caps_of s e)\"\n\n| \"legal (SysDestroy e c) s = (is_entity s e \\<and> c \\<in> caps_of s e \\<and> {Create} = rights c \\<and>\n                              target c \\<notin> target ` (all_caps_of s - {c}))\"\n\n(* Following functions define how each of the sysOPs modifies the\n * system state_s\n *)\n\ndefinition\n  diminish :: \"right set \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"diminish R cap \\<equiv> cap \\<lparr> rights := rights cap \\<inter> R \\<rparr>\"\n\ndefinition\n  createOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"createOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (full_cap (target c\\<^sub>2))\n                                (direct_caps_of s (target c\\<^sub>1))),\n     target c\\<^sub>2 \\<mapsto> null_entity)\"\n\nlemma createOperation_def2:\n  \"createOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  let new_cap = \\<lparr> target = target c\\<^sub>2, rights = all_rights \\<rparr>;\n      newTarget = ({new_cap} \\<union> direct_caps_of s (target c\\<^sub>1) )\n  in\n  s (target c\\<^sub>1 \\<mapsto> Entity newTarget, target c\\<^sub>2 \\<mapsto> null_entity)\"\n  by (simp add: createOperation_def Let_def full_cap_def null_entity_def)\n\ndefinition\n  takeOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"takeOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (e \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s e)))\"\n\nlemma takeOperation_def2:\n  \"takeOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (e \\<mapsto> Entity ({diminish R c\\<^sub>2} \\<union> direct_caps_of s e))\"\n  by (clarsimp simp: takeOperation_def caps_of_def)\n\ndefinition\n  grantOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"grantOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s (target c\\<^sub>1)) )) \"\n\nlemma grantOperation_def2:\n  \"grantOperation e c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity ( {diminish R c\\<^sub>2} \\<union> direct_caps_of s (target c\\<^sub>1)))\"\n  by (clarsimp simp: grantOperation_def caps_of_def)\n\ndefinition\n  copyOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> right set \\<Rightarrow> modify_state\" where\n  \"copyOperation sRef c\\<^sub>1 c\\<^sub>2 R s \\<equiv>\n  s (target c\\<^sub>1 \\<mapsto> Entity (insert (diminish R c\\<^sub>2) (direct_caps_of s (target c\\<^sub>1)))) \"\n\ndefinition\n  removeOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"removeOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  if is_entity s (target c\\<^sub>1)\n  then\n     s ((target c\\<^sub>1) \\<mapsto> Entity ((direct_caps_of s (target c\\<^sub>1)) - {c\\<^sub>2} ))\n  else\n     s\"\n\nlemma removeOperation_simpler:\n  \"removeOperation e c\\<^sub>1 c\\<^sub>2 s \\<equiv>\n  (case s (target c\\<^sub>1) of\n    None \\<Rightarrow> s\n  | Some (Entity caps) \\<Rightarrow> s (target c\\<^sub>1 \\<mapsto> Entity (caps - {c\\<^sub>2})))\"\n  by (rule eq_reflection, simp add: removeOperation_def is_entity_def direct_caps_of_def\n                             split: if_split_asm option.splits)\n\ndefinition\n  removeSetOperation ::\n  \"entity_id \\<Rightarrow> cap \\<Rightarrow> cap set \\<Rightarrow> modify_state\" where\n  \"removeSetOperation e c C s \\<equiv>\n  if is_entity s (target c) then\n   s ((target c) \\<mapsto> Entity ((direct_caps_of s (target c)) - C ))\n  else\n   s\"\n\nlemma removeSetOperation_simpler:\n  \"removeSetOperation e c caps s \\<equiv>\n  (case s (target c) of\n    None \\<Rightarrow> s\n  | Some (Entity caps') \\<Rightarrow> s (target c \\<mapsto> Entity (caps' - caps)))\"\n  by (auto simp: removeSetOperation_def is_entity_def direct_caps_of_def\n         intro!: eq_reflection\n          split: if_split_asm option.splits)\n\nlemma removeSetOperation_fold_removeOperation:\n  \"removeSetOperation e c (set caps) s = fold (removeOperation e c) caps s\"\n  apply (subst foldr_fold [symmetric])\n   apply (fastforce simp: removeOperation_def direct_caps_of_def is_entity_def)\n  apply (rule sym)\n  apply (induct caps)\n   apply (fastforce simp: removeSetOperation_def removeOperation_def direct_caps_of_def is_entity_def)\n  apply (fastforce simp: removeSetOperation_def removeOperation_def direct_caps_of_def is_entity_def)\n  done\n\ndefinition\n  removeSetOfCaps :: \"(entity_id \\<Rightarrow> cap set) \\<Rightarrow> modify_state\"\nwhere\n  \"removeSetOfCaps cap_map s \\<equiv> \\<lambda>e.\n     if is_entity s e\n     then Some (Entity ((direct_caps_of s e) - cap_map e ))\n     else None\"\n\ndefinition\n  caps_to_entity :: \"entity_id \\<Rightarrow> entity_id \\<Rightarrow> state \\<Rightarrow> cap set\"\nwhere\n  \"caps_to_entity e e' s \\<equiv> {cap. cap \\<in> direct_caps_of s e' \\<and> target cap = e}\"\n\ndefinition\n  revokeOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> modify_state_n\" where\n  \"revokeOperation e c s \\<equiv>\n    {s'. \\<exists>cap_map. \\<forall>e'. cap_map e' \\<subseteq> caps_to_entity (target c) e' s \\<and>\n         s' = removeSetOfCaps cap_map s}\"\n\ndefinition\n  destroyOperation :: \"entity_id \\<Rightarrow> cap \\<Rightarrow> modify_state\" where\n  \"destroyOperation e c s \\<equiv> s(target c := None)\"\n\n\n(* Non deterministically executing system calls:\n * How we execute a single operation\n *)\nprimrec\n  step' :: \"sysOPs \\<Rightarrow> modify_state_n\"\nwhere\n  \"step' (SysCreate    e c\\<^sub>1 c\\<^sub>2) s   = {createOperation e c\\<^sub>1 c\\<^sub>2 s}\"\n| \"step' (SysTake      e c\\<^sub>1 c\\<^sub>2 R) s = {takeOperation  e c\\<^sub>1 c\\<^sub>2 R s}\"\n| \"step' (SysGrant     e c\\<^sub>1 c\\<^sub>2 R) s = {grantOperation  e c\\<^sub>1 c\\<^sub>2 R s}\"\n| \"step' (SysCopy      e c\\<^sub>1 c\\<^sub>2 R) s = {copyOperation e c\\<^sub>1 c\\<^sub>2 R s}\"\n| \"step' (SysRemove    e c\\<^sub>1 c\\<^sub>2)   s = {removeOperation e c\\<^sub>1 c\\<^sub>2 s}\"\n| \"step' (SysRemoveSet e c C)    s = {removeSetOperation e c C s}\"\n| \"step' (SysRevoke    e c) s      =  revokeOperation e c s\"\n| \"step' (SysDestroy   e c) s      = {destroyOperation e c s}\"\n\n(* single operation is allowed only if it is legal in the current state_s *)\ndefinition\n  step :: \"sysOPs \\<Rightarrow> modify_state_n\" where\n  \"step cmd s \\<equiv> if legal cmd s then (step' cmd s) \\<union> {s} else {s}\"\n\n(* execution of a list of commands (from back of list)\n *)\nprimrec\n  execute :: \"sysOPs list \\<Rightarrow> state \\<Rightarrow> state set\"\nwhere\n  \"execute [] s = {s}\"\n| \"execute (cmd#cmds) s = \\<Union> (step cmd ` ( execute cmds s ))\"\n\n\n\n(***************************\n * Lemmas about the model. *\n ***************************)\n\nlemma Int_all_rights [simp]: \"c \\<inter> all_rights = c\"\n  by (simp add: all_rights_def)\n\nlemma is_entity_dom: \"is_entity s e = (e \\<in> dom s)\"\n  by (simp add: is_entity_def dom_def)\n\nlemma is_entity_imp_not_None:\n  \"is_entity s e \\<Longrightarrow> s e \\<noteq> None\"\n  by (simp add: is_entity_def)\n\nlemma store_connected_refl [simp]:\n  \"(e, e) \\<in> store_connected s\"\n  by (simp add: store_connected_def)\n\nlemma no_caps_of_imp_not_connected [rule_format]:\n  \"\\<lbrakk>(e, x) \\<in> store_connected s\\<rbrakk>\n  \\<Longrightarrow> direct_caps_of s e = {} \\<longrightarrow> x = e\"\n  apply (unfold store_connected_def)\n  apply (erule rtrancl.induct)\n   apply simp\n  apply (clarsimp simp: store_connected_direct_def direct_caps_of_def)\n  done\n\nlemma no_direct_caps_of_no_caps_of:\n  \"(direct_caps_of s e = {}) = (caps_of s e = {})\"\n  apply (rule iffI)\n   apply (clarsimp simp add: caps_of_def)\n   apply (drule (1) no_caps_of_imp_not_connected)\n   apply simp\n  apply (clarsimp simp add: caps_of_def store_connected_def)\n  done\n\nlemma no_direct_caps_of_imp_no_caps_of:\n  \"direct_caps_of s e = {} \\<Longrightarrow> caps_of s e = {}\"\n  by (rule no_direct_caps_of_no_caps_of [THEN iffD1])\n\nlemma no_caps_of_imp_no_direct_caps_of:\n  \"caps_of s e = {} \\<Longrightarrow> direct_caps_of s e = {}\"\n  by (rule no_direct_caps_of_no_caps_of [THEN iffD2])\n\nlemma store_connected_direct_in_store_connected:\n  \"(x, y) \\<in> store_connected_direct s \\<Longrightarrow> (x, y) \\<in> store_connected s\"\n  by (simp add: store_connected_def)\n\nlemma no_diminish [simp]:\n  \"diminish all_rights c = c\"\n  by (simp add: diminish_def)\n\nlemma no_diminish_image [simp]:\n  \"diminish all_rights ` C = C\"\n  by (fastforce)\n\nlemma diminish_diminish [simp]:\n  \"diminish dimR2 (diminish dimR1 sc) = diminish (dimR1 \\<inter> dimR2) sc\"\n  by (clarsimp simp add: diminish_def Int_assoc)\n\nlemma diminish_range_diminish [simp]:\n  \"diminish dimR2 ` diminish dimR1 ` ssc = diminish (dimR1 \\<inter> dimR2) ` ssc\"\n  apply (rule set_eqI)\n  apply (rule iffI)\n   apply (clarsimp)\n  apply (clarsimp simp del: diminish_diminish simp add: diminish_diminish [symmetric])\n  done\n\nlemma execute_not_empty:\n  \"execute ops s \\<noteq> {}\"\n  apply (induct ops)\n   apply (simp)\n  apply (simp add: step_def del: if_image_distrib, fast)\n  done\n\nlemma execute_append [intro]:\n  \"\\<And> s s' s'' opsA. \\<lbrakk> s'' \\<in> execute opsA s; s' \\<in> execute opsB s'' \\<rbrakk> \\<Longrightarrow> s' \\<in> execute (opsB @ opsA) s\"\n  apply (induct opsB)\n   apply (simp)\n  apply (atomize)\n  apply (clarsimp)\n  apply (rule bexI)\n   apply (assumption)\n  by (drule spec | drule(1) mp)+\n\n(* Lemma on caps *)\n\nlemma heapAdd_read_cap [simp]:\n  \"target (read_cap e) = e\"\n  by (simp add: read_cap_def)\n\nlemma rights_read_cap [simp]:\n  \"rights (read_cap e) = {Read}\"\n  by (simp add: read_cap_def)\n\nlemma heapAdd_write_cap [simp]:\n  \"target (write_cap e) = e\"\n  by (simp add: write_cap_def)\n\nlemma rights_write_cap [simp]:\n  \"rights (write_cap e) = {Write}\"\n  by (simp add: write_cap_def)\n\nlemma heapAdd_take_cap [simp]:\n  \"target (take_cap e) = e\"\n  by (simp add: take_cap_def)\n\nlemma rights_take_cap [simp]:\n  \"rights (take_cap e) = {Take}\"\n  by (simp add: take_cap_def)\n\nlemma heapAdd_grant_cap [simp]:\n  \"target (grant_cap e) = e\"\n  by (simp add: grant_cap_def)\n\nlemma rights_grant_cap [simp]:\n  \"rights (grant_cap e) = {Grant}\"\n  by (simp add: grant_cap_def)\n\nlemma heapAdd_create_cap [simp]:\n  \"target (create_cap e) = e\"\n  by (simp add: create_cap_def)\n\nlemma rights_create_cap [simp]:\n  \"rights (create_cap e) = {Create}\"\n  by (simp add: create_cap_def)\n\nlemma heapAdd_store_cap [simp]:\n  \"target (store_cap e) = e\"\n  by (simp add: store_cap_def)\n\nlemma rights_store_cap [simp]:\n  \"rights (store_cap e) = {Store}\"\n  by (simp add: store_cap_def)\n\nlemma heapAdd_full_cap [simp]:\n  \"target (full_cap e) = e\"\n  by (simp add: full_cap_def)\n\nlemma rights_full_cap [simp]:\n  \"rights (full_cap e) = all_rights\"\n  by (simp add: full_cap_def)\n\nlemma entity_diminish [simp]:\n  \"target (diminish R c) = target c\"\n  by (simp add: diminish_def)\n\nlemma rights_diminish [simp]:\n  \"rights (diminish R c) = rights c \\<inter> R\"\n  by (simp add: diminish_def)\n\n(* Lemmas on caps_of *)\n\nlemma caps_of_imp_some_direct_cap:\n  \"c \\<in> caps_of s e \\<Longrightarrow> \\<exists>e'. c \\<in> direct_caps_of s e'\"\n  by (auto simp: caps_of_def)\n\nlemma caps_of_imp_some_store_connected_direct_cap:\n  \"c \\<in> caps_of s e \\<Longrightarrow> \\<exists>e'. (e, e') \\<in> store_connected s \\<and> c \\<in> direct_caps_of s e'\"\n  by (auto simp: caps_of_def)\n\nlemma direct_cap_in_cap:\n  \"c \\<in> direct_caps_of s e \\<Longrightarrow> c \\<in> caps_of s e\"\n  by (auto simp: caps_of_def store_connected_def)\n\nlemma all_caps_ofE [elim!]:\n  \"\\<lbrakk> c \\<in> all_caps_of s; \\<And>e'. c \\<in> direct_caps_of s e' \\<Longrightarrow> P \\<rbrakk> \\<Longrightarrow> P\"\n  by (fastforce simp add: all_caps_of_def)\n\nlemma all_caps_ofI [intro]:\n  \"c \\<in> direct_caps_of s e' \\<Longrightarrow> c \\<in> all_caps_of s\"\n  by (fastforce simp add: all_caps_of_def)\n\n(* Lemmas on entities *)\n\nlemma entity_not_not_entity:\n  \"\\<lbrakk>is_entity s e\\<^sub>1; \\<not> is_entity s e\\<^sub>2\\<rbrakk> \\<Longrightarrow> e\\<^sub>1 \\<noteq> e\\<^sub>2\"\n  by (auto simp: is_entity_def)\n\nlemma no_direct_caps_of_in_nonEntity:\n  \"\\<not> is_entity s e \\<Longrightarrow> direct_caps_of s e = {}\"\n  by (auto simp: direct_caps_of_def is_entity_def split:option.splits)\n\nlemma not_is_entity_imp_no_direct_caps_of:\n  \"\\<not> is_entity s e \\<Longrightarrow> caps_of s e = {}\"\n  by (drule no_direct_caps_of_in_nonEntity, erule no_direct_caps_of_imp_no_caps_of)\n\nlemma direct_caps_of_imp_is_entity:\n  \"c \\<in> direct_caps_of s e \\<Longrightarrow> is_entity s e\"\n  by (auto intro: classical dest: no_direct_caps_of_in_nonEntity)\n\nlemma caps_of_imp_is_entity:\n  \"c \\<in> caps_of s e \\<Longrightarrow> is_entity s e\"\n  by (auto intro: classical dest: not_is_entity_imp_no_direct_caps_of)\n\n(* Lemmas on store_connected *)\n\nlemma store_caps_of_store_connected_direct:\n  \"\\<lbrakk>c \\<in> direct_caps_of s e; Store \\<in> rights c\\<rbrakk>\n  \\<Longrightarrow> (e, target c) \\<in> store_connected_direct s\"\n  by (fastforce simp: store_connected_direct_def)\n\nlemma store_caps_store_connected:\n  \"\\<lbrakk>c \\<in> caps_of s e; Store \\<in> rights c\\<rbrakk> \\<Longrightarrow> (e, target c) \\<in> store_connected s\"\n  apply (clarsimp simp: store_connected_def caps_of_def)\n  by (frule (1) store_caps_of_store_connected_direct, simp)\n\nend"}
{"title": "./spec/take-grant/Islands_S.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Title:   Confinement_S\n * Description: Rephrasing of the confinement proof using the concept of islands.\n *)\n\ntheory Islands_S\nimports Confine_S\nbegin\n\ndefinition\n  island :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id set\" where\n  \"island s x \\<equiv> {e\\<^sub>i. s \\<turnstile> x \\<leftrightarrow>* e\\<^sub>i}\"\n\ndefinition\n  island_caps :: \"state \\<Rightarrow> entity_id \\<Rightarrow> cap set\" where\n  \"island_caps s x \\<equiv> \\<Union>(caps_of s ` island s x)\"\n\nlemma island_caps_def2:\n  \"island_caps s x \\<equiv> \\<Union> e \\<in> island s x. caps_of s e\"\n  by(simp add: island_caps_def)\n\nlemma island_caps_def3:\n  \"island_caps s x =  \\<Union>(direct_caps_of s ` island s x)\"\n  apply (clarsimp simp: island_caps_def)\n  apply rule\n   apply (clarsimp simp: island_def caps_of_def)\n   apply (drule store_connected_directly_tgs_connected)\n   apply (metis directly_tgs_connected_rtrancl_into_rtrancl)\n  apply (fastforce simp: caps_of_def store_connected_def)\n  done\n\nlemma island_caps_dom:\n  \"island_caps s e\\<^sub>x \\<le>cap c =\n  (\\<forall>e\\<^sub>i. (e\\<^sub>x, e\\<^sub>i) \\<in> tgs_connected s \\<longrightarrow> caps_of s e\\<^sub>i \\<le>cap c)\"\n  by (auto simp add: island_caps_def caps_dominated_by_def island_def)\n\nlemma authority_confinement_islands:\n  \"\\<lbrakk>s' \\<in> execute cmds s;\n    island_caps s x \\<le>cap c\\<rbrakk>\n  \\<Longrightarrow> island_caps s' x \\<le>cap c\"\n  apply (simp add: island_caps_dom)\n  apply clarsimp\n  apply (frule (1) tgs_connected_preserved)\n  apply (subst (asm) tgs_connected_comm_eq)\n  apply (erule authority_confinement)\n  apply clarsimp\n  apply (erule_tac x=e\\<^sub>i' in allE)\n  apply (erule impE)\n  apply (metis (opaque_lifting, no_types) tgs_connected_comm_eq tgs_connected_def rtrancl_trans)\n  apply clarsimp\n  done\n\nend"}
{"title": "./spec/take-grant/Isolation_S.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Isolation_S\nimports Islands_S\nbegin\n\ndefinition\n  set_flow :: \"state \\<Rightarrow> (entity_id set \\<times> entity_id set) set\" where\n  \"set_flow s \\<equiv> {(X,Y). \\<exists>x \\<in> X. \\<exists>y \\<in> Y.\n                        (read_cap x \\<in>cap caps_of s y \\<or>\n                        write_cap y \\<in>cap caps_of s x)}\"\n\nlemma set_flow_def2:\n  \"(X, Y) \\<in> set_flow s = (\\<exists>x \\<in> X. \\<exists>y \\<in> Y.\n                        (read_cap x \\<in>cap caps_of s y \\<or>\n                        write_cap y \\<in>cap caps_of s x))\"\n  by (simp add: set_flow_def)\n\ndefinition\n  flow :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" where\n  \"flow s \\<equiv>  {(x,y). (island s x, island s y) \\<in> set_flow s}\"\n\nlemma flow_def2:\n  \"(x, y) \\<in> flow s = ((island s x, island s y) \\<in> set_flow s)\"\n  by (simp add: flow_def)\n\n\nabbreviation\n  in_flow :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<leadsto> _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x \\<leadsto> y \\<equiv> (x,y) \\<in> flow s\"\n\ndefinition\n  flow_trans :: \"state \\<Rightarrow> (entity_id \\<times> entity_id) set\" (\"flow\\<^sup>*\") where\n  \"flow_trans s \\<equiv> (flow s)\\<^sup>*\"\n\nabbreviation\n  in_flow_trans :: \"state \\<Rightarrow> entity_id \\<Rightarrow> entity_id \\<Rightarrow> bool\" (\"_ \\<turnstile> _ \\<leadsto>* _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x \\<leadsto>* y == (x,y) \\<in> flow_trans s\"\n\nnotation (latex output)\n  in_flow_trans (\"_ \\<turnstile> _ \\<leadsto>\\<^sup>* _\" [60,0,60] 61)\n\ntranslations\n  \"\\<not> (s \\<turnstile> x \\<leadsto> y)\" <= \"(x,y) \\<notin> CONST flow s\"\n  \"\\<not> (s \\<turnstile> x \\<leadsto>* y)\" <= \"(x,y) \\<notin> CONST flow_trans s\"\n\n\n(* Proof *)\nlemma rights_extra_rights_read_cap [simp]:\n  \"rights (extra_rights (read_cap e)) = {Read}\"\n  by (simp add: rights_extra_rights)\n\nlemma rights_extra_rights_write_cap [simp]:\n  \"rights (extra_rights (write_cap e)) = {Write}\"\n  by (simp add: rights_extra_rights)\n\nlemma flow_trans_refl [simp]:\n  \"s \\<turnstile> x \\<leadsto>* x\"\n  by (metis flow_trans_def rtrancl.rtrancl_refl)\n\nlemma flow_connected_step:\n  \"\\<lbrakk>s' \\<turnstile> x \\<leadsto>* y; s' \\<in> step cmd s\\<rbrakk> \\<Longrightarrow>\n    s \\<turnstile> x \\<leadsto>* y\"\n  apply (erule rtrancl_induct [where r=\"flow s'\",\n                              simplified flow_trans_def[symmetric]])\n   apply simp\n  apply (subgoal_tac \"s \\<turnstile> y \\<leadsto> z\")\n   apply (fastforce simp: flow_trans_def rtrancl.rtrancl_into_rtrancl)\n  apply (clarsimp simp: flow_def island_def set_flow_def)\n  apply (frule_tac x=y in tgs_connected_preserved_step, simp)\n  apply (frule_tac x=z in tgs_connected_preserved_step, simp)\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (erule disjE)\n   apply clarsimp\n   apply (drule (1) caps_of_op)\n   apply (clarsimp simp: cap_in_caps_def)\n   apply (metis (no_types) tgs_connected_trans subsetD)\n  apply clarsimp\n  apply (drule (1) caps_of_op)\n  apply (clarsimp simp: cap_in_caps_def)\n  apply (metis (no_types) tgs_connected_trans subsetD)\n  done\n\nlemma flow_connected [rule_format]:\n  \"\\<forall>s'.  s' \\<in> execute cmds s \\<longrightarrow>\n    s' \\<turnstile> x \\<leadsto>* y \\<longrightarrow>\n    s \\<turnstile> x \\<leadsto>* y\"\n  apply (induct_tac cmds, simp)\n  apply clarsimp\n  apply (drule (1) flow_connected_step)\n  apply auto\n  done\n\nlemma information_flow:\n  \"\\<lbrakk>s' \\<in> execute cmds s;\n  \\<not> s \\<turnstile> x \\<leadsto>* y\\<rbrakk> \\<Longrightarrow>\n  \\<not> s' \\<turnstile> x \\<leadsto>* y\"\n  by (auto simp: flow_connected)\n\nend"}
{"title": "./spec/take-grant/Example.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Example\nimports System_S\nbegin\n\ndefinition \"id0 \\<equiv> 0\"\ndefinition  \"id1 \\<equiv> 1\"\ndefinition  \"id2 \\<equiv> 2\"\n\ndefinition \"e0 \\<equiv> Entity {\\<lparr> target = id1, rights = {Store}\\<rparr>}\"\ndefinition \"e1 \\<equiv> Entity {\\<lparr> target = id2, rights = {Grant}\\<rparr>}\"\ndefinition \"e2 \\<equiv> Entity {}\"\n\nlemmas id_defs = id0_def id1_def id2_def\nlemmas entity_defs = e0_def e1_def e2_def\n\ndefinition example_state :: \"state\" where\n\"example_state \\<equiv> [0 \\<mapsto> e0, 1 \\<mapsto> e1, 2 \\<mapsto> e2] \"\n\nlemma de0:\n  \"direct_caps_of example_state id0 =\n   {\\<lparr> target = id1, rights = {Store}\\<rparr>}\"\n  by (simp add: direct_caps_of_def example_state_def\n                id_defs entity_defs\n         split: option.splits)\n\nlemma de1:\n  \"direct_caps_of example_state id1 =\n   {\\<lparr> target = id2, rights = {Grant}\\<rparr>}\"\n  by (simp add: direct_caps_of_def example_state_def\n                id_defs entity_defs\n         split: option.splits)\n\nlemma de2: \"direct_caps_of example_state id2 = {}\"\n  by (simp add: direct_caps_of_def example_state_def\n                id_defs entity_defs\n         split: option.splits)\n\n\nlemma scd:\n  \"store_connected_direct example_state = {(id0,id1)}\"\n  by (auto simp: store_connected_direct_def direct_caps_of_def\n                 example_state_def id_defs entity_defs\n          split: if_split_asm option.splits\n           cong: conj_cong)\n\nlemma sc:\n  \"store_connected example_state = {(id0,id1)} \\<union> Id\"\n  apply simp\n  apply (rule equalityI)\n  apply (insert scd)\n   apply (simp add: store_connected_def)\n   apply clarsimp\n   apply (erule converse_rtranclE)\n    apply simp\n   apply clarsimp\n   apply (erule rtranclE)\n    apply simp\n   apply clarsimp\n  apply (fastforce simp: store_connected_def)\n  done\n\nlemma sc': \"store_connected example_state = Id \\<union> {(0,1)}\"\n  by (clarsimp simp: sc id_defs)\n\nlemma ce0:\n  \"caps_of example_state id0 =\n   {\\<lparr>target = id1, rights = {Store}\\<rparr>,\n    \\<lparr>target = id2, rights = {Grant}\\<rparr>}\"\n  by (fastforce simp: caps_of_def sc Collect_disj_eq de0 de1)\n\nlemma ce1:\n  \"caps_of example_state id1 =\n   {\\<lparr> target = id2, rights = {Grant}\\<rparr>}\"\n  apply (clarsimp simp: caps_of_def sc Collect_disj_eq de0 de1)\n  apply (simp add: id0_def id1_def)\n  done\n\nlemma ce2: \"caps_of example_state id2 = {}\"\n  apply (simp add: caps_of_def sc)\n  apply (rule allI)\n  apply (rule conjI)\n   apply (simp add: id0_def id2_def)\n  apply (simp add: de2)\n  done\n\nend"}
{"title": "./spec/design/skel/ObjectInstances_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Defines the instances of pspace_storable objects.\n*)\n\nchapter \"Storable Object Instances\"\n\ntheory ObjectInstances_H\nimports\n  Structures_H\n  State_H\n  PSpaceStorable_H\n  Config_H\nbegin\n\narch_requalify_consts (H)\n  VPtr\n  newContext\n\nlemma projectKO_eq2:\n  \"((obj,s') \\<in> fst (projectKO ko s)) = (projectKO_opt ko = Some obj \\<and> s' = s)\"\n  by (auto simp: projectKO_def fail_def return_def split: option.splits)\n\n\n\\<comment> \\<open>-----------------------------------\\<close>\n\ninstantiation endpoint :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_ep:\n  \"projectKO_opt e \\<equiv> case e of KOEndpoint e \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_ep [simp]:\n  \"injectKO e \\<equiv> KOEndpoint e\"\n\ndefinition\n  koType_ep [simp]:\n  \"koType (t::endpoint itself) \\<equiv> EndpointT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_ep split: kernel_object.splits)\n\nend\n\ninstantiation notification :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_ntfn:\n  \"projectKO_opt e \\<equiv> case e of KONotification e \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_ntfn [simp]:\n  \"injectKO e \\<equiv> KONotification e\"\n\ndefinition\n  koType_ntfn [simp]:\n  \"koType (t::notification itself) \\<equiv> NotificationT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_ntfn split: kernel_object.splits)\n\nend\n\n\ninstantiation cte :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_cte:\n  \"projectKO_opt e \\<equiv> case e of KOCTE e \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_cte [simp]:\n  \"injectKO c \\<equiv> KOCTE c\"\n\ndefinition\n  koType_cte [simp]:\n  \"koType (t::cte itself) \\<equiv> CTET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_cte split: kernel_object.splits)\n\nend\n\ninstantiation user_data_device :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_user_data_device:\n  \"projectKO_opt e \\<equiv> case e of KOUserDataDevice \\<Rightarrow> Some UserDataDevice | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_user_data_device [simp]:\n  \"injectKO (t :: user_data_device) \\<equiv> KOUserDataDevice\"\n\ndefinition\n  koType_user_data_device [simp]:\n  \"koType (t::user_data_device itself) \\<equiv> UserDataDeviceT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_user_data_device split: kernel_object.splits)\nend\n\ninstantiation user_data :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_user_data:\n  \"projectKO_opt e \\<equiv> case e of KOUserData \\<Rightarrow> Some UserData | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_user_data [simp]:\n  \"injectKO (t :: user_data) \\<equiv> KOUserData\"\n\ndefinition\n  koType_user_data [simp]:\n  \"koType (t::user_data itself) \\<equiv> UserDataT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_user_data split: kernel_object.splits)\n\nend\n\n\ninstantiation tcb :: pre_storable\nbegin\n\ndefinition\n  projectKO_opt_tcb:\n  \"projectKO_opt e \\<equiv> case e of KOTCB e \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_tcb [simp]:\n  \"injectKO t \\<equiv> KOTCB t\"\n\ndefinition\n  koType_tcb [simp]:\n  \"koType (t::tcb itself) \\<equiv> TCBT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_tcb split: kernel_object.splits)\n\nend\n\n\nlemmas projectKO_opts_defs =\n  projectKO_opt_tcb projectKO_opt_cte projectKO_opt_ntfn projectKO_opt_ep\n  projectKO_opt_user_data projectKO_opt_user_data_device\n\nlemmas injectKO_defs =\n  injectKO_tcb injectKO_cte injectKO_ntfn injectKO_ep injectKO_user_data injectKO_user_data_device\n\nlemmas koType_defs =\n  koType_tcb koType_cte koType_ntfn koType_ep koType_user_data koType_user_data_device\n\n\\<comment> \\<open>-----------------------------------\\<close>\n\ninstantiation endpoint :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY Endpoint\n\ninstance\n  apply (intro_classes)\n  apply simp\n  apply (case_tac ko, auto simp: projectKO_opt_ep updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\ninstantiation notification :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY Notification\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_ntfn updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\ninstantiation cte :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY CTE\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_cte updateObject_cte\n                                 in_monad projectKO_eq2 typeError_def alignError_def\n                           split: kernel_object.splits if_split_asm)\n  done\n\nend\n\n\ninstantiation user_data :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY UserData\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_user_data updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\ninstantiation user_data_device :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY UserDataDevice\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_user_data_device updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\ninstantiation tcb :: pspace_storable\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Instances.lhs instanceproofs bodies_only ONLY TCB\n\ninstance\n  apply (intro_classes)\n  apply (case_tac ko, auto simp: projectKO_opt_tcb updateObject_default_def\n                                 in_monad projectKO_eq2\n                           split: kernel_object.splits)\n  done\n\nend\n\n\nend"}
{"title": "./spec/design/skel/InvocationLabels_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Kernel Invocation Labels\"\n\ntheory InvocationLabels_H\nimports ArchInvocationLabels_H\nbegin\n\ntext \\<open>\n  An enumeration of all system call labels.\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels.lhs ArchLabels= ONLY GenInvocationLabels InvocationLabel\n#INCLUDE_HASKELL SEL4/API/InvocationLabels.lhs instanceproofs\n\nend"}
{"title": "./spec/design/skel/PSpaceStorable_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory PSpaceStorable_H\nimports\n  Structures_H\n  KernelStateData_H\n  \"Lib.DataMap\"\nbegin\n\narch_requalify_types (H)\n  arch_kernel_object_type\n\narch_requalify_consts (H)\n  archTypeOf\n\nlemma UserData_singleton [simp]:\n  \"(v = UserData) = True\" \"(UserData = v) = True\"\n  by (cases v, simp)+\n\nlemma UserDataDevice_singleton [simp]:\n  \"(v = UserDataDevice) = True\" \"(UserDataDevice = v) = True\"\n  by (cases v, simp)+\n\ndatatype\n  kernel_object_type =\n    EndpointT\n  | NotificationT\n  | CTET\n  | TCBT\n  | UserDataT\n  | UserDataDeviceT\n  | KernelDataT\n  | ArchT arch_kernel_object_type\n\nprimrec\n  koTypeOf :: \"kernel_object \\<Rightarrow> kernel_object_type\"\nwhere\n  \"koTypeOf (KOEndpoint e) = EndpointT\"\n| \"koTypeOf (KONotification e) = NotificationT\"\n| \"koTypeOf (KOCTE e) = CTET\"\n| \"koTypeOf (KOTCB e) = TCBT\"\n| \"koTypeOf (KOUserData) = UserDataT\"\n| \"koTypeOf (KOUserDataDevice) = UserDataDeviceT\"\n| \"koTypeOf (KOKernelData) = KernelDataT\"\n| \"koTypeOf (KOArch e) = ArchT (archTypeOf e)\"\n\ndefinition\n  typeError :: \"unit list \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\" where\n  \"typeError t1 t2 \\<equiv> fail\"\n\ndefinition\n  alignError :: \"nat \\<Rightarrow> 'a kernel\" where\n  \"alignError n \\<equiv> fail\"\n\ndefinition\n  alignCheck :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> unit kernel\" where\n  \"alignCheck x n \\<equiv> unless ((x && mask n) = 0) $ alignError n\"\n\ndefinition\n  magnitudeCheck :: \"machine_word \\<Rightarrow> machine_word option \\<Rightarrow> nat \\<Rightarrow> unit kernel\"\nwhere\n \"magnitudeCheck x y n \\<equiv> case y of None \\<Rightarrow> return ()\n               | Some z \\<Rightarrow> when (z - x < 1 << n) fail\"\n\nclass pre_storable =\n  fixes injectKO :: \"'a \\<Rightarrow> kernel_object\"\n  fixes projectKO_opt :: \"kernel_object \\<Rightarrow> 'a option\"\n  fixes koType :: \"'a itself \\<Rightarrow> kernel_object_type\"\n\n  assumes project_inject: \"(projectKO_opt ko = Some v) = (injectKO v = ko)\"\n  assumes project_koType: \"(\\<exists>v. projectKO_opt ko = Some (v::'a)) = (koTypeOf ko = koType TYPE('a))\"\nbegin\n\ndefinition\n  projectKO :: \"kernel_object \\<Rightarrow> 'a kernel\"\nwhere\n  \"projectKO e \\<equiv>\n  case projectKO_opt e of None \\<Rightarrow> fail | Some k \\<Rightarrow> return k\"\n\ndefinition\n  objBits :: \"'a \\<Rightarrow> nat\"\nwhere\n  \"objBits v \\<equiv> objBitsKO (injectKO v)\"\n\ndefinition\n  loadObject_default :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\"\nwhere\n  \"loadObject_default ptr ptr' next obj \\<equiv> do\n     assert (ptr = ptr');\n     val \\<leftarrow> projectKO obj;\n     alignCheck ptr (objBits val);\n     magnitudeCheck ptr next (objBits val);\n     return val\n  od\"\n\ndefinition\n  updateObject_default :: \"'a \\<Rightarrow> kernel_object \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object kernel\"\nwhere\n  \"updateObject_default val oldObj ptr ptr' next \\<equiv> do\n     assert (ptr = ptr');\n     (_ :: 'a) \\<leftarrow> projectKO oldObj;\n     alignCheck ptr (objBits val);\n     magnitudeCheck ptr next (objBits val);\n     return (injectKO val)\n  od\"\n\nend\n\nclass pspace_storable = pre_storable +\n  fixes makeObject :: 'a\n\n  \\<comment>\\<open>\n    `loadObject` is only used in the generic definition of `getObject`. It\n    describes how to extract a value of type `'a` from memory.\n\n    If `(obj, _) \\<in> loadObjext p before after ko` within `getObject`, then:\n      - @{term \"p :: machine_word\"} is the addres that we want to read an\n        instance of `'a` from.\n      - @{term \"before :: machine_word\"} is the address of the nearest\n        object at or before `p`.\n      - @{term \"after :: machine_word option\"} is the address of the nearest\n        object after `p`, if any (for checking overlap).\n      - @{term \"ko :: kernel_object\"} is the object currently at `before`.\n      - @{term \"obj :: 'a\"} is the value extracted from `ko`.\n\n    Graphically, the \"memory\" looks like this:\n\n    before  p              after\n    |-------|--+-----+-----|---|\n    |       +~~+ <---+---------- The span of obj, the object we want to extract.\n    +~~~~~~~~~~~~~~~~+ <-------- The span of ko, the existing object that spans obj.\n\n                           +~~~+ The span of whatever object comes after obj.\n                                 We don't care about this beyond making sure\n                                 it doesn't overlap with ko.\n\n    In almost every case, the object in memory (ko) is the same type of object\n    as the one being loaded (obj). For example, for a reply object our parameters\n    look like this:\n\n    p, before\n    |-----------|\n    +~~~~~~~~~~~+ <- The span of two objects:\n                     - ko, the existing object (which should be a reply object).\n                     - obj, the object that we want to load from memory. This will\n                       just be ko projected through @{term projectKO}.\n\n    In these simple cases, @{term loadObject_default} is a good specification\n    for how to load an instance of `'a` from memory.\n\n    The only interesting case is when we're loading a CTE, which might be\n    inside a TCB. Then memory looks like this:\n\n    before  p\n    |-------|--+-----+\n    |       +~~+ <---+---- The span of obj, i.e. the CTE which we're reading from\n    |                |     memory.\n    +~~~~~~~~~~~~~~~~+ <-- The span of ko, i.e. the TCB surrounding and containing\n                           obj.\n\n    In this case, the process for extracting the CTE from the surrounding TCB\n    is more involved. See `loadObject_cte` in `ObjectInstances_H`.\n  \\<close>\n  fixes loadObject :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word option \\<Rightarrow> kernel_object \\<Rightarrow> 'a kernel\"\n\n  \\<comment>\\<open>\n    `updateObject` is only used in the generic definition of `setObject`,\n    but it shows up in a few lemma statements as well. It describes how to update\n    the kernel object contents of memory depending on what's already in that\n    memory.\n\n    If `(ko', _) \\<in> updateObject v ko p before after s` within `setObject`, then:\n      - @{term \"v :: 'a\"} is the new object you want to write at pointer\n        @{term \"p :: machine_word\"}.\n      - @{term \"before :: machine_word\"} is the address of the nearest\n        object at or before `p`.\n      - @{term \"ko :: kernel_object\"} is the object currently at `before`.\n      - @{term \"after :: machine_word option\"} should be the address of the nearest\n        object after `p`, if any (for checking overlap).\n      - The returned value @{term \"ko' :: kernel_object\"} is the old object `ko`,\n        updated as required by `v`. This value gets inserted by `setObject` into\n        memory at the address `before`.\n\n    Graphically, the \"memory\" looks like this:\n\n    before  p              after\n    |-------|--+-----+-----|---|\n    |       +~~+ <---+---------- The span of v, the object we want to insert.\n    +~~~~~~~~~~~~~~~~+ <-------- The span of ko, the existing object that spans v.\n                                 This is also the span of ko', which will be what\n                                 gets put into memory after the update.\n\n                           +~~~+ The span of whatever object comes after ko.\n                                 We don't care about this beyond making sure\n                                 it doesn't overlap with ko before or after it\n                                 gets updated with v.\n\n    In almost every case, the object in memory (ko) is the same type of object\n    as the one being inserted (v). For example, for a reply object our parameters\n    look like this:\n\n    p, before\n    |-----------|\n    +~~~~~~~~~~~+ <- The span of three objects:\n                     - v, the new reply object we want to insert.\n                     - ko, the existing object (which should be a reply object).\n                     - ko', the new object (which should be a reply object if\n                       the previous one was).\n\n    In these simple cases, @{term updateObject_default} is a good specification\n    for how to update the existing kernel object.\n\n    The only interesting case is when we're updating a CTE, which might be\n    inside a TCB. Then memory looks like this:\n\n    before  p\n    |-------|--+-----+\n    |       +~~+ <---+---- The span of v, i.e. the CTE which we're inserting into\n    |                |     memory.\n    +~~~~~~~~~~~~~~~~+ <-- The span of ko, i.e. the TCB surrounding and containing v.\n                           This is also the span of ko', which is \"just\" a copy\n                           of ko with the relevant CTE updated.\n\n    In this case, the process for updating the surrounding TCB is more involved.\n    See `updateObject_cte` in `ObjectInstances_H`.\n  \\<close>\n  fixes updateObject :: \"'a \\<Rightarrow> kernel_object \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow>\n                              machine_word option \\<Rightarrow> kernel_object kernel\"\n\n  \\<comment>\\<open>\n    If updating an object succeeds, then the type of the updated object (ko')\n    should be the same as the original object (ko).\n  \\<close>\n  assumes updateObject_type:\n  \"(ko', s') \\<in> fst (updateObject v ko p p' p'' s) \\<Longrightarrow> koTypeOf ko' = koTypeOf ko\"\n\nend"}
{"title": "./spec/design/skel/CNode_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"CNodes\"\n\ntheory CNode_H\nimports\n  FaultMonad_H\n  ThreadDecls_H\n  RetypeDecls_H\n  TCBDecls_H\n  CSpaceDecls_H\n  EndpointDecls_H\n  PSpaceFuns_H\nbegin\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs decls_only NOT cteRevoke\n\nfunction\n  cteRevoke :: \"machine_word \\<Rightarrow> unit kernel_p\"\nwhere\n \"cteRevoke p s =\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteRevoke\n\n  p s\"\nby auto\n\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs bodies_only NOT finaliseSlot cteRevoke cteDeleteOne noReplyCapsFor\n\nend"}
{"title": "./spec/design/skel/InterruptDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory InterruptDecls_H\nimports\n  RetypeDecls_H\n  KI_Decls_H\nbegin\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n#INCLUDE_HASKELL SEL4/Object/Interrupt.lhs Arch=ArchInterrupt_H decls_only NOT deletedIRQHandler\n\nend"}
{"title": "./spec/design/skel/CSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"CSpace\"\n\ntheory CSpace_H\nimports CSpaceDecls_H Object_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/CSpace.lhs bodies_only NOT resolveAddressBits\n\n\nfunction\n  resolveAddressBits ::\n  \"capability \\<Rightarrow> cptr \\<Rightarrow> nat \\<Rightarrow>\n   (lookup_failure, (machine_word * nat)) kernel_f\"\nwhere\n \"resolveAddressBits a b c =\n#INCLUDE_HASKELL SEL4/Kernel/CSpace.lhs BODY resolveAddressBits\na b c\"\n  by auto\n\ntermination\n  apply (relation \"measure (snd o snd)\")\n  apply (auto simp add: in_monad split: if_split_asm)\n  done\n\ndefs\n  resolveAddressBits_decl_def:\n  \"CSpaceDecls_H.resolveAddressBits \\<equiv> resolveAddressBits\"\ndeclare resolveAddressBits_decl_def[simp]\n\nend"}
{"title": "./spec/design/skel/PSpaceStruct_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Physical Memory Structure\"\n\ntheory PSpaceStruct_H\nimports\n  Structures_H\n  \"Lib.DataMap\"\nbegin\n\ntext \\<open>Helper Functions\\<close>\n\ndefinition\n  ptrBits_def[simp]:\n \"ptrBits \\<equiv> to_bl\"\n\n#INCLUDE_HASKELL SEL4/Model/PSpace.lhs ONLY ptrBitsForSize\n\ntext \\<open>Physical Memory Structures\\<close>\n\n#INCLUDE_HASKELL SEL4/Model/PSpace.lhs Data.Map=DataMap ONLY PSpace\n\nend"}
{"title": "./spec/design/skel/ThreadDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\n  ArchThreadDecls_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs decls_only NOT transferCapsToSlots\n\nend"}
{"title": "./spec/design/skel/Fault_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    The fault datatype.\n*)\n\nchapter \"Fault Structures\"\n\ntheory Fault_H\nimports ArchFault_H\nbegin\n\narch_requalify_types (H)\n  arch_fault\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Types.lhs\n#INCLUDE_HASKELL SEL4/API/Failures.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Failures.lhs bodies_only\n\nend"}
{"title": "./spec/design/skel/RetypeDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Function Declarations for Retyping Objects\"\n\ntheory RetypeDecls_H\nimports\n  ArchRetypeDecls_H\n  Structures_H\n  FaultMonad_H\n  Invocations_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType.lhs decls_only\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt.lhs decls_only ONLY deletedIRQHandler\n\nend"}
{"title": "./spec/design/skel/Object_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Kernel Objects\"\n\ntheory Object_H\nimports\n  Notification_H\n  Endpoint_H\n  Retype_H\nbegin\n\ntext \\<open>\n  this theory collects the SEL4.Model.* modules\n\\<close>\n\nend"}
{"title": "./spec/design/skel/Thread_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Threads\"\n\ntheory Thread_H\nimports\n  ThreadDecls_H\n  CSpace_H\n  ArchThread_H\n  FaultHandler_H\n  Config_H\nbegin\n\narch_requalify_consts (H)\n  capRegister\n  faultRegister\n  nextInstructionRegister\n\ncontext Arch begin\n\n(* match Haskell, expects these under Arch. *)\nrequalify_consts\n  activateIdleThread\n\n(* disambiguate name clash between Arch and non-arch consts with same names *)\nrequalify_consts (aliasing)\n  configureIdleThread\n  switchToIdleThread\n  switchToThread\n\ncontext begin global_naming global\n\nrequalify_consts (aliasing)\n  ThreadDecls_H.configureIdleThread\n  ThreadDecls_H.switchToIdleThread\n  ThreadDecls_H.switchToThread\n\nend\nend\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs Arch=Arch bodies_only NOT doNormalTransfer doIPCTransfer doReplyTransfer doNormalTransfer transferCaps transferCapsToSlots\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs Arch=Arch ONLY transferCapsToSlots\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs Arch=Arch bodies_only ONLY doNormalTransfer doIPCTransfer doReplyTransfer doNormalTransfer transferCaps\n\nend"}
{"title": "./spec/design/skel/NotificationDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Function Declarations for Notifications\"\n\ntheory NotificationDecls_H imports    \"FaultMonad_H\"\n begin\n\n#INCLUDE_HASKELL SEL4/Object/Notification.lhs decls_only\n\nend"}
{"title": "./spec/design/skel/Delete_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Deleting Capabilities\"\n\ntheory Delete_H\nimports\n  CNode_H\n  Interrupt_H\n  Endpoint_H\n  Thread_H\nbegin\n\ndefinition\n  slotsPointed :: \"capability \\<Rightarrow> machine_word set\"\nwhere\n \"slotsPointed cap \\<equiv> case cap of\n   CNodeCap ptr a b c   \\<Rightarrow> {ptr}\n | ThreadCap ptr        \\<Rightarrow> {ptr}\n | Zombie ptr bits num  \\<Rightarrow> {ptr}\n | _                    \\<Rightarrow> {}\"\n\nprimrec\n  sethelper :: \"bool \\<Rightarrow> 'a set \\<Rightarrow> 'a set\"\nwhere\n  \"sethelper True  s = {}\"\n| \"sethelper False s = s\"\n\nfunction\n  finaliseSlot' :: \"machine_word \\<Rightarrow> bool \\<Rightarrow> (bool * capability) kernel_p\"\nwhere\n \"finaliseSlot' x b s =\n(\\<lambda> finaliseSlot.\n(\\<lambda> cteDelete.\n(\\<lambda> reduceZombie.\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY finaliseSlot\n)\n(\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY reduceZombie\n)\n)\n(\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteDelete\n)\n)\nfinaliseSlot' x b s\"\n\n  by auto\n\ndefs\n  finaliseSlot_def:\n \"finaliseSlot \\<equiv> finaliseSlot'\"\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n\nfunction\n  cteDeleteOne' :: \"machine_word \\<Rightarrow> unit kernel\"\nwhere\n \"cteDeleteOne' x s =\n(\\<lambda> cteDeleteOne.\n(\\<lambda> deletingIRQHandler.\n(\\<lambda> cancelIPC.\n(\\<lambda> suspend.\n(\\<lambda> finaliseCap.\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteDeleteOne\n)\n(\n#INCLUDE_HASKELL SEL4/Object/ObjectType.lhs Arch=Arch BODY finaliseCap\n)\n)\n(\n#INCLUDE_HASKELL SEL4/Kernel/Thread.lhs BODY suspend\n)\n)\n(\n#INCLUDE_HASKELL SEL4/Object/Endpoint.lhs BODY cancelIPC\n)\n)\n(\n#INCLUDE_HASKELL SEL4/Object/Interrupt.lhs BODY deletingIRQHandler\n)\n)\ncteDeleteOne' x s\"\n\n  by auto\n\ndefs\n  cteDeleteOne_def1:\n \"cteDeleteOne \\<equiv> cteDeleteOne'\"\n\ntermination cteDeleteOne'\n  by (rule cteDeleteOne'.termination[OF wf_empty], simp+)\n\nlemma cteDeleteOne_def:\n \"cteDeleteOne =\n(\n#INCLUDE_HASKELL SEL4/Object/CNode.lhs BODY cteDeleteOne\n)\"\n  apply (rule ext)+\n  apply (subst cteDeleteOne_def1)\n  apply (subst cteDeleteOne'.simps)\n  apply (unfold finaliseCap_def suspend_def cancelIPC_def\n                deletingIRQHandler_def cteDeleteOne_def1)\n  apply (rule refl)\n  done\n\nlemma card_reduce:\n  \"(s :: ('a :: finite) set) \\<inter> s' = {} \\<Longrightarrow> card (UNIV - (s \\<union> s')) < card (UNIV - s) = (s' \\<noteq> {})\"\n  apply (case_tac \"s' \\<subseteq> s\")\n   apply (simp add: Un_absorb2)\n   apply (simp add: Int_absorb1)\n  apply (clarsimp simp: subset_iff)\n  apply (subst psubset_card_mono)\n    apply simp\n   apply blast\n  apply blast\n  done\n\nlemma isCapDs:\n  \"isUntypedCap cap \\<Longrightarrow> \\<exists>dev ptr size freeIndex. cap = UntypedCap dev ptr size freeIndex\"\n  \"isEndpointCap cap \\<Longrightarrow> \\<exists>ptr bdg cans canr cang cangr. cap = EndpointCap ptr bdg cans canr cang cangr\"\n  \"isNotificationCap cap \\<Longrightarrow> \\<exists>ptr bdg cans canr. cap = NotificationCap ptr bdg cans canr\"\n  \"isCNodeCap cap \\<Longrightarrow> \\<exists>ptr bits grd gsize. cap = CNodeCap ptr bits grd gsize\"\n  \"isThreadCap cap \\<Longrightarrow> \\<exists>ptr. cap = ThreadCap ptr\"\n  \"isArchObjectCap cap \\<Longrightarrow> \\<exists>archcap. cap = ArchObjectCap archcap\"\n  \"isZombie cap \\<Longrightarrow> \\<exists>ptr bits num. cap = Zombie ptr bits num\"\n  apply (case_tac cap, simp_all add: isUntypedCap_def)\n  apply (case_tac cap, simp_all add: isEndpointCap_def)\n  apply (case_tac cap, simp_all add: isNotificationCap_def)\n  apply (case_tac cap, simp_all add: isCNodeCap_def)\n  apply (case_tac cap, simp_all add: isThreadCap_def)\n  apply (case_tac cap, simp_all add: isArchObjectCap_def)\n  apply (case_tac cap, simp_all add: isZombie_def)\n  done\n\nend"}
{"title": "./spec/design/skel/Hypervisor_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Hypervisor code.\n*)\n\ntheory Hypervisor_H\nimports\n  CNode_H\n  ArchHypervisor_H\n  KernelInitMonad_H\nbegin\n\narch_requalify_consts (H)\n  handleHypervisorFault\n\nend"}
{"title": "./spec/design/skel/Invocations_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Invocations_H\nimports\n  Structures_H\n  ArchRetypeDecls_H\n  ArchLabelFuns_H\nbegin\n\n(* Haskell expects these with Arch prefix *)\nrequalify_types (in Arch)\n  copy_register_sets irqcontrol_invocation\n  invocation\n\n#INCLUDE_HASKELL SEL4/API/Invocation.lhs Arch=Arch NOT GenInvocationLabels InvocationLabel\n#INCLUDE_HASKELL SEL4/API/InvocationLabels.lhs ONLY invocationType genInvocationType\n\n(* disambiguate name clash between Arch and non-arch consts with same names *)\ncontext Arch begin\ncontext begin global_naming global\nrequalify_types (aliasing)\n  Invocations_H.invocation\nend\nend\n\nend"}
{"title": "./spec/design/skel/Types_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n   Types visible in the API.\n*)\n\nchapter \"Types visible in the API\"\n\ntheory Types_H\nimports\n  MachineExports\n  ArchTypes_H\nbegin\n\narch_requalify_types (H)\n  object_type\n  paddr\n  vptr\n\narch_requalify_consts (H)\n  getObjectSize\n  fromAPIType\n  toAPIType\n  isFrameType\n  pageType\n  tcbBlockSizeBits\n\narch_requalify_facts (H)\n  tcbBlockSizeBits_def\n\n#INCLUDE_HASKELL SEL4/API/Types.lhs all_bits NOT wordsFromBootInfo messageInfoFromWord wordFromMessageInfo ObjectType getObjectSize fromAPIType toAPIType isFrameType pageType\n#INCLUDE_HASKELL SEL4/API/Types.lhs all_bits ONLY wordsFromBootInfo messageInfoFromWord wordFromMessageInfo\n\nend"}
{"title": "./spec/design/skel/KernelInitMonad_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Kernel Init Monad\"\n\ntheory KernelInitMonad_H\nimports KernelStateData_H Types_H Fault_H\nbegin\n\ntext \\<open>This is a similar way of getting around StateT as with the kernel\nstate, we add an extra field to the record that Haskell expects to store the\ninner monad state.\\<close>\n\nrecord init_data =\n  initFreeMemory   :: \"region list\"\n  initSlotPosCur :: \"machine_word\"\n  initSlotPosMax   :: \"machine_word\"\n  initBootInfo    :: \"biframe_data\"\n  initBootInfoFrame       :: paddr\n  initKernelState :: kernel_state\n\ntype_synonym 'a kernel_init_state = \"(init_data, 'a) nondet_monad\"\n\ntranslations\n  (type) \"'c kernel_init_state\" <= (type) \"(init_data, 'c) nondet_monad\"\n\ntype_synonym 'a kernel_init = \"(init_failure + 'a) kernel_init_state\"\n\ntranslations\n  (type) \"'a kernel_init\" <= (type) \"(init_failure + 'a) kernel_init\"\n\ndefinition\n  noInitFailure :: \"'a kernel_init_state \\<Rightarrow> 'a kernel_init\"\nwhere\n  noInitFailure_def[simp]:\n  \"noInitFailure \\<equiv> liftE\"\n\n\n\ndefinition\n  doKernelOp :: \"'a kernel \\<Rightarrow> 'a kernel_init\"\nwhere\n \"doKernelOp kop \\<equiv> doE\n    ms \\<leftarrow> liftE $ gets initKernelState;\n    (r, ms') \\<leftarrow> liftE $ select_f (kop ms);\n    liftE $ modify (\\<lambda>ks. ks \\<lparr> initKernelState := ms' \\<rparr>);\n    returnOk r\n  odE\"\n\nconsts\n  itASID :: asid\n  biCapNull :: machine_word\n  biCapITTCB :: machine_word\n  biCapITCNode :: machine_word\n  biCapITPD :: machine_word\n  biCapIRQControl :: machine_word\n  biCapASIDControl :: machine_word\n  biCapITASIDPool :: machine_word\n  biCapIOPort :: machine_word\n  biCapIOSpace :: machine_word\n  biCapBIFrame :: machine_word\n  biCapITIPCBuf :: machine_word\n  biCapDynStart :: machine_word\n  biFrameSizeBits :: nat\n  nopBIFrameData :: biframe_data\n\ndefinition\n  runInit :: \"machine_word \\<Rightarrow> 'a kernel_init \\<Rightarrow> 'b kernel\"\nwhere\n  \"runInit initOffset doInit \\<equiv> do\n    ks \\<leftarrow> get;\n    initData \\<leftarrow> return \\<lparr> initFreeMemory = [],\n                   initSlotPosCur = 0,\n                   initSlotPosMax = bit (pageBits),\n                   initBootInfo = nopBIFrameData,\n                   initBootInfoFrame = 0,\n                   initKernelState = ks \\<rparr>;\n    (ret, initData') \\<leftarrow> select_f (doInit initData);\n    (case ret of\n      Inr a \\<Rightarrow> fail\n    | Inl _ \\<Rightarrow> fail)\n  od\"\n\nend"}
{"title": "./spec/design/skel/PSpaceFuns_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Physical Memory Functions\"\n\ntheory PSpaceFuns_H\nimports\n  ObjectInstances_H\n  FaultMonad_H\n  ArchPSpace_H\n  \"Lib.DataMap\"\nbegin\n\n(* Haskell expects this with Arch prefix *)\nrequalify_consts (in Arch)\n  deleteGhost\n\ndefinition deleteRange :: \"( machine_word , 'a ) DataMap.map \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> ( machine_word , 'a ) DataMap.map\"\nwhere \"deleteRange m ptr bits \\<equiv>\n        let inRange = (\\<lambda> x. x && ((- mask bits) - 1) = fromPPtr ptr) in\n        data_map_filterWithKey (\\<lambda> x _. Not (inRange x)) m\"\n\n#INCLUDE_HASKELL SEL4/Model/PSpace.lhs decls_only Data.Map=DataMap NOT PSpace ptrBits ptrBitsForSize lookupAround maybeToMonad lookupAround2 typeError alignError alignCheck sizeCheck objBits deleteRange\n\nconsts\nlookupAround2 :: \"('k :: {linorder,finite}) \\<Rightarrow> ( 'k , 'a ) DataMap.map \\<Rightarrow> (('k * 'a) option * 'k option)\"\n\n#INCLUDE_HASKELL SEL4/Model/PSpace.lhs bodies_only Data.Map=DataMap NOT PSpace ptrBits ptrBitsForSize lookupAround maybeToMonad typeError alignError alignCheck sizeCheck objBits deletionIsSafe deletionIsSafe_delete_locale cNodePartialOverlap pointerInUserData ksASIDMapSafe deleteRange\n\nend"}
{"title": "./spec/design/skel/Intermediate_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Intermediate\"\n\ntheory Intermediate_H\nimports \"API_H\"\nbegin\n\n(*\n * Intermediate function bodies that were once in the Haskell spec, but are\n * now no longer.\n *\n * The idea is that these \"Old Haskell\" specs allow us to have refinement as\n * follows:\n *\n *  C <---> Haskell <---> Old Haskell <---> Abstract\n *\n * This provides a stepping stone for refactoring the Haskell without breaking\n * the upper proofs until a later time.\n *)\n\nconsts\ninsertNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> machine_word list \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> unit kernel\"\n\nconsts\ncreateObjects :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> Structures_H.kernel_object \\<Rightarrow> nat \\<Rightarrow> machine_word list kernel\"\n\nconsts\ncreateObjects' :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> kernel_object \\<Rightarrow> nat \\<Rightarrow> unit kernel\"\n\nconsts\ncreateNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> capability list kernel\"\n\nconsts\nArch_createNewCaps :: \"object_type \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_capability list kernel\"\n\ndefs insertNewCaps_def:\n\"insertNewCaps newType srcSlot destSlots regionBase magnitudeBits dev \\<equiv> (do\n    caps \\<leftarrow> createNewCaps newType regionBase (length destSlots) magnitudeBits dev;\n    zipWithM_x (insertNewCap srcSlot) destSlots caps\n  od)\"\n\ndefs createNewCaps_def:\n\"createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    (case toAPIType t of\n          Some TCBObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::tcb)) 0;\n            curdom \\<leftarrow> curDomain;\n            mapM_x (\\<lambda>tptr. threadSet (tcbDomain_update (\\<lambda>_. curdom)) tptr) addrs;\n            return $ map (\\<lambda> addr. ThreadCap addr) addrs\n          od)\n        | Some EndpointObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::endpoint)) 0;\n            return $ map (\\<lambda> addr. EndpointCap addr 0 True True True True) addrs\n          od)\n        | Some NotificationObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::notification)) 0;\n            return $ map (\\<lambda> addr. NotificationCap addr 0 True True) addrs\n          od)\n        | Some ArchTypes_H.CapTableObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject ::cte)) userSize;\n            modify (\\<lambda> ks. ks \\<lparr> gsCNodes := (\\<lambda> addr.\n              if addr `~elem~` map fromPPtr addrs then Just userSize\n              else gsCNodes ks addr)\\<rparr>);\n            return $ map (\\<lambda> addr. CNodeCap addr userSize 0 0) addrs\n          od)\n        | Some ArchTypes_H.Untyped \\<Rightarrow>\n            return $ map\n                (\\<lambda> n. UntypedCap dev (regionBase + n * 2 ^ (fromIntegral userSize)) userSize 0)\n                [0  .e.  (fromIntegral numObjects) - 1]\n        | None \\<Rightarrow>   (do\n            archCaps \\<leftarrow> Arch_createNewCaps t regionBase numObjects userSize dev;\n            return $ map ArchObjectCap archCaps\n          od)\n        )\"\n\ndefs createObjects_def:\n\"createObjects ptr numObjects val gSize \\<equiv> (do\n        oBits \\<leftarrow> return ( objBitsKO val);\n        gBits \\<leftarrow> return ( oBits + gSize);\n        createObjects' ptr numObjects val gSize;\n        return (map (\\<lambda> n. (ptr + n `~shiftL~` gBits))\n                [0  .e.  (of_nat numObjects) - 1])\n  od)\"\n\ndefs createObjects'_def:\n\"createObjects' ptr numObjects val gSize\\<equiv> (do\n        oBits \\<leftarrow> return ( objBitsKO val);\n        gBits \\<leftarrow> return ( oBits + gSize);\n        unless (fromPPtr ptr && mask gBits = 0) $\n            alignError gBits;\n        ps \\<leftarrow> gets ksPSpace;\n        end \\<leftarrow> return ( fromPPtr ptr + fromIntegral ((numObjects `~shiftL~` gBits) - 1));\n        (before, _) \\<leftarrow> return ( lookupAround2 end (psMap ps));\n        (case before of\n              None \\<Rightarrow>   return ()\n            | Some (x, _) \\<Rightarrow>   haskell_assert (x < fromPPtr ptr)\n                []\n            );\n        addresses \\<leftarrow> return ( map\n                (\\<lambda> n. fromPPtr ptr + n `~shiftL~` oBits)\n                [0  .e.  (fromIntegral numObjects `~shiftL~` gSize) - 1]);\n        map' \\<leftarrow> return ( foldR\n               (\\<lambda> addr map. data_map_insert addr val map)\n               (psMap ps) addresses);\n        ps' \\<leftarrow> return ( ps \\<lparr> psMap := map' \\<rparr>);\n        modify (\\<lambda> ks. ks \\<lparr> ksPSpace := ps'\\<rparr>)\nod)\"\n\n\nend"}
{"title": "./spec/design/skel/Structures_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n   datatypes/records for the various kernel data structures.\n*)\n\nchapter \"Kernel Data Structures\"\n\ntheory Structures_H\nimports\n  Config_H\n  State_H\n  Fault_H\n  Types_H\n  ArchStructures_H\nbegin\n\narch_requalify_types (H)\n  arch_capability\n  arch_kernel_object\n  asid\n  arch_tcb\n\narch_requalify_consts (H)\n  archObjSize\n  nullPointer\n  newArchTCB\n  fromPPtr\n  PPtr\n  atcbContextGet\n  atcbContextSet\n\n#INCLUDE_HASKELL SEL4/Object/Structures.lhs decls_only NOT isNullCap isUntypedCap isIRQControlCap isReplyCap isDomainCap isNotificationCap\n#INCLUDE_HASKELL SEL4/Object/Structures.lhs bodies_only NOT kernelObjectTypeName isNullCap isUntypedCap isIRQControlCap isReplyCap isDomainCap isNotificationCap\n\n\nend"}
{"title": "./spec/design/skel/FaultMonad_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"The Fault Monad\"\n\ntheory FaultMonad_H\nimports\n  KernelStateData_H\n  Fault_H\nbegin\n\ntype_synonym ('f, 'a) kernel_f = \"('f + 'a) kernel\"\n\ntranslations\n  (type) \"('f,'a) kernel_f\" <= (type) \"('f + 'a) kernel\""}
{"title": "./spec/design/skel/FaultMonad_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  withoutFailure :: \"'a kernel \\<Rightarrow> ('f, 'a) kernel_f\"\nwhere\n  withoutFailure_def[simp]:\n  \"withoutFailure \\<equiv> liftE\"\n\ndefinition\n  throw :: \"'f \\<Rightarrow> ('f, 'a) kernel_f\"\nwhere\n  throw_def[simp]:\n  \"throw \\<equiv> throwError\"\n\ndefinition\n  catchFailure :: \"('f, 'a) kernel_f \\<Rightarrow> ('f \\<Rightarrow> 'a kernel) \\<Rightarrow> 'a kernel\"\nwhere\n  catchFailure_def[simp]:\n \"catchFailure \\<equiv> catch\"\n\ndefinition\n  rethrowFailure :: \"('f1 \\<Rightarrow> 'f2) \\<Rightarrow> ('f1, 'a) kernel_f \\<Rightarrow> ('f2, 'a) kernel_f\"\nwhere\n \"rethrowFailure f m \\<equiv> m <handle2> (throwError \\<circ> f)\"\n\ndefinition\n  ignoreFailure :: \"( 'f , unit ) kernel_f \\<Rightarrow> unit kernel\"\nwhere\n  \"ignoreFailure x \\<equiv> (catchFailure x (const (return ())))\"\n\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures.lhs\n#INCLUDE_HASKELL SEL4/Model/Failures.lhs NOT KernelF withoutFailure catchFailure throw rethrowFailure nullCapOnFailure nothingOnFailure ignoreFailure emptyOnFailure\n\ndefinition\n  nullCapOnFailure :: \"('f, capability) kernel_f \\<Rightarrow> capability kernel\"\nwhere\n \"nullCapOnFailure m \\<equiv> m <catch> (\\<lambda>x. return NullCap)\"\n\ndefinition\n  emptyOnFailure :: \"('f, 'a list) kernel_f \\<Rightarrow> 'a list kernel\"\nwhere\n \"emptyOnFailure m \\<equiv> m <catch> (\\<lambda>x. return [])\"\n\ndefinition\n  nothingOnFailure :: \"('f, 'a option) kernel_f \\<Rightarrow> 'a option kernel\"\nwhere\n \"nothingOnFailure m \\<equiv> m <catch> (\\<lambda>x. return Nothing)\""}
{"title": "./spec/design/skel/FaultMonad_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\ntype_synonym 'a kernel_p = \"(irq + 'a) kernel\"\n\ntranslations\n  (type) \"'a kernel_p\" <= (type) \"(irq + 'a) kernel\"\n\ndefinition\n  withoutPreemption :: \"'a kernel \\<Rightarrow> 'a kernel_p\"\nwhere\n  withoutPreemption_def[simp]:\n \"withoutPreemption \\<equiv> liftE\"\n\ndefinition\n  workUnitsLimit :: machine_word\nwhere\n  \"workUnitsLimit \\<equiv> 0x64\"\n\ndefinition\n  preemptionPoint :: \"unit kernel_p\"\nwhere\n  \"preemptionPoint \\<equiv> doE\n     liftE $ modifyWorkUnits (\\<lambda>u. u + 1);\n     workUnits <- liftE $ getWorkUnits;\n     whenE (workUnitsLimit <= workUnits) $ doE\n       liftE $ setWorkUnits 0;\n       preempt <- liftE $ doMachineOp (getActiveIRQ True);\n       case preempt of\n           Some irq => throwError irq\n           | None => returnOk ()\n     odE\n   odE\"\n\n\nend"}
{"title": "./spec/design/skel/Notification_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Notifications\"\n\ntheory Notification_H imports    \"NotificationDecls_H\"\n    \"TCB_H\"\n  TCB_H\n  ThreadDecls_H\n  CSpaceDecls_H\n  ObjectInstances_H\nbegin\n\narch_requalify_consts (H)\n  badgeRegister\n\n#INCLUDE_HASKELL SEL4/Object/Notification.lhs bodies_only\n\nend"}
{"title": "./spec/design/skel/Endpoint_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Endpoints\"\n\ntheory Endpoint_H\nimports\n  EndpointDecls_H\n  TCB_H\n  ThreadDecls_H\n  CSpaceDecls_H\n  FaultHandlerDecls_H\n  Notification_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Endpoint.lhs bodies_only\n\nend"}
{"title": "./spec/design/skel/CSpaceDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Function Declarations for CSpace\"\n\ntheory CSpaceDecls_H\nimports FaultMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/CSpace.lhs decls_only\n\nend"}
{"title": "./spec/design/skel/TCB_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Thread Control Blocks\"\n\ntheory TCB_H\nimports\n  NotificationDecls_H\n  TCBDecls_H\n  CNode_H\n  VSpace_H\n  ArchTCB_H\nbegin\n\narch_requalify_consts (H)\n  decodeTransfer\n  performTransfer\n  msgInfoRegister\n  msgRegisters\n  fromVPtr\n  postModifyRegisters\n  sanitiseRegister\n  getSanitiseRegisterInfo\n\n(* clobbers previously requalified abstract spec constants with design spec versions *)\narch_requalify_consts (aliasing, H)\n  gpRegisters\n  frameRegisters\n  tlsBaseRegister\n\nabbreviation \"mapMaybe \\<equiv> option_map\"\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= bodies_only NOT liftFnMaybe assertDerived archThreadGet archThreadSet asUser sanitiseRegister getSanitiseRegisterInfo\n\ndefs asUser_def:\n\"asUser tptr f\\<equiv> (do\n        uc \\<leftarrow> threadGet  (atcbContextGet o tcbArch) tptr;\n        (a, uc') \\<leftarrow> select_f (f uc);\n        threadSet (\\<lambda> tcb. tcb \\<lparr> tcbArch := atcbContextSet uc' (tcbArch tcb)\\<rparr>) tptr;\n        return a\nod)\"\n\nend"}
{"title": "./spec/design/skel/Retype_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory Retype_H\nimports\n  RetypeDecls_H\n  Endpoint_H\n  Untyped_H\n  Interrupt_H\nbegin\n\ncontext Arch begin\n\n(* match Haskell, expects these under Arch. *)\nrequalify_consts\n  cteRightsBits cteGuardBits\n\n(* disambiguate name clash between Arch and non-arch consts with same names *)\nrequalify_consts (aliasing)\n  deriveCap finaliseCap postCapDeletion isCapRevocable\n  hasCancelSendRights sameRegionAs isPhysicalCap\n  sameObjectAs updateCapData maskCapRights\n  createObject capUntypedPtr capUntypedSize\n  performInvocation decodeInvocation prepareThreadDelete\n\ncontext begin global_naming global\n\nrequalify_consts (aliasing)\n  RetypeDecls_H.deriveCap RetypeDecls_H.finaliseCap RetypeDecls_H.postCapDeletion\n  RetypeDecls_H.isCapRevocable\n  RetypeDecls_H.hasCancelSendRights RetypeDecls_H.sameRegionAs RetypeDecls_H.isPhysicalCap\n  RetypeDecls_H.sameObjectAs RetypeDecls_H.updateCapData RetypeDecls_H.maskCapRights\n  RetypeDecls_H.createObject RetypeDecls_H.capUntypedPtr RetypeDecls_H.capUntypedSize\n  RetypeDecls_H.performInvocation RetypeDecls_H.decodeInvocation\nend\n\nend\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType.lhs Arch=Arch bodies_only\n\nend"}
{"title": "./spec/design/skel/VSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    VSpace lookup code.\n*)\n\ntheory VSpace_H\nimports\n  CNode_H\n  ArchVSpace_H\n  KernelInitMonad_H\nbegin\n\narch_requalify_consts (H)\n  mapKernelWindow\n  activateGlobalVSpace\n  initIRQController\n  createIPCBufferFrame\n  createBIFrame\n  createFramesOfRegion\n  createITPDPTs\n  writeITPDPTs\n  createITASIDPool\n  writeITASIDPool\n  createDeviceFrames\n  handleVMFault\n  isValidVTableRoot\n  checkValidIPCBuffer\n  lookupIPCBuffer\n  vptrFromPPtr\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace.lhs Arch= ONLY initKernelVM initPlatform initCPU\n\nend"}
{"title": "./spec/design/skel/Interrupt_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Interrupt_H\nimports\n  RetypeDecls_H\n  ArchInterrupt_H\n  Notification_H\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\n\ncontext Arch begin\n\n(* match Haskell, expects these under Arch. *)\nrequalify_consts\n  checkIRQ\n  handleReservedIRQ\n  maskIrqSignal\n\n(* disambiguate name clash between Arch and non-arch consts with same names *)\nrequalify_consts (aliasing)\n  decodeIRQControlInvocation\n  invokeIRQHandler\n  performIRQControl\n  initInterruptController\n\ncontext begin global_naming global\nrequalify_consts (aliasing)\n  InterruptDecls_H.decodeIRQControlInvocation\n  InterruptDecls_H.invokeIRQHandler\n  InterruptDecls_H.performIRQControl\n  InterruptDecls_H.initInterruptController\n\nend\nend\n\n(* override Kernel_Config const with constrained abbreviation from Hardware_H *)\narch_requalify_consts (aliasing, H)\n  maxIRQ\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs\n#INCLUDE_HASKELL SEL4/Object/Interrupt.lhs bodies_only\n\nend"}
{"title": "./spec/design/skel/Event_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Kernel Events\"\n\ntheory Event_H\nimports MachineExports\nbegin\n\ntext \\<open>\n  \\label{sec:Event_H}\n\n  These are the user-level and machine generated events the kernel reacts to.\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/Syscall.lhs ONLY Event Syscall\n\nend"}
{"title": "./spec/design/skel/Config_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Config_H\nimports Types_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Config.lhs NOT numDomains timeSlice resetChunkBits retypeFanOutLimit\n\nend"}
{"title": "./spec/design/skel/Syscall_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"System Calls\"\n\ntheory Syscall_H\nimports Kernel_H Event_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Model/Syscall.lhs\n#INCLUDE_HASKELL SEL4/API/Syscall.lhs decls_only NOT Event Syscall\n#INCLUDE_HASKELL SEL4/API/Syscall.lhs bodies_only\n\nend"}
{"title": "./spec/design/skel/KernelStateData_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Kernel State and Monads\"\n\ntheory KernelStateData_H\nimports\n  PSpaceStruct_H\n  Structures_H\n  MachineOps\n  ArchStateData_H\nbegin\n\nrequalify_types (in Arch)\n  kernel_state"}
{"title": "./spec/design/skel/KernelStateData_H.thy", "section": "", "subsection": "Kernel Functions", "subsubsection": "", "code": "\ntype_synonym ready_queue = tcb_queue\n\ntext \\<open>We pull a fast one on haskell here ... although Haskell expects\na KernelMonad which is a StateT monad in KernelData that wraps a MachineMonad,\nwe push the extra MachineMonad data into the KernelState. Fortunately the\nupdate and accessor functions all still work.\\<close>\n\nrecord kernel_state =\n  ksPSpace             :: pspace\n  gsUserPages          :: \"machine_word \\<Rightarrow> vmpage_size option\"\n  gsCNodes             :: \"machine_word \\<Rightarrow> nat option\"\n  gsUntypedZeroRanges  :: \"(machine_word \\<times> machine_word) set\"\n  gsMaxObjectSize      :: nat\n  ksDomScheduleIdx     :: nat\n  ksDomSchedule        :: \"(domain \\<times> machine_word) list\"\n  ksCurDomain          :: domain\n  ksDomainTime         :: machine_word\n  ksReadyQueues        :: \"domain \\<times> priority \\<Rightarrow> ready_queue\"\n  ksReadyQueuesL1Bitmap :: \"domain \\<Rightarrow> machine_word\"\n  ksReadyQueuesL2Bitmap :: \"domain \\<times> nat \\<Rightarrow> machine_word\"\n  ksCurThread          :: machine_word\n  ksIdleThread         :: machine_word\n  ksSchedulerAction    :: scheduler_action\n  ksInterruptState     :: interrupt_state\n  ksWorkUnitsCompleted :: machine_word\n  ksArchState          :: Arch.kernel_state\n  ksMachineState       :: machine_state\n\ncontext Arch begin\ncontext begin global_naming global\nrequalify_types KernelStateData_H.kernel_state\nend\nend\n\ntype_synonym 'a kernel = \"(kernel_state, 'a) nondet_monad\"\n\ntranslations\n  (type) \"'c kernel\" <= (type) \"(kernel_state, 'c) nondet_monad\""}
{"title": "./spec/design/skel/KernelStateData_H.thy", "section": "", "subsection": "Kernel Functions", "subsubsection": "", "code": "\ndefinition\n  doMachineOp :: \"(machine_state, 'a) nondet_monad  \\<Rightarrow> 'a kernel\"\nwhere\n \"doMachineOp mop \\<equiv> do\n    ms \\<leftarrow> gets ksMachineState;\n    (r, ms') \\<leftarrow> select_f (mop ms);\n    modify (\\<lambda>ks. ks \\<lparr> ksMachineState := ms' \\<rparr>);\n    return r\n  od\"\n\n#INCLUDE_HASKELL SEL4/Model/StateData.lhs decls_only ONLY capHasProperty ksReadyQueues_asrt ready_qs_runnable idleThreadNotQueued\n#INCLUDE_HASKELL SEL4/Model/StateData.lhs NOT doMachineOp KernelState ReadyQueue Kernel assert stateAssert findM funArray newKernelState capHasProperty ksReadyQueues_asrt ready_qs_runnable idleThreadNotQueued\n\nend"}
{"title": "./spec/design/skel/TCBDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Function Declarations for TCBs\"\n\ntheory TCBDecls_H\nimports FaultMonad_H Invocations_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs decls_only \\\n  NOT archThreadGet archThreadSet sanitiseRegister getSanitiseRegisterInfo\n\nend"}
{"title": "./spec/design/skel/Kernel_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Kernel\"\n\ntheory Kernel_H\nimports\n  KernelInit_H\n  Thread_H\n  FaultHandler_H\n  CSpace_H\n  Hypervisor_H\nbegin\nend"}
{"title": "./spec/design/skel/EndpointDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Function Declarations for Endpoints\"\n\ntheory EndpointDecls_H\nimports FaultMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Object/Endpoint.lhs decls_only\n\nend"}
{"title": "./spec/design/skel/FaultHandler_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Fault Handlers\"\n\ntheory FaultHandler_H\nimports\n  FaultHandlerDecls_H\n  TCB_H\n  ArchFaultHandler_H\nbegin\n\narch_requalify_consts (H)\n  makeArchFaultMessage\n  handleArchFaultReply\n\n(* clobbers previously requalified abstract spec constants with design spec versions *)\narch_requalify_consts (aliasing, H)\n  syscallMessage\n  exceptionMessage\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures.lhs\n\n#INCLUDE_HASKELL SEL4/Kernel/FaultHandler.lhs bodies_only\n#INCLUDE_HASKELL SEL4/API/Faults.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults.lhs bodies_only\n\nend"}
{"title": "./spec/design/skel/FaultHandlerDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Declarations from SEL4.Kernel.FaultHandler\n*)\n\nchapter \"Function Declarations for Fault Handlers\"\n\ntheory FaultHandlerDecls_H\nimports Structures_H FaultMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/FaultHandler.lhs decls_only\n\nend"}
{"title": "./spec/design/skel/API_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"The API\"\n\ntheory API_H\nimports Syscall_H Delete_H\nbegin\n\ntext \\<open>collects all API modules\\<close>\n\n#INCLUDE_HASKELL SEL4.lhs decls_only NOT callKernel\n\n#INCLUDE_HASKELL SEL4.lhs NOT kernelExitAssertions fastpathKernelAssertions\n\nend"}
{"title": "./spec/design/skel/KI_Decls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Initialisation\"\n\ntheory KI_Decls_H\nimports\n  ThreadDecls_H\n  KernelInitMonad_H\nbegin\n\n#INCLUDE_HASKELL SEL4/Kernel/Init.lhs decls_only NOT isAligned funArray newKernelState distinct rangesBy doKernelOp runInit\n\nend"}
{"title": "./spec/design/skel/Untyped_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Untyped Objects\"\n\ntheory Untyped_H\nimports\n  RetypeDecls_H\n  CSpaceDecls_H\n  CNode_H\n  Invocations_H\n  InvocationLabels_H\n  Config_H\nbegin\n\narch_requalify_consts (H)\n  minUntypedSizeBits\n  maxUntypedSizeBits\n\nconsts\n  cNodeOverlap :: \"(machine_word \\<Rightarrow> nat option) \\<Rightarrow> (machine_word \\<Rightarrow> bool) \\<Rightarrow> bool\"\n\n#INCLUDE_HASKELL SEL4/Object/Untyped.lhs decls_only ONLY archOverlap\n\n#INCLUDE_HASKELL SEL4/Object/Untyped.lhs NOT cNodeOverlap canonicalAddressAssert archOverlap\n\nend"}
{"title": "./spec/design/skel/KernelInit_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Initialisation\"\n\ntheory KernelInit_H\nimports\n  KI_Decls_H\n  ArchRetype_H\n  Retype_H\n  Config_H\n  Thread_H\nbegin\n\narch_requalify_consts\n  getMemoryRegions\n  addrFromPPtr\n  init_machine_state\n\nrequalify_consts (in Arch)\n  newKernelState\n\nfun coverOf :: \"region list => region\"\nwhere \"coverOf x0 = (case x0 of\n    [] =>    Region (0,0)\n  | [x] =>    x\n  | (x#xs) =>\n    let\n        (l,h) = fromRegion x;\n        (ll,hh) = fromRegion $ coverOf xs;\n        ln = if l \\<le> ll then l else ll;\n        hn = if h \\<le> hh then hh else h\n    in\n    Region (ln, hn)\n  )\"\n\ndefinition syncBIFrame :: \"unit kernel_init\"\nwhere \"syncBIFrame \\<equiv> returnOk ()\"\n\n#INCLUDE_HASKELL SEL4/Kernel/Init.lhs bodies_only NOT isAligned funArray newKernelState distinct rangesBy InitData doKernelOp runInit noInitFailure coverOf foldME\n\nconsts\n  newKSDomSchedule :: \"(domain \\<times> machine_word) list\"\n  newKSDomScheduleIdx :: nat\n  newKSCurDomain :: domain\n  newKSDomainTime :: machine_word\n  newKernelState :: \"machine_word \\<Rightarrow> kernel_state\"\n\ndefs\nnewKernelState_def:\n\"newKernelState data_start \\<equiv> \\<lparr>\n        ksPSpace = newPSpace,\n        gsUserPages = (\\<lambda>x. None),\n        gsCNodes = (\\<lambda>x. None),\n        gsUntypedZeroRanges = {},\n        gsMaxObjectSize = card (UNIV :: machine_word set),\n        ksDomScheduleIdx = newKSDomScheduleIdx,\n        ksDomSchedule = newKSDomSchedule,\n        ksCurDomain = newKSCurDomain,\n        ksDomainTime = newKSDomainTime,\n        ksReadyQueues = const (TcbQueue None None),\n        ksReadyQueuesL1Bitmap = const 0,\n        ksReadyQueuesL2Bitmap = const 0,\n        ksCurThread = error [],\n        ksIdleThread = error [],\n        ksSchedulerAction = ResumeCurrentThread,\n        ksInterruptState = error [],\n        ksWorkUnitsCompleted = 0,\n        ksArchState = fst (Arch.newKernelState data_start),\n        ksMachineState = init_machine_state\n\\<rparr>\"\n\n(* disambiguate name clash between Arch and non-arch consts with same names *)\ncontext Arch begin\nrequalify_facts (aliasing)\n   newKernelState_def\nrequalify_consts (aliasing)\n   newKernelState\n\ncontext begin global_naming global\nrequalify_facts (aliasing)\n   KernelInit_H.newKernelState_def\nrequalify_consts (aliasing)\n   KernelInit_H.newKernelState\nend\nend\n\nend"}
{"title": "./spec/design/skel/ARM/ArchPSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/ARM.hs\n\nend (* context Arch *)\n\nend"}
{"title": "./spec/design/skel/ARM/ArchThreadDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT Arch decls_only\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchTypes_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n   Types visible in the API.\n*)\n\nchapter \"Arch-dependant Types visible in the API\"\n\ntheory ArchTypes_H\nimports\n  State_H\n  Hardware_H\n  \"Lib.Lib\"\nbegin\n\n#INCLUDE_HASKELL SEL4/API/Types/Universal.lhs all_bits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Types/ARM.lhs CONTEXT ARM_H\n\nend\n\ntext \\<open>object\\_type instance proofs\\<close>\n\nqualify ARM_H (in Arch)\ninstantiation ARM_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [PageDirectoryObject,\n      SmallPageObject,\n      LargePageObject,\n      SectionObject,\n      SuperSectionObject,\n      PageTableObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation ARM_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation ARM_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend"}
{"title": "./spec/design/skel/ARM/ArchStateData_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_H NOT ArmVSpaceRegionUse\n\nend\n\nend"}
{"title": "./spec/design/skel/ARM/ArchFault_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/API/Failures/ARM.lhs CONTEXT ARM_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/ARM.lhs CONTEXT ARM_H bodies_only\n\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchObjInsts_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Defines the instances of pspace_storable objects.\n*)\n\nchapter \"Storable Arch Object Instances\"\n\ntheory ArchObjInsts_H\nimports\n  ArchTypes_H\n  PSpaceStorable_H\n  ObjectInstances_H\nbegin\nqualify ARM_H (in Arch)\n\ninstantiation ARM_H.pde :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pde:\n  \"projectKO_opt e \\<equiv> case e of KOArch (KOPDE e) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pde:\n  \"injectKO e \\<equiv> KOArch (KOPDE e)\"\n\ndefinition\n  koType_pde:\n  \"koType (t::pde itself) \\<equiv> ArchT PDET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pde injectKO_pde koType_pde\n          split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation ARM_H.pte :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pte:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOPTE e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pte:\n  \"injectKO e \\<equiv> KOArch (KOPTE e)\"\n\ndefinition\n  koType_pte:\n  \"koType (t::pte itself) \\<equiv> ArchT PTET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pte injectKO_pte koType_pte\n          split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\n\ninstantiation ARM_H.asidpool :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  injectKO_asidpool:\n  \"injectKO e \\<equiv> KOArch (KOASIDPool e)\"\n\ndefinition\n  koType_asidpool:\n  \"koType (t::asidpool itself) \\<equiv> ArchT ASIDPoolT\"\n\ndefinition\n  projectKO_opt_asidpool:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOASIDPool e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_asidpool injectKO_asidpool koType_asidpool\n          split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\nlemmas (in Arch) projectKO_opts_defs =\n  projectKO_opt_pde projectKO_opt_pte projectKO_opt_asidpool\n  ObjectInstances_H.projectKO_opts_defs\n\nlemmas (in Arch) [simp] =\n  injectKO_pde koType_pde\n  injectKO_pte koType_pte\n  injectKO_asidpool koType_asidpool\n\n\\<comment> \\<open>--------------------------------------\\<close>\n\n#INCLUDE_SETTINGS keep_constructor = asidpool\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/ARM.lhs\n#INCLUDE_HASKELL_PREPARSE SEL4/Machine/Hardware/ARM.lhs\n\n\ninstantiation ARM_H.pde :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/ARM.lhs instanceproofs bodies_only ONLY PDE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\ninstantiation ARM_H.pte :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/ARM.lhs instanceproofs bodies_only ONLY PTE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\n(* This is hard coded since using funArray in haskell for 2^32 bound is risky *)\n\ninstantiation ARM_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pde updateObject_pde\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend"}
{"title": "./spec/design/skel/ARM/Arch_Structs_B.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Main Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_H ONLY ArmVSpaceRegionUse\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchVSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  Untyped_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/ARM.lhs CONTEXT ARM_H bodies_only ArchInv=ArchRetypeDecls_H.ARM ArchLabels=ArchInvocationLabels_H.ARM NOT checkPDAt checkPTAt checkPDASIDMapMembership checkValidMappingSize vptrFromPPtr\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert\n    (\\<lambda>s. 2 ^ pageBitsForSize sz <= gsMaxObjectSize s) []\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchTCB_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchTCB_H\nimports TCBDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/ARM.lhs RegisterSet= CONTEXT ARM_H\n\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchVSpaceDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT ARM_H\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/ARM.lhs CONTEXT ARM_H decls_only ArchInv=\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchRetypeDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetypeDecls_H\nimports\n  ArchLabelFuns_H\n  FaultMonad_H\n  EndpointDecls_H\n  KernelInitMonad_H\n  PSpaceFuns_H\n  ArchObjInsts_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs CONTEXT ARM_H decls_only NOT isPageFlushLabel isPDFlushLabel Invocation IRQControlInvocation CopyRegisterSets\n\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs CONTEXT ARM_H decls_only ONLY Invocation IRQControlInvocation CopyRegisterSets\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/ARM.lhs CONTEXT ARM_H Arch.Types=ArchTypes_H ArchInv= decls_only\n\nend\n\n(* Defined differently and/or delayed on different architectures *)\ndefinition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend"}
{"title": "./spec/design/skel/ARM/ArchInvocationLabels_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Labels\"\n\ntheory ArchInvocationLabels_H\nimports\n    \"Word_Lib.Enumeration\"\n    Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\ntext \\<open>\n  An enumeration of arch-specific system call labels.\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_H ONLY ArchInvocationLabel\n\nend\n\n(* not possible to move this requalification to generic, since enum instance proofs must\n   be done outside of Arch locale *)\narch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend"}
{"title": "./spec/design/skel/ARM/RegisterSet_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext ((K 0) aLU initContext)\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchFaultHandler_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/ARM.lhs\n\n#INCLUDE_HASKELL SEL4/API/Faults/ARM.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/ARM.lhs bodies_only\n\nend\n\n\nend"}
{"title": "./spec/design/skel/ARM/ArchStructures_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_H decls_only\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_H instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_H bodies_only\n\ndatatype arch_kernel_object_type =\n    PDET\n  | PTET\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPDE e) = PDET\"\n| \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM/State_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Machine and kernel state.\n*)\n\nchapter \"Machine State\"\n\ntheory State_H\nimports\n  \"Lib.HaskellLib_H\"\n  RegisterSet_H\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  Word :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  Word_def[simp]:\n \"Word \\<equiv> id\"\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits ONLY wordBits\n\nend\n\n(* Note: while this requalify and arch-generic Haskell import of WordLib.lhs could be moved to\n   a generic theory, no good candidate theory exists at the moment. *)\narch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=ARM CONTEXT ARM_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchInterrupt_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/ARM.lhs Arch= CONTEXT ARM_H bodies_only ArchInv=\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchRetype_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/ARM.lhs CONTEXT ARM_H Arch.Types= ArchInv= bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs bodies_only CONTEXT ARM_H NOT isPDFlushLabel isPageFlushLabel\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchIntermediate_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewPageCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        when (\\<not>dev) $\n          mapM_x (\\<lambda>addr. doMachineOp $\n                            cleanCacheRange_RAM addr\n                                                (addr + mask (pageBitsForSize pSize))\n                                                (addrFromPPtr addr)) addrs;\n        return $ map (\\<lambda>n. PageCap dev (PPtr (fromPPtr n)) VMReadWrite pSize Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      mapM_x (\\<lambda>addr. doMachineOp $\n                       cleanCacheRange_PoU addr (addr + mask tableBits) (addrFromPPtr addr)) addrs;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 0 ARMSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 4 ARMLargePage\n        | SectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 8 ARMSection\n        | SuperSectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 12 ARMSuperSection\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        | PageDirectoryObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdBits (makeObject::pde) PageDirectoryCap\n              (\\<lambda>pds. do objSize \\<leftarrow> return (((1::nat) `~shiftL~` pdBits));\n                        mapM_x copyGlobalMappings pds\n                     od)\n        )\"\n\nend\nend\n\nend"}
{"title": "./spec/design/skel/ARM/ArchThread_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT ARM_H ARMHardware=ARM bodies_only\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchLabelFuns_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Label Functions\"\n\ntheory ArchLabelFuns_H\nimports InvocationLabels_H\nbegin\ncontext Arch begin arch_global_naming (H)\ntext \\<open>\n  Arch-specific functions on invocation labels\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs CONTEXT ARM_H ONLY isPDFlushLabel isPageFlushLabel\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchHypervisor_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  Hypervisor stub for ARM\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_H bodies_only ArchInv= ArchLabels=\n\nend\nend"}
{"title": "./spec/design/skel/ARM/ArchInterruptDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/ARM.lhs CONTEXT ARM_H decls_only ArchInv=\n\nend\n\nend"}
{"title": "./spec/design/skel/ARM/Hardware_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs Platform=Platform.ARM CONTEXT ARM_H NOT getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory writeTTBR0 setGlobalPD  setTTBCR setHardwareASID invalidateLocalTLB invalidateLocalTLB_ASID invalidateLocalTLB_VAASID cleanByVA cleanByVA_PoU invalidateByVA invalidateByVA_I invalidate_I_PoU cleanInvalByVA branchFlush clean_D_PoU cleanInvalidate_D_PoC cleanInvalidate_D_PoU cleanInvalidateL2Range invalidateL2Range cleanL2Range isb dsb dmb getIFSR getDFSR getFAR HardwareASID wordFromPDE wordFromPTE VMFaultType VMPageSize HypFaultType pageBits pageBitsForSize toPAddr cacheLineBits cacheLine lineStart cacheRangeOp cleanCacheRange_PoC cleanInvalidateCacheRange_RAM cleanCacheRange_RAM cleanCacheRange_PoU invalidateCacheRange_RAM invalidateCacheRange_I branchFlushRange cleanCaches_PoU cleanInvalidateL1Caches addrFromPPtr ptrFromPAddr initIRQController setIRQTrigger MachineData paddrBase pptrBase pptrTop paddrTop kernelELFPAddrBase kernelELFBase kernelELFBaseOffset pptrBaseOffset addrFromKPPtr\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_H instanceproofs NOT HardwareASID VMFaultType VMPageSize HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_H ONLY wordFromPDE wordFromPTE\n\n(* Kernel_Config provides a generic numeral, Haskell expects type irq *)\nabbreviation (input) maxIRQ :: irq where\n  \"maxIRQ == Kernel_Config.maxIRQ\"\n\n(* provide ARM/ARM_HYP machine op in _H global_prefix for arch-split *)\nabbreviation (input) initIRQController where\n  \"initIRQController \\<equiv> ARM.initIRQController\"\n\nend\nend"}
{"title": "./spec/design/skel/X64/ArchPSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/X64.hs\n\nend (* context Arch *)\n\nend"}
{"title": "./spec/design/skel/X64/ArchThreadDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/X64.lhs CONTEXT X64_H decls_only\n\nend (* context X64 *)\n\nend"}
{"title": "./spec/design/skel/X64/ArchTypes_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n   Types visible in the API.\n*)\n\nchapter \"Arch-dependant Types visible in the API\"\n\ntheory ArchTypes_H\nimports\n  State_H\n  Hardware_H\n  \"Lib.Lib\"\nbegin\n\n#INCLUDE_HASKELL SEL4/API/Types/Universal.lhs all_bits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Types/X64.lhs CONTEXT X64_H\n\nend\n\ntext \\<open>object\\_type instance proofs\\<close>\n\nqualify X64_H (in Arch)\ninstantiation X64_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [PDPointerTableObject,\n      PML4Object,\n      HugePageObject,\n      SmallPageObject,\n      LargePageObject,\n      PageTableObject,\n      PageDirectoryObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation X64_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation X64_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend"}
{"title": "./spec/design/skel/X64/ArchHook_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"ArchHook\"\n\ntheory ArchHook_H\nimports KernelStateData_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  cEntryHook :: \"unit kernel\"\nwhere\n  \"cEntryHook\\<equiv> return ()\"\n\ndefinition\n  cExitHook :: \"unit kernel\"\nwhere\n  \"cExitHook\\<equiv> return ()\"\n\nend\nend"}
{"title": "./spec/design/skel/X64/ArchStateData_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/X64.lhs CONTEXT X64_H NOT X64VSpaceRegionUse\n\nend\nend"}
{"title": "./spec/design/skel/X64/ArchFault_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Failures/X64.lhs CONTEXT X64_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/X64.lhs CONTEXT X64_H bodies_only\n\nend\nend"}
{"title": "./spec/design/skel/X64/ArchObjInsts_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Defines the instances of pspace_storable objects.\n*)\n\nchapter \"Storable Arch Object Instances\"\n\ntheory ArchObjInsts_H\nimports\n  ArchTypes_H\n  PSpaceStorable_H\n  ObjectInstances_H\nbegin\nqualify X64_H (in Arch)\n\ninstantiation X64_H.pde :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pde:\n  \"projectKO_opt e \\<equiv> case e of KOArch (KOPDE e) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pde [simp]:\n  \"injectKO e \\<equiv> KOArch (KOPDE e)\"\n\ndefinition\n  koType_pde [simp]:\n  \"koType (t::pde itself) \\<equiv> ArchT PDET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pde split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\n\ninstantiation X64_H.pte :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pte:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOPTE e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pte [simp]:\n  \"injectKO e \\<equiv> KOArch (KOPTE e)\"\n\ndefinition\n  koType_pte [simp]:\n  \"koType (t::pte itself) \\<equiv> ArchT PTET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pte split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation X64_H.pdpte :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pdpte:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOPDPTE e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pdpte [simp]:\n  \"injectKO e \\<equiv> KOArch (KOPDPTE e)\"\n\ndefinition\n  koType_pdpte [simp]:\n  \"koType (t::pdpte itself) \\<equiv> ArchT PDPTET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pdpte split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation X64_H.pml4e :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pml4e:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOPML4E e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pml4e [simp]:\n  \"injectKO e \\<equiv> KOArch (KOPML4E e)\"\n\ndefinition\n  koType_pml4e [simp]:\n  \"koType (t::pml4e itself) \\<equiv> ArchT PML4ET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pml4e split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation X64_H.asidpool :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  injectKO_asidpool [simp]:\n  \"injectKO e \\<equiv> KOArch (KOASIDPool e)\"\n\ndefinition\n  koType_asidpool [simp]:\n  \"koType (t::asidpool itself) \\<equiv> ArchT ASIDPoolT\"\n\ndefinition\n  projectKO_opt_asidpool:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOASIDPool e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_asidpool split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\nlemmas (in Arch) projectKO_opts_defs =\n  projectKO_opt_pte projectKO_opt_pde\n  projectKO_opt_pdpte projectKO_opt_pml4e\n  projectKO_opt_asidpool\n  ObjectInstances_H.projectKO_opts_defs\n\nlemmas (in Arch) [simp] =\n  injectKO_pte koType_pte\n  injectKO_pde koType_pde\n  injectKO_pdpte koType_pdpte\n  injectKO_pml4e koType_pml4e\n  injectKO_asidpool koType_asidpool\n\n\n\\<comment> \\<open>--------------------------------------\\<close>\n\n#INCLUDE_SETTINGS keep_constructor = asidpool\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/X64.lhs\n#INCLUDE_HASKELL_PREPARSE SEL4/Machine/Hardware/X64.lhs\n\n\ninstantiation X64_H.pde :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/X64.lhs instanceproofs bodies_only ONLY PDE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\ninstantiation X64_H.pte :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/X64.lhs instanceproofs bodies_only ONLY PTE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\n\ninstantiation X64_H.pdpte :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/X64.lhs instanceproofs bodies_only ONLY PDPTE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\ninstantiation X64_H.pml4e :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/X64.lhs instanceproofs bodies_only ONLY PML4E\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\n(* This is hard coded since using funArray in haskell for 2^32 bound is risky *)\n\ninstantiation X64_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pte updateObject_pte\n  loadObject_pde updateObject_pde\n  loadObject_pdpte updateObject_pdpte\n  loadObject_pml4e updateObject_pml4e\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend"}
{"title": "./spec/design/skel/X64/Arch_Structs_B.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Main Setup_Locale\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/X64.lhs CONTEXT X64_H ONLY X64VSpaceRegionUse\n\nend (* context X64 *)\n\nend"}
{"title": "./spec/design/skel/X64/ArchVSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  Untyped_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/X64.lhs CONTEXT X64_H bodies_only ArchInv=ArchRetypeDecls_H NOT checkPML4At checkPDPTAt checkPDAt checkPTAt checkValidMappingSize\n#INCLUDE_HASKELL SEL4/Object/IOPort/X64.lhs CONTEXT X64_H bodies_only ArchInv=ArchRetypeDecls_H\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert\n    (\\<lambda>s. 2 ^ pageBitsForSize sz <= gsMaxObjectSize s) []\"\n\nend\n\nend"}
{"title": "./spec/design/skel/X64/ArchTCB_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchTCB_H\nimports TCBDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/X64.lhs RegisterSet= CONTEXT X64_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend"}
{"title": "./spec/design/skel/X64/ArchVSpaceDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT X64_H\n#INCLUDE_HASKELL_PREPARSE SEL4/API/InvocationLabels/X64.lhs CONTEXT X64\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/X64.lhs CONTEXT X64_H decls_only ArchInv=\n#INCLUDE_HASKELL SEL4/Object/IOPort/X64.lhs CONTEXT X64_H decls_only ArchInv=\n\nend (* context X64 *)\n\nend"}
{"title": "./spec/design/skel/X64/ArchRetypeDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetypeDecls_H\nimports\n  FaultMonad_H\n  EndpointDecls_H\n  KernelInitMonad_H\n  PSpaceFuns_H\n  ArchObjInsts_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Invocation/X64.lhs CONTEXT X64_H decls_only NOT Invocation IRQControlInvocation\n\n#INCLUDE_HASKELL SEL4/API/Invocation/X64.lhs CONTEXT X64_H decls_only ONLY Invocation IRQControlInvocation\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/X64.lhs CONTEXT X64_H Arch.Types=ArchTypes_H ArchInv= decls_only\n\nend (*context X64*)\n\n(* Defined differently and/or delayed on different architectures *)\ndefinition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend"}
{"title": "./spec/design/skel/X64/ArchInvocationLabels_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Labels\"\n\ntheory ArchInvocationLabels_H\nimports\n  \"Word_Lib.Enumeration\"\n  Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\ntext \\<open>\n  An enumeration of arch-specific system call labels.\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/X64.lhs CONTEXT X64_H ONLY ArchInvocationLabel\n\nend\n\n(* not possible to move this requalification to generic, since enum instance proofs must\n   be done outside of Arch locale *)\narch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/X64.lhs CONTEXT X64_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend"}
{"title": "./spec/design/skel/X64/RegisterSet_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext FPUNullState ((K 0) aLU initContext)\"\n\nend\nend"}
{"title": "./spec/design/skel/X64/ArchFaultHandler_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/X64.lhs\n\n#INCLUDE_HASKELL SEL4/API/Faults/X64.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/X64.lhs bodies_only\n\nend\n\nend"}
{"title": "./spec/design/skel/X64/ArchStructures_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/X64.lhs CONTEXT X64_H decls_only\n#INCLUDE_HASKELL SEL4/Object/Structures/X64.lhs CONTEXT X64_H instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/X64.lhs CONTEXT X64_H bodies_only\n\ndatatype arch_kernel_object_type =\n    PDET\n  | PTET\n  | PDPTET\n  | PML4ET\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPDE e) = PDET\"\n| \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOPDPTE e) = PDPTET\"\n| \"archTypeOf (KOPML4E e) = PML4ET\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\nend"}
{"title": "./spec/design/skel/X64/State_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Machine and kernel state.\n*)\n\nchapter \"Machine State\"\n\ntheory State_H\nimports\n  RegisterSet_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  Word :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  Word_def[simp]:\n \"Word \\<equiv> id\"\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits ONLY wordBits\n\nend\n\n(* Note: while this requalify and arch-generic Haskell import of WordLib.lhs could be moved to\n   a generic theory, no good candidate theory exists at the moment. *)\narch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=X64 CONTEXT X64_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend"}
{"title": "./spec/design/skel/X64/ArchInterrupt_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/X64.lhs CONTEXT X64_H bodies_only ArchInv= Arch=\n\nend\n\nend"}
{"title": "./spec/design/skel/X64/ArchRetype_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/X64.lhs CONTEXT X64_H Arch.Types=ArchTypes_H ArchInv=ArchRetypeDecls_H NOT bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/X64.lhs CONTEXT X64_H bodies_only\n\nend (* context X64 *)\nend"}
{"title": "./spec/design/skel/X64/ArchIntermediate_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewPageCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        return $ map (\\<lambda>n. PageCap (PPtr (fromPPtr n)) VMReadWrite VMNoMap pSize dev Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 0 X64SmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev ptTranslationBits X64LargePage\n        | HugePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev (ptTranslationBits + ptTranslationBits) X64HugePage\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        | PageDirectoryObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdBits (makeObject::pde) PageDirectoryCap\n              (\\<lambda>pts. return ())\n        | PDPointerTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdptBits (makeObject::pdpte) PDPointerTableCap\n              (\\<lambda>pts. return ())\n        | PML4Object \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pml4Bits (makeObject::pml4e) PML4Cap\n              (\\<lambda>pms. mapM_x copyGlobalMappings pms)\n        )\"\n\nend\nend\n\nend"}
{"title": "./spec/design/skel/X64/ArchThread_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\nbegin\n\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/X64.lhs CONTEXT X64_H Arch=MachineOps ArchReg=MachineTypes bodies_only\n\nend (* context X64 *)\n\nend"}
{"title": "./spec/design/skel/X64/ArchLabelFuns_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Label Functions\"\n\ntheory ArchLabelFuns_H\nimports InvocationLabels_H\nbegin\n\ntext \\<open>\n  Arch-specific functions on invocation labels\n\\<close>\n\n(* None for x64 *)\n\nend"}
{"title": "./spec/design/skel/X64/ArchHypervisor_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  Hypervisor stub for X64\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/X64.lhs Arch= CONTEXT X64_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/X64.lhs Arch= CONTEXT X64_H bodies_only ArchInv= ArchLabels=\n\nend\nend"}
{"title": "./spec/design/skel/X64/ArchInterruptDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/X64.lhs CONTEXT X64_H decls_only ArchInv= Arch=MachineOps\n\nend (* context X64 *)\n\nend"}
{"title": "./spec/design/skel/X64/Hardware_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs Platform=Platform.X64 CONTEXT X64_H NOT getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory wordFromPDE wordFromPTE VMFaultType HypFaultType VMMapType VMPageSize pageBits pageBitsForSize paddrBase pptrBase pptrTop pptrBaseOffset kernelELFBaseOffset kernelELFPAddrBase kernelELFBase toPAddr addrFromPPtr ptrFromPAddr addrFromKPPtr setCurrentUserCR3 getCurrentUserCR3 invalidateTLB invalidateTLBEntry mfence wordFromPML4E wordFromPDPTE firstValidIODomain numIODomainIDBits hwASIDInvalidate getFaultAddress irqIntOffset maxPCIBus maxPCIDev maxPCIFunc ioapicIRQLines ioapicMapPinToVector irqStateIRQIOAPICNew irqStateIRQMSINew updateIRQState in8 out8 in16 out16 in32 out32 invalidatePageStructureCache writeCR3 invalidateASID invalidateTranslationSingleASID invalidateLocalPageStructureCacheASID ptTranslationBits nativeThreadUsingFPU switchFpuOwner\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64_H instanceproofs NOT VMFaultType VMPageSize VMPageEntry VMMapType HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64_H ONLY wordFromPDE wordFromPTE wordFromPML4E wordFromPDPTE\n\n(* Unlike on Arm architectures, maxIRQ comes from Platform definitions.\n   We provide this abbreviation to match arch-split expectations. *)\nabbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Platform.X64.maxIRQ\"\n\nend (* context X64 *)\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchPSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/RISCV64.hs\n\nend (* context Arch *)\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchThreadDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/RISCV64.hs CONTEXT RISCV64_H decls_only\n\nend (* context RISCV64 *)\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchTypes_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n   Types visible in the API.\n*)\n\nchapter \"Arch-dependant Types visible in the API\"\n\ntheory ArchTypes_H\nimports\n  State_H\n  Hardware_H\n  \"Lib.Lib\"\nbegin\n\n#INCLUDE_HASKELL SEL4/API/Types/Universal.lhs all_bits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Types/RISCV64.hs CONTEXT RISCV64_H\n\nend\n\ntext \\<open>object\\_type instance proofs\\<close>\n\nqualify RISCV64_H (in Arch)\ninstantiation RISCV64_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [HugePageObject,\n      SmallPageObject,\n      LargePageObject,\n      PageTableObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation RISCV64_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation RISCV64_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchStateData_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/RISCV64.hs CONTEXT RISCV64_H NOT RISCVVSpaceRegionUse\n\nend\nend"}
{"title": "./spec/design/skel/RISCV64/ArchFault_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Failures/RISCV64.hs CONTEXT RISCV64_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/RISCV64.hs CONTEXT RISCV64_H bodies_only\n\nend\nend"}
{"title": "./spec/design/skel/RISCV64/ArchObjInsts_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Defines the instances of pspace_storable objects.\n*)\n\nchapter \"Storable Arch Object Instances\"\n\ntheory ArchObjInsts_H\nimports\n  ArchTypes_H\n  PSpaceStorable_H\n  ObjectInstances_H\nbegin\n\nqualify RISCV64_H (in Arch)\n\ninstantiation RISCV64_H.pte :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pte:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOPTE e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pte [simp]:\n  \"injectKO e \\<equiv> KOArch (KOPTE e)\"\n\ndefinition\n  koType_pte [simp]:\n  \"koType (t::pte itself) \\<equiv> ArchT PTET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pte split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation RISCV64_H.asidpool :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  injectKO_asidpool [simp]:\n  \"injectKO e \\<equiv> KOArch (KOASIDPool e)\"\n\ndefinition\n  koType_asidpool [simp]:\n  \"koType (t::asidpool itself) \\<equiv> ArchT ASIDPoolT\"\n\ndefinition\n  projectKO_opt_asidpool:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOASIDPool e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_asidpool split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\nlemmas (in Arch) projectKO_opts_defs =\n  projectKO_opt_pte\n  projectKO_opt_asidpool\n  ObjectInstances_H.projectKO_opts_defs\n\nlemmas (in Arch) [simp] =\n  injectKO_pte koType_pte\n  injectKO_asidpool koType_asidpool\n\n\n\\<comment> \\<open>--------------------------------------\\<close>\n\n#INCLUDE_SETTINGS keep_constructor = asidpool\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/RISCV64.hs\n#INCLUDE_HASKELL_PREPARSE SEL4/Machine/Hardware/RISCV64.hs\n\n\ninstantiation RISCV64_H.pte :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/RISCV64.hs instanceproofs bodies_only ONLY PTE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\n\n\n(* This is hard coded since using funArray in haskell for 2^32 bound is risky *)\n\ninstantiation RISCV64_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend"}
{"title": "./spec/design/skel/RISCV64/Arch_Structs_B.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Setup_Locale\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/RISCV64.hs CONTEXT RISCV64_H ONLY RISCVVSpaceRegionUse\n\nend\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchVSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  Untyped_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/RISCV64.hs CONTEXT RISCV64_H bodies_only ArchInv=ArchRetypeDecls_H ONLY pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft\n\nfun\n  lookupPTSlotFromLevel :: \"nat => machine_word => machine_word => (nat * machine_word) kernel\"\nwhere\n  \"lookupPTSlotFromLevel 0 ptPtr vPtr =\n     return (ptBitsLeft 0, ptSlotIndex 0 ptPtr vPtr)\"\n| \"lookupPTSlotFromLevel level ptPtr vPtr = do\n     pte <- pteAtIndex level ptPtr vPtr;\n     if isPageTablePTE pte\n     then do\n       checkPTAt (getPPtrFromHWPTE pte);\n       lookupPTSlotFromLevel (level - 1) (getPPtrFromHWPTE pte) vPtr\n     od\n     else return (ptBitsLeft level, ptSlotIndex level ptPtr vPtr)\n   od\"\n\nfun\n  lookupPTFromLevel :: \"nat => machine_word => machine_word => machine_word =>\n    (lookup_failure, machine_word) kernel_f\"\nwhere\n  \"lookupPTFromLevel level ptPtr vPtr targetPtPtr = doE\n    assertE (ptPtr \\<noteq> targetPtPtr);\n    unlessE (0 < level) $ throw InvalidRoot;\n    slot <- returnOk $ ptSlotIndex level ptPtr vPtr;\n    pte <- withoutFailure $ getObject slot;\n    unlessE (isPageTablePTE pte) $ throw InvalidRoot;\n    ptr <- returnOk (getPPtrFromHWPTE pte);\n    if ptr = targetPtPtr\n        then returnOk slot\n        else doE\n          liftE $ checkPTAt ptr;\n          lookupPTFromLevel (level - 1) ptr vPtr targetPtPtr\n        odE\n  odE\"\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/RISCV64.hs CONTEXT RISCV64_H bodies_only ArchInv=ArchRetypeDecls_H NOT lookupPTSlotFromLevel lookupPTFromLevel pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft checkPTAt\n\nend\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchTCB_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchTCB_H\nimports TCBDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/RISCV64.hs RegisterSet= CONTEXT RISCV64_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend"}
{"title": "./spec/design/skel/RISCV64/ArchVSpaceDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT RISCV64_H\n#INCLUDE_HASKELL_PREPARSE SEL4/API/InvocationLabels/RISCV64.hs CONTEXT RISCV64\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/RISCV64.hs CONTEXT RISCV64_H decls_only ArchInv= NOT lookupPTSlotFromLevel lookupPTFromLevel\n\nend (* context RISCV64 *)\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchRetypeDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetypeDecls_H\nimports\n  FaultMonad_H\n  EndpointDecls_H\n  KernelInitMonad_H\n  PSpaceFuns_H\n  ArchObjInsts_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/RISCV64.hs\n\n#INCLUDE_HASKELL SEL4/API/Invocation/RISCV64.hs CONTEXT RISCV64_H decls_only NOT Invocation IRQControlInvocation\n\n#INCLUDE_HASKELL SEL4/API/Invocation/RISCV64.hs CONTEXT RISCV64_H decls_only ONLY Invocation IRQControlInvocation\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/RISCV64.hs CONTEXT RISCV64_H Arch.Types=ArchTypes_H ArchInv= decls_only\n\nend (*context RISCV64*)\n\n(* Defined differently and/or delayed on different architectures *)\nconsts canonicalAddressAssert :: \"machine_word => bool\"\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchInvocationLabels_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Labels\"\n\ntheory ArchInvocationLabels_H\nimports\n  \"Word_Lib.Enumeration\"\n  Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\ntext \\<open>\n  An enumeration of arch-specific system call labels.\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/RISCV64.hs CONTEXT RISCV64_H ONLY ArchInvocationLabel\n\nend\n\n(* not possible to move this requalification to generic, since enum instance proofs must\n   be done outside of Arch locale *)\narch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/RISCV64.hs CONTEXT RISCV64_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend"}
{"title": "./spec/design/skel/RISCV64/RegisterSet_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext ((K 0) aLU initContext)\"\n\nend\nend"}
{"title": "./spec/design/skel/RISCV64/ArchFaultHandler_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/RISCV64.hs\n\n#INCLUDE_HASKELL SEL4/API/Faults/RISCV64.hs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/RISCV64.hs bodies_only\n\nend\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchStructures_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H decls_only\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/RISCV64.hs CONTEXT RISCV64_H bodies_only\n\ndatatype arch_kernel_object_type =\n    PTET\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\nend"}
{"title": "./spec/design/skel/RISCV64/State_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Machine and kernel state.\n*)\n\nchapter \"Machine State\"\n\ntheory State_H\nimports\n  RegisterSet_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  Word :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  Word_def[simp]:\n \"Word \\<equiv> id\"\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits ONLY wordBits\n\nend\n\n(* Note: while this requalify and arch-generic Haskell import of WordLib.lhs could be moved to\n   a generic theory, no good candidate theory exists at the moment. *)\narch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=RISCV64 CONTEXT RISCV64_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend"}
{"title": "./spec/design/skel/RISCV64/ArchInterrupt_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/RISCV64.hs CONTEXT RISCV64_H bodies_only ArchInv= Arch= NOT plic_complete_claim\n\nend\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchRetype_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/RISCV64.hs CONTEXT RISCV64_H Arch.Types=ArchTypes_H ArchInv=ArchRetypeDecls_H NOT bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/RISCV64.hs CONTEXT RISCV64_H bodies_only\n\nend (* context RISCV64 *)\nend"}
{"title": "./spec/design/skel/RISCV64/ArchIntermediate_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewFrameCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        return $ map (\\<lambda>n. FrameCap  (PPtr (fromPPtr n)) VMReadWrite pSize dev Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev 0 RISCVSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev ptTranslationBits RISCVLargePage\n        | HugePageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev (ptTranslationBits + ptTranslationBits) RISCVHugePage\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        )\"\n\nend\nend\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchThread_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/RISCV64.hs CONTEXT RISCV64_H Arch=MachineOps ArchReg=MachineTypes bodies_only\n\nend (* context RISCV64 *)\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchLabelFuns_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Label Functions\"\n\ntheory ArchLabelFuns_H\nimports InvocationLabels_H\nbegin\n\ntext \\<open>\n  Arch-specific functions on invocation labels\n\\<close>\n\n(* None for RISCV64 *)\n\nend"}
{"title": "./spec/design/skel/RISCV64/ArchHypervisor_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  Hypervisor stub for RISCV64\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  KI_Decls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/RISCV64.hs Arch= CONTEXT RISCV64_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/RISCV64.hs Arch= CONTEXT RISCV64_H bodies_only ArchInv= ArchLabels=\n\nend\nend"}
{"title": "./spec/design/skel/RISCV64/ArchInterruptDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/RISCV64.hs CONTEXT RISCV64_H decls_only ArchInv= Arch=MachineOps NOT plic_complete_claim\n\nend (* context RISCV64 *)\n\nend"}
{"title": "./spec/design/skel/RISCV64/Hardware_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs Platform=Platform.RISCV64 CONTEXT RISCV64_H NOT plic_complete_claim getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory setHardwareASID wordFromPDE wordFromPTE VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize toPAddr addrFromPPtr ptrFromPAddr sfence physBase paddrBase pptrBase pptrBaseOffset pptrTop pptrUserTop kernelELFBase kernelELFBaseOffset kernelELFPAddrBase addrFromKPPtr ptTranslationBits vmFaultTypeFSR read_stval setVSpaceRoot hwASIDFlush setIRQTrigger\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64_H instanceproofs NOT plic_complete_claim HardwareASID VMFaultType VMPageSize VMPageEntry HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64_H ONLY wordFromPTE\n\n(* Unlike on Arm architectures, maxIRQ comes from Platform definitions.\n   We provide this abbreviation to match arch-split expectations. *)\nabbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Platform.RISCV64.maxIRQ\"\n\nend (* context RISCV64 *)\n\nend"}
{"title": "./spec/design/skel/AARCH64/VCPU_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"VCPU\"\n\ntheory VCPU_H\nimports\n  Hardware_H\n  Structures_H\n  Invocations_H\n  TCB_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT AARCH64_H\n#INCLUDE_HASKELL SEL4/Object/VCPU/AARCH64.hs CONTEXT AARCH64_H ArchInv=Arch \\\n  NOT vcpuUpdate vgicUpdate vgicUpdateLR vcpuSaveReg vcpuRestoreReg \\\n    vcpuSaveRegRange vcpuRestoreRegRange vcpuWriteReg vcpuReadReg saveVirtTimer \\\n    restoreVirtTimer vcpuDisable vcpuEnable vcpuRestore vcpuSave vcpuSwitch \\\n    vcpuInvalidateActive vcpuCleanInvalidateActive countTrailingZeros virqType \\\n    virqSetEOIIRQEN vgicMaintenance vppiEvent irqVPPIEventIndex armvVCPUSave \\\n    curVCPUActive\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/ArchPSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/AARCH64.hs decls_only ONLY pTablePartialOverlap\n#INCLUDE_HASKELL SEL4/Model/PSpace/AARCH64.hs NOT pTablePartialOverlap\n\nend (* context Arch *)\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchThreadDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/AARCH64.hs CONTEXT AARCH64_H decls_only\n\nend (* context AARCH64 *)\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchTypes_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n   Types visible in the API.\n*)\n\nchapter \"Arch-dependant Types visible in the API\"\n\ntheory ArchTypes_H\nimports\n  State_H\n  Hardware_H\n  \"Lib.Lib\"\nbegin\n\n#INCLUDE_HASKELL SEL4/API/Types/Universal.lhs all_bits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Types/AARCH64.hs CONTEXT AARCH64_H\n\nend\n\ntext \\<open>object\\_type instance proofs\\<close>\n\nqualify AARCH64_H (in Arch)\ninstantiation AARCH64_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [HugePageObject,\n      VSpaceObject,\n      SmallPageObject,\n      LargePageObject,\n      PageTableObject,\n      VCPUObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation AARCH64_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation AARCH64_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchStateData_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/AARCH64.hs CONTEXT AARCH64_H NOT ArmVSpaceRegionUse\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/ArchFault_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Failures/AARCH64.hs CONTEXT AARCH64_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/AARCH64.hs CONTEXT AARCH64_H bodies_only\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/ArchObjInsts_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Defines the instances of pspace_storable objects.\n*)\n\nchapter \"Storable Arch Object Instances\"\n\ntheory ArchObjInsts_H\nimports\n  ArchTypes_H\n  PSpaceStorable_H\n  ObjectInstances_H\nbegin\n\nqualify AARCH64_H (in Arch)\n\ninstantiation AARCH64_H.pte :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pte:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOPTE e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pte [simp]:\n  \"injectKO e \\<equiv> KOArch (KOPTE e)\"\n\ndefinition\n  koType_pte [simp]:\n  \"koType (t::pte itself) \\<equiv> ArchT PTET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pte split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation AARCH64_H.vcpu :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_vcpu:\n  \"projectKO_opt e \\<equiv> case e of KOArch (KOVCPU e) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_vcpu [simp]:\n  \"injectKO e \\<equiv> KOArch (KOVCPU e)\"\n\ndefinition\n  koType_vcpu [simp]:\n  \"koType (t::vcpu itself) \\<equiv> ArchT VCPUT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_vcpu injectKO_vcpu koType_vcpu\n          split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation AARCH64_H.asidpool :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  injectKO_asidpool [simp]:\n  \"injectKO e \\<equiv> KOArch (KOASIDPool e)\"\n\ndefinition\n  koType_asidpool [simp]:\n  \"koType (t::asidpool itself) \\<equiv> ArchT ASIDPoolT\"\n\ndefinition\n  projectKO_opt_asidpool:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOASIDPool e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_asidpool split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\nlemmas (in Arch) projectKO_opts_defs =\n  projectKO_opt_pte\n  projectKO_opt_vcpu\n  projectKO_opt_asidpool\n  ObjectInstances_H.projectKO_opts_defs\n\nlemmas (in Arch) [simp] =\n  injectKO_pte koType_pte\n  injectKO_asidpool koType_asidpool\n\n\n\\<comment> \\<open>--------------------------------------\\<close>\n\n#INCLUDE_SETTINGS keep_constructor = asidpool\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/AARCH64.hs\n#INCLUDE_HASKELL_PREPARSE SEL4/Machine/Hardware/AARCH64.hs\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/VCPU/AARCH64.hs\n\ninstantiation AARCH64_H.pte :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/AARCH64.hs instanceproofs bodies_only ONLY PTE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\ninstantiation AARCH64_H.vcpu :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/AARCH64.hs\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/VCPU/AARCH64.hs\n#INCLUDE_HASKELL SEL4/Object/Instances/AARCH64.hs instanceproofs bodies_only ONLY VCPU\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\n(* This is hard coded since using funArray in haskell for 2^32 bound is risky *)\n\ninstantiation AARCH64_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend"}
{"title": "./spec/design/skel/AARCH64/Arch_Structs_B.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Setup_Locale\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/AARCH64.hs CONTEXT AARCH64_H ONLY ArmVSpaceRegionUse\n\n#INCLUDE_HASKELL SEL4/API/Invocation/AARCH64.hs CONTEXT AARCH64_H ONLY FlushType\n\nend\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchVSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv=ArchRetypeDecls_H ONLY pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft\n\nfun\n  lookupPTSlotFromLevel :: \"nat => machine_word => machine_word => (nat * machine_word) kernel\"\nwhere\n  \"lookupPTSlotFromLevel 0 ptPtr vPtr =\n     return (ptBitsLeft 0, ptSlotIndex 0 ptPtr vPtr)\"\n| \"lookupPTSlotFromLevel level ptPtr vPtr = do\n     pte <- pteAtIndex level ptPtr vPtr;\n     if isPageTablePTE pte\n     then do\n       checkPTAt NormalPT_T (getPPtrFromPTE pte);\n       lookupPTSlotFromLevel (level - 1) (getPPtrFromPTE pte) vPtr\n     od\n     else return (ptBitsLeft level, ptSlotIndex level ptPtr vPtr)\n   od\"\n\nfun\n  lookupPTFromLevel :: \"nat => machine_word => machine_word => machine_word =>\n    (lookup_failure, machine_word) kernel_f\"\nwhere\n  \"lookupPTFromLevel level ptPtr vPtr targetPtPtr = doE\n    assertE (ptPtr \\<noteq> targetPtPtr);\n    unlessE (0 < level) $ throw InvalidRoot;\n    slot <- returnOk $ ptSlotIndex level ptPtr vPtr;\n    pte <- withoutFailure $ getObject slot;\n    unlessE (isPageTablePTE pte) $ throw InvalidRoot;\n    ptr <- returnOk (getPPtrFromPTE pte);\n    if ptr = targetPtPtr\n        then returnOk slot\n        else doE\n          liftE $ checkPTAt NormalPT_T ptr;\n          lookupPTFromLevel (level - 1) ptr vPtr targetPtPtr\n        odE\n  odE\"\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv=ArchRetypeDecls_H NOT lookupPTSlotFromLevel lookupPTFromLevel pteAtIndex getPPtrFromHWPTE isPageTablePTE ptBitsLeft checkPTAt checkValidMappingSize\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert (\\<lambda>s. 2 ^ sz <= gsMaxObjectSize s) []\"\n\nend\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchTCB_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchTCB_H\nimports TCBDecls_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/AARCH64.hs RegisterSet= CONTEXT AARCH64_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/ArchVSpaceDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT AARCH64_H\n#INCLUDE_HASKELL_PREPARSE SEL4/API/InvocationLabels/AARCH64.hs CONTEXT AARCH64\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/AARCH64.hs CONTEXT AARCH64_H decls_only ArchInv= \\\n  NOT lookupPTSlotFromLevel lookupPTFromLevel pageBase\n\n(* no \"wordlike\" class with a direct translation available, use more constrained spec *)\nconsts'\npageBase :: \"('a :: len word) \\<Rightarrow> nat \\<Rightarrow> 'a word\"\n\nend (* context AARCH64 *)\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchRetypeDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetypeDecls_H\nimports\n  FaultMonad_H\n  EndpointDecls_H\n  KernelInitMonad_H\n  PSpaceFuns_H\n  ArchObjInsts_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/AARCH64.hs\n\n#INCLUDE_HASKELL SEL4/API/Invocation/AARCH64.hs CONTEXT AARCH64_H decls_only \\\n  NOT Invocation IRQControlInvocation isVSpaceFlushLabel isPageFlushLabel FlushType\n\n#INCLUDE_HASKELL SEL4/API/Invocation/AARCH64.hs CONTEXT AARCH64_H decls_only ONLY Invocation IRQControlInvocation\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/AARCH64.hs CONTEXT AARCH64_H Arch.Types=ArchTypes_H ArchInv= decls_only\n\nend (*context AARCH64*)\n\n(* Defined differently and/or delayed on different architectures *)\nconsts canonicalAddressAssert :: \"machine_word => bool\"\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchInvocationLabels_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Labels\"\n\ntheory ArchInvocationLabels_H\nimports\n  \"Word_Lib.Enumeration\"\n  Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\ntext \\<open>\n  An enumeration of arch-specific system call labels.\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/AARCH64.hs CONTEXT AARCH64_H ONLY ArchInvocationLabel\n\nend\n\n(* not possible to move this requalification to generic, since enum instance proofs must\n   be done outside of Arch locale *)\narch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/AARCH64.hs CONTEXT AARCH64_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/RegisterSet_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition newFPUState :: \"fpu_state\" where\n  \"newFPUState \\<equiv> FPUState (K 0) 0 0 \"\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext newFPUState ((K 0) aLU initContext)\"\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/ArchFaultHandler_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/AARCH64.hs\n\n#INCLUDE_HASKELL SEL4/API/Faults/AARCH64.hs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/AARCH64.hs bodies_only\n\nend\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchStructures_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64_H decls_only \\\n  NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64_H instanceproofs \\\n  NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64_H bodies_only \\\n  NOT makeVCPUObject\n\n(* we define makeVCPUObject_def manually because we want a total function vgicLR *)\ndefs makeVCPUObject_def:\n\"makeVCPUObject \\<equiv>\n    VCPUObj_ \\<lparr>\n          vcpuTCBPtr= Nothing\n        , vcpuVGIC= VGICInterface_ \\<lparr>\n                          vgicHCR= vgicHCREN\n                        , vgicVMCR= 0\n                        , vgicAPR= 0\n                        , vgicLR= (\\<lambda>_. 0)\n                        \\<rparr>\n        , vcpuRegs= funArray (const 0)  aLU  [(VCPURegSCTLR, sctlrEL1VM)]\n        , vcpuVPPIMasked= (\\<lambda>_. False)\n        , vcpuVTimer= VirtTimer 0\n        \\<rparr>\"\n\ndatatype arch_kernel_object_type =\n    PTET\n  | VCPUT\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOVCPU e) = VCPUT\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\n\n(* not possible to move this requalification to generic, as some arches don't have vcpu *)\narch_requalify_types (H)\n  vcpu\n\nend"}
{"title": "./spec/design/skel/AARCH64/State_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Machine and kernel state.\n*)\n\nchapter \"Machine State\"\n\ntheory State_H\nimports\n  RegisterSet_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  Word :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  Word_def[simp]:\n \"Word \\<equiv> id\"\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits ONLY wordBits\n\nend\n\n(* Note: while this requalify and arch-generic Haskell import of WordLib.lhs could be moved to\n   a generic theory, no good candidate theory exists at the moment. *)\narch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=AARCH64 CONTEXT AARCH64_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/ArchInterrupt_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/AARCH64.hs CONTEXT AARCH64_H bodies_only ArchInv= Arch= NOT plic_complete_claim\n\nend\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchRetype_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  KI_Decls_H\n  VCPU_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/AARCH64.hs CONTEXT AARCH64_H Arch.Types=ArchTypes_H ArchInv=ArchRetypeDecls_H NOT bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/AARCH64.hs CONTEXT AARCH64_H bodies_only \\\n  NOT isVSpaceFlushLabel isPageFlushLabel\n\nend (* context AARCH64 *)\nend"}
{"title": "./spec/design/skel/AARCH64/ArchIntermediate_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewFrameCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        when (\\<not>dev) $\n          mapM_x (\\<lambda>addr. doMachineOp $\n                            cleanCacheRange_RAM addr\n                                                (addr + mask (pageBitsForSize pSize))\n                                                (addrFromPPtr addr)) addrs;\n        return $ map (\\<lambda>n. FrameCap  (PPtr (fromPPtr n)) VMReadWrite pSize dev Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects ptType objectProto cap initialiseMappings \\<equiv> (do\n      tableBits \\<leftarrow> return (ptBits ptType);\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      modify (\\<lambda>ks. ks \\<lparr>ksArchState :=\n                         ksArchState ks \\<lparr>gsPTTypes := (\\<lambda>addr.\n                                           if addr `~elem~` map fromPPtr addrs then Just ptType\n                                           else gsPTTypes (ksArchState ks) addr)\\<rparr>\\<rparr>);\n      initialiseMappings pts;\n      mapM_x (\\<lambda>addr. doMachineOp $\n                       cleanCacheRange_PoU addr (addr + mask tableBits) (addrFromPPtr addr)) addrs;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev 0 ARMSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev (ptTranslationBits NormalPT_T) ARMLargePage\n        | HugePageObject \\<Rightarrow>\n            createNewFrameCaps regionBase numObjects dev (2 * ptTranslationBits NormalPT_T) ARMHugePage\n        | VSpaceObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects VSRootPT_T (makeObject::pte)\n              (\\<lambda>base addr. PageTableCap base VSRootPT_T addr)\n              (\\<lambda>pts. return ())\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects NormalPT_T (makeObject::pte)\n              (\\<lambda>base addr. PageTableCap base NormalPT_T addr)\n              (\\<lambda>pts. return ())\n        | VCPUObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject :: vcpu)) 0;\n            return $ map (\\<lambda>addr. VCPUCap addr) addrs\n            od)\n        )\"\n\nend\nend\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchThread_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/AARCH64.hs CONTEXT AARCH64_H Arch=MachineOps ArchReg=MachineTypes bodies_only\n\nend (* context AARCH64 *)\n\nend"}
{"title": "./spec/design/skel/AARCH64/ArchLabelFuns_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Label Functions\"\n\ntheory ArchLabelFuns_H\nimports InvocationLabels_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\ntext \\<open>\n  Arch-specific functions on invocation labels\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/Invocation/AARCH64.hs CONTEXT AARCH64_H \\\n  ONLY isVSpaceFlushLabel isPageFlushLabel\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/ArchHypervisor_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  Hypervisor function definitions for AARCH64\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  FaultHandlerDecls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/VCPU/AARCH64.hs CONTEXT AARCH64_H decls_only \\\n  ONLY countTrailingZeros irqVPPIEventIndex\n#INCLUDE_HASKELL SEL4/Object/VCPU/AARCH64.hs CONTEXT AARCH64_H bodies_only \\\n  ONLY countTrailingZeros irqVPPIEventIndex\n#INCLUDE_HASKELL SEL4/Object/VCPU/AARCH64.hs CONTEXT AARCH64_H ArchInv=Arch \\\n  ONLY vcpuUpdate vgicUpdate vgicUpdateLR vcpuSaveReg vcpuRestoreReg \\\n    vcpuSaveRegRange vcpuRestoreRegRange vcpuWriteReg vcpuReadReg saveVirtTimer \\\n    restoreVirtTimer vcpuDisable vcpuEnable vcpuRestore armvVCPUSave \\\n    vcpuSave vcpuSwitch vcpuInvalidateActive vcpuCleanInvalidateActive \\\n    virqType virqSetEOIIRQEN vgicMaintenance vppiEvent curVCPUActive\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/AARCH64.hs Arch= CONTEXT AARCH64_H decls_only ArchInv= ArchLabels=\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/AARCH64.hs Arch= CONTEXT AARCH64_H bodies_only ArchInv= ArchLabels=\n\nend\nend"}
{"title": "./spec/design/skel/AARCH64/ArchInterruptDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/AARCH64.hs CONTEXT AARCH64_H decls_only ArchInv= Arch=MachineOps NOT plic_complete_claim\n\nend (* context AARCH64 *)\n\nend"}
{"title": "./spec/design/skel/AARCH64/Hardware_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs Platform=Platform.AARCH64 CONTEXT AARCH64_H \\\n  NOT PT_Type plic_complete_claim getMemoryRegions getDeviceRegions getKernelDevices \\\n  loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt \\\n  configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory \\\n  clearMemoryVM initMemory freeMemory setHardwareASID wordFromPDE wordFromPTE \\\n  VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize toPAddr \\\n  addrFromPPtr ptrFromPAddr sfence physBase paddrBase pptrBase pptrBaseOffset \\\n  pptrUserTop kernelELFBase kernelELFBaseOffset kernelELFPAddrBase \\\n  addrFromKPPtr ptTranslationBits vmFaultTypeFSR setVSpaceRoot \\\n  setIRQTrigger \\\n  config_ARM_PA_SIZE_BITS_40 fpuThreadDeleteOp isFpuEnable \\\n  hcrVCPU hcrNative sctlrDefault vgicHCREN gicVCPUMaxNumLR sctlrEL1VM \\\n  get_gic_vcpu_ctrl_hcr set_gic_vcpu_ctrl_hcr get_gic_vcpu_ctrl_vmcr \\\n  set_gic_vcpu_ctrl_vmcr get_gic_vcpu_ctrl_apr set_gic_vcpu_ctrl_apr \\\n  get_gic_vcpu_ctrl_vtr get_gic_vcpu_ctrl_eisr0 get_gic_vcpu_ctrl_eisr1 \\\n  get_gic_vcpu_ctrl_misr get_gic_vcpu_ctrl_lr set_gic_vcpu_ctrl_lr read_cntpct \\\n  check_export_arch_timer \\\n  isb dsb dmb \\\n  invalidateTranslationASID invalidateTranslationSingle \\\n  cleanByVA_PoU cleanInvalidateCacheRange_RAM cleanCacheRange_RAM cleanCacheRange_PoU \\\n  invalidateCacheRange_RAM invalidateCacheRange_I branchFlushRange \\\n  enableFpuEL01 \\\n  getFAR getDFSR getIFSR getHSR setHCR getESR  getSCTLR setSCTLR \\\n  addressTranslateS1 \\\n  readVCPUHardwareReg writeVCPUHardwareReg vcpuBits\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs CONTEXT AARCH64_H instanceproofs NOT plic_complete_claim HardwareASID VMFaultType VMPageSize VMPageEntry HypFaultType\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs CONTEXT AARCH64_H ONLY wordFromPTE\n\n(* Kernel_Config provides a generic numeral, Haskell expects type irq *)\nabbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Kernel_Config.maxIRQ\"\n\nend (* context AARCH64 *)\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/VCPU_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"VCPU\"\n\ntheory VCPU_H\nimports\n  Hardware_H\n  Structures_H\n  Invocations_H\n  TCB_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT ARM_HYP_H\n#INCLUDE_HASKELL SEL4/Object/VCPU/ARM.lhs CONTEXT ARM_HYP_H ArchInv=Arch NOT vcpuUpdate vgicUpdate vgicUpdateLR vcpuSaveReg vcpuRestoreReg vcpuSaveRegRange vcpuRestoreRegRange vcpuWriteReg vcpuReadReg saveVirtTimer restoreVirtTimer vcpuDisable vcpuEnable vcpuRestore vcpuSave vcpuSwitch vcpuInvalidateActive vcpuCleanInvalidateActive countTrailingZeros virqSetEOIIRQEN vgicMaintenance vppiEvent irqVPPIEventIndex armvVCPUSave\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchPSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Arch-specific ghost update functions for physical memory *)\n\ntheory ArchPSpace_H\nimports\n  ObjectInstances_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/PSpace/ARM.hs\n\nend (* context Arch *)\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchThreadDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Declarations from SEL4.Kernel.Thread.\n*)\n\nchapter \"Function Declarations for Threads\"\n\ntheory ArchThreadDecls_H\nimports\n  Structures_H\n  FaultMonad_H\n  KernelInitMonad_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT Arch decls_only\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchTypes_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n   Types visible in the API.\n*)\n\nchapter \"Arch-dependant Types visible in the API\"\n\ntheory ArchTypes_H\nimports\n  State_H\n  Hardware_H\n  \"Lib.Lib\"\nbegin\n\n#INCLUDE_HASKELL SEL4/API/Types/Universal.lhs all_bits\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Types/ARM.lhs CONTEXT ARM_HYP_H\n\nend\n\ntext \\<open>object\\_type instance proofs\\<close>\n\nqualify ARM_HYP_H (in Arch)\ninstantiation ARM_HYP_H.object_type :: enum\nbegin\ninterpretation Arch .\ndefinition\n  enum_object_type: \"enum_class.enum \\<equiv>\n    map APIObjectType (enum_class.enum :: apiobject_type list) @\n     [PageDirectoryObject,\n      SmallPageObject,\n      LargePageObject,\n      SectionObject,\n      SuperSectionObject,\n      PageTableObject,\n      VCPUObject\n    ]\"\n\ndefinition\n  \"enum_class.enum_all (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Ball UNIV P\"\n\ndefinition\n  \"enum_class.enum_ex (P :: object_type \\<Rightarrow> bool) \\<longleftrightarrow> Bex UNIV P\"\n\n  instance\n    apply intro_classes\n     apply (safe, simp)\n     apply (case_tac x)\n    apply (simp_all add: enum_object_type)\n    apply (auto intro: distinct_map_enum\n                 simp: enum_all_object_type_def enum_ex_object_type_def)\n    done\nend\n\n\ninstantiation ARM_HYP_H.object_type :: enum_alt\nbegin\ninterpretation Arch .\ndefinition\n  enum_alt_object_type: \"enum_alt \\<equiv>\n    alt_from_ord (enum :: object_type list)\"\ninstance ..\nend\n\ninstantiation ARM_HYP_H.object_type :: enumeration_both\nbegin\ninterpretation Arch .\ninstance by (intro_classes, simp add: enum_alt_object_type)\nend\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchStateData_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Kernel state and kernel monads, imports everything that SEL4.Model needs.\n*)\n\nchapter \"Architecture Specific Kernel State and Monads\"\n\ntheory ArchStateData_H\nimports\n  Arch_Structs_B\n  ArchTypes_H\n  ArchStructures_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_HYP_H NOT ArmVSpaceRegionUse\n\nend\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchFault_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchFault_H\nimports Types_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/API/Failures/ARM.lhs CONTEXT ARM_HYP_H decls_only\n#INCLUDE_HASKELL SEL4/API/Failures/ARM.lhs CONTEXT ARM_HYP_H bodies_only\n\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchObjInsts_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Defines the instances of pspace_storable objects.\n*)\n\nchapter \"Storable Arch Object Instances\"\n\ntheory ArchObjInsts_H\nimports\n  ArchTypes_H\n  PSpaceStorable_H\n  ObjectInstances_H\nbegin\nqualify ARM_HYP_H (in Arch)\n\ninstantiation ARM_HYP_H.pde :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pde:\n  \"projectKO_opt e \\<equiv> case e of KOArch (KOPDE e) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pde:\n  \"injectKO e \\<equiv> KOArch (KOPDE e)\"\n\ndefinition\n  koType_pde:\n  \"koType (t::pde itself) \\<equiv> ArchT PDET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pde injectKO_pde koType_pde\n          split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation ARM_HYP_H.pte :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_pte:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOPTE e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_pte:\n  \"injectKO e \\<equiv> KOArch (KOPTE e)\"\n\ndefinition\n  koType_pte:\n  \"koType (t::pte itself) \\<equiv> ArchT PTET\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_pte injectKO_pte koType_pte\n          split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation ARM_HYP_H.vcpu :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  projectKO_opt_vcpu:\n  \"projectKO_opt e \\<equiv> case e of KOArch (KOVCPU e) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ndefinition\n  injectKO_vcpu:\n  \"injectKO e \\<equiv> KOArch (KOVCPU e)\"\n\ndefinition\n  koType_vcpu:\n  \"koType (t::vcpu itself) \\<equiv> ArchT VCPUT\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_vcpu injectKO_vcpu koType_vcpu\n          split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\ninstantiation ARM_HYP_H.asidpool :: pre_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  injectKO_asidpool:\n  \"injectKO e \\<equiv> KOArch (KOASIDPool e)\"\n\ndefinition\n  koType_asidpool:\n  \"koType (t::asidpool itself) \\<equiv> ArchT ASIDPoolT\"\n\ndefinition\n  projectKO_opt_asidpool:\n  \"projectKO_opt e \\<equiv> case e of (KOArch (KOASIDPool e)) \\<Rightarrow> Some e | _ \\<Rightarrow> None\"\n\ninstance\n  by (intro_classes,\n      auto simp: projectKO_opt_asidpool injectKO_asidpool koType_asidpool\n          split: kernel_object.splits arch_kernel_object.splits)\n\nend\n\nlemmas (in Arch) projectKO_opts_defs =\n  projectKO_opt_pde projectKO_opt_pte projectKO_opt_vcpu projectKO_opt_asidpool\n  ObjectInstances_H.projectKO_opts_defs\n\nlemmas (in Arch) [simp] =\n  injectKO_pde koType_pde\n  injectKO_pte koType_pte\n  injectKO_vcpu koType_vcpu\n  injectKO_asidpool koType_asidpool\n\n\\<comment> \\<open>--------------------------------------\\<close>\n\n#INCLUDE_SETTINGS keep_constructor = asidpool\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/ARM.lhs\n#INCLUDE_HASKELL_PREPARSE SEL4/Machine/Hardware/ARM.lhs\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/VCPU/ARM.lhs\n\n\ninstantiation ARM_HYP_H.pde :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL SEL4/Object/Instances/ARM.lhs instanceproofs bodies_only ONLY PDE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\ninstantiation ARM_HYP_H.pte :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/ARM.lhs\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/VCPU/ARM.lhs\n#INCLUDE_HASKELL SEL4/Object/Instances/ARM.lhs instanceproofs bodies_only ONLY PTE\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\ninstantiation ARM_HYP_H.vcpu :: pspace_storable\nbegin\ninterpretation Arch .\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures/ARM.lhs\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/VCPU/ARM.lhs\n#INCLUDE_HASKELL SEL4/Object/Instances/ARM.lhs instanceproofs bodies_only ONLY VCPU\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\n(* This is hard coded since using funArray in haskell for 2^32 bound is risky *)\n\ninstantiation ARM_HYP_H.asidpool :: pspace_storable\nbegin\ninterpretation Arch .\n\ndefinition\n  makeObject_asidpool: \"(makeObject :: asidpool)  \\<equiv> ASIDPool $\n        funArray (const Nothing)\"\n\ndefinition\n  loadObject_asidpool[simp]:\n \"(loadObject p q n obj) :: asidpool kernel \\<equiv>\n    loadObject_default p q n obj\"\n\ndefinition\n  updateObject_asidpool[simp]:\n \"updateObject (val :: asidpool) \\<equiv>\n    updateObject_default val\"\n\ninstance\n  apply (intro_classes)\n  apply (clarsimp simp add: updateObject_default_def in_monad projectKO_opts_defs\n                            projectKO_eq2\n                     split: kernel_object.splits arch_kernel_object.splits)\n  done\n\nend\n\nlemmas load_update_defs =\n  loadObject_pde updateObject_pde\n  loadObject_pte updateObject_pte\n  loadObject_asidpool updateObject_asidpool\n\ndeclare load_update_defs[simp del]\n\nend_qualify\n\ndeclare (in Arch) load_update_defs[simp]\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/Arch_Structs_B.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* Architecture-specific data types shared by spec and abstract. *)\n\nchapter \"Common, Architecture-Specific Data Types\"\n\ntheory Arch_Structs_B\nimports Main Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Model/StateData/ARM.lhs CONTEXT ARM_HYP_H ONLY ArmVSpaceRegionUse\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchVSpace_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchVSpace_H\nimports\n  CNode_H\n  KI_Decls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/ARM.lhs CONTEXT ARM_HYP_H bodies_only ArchInv=ArchRetypeDecls_H.ARM_HYP ArchLabels=ArchInvocationLabels_H.ARM_HYP NOT checkPDAt checkPTAt checkPDASIDMapMembership checkValidMappingSize vptrFromPPtr\n\ndefs checkValidMappingSize_def:\n  \"checkValidMappingSize sz \\<equiv> stateAssert\n    (\\<lambda>s. 2 ^ pageBitsForSize sz <= gsMaxObjectSize s) []\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchTCB_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchTCB_H\nimports TCBDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/TCB/ARM.lhs RegisterSet= CONTEXT ARM_HYP_H\n\n#INCLUDE_HASKELL SEL4/Object/TCB.lhs Arch= ONLY archThreadGet archThreadSet\n\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchVSpaceDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchVSpaceDecls_H\nimports ArchRetypeDecls_H InvocationLabels_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL_PREPARSE SEL4/Object/Structures.lhs CONTEXT ARM_HYP_H\n#INCLUDE_HASKELL SEL4/Kernel/VSpace/ARM.lhs CONTEXT ARM_HYP_H decls_only NOT pageBase ArchInv=\n\n(* no \"wordlike\" class with a direct translation available, use more constrained spec *)\nconsts'\npageBase :: \"('a :: len word) \\<Rightarrow> vmpage_size \\<Rightarrow> 'a word\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchRetypeDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetypeDecls_H\nimports\n  ArchLabelFuns_H\n  FaultMonad_H\n  EndpointDecls_H\n  KernelInitMonad_H\n  PSpaceFuns_H\n  ArchObjInsts_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs CONTEXT ARM_HYP_H decls_only NOT isPageFlushLabel isPDFlushLabel Invocation IRQControlInvocation CopyRegisterSets\n\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs CONTEXT ARM_HYP_H decls_only ONLY Invocation IRQControlInvocation CopyRegisterSets\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/ARM.lhs CONTEXT ARM_HYP_H Arch.Types=ArchTypes_H ArchInv= decls_only\n\n(* Defined differently and/or delayed on different architectures *)\ndefinition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend\n\n(* Defined differently and/or delayed on different architectures *)\ndefinition\n  canonicalAddressAssert :: \"machine_word => bool\" where\n  canonicalAddressAssert_def[simp]:\n  \"canonicalAddressAssert p = True\"\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchInvocationLabels_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Labels\"\n\ntheory ArchInvocationLabels_H\nimports\n    \"Word_Lib.Enumeration\"\n    Setup_Locale\nbegin\ncontext Arch begin arch_global_naming (H)\n\ntext \\<open>\n  An enumeration of arch-specific system call labels.\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_HYP_H ONLY ArchInvocationLabel\n\nend\n\n(* not possible to move this requalification to generic, since enum instance proofs must\n   be done outside of Arch locale *)\narch_requalify_types (H)\n  arch_invocation_label\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/API/InvocationLabels/ARM.lhs CONTEXT ARM_HYP_H instanceproofs ONLY ArchInvocationLabel\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/RegisterSet_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Register Set\"\n\ntheory RegisterSet_H\nimports\n  \"Lib.HaskellLib_H\"\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  newContext :: \"user_context\"\nwhere\n \"newContext \\<equiv> UserContext ((K 0) aLU initContext)\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchFaultHandler_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Fault Handlers\"\n\ntheory ArchFaultHandler_H\nimports TCB_H Structures_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL_PREPARSE SEL4/API/Failures/ARM.lhs\n\n#INCLUDE_HASKELL SEL4/API/Faults/ARM.lhs decls_only\n#INCLUDE_HASKELL SEL4/API/Faults/ARM.lhs bodies_only\n\nend\n\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchStructures_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchStructures_H\nimports\n  \"Lib.Lib\"\n  Types_H\n  Hardware_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_SETTINGS keep_constructor=asidpool\n#INCLUDE_SETTINGS keep_constructor=arch_tcb\n\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H decls_only NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H instanceproofs NOT VPPIEventIRQ VirtTimer\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP_H bodies_only NOT makeVCPUObject\n\n(* we define makeVCPUObject_def manually because we want a total function vgicLR *)\ndefs makeVCPUObject_def:\n\"makeVCPUObject \\<equiv>\n    VCPUObj_ \\<lparr>\n          vcpuTCBPtr= Nothing\n        , vcpuVGIC= VGICInterface_ \\<lparr>\n                          vgicHCR= vgicHCREN\n                        , vgicVMCR= 0\n                        , vgicAPR= 0\n                        , vgicLR= (\\<lambda>_. 0)\n                        \\<rparr>\n        , vcpuRegs= funArray (const 0)  aLU  [(VCPURegSCTLR, sctlrDefault)\n                                             ,(VCPURegACTLR, actlrDefault)]\n        , vcpuVPPIMasked= (\\<lambda>_. False)\n        , vcpuVTimer= VirtTimer 0\n        \\<rparr>\"\n\ndatatype arch_kernel_object_type =\n    PDET\n  | PTET\n  | VCPUT\n  | ASIDPoolT\n\nprimrec\n  archTypeOf :: \"arch_kernel_object \\<Rightarrow> arch_kernel_object_type\"\nwhere\n  \"archTypeOf (KOPDE e) = PDET\"\n| \"archTypeOf (KOPTE e) = PTET\"\n| \"archTypeOf (KOVCPU e) = VCPUT\"\n| \"archTypeOf (KOASIDPool e) = ASIDPoolT\"\n\nend\n\n(* not possible to move this requalification to generic, as some arches don't have vcpu *)\narch_requalify_types (H)\n  vcpu\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/State_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n    Machine and kernel state.\n*)\n\nchapter \"Machine State\"\n\ntheory State_H\nimports\n  \"Lib.HaskellLib_H\"\n  RegisterSet_H\n  MachineOps\nbegin\ncontext Arch begin arch_global_naming (H)\n\ndefinition\n  Word :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  Word_def[simp]:\n \"Word \\<equiv> id\"\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits ONLY wordBits\n\nend\n\n(* Note: while this requalify and arch-generic Haskell import of WordLib.lhs could be moved to\n   a generic theory, no good candidate theory exists at the moment. *)\narch_requalify_consts (H)\n  wordBits\n\n#INCLUDE_HASKELL Data/WordLib.lhs all_bits NOT wordBits\n\ncontext Arch begin arch_global_naming (H)\n\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet.lhs Arch=ARM_HYP CONTEXT ARM_HYP_H all_bits NOT UserContext UserMonad getRegister setRegister newContext mask Word PPtr\n\ndefinition\n  PPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  PPtr_def[simp]:\n \"PPtr \\<equiv> id\"\n\ndefinition\n  fromPPtr :: \"machine_word \\<Rightarrow> machine_word\"\nwhere\n  fromPPtr_def[simp]:\n \"fromPPtr \\<equiv> id\"\n\ndefinition\n  nullPointer :: machine_word\nwhere\n \"nullPointer \\<equiv> 0\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchInterrupt_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterrupt_H\nimports\n  RetypeDecls_H\n  CNode_H\n  InterruptDecls_H\n  ArchInterruptDecls_H\n  ArchHypervisor_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/ARM.lhs Arch= CONTEXT ARM_HYP_H bodies_only ArchInv= NOT initInterruptController\n\ndefinition initInterruptController :: \"unit kernel\"\n  where \"initInterruptController \\<equiv> (do\n    setIRQState IRQReserved $ irqVGICMaintenance;\n    return ()\nod)\"\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchRetype_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Retyping Objects\"\n\ntheory ArchRetype_H\nimports\n  ArchRetypeDecls_H\n  ArchVSpaceDecls_H\n  Hardware_H\n  VCPU_H\n  KI_Decls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/ObjectType/ARM.lhs CONTEXT ARM_HYP_H Arch.Types= ArchInv= bodies_only\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs bodies_only CONTEXT ARM_HYP_H NOT isPDFlushLabel isPageFlushLabel\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchIntermediate_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Intermediate\"\n\ntheory ArchIntermediate_H\nimports Intermediate_H\nbegin\n\ncontext Arch begin\ncontext begin\n\nprivate abbreviation (input)\n  \"createNewPageCaps regionBase numObjects dev gSize pSize \\<equiv>\n    let Data = (if dev then KOUserDataDevice else KOUserData) in\n    (do addrs \\<leftarrow> createObjects regionBase numObjects Data gSize;\n        modify (\\<lambda>ks. ks \\<lparr> gsUserPages := (\\<lambda> addr.\n          if addr `~elem~` map fromPPtr addrs then Just pSize\n          else gsUserPages ks addr)\\<rparr>);\n        when (\\<not>dev) $\n          mapM_x (\\<lambda>addr. doMachineOp $\n                            cleanCacheRange_RAM addr\n                                                (addr + mask (pageBitsForSize pSize))\n                                                (addrFromPPtr addr)) addrs;\n        return $ map (\\<lambda>n. PageCap dev (PPtr (fromPPtr n)) VMReadWrite pSize Nothing) addrs\n     od)\"\n\nprivate abbreviation (input)\n  \"createNewTableCaps regionBase numObjects tableBits objectProto cap initialiseMappings \\<equiv> (do\n      tableSize \\<leftarrow> return (tableBits - objBits objectProto);\n      addrs \\<leftarrow> createObjects regionBase numObjects (injectKO objectProto) tableSize;\n      pts \\<leftarrow> return (map (PPtr \\<circ> fromPPtr) addrs);\n      initialiseMappings pts;\n      mapM_x (\\<lambda>addr. doMachineOp $\n                       cleanCacheRange_PoU addr (addr + mask tableBits) (addrFromPPtr addr)) addrs;\n      return $ map (\\<lambda>pt. cap pt Nothing) pts\n    od)\"\n\ndefs Arch_createNewCaps_def:\n\"Arch_createNewCaps t regionBase numObjects userSize dev \\<equiv>\n    let pointerCast = PPtr \\<circ> fromPPtr\n    in (case t of\n          APIObjectType apiObject \\<Rightarrow> haskell_fail []\n        | SmallPageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 0 ARMSmallPage\n        | LargePageObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 4 ARMLargePage\n        | SectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 9 ARMSection\n        | SuperSectionObject \\<Rightarrow>\n            createNewPageCaps regionBase numObjects dev 13 ARMSuperSection\n        | PageTableObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects ptBits (makeObject::pte) PageTableCap\n              (\\<lambda>pts. return ())\n        | PageDirectoryObject \\<Rightarrow>\n            createNewTableCaps regionBase numObjects pdBits (makeObject::pde) PageDirectoryCap\n              (\\<lambda>pds. do objSize \\<leftarrow> return (((1::nat) `~shiftL~` pdBits));\n                        mapM_x copyGlobalMappings pds\n                     od)\n        | VCPUObject \\<Rightarrow> (do\n            addrs \\<leftarrow> createObjects regionBase numObjects (injectKO (makeObject :: vcpu)) 0;\n            return $ map (\\<lambda>addr. VCPUCap addr) addrs\n            od)\n        )\"\n\nend\nend\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchThread_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Threads\"\n\ntheory ArchThread_H\nimports\n  ArchThreadDecls_H\n  TCBDecls_H\n  ArchVSpaceDecls_H\n  ArchHypervisor_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Kernel/Thread/ARM.lhs CONTEXT ARM_HYP_H ARMHardware=ARM_HYP bodies_only\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchLabelFuns_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Invocation Label Functions\"\n\ntheory ArchLabelFuns_H\nimports InvocationLabels_H\nbegin\ncontext Arch begin arch_global_naming (H)\ntext \\<open>\n  Arch-specific functions on invocation labels\n\\<close>\n\n#INCLUDE_HASKELL SEL4/API/Invocation/ARM.lhs CONTEXT ARM_HYP_H ONLY isPDFlushLabel isPageFlushLabel\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchHypervisor_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n  VSpace lookup code.\n*)\n\ntheory ArchHypervisor_H\nimports\n  CNode_H\n  FaultHandlerDecls_H\n  InterruptDecls_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/VCPU/ARM.lhs CONTEXT ARM_HYP_H decls_only ONLY countTrailingZeros irqVPPIEventIndex\n#INCLUDE_HASKELL SEL4/Object/VCPU/ARM.lhs CONTEXT ARM_HYP_H bodies_only ONLY countTrailingZeros irqVPPIEventIndex\n\n#INCLUDE_HASKELL SEL4/Object/VCPU/ARM.lhs CONTEXT ARM_HYP_H ArchInv=Arch ONLY vcpuUpdate vgicUpdate vgicUpdateLR vcpuSaveReg vcpuRestoreReg vcpuSaveRegRange vcpuRestoreRegRange vcpuWriteReg vcpuReadReg saveVirtTimer restoreVirtTimer vcpuDisable vcpuEnable vcpuRestore armvVCPUSave vcpuSave vcpuSwitch vcpuInvalidateActive vcpuCleanInvalidateActive virqSetEOIIRQEN vgicMaintenance vppiEvent\n\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_HYP_H decls_only\n#INCLUDE_HASKELL SEL4/Kernel/Hypervisor/ARM.lhs Arch= CONTEXT ARM_HYP_H bodies_only\n\nend\nend"}
{"title": "./spec/design/skel/ARM_HYP/ArchInterruptDecls_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory ArchInterruptDecls_H\nimports RetypeDecls_H CNode_H\nbegin\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Object/Interrupt/ARM.lhs CONTEXT Arch decls_only ArchInv=\n\nend\n\nend"}
{"title": "./spec/design/skel/ARM_HYP/Hardware_H.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Hardware_H\nimports\n  MachineOps\n  State_H\nbegin\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs Platform=Platform.ARM_HYP CONTEXT ARM_HYP_H NOT getMemoryRegions getDeviceRegions getKernelDevices loadWord storeWord storeWordVM getActiveIRQ ackInterrupt maskInterrupt configureTimer resetTimer debugPrint getRestartPC setNextPC clearMemory clearMemoryVM initMemory freeMemory writeTTBR0 setGlobalPD  setTTBCR setHardwareASID invalidateLocalTLB invalidateLocalTLB_ASID invalidateLocalTLB_VAASID cleanByVA cleanByVA_PoU invalidateByVA invalidateByVA_I invalidate_I_PoU cleanInvalByVA branchFlush clean_D_PoU cleanInvalidate_D_PoC cleanInvalidate_D_PoU cleanInvalidateL2Range invalidateL2Range cleanL2Range isb dsb dmb getIFSR getDFSR getFAR HardwareASID wordFromPDE wordFromPTE VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize toPAddr paddrBase pptrBase pptrTop paddrTop kernelELFPAddrBase kernelELFBase kernelELFBaseOffset pptrBaseOffset cacheLineBits cacheLine lineStart cacheRangeOp cleanCacheRange_PoC cleanInvalidateCacheRange_RAM cleanCacheRange_RAM cleanCacheRange_PoU invalidateCacheRange_RAM invalidateCacheRange_I branchFlushRange cleanCaches_PoU cleanInvalidateL1Caches addrFromPPtr ptrFromPAddr addrFromKPPtr initIRQController MachineData hapFromVMRights wordsFromPDE wordsFromPTE writeContextIDAndPD hcrVCPU hcrNative vgicHCREN sctlrDefault actlrDefault gicVCPUMaxNumLR getHSR setHCR getHDFAR addressTranslateS1 getSCTLR setSCTLR getACTLR setACTLR get_gic_vcpu_ctrl_hcr set_gic_vcpu_ctrl_hcr get_gic_vcpu_ctrl_vmcr set_gic_vcpu_ctrl_vmcr get_gic_vcpu_ctrl_apr set_gic_vcpu_ctrl_apr get_gic_vcpu_ctrl_vtr get_gic_vcpu_ctrl_eisr0 get_gic_vcpu_ctrl_eisr1 get_gic_vcpu_ctrl_misr get_gic_vcpu_ctrl_lr set_gic_vcpu_ctrl_lr setCurrentPDPL2 readVCPUHardwareReg setIRQTrigger writeVCPUHardwareReg getTPIDRURO setTPIDRURO get_cntv_cval_64 set_cntv_cval_64 set_cntv_off_64 get_cntv_off_64 read_cntpct\n\nend\n\narch_requalify_types (H)\n  vmrights\n\ncontext Arch begin arch_global_naming (H)\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_HYP_H instanceproofs NOT HardwareASID VMFaultType HypFaultType VMPageSize\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_HYP_H ONLY hapFromVMRights wordsFromPDE wordsFromPTE\n\n(* Kernel_Config provides a generic numeral, Haskell expects type irq *)\nabbreviation (input) maxIRQ :: irq where\n  \"maxIRQ \\<equiv> Kernel_Config.maxIRQ\"\n\n(* provide ARM/ARM_HYP machine op in _H global_prefix for arch-split *)\nabbreviation (input) initIRQController where\n  \"initIRQController \\<equiv> ARM_HYP.initIRQController\"\n\nend\nend"}
{"title": "./spec/design/m-skel/ARM/MachineTypes.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"ARM Machine Types\"\n\ntheory MachineTypes\nimports\n  Word_Lib.WordSetup\n  Monads.Nondet_Empty_Fail\n  Monads.Nondet_Reader_Option\n  Setup_Locale\n  Platform\nbegin\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  An implementation of the machine's types, defining register set\n  and some observable machine state.\n\\<close>"}
{"title": "./spec/design/m-skel/ARM/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM decls_only NOT UserContext UserMonad Word getRegister setRegister newContext\n(*<*)\n\nend\n\narch_requalify_types register\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM instanceproofs\n(*>*)\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM bodies_only NOT getRegister setRegister newContext"}
{"title": "./spec/design/m-skel/ARM/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\ntext \\<open>\n  The exclusive monitors state is observable in user mode.\n  The type for this is the type used in the Cambridge HOL4 ARM model.\n\\<close>\ntype_synonym exclusive_monitors = \"(word32 \\<Rightarrow> bool) list \\<times> (word32 \\<times> nat \\<Rightarrow> bool)\"\n\ntext \\<open>\n  The full machine state is the state observable by the kernel plus\n  the underspecified rest above. The observable parts are the\n  interrupt controller (which IRQs are masked) and the memory of the\n  machine. The latter is shadow state: kernel memory is kept in a\n  separate, more abstract datatype; user memory is reflected down\n  to the underlying memory of the machine.\n\\<close>\nend\n\nqualify ARM (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"ARM.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  device_state :: \"word32 \\<Rightarrow> word8 option\"\n  exclusive_state :: ARM.exclusive_monitors\n  machine_state_rest :: ARM.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> ARM.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall> n. irq_oracle n <= Kernel_Config.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  The machine monad is used for operations on the state defined above.\n\\<close>\ntype_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c ARM.machine_monad\" <= (type) \"(ARM.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  After kernel initialisation all IRQs are masked.\n\\<close>\ndefinition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"\n\ntext \\<open>\n  The initial contents of the user-visible memory is 0.\n\\<close>\ndefinition\n  init_underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"\n\ntext \\<open>\n  The initial exclusive state is the same constant\n  that clearExMonitor defaults it to.\n\\<close>\n\nconsts' default_exclusive_state :: exclusive_monitors\n\ntext \\<open>\n  We leave open the underspecified rest of the machine state in\n  the initial state.\n\\<close>\ndefinition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         exclusive_state = default_exclusive_state,\n                         machine_state_rest = undefined \\<rparr>\"\n\n\n(* Machine/Hardware/ARM.lhs - hardware_asid, vmfault_type and vmpage_size *)\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM ONLY HardwareASID VMFaultType VMPageSize HypFaultType pageBits pageBitsForSize\n\nend\n\narch_requalify_types vmpage_size\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM instanceproofs ONLY HardwareASID VMFaultType VMPageSize HypFaultType\n\nend\nend"}
{"title": "./spec/design/m-skel/X64/MachineTypes.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"x86-64bit Machine Types\"\n\ntheory MachineTypes\nimports\n  Word_Lib.WordSetup\n  Monads.Nondet_Empty_Fail\n  Monads.Nondet_Reader_Option\n  Lib.HaskellLib_H\n  Platform\nbegin\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  An implementation of the machine's types, defining register set\n  and some observable machine state.\n\\<close>"}
{"title": "./spec/design/m-skel/X64/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/X64.lhs CONTEXT X64 decls_only NOT UserContext UserMonad Word getRegister setRegister newContext\n(*<*)\n\nend\n\narch_requalify_types register gdtslot\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/X64.lhs CONTEXT X64 instanceproofs\n(*>*)\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/X64.lhs CONTEXT X64 bodies_only NOT getRegister setRegister newContext"}
{"title": "./spec/design/m-skel/X64/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\nend\n\nqualify X64 (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"X64.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"word64 \\<Rightarrow> word8\"\n  device_state :: \"word64 \\<Rightarrow> word8 option\"\n  machine_state_rest :: X64.machine_state_rest\n\nconsts irq_oracle :: \"nat \\<Rightarrow> word8\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  The machine monad is used for operations on the state defined above.\n\\<close>\ntype_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c X64.machine_monad\" <= (type) \"(X64.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  After kernel initialisation all IRQs are masked.\n\\<close>\ndefinition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"\n\ntext \\<open>\n  The initial contents of the user-visible memory is 0.\n\\<close>\ndefinition\n  init_underlying_memory :: \"word64 \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"\n\ntext \\<open>\n  We leave open the underspecified rest of the machine state in\n  the initial state.\n\\<close>\ndefinition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         machine_state_rest = undefined \\<rparr>\"\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64 ONLY VMFaultType HypFaultType VMPageSize VMMapType pageBits ptTranslationBits pageBitsForSize\n\nend\n\narch_requalify_types vmpage_size vmmap_type\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/X64.lhs CONTEXT X64 instanceproofs ONLY VMFaultType HypFaultType VMPageSize VMMapType\n\nend\nend"}
{"title": "./spec/design/m-skel/RISCV64/MachineTypes.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"RISCV 64bit Machine Types\"\n\ntheory MachineTypes\nimports\n  Word_Lib.WordSetup\n  Monads.Nondet_Empty_Fail\n  Monads.Nondet_Reader_Option\n  Lib.HaskellLib_H\n  Platform\nbegin\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  An implementation of the machine's types, defining register set\n  and some observable machine state.\n\\<close>"}
{"title": "./spec/design/m-skel/RISCV64/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/RISCV64.hs CONTEXT RISCV64 decls_only NOT UserContext UserMonad Word getRegister setRegister newContext\n(*<*)\n\nend\n\narch_requalify_types register\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/RISCV64.hs CONTEXT RISCV64 instanceproofs\n(*>*)\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/RISCV64.hs CONTEXT RISCV64 bodies_only NOT getRegister setRegister newContext"}
{"title": "./spec/design/m-skel/RISCV64/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\nend\n\nqualify RISCV64 (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"RISCV64.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"machine_word \\<Rightarrow> word8\"\n  device_state :: \"machine_word \\<Rightarrow> word8 option\"\n  machine_state_rest :: RISCV64.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> RISCV64.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall>n. irq_oracle n <= RISCV64.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  The machine monad is used for operations on the state defined above.\n\\<close>\ntype_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c RISCV64.machine_monad\" <= (type) \"(RISCV64.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  After kernel initialisation all IRQs are masked.\n\\<close>\ndefinition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"\n\ntext \\<open>\n  The initial contents of the user-visible memory is 0.\n\\<close>\ndefinition\n  init_underlying_memory :: \"machine_word \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"\n\ntext \\<open>\n  We leave open the underspecified rest of the machine state in\n  the initial state.\n\\<close>\ndefinition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         machine_state_rest = undefined \\<rparr>\"\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64 ONLY VMFaultType HypFaultType vmFaultTypeFSR VMPageSize pageBits ptTranslationBits pageBitsForSize\n\nend\n\narch_requalify_types vmpage_size\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/RISCV64.hs CONTEXT RISCV64 instanceproofs ONLY VMFaultType HypFaultType VMPageSize\n\nend\nend"}
{"title": "./spec/design/m-skel/AARCH64/MachineTypes.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"AARCH64 Machine Types\"\n\ntheory MachineTypes\nimports\n  Word_Lib.WordSetup\n  Monads.Nondet_Empty_Fail\n  Monads.Nondet_Reader_Option\n  Lib.HaskellLib_H\n  Platform\nbegin\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_SETTINGS keep_constructor=hyp_fault_type\n#INCLUDE_SETTINGS keep_constructor=virt_timer\n\ntext \\<open>\n  An implementation of the machine's types, defining register set\n  and some observable machine state.\n\\<close>"}
{"title": "./spec/design/m-skel/AARCH64/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/AARCH64.hs CONTEXT AARCH64 decls_only NOT UserContext UserMonad Word getRegister setRegister newContext FPUState newFPUState\n\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64 ONLY VPPIEventIRQ VirtTimer\n(*<*)\n\nend\n\narch_requalify_types register vcpureg vppievent_irq virt_timer\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/AARCH64.hs CONTEXT AARCH64 instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/AARCH64.hs CONTEXT AARCH64 instanceproofs ONLY VPPIEventIRQ VirtTimer\n(*>*)\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/AARCH64.hs CONTEXT AARCH64 bodies_only NOT getRegister setRegister newContext newFPUState"}
{"title": "./spec/design/m-skel/AARCH64/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\nend\n\nqualify AARCH64 (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"AARCH64.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"machine_word \\<Rightarrow> word8\"\n  device_state :: \"machine_word \\<Rightarrow> word8 option\"\n  machine_state_rest :: AARCH64.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> AARCH64.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall>n. irq_oracle n <= Kernel_Config.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  The machine monad is used for operations on the state defined above.\n\\<close>\ntype_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c AARCH64.machine_monad\" <= (type) \"(AARCH64.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  After kernel initialisation all IRQs are masked.\n\\<close>\ndefinition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"\n\ntext \\<open>\n  The initial contents of the user-visible memory is 0.\n\\<close>\ndefinition\n  init_underlying_memory :: \"machine_word \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"\n\ntext \\<open>\n  We leave open the underspecified rest of the machine state in\n  the initial state.\n\\<close>\ndefinition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         machine_state_rest = undefined \\<rparr>\"\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs CONTEXT AARCH64 ONLY \\\n  PT_Type \\\n  VMFaultType HypFaultType vmFaultTypeFSR VMPageSize pageBits ptTranslationBits \\\n  pageBitsForSize \\\n  hcrCommon hcrTWE hcrTWI \\\n  hcrVCPU hcrNative vgicHCREN sctlrDefault sctlrEL1VM actlrDefault gicVCPUMaxNumLR \\\n  vcpuBits\n\nend\n\narch_requalify_types vmpage_size\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/AARCH64.hs CONTEXT AARCH64 instanceproofs ONLY VMFaultType HypFaultType VMPageSize\n\nend\nend"}
{"title": "./spec/design/m-skel/ARM_HYP/MachineTypes.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>ARM\\_HYP Machine Types\\<close>\n\ntheory MachineTypes\nimports\n  Word_Lib.WordSetup\n  Monads.Nondet_Empty_Fail\n  Monads.Nondet_Reader_Option\n  Lib.HaskellLib_H\n  Platform\nbegin\ncontext Arch begin arch_global_naming\n\n#INCLUDE_SETTINGS keep_constructor=hyp_fault_type\n#INCLUDE_SETTINGS keep_constructor=virt_timer\n\ntext \\<open>\n  An implementation of the machine's types, defining register set\n  and some observable machine state.\n\\<close>"}
{"title": "./spec/design/m-skel/ARM_HYP/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP decls_only NOT UserContext UserMonad Word getRegister setRegister newContext\n\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP ONLY VPPIEventIRQ VirtTimer\n(*<*)\n\nend\n\narch_requalify_types register vcpureg vppievent_irq virt_timer\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP instanceproofs\n#INCLUDE_HASKELL SEL4/Object/Structures/ARM.lhs CONTEXT ARM_HYP instanceproofs ONLY VPPIEventIRQ VirtTimer\n(*>*)\n#INCLUDE_HASKELL SEL4/Machine/RegisterSet/ARM.lhs CONTEXT ARM_HYP bodies_only NOT getRegister setRegister newContext"}
{"title": "./spec/design/m-skel/ARM_HYP/MachineTypes.thy", "section": "Machine State", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Most of the machine state is left underspecified at this level.\n  We know it exists, we will declare some interface functions, but\n  at this level we do not have access to how this state is transformed\n  or what effect it has on the machine.\n\\<close>\ntypedecl machine_state_rest\n\ntext \\<open>\n  The exclusive monitors state is observable in user mode.\n  The type for this is the type used in the Cambridge HOL4 ARM model.\n\\<close>\ntype_synonym exclusive_monitors = \"(word32 \\<Rightarrow> bool) list \\<times> (word32 \\<times> nat \\<Rightarrow> bool)\"\n\ntext \\<open>\n  The full machine state is the state observable by the kernel plus\n  the underspecified rest above. The observable parts are the\n  interrupt controller (which IRQs are masked) and the memory of the\n  machine. The latter is shadow state: kernel memory is kept in a\n  separate, more abstract datatype; user memory is reflected down\n  to the underlying memory of the machine.\n\\<close>\nend\n\nqualify ARM_HYP (in Arch)\n\nrecord\n  machine_state =\n  irq_masks :: \"ARM_HYP.irq \\<Rightarrow> bool\"\n  irq_state :: nat\n  underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  device_state :: \"word32 \\<Rightarrow> word8 option\"\n  exclusive_state :: ARM_HYP.exclusive_monitors\n  machine_state_rest :: ARM_HYP.machine_state_rest\n\naxiomatization\n  irq_oracle :: \"nat \\<Rightarrow> ARM_HYP.irq\"\nwhere\n  irq_oracle_max_irq: \"\\<forall> n. irq_oracle n <= Kernel_Config.maxIRQ\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  The machine monad is used for operations on the state defined above.\n\\<close>\ntype_synonym 'a machine_monad = \"(machine_state, 'a) nondet_monad\"\n\nend\n\ntranslations\n  (type) \"'c ARM_HYP.machine_monad\" <= (type) \"(ARM_HYP.machine_state, 'c) nondet_monad\"\n\ncontext Arch begin arch_global_naming\n\ntext \\<open>\n  After kernel initialisation all IRQs are masked.\n\\<close>\ndefinition\n  \"init_irq_masks \\<equiv> \\<lambda>_. True\"\n\ntext \\<open>\n  The initial contents of the user-visible memory is 0.\n\\<close>\ndefinition\n  init_underlying_memory :: \"word32 \\<Rightarrow> word8\"\n  where\n  \"init_underlying_memory \\<equiv> \\<lambda>_. 0\"\n\ntext \\<open>\n  The initial exclusive state is the same constant\n  that clearExMonitor defaults it to.\n\\<close>\n\nconsts' default_exclusive_state :: exclusive_monitors\n\ntext \\<open>\n  We leave open the underspecified rest of the machine state in\n  the initial state.\n\\<close>\ndefinition\n  init_machine_state :: machine_state where\n \"init_machine_state \\<equiv> \\<lparr> irq_masks = init_irq_masks,\n                         irq_state = 0,\n                         underlying_memory = init_underlying_memory,\n                         device_state = Map.empty,\n                         exclusive_state = default_exclusive_state,\n                         machine_state_rest = undefined \\<rparr>\"\n\n\n(* Machine/Hardware/ARM.lhs - hardware_asid, vmfault_type and vmpage_size *)\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_HYP ONLY HardwareASID VMFaultType HypFaultType VMPageSize pageBits pageBitsForSize hcrCommon hcrTWE hcrTWI hcrVCPU hcrNative vgicHCREN sctlrDefault actlrDefault gicVCPUMaxNumLR\n\nend\n\narch_requalify_types vmpage_size\n\ncontext Arch begin arch_global_naming\n\n#INCLUDE_HASKELL SEL4/Machine/Hardware/ARM.lhs CONTEXT ARM_HYP instanceproofs ONLY HardwareASID VMFaultType HypFaultType VMPageSize\n\nend\nend"}
{"title": "./spec/capDL/Decode_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Decode_D\nimports\n  Asid_D\n  CNode_D\n  Interrupt_D\n  PageTable_D\n  Tcb_D\n  Untyped_D\nbegin\n\ndefinition\n  get_cnode_intent :: \"cdl_intent \\<Rightarrow> cdl_cnode_intent option\"\nwhere\n  \"get_cnode_intent intent \\<equiv>\n    case intent of\n        CNodeIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_tcb_intent :: \"cdl_intent \\<Rightarrow> cdl_tcb_intent option\"\nwhere\n  \"get_tcb_intent intent \\<equiv>\n    case intent of\n        TcbIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_irq_control_intent :: \"cdl_intent \\<Rightarrow> cdl_irq_control_intent option\"\nwhere\n  \"get_irq_control_intent intent \\<equiv>\n    case intent of\n        IrqControlIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_irq_handler_intent :: \"cdl_intent \\<Rightarrow> cdl_irq_handler_intent option\"\nwhere\n  \"get_irq_handler_intent intent \\<equiv>\n    case intent of\n        IrqHandlerIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_asid_pool_intent :: \"cdl_intent \\<Rightarrow> cdl_asid_pool_intent option\"\nwhere\n  \"get_asid_pool_intent intent \\<equiv>\n    case intent of\n        AsidPoolIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\n\ndefinition\n  get_asid_control_intent :: \"cdl_intent \\<Rightarrow> cdl_asid_control_intent option\"\nwhere\n  \"get_asid_control_intent intent \\<equiv>\n    case intent of\n        AsidControlIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_page_intent :: \"cdl_intent \\<Rightarrow> cdl_page_intent option\"\nwhere\n  \"get_page_intent intent \\<equiv>\n    case intent of\n        PageIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_page_table_intent :: \"cdl_intent \\<Rightarrow> cdl_page_table_intent option\"\nwhere\n  \"get_page_table_intent intent \\<equiv>\n    case intent of\n        PageTableIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_page_directory_intent :: \"cdl_intent \\<Rightarrow> cdl_page_directory_intent option\"\nwhere\n  \"get_page_directory_intent intent \\<equiv>\n    case intent of\n        PageDirectoryIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_untyped_intent :: \"cdl_intent \\<Rightarrow> cdl_untyped_intent option\"\nwhere\n  \"get_untyped_intent intent \\<equiv>\n    case intent of\n        UntypedIntent x \\<Rightarrow> Some x\n      | _ \\<Rightarrow> None\"\n\ndefinition\n  get_domain_intent :: \"cdl_intent \\<Rightarrow> cdl_domain_intent option\"\nwhere\n  \"get_domain_intent intent \\<equiv>\n     case intent of\n         DomainIntent x \\<Rightarrow> Some x\n       | _ \\<Rightarrow> None\"\n\n(*\n * Decode and validate the given intent, turning it into an\n * invocation.\n *)\ndefinition\n  decode_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_intent \\<Rightarrow> cdl_invocation except_monad\"\nwhere\n  \"decode_invocation invoked_cap invoked_cap_ref caps intent \\<equiv>\n    case invoked_cap of\n       \\<comment> \\<open>For endpoint-like caps, we always perform an operation,\n          regardless of the user's actual intent.\\<close>\n         EndpointCap o_id badge rights \\<Rightarrow>\n           (if Write \\<in> rights then\n             returnOk $ InvokeEndpoint (SyncMessage badge (Grant \\<in> rights) (GrantReply \\<in> rights) o_id)\n           else\n             throw)\n       | NotificationCap o_id badge rights \\<Rightarrow>\n           (if Write \\<in> rights then\n             returnOk $ InvokeNotification (Signal badge o_id)\n           else\n             throw)\n       | ReplyCap o_id rights \\<Rightarrow>\n           returnOk $ InvokeReply (ReplyMessage o_id invoked_cap_ref (Grant \\<in> rights))\n\n       \\<comment> \\<open>\n         For other operations, we only perform the user's intent\n         if it matches up with the cap.\n        \n         Note that this does not currently match the current\n         implementation: instead, the user's message will be\n         decoded into a new (undefined) intent for what the\n         cap happened to be. I propose modifying labels used to\n         avoid overlaps between different items so that we can\n         recognise when the user is invoking the wrong item.\n       \\<close>\n       | CNodeCap _ _ _ _ \\<Rightarrow>\n           doE\n             cnode_intent \\<leftarrow> throw_opt undefined $ get_cnode_intent intent;\n             liftME InvokeCNode $ decode_cnode_invocation invoked_cap invoked_cap_ref caps cnode_intent\n           odE\n       | TcbCap _ \\<Rightarrow>\n           doE\n             tcb_intent \\<leftarrow> throw_opt undefined $ get_tcb_intent intent;\n             liftME InvokeTcb $ decode_tcb_invocation invoked_cap invoked_cap_ref caps tcb_intent\n           odE\n       | IrqControlCap \\<Rightarrow>\n           doE\n             irq_control_intent \\<leftarrow> throw_opt undefined $ get_irq_control_intent intent;\n             liftME InvokeIrqControl $ decode_irq_control_invocation\n                 invoked_cap invoked_cap_ref caps irq_control_intent\n           odE\n       | IrqHandlerCap _ \\<Rightarrow>\n           doE\n             irq_handler_intent \\<leftarrow> throw_opt undefined $ get_irq_handler_intent intent;\n             liftME InvokeIrqHandler $ decode_irq_handler_invocation\n                 invoked_cap invoked_cap_ref caps irq_handler_intent\n           odE\n       | AsidPoolCap _ _\\<Rightarrow>\n           doE\n             asid_pool_intent \\<leftarrow> throw_opt undefined $ get_asid_pool_intent intent;\n             liftME InvokeAsidPool $ decode_asid_pool_invocation\n                 invoked_cap invoked_cap_ref caps asid_pool_intent\n           odE\n       | AsidControlCap \\<Rightarrow>\n           doE\n             asid_control_intent \\<leftarrow> throw_opt undefined $ get_asid_control_intent intent;\n             liftME InvokeAsidControl $ decode_asid_control_invocation\n                 invoked_cap invoked_cap_ref caps asid_control_intent\n           odE\n       | UntypedCap _ _ _ \\<Rightarrow>\n           doE\n             untyped_intent \\<leftarrow> throw_opt undefined $ get_untyped_intent intent;\n             liftME InvokeUntyped $ decode_untyped_invocation\n                 invoked_cap invoked_cap_ref caps untyped_intent\n           odE\n       | FrameCap _ _ _ _ _ _ \\<Rightarrow>\n           doE\n             page_intent \\<leftarrow> throw_opt undefined $ get_page_intent intent;\n             liftME InvokePage $ decode_page_invocation\n                 invoked_cap invoked_cap_ref caps page_intent\n           odE\n       | PageTableCap _ _ _ \\<Rightarrow>\n           doE\n             page_table_intent \\<leftarrow> throw_opt undefined $ get_page_table_intent intent;\n             liftME InvokePageTable $ decode_page_table_invocation\n                 invoked_cap invoked_cap_ref caps page_table_intent\n           odE\n       | PageDirectoryCap _ _ _ \\<Rightarrow>\n          doE\n             page_directory_intent \\<leftarrow> throw_opt undefined $ get_page_directory_intent intent;\n             liftME InvokePageDirectory $ decode_page_directory_invocation\n                 invoked_cap invoked_cap_ref caps page_directory_intent\n           odE\n       | DomainCap \\<Rightarrow>\n          doE\n            domain_intent \\<leftarrow> throw_opt undefined $ get_domain_intent intent;\n            liftME InvokeDomain $ decode_domain_invocation caps domain_intent\n          odE\n\n       \\<comment> \\<open>Don't support operations on other types of caps.\\<close>\n       | _ \\<Rightarrow> throw\"\n\nend"}
{"title": "./spec/capDL/Asid_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Operations on page table objects and frames.\n *)\n\ntheory Asid_D\nimports\n  Invocations_D\n  CSpace_D\n  Untyped_D\nbegin\n\ndefinition\n  decode_asid_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_asid_control_intent \\<Rightarrow> cdl_asid_control_invocation except_monad\"\nwhere\n  \"decode_asid_control_invocation target target_ref caps intent \\<equiv> case intent of\n     AsidControlMakePoolIntent index depth \\<Rightarrow>\n       doE\n         base \\<leftarrow> liftE $ select {x. x < 2 ^ asid_high_bits};\n\n         \\<comment> \\<open>Fetch the untyped item, and ensure it is valid.\\<close>\n         (untyped_cap, untyped_cap_ref) \\<leftarrow> throw_on_none $ get_index caps 0;\n         (case untyped_cap of\n             UntypedCap _ s _ \\<Rightarrow> returnOk ()\n           | _ \\<Rightarrow> throw);\n         ensure_no_children untyped_cap_ref;\n\n         \\<comment> \\<open>Fetch the slot we plan to put the generated cap into.\\<close>\n         (cspace_cap, _) \\<leftarrow> throw_on_none $ get_index caps 1;\n         target_slot \\<leftarrow> lookup_slot_for_cnode_op cspace_cap index (unat depth);\n         ensure_empty target_slot;\n\n         returnOk $ MakePool (set_available_range untyped_cap {}) untyped_cap_ref\n           (cap_objects untyped_cap) target_slot base\n       odE \\<sqinter> throw\"\n\ndefinition\n  decode_asid_pool_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_asid_pool_intent \\<Rightarrow> cdl_asid_pool_invocation except_monad\"\nwhere\n  \"decode_asid_pool_invocation target target_ref caps intent \\<equiv> case intent of\n     AsidPoolAssignIntent \\<Rightarrow>\n       doE\n         (pd_cap, pd_cap_ref) \\<leftarrow> throw_on_none $ get_index caps 0;\n         (case pd_cap of\n             PageDirectoryCap _ _ _ \\<Rightarrow> returnOk ()\n           | _ \\<Rightarrow> throw);\n\n         base \\<leftarrow> (case target of\n             AsidPoolCap p base \\<Rightarrow> returnOk $ base\n           | _ \\<Rightarrow> throw);\n         offset \\<leftarrow> liftE $ select {x. x < 2 ^ asid_low_bits};\n         returnOk $ Assign (base, offset) pd_cap_ref (cap_object target, offset)\n       odE \\<sqinter> throw\"\n\ndefinition\n  invoke_asid_control :: \"cdl_asid_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_asid_control params \\<equiv>\n    case params of\n        MakePool untyped_cap untyped_cap_ref untyped_covers target_slot base \\<Rightarrow>\n          do\n            \\<comment> \\<open>Untype the region. A choice may be made about whether to detype\n               objects with Untyped addresses.\\<close>\n            modify (detype untyped_covers);\n            set_cap untyped_cap_ref untyped_cap;\n            targets \\<leftarrow> generate_object_ids 1 AsidPoolType untyped_covers;\n\n            \\<comment> \\<open>Retype the region.\\<close>\n            retype_region 0 AsidPoolType targets;\n            assert (targets \\<noteq> []);\n\n            \\<comment> \\<open>Insert the cap.\\<close>\n            frame \\<leftarrow> return $ pick (hd targets);\n            insert_cap_child (AsidPoolCap frame base) untyped_cap_ref target_slot;\n\n            \\<comment> \\<open>Update the asid table.\\<close>\n            asid_table \\<leftarrow> gets cdl_asid_table;\n            asid_table' \\<leftarrow> return $ asid_table (base \\<mapsto> AsidPoolCap frame 0);\n            modify (\\<lambda>s. s \\<lparr>cdl_asid_table := asid_table'\\<rparr>)\n\n          od\"\n\ndefinition\n  invoke_asid_pool :: \"cdl_asid_pool_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_asid_pool params \\<equiv>\n     case params of\n       Assign asid pd_cap_ref ap_target_slot \\<Rightarrow> do\n         pd_cap \\<leftarrow> get_cap pd_cap_ref;\n         case pd_cap of\n           PageDirectoryCap pd_id _ _ \\<Rightarrow> do\n             set_cap pd_cap_ref (PageDirectoryCap pd_id Real (Some asid));\n             set_cap ap_target_slot (PageDirectoryCap pd_id Fake None)\n           od\n         | _ \\<Rightarrow> fail\n       od\"\n\nend"}
{"title": "./spec/capDL/Untyped_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Operations on untyped memory objects.\n *)\n\ntheory Untyped_D\nimports Invocations_D CSpace_D\nbegin\n\ndefinition\n  decode_untyped_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_untyped_intent \\<Rightarrow> cdl_untyped_invocation except_monad\"\nwhere\n  \"decode_untyped_invocation untyped_cap untyped_ref caps intent \\<equiv> case intent of\n     UntypedRetypeIntent type size_bits node_index node_depth node_offset node_window \\<Rightarrow>\n       doE\n         (root_cap, root_slot) \\<leftarrow> throw_on_none $ get_index caps 0;\n\n         \\<comment> \\<open>Lookup the destination slots.\\<close>\n         target_node \\<leftarrow> if node_depth = 0 then\n             returnOk root_cap\n           else\n             doE\n               target_slot \\<leftarrow> lookup_slot_for_cnode_op root_cap node_index (unat node_depth);\n               liftE $ get_cap target_slot\n             odE;\n\n         \\<comment> \\<open>Ensure it is a CNode cap.\\<close>\n         unlessE (is_cnode_cap target_node) throw;\n\n         \\<comment> \\<open>Find our target slots.\\<close>\n         slots \\<leftarrow> returnOk $ map (\\<lambda>n. (cap_object target_node, n))\n               [unat node_offset ..< unat node_offset + unat node_window];\n         mapME_x ensure_empty slots;\n\n         \\<comment> \\<open>Work out what names are available. If we haven't haven't already been typed into something we can reuse our names.\\<close>\n         s \\<leftarrow> liftE $ get;\n         has_kids \\<leftarrow> returnOk $ has_children untyped_ref s;\n\n         returnOk $ Retype untyped_ref type (unat size_bits) slots has_kids (unat node_window)\n       odE \\<sqinter> throw\"\n\n(* Zero out a set of addresses. *)\ndefinition\n  detype :: \"cdl_object_id set \\<Rightarrow> cdl_state \\<Rightarrow> cdl_state\"\nwhere\n  \"detype detype_set s \\<equiv>\n     (s\\<lparr> cdl_objects :=\n         (\\<lambda>x. if x \\<in> detype_set then\n           Some Untyped\n         else cdl_objects s x)\\<rparr>)\"\n\n(*\n * Retype the given untyped object into a new object type,\n * and return a list of pointers to the newly constructed items.\n *)\n\ndefinition\n  generate_object_ids :: \"nat \\<Rightarrow> cdl_object_type \\<Rightarrow> cdl_object_id set \\<Rightarrow>  ((cdl_object_id set) list) k_monad\"\n  where \"generate_object_ids num_objects type object_range\n  \\<equiv> do\n    s \\<leftarrow> get;\n    available_names \\<leftarrow> return $ (cdl_objects s) -` {Some Untyped};\n    setlist \\<leftarrow> select {x. distinct  x \\<and> (\\<forall>a\\<in> set x. \\<forall>b \\<in> set x. a \\<noteq> b \\<longrightarrow> a \\<inter> b = {})\n           \\<and> (\\<forall>y \\<in> set x. y \\<noteq> {} \\<and> y \\<subseteq> object_range \\<inter> available_names)\n           \\<and> (num_objects = (size x)) };\n    if (type \\<noteq> UntypedType) then (return $ map (\\<lambda>x. {pick x}) setlist)\n    else return setlist\n    od\"\n\ndefinition create_objects :: \"(cdl_object_id set) list \\<Rightarrow> cdl_object option \\<Rightarrow> unit k_monad\"\nwhere\n  \"create_objects target_object_ids object \\<equiv>\n    (modify (\\<lambda>s. s\\<lparr>cdl_objects := (\\<lambda>x.\n     if {x} \\<in> set target_object_ids then\n      object\n     else\n      cdl_objects s x)\\<rparr>))\"\n\n\n(* Insert a cap for a new object in the given location. *)\ndefinition\n  create_cap :: \"cdl_object_type \\<Rightarrow> nat \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool \\<Rightarrow> (cdl_cap_ref \\<times> cdl_object_id set) \\<Rightarrow> unit k_monad\"\nwhere\n  \"create_cap new_type sz parent_slot dev \\<equiv> \\<lambda>(dest_slot, obj_refs).\n  do\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_cap dest_slot (default_cap new_type obj_refs sz dev);\n    set_parent dest_slot parent_slot\n  od\"\n\n\ndefinition\n  update_available_range :: \"(cdl_object_id set) => (cdl_object_id list) \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere \"update_available_range orange newids cap_ref cap \\<equiv>\n  do\n     new_range  \\<leftarrow> select {x. x \\<subseteq> orange - set newids};\n     set_cap cap_ref $ set_available_range cap new_range\n  od\"\n\n\ndefinition\n  retype_region :: \"nat \\<Rightarrow> cdl_object_type \\<Rightarrow> (cdl_object_id set list)\n  \\<Rightarrow> ((cdl_object_id set) list) k_monad\"\nwhere\n  \"retype_region target_bits target_type target_object_ids \\<equiv>\n    do\n      \\<comment> \\<open>Get a list of target locations. We are happy with any unused name\n         within the target range.\\<close>\n\n      if (target_type \\<noteq> UntypedType) then\n       do\n         current_domain \\<leftarrow> gets cdl_current_domain;\n         create_objects target_object_ids (default_object target_type target_bits current_domain)\n       od\n      else return ();\n\n      \\<comment> \\<open>Get a list of target locations. We are happy with any unused name\n         within the target range.\\<close>\n      return target_object_ids\n    od\"\n\nprimrec (nonexhaustive)\n  untyped_is_device :: \"cdl_cap \\<Rightarrow> bool\"\nwhere\n    \"untyped_is_device (UntypedCap d _ _) = d\"\n\ndefinition\n  reset_untyped_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"reset_untyped_cap cref \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap cref;\n    whenE (available_range cap \\<noteq> cap_objects cap) $ doE\n      liftE $ modify (detype (cap_objects cap));\n      new_rans \\<leftarrow> liftE $ select {xs. (\\<forall>S \\<in> set xs.\n              S \\<subseteq> cap_objects cap \\<and> available_range cap \\<subset> S)\n          \\<and> xs \\<noteq> [] \\<and> List.last xs = cap_objects cap};\n      mapME_x (\\<lambda>r. doE\n        liftE $ set_cap cref $ set_available_range cap r;\n        returnOk () \\<sqinter> throw\n      odE) new_rans\n    odE\n  odE\"\n\ndefinition\n  invoke_untyped :: \"cdl_untyped_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_untyped params \\<equiv> case params of\n     Retype untyped_ref new_type type_size target_slots has_kids num_objects \\<Rightarrow>\n   doE\n     unlessE has_kids $ reset_untyped_cap untyped_ref;\n       liftE $ do\n         untyped_cap \\<leftarrow> get_cap untyped_ref;\n\n         new_range \\<leftarrow> return $ available_range untyped_cap;\n         new_obj_refs \\<leftarrow> generate_object_ids num_objects new_type new_range;\n\n         update_available_range new_range (map (\\<lambda>s. pick s) new_obj_refs) untyped_ref untyped_cap;\n\n         \\<comment> \\<open>Construct new objects within the covered range.\\<close>\n         retype_region type_size new_type new_obj_refs;\n\n         \\<comment> \\<open>Construct caps for the new objects.\\<close>\n         mapM_x (create_cap new_type type_size untyped_ref (untyped_is_device untyped_cap)) (zip target_slots new_obj_refs);\n\n         \\<comment> \\<open>Ideally, we should return back to the user how many\n            objects were created.\\<close>\n\n         return ()\n       od\n    odE\"\n\nend"}
{"title": "./spec/capDL/Intents_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * This file contains user \"intents\".\n *\n * Such intents attempt to capture the semantics of an operation the\n * user is attempting to perform, without having to worry about how the\n * operation is actually encoded within their message registers.\n *\n * There is a one-to-one mapping between the following intents and the\n * invocations made available to userspace. There is not quite\n * a one-to-one mapping between these intents and the invocations listed\n * in Invocations_D, as some of these intents are multiplexed onto\n * a single invocation when being validated.\n *\n * Caps required by the intents are not stored in the intent themselves,\n * but passed seperately in when required. In some sense, the Intent\n * is the \"data\" part of an invocation, but not the \"caps\" part of it.\n *)\n\ntheory Intents_D\nimports\n  \"ASpec.CapRights_A\"\n  ExecSpec.Platform\nbegin\n\ncontext begin interpretation Arch .\nrequalify_types irq\nend\n\n(*\n * Entities in seL4 have particular rights to kernel objects, which\n * affects how entities can interact with those particular objects.\n *)\ntype_synonym cdl_right = rights\n\n(* A user cap pointer. *)\ntype_synonym cdl_cptr = word32\n\nabbreviation (input) Read ::rights\n  where \"Read \\<equiv> AllowRead\"\n\nabbreviation (input) Write::rights\n  where \"Write \\<equiv> AllowWrite\"\n\nabbreviation (input) Grant::rights\n  where \"Grant \\<equiv> AllowGrant\"\n\nabbreviation (input) GrantReply::rights\n  where \"GrantReply \\<equiv> AllowGrantReply\"\n\n(* Capability data, such as guard information. *)\ntype_synonym cdl_raw_capdata = word32\n\n(* VM Attributes, such as page cache attributes. *)\ntype_synonym cdl_raw_vmattrs = word32\n\n(* TCB context, for operations such as write to a thread's registers. *)\ntype_synonym cdl_raw_usercontext = \"word32 list\"\n\n(* Kernel objects types. *)\ndatatype cdl_object_type =\n    EndpointType\n  | NotificationType\n  | TcbType\n  | CNodeType\n  | IRQNodeType\n  | UntypedType\n  | AsidPoolType\n  | PageTableType\n  | PageDirectoryType\n  | FrameType nat (* size in bits of desired page *)\n\ndatatype cdl_cnode_intent =\n    (* Copy: (target), dest_index, dest_depth, (src_root), src_index, src_depth, rights *)\n    CNodeCopyIntent word32 word32 word32 word32 \"cdl_right set\"\n    (* Mint: (target), dest_index, dest_depth, (src_root), src_index, src_depth, rights, badge *)\n |  CNodeMintIntent word32 word32 word32 word32 \"cdl_right set\" cdl_raw_capdata\n    (* Move: (target), dest_index, dest_depth, (src_root), src_index, src_depth *)\n |  CNodeMoveIntent word32 word32 word32 word32\n    (* Mutate: (target), dest_index, dest_depth, (src_root), src_index, src_depth, badge *)\n |  CNodeMutateIntent word32 word32 word32 word32 cdl_raw_capdata\n    (* Revoke: (target), index, depth *)\n |  CNodeRevokeIntent word32 word32\n    (* Delete: (target), index, depth *)\n |  CNodeDeleteIntent word32 word32\n    (* SaveCaller: (target), index, depth *)\n |  CNodeSaveCallerIntent word32 word32\n    (* CancelBadgedSends: (target), index, depth *)\n |  CNodeCancelBadgedSendsIntent word32 word32\n    (* Rotate: (target), dest_index, dest_depth, (pivot_root), pivot_index, pivot_depth, pivot_badge, (src_root), src_index, src_depth, src_badge *)\n |  CNodeRotateIntent word32 word32 word32 word32 cdl_raw_capdata word32 word32 cdl_raw_capdata\n\ndatatype cdl_tcb_intent =\n    (* ReadRegisters: (target), suspend_source, arch_flags, count *)\n    TcbReadRegistersIntent bool word8 word32\n    (* WriteRegisters: (target), resume_target, arch_flags, count, regs *)\n |  TcbWriteRegistersIntent bool word8 word32 cdl_raw_usercontext\n    (* CopyRegisters: (target), (source), suspend_source, resume_target, transfer_frame, transfer_integer, arch_flags *)\n |  TcbCopyRegistersIntent bool bool bool bool word8\n    (* Suspend: (target) *)\n |  TcbSuspendIntent\n    (* Resume: (target) *)\n |  TcbResumeIntent\n    (* Configure: (target), fault_ep, (cspace_root), cspace_root_data, (vspace_root), vspace_root_data, buffer, (bufferFrame) *)\n |  TcbConfigureIntent cdl_cptr cdl_raw_capdata cdl_raw_capdata word32\n    (* SetMCPriority: (target), mcp *)\n |  TcbSetMCPriorityIntent word8\n    (* SetPriority: (target), priority *)\n |  TcbSetPriorityIntent word8\n    (* SetSchedParams: (target), mcp, priority *)\n |  TcbSetSchedParamsIntent word8 word8\n    (* SetIPCBuffer: (target), buffer, (bufferFrame) *)\n |  TcbSetIPCBufferIntent word32\n    (* SetSpace: (target), fault_ep, (cspace_root), cspace_root_data, (vspace_root), vspace_root_data *)\n |  TcbSetSpaceIntent word32 cdl_raw_capdata cdl_raw_capdata\n    (* BindNTFN: (target), (ntfn) *)\n |  TcbBindNTFNIntent\n    (* UnbindNTFN: (target) *)\n |  TcbUnbindNTFNIntent\n    (* SetTLSBase: (target) *)\n |  TcbSetTLSBaseIntent\n\ndatatype cdl_untyped_intent =\n    (* Retype: (target), (do_reset), type, size_bits, (root), node_index, node_depth, node_offset, node_window, has_children *)\n    UntypedRetypeIntent cdl_object_type word32 word32 word32 word32 word32\n\ndatatype cdl_irq_handler_intent =\n    (* Ack: (target) *)\n    IrqHandlerAckIntent\n    (* SetEndpoint: (target), (endpoint) *)\n |  IrqHandlerSetEndpointIntent\n    (* Clear: (target) *)\n |  IrqHandlerClearIntent\n\ndatatype cdl_arch_irq_control_intent =\n    (* ArchIssueIrqHandler: (target), irq, (root), index, depth *)\n    ARMIrqControlIssueIrqHandlerIntent irq word32 word32\n\ndatatype cdl_irq_control_intent =\n    (* IssueIrqHandler: (target), irq, (root), index, depth *)\n    IrqControlIssueIrqHandlerIntent irq word32 word32\n    (* InterruptControl *)\n |  ArchIrqControlIssueIrqHandlerIntent cdl_arch_irq_control_intent\n\ndatatype cdl_page_table_intent =\n    (* Map: (target), (pd), vaddr, attr *)\n    PageTableMapIntent word32 cdl_raw_vmattrs\n |  PageTableUnmapIntent\n\ndatatype cdl_page_intent =\n    (* Map: (target), (pd), vaddr, rights, attr *)\n    PageMapIntent word32 \"cdl_right set\" cdl_raw_vmattrs\n    (* Unmap: (target) *)\n |  PageUnmapIntent\n    (* FlushCaches: (target) *)\n |  PageFlushCachesIntent\n    (* GetAddress *)\n | PageGetAddressIntent\n\n\ndatatype cdl_page_directory_intent =\n   PageDirectoryFlushIntent\n | PageDirectoryNothingIntent\n\ndatatype cdl_asid_control_intent =\n    (* MakePool: (target), (untyped), (root), index, depth *)\n    AsidControlMakePoolIntent word32 word32\n\ndatatype cdl_asid_pool_intent =\n    (* Assign: (target), (vroot) *)\n    AsidPoolAssignIntent\n\ndatatype cdl_notification_intent =\n    SendSignalIntent word32\n\n(* Also used with reply caps *)\ndatatype cdl_endpoint_intent =\n    SendMessageIntent \"cdl_cptr list\"\n\ndatatype cdl_domain_intent = DomainSetIntent word8\n\ndatatype cdl_intent =\n    CNodeIntent cdl_cnode_intent\n  | TcbIntent cdl_tcb_intent\n  | UntypedIntent cdl_untyped_intent\n  | IrqHandlerIntent cdl_irq_handler_intent\n  | IrqControlIntent cdl_irq_control_intent\n  | PageTableIntent cdl_page_table_intent\n  | PageIntent cdl_page_intent\n  | PageDirectoryIntent cdl_page_directory_intent\n  | AsidControlIntent cdl_asid_control_intent\n  | AsidPoolIntent cdl_asid_pool_intent\n  | NotificationIntent cdl_notification_intent\n  | EndpointIntent cdl_endpoint_intent\n  | DomainIntent cdl_domain_intent\n\nrecord cdl_full_intent =\n  cdl_intent_op        :: \"cdl_intent option\"\n  cdl_intent_error     :: bool\n  cdl_intent_cap       :: cdl_cptr\n  cdl_intent_extras    :: \"cdl_cptr list\"\n  cdl_intent_recv_slot :: \"(cdl_cptr \\<times> word32 \\<times> nat) option\"\n\nend"}
{"title": "./spec/capDL/Tcb_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Operations on thread control blocks.\n *)\n\ntheory Tcb_D\nimports Invocations_D CSpace_D\nbegin\n\ndefinition cdl_update_cnode_cap_data :: \"cdl_cap \\<Rightarrow> word32 \\<Rightarrow> cdl_cap\"\nwhere \"cdl_update_cnode_cap_data cap data  \\<equiv>\n  case cap of cdl_cap.CNodeCap oid _ _ sz \\<Rightarrow> if data\\<noteq>0 then\n    (let reserved_bits = 3; guard_bits = 18; guard_size_bits = 5; new_guard_size = unat ((data >> reserved_bits) && mask guard_size_bits);\n        new_guard =\n          (data >> reserved_bits + guard_size_bits) && mask (min (unat ((data >> reserved_bits) && mask guard_size_bits)) guard_bits)\n    in CNodeCap oid new_guard new_guard_size sz)\n    else cap\n  | _ \\<Rightarrow> cap\"\n\ndefinition cdl_same_arch_obj_as :: \"cdl_cap \\<Rightarrow> cdl_cap \\<Rightarrow> bool\"\nwhere \"cdl_same_arch_obj_as capa capb \\<equiv>\n  case capa of AsidPoolCap x _ \\<Rightarrow> (\n        case capb of AsidPoolCap y _ \\<Rightarrow>  y = x\n        | _ \\<Rightarrow> False)\n  | AsidControlCap \\<Rightarrow> (\n       case capb of AsidControlCap \\<Rightarrow> True\n        | _ \\<Rightarrow> False)\n  | FrameCap dev ra _ sa _ _ \\<Rightarrow> (\n       case capb of FrameCap dev' rb _ sb _ _ \\<Rightarrow> rb = ra \\<and> sb = sa \\<and> dev = dev'\n        | _ \\<Rightarrow> False)\n  | cdl_cap.PageTableCap a _ _ \\<Rightarrow> (\n       case capb of cdl_cap.PageTableCap b _ _ \\<Rightarrow> b = a\n        | _ \\<Rightarrow> False)\n  | cdl_cap.PageDirectoryCap a _ _ \\<Rightarrow> (\n       case capb of cdl_cap.PageDirectoryCap b _ _ \\<Rightarrow> b = a\n        | _ \\<Rightarrow> False)\n  | _ \\<Rightarrow> False\"\n\ndefinition\n  decode_tcb_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_tcb_intent \\<Rightarrow> cdl_tcb_invocation except_monad\"\nwhere\n  \"decode_tcb_invocation target slot caps intent \\<equiv> case intent of\n       \\<comment> \\<open>Read another thread's registers.\\<close>\n       TcbReadRegistersIntent suspend flags count \\<Rightarrow>\n         returnOk (ReadRegisters (cap_object target) suspend 0 0) \\<sqinter> throw\n\n       \\<comment> \\<open>Write another thread's registers.\\<close>\n     | TcbWriteRegistersIntent resume flags count regs \\<Rightarrow>\n         returnOk (WriteRegisters (cap_object target) resume [0] 0) \\<sqinter> throw\n\n       \\<comment> \\<open>Copy registers from one thread to another.\\<close>\n     | TcbCopyRegistersIntent suspend_source resume_target f1 f2 f3 \\<Rightarrow>\n         doE\n           (source_cap, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           source_tcb \\<leftarrow> (\n              case source_cap of\n                  TcbCap x \\<Rightarrow> returnOk x\n                | _ \\<Rightarrow> throw);\n           target_tcb \\<leftarrow> returnOk $ cap_object target;\n           returnOk (CopyRegisters target_tcb source_tcb suspend_source resume_target f1 f2 0)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Suspend the target thread.\\<close>\n     | TcbSuspendIntent \\<Rightarrow>\n         returnOk (Suspend (cap_object target)) \\<sqinter> throw\n\n       \\<comment> \\<open>Resume the target thread.\\<close>\n     | TcbResumeIntent \\<Rightarrow>\n         returnOk (Resume (cap_object target)) \\<sqinter> throw\n\n       \\<comment> \\<open>Configure: target, fault_ep, mcp, priority, cspace_root_data, vspace_root_data, buffer\\<close>\n     | TcbConfigureIntent fault_ep cspace_root_data vspace_root_data buffer \\<Rightarrow>\n         doE\n           cspace_root \\<leftarrow> throw_on_none $ get_index caps 0;\n           vspace_root \\<leftarrow> throw_on_none $ get_index caps 1;\n           buffer_frame \\<leftarrow> throw_on_none $ get_index caps 2;\n           cspace_root_cap_ref \\<leftarrow> returnOk $ (cdl_update_cnode_cap_data (fst cspace_root) cspace_root_data,snd cspace_root);\n           vspace_root_cap_ref \\<leftarrow> returnOk $ vspace_root;\n           buffer_frame_opt \\<leftarrow> returnOk $ (if (buffer \\<noteq> 0) then Some (reset_mem_mapping (fst buffer_frame), snd buffer_frame) else None);\n           returnOk (ThreadControl (cap_object target) slot (Some fault_ep)\n               (Some cspace_root_cap_ref) (Some vspace_root_cap_ref) (buffer_frame_opt))\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Modify a thread's maximum control priority.\\<close>\n     | TcbSetMCPriorityIntent mcp \\<Rightarrow>\n         doE\n           auth_cap \\<leftarrow> throw_on_none $ get_index caps 0;\n           returnOk (ThreadControl (cap_object target) slot None None None None)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Modify a thread's priority.\\<close>\n     | TcbSetPriorityIntent priority \\<Rightarrow>\n         doE\n           auth_cap \\<leftarrow> throw_on_none $ get_index caps 0;\n           returnOk (ThreadControl (cap_object target) slot None None None None)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Modify a thread's mcp and priority at the same time.\\<close>\n     | TcbSetSchedParamsIntent mcp priority \\<Rightarrow>\n         doE\n           auth_cap \\<leftarrow> throw_on_none $ get_index caps 0;\n           returnOk (ThreadControl (cap_object target) slot None None None None)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Modify a thread's IPC buffer.\\<close>\n     | TcbSetIPCBufferIntent buffer \\<Rightarrow>\n         doE\n           buffer_frame \\<leftarrow> throw_on_none $ get_index caps 0;\n           buffer_frame_opt \\<leftarrow> returnOk $ (if (buffer \\<noteq> 0) then Some (reset_mem_mapping (fst buffer_frame), snd buffer_frame) else None);\n           returnOk (ThreadControl (cap_object target) slot None None None buffer_frame_opt)\n         odE \\<sqinter> throw\n\n       \\<comment> \\<open>Update the various spaces (CSpace/VSpace) of a thread.\\<close>\n     | TcbSetSpaceIntent fault_ep cspace_root_data vspace_root_data \\<Rightarrow>\n         doE\n           cspace_root \\<leftarrow> throw_on_none $ get_index caps 0;\n           vspace_root \\<leftarrow> throw_on_none $ get_index caps 1;\n           cspace_root_cap_ref \\<leftarrow> returnOk $ (cdl_update_cnode_cap_data (fst cspace_root) cspace_root_data,snd cspace_root);\n           vspace_root_cap_ref \\<leftarrow> returnOk $ vspace_root;\n           returnOk (ThreadControl (cap_object target) slot (Some fault_ep)\n               (Some cspace_root_cap_ref) (Some vspace_root_cap_ref) None)\n        odE \\<sqinter> throw\n     | TcbBindNTFNIntent \\<Rightarrow> doE\n           (ntfn_cap, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           returnOk (NotificationControl (cap_object target) (Some (cap_object ntfn_cap)))\n         odE \\<sqinter> throw\n     | TcbUnbindNTFNIntent \\<Rightarrow> returnOk (NotificationControl (cap_object target) None) \\<sqinter> throw\n     | TCBSetTLSBaseIntent \\<Rightarrow> returnOk (SetTLSBase (cap_object target)) \\<sqinter> throw\n  \"\n\n\n(* Delete the given slot of a TCB. *)\n\ndefinition\n  tcb_empty_thread_slot :: \"cdl_object_id \\<Rightarrow> cdl_cnode_index \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_empty_thread_slot target_tcb target_slot \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap (target_tcb,target_slot);\n    whenE (cap \\<noteq> NullCap) $\n      delete_cap  (target_tcb, target_slot)\n  odE\"\n\n(* Update the given slot of a TCB with a new cap, delete the previous\n * capability that was in the slot. *)\n\ndefinition\n  tcb_update_thread_slot :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cnode_index \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_thread_slot target_tcb tcb_cap_slot target_slot pcap \\<equiv>\n         liftE (do\n           thread_cap \\<leftarrow> get_cap tcb_cap_slot;\n           when (thread_cap = TcbCap target_tcb)\n           (insert_cap_child (fst pcap) (snd pcap) (target_tcb, target_slot)\n            \\<sqinter> insert_cap_sibling (fst pcap) (snd pcap) (target_tcb,target_slot))\n         od)\"\n\n(* Update a thread's CSpace root. *)\ndefinition\n  tcb_update_cspace_root :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap \\<times> cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_cspace_root target_tcb tcb_cap_ref croot \\<equiv>\n  doE\n     tcb_empty_thread_slot target_tcb tcb_cspace_slot;\n     src_cap \\<leftarrow> liftE $ get_cap (snd croot);\n     whenE (is_cnode_cap src_cap \\<and> (cap_object src_cap = cap_object (fst croot)))\n       $ tcb_update_thread_slot target_tcb tcb_cap_ref tcb_cspace_slot croot\n  odE\"\n\n(* Update a thread's VSpace root. *)\ndefinition\n  tcb_update_vspace_root :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_vspace_root target_tcb tcb_cap_ref vroot \\<equiv>\n  doE\n     tcb_empty_thread_slot target_tcb tcb_vspace_slot;\n     src_cap \\<leftarrow> liftE $ get_cap (snd vroot);\n     whenE (cdl_same_arch_obj_as (fst vroot) src_cap)\n       $ tcb_update_thread_slot target_tcb tcb_cap_ref tcb_vspace_slot vroot\n  odE\"\n\n\n\n(* Modify the TCB's intent to indicate an error during decode. *)\ndefinition\n  mark_tcb_intent_error :: \"cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"mark_tcb_intent_error target_tcb has_error \\<equiv>\n      update_thread target_tcb (\\<lambda>t. (t\\<lparr>cdl_tcb_intent := (cdl_tcb_intent t)\\<lparr>cdl_intent_error := has_error\\<rparr>\\<rparr>))\"\n\n(* Update a thread's IPC buffer. *)\n\ndefinition\n  tcb_update_ipc_buffer :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"tcb_update_ipc_buffer target_tcb tcb_cap_ref ipc_buffer \\<equiv>\n     doE\n       tcb_empty_thread_slot target_tcb tcb_ipcbuffer_slot;\n       liftE $ corrupt_tcb_intent target_tcb;\n       src_cap \\<leftarrow> liftE $ get_cap (snd ipc_buffer);\n       whenE (cdl_same_arch_obj_as (fst ipc_buffer) src_cap)\n         $ tcb_update_thread_slot target_tcb tcb_cap_ref tcb_ipcbuffer_slot ipc_buffer\n     odE\n\"\n\n(* Resume a thread, aborting any pending operation, and revoking\n * any incoming reply caps. *)\ndefinition\n  restart :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"restart target_tcb \\<equiv>\n  do\n     cap \\<leftarrow> KHeap_D.get_cap (target_tcb,tcb_pending_op_slot);\n     when (cap \\<noteq> RestartCap \\<and> cap\\<noteq> RunningCap)\n     (do\n       CSpace_D.cancel_ipc target_tcb;\n       KHeap_D.set_cap (target_tcb,tcb_replycap_slot) (cdl_cap.MasterReplyCap target_tcb);\n       KHeap_D.set_cap (target_tcb,tcb_pending_op_slot) (cdl_cap.RestartCap)\n      od)\n  od\"\n\n(* Suspend a thread, aborting any pending operation, and revoking\n * any incoming reply caps. *)\ndefinition\n  suspend :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"suspend target_tcb \\<equiv> CSpace_D.cancel_ipc target_tcb >>= K (KHeap_D.set_cap (target_tcb,tcb_pending_op_slot) cdl_cap.NullCap)\"\n\ndefinition\n  bind_notification :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"bind_notification tcb_id ntfn_id \\<equiv> set_cap (tcb_id, tcb_boundntfn_slot) (BoundNotificationCap ntfn_id)\"\n\ndefinition\n  invoke_tcb :: \"cdl_tcb_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_tcb params \\<equiv> case params of\n    \\<comment> \\<open>Modify a thread's registers.\\<close>\n      WriteRegisters target_tcb resume _ _ \\<Rightarrow>\n        liftE $\n        do\n          corrupt_tcb_intent target_tcb;\n          when resume $ restart target_tcb\n        od\n\n    \\<comment> \\<open>Read a thread's registers.\\<close>\n    | ReadRegisters src_tcb _ _ _ \\<Rightarrow>\n        liftE $ suspend src_tcb \\<sqinter> return ()\n\n    \\<comment> \\<open>Copy registers from one thread to another\\<close>\n    | CopyRegisters target_tcb source_tcb _ _ _ _ _ \\<Rightarrow>\n        liftE $\n        do\n          suspend source_tcb \\<sqinter> return ();\n          restart target_tcb \\<sqinter> return ();\n          corrupt_tcb_intent target_tcb\n       od\n\n    \\<comment> \\<open>Suspend this thread.\\<close>\n    | Suspend target_tcb \\<Rightarrow>\n        liftE $ suspend target_tcb \\<sqinter> return ()\n\n    \\<comment> \\<open>Resume this thread.\\<close>\n    | Resume target_tcb \\<Rightarrow>\n        liftE $ restart target_tcb\n\n    \\<comment> \\<open>Update a thread's options.\\<close>\n    | ThreadControl target_tcb tcb_cap_slot faultep croot vroot ipc_buffer \\<Rightarrow>\n        doE\n          case faultep of\n              Some x \\<Rightarrow> liftE $ update_thread target_tcb (\\<lambda>tcb. tcb\\<lparr>cdl_tcb_fault_endpoint := x\\<rparr>)\n            | None \\<Rightarrow> returnOk ();\n\n          \\<comment> \\<open>Possibly update CSpace\\<close>\n          case croot of\n              Some x \\<Rightarrow> tcb_update_cspace_root target_tcb tcb_cap_slot x\n            | None \\<Rightarrow> returnOk ();\n\n          \\<comment> \\<open>Possibly update VSpace\\<close>\n          case vroot of\n              Some x \\<Rightarrow> tcb_update_vspace_root target_tcb tcb_cap_slot x\n            | None \\<Rightarrow> returnOk ();\n\n          \\<comment> \\<open>Possibly update Ipc Buffer\\<close>\n          case ipc_buffer of\n              Some x \\<Rightarrow> tcb_update_ipc_buffer target_tcb tcb_cap_slot x\n            | None \\<Rightarrow> (returnOk () \\<sqinter> (doE tcb_empty_thread_slot target_tcb tcb_ipcbuffer_slot;\n                 liftE $ corrupt_tcb_intent target_tcb odE))\n        odE\n    | NotificationControl tcb ntfn \\<Rightarrow>\n          liftE $ (case ntfn of\n             Some ntfn_id \\<Rightarrow> bind_notification tcb ntfn_id\n           | None \\<Rightarrow> unbind_notification tcb)\n    | SetTLSBase tcb \\<Rightarrow> liftE $ corrupt_tcb_intent tcb\"\n\n\ndefinition\n  decode_domain_invocation :: \"(cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_domain_intent \\<Rightarrow> cdl_domain_invocation except_monad\"\nwhere\n  \"decode_domain_invocation caps intent \\<equiv> case intent of\n     DomainSetIntent d \\<Rightarrow> returnOk (SetDomain (cap_object (fst (hd caps))) d) \\<sqinter> throw\"\n\ndefinition\n  set_domain :: \"cdl_object_id \\<Rightarrow> word8 \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_domain tcb d \\<equiv> update_thread tcb (\\<lambda>t. (t\\<lparr>cdl_tcb_domain := d \\<rparr>))\"\n\ndefinition\n  invoke_domain :: \"cdl_domain_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_domain params \\<equiv> case params of\n     SetDomain tcb d \\<Rightarrow> liftE $ set_domain tcb d\"\n\n\nend"}
{"title": "./spec/capDL/Endpoint_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Operations on endpoints.\n *)\n\ntheory Endpoint_D\nimports Invocations_D CSpace_D Tcb_D\nbegin\n\n(* Inject the reply cap into the target TCB *)\ndefinition\n  inject_reply_cap :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"inject_reply_cap src_tcb_id dst_tcb_id can_grant \\<equiv> do\n     set_cap (src_tcb_id, tcb_pending_op_slot) $\n         cdl_cap.PendingSyncRecvCap src_tcb_id True False;\n     insert_cap_child (ReplyCap src_tcb_id (if can_grant then {Grant, Write} else {Write}))\n                      (src_tcb_id, tcb_replycap_slot)\n                      (dst_tcb_id, tcb_caller_slot);\n     return ()\n  od\"\n\n(*\n * Get the slot where we should place an incoming cap for a\n * particular thread.\n *)\n\ndefinition\n  get_receive_slot :: \"cdl_object_id \\<Rightarrow> cdl_cap_ref option k_monad\"\nwhere\n  \"get_receive_slot thread \\<equiv>\n    do\n      tcb \\<leftarrow> get_thread thread;\n      recv_slot \\<leftarrow> (case (cdl_tcb_caps tcb tcb_ipcbuffer_slot) of (Some (FrameCap _ _ rights _ _ _)) \\<Rightarrow>\n        if (Read \\<in> rights \\<and> Write \\<in> rights)\n          then return (cdl_intent_recv_slot (cdl_tcb_intent tcb))\n        else\n          return None\n      | _ \\<Rightarrow> return None);\n      case ( recv_slot ) of\n          None \\<Rightarrow>\n            return None\n        | Some (croot, index, depth) \\<Rightarrow>\n            doE\n              \\<comment> \\<open>Lookup the slot.\\<close>\n              cspace_root \\<leftarrow> unify_failure $ lookup_cap thread croot;\n              result \\<leftarrow> unify_failure $ lookup_slot_for_cnode_op cspace_root index depth;\n\n              \\<comment> \\<open>Ensure nothing is already in it.\\<close>\n              cap \\<leftarrow> liftE $ get_cap result;\n              whenE (cap \\<noteq> NullCap) throw;\n\n              returnOk $ Some result\n            odE <catch> (\\<lambda>_. return None)\n    od\n  \"\n\n(* Get the cptr's that the given thread wishes to transfer. *)\ndefinition\n  get_send_slots :: \"cdl_object_id \\<Rightarrow> cdl_cptr list k_monad\"\nwhere\n  \"get_send_slots thread \\<equiv>\n    do\n      tcb \\<leftarrow> get_thread thread;\n      return $ cdl_intent_extras (cdl_tcb_intent tcb)\n    od\n  \"\n\ndefinition\n  get_ipc_buffer :: \"cdl_object_id \\<Rightarrow> bool \\<Rightarrow> cdl_object_id option k_monad\"\nwhere\n  \"get_ipc_buffer oid in_receive \\<equiv> do\n    frame_cap \\<leftarrow> get_cap (oid,tcb_ipcbuffer_slot);\n    (case frame_cap of\n        Types_D.FrameCap _ a rights _ _ _ \\<Rightarrow> if (Write \\<in> rights \\<and> Read \\<in> rights) \\<or> (Read\\<in> rights \\<and> \\<not> in_receive)\n          then return (Some a)\n          else return None\n        | _ \\<Rightarrow> return None)\n   od\"\n\ndefinition\n  corrupt_ipc_buffer :: \"cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\n  where\n  \"corrupt_ipc_buffer oid in_receive \\<equiv> do\n    buffer \\<leftarrow> get_ipc_buffer oid in_receive;\n    (case buffer of\n        Some a \\<Rightarrow> corrupt_frame a\n      | None \\<Rightarrow> corrupt_tcb_intent oid)\n  od\"\n\n(*\n * Transfers at most one cap in addition to a number of endpoint badges.\n *\n * Endpoint badges are transferred if the cap to be transferred is to\n * the endpoint used in the transfer.\n *)\nfun\n  transfer_caps_loop :: \"cdl_object_id option \\<Rightarrow> cdl_object_id \\<Rightarrow>\n                         (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow> cdl_cap_ref option\n                         \\<Rightarrow> unit k_monad\"\nwhere\n  \"transfer_caps_loop ep receiver [] dest = return ()\"\n| \"transfer_caps_loop ep receiver ((cap,slot)#caps) dest =\n      \\<comment> \\<open>Transfer badge, transfer cap, or abort early if more than\n         one cap to transfer\\<close>\n      (if is_ep_cap cap \\<and> ep = Some (cap_object cap)\n      then do\n        \\<comment> \\<open>transfer badge\\<close>\n        corrupt_ipc_buffer receiver True;\n        \\<comment> \\<open>transfer rest of badges or cap\\<close>\n        transfer_caps_loop ep receiver caps dest\n      od\n      else if dest \\<noteq> None then doE\n        new_cap \\<leftarrow> returnOk (update_cap_rights (cap_rights cap - {Write}) cap) \\<sqinter>\n                  returnOk cap;\n\n        \\<comment> \\<open>Target cap is derived. This may abort transfer early.\\<close>\n        target_cap \\<leftarrow> derive_cap slot new_cap;\n        whenE (target_cap = NullCap) throw;\n\n        \\<comment> \\<open>Copy the cap across as either a child or sibling.\\<close>\n        liftE (insert_cap_child target_cap slot (the dest)\n               \\<sqinter> insert_cap_sibling target_cap slot (the dest));\n\n        \\<comment> \\<open>Transfer rest of badges\\<close>\n        liftE $ transfer_caps_loop ep receiver caps None\n      odE <catch> (\\<lambda>_. return ())\n      else\n        return ())\"\n\n\n(*\n * Transfer caps from src to dest.\n *\n * In theory, the source thread specifies a list of caps to send, and\n * the destination thread specifies a list of cap slots to put them in.\n *\n * In the true spirit of L4 Pistachio, what _actually_ occurs during the\n * IPC transfer is hard to determine without knowing intricate details\n * of the kernel's implementation. In particular:\n *\n *   - Caps often just won't send, but still 'burn' the receive slot\n *     (ZombieCaps, ReplyCaps, IrqControlCap);\n *\n *   - Caps may not send, but still allow later caps to\n *     use the receive slot (Unwrapped endpoints);\n *\n *   - Cap sending may stop half way (cap lookup faults);\n *\n *   - The new cap may either be a sibling or child of source cap,\n *     depending on where in the CDT the source cap is.\n *\n *   - In reality, no more than one cap will ever be sent, because only\n *     one destination cap slot is supported elsewhere in the code.\n *\n * We remove some of the details, replacing them with nondeterminism.\n *)\ndefinition\n  transfer_caps :: \"cdl_object_id option \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n                    cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"transfer_caps ep caps sender receiver \\<equiv>\n    do\n      dest_slot \\<leftarrow> get_receive_slot receiver \\<sqinter> return None;\n      transfer_caps_loop ep receiver caps dest_slot\n    od\"\n\n(*\n * Get the set of threads waiting to receive on the given notification.\n *)\ndefinition\n  get_waiting_ntfn_recv_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_waiting_ntfn_recv_threads target state \\<equiv>\n     {x. \\<exists>a. (cdl_objects state) x = Some (Tcb a) \\<and>\n         (((cdl_tcb_caps a) tcb_pending_op_slot) = Some (PendingNtfnRecvCap target)) }\"\n\n(* Get the set of threads waiting to receive on the given sync endpoint. *)\ndefinition\n  get_waiting_sync_recv_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_waiting_sync_recv_threads target state \\<equiv>\n     {x. \\<exists>a. (cdl_objects state) x = Some (Tcb a) \\<and>\n         (\\<exists>can_grant. (cdl_tcb_caps a) tcb_pending_op_slot = Some (PendingSyncRecvCap target False can_grant)) }\"\n\n(*\n * Get the set of threads waiting to send to the given sync endpoint.\n *)\ndefinition\n  get_waiting_sync_send_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_waiting_sync_send_threads target state \\<equiv>\n     {t. \\<exists>fault a b. (cdl_objects state) t = Some (Tcb a) \\<and>\n         (\\<exists>call can_grant can_grant_reply. (cdl_tcb_caps a) tcb_pending_op_slot =\n                    Some (PendingSyncSendCap target b call can_grant can_grant_reply fault)) }\"\n\n(*\n * Get the set of threads which are bound to the given ntfn, but are\n * also waiting on sync IPC\n *)\ndefinition\n  get_waiting_sync_bound_ntfn_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_waiting_sync_bound_ntfn_threads ntfn_id state \\<equiv>\n     {x. \\<exists>a ep_id. (cdl_objects state) x = Some (Tcb a) \\<and>\n         (\\<exists>can_grant. (cdl_tcb_caps a) tcb_pending_op_slot = Some (PendingSyncRecvCap ep_id False can_grant)) \\<and>\n         ((cdl_tcb_caps a) tcb_boundntfn_slot = Some (BoundNotificationCap ntfn_id))}\"\n\n(*\n * Mark a thread blocked on IPC.\n *\n * Theads get a new implicit \"send once\" or \"receive once\" capability\n * when they block on an IPC. This is because if the capability they\n * used to start the send/receive is revoked, the transfer will still be\n * allowed to proceed (even if it is at a much later point in time).\n *)\n\ndefinition\n  block_thread_on_ipc :: \"cdl_object_id \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere\n  \"block_thread_on_ipc tcb cap \\<equiv> set_cap (tcb, tcb_pending_op_slot) cap\" (* Might need to do some check here *)\n\ndefinition\n  lookup_extra_caps :: \"cdl_object_id \\<Rightarrow> cdl_cptr list \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list fault_monad\"\nwhere\n  \"lookup_extra_caps thread cptrs \\<equiv>\n     mapME (\\<lambda>cptr. lookup_cap_and_slot thread cptr) cptrs\"\n\n(*\n * Transfer a message from \"sender\" to \"receiver\", possibly copying caps\n * over in the process. If a fault is pending in receiver, send fault instead.\n *)\ndefinition\n  do_ipc_transfer :: \"cdl_object_id option \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"do_ipc_transfer ep_id sender_id receiver_id can_grant \\<equiv> do\n      \\<comment> \\<open>look up cap transfer\\<close>\n      src_slots \\<leftarrow> get_send_slots sender_id;\n      do \\<comment> \\<open>do normal transfer\\<close>\n        caps \\<leftarrow> if can_grant then\n                lookup_extra_caps sender_id src_slots <catch> (\\<lambda>_. return [])\n              else\n                return [];\n        \\<comment> \\<open>copy registers, transfer message or fault\\<close>\n        corrupt_ipc_buffer receiver_id True;\n        \\<comment> \\<open>transfer caps if no fault occured\\<close>\n        transfer_caps ep_id caps sender_id receiver_id\n      od  \\<sqinter>  \\<comment> \\<open>fault transfer\\<close>\n      corrupt_ipc_buffer receiver_id True;\n      \\<comment> \\<open>set message info\\<close>\n      corrupt_tcb_intent receiver_id\n  od\"\n\n\n(*\n * Transfer a message from \"sender\" to \"receiver\" using a reply capability.\n *\n * The sender may have the right to grant caps over the channel.\n *\n * If a fault is pending in the receiver, the fault is transferred.\n *)\n\ndefinition\n  do_reply_transfer :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"do_reply_transfer sender_id receiver_id reply_cap_slot can_grant \\<equiv>\n    do\n      has_fault \\<leftarrow> get_thread_fault receiver_id;\n      when (\\<not> has_fault) $ do_ipc_transfer None sender_id receiver_id can_grant;\n      \\<comment> \\<open>Clear out any pending operation caps.\\<close>\n      delete_cap_simple reply_cap_slot;\n      when (has_fault) $ (do corrupt_tcb_intent receiver_id;\n        update_thread_fault receiver_id (\\<lambda>_. False) od );\n      if ( \\<not> has_fault) then set_cap (receiver_id, tcb_pending_op_slot) RunningCap\n      else\n         (set_cap (receiver_id,tcb_pending_op_slot) NullCap\n        \\<sqinter> set_cap (receiver_id,tcb_pending_op_slot) RestartCap)\n    od\"\n\n(* Wake-up a thread waiting on an notification. *)\ndefinition\n  do_notification_transfer :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"do_notification_transfer receiver_id \\<equiv> do\n      set_cap (receiver_id,tcb_pending_op_slot) RunningCap;\n      corrupt_tcb_intent receiver_id\n   od\"\n\n(*\n * Signal on a notification.\n *\n * If someone is blocked on the notifications, we wake them up. Otherwise,\n * this is a no-(.)\n *)\n\ndefinition\n  send_signal_bound :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"send_signal_bound ntfn_id \\<equiv> do\n      bound_tcbs \\<leftarrow> gets $ get_waiting_sync_bound_ntfn_threads ntfn_id;\n      if (bound_tcbs \\<noteq> {}) then do\n          t \\<leftarrow> select bound_tcbs;\n          set_cap (t, tcb_pending_op_slot) NullCap;\n          do_notification_transfer t\n        od\n      else return ()\n    od\"\n\ndefinition\n  send_signal :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"send_signal ep_id \\<equiv>\n    (do waiters \\<leftarrow> gets $ get_waiting_ntfn_recv_threads ep_id;\n          t \\<leftarrow> option_select waiters;\n          case t of\n              None \\<Rightarrow> return ()\n            | Some receiver \\<Rightarrow> do_notification_transfer receiver\n     od)\n            \\<sqinter> send_signal_bound ep_id\"\n\n(*\n * Receive a signal (receive from a notification).\n *\n * We will either receive data or block waiting.\n *)\ndefinition\n  recv_signal :: \"cdl_object_id \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere\n  \"recv_signal tcb_id_receiver ep_cap  \\<equiv> do\n     ep_id \\<leftarrow> return $ cap_object ep_cap;\n     block_thread_on_ipc tcb_id_receiver (PendingNtfnRecvCap ep_id) \\<sqinter> corrupt_tcb_intent tcb_id_receiver\n   od\"\n\n(*\n * Send an IPC to the given endpoint. If someone is waiting, we wake\n * them up. Otherwise, we put the sender to sleep.\n *)\ndefinition\n  send_ipc :: \"bool \\<Rightarrow> bool \\<Rightarrow> cdl_badge \\<Rightarrow> bool \\<Rightarrow> bool \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"send_ipc block call badge can_grant can_grant_reply tcb_id_sender ep_id \\<equiv>\n    do\n      waiters \\<leftarrow> gets $ get_waiting_sync_recv_threads ep_id;\n      t \\<leftarrow> option_select waiters;\n      case t of\n          None \\<Rightarrow>\n            if block then\n              block_thread_on_ipc tcb_id_sender\n                  (PendingSyncSendCap ep_id badge call can_grant can_grant_reply False)\n            else\n              return ()\n        | Some tcb_id_receiver \\<Rightarrow> do\n             \\<comment> \\<open>liftM instead of bind+return avoids early unfolding in send_ipc_corres\\<close>\n             recv_state \\<leftarrow> liftM (\\<lambda>tcb. the (cdl_tcb_caps tcb tcb_pending_op_slot)) $\n                              get_thread tcb_id_receiver;\n             reply_can_grant \\<leftarrow>\n               (case recv_state of\n                    PendingSyncRecvCap target False receiver_grant \\<Rightarrow> do\n                      do_ipc_transfer (Some ep_id) tcb_id_sender tcb_id_receiver can_grant;\n                      return receiver_grant od\n                  | _ \\<Rightarrow> fail);\n             set_cap (tcb_id_receiver,tcb_pending_op_slot) RunningCap;\n             (when (can_grant \\<or> can_grant_reply) $\n                  (inject_reply_cap tcb_id_sender tcb_id_receiver reply_can_grant))\n               \\<sqinter> set_cap (tcb_id_sender,tcb_pending_op_slot) NullCap \\<sqinter> return ()\n          od\n    od\"\n\n(*\n * Receive an IPC from the given endpoint. If someone is waiting, we\n * wake them up. Otherwise, we put the receiver to sleep.\n *)\ndefinition\n  receive_sync :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"receive_sync thread ep_id receiver_can_grant \\<equiv> do\n    waiters \\<leftarrow> gets $ get_waiting_sync_send_threads ep_id;\n      waiter \\<leftarrow> option_select waiters;\n      (case waiter of\n          None \\<Rightarrow>\n            block_thread_on_ipc thread (PendingSyncRecvCap ep_id False receiver_can_grant)\n             \\<sqinter> corrupt_tcb_intent thread\n        | Some tcb_id_sender \\<Rightarrow> (do\n            tcb \\<leftarrow> get_thread tcb_id_sender;\n            case ((cdl_tcb_caps tcb) tcb_pending_op_slot) of\n              Some (PendingSyncSendCap target _ call can_grant can_grant_reply fault) \\<Rightarrow> (do\n                 do_ipc_transfer (Some ep_id) tcb_id_sender thread can_grant;\n                 (when (can_grant \\<or> can_grant_reply) $\n                    (inject_reply_cap tcb_id_sender thread receiver_can_grant)) \\<sqinter>\n                 set_cap (tcb_id_sender, tcb_pending_op_slot) RunningCap \\<sqinter>\n                 set_cap (tcb_id_sender, tcb_pending_op_slot) NullCap\n              od)\n        od)\n      )\n    od\"\n\n(* This is more nonderministic than is really required, but\n   it makes the refinement proofs much easier *)\ndefinition\n  receive_ipc :: \"cdl_object_id \\<Rightarrow> cdl_object_id \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"receive_ipc thread ep_id can_grant \\<equiv> corrupt_tcb_intent thread \\<sqinter> receive_sync thread ep_id can_grant\"\n\ndefinition\n  invoke_endpoint :: \"bool \\<Rightarrow> bool \\<Rightarrow> cdl_endpoint_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_endpoint is_call can_block params \\<equiv> case params of\n    SyncMessage badge can_grant can_grant_reply ep_id \\<Rightarrow> do\n      thread \\<leftarrow> gets_the cdl_current_thread;\n      send_ipc can_block is_call badge can_grant can_grant_reply thread ep_id\n    od\"\n\ndefinition\n  invoke_notification :: \"cdl_notification_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_notification params \\<equiv> case params of\n    Signal badge ep_id \\<Rightarrow>\n      send_signal ep_id\"\n\ndefinition\n  invoke_reply :: \"cdl_reply_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_reply params \\<equiv> case params of\n    ReplyMessage recv reply_cap_ref rights \\<Rightarrow> do\n      send \\<leftarrow> gets_the cdl_current_thread;\n      do_reply_transfer send recv reply_cap_ref rights\n    od\"\n\n\n(*\n * Send a fault IPC to the given thread's fault handler.\n *)\ndefinition\n  send_fault_ipc :: \"cdl_object_id \\<Rightarrow> unit fault_monad\"\n  where\n  \"send_fault_ipc tcb_id \\<equiv>\n    doE\n      \\<comment> \\<open>Lookup where we should send the fault IPC to.\\<close>\n      tcb \\<leftarrow> liftE $ get_thread tcb_id;\n      target_ep_cptr \\<leftarrow> returnOk $ cdl_tcb_fault_endpoint tcb;\n      handler_cap \\<leftarrow> lookup_cap tcb_id target_ep_cptr;\n      (case handler_cap of\n          EndpointCap ref badge rights \\<Rightarrow>\n            if Write \\<in> rights \\<and> (Grant \\<in> rights \\<or> GrantReply \\<in> rights) then\n              liftE $ do\n                update_thread_fault tcb_id (\\<lambda>_. True);\n                send_ipc True True badge (Grant \\<in> rights) True tcb_id ref\n              od\n            else\n               throw\n        | _ \\<Rightarrow> throw)\n    odE\"\n\n(*\n * Handle a fault caused by the current thread.\n *\n * The abstract spec adds two additional parameters:\n *\n *    1. The fault type (which we abstract away);\n *\n *    2. The thread causing the fault (which always turns out\n *       to be the current thread).\n *)\ndefinition\n  handle_fault :: \"unit k_monad\"\nwhere\n  \"handle_fault \\<equiv> do\n    tcb_id \\<leftarrow> gets_the cdl_current_thread;\n    (send_fault_ipc tcb_id\n      <catch> (\\<lambda>_. KHeap_D.set_cap (tcb_id,tcb_pending_op_slot) cdl_cap.NullCap))\n  od\"\n\nend"}
{"title": "./spec/capDL/CNode_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Operations on CNodes.\n *)\n\ntheory CNode_D\nimports Invocations_D CSpace_D\nbegin\n\ndefinition\n  has_cancel_send_rights :: \"cdl_cap \\<Rightarrow> bool\" where\n  \"has_cancel_send_rights cap \\<equiv> case cap of\n   EndpointCap _ _ R \\<Rightarrow> R = UNIV\n   | _ \\<Rightarrow> False\"\n\ndefinition\n  decode_cnode_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_cnode_intent \\<Rightarrow> cdl_cnode_invocation except_monad\"\nwhere\n  \"decode_cnode_invocation target target_ref caps intent \\<equiv> case intent of\n       \\<comment> \\<open>Copy a cap to anther capslot, without modifying the cap.\\<close>\n       CNodeCopyIntent dest_index dest_depth src_index src_depth rights \\<Rightarrow>\n         doE\n           (src_root, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op target dest_index (unat dest_depth);\n           ensure_empty dest_slot;\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n           new_cap \\<leftarrow> returnOk $ update_cap_rights (cap_rights src_cap \\<inter> rights) src_cap;\n           cap \\<leftarrow> derive_cap src_slot new_cap;\n           whenE (cap = cdl_cap.NullCap) throw;\n\n           returnOk $ InsertCall cap src_slot dest_slot\n         odE\n\n     \\<comment> \\<open>Copy a cap to another capslot, possibly modifying the cap.\\<close>\n     | CNodeMintIntent dest_index dest_depth src_index src_depth rights badge \\<Rightarrow>\n         doE\n           (src_root, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op target dest_index (unat dest_depth);\n           ensure_empty dest_slot;\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n\n           \\<comment> \\<open>Munge the caps rights/data.\\<close>\n           new_cap \\<leftarrow> returnOk $ update_cap_rights (cap_rights src_cap \\<inter> rights) src_cap;\n           new_cap' \\<leftarrow> liftE $ update_cap_data False badge new_cap;\n\n           cap \\<leftarrow> derive_cap src_slot new_cap';\n           whenE (cap = cdl_cap.NullCap) throw;\n\n           returnOk $ InsertCall cap src_slot dest_slot\n         odE\n\n     \\<comment> \\<open>Move a cap to another capslot, without modifying the cap.\\<close>\n     | CNodeMoveIntent dest_index dest_depth src_index src_depth \\<Rightarrow>\n         doE\n           (src_root, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op target dest_index (unat dest_depth);\n           ensure_empty dest_slot;\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n           whenE (src_cap = NullCap) throw;\n           returnOk $ MoveCall src_cap src_slot dest_slot\n         odE\n\n     \\<comment> \\<open>Move a cap to another capslot, possibly modifying the cap.\\<close>\n     | CNodeMutateIntent dest_index dest_depth src_index src_depth badge \\<Rightarrow>\n         doE\n           (src_root, _) \\<leftarrow> throw_on_none $ get_index caps 0;\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op target dest_index (unat dest_depth);\n           ensure_empty dest_slot;\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n\n           \\<comment> \\<open>Munge the caps rights/data.\\<close>\n           cap \\<leftarrow> liftE $ update_cap_data True badge src_cap;\n           whenE (cap = NullCap) throw;\n\n           returnOk $ MoveCall cap src_slot dest_slot\n         odE\n\n     \\<comment> \\<open>Revoke all CDT children of the given cap.\\<close>\n     | CNodeRevokeIntent index depth \\<Rightarrow>\n         doE\n           target_slot \\<leftarrow> lookup_slot_for_cnode_op target index (unat depth);\n           returnOk $ RevokeCall target_slot\n         odE\n\n     \\<comment> \\<open>Delete the given cap, but not its children.\\<close>\n     | CNodeDeleteIntent index depth \\<Rightarrow>\n         doE\n           target_slot \\<leftarrow> lookup_slot_for_cnode_op target index (unat depth);\n           returnOk $ DeleteCall target_slot\n         odE\n\n     \\<comment> \\<open>Save the current thread's reply cap into the target slot.\\<close>\n     | CNodeSaveCallerIntent index depth \\<Rightarrow>\n         doE\n           target_slot \\<leftarrow> lookup_slot_for_cnode_op target index (unat depth);\n           ensure_empty target_slot;\n           returnOk $ SaveCall target_slot\n         odE\n\n     \\<comment> \\<open>Recycle the target cap.\\<close>\n     | CNodeCancelBadgedSendsIntent index depth \\<Rightarrow>\n         doE\n           target_slot \\<leftarrow> lookup_slot_for_cnode_op target index (unat depth);\n           cap \\<leftarrow> liftE $ get_cap target_slot;\n           unlessE (has_cancel_send_rights cap) throw;\n           returnOk $ CancelBadgedSendsCall cap\n         odE\n\n     \\<comment> \\<open>Atomically move several caps.\\<close>\n     | CNodeRotateIntent dest_index dest_depth pivot_index pivot_depth pivot_badge src_index src_depth src_badge \\<Rightarrow>\n         doE\n           pivot_root \\<leftarrow> throw_on_none $ get_index caps 0;\n           src_root \\<leftarrow> throw_on_none $ get_index caps 1;\n\n           dest_root \\<leftarrow> returnOk $ target;\n           pivot_root \\<leftarrow> returnOk $ fst pivot_root;\n           src_root \\<leftarrow> returnOk $ fst src_root;\n\n           dest_slot \\<leftarrow> lookup_slot_for_cnode_op dest_root dest_index (unat dest_depth);\n           src_slot \\<leftarrow> lookup_slot_for_cnode_op src_root src_index (unat src_depth);\n           pivot_slot \\<leftarrow> lookup_slot_for_cnode_op pivot_root pivot_index (unat pivot_depth);\n\n           whenE (pivot_slot = src_slot \\<or> pivot_slot = dest_slot) throw;\n\n           unlessE (src_slot = dest_slot) $ ensure_empty dest_slot;\n\n           src_cap \\<leftarrow> liftE $ get_cap src_slot;\n           whenE (src_cap = NullCap) throw;\n\n           pivot_cap \\<leftarrow> liftE $ get_cap pivot_slot;\n           whenE (pivot_cap = NullCap) throw;\n\n           \\<comment> \\<open>Munge caps.\\<close>\n           new_src \\<leftarrow> liftE $ update_cap_data True src_badge src_cap;\n           new_pivot \\<leftarrow> liftE $ update_cap_data True pivot_badge pivot_cap;\n\n           whenE (new_src = NullCap) throw;\n           whenE (new_pivot = NullCap) throw;\n\n           returnOk $ RotateCall new_src new_pivot src_slot pivot_slot dest_slot\n         odE\n   \"\n\ndefinition\n  invoke_cnode :: \"cdl_cnode_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"invoke_cnode params \\<equiv> case params of\n    \\<comment> \\<open>Insert a new cap.\\<close>\n      InsertCall cap src_slot dest_slot \\<Rightarrow>\n        liftE $\n          insert_cap_sibling cap src_slot dest_slot\n          \\<sqinter>\n          insert_cap_child cap src_slot dest_slot\n\n    \\<comment> \\<open>Move a cap, possibly modifying it in the process.\\<close>\n    | MoveCall cap src_slot dest_slot \\<Rightarrow>\n        liftE $ move_cap cap src_slot dest_slot\n\n    \\<comment> \\<open>Revoke a cap.\\<close>\n    | RevokeCall src_slot \\<Rightarrow>\n        revoke_cap src_slot\n\n    \\<comment> \\<open>Delete a cap.\\<close>\n    | DeleteCall src_slot \\<Rightarrow>\n        delete_cap src_slot\n\n    \\<comment> \\<open>Atomically move two capabilities.\\<close>\n    | RotateCall cap1 cap2 slot1 slot2 slot3 \\<Rightarrow>\n        liftE $ if slot1 = slot3 then\n          swap_cap cap1 slot1 cap2 slot2\n        else\n          do\n            move_cap cap2 slot2 slot3;\n            move_cap cap1 slot1 slot2\n          od\n\n    \\<comment> \\<open>Save a reply cap from the caller's TCB into this CNode.\\<close>\n    | SaveCall dest_slot \\<Rightarrow>\n        liftE $ do\n          current \\<leftarrow> gets_the cdl_current_thread;\n          replycap \\<leftarrow> get_cap (current, tcb_caller_slot);\n          when (replycap \\<noteq> NullCap)\n            $ move_cap replycap (current, tcb_caller_slot) dest_slot\n        od\n\n    \\<comment> \\<open>Reset an object into its original state.\\<close>\n    | CancelBadgedSendsCall (EndpointCap ep b _) \\<Rightarrow> liftE $ when (b \\<noteq> 0) $ cancel_badged_sends ep b\n    | CancelBadgedSendsCall _ \\<Rightarrow> fail\n  \"\n\nend"}
{"title": "./spec/capDL/PageTable_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Operations on page table objects and frames.\n *)\n\ntheory PageTable_D\nimports Invocations_D CSpace_D\nbegin\n\n(* Return the set of free PD slots in the given PD. *)\ndefinition\n  free_pd_slots :: \"cdl_object \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n  \"free_pd_slots pd pd_id state \\<equiv> {(pd_id, y). (object_slots pd) y = Some NullCap}\"\n\n(* Return the set of all PD/PT slots in the given PD. *)\ndefinition\n  all_pd_pt_slots :: \"cdl_object \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n  \"all_pd_pt_slots pd pd_id state \\<equiv> {(pd_id, y). y \\<in> dom (object_slots pd)}\n     \\<union> {(x, y). \\<exists> a b c. (object_slots pd) a = Some (PageTableCap x b c) \\<and> x \\<in> dom (cdl_objects state)}\"\n\ndefinition\n  \"cdl_get_pt_mapped_addr cap \\<equiv>\n    case cap of PageTableCap pid ctype maddr \\<Rightarrow>  maddr\n    | _ \\<Rightarrow> None\"\n\n(* Decode a page table intent into an invocation. *)\ndefinition\n  decode_page_table_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_page_table_intent \\<Rightarrow> cdl_page_table_invocation except_monad\"\nwhere\n  \"decode_page_table_invocation target target_ref caps intent \\<equiv> case intent of\n    \\<comment> \\<open>\n      Map the given PageTable into the given PageDirectory at the given\n      virtual address.\n\n      The concrete implementation only allows a PageTable to be mapped\n      once at any point in time, but we don't enforce that here.\n     \\<close>\n    PageTableMapIntent vaddr attr \\<Rightarrow>\n      doE\n        case cdl_get_pt_mapped_addr target of Some a \\<Rightarrow> throw\n        | None \\<Rightarrow> returnOk ();\n        \\<comment> \\<open>Ensure that a PD was passed in.\\<close>\n        pd \\<leftarrow> throw_on_none $ get_index caps 0;\n        (pd_object_id, asid) \\<leftarrow>\n          case (fst pd) of\n              PageDirectoryCap x _ (Some asid) \\<Rightarrow> returnOk (x, asid)\n            | _ \\<Rightarrow> throw;\n\n        target_slot \\<leftarrow> returnOk $ cdl_lookup_pd_slot pd_object_id vaddr;\n\n        returnOk $ PageTableMap (PageTableCap (cap_object target) Real (Some (asid,vaddr && ~~ mask 20)))\n          (PageTableCap (cap_object target) Fake None) target_ref target_slot\n      odE \\<sqinter> throw\n    \\<comment> \\<open>Unmap this PageTable.\\<close>\n    | PageTableUnmapIntent \\<Rightarrow> (\n        case target of PageTableCap pid ctype maddr \\<Rightarrow>\n        (returnOk $ PageTableUnmap maddr pid target_ref)\n        | _ \\<Rightarrow> throw\n      ) \\<sqinter> throw\n  \"\n\n(* Decode a page table intent into an invocation. *)\ndefinition\n  decode_page_directory_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_page_directory_intent \\<Rightarrow> cdl_page_directory_invocation except_monad\"\nwhere\n  \"decode_page_directory_invocation target target_ref caps intent \\<equiv>\n      (returnOk $ PageDirectoryNothing) \\<sqinter>\n      (returnOk $ PageDirectoryFlush Unify)  \\<sqinter>  (returnOk $ PageDirectoryFlush Clean)  \\<sqinter>\n      (returnOk $ PageDirectoryFlush CleanInvalidate )  \\<sqinter> (returnOk $ PageDirectoryFlush Invalidate)\n      \\<sqinter> throw \"\n\n\n\n\n(* Decode a page intent into an invocation. *)\n\ndefinition\n  decode_page_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_page_intent \\<Rightarrow> cdl_page_invocation except_monad\"\nwhere\n  \"decode_page_invocation target target_ref caps intent \\<equiv> case intent of\n      \\<comment> \\<open>\n        Map the given Page into the given PageDirectory or PageTable at\n        the given virtual address.\n\n        The concrete implementation only allows a Page to be mapped\n        once at any point in time, but we don't enforce that here.\n       \\<close>\n      PageMapIntent vaddr rights attr \\<Rightarrow>\n        doE\n          \\<comment> \\<open>Ensure that a PD was passed in.\\<close>\n          pd \\<leftarrow> throw_on_none $ get_index caps 0;\n          (pd_object_id, asid) \\<leftarrow>\n            case (fst pd) of\n                PageDirectoryCap x _ (Some asid) \\<Rightarrow> returnOk (x, asid)\n              | _ \\<Rightarrow> throw;\n\n          \\<comment> \\<open>Collect mapping from target cap.\\<close>\n          (frame,sz,dev) \\<leftarrow> returnOk $ (case target of FrameCap dev p R sz m mp \\<Rightarrow> (p,sz,dev));\n\n          target_slots \\<leftarrow> cdl_page_mapping_entries vaddr sz pd_object_id;\n\n          \\<comment> \\<open>Calculate rights.\\<close>\n          new_rights \\<leftarrow> returnOk $ validate_vm_rights $ cap_rights target \\<inter> rights;\n\n          \\<comment> \\<open>Return the map intent.\\<close>\n          returnOk $ PageMap (FrameCap dev frame (cap_rights target) sz Real (Some (asid,vaddr)))\n            (FrameCap False frame new_rights sz Fake None) target_ref target_slots\n        odE \\<sqinter> throw\n\n    \\<comment> \\<open>Unmap this PageTable.\\<close>\n    | PageUnmapIntent \\<Rightarrow> doE\n        (frame, asid, sz) \\<leftarrow> (case target of\n           FrameCap _ p R sz m mp \\<Rightarrow> returnOk (p, mp , sz)\n        | _ \\<Rightarrow> throw);\n      (returnOk $ PageUnmap asid frame target_ref sz) \\<sqinter> throw\n      odE\n\n    \\<comment> \\<open>Flush the caches associated with this page.\\<close>\n    | PageFlushCachesIntent \\<Rightarrow>\n       (returnOk $ PageFlushCaches Unify)  \\<sqinter>  (returnOk $ PageFlushCaches Clean)  \\<sqinter>\n      (returnOk $ PageFlushCaches CleanInvalidate )  \\<sqinter> (returnOk $ PageFlushCaches Invalidate)\n      \\<sqinter> throw\n\n    | PageGetAddressIntent \\<Rightarrow> returnOk PageGetAddress\n\n  \"\n\n(* Invoke a page table. *)\ndefinition\n  invoke_page_directory :: \"cdl_page_directory_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_page_directory params \\<equiv> case params of\n      PageDirectoryFlush flush  => return ()\n    | PageDirectoryNothing => return ()\n  \"\n\ndefinition \"option_exec f \\<equiv> \\<lambda>x. case x of Some a \\<Rightarrow> f a | None \\<Rightarrow> return ()\"\n\n(* Invoke a page table. *)\ndefinition\n  invoke_page_table :: \"cdl_page_table_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_page_table params \\<equiv> case params of\n      PageTableMap real_pt_cap pt_cap pt_cap_ref pd_target_slot \\<Rightarrow>\n        do set_cap pt_cap_ref real_pt_cap;\n           \\<comment> \\<open>\n             We install the Page Table into the Page Directory.  The\n             concrete kernel uses hardware-defined PDEs (Page Directory\n             Entries). Our abstract spec just uses caps.\n            \\<close>\n           insert_cap_orphan pt_cap pd_target_slot\n        od\n    | PageTableUnmap mapped_addr pt_id pt_cap_ref \\<Rightarrow> do\n        (case mapped_addr of Some maddr \\<Rightarrow> do\n                 unmap_page_table maddr pt_id;\n                 clear_object_caps pt_id \\<sqinter> return ()\n               od\n          | _ \\<Rightarrow> return ());\n        cap \\<leftarrow> get_cap pt_cap_ref;\n        set_cap pt_cap_ref (reset_mem_mapping cap)\n        od\n\n  \"\n\n(* Invoke a page. *)\ndefinition\n  invoke_page :: \"cdl_page_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_page params \\<equiv> case params of\n      PageMap frame_cap pseudo_frame_cap frame_cap_ref target_slots \\<Rightarrow>\n          \\<comment> \\<open>Clear out the target slots.\\<close>\n        do\n          set_cap frame_cap_ref frame_cap;\n          mapM_x (swp set_cap pseudo_frame_cap) target_slots\n        od\n\n    | PageUnmap mapped_addr frame_id frame_cap_ref pgsz \\<Rightarrow> do\n        (case mapped_addr of\n          Some maddr \\<Rightarrow> unmap_page maddr frame_id pgsz\n        | _ \\<Rightarrow> return ());\n        cap \\<leftarrow> get_cap frame_cap_ref;\n        set_cap frame_cap_ref (reset_mem_mapping cap)\n      od\n\n    | PageFlushCaches flush \\<Rightarrow> return ()\n\n    | PageGetAddress \\<Rightarrow> return ()\n\n  \"\n\nend"}
{"title": "./spec/capDL/Syscall_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * System calls\n *)\n\ntheory Syscall_D\nimports\n  Schedule_D\n  Decode_D\n  \"ExecSpec.Event_H\"\nbegin\n\n(*\n * Perform system calls.\n *\n * Each system call is broken into three stages:\n *\n *   (1) Cap validation, where we ensure that all caps passed\n *       into the system call are valid;\n *\n *   (2) Argument validation, where we ensure that the requested\n *       operation is valid and permitted; and\n *\n *   (3) Syscall execution, where we carry out the actual\n *       operation.\n *\n * For this function, the user passes us in 5 functions:\n *\n *   (1, 2) A cap validation function, and an error handler;\n *   (3, 4) A argument validation function, and an error handler;\n *   (5)    A syscall execution function.\n *\n * This function returns an item of type \"'c\", and may also\n * return an exception if operation (3) above was preempted\n * by an interrupt.\n *)\n\ndefinition\nsyscall :: \"\n  ('a fault_monad) \\<Rightarrow> (unit k_monad) \\<Rightarrow>\n  ('a \\<Rightarrow> 'b except_monad) \\<Rightarrow> (unit k_monad) \\<Rightarrow>\n  ('b \\<Rightarrow> unit preempt_monad) \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"syscall\n      cap_decoder_fn decode_error_handler_fn\n      arg_decode_fn arg_error_handler_fn\n      perform_syscall_fn \\<equiv>\n    cap_decoder_fn\n    <handle>\n      (\\<lambda> _. liftE $ decode_error_handler_fn)\n    <else>\n      (\\<lambda> a. ((arg_decode_fn a)\n        <handle>\n          (\\<lambda> _. liftE $ arg_error_handler_fn)\n        <else>\n          perform_syscall_fn))\n  \"\n\nfun\n  perform_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> cdl_invocation \\<Rightarrow> unit preempt_monad\"\nwhere\n    \"perform_invocation is_call can_block (InvokeUntyped untyped_params) = (invoke_untyped untyped_params)\"\n  | \"perform_invocation is_call can_block (InvokeEndpoint endpoint_params) = liftE (invoke_endpoint is_call can_block endpoint_params)\"\n  | \"perform_invocation is_call can_block (InvokeNotification ntfn_params) = liftE (invoke_notification ntfn_params)\"\n  | \"perform_invocation is_call can_block (InvokeReply reply_params) = liftE (invoke_reply reply_params)\"\n  | \"perform_invocation is_call can_block (InvokeTcb tcb_params) = (invoke_tcb tcb_params)\"\n  | \"perform_invocation is_call can_block (InvokeDomain domain_params) = (invoke_domain domain_params)\"\n  | \"perform_invocation is_call can_block (InvokeCNode cnode_params) = invoke_cnode cnode_params\"\n  | \"perform_invocation is_call can_block (InvokeIrqControl irq_params) = liftE (invoke_irq_control irq_params)\"\n  | \"perform_invocation is_call can_block (InvokeIrqHandler handler_params) = liftE (invoke_irq_handler handler_params)\"\n  | \"perform_invocation is_call can_block (InvokePageTable page_table_params) = liftE (invoke_page_table page_table_params)\"\n  | \"perform_invocation is_call can_block (InvokePage page_params) = liftE (invoke_page page_params)\"\n  | \"perform_invocation is_call can_block (InvokeAsidControl asid_control_params) = liftE (invoke_asid_control asid_control_params)\"\n  | \"perform_invocation is_call can_block (InvokeAsidPool asid_pool_params) = liftE (invoke_asid_pool asid_pool_params)\"\n  | \"perform_invocation is_call can_block (InvokePageDirectory page_dir_params) = liftE (invoke_page_directory page_dir_params) \"\n\ndefinition ep_related_cap :: \"cdl_cap \\<Rightarrow> bool\"\nwhere \"ep_related_cap cap \\<equiv> case cap of\n cdl_cap.EndpointCap o_id badge rights \\<Rightarrow> True\n| cdl_cap.NotificationCap o_id badge rights \\<Rightarrow> True\n| cdl_cap.ReplyCap o_id rights \\<Rightarrow> True\n| _ \\<Rightarrow> False\"\n\ndefinition \"has_restart_cap \\<equiv> \\<lambda>tcb_id. do\n  t \\<leftarrow> get_thread tcb_id;\n  return ((cdl_tcb_caps t) tcb_pending_op_slot = Some cdl_cap.RestartCap)\n  od\"\n\ndefinition\n  handle_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"handle_invocation is_call can_block \\<equiv>\n    doE\n      thread_ptr \\<leftarrow> liftE $ gets_the cdl_current_thread;\n      thread \\<leftarrow> liftE $ get_thread thread_ptr;\n      full_intent \\<leftarrow> returnOk $ cdl_tcb_intent thread;\n\n      intent \\<leftarrow> returnOk $ cdl_intent_op full_intent;\n      invoked_cptr \\<leftarrow> returnOk $ cdl_intent_cap full_intent;\n      extra_cap_cptrs \\<leftarrow> returnOk $ cdl_intent_extras full_intent;\n\n      syscall\n        \\<comment> \\<open>Lookup all caps presented.\\<close>\n        (doE\n          (cap, cap_ref) \\<leftarrow> lookup_cap_and_slot thread_ptr invoked_cptr;\n          extra_caps \\<leftarrow> lookup_extra_caps thread_ptr extra_cap_cptrs;\n          returnOk (cap, cap_ref, extra_caps)\n        odE)\n        \\<comment> \\<open>If that failed, send off a fault IPC (if we did a blocking operation).\\<close>\n        (when can_block $ handle_fault)\n\n        \\<comment> \\<open>Decode the user's intent.\\<close>\n        (\\<lambda> (cap, cap_ref, extra_caps).\n          case intent of\n              None \\<Rightarrow> (if ep_related_cap cap then\n                decode_invocation cap cap_ref extra_caps undefined\n                else throw)\n            | Some intent' \\<Rightarrow>\n                decode_invocation cap cap_ref extra_caps intent')\n\n        \\<comment> \\<open>If that stuffed up, we do nothing more than corrupt the frames.\\<close>\n        (do corrupt_ipc_buffer thread_ptr True;\n            when is_call (mark_tcb_intent_error thread_ptr True)\n         od)\n\n        \\<comment> \\<open>Invoke the system call.\\<close>\n        (\\<lambda> inv. doE\n            liftE $ set_cap (thread_ptr,tcb_pending_op_slot) RestartCap;\n            perform_invocation is_call can_block inv;\n            restart \\<leftarrow> liftE $ has_restart_cap thread_ptr;\n            whenE restart $ liftE (do\n                       corrupt_ipc_buffer thread_ptr True;\n                       when (is_call) (mark_tcb_intent_error thread_ptr False);\n                       set_cap (thread_ptr,tcb_pending_op_slot) RunningCap\n            od)\n            odE)\n  odE\n  \"\n\ndefinition\n  handle_recv :: \"unit k_monad\"\nwhere\n  \"handle_recv \\<equiv>\n    do\n      \\<comment> \\<open>Get the current thread.\\<close>\n      tcb_id \\<leftarrow> gets_the cdl_current_thread;\n      tcb \\<leftarrow> get_thread tcb_id;\n      \\<comment> \\<open>Get the endpoint it is trying to receive from.\\<close>\n      (doE\n        ep_cptr \\<leftarrow> returnOk $ cdl_intent_cap (cdl_tcb_intent tcb);\n        ep_cap \\<leftarrow> lookup_cap tcb_id ep_cptr;\n        (case ep_cap of\n          EndpointCap o_id badge rights \\<Rightarrow>\n            if Read \\<in> rights then\n              (liftE $ do\n                   delete_cap_simple (tcb_id, tcb_caller_slot);\n                   receive_ipc tcb_id (cap_object ep_cap) (Grant \\<in> rights)\n                od) \\<sqinter> throw\n            else\n              throw\n        | NotificationCap o_id badge rights \\<Rightarrow>\n            if Read \\<in> rights then\n              (liftE $ recv_signal tcb_id ep_cap) \\<sqinter> throw\n            else\n              throw\n        | _ \\<Rightarrow>\n            throw)\n      odE)\n      <catch>\n        (\\<lambda> _. handle_fault)\n    od\n  \"\n\ndefinition\n  handle_reply :: \"unit k_monad\"\nwhere\n  \"handle_reply \\<equiv>\n    do\n      tcb_id \\<leftarrow> gets_the cdl_current_thread;\n      caller_cap \\<leftarrow> get_cap (tcb_id, tcb_caller_slot);\n\n      case caller_cap of\n          ReplyCap target rights \\<Rightarrow> do_reply_transfer tcb_id target (tcb_id, tcb_caller_slot) (Grant \\<in> rights)\n        | NullCap \\<Rightarrow> return ()\n        | _ \\<Rightarrow> fail\n    od\n  \"\n\ndefinition handle_hypervisor_fault :: \"unit k_monad\"\nwhere \"handle_hypervisor_fault \\<equiv> return ()\"\n\ndefinition\n  handle_syscall :: \"syscall \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"handle_syscall sys \\<equiv>\n    case sys of\n      SysSend  \\<Rightarrow> handle_invocation False True\n    | SysNBSend \\<Rightarrow> handle_invocation False False\n    | SysCall \\<Rightarrow> handle_invocation True True\n    | SysRecv \\<Rightarrow> liftE $ handle_recv\n    | SysYield \\<Rightarrow> returnOk ()\n    | SysReply \\<Rightarrow> liftE $ handle_reply\n    | SysReplyRecv \\<Rightarrow> liftE $ do\n        handle_reply;\n        handle_recv\n      od\n    | SysNBRecv \\<Rightarrow> liftE $ handle_recv\"\n\ndefinition\n  handle_event :: \"event \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"handle_event ev \\<equiv> case ev of\n      SyscallEvent sys \\<Rightarrow> handle_syscall sys\n    | UnknownSyscall n \\<Rightarrow> liftE $ handle_fault\n    | UserLevelFault a b \\<Rightarrow> liftE $ handle_fault\n    | VMFaultEvent c \\<Rightarrow> liftE $ handle_fault\n    | Interrupt \\<Rightarrow> liftE $ handle_pending_interrupts\n    | HypervisorEvent w \\<Rightarrow> liftE $ handle_hypervisor_fault\n    \"\n\ndefinition\n  call_kernel :: \"event \\<Rightarrow> unit k_monad\"\nwhere\n  \"call_kernel ev \\<equiv>\n    do\n      \\<comment> \\<open>Deal with the event.\\<close>\n      handle_event ev\n        <handle> (\\<lambda> _. liftE handle_pending_interrupts);\n      schedule;\n      t \\<leftarrow> gets cdl_current_thread;\n      case t of Some thread \\<Rightarrow> do\n       restart \\<leftarrow> has_restart_cap thread;\n       when restart $ set_cap (thread, tcb_pending_op_slot) RunningCap\n      od | None \\<Rightarrow> return ()\n    od\"\n\nend"}
{"title": "./spec/capDL/PageTableUnmap_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Unmapping pages and page tables and what is needed for it:\n * short cut delete, revoke and finale of caps, ipc cancelling.\n *)\n\ntheory PageTableUnmap_D\nimports\n  Invocations_D\n  KHeap_D\nbegin\n\n\\<comment> \\<open>Return all slots in the system containing a cap with the given property.\\<close>\ndefinition\n  slots_with :: \"(cdl_cap \\<Rightarrow> bool) \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n  \"slots_with P s \\<equiv> {(obj, slot). \\<exists>x c. cdl_objects s obj = Some x \\<and>\n                                        has_slots x \\<and>\n                                        object_slots x slot = Some c \\<and> P c}\"\n\n\n\\<comment> \\<open>Remove a pending operation from the given TCB.\\<close>\ndefinition\n  remove_pending_operation :: \"cdl_tcb \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_tcb\"\nwhere\n  \"remove_pending_operation t cap \\<equiv> t\\<lparr>cdl_tcb_caps := (cdl_tcb_caps t)(tcb_pending_op_slot \\<mapsto> cap)\\<rparr>\"\n\n\n\\<comment> \\<open>Is the given thread pending on the given endpoint?\\<close>\ndefinition\n  is_thread_blocked_on_endpoint :: \"cdl_tcb \\<Rightarrow> cdl_object_id \\<Rightarrow> bool\"\nwhere\n  \"is_thread_blocked_on_endpoint t ep \\<equiv>\n    case (cdl_tcb_caps t tcb_pending_op_slot) of\n        Some (PendingSyncSendCap p _ _ _ _ _) \\<Rightarrow> p = ep\n      | Some (PendingSyncRecvCap p is_reply _) \\<Rightarrow> p = ep \\<and> \\<not> is_reply\n      | Some (PendingNtfnRecvCap p) \\<Rightarrow> p = ep\n      | _ \\<Rightarrow> False\"\n\n\n\\<comment> \\<open>Cancel all pending IPCs currently blocked on this endpoint.\\<close>\ndefinition\n  cancel_all_ipc :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"cancel_all_ipc ep \\<equiv>\n    modify (\\<lambda>s. s\\<lparr>cdl_objects :=  map_option\n        (\\<lambda>obj. case obj of\n            Tcb t \\<Rightarrow>\n              if (is_thread_blocked_on_endpoint t ep) then\n                Tcb (remove_pending_operation t RestartCap)\n              else\n                Tcb t\n           | _ \\<Rightarrow> obj)\n          \\<circ> (cdl_objects s)\\<rparr>)\"\n\n\\<comment> \\<open>Is the given thread bound to the given ntfn?\\<close>\ndefinition\n  is_thread_bound_to_ntfn :: \"cdl_tcb \\<Rightarrow> cdl_object_id \\<Rightarrow> bool\"\nwhere\n  \"is_thread_bound_to_ntfn t ntfn \\<equiv>\n    case (cdl_tcb_caps t tcb_boundntfn_slot) of\n        Some (BoundNotificationCap a) \\<Rightarrow> a = ntfn\n      | _ \\<Rightarrow> False\"\n\n\\<comment> \\<open>find all tcbs that are bound to a given ntfn\\<close>\ndefinition\n  get_bound_notification_threads :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"get_bound_notification_threads ntfn_id state \\<equiv>\n     {x. \\<exists>a. (cdl_objects state) x = Some (Tcb a) \\<and>\n         (((cdl_tcb_caps a) tcb_boundntfn_slot) = Some (BoundNotificationCap ntfn_id))}\"\n\ndefinition\n  modify_bound_ntfn :: \"cdl_tcb \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_tcb\"\nwhere\n  \"modify_bound_ntfn t cap \\<equiv> t \\<lparr> cdl_tcb_caps := (cdl_tcb_caps t)(tcb_boundntfn_slot \\<mapsto> cap)\\<rparr>\"\n\n\nabbreviation\n  do_unbind_notification :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"do_unbind_notification tcb \\<equiv> set_cap (tcb, tcb_boundntfn_slot) NullCap\"\n\ndefinition\n  unbind_notification :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"unbind_notification tcb \\<equiv> do\n     cap \\<leftarrow> KHeap_D.get_cap (tcb, tcb_boundntfn_slot);\n     (case cap of\n      BoundNotificationCap _ \\<Rightarrow> do_unbind_notification tcb\n    | _ \\<Rightarrow> return ())\n   od\"\n\ndefinition\n  unbind_maybe_notification :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"unbind_maybe_notification ntfn_id \\<equiv> do\n     bound_tcbs \\<leftarrow> gets $ get_bound_notification_threads ntfn_id;\n     t \\<leftarrow> option_select bound_tcbs;\n     (case t of\n       None \\<Rightarrow> return ()\n     | Some tcb \\<Rightarrow> do_unbind_notification tcb)\n  od\"\n\ndefinition\n  can_fast_finalise :: \"cdl_cap \\<Rightarrow> bool\" where\n \"can_fast_finalise cap \\<equiv> case cap of ReplyCap r R \\<Rightarrow> True\n                       | MasterReplyCap r \\<Rightarrow> True\n                       | EndpointCap r b R \\<Rightarrow> True\n                       | NotificationCap r b R \\<Rightarrow> True\n                       | NullCap \\<Rightarrow> True\n                       | RestartCap \\<Rightarrow> True\n                       | RunningCap \\<Rightarrow> True\n                       | PendingSyncSendCap r _ _ _ _ _ \\<Rightarrow> True\n                       | PendingSyncRecvCap r _ _ \\<Rightarrow> True\n                       | PendingNtfnRecvCap r \\<Rightarrow> True\n                       | DomainCap \\<Rightarrow> True\n                       | PageDirectoryCap _ x _ \\<Rightarrow> \\<not>(x = Real)\n                       | PageTableCap _ x _ \\<Rightarrow> \\<not>(x = Real)\n                       | FrameCap _ _ _ _ x _ \\<Rightarrow> \\<not>(x = Real)\n                       | _ \\<Rightarrow> False\"\n\ncontext\nnotes [[function_internals =true]]\nbegin\n\nfun\n  fast_finalise :: \"cdl_cap \\<Rightarrow> bool \\<Rightarrow> unit k_monad\"\nwhere\n  \"fast_finalise NullCap                  final = return ()\"\n| \"fast_finalise (RestartCap)             final = return ()\"\n| \"fast_finalise (RunningCap)             final = return ()\"\n| \"fast_finalise (ReplyCap r R)           final = return ()\"\n| \"fast_finalise (MasterReplyCap r)       final = return ()\"\n| \"fast_finalise (EndpointCap r b R)      final =\n      (when final $ cancel_all_ipc r)\"\n| \"fast_finalise (NotificationCap r b R) final =\n      (when final $ do\n            unbind_maybe_notification r;\n            cancel_all_ipc r\n          od)\"\n| \"fast_finalise (PendingSyncSendCap r _ _ _ _ _) final = return()\"\n| \"fast_finalise (PendingSyncRecvCap r _ _) final = return()\"\n| \"fast_finalise  (PendingNtfnRecvCap r) final = return()\"\n| \"fast_finalise DomainCap final = return ()\"\n| \"fast_finalise (PageDirectoryCap _ x _) _ = (if x = Real then fail else return())\"\n| \"fast_finalise (PageTableCap _ x _) _ = (if x = Real then fail else return())\"\n| \"fast_finalise (FrameCap _ _ _ _ x _) _ = (if x = Real then fail else return())\"\n| \"fast_finalise _ _ = fail\"\n\nend\n\n\\<comment> \\<open>These caps don't count when determining if an entity should be deleted or not\\<close>\ndefinition\n  cap_counts :: \"cdl_cap \\<Rightarrow> bool\" where\n \"cap_counts cap \\<equiv> (case cap of\n    cdl_cap.NullCap \\<Rightarrow> False\n  | UntypedCap _ _ _ \\<Rightarrow> False\n  | ReplyCap _ _ \\<Rightarrow> False\n  | MasterReplyCap _ \\<Rightarrow> False\n  | RestartCap \\<Rightarrow> False\n  | RunningCap \\<Rightarrow> False\n  | PendingSyncSendCap _ _ _ _ _ _ \\<Rightarrow> False\n  | PendingSyncRecvCap _ _ _ \\<Rightarrow> False\n  | PendingNtfnRecvCap _ \\<Rightarrow> False\n  | DomainCap \\<Rightarrow> False\n  | BoundNotificationCap _ \\<Rightarrow> False\n  | IrqControlCap  \\<Rightarrow> False\n  | AsidControlCap \\<Rightarrow> False\n  | IOSpaceMasterCap \\<Rightarrow> False\n  | FrameCap _ _ _ _ c _ \\<Rightarrow> c = Real\n  | PageTableCap _ c _ \\<Rightarrow> c = Real\n  | PageDirectoryCap _ c _ \\<Rightarrow> c = Real\n  | _ \\<Rightarrow> True)\"\n\ndefinition\n  cdl_cap_irq :: \"cdl_cap \\<Rightarrow> cdl_irq option\" where\n \"cdl_cap_irq cap \\<equiv> (case cap of IrqHandlerCap irq \\<Rightarrow> Some irq | _ \\<Rightarrow> None)\"\n\n\\<comment> \\<open>Some caps don't count when determining if an entity should be deleted or not\\<close>\ndefinition\n  is_final_cap' :: \"cdl_cap \\<Rightarrow> cdl_state \\<Rightarrow> bool\" where\n \"is_final_cap' cap s \\<equiv> ((cap_counts cap) \\<and>\n  (\\<exists>cref. {cref. \\<exists>cap'. opt_cap cref s = Some cap'\n                       \\<and> (cap_object cap = cap_object cap'\n                             \\<and> cdl_cap_irq cap = cdl_cap_irq cap')\n                       \\<and> cap_counts cap'}\n         = {cref}))\"\n\n\ndefinition\n  is_final_cap :: \"cdl_cap \\<Rightarrow> bool k_monad\" where\n  \"is_final_cap cap \\<equiv> gets (is_final_cap' cap)\"\n\n\ndefinition\n  always_empty_slot :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n \"always_empty_slot slot = do\n    remove_parent slot;\n    set_cap slot NullCap\n  od\"\n\ndefinition\n  empty_slot :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n \"empty_slot slot = do\n  cap \\<leftarrow> get_cap slot;\n  if cap = NullCap then\n    return ()\n  else do\n    remove_parent slot;\n    set_cap slot NullCap\n    od\n  od\"\n\n\ntext \\<open>\n Non-premptable delete.\n\n Should only be used on deletes guaranteed not to preempt\n (and you are happy to prove this). In particular, it is\n useful for deleting caps that exist at the CapDL level\n but not at lower levels.\n\\<close>\ndefinition\n  delete_cap_simple :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"delete_cap_simple cap_ref \\<equiv> do\n    cap \\<leftarrow> get_cap cap_ref;\n    unless (cap = NullCap) $ do\n      final \\<leftarrow> is_final_cap cap;\n      fast_finalise cap final;\n      always_empty_slot cap_ref\n    od\n  od\"\n\n\ntext \\<open>\n  Non-preemptable revoke.\n\n  Should only be used on bounded revokes.\n   * PageTableUnmap pt_cap_ref\n   * PageUnmap frame_cap_ref \\<Rightarrow>\n   * revoke_cap_simple (target_tcb, tcb_replycap_slot)\n\\<close>\nfunction\n  revoke_cap_simple :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"revoke_cap_simple victim s = (do\n    descendants \\<leftarrow> gets $ KHeap_D.descendants_of victim;\n    assert (finite descendants);\n    non_null \\<leftarrow> gets (\\<lambda>s. {slot. opt_cap slot s \\<noteq> Some NullCap \\<and> opt_cap slot s \\<noteq> None});\n    non_null_descendants \\<leftarrow> return (descendants \\<inter> non_null);\n    if (non_null_descendants \\<noteq> {}) then do\n      a \\<leftarrow> select non_null_descendants;\n      delete_cap_simple a;\n      revoke_cap_simple victim\n    od else return ()\n  od) s\"\n  by auto\n\n\ndefinition cdl_get_pde :: \"(word32 \\<times> nat)\\<Rightarrow> cdl_cap k_monad\"\nwhere \"cdl_get_pde ptr \\<equiv>\n  KHeap_D.get_cap ptr\"\n\ndefinition cdl_lookup_pd_slot :: \"word32 \\<Rightarrow> word32 \\<Rightarrow> word32 \\<times> nat \"\n  where \"cdl_lookup_pd_slot pd vptr \\<equiv> (pd, unat (vptr >> 20))\"\n\ndefinition cdl_lookup_pt_slot :: \"word32 \\<Rightarrow> word32 \\<Rightarrow> (word32 \\<times> nat) except_monad\"\n  where \"cdl_lookup_pt_slot pd vptr \\<equiv>\n    doE pd_slot \\<leftarrow> returnOk (cdl_lookup_pd_slot pd vptr);\n        pdcap \\<leftarrow> liftE $ cdl_get_pde pd_slot;\n        (case pdcap of cdl_cap.PageTableCap ref Fake None\n         \\<Rightarrow> ( doE pt \\<leftarrow> returnOk ref;\n              pt_index \\<leftarrow> returnOk ((vptr >> 12) && 0xFF);\n              returnOk (pt,unat pt_index)\n         odE)\n        | _ \\<Rightarrow> Monads_D.throw)\n    odE\"\n\ndefinition\n  cdl_find_pd_for_asid :: \"cdl_mapped_addr \\<Rightarrow> cdl_object_id except_monad\"\nwhere\n  \"cdl_find_pd_for_asid maddr \\<equiv> doE\n     asid_table \\<leftarrow> liftE $ gets cdl_asid_table;\n     asid_pool \\<leftarrow> returnOk $ asid_table (fst (fst maddr));\n     pd_cap_ref \\<leftarrow> (case asid_pool of Some (AsidPoolCap ptr _) \\<Rightarrow> returnOk (ptr, (snd \\<circ> fst) maddr)\n              | _ \\<Rightarrow> throw );\n     pd_cap \\<leftarrow> liftE $ get_cap pd_cap_ref;\n     case pd_cap of (PageDirectoryCap pd _ _) \\<Rightarrow> returnOk pd\n     | _ \\<Rightarrow> throw\n   odE \"\n\ndefinition cdl_page_mapping_entries :: \"32 word \\<Rightarrow> nat \\<Rightarrow> 32 word\n                                       \\<Rightarrow> ((32 word \\<times> nat) list) except_monad\"\n  where \"cdl_page_mapping_entries vptr pgsz pd \\<equiv>\n  if pgsz = 12 then doE\n    p \\<leftarrow> cdl_lookup_pt_slot pd vptr;\n         returnOk [p]\n    odE\n\n  else if pgsz = 16 then doE\n    p \\<leftarrow> cdl_lookup_pt_slot pd vptr;\n         returnOk [p]\n    odE\n  else if pgsz = 20 then doE\n    p \\<leftarrow> returnOk $ (cdl_lookup_pd_slot pd vptr);\n         returnOk [p]\n    odE\n  else if pgsz = 24 then doE\n    p \\<leftarrow> returnOk $ (cdl_lookup_pd_slot pd vptr);\n         returnOk [p]\n    odE\n  else throw\"\n\ndefinition\n  cdl_page_table_mapped :: \"cdl_mapped_addr \\<Rightarrow> cdl_object_id \\<Rightarrow> (cdl_cap_ref option) k_monad\"\nwhere\n  \"cdl_page_table_mapped maddr pt_id \\<equiv> doE\n     pd \\<leftarrow> cdl_find_pd_for_asid maddr;\n     pd_slot \\<leftarrow> returnOk (cdl_lookup_pd_slot pd (snd maddr));\n     pdcap \\<leftarrow> liftE $ cdl_get_pde pd_slot;\n     (case pdcap of\n       cdl_cap.PageTableCap ref Fake None \\<Rightarrow>\n         (returnOk $ if ref = pt_id then Some pd_slot else None)\n     | _ \\<Rightarrow> returnOk None )\n   odE <catch> (K (return None))\"\n\ntext \\<open>\n  Unmap a frame.\n\\<close>\n\ndefinition\n \"might_throw \\<equiv> (returnOk ()) \\<sqinter> throw\"\n\ndefinition\n  unmap_page :: \"cdl_mapped_addr  \\<Rightarrow> cdl_object_id \\<Rightarrow> nat \\<Rightarrow> unit k_monad\"\nwhere\n  \"unmap_page maddr frame_id pgsz \\<equiv>\n    doE\n      pd \\<leftarrow> cdl_find_pd_for_asid maddr;\n      pslots \\<leftarrow> cdl_page_mapping_entries (snd maddr) pgsz pd;\n      might_throw;\n      liftE $ mapM_x delete_cap_simple pslots;\n      returnOk ()\n    odE <catch> (K $ return ())\"\n\n\ntext \\<open>\n  Unmap a page table.\n\n  This hits the same problems as 'unmap_page', so we also\n  non-deterministically choose a bunch of page-tables to unmap.\n\\<close>\ndefinition\n  unmap_page_table  :: \"cdl_mapped_addr \\<Rightarrow> cdl_object_id  \\<Rightarrow> unit k_monad\"\nwhere\n  \"unmap_page_table maddr pt_id\\<equiv>\n    do\n      pt_slot \\<leftarrow> cdl_page_table_mapped maddr pt_id;\n      case pt_slot of (Some slot) \\<Rightarrow> delete_cap_simple slot\n      | None \\<Rightarrow> return ()\n    od\"\n\n\nend"}
{"title": "./spec/capDL/Types_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * CapDL Types\n *\n * This file introduces many of the high-level types used in this\n * specification.\n *)\n\ntheory Types_D\nimports\n  \"ASpec.VMRights_A\"\n  Intents_D\n  \"Lib.Lib\"\n  \"Lib.SplitRule\"\n  \"HOL-Combinatorics.Transposition\" (* for Fun.swap *)\nbegin\n\n(* A hardware IRQ number. *)\ntype_synonym cdl_irq = irq\n\n(*\n * How objects are named within the kernel.\n *\n * Objects are named by 32 bit words.\n * This name may correspond to the memory address of the object.\n *)\ntype_synonym cdl_object_id = word32\n\ntype_synonym cdl_object_set = \"(cdl_object_id set)\"\n\n(* The badge of an endpoint *)\ntype_synonym cdl_badge = word32\n\n(* The guard of a CNode cap, and the number of bits the guard uses. *)\ntype_synonym cdl_cap_guard = word32\ntype_synonym cdl_cap_guard_size = nat\n\n(* The type we use to represent object sizes. *)\ntype_synonym cdl_size_bits = nat\n\n(* A single IA32 IO port. *)\ntype_synonym cdl_io_port = nat\n\n(* The depth of a particular IA32 pagetable. *)\ntype_synonym cdl_io_pagetable_level = nat\n\n(* An index into a CNode, TCB, or other kernel object that contains caps. *)\ntype_synonym cdl_cnode_index = nat\n\n(* A reference to a capability slot. *)\ntype_synonym cdl_cap_ref = \"cdl_object_id \\<times> cdl_cnode_index\"\n\n(* A virtual ASID. *)\ntype_synonym cdl_asid = \"cdl_cnode_index \\<times> cdl_cnode_index\"\n\n(* mapped address  *)\ntype_synonym cdl_mapped_addr = \"(cdl_asid \\<times> word32)\"\n\n(* Number of bits of a badge we can use. *)\ndefinition\n  badge_bits :: nat\nwhere\n  \"badge_bits \\<equiv> 28\"\n\n(* FrameCaps, PageTableCaps and PageDirectoryCaps can either be\n * \"real\" cap or \"fake\" cap. Real caps are installed in CNodes,\n * and fake caps represent a page table mapping.\n *)\ndatatype cdl_frame_cap_type = Real | Fake\n\n(*\n * Kernel capabilities.\n *\n * Such capabilities (or \"caps\") give the holder particular rights to\n * a kernel object or system hardware.\n *\n * Caps have attributes such as the object they point to, the rights\n * they give the holder, or how the holder is allowed to interact with\n * the target object.\n *)\n\ndatatype cdl_cap =\n    NullCap\n\n  (* Kernel object capabilities *)\n  | UntypedCap bool cdl_object_set cdl_object_set\n  | EndpointCap cdl_object_id cdl_badge \"cdl_right set\"\n  | NotificationCap cdl_object_id cdl_badge \"cdl_right set\"\n  | ReplyCap cdl_object_id \"cdl_right set\" (* The id of the tcb of the target thread *)\n  | MasterReplyCap cdl_object_id\n  | CNodeCap cdl_object_id cdl_cap_guard cdl_cap_guard_size cdl_size_bits\n  | TcbCap cdl_object_id\n  | DomainCap\n\n  (*\n   * Capabilities representing threads waiting in endpoint queues.\n   *)\n  (* thread, badge, is call, can grant, can grant reply, is fault ipc *)\n  | PendingSyncSendCap cdl_object_id cdl_badge bool bool bool bool\n  (* thread, is waiting for reply, can grant *)\n  | PendingSyncRecvCap cdl_object_id bool bool\n  | PendingNtfnRecvCap cdl_object_id\n\n  (* Indicate that the thread is ready for Reschedule *)\n  | RestartCap\n  | RunningCap\n\n  (* Interrupt capabilities *)\n  | IrqControlCap\n  | IrqHandlerCap cdl_irq\n\n  (* Virtual memory capabilties *)\n  | FrameCap bool cdl_object_id \"cdl_right set\" nat cdl_frame_cap_type \"cdl_mapped_addr option\"\n  | PageTableCap cdl_object_id cdl_frame_cap_type \"cdl_mapped_addr option\"\n  | PageDirectoryCap cdl_object_id cdl_frame_cap_type \"cdl_asid option\"\n  | AsidControlCap\n  | AsidPoolCap cdl_object_id \"cdl_cnode_index\"\n\n  (* x86-specific capabilities *)\n  | IOPortsCap cdl_object_id \"cdl_io_port set\"\n  | IOSpaceMasterCap\n  | IOSpaceCap cdl_object_id\n  | IOPageTableCap cdl_object_id\n\n  (* Zombie caps (representing objects mid-deletion) *)\n  | ZombieCap cdl_object_id\n\n  (* Bound NTFN caps signifying when a tcb is bound to an NTFN *)\n  | BoundNotificationCap cdl_object_id\n\n(* A mapping from capability identifiers to capabilities. *)\n\ntype_synonym cdl_cap_map = \"cdl_cnode_index \\<Rightarrow> cdl_cap option\"\n\n(*\n * The cap derivation tree (CDT).\n *\n * This tree records how certain caps are derived from others. This\n * information is important because it affects how caps are revoked; if an\n * entity revokes a particular cap, all of the cap's children (as\n * recorded in the CDT) are also revoked.\n *\n * At this point in time, we leave the definition of the CDT quite\n * abstract. This may be made more concrete in the future allowing us to\n * reason about revocation.\n *)\ntype_synonym cdl_cdt = \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref option\"\n\ntranslations\n  (type) \"cdl_cap_map\" <=(type) \"nat \\<Rightarrow> cdl_cap option\"\n  (type) \"cdl_cap_ref\" <=(type) \"cdl_object_id \\<times> nat\"\n  (type) \"cdl_cap_ref\" <=(type) \"word32 \\<times> nat\"\n  (type) \"cdl_cdt\"     <=(type) \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref option\"\n\n\n(* Kernel objects *)\nrecord cdl_tcb =\n  cdl_tcb_caps           :: cdl_cap_map\n  cdl_tcb_fault_endpoint :: cdl_cptr\n  cdl_tcb_intent         :: cdl_full_intent\n  cdl_tcb_has_fault      :: bool\n  cdl_tcb_domain         :: word8\n\nrecord cdl_cnode =\n  cdl_cnode_caps :: cdl_cap_map\n  cdl_cnode_size_bits :: cdl_size_bits\n\nrecord cdl_asid_pool =\n  cdl_asid_pool_caps :: cdl_cap_map\n\nrecord cdl_page_table =\n  cdl_page_table_caps :: cdl_cap_map\n\nrecord cdl_page_directory =\n  cdl_page_directory_caps :: cdl_cap_map\n\nrecord cdl_frame =\n  cdl_frame_size_bits :: cdl_size_bits\n\nrecord cdl_irq_node =\n  cdl_irq_node_caps :: cdl_cap_map\n\n(*\n * Kernel objects.\n *\n * These are in-memory objects that may, over the course of the system\n * execution, be created or deleted by users.\n *)\ndatatype cdl_object =\n    Endpoint\n  | Notification\n  | Tcb cdl_tcb\n  | CNode cdl_cnode\n  | AsidPool cdl_asid_pool\n  | PageTable cdl_page_table\n  | PageDirectory cdl_page_directory\n  | Frame cdl_frame\n  | Untyped\n  | IRQNode cdl_irq_node\n\n(* The architecture that we are modelling. *)\ndatatype cdl_arch = IA32 | ARM11\n\n(* The map of objects that are in the system. *)\ntype_synonym cdl_heap = \"cdl_object_id \\<Rightarrow> cdl_object option\"\n\ntranslations\n  (type) \"cdl_heap\" <=(type) \"32 word \\<Rightarrow> cdl_object option\"\n\n(*\n * The current state of the system.\n *\n * The state record contains the following primary pieces of information:\n *\n * arch:\n *   The architecture of the system. This affects what capabilities and\n *   kernel objects could possibly be present. In the current kernel\n *   arch will not change at runtime.\n *\n * objects:\n *   The objects that currently exist in the system.\n *\n * cdt:\n *   The cap derivation tree of the system.\n *\n * current_thread:\n *   The currently running thread. Operations will always be performed\n *   on behalf of this thread.\n *\n * irq_node:\n *   Which IRQs are mapped to which notifications.\n *\n * asid_table:\n *   The first level of the asid table, containing capabilities to all\n *   of the ASIDPools.\n *\n * current_domain:\n *   The currently running domain.\n *)\nrecord cdl_state =\n  cdl_arch           :: cdl_arch\n  cdl_objects        :: cdl_heap\n  cdl_cdt            :: cdl_cdt\n  cdl_current_thread :: \"cdl_object_id option\"\n  cdl_irq_node       :: \"cdl_irq \\<Rightarrow> cdl_object_id\"\n  cdl_asid_table     :: cdl_cap_map\n  cdl_current_domain :: word8\n\n(* Return the type of an object. *)\ndefinition\n  object_type :: \"cdl_object \\<Rightarrow> cdl_object_type\"\nwhere\n  \"object_type x \\<equiv>\n    case x of\n        Untyped \\<Rightarrow> UntypedType\n      | Endpoint \\<Rightarrow> EndpointType\n      | Notification \\<Rightarrow> NotificationType\n      | Tcb _ \\<Rightarrow> TcbType\n      | CNode _ \\<Rightarrow> CNodeType\n      | IRQNode _ \\<Rightarrow> IRQNodeType\n      | AsidPool _ \\<Rightarrow> AsidPoolType\n      | PageTable _ \\<Rightarrow> PageTableType\n      | PageDirectory _ \\<Rightarrow> PageDirectoryType\n      | Frame f \\<Rightarrow> FrameType (cdl_frame_size_bits f)\"\n\nlemmas object_type_simps = object_type_def[split_simps cdl_object.split]\n\ndefinition\n  asid_high_bits :: nat where\n  \"asid_high_bits \\<equiv> 7\"\ndefinition\n  asid_low_bits :: nat where\n  \"asid_low_bits \\<equiv> 10 :: nat\"\ndefinition\n  asid_bits :: nat where\n  \"asid_bits \\<equiv> 17 :: nat\"\n\n(*\n * Each TCB contains a number of cap slots, each with a specific\n * purpose. These constants define the purpose of each slot.\n *\n * The specific list of slots is chosen to be consistent with the output\n * of the CapDL-tool.\n *)\ndefinition \"tcb_cspace_slot     = (0 :: cdl_cnode_index)\"\ndefinition \"tcb_vspace_slot     = (1 :: cdl_cnode_index)\"\ndefinition \"tcb_replycap_slot   = (2 :: cdl_cnode_index)\"\ndefinition \"tcb_caller_slot     = (3 :: cdl_cnode_index)\"\ndefinition \"tcb_ipcbuffer_slot  = (4 :: cdl_cnode_index)\"\ndefinition \"tcb_pending_op_slot = (5 :: cdl_cnode_index)\"\ndefinition \"tcb_boundntfn_slot  = (8 :: cdl_cnode_index)\"\n\ndefinition \"tcb_slots_list \\<equiv> [0..<tcb_pending_op_slot + 1] @ [tcb_boundntfn_slot]\"\nabbreviation \"tcb_slots \\<equiv> set tcb_slots_list\"\nlemmas tcb_slots_def = tcb_slots_list_def\n\nlemmas tcb_slot_defs =\n  tcb_cspace_slot_def\n  tcb_vspace_slot_def\n  tcb_replycap_slot_def\n  tcb_caller_slot_def\n  tcb_ipcbuffer_slot_def\n  tcb_pending_op_slot_def\n  tcb_boundntfn_slot_def\n  tcb_slots_list_def\n\n(*\n * Getters and setters for various data types.\n *)\n\n(* Capability getters / setters *)\n\nprimrec (nonexhaustive)\n  cap_objects :: \"cdl_cap \\<Rightarrow> cdl_object_id set\"\nwhere\n    \"cap_objects (IOPageTableCap x) = {x}\"\n  | \"cap_objects (IOSpaceCap x) = {x}\"\n  | \"cap_objects (IOPortsCap x _) = {x}\"\n  | \"cap_objects (AsidPoolCap x _) = {x}\"\n  | \"cap_objects (PageDirectoryCap x _ _) = {x}\"\n  | \"cap_objects (PageTableCap x _ _) = {x}\"\n  | \"cap_objects (FrameCap _ x _ _ _ _) = {x}\"\n  | \"cap_objects (TcbCap x) = {x}\"\n  | \"cap_objects (CNodeCap x _ _ _) = {x}\"\n  | \"cap_objects (MasterReplyCap x) = {x}\"\n  | \"cap_objects (ReplyCap x _) = {x}\"\n  | \"cap_objects (NotificationCap x _ _) = {x}\"\n  | \"cap_objects (EndpointCap x _ _) = {x}\"\n  | \"cap_objects (UntypedCap _ x a) = x\"\n  | \"cap_objects (ZombieCap x) = {x}\"\n  | \"cap_objects (PendingSyncSendCap x _ _ _ _ _) = {x}\"\n  | \"cap_objects (PendingSyncRecvCap x _ _) = {x}\"\n  | \"cap_objects (PendingNtfnRecvCap x) = {x}\"\n  | \"cap_objects (BoundNotificationCap x) = {x}\"\n\ndefinition\n  cap_has_object :: \"cdl_cap \\<Rightarrow> bool\"\nwhere\n  \"cap_has_object cap \\<equiv> case cap of\n     NullCap          \\<Rightarrow> False\n  | IrqControlCap    \\<Rightarrow> False\n  | IrqHandlerCap _  \\<Rightarrow> False\n  | AsidControlCap   \\<Rightarrow> False\n  | IOSpaceMasterCap \\<Rightarrow> False\n  | RestartCap       \\<Rightarrow> False\n  | RunningCap       \\<Rightarrow> False\n  | DomainCap        \\<Rightarrow> False\n  | _                \\<Rightarrow> True\"\n\ndefinition\n  cap_object :: \"cdl_cap \\<Rightarrow> cdl_object_id\"\nwhere\n  \"cap_object cap \\<equiv>\n     if cap_has_object cap\n     then (THE c. c \\<in> cap_objects cap)\n     else undefined\"\n\nlemma cap_object_simps[simp]:\n  \"cap_object (IOPageTableCap x) = x\"\n  \"cap_object (IOSpaceCap x) = x\"\n  \"cap_object (IOPortsCap x a) = x\"\n  \"cap_object (AsidPoolCap x b) = x\"\n  \"cap_object (PageDirectoryCap x c d) = x\"\n  \"cap_object (PageTableCap x e f) = x\"\n  \"cap_object (FrameCap dev x g h i j) = x\"\n  \"cap_object (TcbCap x) = x\"\n  \"cap_object (CNodeCap x k l sz) = x\"\n  \"cap_object (MasterReplyCap x) = x\"\n  \"cap_object (ReplyCap x q) = x\"\n  \"cap_object (NotificationCap x m n) = x\"\n  \"cap_object (EndpointCap x p q) = x\"\n  \"cap_object (ZombieCap x) = x\"\n  \"cap_object (PendingSyncSendCap x s t u v w) = x\"\n  \"cap_object (PendingSyncRecvCap x t u) = x\"\n  \"cap_object (PendingNtfnRecvCap x) = x\"\n  \"cap_object (BoundNotificationCap x) = x\"\n  by (simp_all add:cap_object_def Nitpick.The_psimp cap_has_object_def)\n\nprimrec (nonexhaustive) cap_badge :: \"cdl_cap \\<Rightarrow> cdl_badge\"\nwhere\n    \"cap_badge (NotificationCap _ x _) = x\"\n  | \"cap_badge (EndpointCap _ x _) = x\"\n\ndefinition\n  update_cap_badge :: \"cdl_badge \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"update_cap_badge x c \\<equiv> case c of\n      NotificationCap f1 _ f3 \\<Rightarrow> NotificationCap f1 x f3\n    | EndpointCap f1 _ f3      \\<Rightarrow> EndpointCap f1 x f3\n    | _ \\<Rightarrow> c\"\n\ndefinition all_cdl_rights :: \"cdl_right set\" where\n  \"all_cdl_rights = {Read, Write, Grant, GrantReply}\"\n\ndefinition\n  cap_rights :: \"cdl_cap \\<Rightarrow> cdl_right set\"\nwhere\n  \"cap_rights c \\<equiv> case c of\n      FrameCap _ _ x _ _ _ \\<Rightarrow> x\n    | NotificationCap _ _ x \\<Rightarrow> x\n    | EndpointCap _ _ x \\<Rightarrow> x\n    | ReplyCap _ x \\<Rightarrow> x\n    | _ \\<Rightarrow> all_cdl_rights\"\n\ndefinition\n  update_cap_rights :: \"cdl_right set \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"update_cap_rights r c \\<equiv> case c of\n      FrameCap dev f1 _ f2 f3 f4 \\<Rightarrow> FrameCap dev f1 (validate_vm_rights r) f2 f3 f4\n    | NotificationCap f1 f2 _ \\<Rightarrow> NotificationCap f1 f2 (r - {Grant, GrantReply})\n    | EndpointCap f1 f2 _ \\<Rightarrow> EndpointCap f1 f2 r\n    | ReplyCap f1 _ \\<Rightarrow> ReplyCap f1 (r - {Read, GrantReply} \\<union> {Write})\n    | _ \\<Rightarrow> c\"\n\ndefinition\n  update_mapping_cap_status :: \"cdl_frame_cap_type \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n \"update_mapping_cap_status r c \\<equiv> case c of\n      FrameCap dev f1 f2 f3 _ f4 \\<Rightarrow> FrameCap dev f1 f2 f3 r f4\n    | PageTableCap pt1 _ pt2 \\<Rightarrow> PageTableCap pt1 r pt2\n    | _ \\<Rightarrow> c\"\n\nprimrec (nonexhaustive) cap_guard :: \"cdl_cap \\<Rightarrow> cdl_cap_guard\"\nwhere\n  \"cap_guard (CNodeCap _ x _ _) = x\"\n\ndefinition\n  update_cap_guard :: \"cdl_cap_guard \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"update_cap_guard x c \\<equiv> case c of\n      CNodeCap f1 _ f3 f4 \\<Rightarrow> CNodeCap f1 x f3 f4\n    | _ \\<Rightarrow> c\"\n\nprimrec (nonexhaustive) cap_guard_size :: \"cdl_cap \\<Rightarrow> cdl_cap_guard_size\"\nwhere\n  \"cap_guard_size (CNodeCap _ _ x _ ) = x\"\n\ndefinition\n  cnode_cap_size :: \"cdl_cap \\<Rightarrow> cdl_size_bits\"\nwhere\n  \"cnode_cap_size cap \\<equiv> case cap of\n      CNodeCap _ _ _ x \\<Rightarrow> x\n    | _ \\<Rightarrow> 0\"\n\ndefinition\n  update_cap_guard_size :: \"cdl_cap_guard_size \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"update_cap_guard_size x c \\<equiv> case c of\n      CNodeCap f1 f2 _ f3 \\<Rightarrow> CNodeCap f1 f2 x f3\n    | _ \\<Rightarrow> c\"\n\n(* Kernel object getters / setters *)\ndefinition\n  object_slots :: \"cdl_object \\<Rightarrow> cdl_cap_map\"\nwhere\n  \"object_slots obj \\<equiv> case obj of\n    PageDirectory x \\<Rightarrow> cdl_page_directory_caps x\n  | PageTable x \\<Rightarrow> cdl_page_table_caps x\n  | AsidPool x \\<Rightarrow> cdl_asid_pool_caps x\n  | CNode x \\<Rightarrow> cdl_cnode_caps x\n  | Tcb x \\<Rightarrow> cdl_tcb_caps x\n  | IRQNode x \\<Rightarrow> cdl_irq_node_caps x\n  | _ \\<Rightarrow> Map.empty\"\n\ndefinition\n  update_slots :: \"cdl_cap_map \\<Rightarrow> cdl_object \\<Rightarrow> cdl_object\"\nwhere\n  \"update_slots new_val obj \\<equiv> case obj of\n    PageDirectory x \\<Rightarrow> PageDirectory (x\\<lparr>cdl_page_directory_caps := new_val\\<rparr>)\n  | PageTable x \\<Rightarrow> PageTable (x\\<lparr>cdl_page_table_caps := new_val\\<rparr>)\n  | AsidPool x \\<Rightarrow> AsidPool (x\\<lparr>cdl_asid_pool_caps := new_val\\<rparr>)\n  | CNode x \\<Rightarrow> CNode (x\\<lparr>cdl_cnode_caps := new_val\\<rparr>)\n  | Tcb x \\<Rightarrow> Tcb (x\\<lparr>cdl_tcb_caps := new_val\\<rparr>)\n  | IRQNode x \\<Rightarrow> IRQNode (x\\<lparr>cdl_irq_node_caps := new_val\\<rparr>)\n  | _ \\<Rightarrow> obj\"\n\ndefinition\n  has_slots :: \"cdl_object \\<Rightarrow> bool\"\nwhere\n  \"has_slots obj \\<equiv> case obj of\n    PageDirectory _ \\<Rightarrow> True\n  | PageTable _ \\<Rightarrow> True\n  | AsidPool _ \\<Rightarrow> True\n  | CNode _ \\<Rightarrow> True\n  | Tcb _ \\<Rightarrow> True\n  | IRQNode _ \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"\n\n\ndefinition\n  cap_free_ids :: \"cdl_cap \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"cap_free_ids cap \\<equiv> (case cap of\n     UntypedCap _ _ free_ids \\<Rightarrow> free_ids\n   | _ \\<Rightarrow> {})\"\n\ndefinition\n  remove_free_ids :: \"cdl_cap \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_cap\"\nwhere\n  \"remove_free_ids cap obj_ids \\<equiv> case cap of\n     UntypedCap dev c a \\<Rightarrow> UntypedCap dev c (a - obj_ids)\n   | _ \\<Rightarrow> cap\"\n\ndefinition cap_irq :: \"cdl_cap \\<Rightarrow> cdl_irq\"\nwhere\n  \"cap_irq cap \\<equiv> case cap of\n      IrqHandlerCap x \\<Rightarrow> x\n    | _ \\<Rightarrow> undefined\"\n\n(*************\n * Cap types *\n *************)\n\n\n\n\ndefinition cap_type :: \"cdl_cap \\<Rightarrow> cdl_object_type option\"\nwhere\n  \"cap_type x \\<equiv> case x of\n    UntypedCap _ _ _         \\<Rightarrow> Some UntypedType\n  | EndpointCap _ _ _      \\<Rightarrow> Some EndpointType\n  | NotificationCap _ _ _ \\<Rightarrow> Some NotificationType\n  | TcbCap _               \\<Rightarrow> Some TcbType\n  | CNodeCap _ _ _ _       \\<Rightarrow> Some CNodeType\n  | AsidPoolCap _ _        \\<Rightarrow> Some AsidPoolType\n  | PageTableCap _ _ _     \\<Rightarrow> Some PageTableType\n  | PageDirectoryCap _ _ _ \\<Rightarrow> Some PageDirectoryType\n  | FrameCap _ _ _ f _ _     \\<Rightarrow> Some (FrameType f)\n  | IrqHandlerCap _        \\<Rightarrow> Some IRQNodeType\n  | _                      \\<Rightarrow> None \"\n\nabbreviation \"is_untyped_cap cap    \\<equiv> (cap_type cap = Some UntypedType)\"\nabbreviation \"is_ep_cap cap         \\<equiv> (cap_type cap = Some EndpointType)\"\nabbreviation \"is_ntfn_cap cap        \\<equiv> (cap_type cap = Some NotificationType)\"\nabbreviation \"is_tcb_cap cap        \\<equiv> (cap_type cap = Some TcbType)\"\nabbreviation \"is_cnode_cap cap      \\<equiv> (cap_type cap = Some CNodeType)\"\nabbreviation \"is_asidpool_cap cap   \\<equiv> (cap_type cap = Some AsidPoolType)\"\nabbreviation \"is_pt_cap cap         \\<equiv> (cap_type cap = Some PageTableType)\"\nabbreviation \"is_pd_cap cap         \\<equiv> (cap_type cap = Some PageDirectoryType)\"\nabbreviation \"is_frame_cap cap      \\<equiv> (\\<exists>sz. cap_type cap = Some (FrameType sz))\"\nabbreviation \"is_irqhandler_cap cap \\<equiv> (cap_type cap = Some IRQNodeType)\"\ndefinition   \"is_irqcontrol_cap cap \\<equiv> (cap = IrqControlCap)\"\n\nlemma cap_type_simps [simp]:\n  \"is_untyped_cap    (UntypedCap dev a a')\"\n  \"is_ep_cap         (EndpointCap b c d)\"\n  \"is_ntfn_cap        (NotificationCap e f g)\"\n  \"is_tcb_cap        (TcbCap h)\"\n  \"is_cnode_cap      (CNodeCap j k l m)\"\n  \"is_asidpool_cap   (AsidPoolCap n p)\"\n  \"is_pd_cap         (PageDirectoryCap r s t)\"\n  \"is_pt_cap         (PageTableCap u v w)\"\n  \"is_frame_cap      (FrameCap dev a1 a2 a3 a4 a5)\"\n  \"is_irqhandler_cap (IrqHandlerCap a6)\"\n  \"cap_type (FrameCap dev obj_id rights sz rs asid) = Some (FrameType sz)\"\n  by (clarsimp simp: cap_type_def)+\n\nabbreviation \"cap_has_type cap \\<equiv> (\\<exists>type. cap_type cap = Some type)\"\n\nlemma cap_type_update_cap_badge [simp]:\n  \"cap_type (update_cap_badge x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_badge_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_cap_rights [simp]:\n  \"cap_type (update_cap_rights x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_rights_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_mapping_cap_status [simp]:\n  \"cap_type (update_mapping_cap_status x cap) = cap_type cap\"\n  by (clarsimp simp: update_mapping_cap_status_def cap_type_def split: cdl_cap.splits)\n\nlemma cap_type_update_cap_guard [simp]:\n  \"cap_type (update_cap_guard x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_guard_def cap_type_def split: cdl_cap.splits)\n\nlemma update_cap_guard_size [simp]:\n  \"cap_type (update_cap_guard_size x cap) = cap_type cap\"\n  by (clarsimp simp: update_cap_guard_size_def cap_type_def split: cdl_cap.splits)\n\n\n\ndefinition is_pending_cap :: \"cdl_cap \\<Rightarrow> bool\"\nwhere \"is_pending_cap c \\<equiv> case c of\n  PendingSyncRecvCap _ _ _ \\<Rightarrow> True\n  | PendingNtfnRecvCap _ \\<Rightarrow> True\n  | PendingSyncSendCap _ _ _ _ _ _ \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"\n\n\n(*\n * Object constructors.\n *)\n\n(* Create a capability map that contains no caps. *)\ndefinition\n  empty_cap_map :: \"nat \\<Rightarrow> cdl_cap_map\"\nwhere\n  \"empty_cap_map sz \\<equiv> (\\<lambda>a. if a < 2^sz then (Some NullCap) else None)\"\n\n(* Create an empty CNode. *)\ndefinition\n  empty_cnode :: \"nat \\<Rightarrow> cdl_cnode\"\nwhere\n  \"empty_cnode sz = \\<lparr> cdl_cnode_caps = empty_cap_map sz, cdl_cnode_size_bits = sz \\<rparr>\"\n\ndefinition\n  empty_irq_node :: cdl_irq_node\nwhere\n  \"empty_irq_node \\<equiv> \\<lparr> cdl_irq_node_caps = empty_cap_map 0 \\<rparr>\"\n\n(* Standard empty TCB object. *)\ndefinition\n  default_tcb :: \"word8 \\<Rightarrow> cdl_tcb\"\nwhere\n  \"default_tcb current_domain = \\<lparr>\n    cdl_tcb_caps = \\<lambda>n. if n \\<in> tcb_slots then Some NullCap else None,\n    cdl_tcb_fault_endpoint = 0,\n    cdl_tcb_intent = \\<lparr>\n      cdl_intent_op = None,\n      cdl_intent_error = False,\n      cdl_intent_cap = 0,\n      cdl_intent_extras = [],\n      cdl_intent_recv_slot = None\n      \\<rparr>,\n    cdl_tcb_has_fault = False,\n    cdl_tcb_domain = current_domain\n    \\<rparr>\"\n\n(* Return a newly constructed object of the given type. *)\ndefinition\n  default_object :: \"cdl_object_type \\<Rightarrow> nat \\<Rightarrow> word8 \\<Rightarrow> cdl_object option\"\nwhere\n  \"default_object x y current_domain \\<equiv>\n    case x of\n        UntypedType \\<Rightarrow> Some Untyped\n      | EndpointType \\<Rightarrow> Some Endpoint\n      | NotificationType \\<Rightarrow> Some Notification\n      | TcbType \\<Rightarrow> Some (Tcb (default_tcb current_domain))\n      | CNodeType \\<Rightarrow> Some (CNode (empty_cnode y))\n      | AsidPoolType \\<Rightarrow> Some (AsidPool \\<lparr> cdl_asid_pool_caps = empty_cap_map asid_low_bits \\<rparr>)\n      | PageTableType \\<Rightarrow> Some (PageTable \\<lparr> cdl_page_table_caps = empty_cap_map 8 \\<rparr>)\n      | PageDirectoryType \\<Rightarrow> Some (PageDirectory \\<lparr> cdl_page_directory_caps = empty_cap_map 12 \\<rparr>)\n      | FrameType sz \\<Rightarrow> Some (Frame \\<lparr> cdl_frame_size_bits = sz \\<rparr>)\n      | IRQNodeType \\<Rightarrow> Some (IRQNode empty_irq_node)\"\n\nabbreviation \"pick a \\<equiv> SOME x. x\\<in> a\"\n\n(* Construct a cap for a new object. *)\ndefinition\n  default_cap :: \"cdl_object_type \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_size_bits \\<Rightarrow> bool \\<Rightarrow> cdl_cap\"\nwhere\n  \"default_cap t id_set sz dev \\<equiv>\n    case t of\n        EndpointType \\<Rightarrow> EndpointCap (pick id_set) 0 UNIV\n      | NotificationType \\<Rightarrow> NotificationCap (THE i. i \\<in> id_set) 0 {Read,Write}\n      | TcbType \\<Rightarrow> TcbCap (pick id_set)\n      | CNodeType \\<Rightarrow> CNodeCap (pick id_set) 0 0 sz\n      | IRQNodeType \\<Rightarrow> IrqHandlerCap undefined\n      | UntypedType \\<Rightarrow> UntypedCap dev id_set id_set\n      | AsidPoolType \\<Rightarrow> AsidPoolCap (pick id_set) 0\n      | PageTableType \\<Rightarrow> PageTableCap (pick id_set) Real None\n      | PageDirectoryType \\<Rightarrow> PageDirectoryCap (pick id_set) Real None\n      | FrameType frame_size \\<Rightarrow> FrameCap dev (pick id_set) {Read, Write} frame_size Real None\"\n\nend"}
{"title": "./spec/capDL/Schedule_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Schedule_D\nimports KHeap_D\nbegin\n\n(*\n * Collect the set of runnable threads in the system.\n *)\ndefinition\n  all_active_tcbs :: \"cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"all_active_tcbs state \\<equiv> {x \\<in> dom (cdl_objects state).\n      \\<exists> a. (cdl_objects state) x = Some (Tcb a)\n          \\<and> ( ((cdl_tcb_caps a) tcb_pending_op_slot) = (Some RunningCap) \\<or> ((cdl_tcb_caps a) tcb_pending_op_slot) = (Some RestartCap))}\"\n\ndefinition\n  active_tcbs_in_domain :: \"word8 \\<Rightarrow> cdl_state \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"active_tcbs_in_domain domain state  = {x \\<in> dom (cdl_objects state).\n      \\<exists> a. (cdl_objects state) x = Some (Tcb a)\n          \\<and> ( ((cdl_tcb_caps a) tcb_pending_op_slot) = (Some RunningCap) \\<or> ((cdl_tcb_caps a) tcb_pending_op_slot) = (Some RestartCap))\n          \\<and> cdl_tcb_domain a = domain }\"\n\n(*\n * Switch to a new thread.\n *)\ndefinition\n  switch_to_thread :: \"cdl_object_id option \\<Rightarrow> unit k_monad\"\nwhere\n  \"switch_to_thread target \\<equiv>\n     modify (\\<lambda> t. t\\<lparr> cdl_current_thread := target \\<rparr>)\"\n\ndefinition\n  change_current_domain :: \"unit k_monad\"\nwhere\n  \"change_current_domain = do\n     next_domain \\<leftarrow> select UNIV;\n     modify      (\\<lambda>s. s\\<lparr> cdl_current_domain := next_domain \\<rparr>)\n   od\"\n(*\n * Scheduling is fully nondeterministic at this level.\n *)\ndefinition\n  schedule :: \"unit k_monad\"\nwhere\n  \"schedule \\<equiv> do\n     change_current_domain;\n     next_domain \\<leftarrow> gets cdl_current_domain;\n     threads     \\<leftarrow> gets (active_tcbs_in_domain next_domain);\n     next_thread \\<leftarrow> select threads;\n     switch_to_thread (Some next_thread)\n   od \\<sqinter> do\n     change_current_domain;\n     switch_to_thread None\n   od\"\n\n\nend"}
{"title": "./spec/capDL/CSpace_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Operations on CSpace\n *)\n\ntheory CSpace_D\nimports\n  PageTableUnmap_D\nbegin\n\n(* Does the given cap have any children? *)\ndefinition\n  has_children :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> bool\"\nwhere\n  \"has_children parent s = (\\<exists>child. is_cdt_parent s parent child)\"\n\n(*\n * Ensure that the given cap does not contain any children\n * in the CDT.\n *)\ndefinition\n  ensure_no_children :: \"cdl_cap_ref \\<Rightarrow> unit except_monad\"\nwhere\n  \"ensure_no_children x \\<equiv> doE\n     c \\<leftarrow> liftE $ gets (has_children x);\n     whenE c $ throw\n   odE\"\n\n(* Ensure that the given cap slot is empty. *)\ndefinition\n  ensure_empty :: \"cdl_cap_ref \\<Rightarrow> unit except_monad\"\nwhere\n  \"ensure_empty cap_ref \\<equiv> doE\n     cap \\<leftarrow> liftE $ get_cap cap_ref;\n     unlessE (cap = NullCap) $ throw\n  odE\"\n\n(* Insert a new cap into an object. The cap will have no parent. *)\ndefinition\n  insert_cap_orphan :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"insert_cap_orphan new_cap dest_slot \\<equiv> do\n     old_cap \\<leftarrow> get_cap dest_slot;\n     assert (old_cap = NullCap);\n     set_cap dest_slot new_cap\n   od\"\n\n\n\nprimrec (nonexhaustive)\n  available_range :: \"cdl_cap \\<Rightarrow> cdl_object_id set\"\nwhere\n  \"available_range (UntypedCap _ r available) = available\"\n\ndefinition\n  set_available_range :: \"cdl_cap \\<Rightarrow> cdl_object_id set \\<Rightarrow> cdl_cap\"\nwhere\n  \"set_available_range cap nrange \\<equiv>\n    case cap of UntypedCap d r available \\<Rightarrow> UntypedCap d r nrange | _ \\<Rightarrow> cap\"\n\nlemmas set_avaiable_range_simps[simp] = set_available_range_def[split_simps cdl_cap.split]\n\ndefinition\n  set_untyped_cap_as_full :: \"cdl_cap \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_untyped_cap_as_full src_cap new_cap src_slot \\<equiv>\n  if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n     \\<and> cap_objects src_cap = cap_objects new_cap) then\n     (set_cap src_slot (set_available_range src_cap {}))\n     else return ()\"\n\n(* Insert a new cap into an object. The cap will be a sibling. *)\ndefinition\n  insert_cap_sibling :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"insert_cap_sibling new_cap src_slot dest_slot \\<equiv> do\n    src_cap \\<leftarrow> get_cap src_slot;\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_untyped_cap_as_full src_cap new_cap src_slot;\n    set_cap dest_slot new_cap;\n    p \\<leftarrow> gets $ opt_parent src_slot;\n    case p of\n      None \\<Rightarrow> return ()\n    | Some parent \\<Rightarrow> set_parent dest_slot parent\n  od\"\n\n(* Insert a new cap into an object. The cap will be a child. *)\ndefinition\n  insert_cap_child :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"insert_cap_child new_cap src_slot dest_slot \\<equiv> do\n    src_cap \\<leftarrow> get_cap src_slot;\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_untyped_cap_as_full src_cap new_cap src_slot;\n    set_cap dest_slot new_cap;\n    set_parent dest_slot src_slot\n  od\"\n\n(*\n * Delete an ASID pool.\n *)\ndefinition\n  delete_asid_pool :: \"cdl_cnode_index \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"delete_asid_pool base ptr \\<equiv> do\n    asid_table \\<leftarrow> gets cdl_asid_table;\n    asid_table' \\<leftarrow> return $ asid_table (base \\<mapsto> NullCap);\n    modify (\\<lambda>s. s \\<lparr>cdl_asid_table := asid_table'\\<rparr>)\n  od \\<sqinter> return ()\"\n\n(*\n * Delete a particular ASID, decactivating the PD using it\n * in the process.\n *)\ndefinition\n  delete_asid :: \"cdl_asid \\<Rightarrow> cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"delete_asid asid pd \\<equiv> do\n    asid_table \\<leftarrow> gets cdl_asid_table;\n    case asid_table (fst asid) of\n       Some NullCap \\<Rightarrow> return ()\n     | Some (AsidPoolCap p _) \\<Rightarrow> set_cap (p, (snd asid)) NullCap\n     | _ \\<Rightarrow> fail\n  od \\<sqinter> return ()\"\n\ndefinition\n  get_irq_slot :: \"cdl_irq \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref\"\nwhere\n  \"get_irq_slot irq s \\<equiv> (cdl_irq_node s irq, 0)\"\n\ntext \\<open>Actions to be taken after deleting an IRQ Handler capability.\\<close>\ndefinition\n  deleting_irq_handler :: \"cdl_irq \\<Rightarrow> unit k_monad\"\nwhere\n \"deleting_irq_handler irq \\<equiv>\n    gets (get_irq_slot irq) >>= delete_cap_simple\"\n\ndefinition\n  cancel_ipc ::\"cdl_object_id \\<Rightarrow> unit k_monad\"\n  where \"cancel_ipc ptr \\<equiv>\n  do cap \\<leftarrow> KHeap_D.get_cap (ptr,tcb_pending_op_slot);\n   (case cap of\n    PendingSyncRecvCap _ is_reply _ \\<Rightarrow> ( do\n     when is_reply $ update_thread_fault ptr (\\<lambda>x. False);\n     revoke_cap_simple (ptr,tcb_replycap_slot);\n     when (\\<not> is_reply) $ set_cap (ptr,tcb_pending_op_slot) NullCap\n     od )\n   | PendingSyncSendCap _ _ _ _ _ _ \\<Rightarrow> (do\n     revoke_cap_simple (ptr,tcb_replycap_slot);\n     set_cap (ptr,tcb_pending_op_slot) NullCap\n     od)\n   | PendingNtfnRecvCap _ \\<Rightarrow> (do\n     revoke_cap_simple (ptr,tcb_replycap_slot);\n     set_cap (ptr, tcb_pending_op_slot) NullCap\n     od)\n   | _ \\<Rightarrow> return ())\n  od\"\n\ndefinition\n  prepare_thread_delete ::\"cdl_object_id \\<Rightarrow> unit k_monad\"\n  where \"prepare_thread_delete ptr \\<equiv> return ()\" (* for ARM it does nothing *)\n\ntext \\<open>Actions that must be taken when a capability is deleted. Returns a\nZombie capability if deletion requires a long-running operation and also a\npossible IRQ to be cleared.\\<close>\nfun\n  finalise_cap :: \"cdl_cap \\<Rightarrow> bool \\<Rightarrow> (cdl_cap \\<times> cdl_cap) k_monad\"\nwhere\n  \"finalise_cap NullCap                  final = return (NullCap, NullCap)\"\n| \"finalise_cap RestartCap               final = return (NullCap, NullCap)\"\n| \"finalise_cap (UntypedCap dev r a)           final = return (NullCap, NullCap)\"\n| \"finalise_cap (EndpointCap r b R)      final =\n      (liftM (K (NullCap, NullCap)) $ when  final $ cancel_all_ipc r)\"\n| \"finalise_cap (NotificationCap r b R) final =\n      (liftM (K (NullCap, NullCap)) $ when  final $\n       do\n         unbind_maybe_notification r;\n         cancel_all_ipc r\n       od)\"\n| \"finalise_cap (ReplyCap r R)           final = return (NullCap, NullCap)\"\n| \"finalise_cap (MasterReplyCap r)       final = return (NullCap, NullCap)\"\n| \"finalise_cap (CNodeCap r bits g sz)   final =\n      (return (if final then ZombieCap r else NullCap, NullCap))\"\n| \"finalise_cap (TcbCap r)               final =\n      (do\n         when final $ (do unbind_notification r;\n         cancel_ipc r;\n         KHeap_D.set_cap (r, tcb_pending_op_slot) cdl_cap.NullCap;\n         prepare_thread_delete r od);\n         return (if final then (ZombieCap r) else NullCap, NullCap)\n       od)\"\n| \"finalise_cap (PendingSyncSendCap r _ _ _ _ _) final = return (NullCap, NullCap)\"\n| \"finalise_cap (PendingSyncRecvCap r _ _) final = return (NullCap, NullCap)\"\n| \"finalise_cap (PendingNtfnRecvCap r)  final = return (NullCap, NullCap)\"\n| \"finalise_cap IrqControlCap            final = return (NullCap, NullCap)\"\n| \"finalise_cap (IrqHandlerCap irq)      final = (\n       if final then do\n         deleting_irq_handler irq;\n         return (NullCap, (IrqHandlerCap irq))\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (ZombieCap r)            final =\n      (do assert final; return (ZombieCap r, NullCap) od)\"\n| \"finalise_cap (AsidPoolCap ptr asid)        final = (\n       if final then do\n         delete_asid_pool asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap AsidControlCap           final = return (NullCap,NullCap)\"\n| \"finalise_cap (PageDirectoryCap ptr x (Some asid))   final = (\n       if final \\<and> x = Real then do\n         delete_asid asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (PageTableCap ptr x (Some asid))     final = (\n       if (final \\<and> x = Real) then do\n         unmap_page_table asid ptr;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (FrameCap dev ptr _ s x (Some asid))       final = (\n       if x = Real then do\n         unmap_page asid ptr s;\n         return (NullCap, NullCap)\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap _ final = return (NullCap, NullCap)\"\n\n\ntext \\<open>The fast_finalise operation is used to delete a capability when it is\nknown that a long-running operation is impossible. It is equivalent to calling\nthe regular finalise operation. It cannot be defined in that way as doing so\nwould create a circular definition.\\<close>\nlemma fast_finalise_def2:\n  \"fast_finalise cap final = do\n     assert (can_fast_finalise cap);\n     result \\<leftarrow> finalise_cap cap final;\n     assert (result = (NullCap, NullCap))\n   od\"\n  unfolding can_fast_finalise_def\n  by (rule finalise_cap.cases[of \"(cap,final)\"]; simp add: assert_def liftM_def)\n\n(*\n * Atomically swap the two given caps.\n *)\n\ndefinition\n  swap_cap :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"swap_cap cap1 slot1 cap2 slot2 \\<equiv> do\n     set_cap slot1 cap2;\n     set_cap slot2 cap1;\n     swap_parents slot1 slot2\n  od\"\n\n(*\n * Move the given cap from one location to another,\n * possibly modifying it along the way.\n *)\ndefinition\n  move_cap :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n  \"move_cap cap src_slot dest_slot \\<equiv> do\n     insert_cap_orphan cap dest_slot;\n     set_cap src_slot NullCap;\n     swap_parents src_slot dest_slot\n  od\"\n\ndefinition\n  monadic_rel_optionation_form :: \"('a \\<Rightarrow> ('s, 'b) nondet_monad)\n      \\<Rightarrow> (('a \\<times> 's) option \\<times> ('b \\<times> 's) option) set\"\nwhere\n \"monadic_rel_optionation_form f =\n    {(x, y). (x \\<noteq> None \\<and> y \\<noteq> None \\<and> the y \\<in> fst (case_prod f (the x)))\n           \\<or> (x \\<noteq> None \\<and> y = None \\<and> snd (case_prod f (the x)))\n           \\<or> (x = None \\<and> y = None)}\"\n\ndefinition\n  monadic_option_dest :: \"('a \\<times> 's) option set \\<Rightarrow> (('a \\<times> 's) set \\<times> bool)\"\nwhere\n \"monadic_option_dest S = (Some -` S, None \\<in> S)\"\n\nlemma use_option_form:\n  \"f x = (\\<lambda>s. monadic_option_dest  (monadic_rel_optionation_form f `` {Some (x, s)}))\"\n  by (simp add: monadic_rel_optionation_form_def monadic_option_dest_def)\n\nlemma ex_option: \" (\\<exists>x. P x) = ((\\<exists>y. P (Some y)) \\<or> P None)\"\n  apply safe\n  apply (case_tac x, auto)\n  done\n\nlemma use_option_form_bind:\n  \"f x >>= g = (\\<lambda>s. monadic_option_dest\n       ((monadic_rel_optionation_form f O monadic_rel_optionation_form g) `` {Some (x, s)}))\"\n  apply (rule ext)\n  apply (simp add: monadic_rel_optionation_form_def monadic_option_dest_def\n                   bind_def split_def)\n  apply (simp add: relcomp_unfold ex_option image_def prod_eq_iff Bex_def)\n  apply fastforce\n  done\n\ndefinition\n  monadic_trancl :: \"('a \\<Rightarrow> ('s, 'a) nondet_monad)\n       \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad\"\nwhere\n \"monadic_trancl f x = (\\<lambda>s. monadic_option_dest ((monadic_rel_optionation_form f)\\<^sup>* `` {Some (x, s)}))\"\n\ndefinition\n  monadic_trancl_preemptible ::\n     \"('a \\<Rightarrow> ('s, 'e + 'a) nondet_monad)\n         \\<Rightarrow> ('a \\<Rightarrow> ('s, 'e + 'a) nondet_monad)\"\nwhere\n \"monadic_trancl_preemptible f x\n    = monadic_trancl (lift f) (Inr x)\"\n\ndefinition\n  cap_removeable :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> bool\"\nwhere\n \"cap_removeable cap slot s =\n   (cap = NullCap\n      \\<or> (\\<exists>p. cap = ZombieCap p \\<and> swp opt_cap s ` (({p} \\<times> UNIV) - {slot})\n              \\<subseteq> {Some NullCap, None}))\"\n\ndefinition\n  finalise_slot_inner1 :: \"cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> bool) k_monad\"\nwhere\n \"finalise_slot_inner1 victim = do\n    cap \\<leftarrow> get_cap victim;\n    final \\<leftarrow> is_final_cap cap;\n    (cap', irqopt) \\<leftarrow> finalise_cap cap final;\n    removeable \\<leftarrow> gets $ cap_removeable cap' victim;\n    when (\\<not> removeable) (set_cap victim cap')\n        \\<sqinter> set_cap victim cap';\n    return (cap', removeable)\n  od\"\n\ndefinition\n  get_zombie_range :: \"cdl_cap \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\"\nwhere\n \"get_zombie_range cap =\n    (\\<lambda>s. case cap of ZombieCap p \\<Rightarrow> dom (swp opt_cap s) \\<inter> ({p} \\<times> UNIV)\n               | _ \\<Rightarrow> {})\"\n\ndefinition\n  swap_for_delete :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\"\nwhere\n \"swap_for_delete ptr1 ptr2 = do\n    cap1 \\<leftarrow> get_cap ptr1;\n    cap2 \\<leftarrow> get_cap ptr2;\n    swap_cap cap1 ptr1 cap2 ptr2\n  od\"\n\ndefinition\n \"finalise_slot_inner2 =\n      (\\<lambda>(region, finalised).\n        liftE (do (victim', remove) \\<leftarrow> select region;\n          (cap', removeable) \\<leftarrow> finalise_slot_inner1 victim';\n          region' \\<leftarrow> gets $ get_zombie_range cap';\n          return (region \\<union> (region' \\<times> {True}), if removeable then {(victim', remove)} else {})\n        od) \\<sqinter>\n        liftE (do (slot, slot') \\<leftarrow> select {(x, y). (x, True) \\<in> region \\<and> (y, True) \\<in> region \\<and> x \\<noteq> y};\n          swap_for_delete slot slot';\n          return (region, {})\n        od) \\<sqinter>\n        liftE (do victim' \\<leftarrow> select {x. (x, True) \\<in> finalised};\n          empty_slot victim';\n          return (region, {})\n        od) \\<sqinter>\n        throw\n      )\"\n\ndefinition\n  finalise_slot :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n \"finalise_slot victim = doE\n    (region, finalised) \\<leftarrow>\n      monadic_trancl_preemptible finalise_slot_inner2\n        ({(victim, False)}, {});\n    whenE (victim \\<notin> fst ` finalised) throw\n  odE\"\n\ndefinition\n  delete_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n \"delete_cap victim = doE\n    finalise_slot victim;\n    liftE $ empty_slot victim\n  odE\"\n\n\n(*\n * Revoke all the descendants of the given cap.\n *\n * If the CDT is being modelled, this will delete all the\n * descendants of the given cap. Wonderful things happen\n * if we happen to, in this process, delete something\n * that contains the cap we are trying to revoke.\n *)\ndefinition\n  revoke_cap :: \"cdl_cap_ref \\<Rightarrow> unit preempt_monad\"\nwhere\n  \"revoke_cap victim = doE\n     fin \\<leftarrow> monadic_trancl_preemptible (K (doE\n          S \\<leftarrow> liftE $ gets $ descendants_of victim;\n          if S = {} then returnOk True\n          else doE\n            child \\<leftarrow> liftE $ select S;\n            cap \\<leftarrow> liftE $ get_cap child;\n            assertE (cap \\<noteq> NullCap);\n            delete_cap child;\n            Monads_D.throw \\<sqinter> returnOk False\n          odE\n       odE)) False;\n     unlessE fin throw\n   odE\"\n\n(*\n * Get the badge the given thread object is using to\n * perform its IPC send operation.\n *)\ndefinition\n  get_tcb_ep_badge :: \"cdl_tcb \\<Rightarrow> cdl_badge option\"\nwhere\n  \"get_tcb_ep_badge t \\<equiv>\n    case (cdl_tcb_caps t tcb_pending_op_slot) of\n      Some (PendingSyncSendCap _ badge _ _ _ _) \\<Rightarrow> Some badge\n    | _ \\<Rightarrow> None\"\n\n(*\n * Cancel all pending send operations to the given endpoint\n * that are using the given badge.\n *)\ndefinition\n  cancel_badged_sends :: \"cdl_object_id \\<Rightarrow> cdl_badge \\<Rightarrow> unit k_monad\"\nwhere\n  \"cancel_badged_sends ep badge \\<equiv>\n    modify (\\<lambda>s. s\\<lparr>cdl_objects := map_option\n        (\\<lambda>obj. case obj of\n            Tcb t \\<Rightarrow>\n              if (is_thread_blocked_on_endpoint t ep\n                  \\<and> get_tcb_ep_badge t = Some badge) then\n                    Tcb (remove_pending_operation t cdl_cap.RestartCap)\n              else\n                Tcb t\n          | _ \\<Rightarrow> obj) \\<circ> (cdl_objects s)\\<rparr>)\"\n\n\n(*\n * Regenerate the target object.\n *\n * Any children of the cap are first revoked. The object\n * is then reset into its original (as-if just created)\n * state. But maybe not. It's complex.\n *\n * In the C implementation, attempting to recycle a\n * non-master cap may do something that is not\n * a recycle. (Should be perhaps return an error?)\n *)\ndefinition\n  clear_object_caps :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n \"clear_object_caps ptr = do\n    ptrs \\<leftarrow> gets (\\<lambda>s. {cptr. fst cptr = ptr \\<and> opt_cap cptr s \\<noteq> None});\n    ptrlist \\<leftarrow> select {xs. set xs = ptrs \\<and> distinct xs};\n    mapM_x empty_slot ptrlist\n  od\"\n\ndefinition cdl_default_tcb :: \"cdl_object\"\nwhere \"cdl_default_tcb \\<equiv>  Tcb \\<lparr>cdl_tcb_caps =\n           [tcb_cspace_slot \\<mapsto> cdl_cap.NullCap, tcb_vspace_slot \\<mapsto> cdl_cap.NullCap, tcb_replycap_slot \\<mapsto>\n            cdl_cap.NullCap, tcb_caller_slot \\<mapsto> cdl_cap.NullCap, tcb_ipcbuffer_slot \\<mapsto> cdl_cap.NullCap,\n            tcb_pending_op_slot \\<mapsto> cdl_cap.NullCap, tcb_boundntfn_slot \\<mapsto> cdl_cap.NullCap],\n           cdl_tcb_fault_endpoint = 0,\n           cdl_tcb_intent =\n             \\<lparr>cdl_intent_op = None, cdl_intent_error = False,cdl_intent_cap = 0, cdl_intent_extras = [],\n                cdl_intent_recv_slot = None\\<rparr>, cdl_tcb_has_fault = False, cdl_tcb_domain = minBound\\<rparr>\"\n\ndefinition obj_tcb :: \"cdl_object \\<Rightarrow> cdl_tcb\"\nwhere \"obj_tcb obj \\<equiv> case obj of Tcb tcb \\<Rightarrow> tcb\"\n\ndefinition tcb_caps_merge :: \"cdl_tcb \\<Rightarrow> cdl_tcb \\<Rightarrow> cdl_tcb\"\n  where \"tcb_caps_merge regtcb captcb \\<equiv> regtcb\\<lparr>cdl_tcb_caps\n  := (cdl_tcb_caps captcb)(tcb_pending_op_slot \\<mapsto> the (cdl_tcb_caps regtcb tcb_pending_op_slot), tcb_boundntfn_slot \\<mapsto> the (cdl_tcb_caps regtcb tcb_boundntfn_slot))\\<rparr>\"\n\ndefinition merge_with_dft_tcb :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere \"merge_with_dft_tcb o_id \\<equiv>\n do\n  new_intent \\<leftarrow> select UNIV;\n  KHeap_D.update_thread o_id (cdl_tcb_intent_update (\\<lambda>x. new_intent) \\<circ> (tcb_caps_merge (obj_tcb cdl_default_tcb)))\n od\"\n\nfun\n  reset_mem_mapping :: \"cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"reset_mem_mapping (FrameCap dev p rts sz b mp) = FrameCap dev p rts sz b None\"\n| \"reset_mem_mapping (PageTableCap ptr b mp) = PageTableCap ptr b None\"\n| \"reset_mem_mapping (PageDirectoryCap ptr b ma) = PageDirectoryCap ptr b None\"\n| \"reset_mem_mapping cap = cap\"\n\n\n(*\n * Walk a user's CSpace to convert a user's CPTR into a cap slot.\n *)\nfunction\n  resolve_address_bits ::\n  \"cdl_cap \\<Rightarrow> cdl_cptr \\<Rightarrow> nat \\<Rightarrow> (cdl_cap_ref \\<times> nat) fault_monad\"\nwhere\n  \"resolve_address_bits cnode_cap cap_ptr remaining_size = doE\n    unlessE (is_cnode_cap cnode_cap) $ throw;\n\n    \\<comment> \\<open>Fetch the next level CNode.\\<close>\n    cnode \\<leftarrow> liftE $ get_cnode $ cap_object cnode_cap;\n    radix_size \\<leftarrow> returnOk $ cdl_cnode_size_bits cnode;\n    guard_size \\<leftarrow> returnOk $ cap_guard_size cnode_cap;\n    cap_guard  \\<leftarrow> returnOk $ cap_guard cnode_cap;\n    level_size \\<leftarrow> returnOk (radix_size + guard_size);\n    assertE (level_size \\<noteq> 0);\n\n    \\<comment> \\<open>Ensure the guard matches up.\\<close>\n    guard \\<leftarrow> returnOk $ (cap_ptr >> (remaining_size-guard_size)) && (mask guard_size);\n    unlessE (guard_size \\<le> remaining_size \\<and> guard = cap_guard) $ throw;\n\n    \\<comment> \\<open>Ensure we still enough unresolved bits left in our CPTR.\\<close>\n    whenE (level_size > remaining_size) $ throw;\n\n    \\<comment> \\<open>Find the next slot.\\<close>\n    offset \\<leftarrow> returnOk $ (cap_ptr >> (remaining_size-level_size)) && (mask radix_size);\n    slot \\<leftarrow> returnOk (cap_object cnode_cap, unat offset);\n    size_left \\<leftarrow> returnOk (remaining_size - level_size);\n    if (size_left = 0) then\n      returnOk (slot, 0)\n    else\n      doE\n        next_cap \\<leftarrow> liftE $ get_cap (slot);\n        if is_cnode_cap next_cap then\n          resolve_address_bits next_cap cap_ptr size_left\n        else\n          returnOk (slot, size_left)\n      odE\n  odE\"\n  by fastforce+\n\ntermination resolve_address_bits\n  apply (relation \"measure (\\<lambda>(a,b,c). c)\")\n  apply (auto simp: in_monad)\n  done\n\ndefinition\n  lookup_slot :: \"cdl_object_id \\<Rightarrow> cdl_cptr \\<Rightarrow> cdl_cap_ref fault_monad\"\nwhere\n  \"lookup_slot thread cptr \\<equiv>\n    doE\n      cspace_root \\<leftarrow> liftE $ get_cap (thread, tcb_cspace_slot);\n      (slot, _) \\<leftarrow> resolve_address_bits cspace_root cptr word_bits;\n      returnOk slot\n    odE\"\n\ndefinition\n  lookup_cap :: \"cdl_object_id \\<Rightarrow> cdl_cptr \\<Rightarrow> cdl_cap fault_monad\"\nwhere\n  \"lookup_cap thread cptr \\<equiv>\n    doE\n      slot \\<leftarrow> lookup_slot thread cptr;\n      liftE $ get_cap slot\n    odE\"\n\ndefinition\n  lookup_cap_and_slot :: \"cdl_object_id \\<Rightarrow> cdl_cptr \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) fault_monad\"\nwhere\n  \"lookup_cap_and_slot thread cptr \\<equiv>\n    doE\n      slot \\<leftarrow> lookup_slot thread cptr;\n      cap \\<leftarrow> liftE $ get_cap slot;\n      returnOk (cap, slot)\n    odE\"\n\ndefinition\n  lookup_slot_for_cnode_op :: \"cdl_cap \\<Rightarrow> cdl_cptr \\<Rightarrow> nat \\<Rightarrow> cdl_cap_ref except_monad\"\nwhere\n  \"lookup_slot_for_cnode_op croot cptr depth \\<equiv>\n    doE\n      whenE (depth < 1 \\<or> depth > word_bits) throw;\n      (slot, rem) \\<leftarrow> fault_to_except $ resolve_address_bits croot cptr depth;\n      if rem = 0 then returnOk slot else throw\n    odE\"\n\n\n(*\n * Update the badge of a cap, masking off bits the lower specs are unable\n * to store for implementation reasons.\n *)\ndefinition\n  badge_update :: \"word32 \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap\"\nwhere\n  \"badge_update data cap \\<equiv> update_cap_badge (data && mask badge_bits) cap\"\n\n(*\n * Transform a capability based on a request from the user.\n *\n * The \"data\" word is interpreted differently for different cap types.\n *\n * We return a set of possible caps to allow for non-deterministic\n * implementations, to avoid messy implementation details of the CDT\n * in lower-level models.\n *)\n\n\ndefinition\n  update_cap_data :: \"bool \\<Rightarrow> word32 \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap k_monad\"\nwhere\n  \"update_cap_data preserve data cap \\<equiv>\n    return $ case cap of\n        EndpointCap _ b _ \\<Rightarrow>\n          if b = 0 \\<and> \\<not> preserve then\n            badge_update data cap\n          else\n            NullCap\n      | NotificationCap _ b _ \\<Rightarrow>\n          if b = 0 \\<and> \\<not> preserve then\n            badge_update data cap\n          else\n            NullCap\n      | CNodeCap object guard guard_size sz \\<Rightarrow>\n          let\n            reserved_bits = 3;\n            guard_bits = 18;\n            guard_size_bits = 5;\n\n            new_guard_size = unat ((data >> reserved_bits) && mask guard_size_bits);\n            new_guard = (data >> (reserved_bits + guard_size_bits)) && mask (min (unat ((data >> reserved_bits) && mask guard_size_bits)) guard_bits)\n          in\n            if new_guard_size + sz > word_bits then NullCap else\n            (CNodeCap object new_guard new_guard_size sz)\n      | _ \\<Rightarrow> cap\"\n\n(*\n * Some caps may not be copied/minted. In this case the following function\n * returns NullCap or throws.\n *\n * PageTable and PageDirectory caps may not be copied if already mapped. This is\n * left out here and modelled by nondeterminism.\n *)\ndefinition\n  derive_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> cdl_cap except_monad\"\nwhere\n  \"derive_cap slot cap \\<equiv> case cap of\n     UntypedCap _ _ _ \\<Rightarrow> doE ensure_no_children slot; returnOk cap odE\n   | ReplyCap _ _ \\<Rightarrow> returnOk NullCap\n   | MasterReplyCap oref \\<Rightarrow> returnOk NullCap\n   | IrqControlCap \\<Rightarrow> returnOk NullCap\n   | ZombieCap _ \\<Rightarrow> returnOk NullCap\n   | FrameCap dev p r sz b x \\<Rightarrow> returnOk (FrameCap dev p r sz b None)\n   | PageTableCap _ _ _ \\<Rightarrow> throw \\<sqinter> returnOk cap\n   | PageDirectoryCap _ _ _ \\<Rightarrow> throw \\<sqinter> returnOk cap\n   | _ \\<Rightarrow> returnOk cap\"\n\n\n(* This function is here to make it available in both Tcb_D and\n   PageTable_D *)\n\n(* Modify the TCB's IpcBuffer or Registers in an arbitrary fashion. *)\ndefinition\n  corrupt_tcb_intent :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\nwhere\n  \"corrupt_tcb_intent target_tcb \\<equiv>\n    do\n      new_intent \\<leftarrow> select UNIV;\n      update_thread target_tcb (\\<lambda>t. t\\<lparr>cdl_tcb_intent := new_intent\\<rparr>)\n    od\"\n\nend"}
{"title": "./spec/capDL/Monads_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * The basic monads used in capDL\n *)\n\ntheory Monads_D\nimports\n  Types_D\n  Monads.Nondet_In_Monad\n  Monads.Nondet_VCG\nbegin\n\n(* Kernel state monad *)\ntype_synonym 'a k_monad = \"(cdl_state, 'a) nondet_monad\"\n\ndatatype cdl_except_error = ExceptError\ndatatype cdl_preempt_error = PreemptError\ndatatype cdl_fault_error = FaultError\n\n(* Exception monad, no further exception information *)\ntype_synonym 'a except_monad = \"(cdl_state, cdl_except_error + 'a) nondet_monad\"\n\n(* Exception monad, no further exception information *)\ntype_synonym 'a preempt_monad = \"(cdl_state, cdl_preempt_error + 'a) nondet_monad\"\n\n(* Exception monad, no further exception information *)\ntype_synonym 'a fault_monad =  \"(cdl_state, cdl_fault_error + 'a) nondet_monad\"\n\nabbreviation\n  throw :: \"(cdl_state, 'a + 'b) nondet_monad\" where\n  \"throw == throwError undefined\"\n\ntext \\<open>Allow preemption at this point.\\<close>\ndefinition\n  preemption_point :: \"unit preempt_monad\" where\n \"preemption_point \\<equiv> throw \\<sqinter> returnOk ()\"\n\n(*\n * Convert an exception monad with aribtrary type into a\n * new exception monad with unit type.\n *)\ndefinition\n  unify_failure :: \"('f + 'a) k_monad \\<Rightarrow> (unit + 'a) k_monad\" where\n \"unify_failure m \\<equiv> handleE' m (\\<lambda>x. throwError ())\"\n\ntext \\<open>\n  Convert a fault monad into an exception monad.\n\\<close>\ndefinition\n  fault_to_except :: \"'a fault_monad \\<Rightarrow> 'a except_monad\"\nwhere\n  \"fault_to_except m \\<equiv> handleE' m (\\<lambda>x. throw)\"\n\n(*\n * Non-deterministically select an item from the given set.\n * If the set if empty, return 'None'.\n *)\ndefinition\n  option_select :: \"'a set \\<Rightarrow> ('s, 'a option) nondet_monad\"\nwhere\n  \"option_select S \\<equiv>\n    if S = {} then\n      return None\n    else\n      select S >>= (\\<lambda>a. return (Some a))\"\n\n(* Return the given object, throwing an error if it is 'None'. *)\ndefinition\n  throw_on_none :: \"'a option \\<Rightarrow> ('e + 'a) k_monad\"\nwhere\n  \"throw_on_none x \\<equiv>\n    case x of\n        None \\<Rightarrow> throw\n      | Some y \\<Rightarrow> returnOk y\"\n\n\nend"}
{"title": "./spec/capDL/Invocations_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Invocations_D\nimports Types_D\nbegin\n\ndatatype cdl_cnode_invocation =\n    InsertCall cdl_cap cdl_cap_ref cdl_cap_ref\n  | MoveCall cdl_cap cdl_cap_ref cdl_cap_ref\n  | RevokeCall cdl_cap_ref\n  | DeleteCall cdl_cap_ref\n  | RotateCall cdl_cap cdl_cap cdl_cap_ref cdl_cap_ref cdl_cap_ref\n  | SaveCall cdl_cap_ref\n  | CancelBadgedSendsCall cdl_cap\n\ndatatype cdl_untyped_invocation =\n    Retype cdl_cap_ref\n        cdl_object_type cdl_size_bits \"cdl_cap_ref list\" bool nat\n\ndatatype cdl_tcb_invocation =\n    WriteRegisters cdl_object_id bool \"word32 list\" nat\n  | ReadRegisters cdl_object_id bool word32 nat\n  | CopyRegisters cdl_object_id cdl_object_id bool bool bool bool nat\n  | ThreadControl cdl_object_id cdl_cap_ref\n        \"cdl_cptr option\"\n        \"(cdl_cap \\<times> cdl_cap_ref) option\"\n        \"(cdl_cap \\<times> cdl_cap_ref) option\"\n        \"(cdl_cap \\<times> cdl_cap_ref) option\"\n  | Suspend cdl_object_id\n  | Resume cdl_object_id\n  | NotificationControl cdl_object_id \"cdl_object_id option\"\n  | SetTLSBase cdl_object_id\n\ndatatype arch_cdl_irq_control_invocation =\n    ARMIssueIrqHandler cdl_irq cdl_cap_ref cdl_cap_ref bool\n\ndatatype cdl_irq_control_invocation =\n    IssueIrqHandler cdl_irq cdl_cap_ref cdl_cap_ref\n  | ArchIssueIrqHandler arch_cdl_irq_control_invocation\n\ndatatype cdl_irq_handler_invocation =\n    AckIrq cdl_irq\n  | SetIrqHandler cdl_irq cdl_cap cdl_cap_ref\n  | ClearIrqHandler cdl_irq\n\ndatatype cdl_endpoint_invocation =\n    (* We need not track the \"block\" or \"call\" bits because they\n       are handled separately in the top-level syscall interface. *)\n    (* badge, grant, grant reply, ep *)\n    SyncMessage cdl_badge bool bool cdl_object_id\n\ndatatype cdl_notification_invocation =\n    (* badge (notification word) and notification object *)\n    Signal cdl_badge cdl_object_id\n\ndatatype cdl_reply_invocation =\n    ReplyMessage cdl_object_id cdl_cap_ref bool (* can grant *)\n\ndatatype cdl_page_table_invocation =\n    (* PageTableMap <real_pt_cap> <pt_cap> <pt_cap_ref> <pd_target_slot> *)\n    PageTableMap cdl_cap cdl_cap cdl_cap_ref cdl_cap_ref\n    (* PageTableUnmap <mapped_addr option> <pt_obj_id> <pt_cap_ref> *)\n  | PageTableUnmap \"cdl_mapped_addr option\"  cdl_object_id cdl_cap_ref\n\ndatatype cdl_asid_control_invocation =\n    MakePool cdl_cap cdl_cap_ref \"cdl_object_id set\" cdl_cap_ref nat\n\ndatatype cdl_asid_pool_invocation =\n    Assign cdl_asid cdl_cap_ref cdl_cap_ref\n\ndatatype flush =\n   Clean | Invalidate | CleanInvalidate | Unify\n\ndatatype cdl_page_invocation =\n    PageMap cdl_cap cdl_cap cdl_cap_ref \"cdl_cap_ref list\"\n  | PageUnmap \"cdl_mapped_addr option\" cdl_object_id \"cdl_cap_ref\" nat\n  | PageFlushCaches flush\n  | PageGetAddress\n\n\ndatatype cdl_page_directory_invocation =\n   PageDirectoryFlush  flush\n | PageDirectoryNothing\n\n\ndatatype cdl_domain_invocation =\n  SetDomain cdl_object_id word8\n\ndatatype cdl_invocation =\n    InvokeUntyped cdl_untyped_invocation\n  | InvokeEndpoint cdl_endpoint_invocation\n  | InvokeNotification cdl_notification_invocation\n  | InvokeReply cdl_reply_invocation\n  | InvokeTcb cdl_tcb_invocation\n  | InvokeDomain cdl_domain_invocation\n  | InvokeCNode cdl_cnode_invocation\n  | InvokeIrqControl cdl_irq_control_invocation\n  | InvokeIrqHandler cdl_irq_handler_invocation\n  | InvokePageTable cdl_page_table_invocation\n  | InvokePage cdl_page_invocation\n  | InvokePageDirectory cdl_page_directory_invocation\n  | InvokeAsidControl cdl_asid_control_invocation\n  | InvokeAsidPool cdl_asid_pool_invocation\n\nend"}
{"title": "./spec/capDL/KHeap_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Accessor functions for objects and caps.\n *)\n\ntheory KHeap_D\nimports Monads_D\nbegin\n\n(* Return an item from the heap. Fail if no such object exists. *)\nabbreviation\n  get_object :: \"cdl_object_id \\<Rightarrow> cdl_object k_monad\"\nwhere\n  \"get_object p \\<equiv> gets_the (\\<lambda>s. cdl_objects s p)\"\n\n(* Set an item on the heap to the given object. *)\ndefinition\n  set_object :: \"cdl_object_id \\<Rightarrow> cdl_object \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_object p obj \\<equiv>\n    modify (\\<lambda>s. s \\<lparr> cdl_objects := (cdl_objects s) (p \\<mapsto> obj) \\<rparr> )\"\n\n(* Get a thread from the given pointer. *)\ndefinition\n  get_thread :: \"cdl_object_id \\<Rightarrow> cdl_tcb k_monad\"\nwhere\n  \"get_thread p \\<equiv>\n    do\n      t \\<leftarrow> get_object p;\n      case t of\n          Tcb tcb \\<Rightarrow> return tcb\n        | _ \\<Rightarrow> fail\n    od\"\n\n(* Get a thread from the given pointer. *)\ndefinition\n  get_thread_fault :: \"cdl_object_id \\<Rightarrow> bool k_monad\"\nwhere\n  \"get_thread_fault p \\<equiv>\n    do\n      t \\<leftarrow> get_object p;\n      case t of\n          Tcb tcb \\<Rightarrow> return (cdl_tcb_has_fault tcb)\n        | _ \\<Rightarrow> fail\n    od\"\n\n(* Update a thread on the heap. *)\ndefinition\n  update_thread :: \"cdl_object_id \\<Rightarrow> (cdl_tcb \\<Rightarrow> cdl_tcb) \\<Rightarrow> unit k_monad\"\nwhere\n  \"update_thread p f \\<equiv>\n     do\n       t \\<leftarrow> get_object p;\n       case t of\n          Tcb tcb \\<Rightarrow> set_object p (Tcb (f tcb))\n       | _ \\<Rightarrow> fail\n     od\"\n\n(* Update a thread on the heap. *)\ndefinition\n  update_thread_fault :: \"cdl_object_id \\<Rightarrow> (bool\\<Rightarrow>bool) \\<Rightarrow> unit k_monad\"\nwhere\n  \"update_thread_fault p f \\<equiv>\n     do\n       t \\<leftarrow> get_object p;\n       case t of\n          Tcb tcb \\<Rightarrow> set_object p (Tcb (tcb\\<lparr>cdl_tcb_has_fault := f (cdl_tcb_has_fault tcb)\\<rparr>))\n       | _ \\<Rightarrow> fail\n     od\"\n\n(* Get a CNode from the given pointer. *)\ndefinition\n  get_cnode :: \"cdl_object_id \\<Rightarrow> cdl_cnode k_monad\"\nwhere\n  \"get_cnode p \\<equiv>\n    do\n      t \\<leftarrow> get_object p;\n      case t of\n          CNode cnode \\<Rightarrow> return cnode\n        | _ \\<Rightarrow> fail\n    od\"\n\n(*\n * Get the index out of the given list, returning None if it\n * doesn't exist.\n *)\ndefinition\n  get_index :: \"'a list \\<Rightarrow> nat \\<Rightarrow> 'a option\"\nwhere\n  \"get_index a b \\<equiv>\n     if b < length a then\n       Some (a ! b)\n     else\n       None\"\n\n(* --- caps --- *)\n\n(* The slots of an object, returns an empty map for non-existing objects\n   or objects that do not have caps *)\ndefinition\n  slots_of :: \"cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_map\"\nwhere\n  \"slots_of obj_id \\<equiv> \\<lambda>s.\n  case cdl_objects s obj_id of\n    None \\<Rightarrow> Map.empty\n  | Some obj \\<Rightarrow> object_slots obj\"\n\n(* The cap at the given cap_ref. None if object or cap does not exist *)\ndefinition\n  opt_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap option\"\nwhere\n  \"opt_cap \\<equiv> \\<lambda>(obj_id, slot) s. slots_of obj_id s slot\"\n\n(* monad version of opt_cap *)\nabbreviation\n  get_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_cap k_monad\" where\n  \"get_cap p \\<equiv> gets_the (opt_cap p)\"\n\n\n(* Setting a cap at specific cap_ref. Object must exist and have cap slots. *)\ndefinition\n  set_cap :: \"cdl_cap_ref \\<Rightarrow> cdl_cap \\<Rightarrow> unit k_monad\"\nwhere\n  \"set_cap \\<equiv> \\<lambda>(obj_id, slot) cap. do\n    obj \\<leftarrow> get_object obj_id;\n    assert (has_slots obj);\n    slots \\<leftarrow> return $ object_slots obj;\n    obj' \\<leftarrow> return $ update_slots (slots (slot \\<mapsto> cap)) obj;\n    obj'' \\<leftarrow> case obj' of\n              Tcb t \\<Rightarrow> if slot = tcb_ipcbuffer_slot \\<and> slots slot \\<noteq> Some cap then do\n                   intent' \\<leftarrow> select UNIV;\n                   return $ Tcb (t \\<lparr> cdl_tcb_intent := intent' \\<rparr>)\n                 od\n                 else return obj'\n             | _ \\<Rightarrow> return obj';\n    set_object obj_id obj''\n  od\"\n\n\n\n(* looking up the parent of a cap in the cdt *)\ndefinition\n  opt_parent :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref option\" where\n  \"opt_parent p \\<equiv> \\<lambda>s. cdl_cdt s p\"\n\nabbreviation\n  get_parent :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref k_monad\" where\n  \"get_parent p \\<equiv> gets_the (opt_parent p)\"\n\n(* setting a cap derivation of a specific cap_ref  *)\ndefinition\n  set_parent :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\" where\n  \"set_parent child parent \\<equiv> do\n    cdt \\<leftarrow> gets cdl_cdt;\n    assert (cdt child = None);\n    modify (\\<lambda>s. s \\<lparr> cdl_cdt := (cdl_cdt s) (child \\<mapsto> parent) \\<rparr> )\n   od\"\n\n(* Removes a cap slot from the cdt, and points all its children to their grandparent *)\ndefinition\n  remove_parent :: \"cdl_cap_ref \\<Rightarrow> unit k_monad\" where\n  \"remove_parent parent \\<equiv>\n   modify (\\<lambda>s. s \\<lparr>cdl_cdt := (\\<lambda> x. if x = parent\n                                 then None\n                                 else (if cdl_cdt s x = Some parent\n                                     then cdl_cdt s parent\n                                     else cdl_cdt s x )) \\<rparr>)\"\n\n(* Swaps the parents of two cap_refs *)\ndefinition\n  swap_parents :: \"cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> unit k_monad\" where\n  \"swap_parents p p' = modify (cdl_cdt_update\n     (\\<lambda>cd. Fun.swap p p'\n          (\\<lambda>x. if cd x = Some p then Some p' else\n              if cd x = Some p' then Some p else cd x)))\"\n\ndefinition\n  is_cdt_parent :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\" where\n  \"is_cdt_parent s p c \\<equiv> cdl_cdt s c = Some p\"\n\ndefinition\n  cdt_parent_rel :: \"cdl_state \\<Rightarrow> (cdl_cap_ref \\<times> cdl_cap_ref) set\" where\n  \"cdt_parent_rel \\<equiv> \\<lambda>s. {(p,c). is_cdt_parent s p c}\"\n\nabbreviation\n  parent_of :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> p cdt_parent_of c \\<equiv> (p,c) \\<in> cdt_parent_rel s\"\n\nabbreviation\n  parent_of_trancl :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>+ _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x cdt_parent_of\\<^sup>+ y \\<equiv> (x, y) \\<in> (cdt_parent_rel s)\\<^sup>+\"\n\nabbreviation\n  parent_of_rtrancl :: \"cdl_state \\<Rightarrow> cdl_cap_ref \\<Rightarrow> cdl_cap_ref \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>* _\" [60,0,60] 61)\nwhere\n  \"s \\<turnstile> x cdt_parent_of\\<^sup>* y \\<equiv> (x, y) \\<in> (cdt_parent_rel s)\\<^sup>*\"\n\n\\<comment> \\<open>descendants of a slot\\<close>\ndefinition\n  descendants_of :: \"cdl_cap_ref \\<Rightarrow> cdl_state \\<Rightarrow> cdl_cap_ref set\" where\n  \"descendants_of p s \\<equiv> {q. (p,q) \\<in> (cdt_parent_rel s)\\<^sup>+}\"\n\n\n\ndefinition\n  tcb_ipcframe_id :: \"cdl_tcb \\<Rightarrow> cdl_object_id option\"\nwhere\n  \"tcb_ipcframe_id tcb \\<equiv> case (cdl_tcb_caps tcb tcb_ipcbuffer_slot) of\n                              Some (FrameCap _ oid _ _ _ _) \\<Rightarrow> Some oid\n                              | _                       \\<Rightarrow> None\"\n\n(*\n * Dealing with writes to message registers or other locations that\n * may have an effect on how intents are interpreted.\n *)\ndefinition\n  corrupt_intents ::\"(word32 \\<Rightarrow> cdl_full_intent) \\<Rightarrow> cdl_object_id \\<Rightarrow> cdl_state \\<Rightarrow> cdl_state\"\nwhere\n  \"corrupt_intents f bufp s \\<equiv>\n  let changed = (\\<lambda>ptr. case cdl_objects s ptr of\n    Some (Tcb tcb)\n      \\<Rightarrow> if tcb_ipcframe_id tcb = Some bufp then Some (Tcb (tcb\\<lparr> cdl_tcb_intent := f ptr \\<rparr> ) ) else None\n  | _ \\<Rightarrow> None)\n  in\n  s\\<lparr>cdl_objects := cdl_objects s ++ changed\\<rparr>\"\n\n(* When a memory frame has been corrupted,\n * we need to change all the intents of tcbs\n * whose ipc_buffer is located within that frame\n *)\ndefinition\n  corrupt_frame :: \"cdl_object_id \\<Rightarrow> unit k_monad\"\n  where\n  \"corrupt_frame bufp \\<equiv> do\n      f \\<leftarrow> select UNIV;\n      modify (corrupt_intents f bufp)\n    od\"\n\nend"}
{"title": "./spec/capDL/Interrupt_D.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n * Operations on interrupt objects.\n *)\n\ntheory Interrupt_D\nimports Endpoint_D \"ExecSpec.Platform\"\nbegin\n\ncontext begin interpretation Arch .\nrequalify_types\n  irq\nend\n\n(* Return the currently pending IRQ. *)\ndefinition\n  get_active_irq :: \"(cdl_irq option) k_monad\"\nwhere\n  \"get_active_irq \\<equiv>\n    do\n      irq \\<leftarrow> select UNIV;\n      return $ Some irq\n    od \\<sqinter> (return None)\n  \"\n\ndefinition\n  arch_decode_irq_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_arch_irq_control_intent \\<Rightarrow> cdl_irq_control_invocation except_monad\"\nwhere\n  \"arch_decode_irq_control_invocation target target_ref caps intent \\<equiv> case intent of\n      ARMIrqControlIssueIrqHandlerIntent irq index depth \\<Rightarrow>\n        doE\n          root \\<leftarrow> throw_on_none $ get_index caps 0;\n          cnode_cap \\<leftarrow> returnOk $ fst root;\n          dest_slot_cap_ref \\<leftarrow> lookup_slot_for_cnode_op cnode_cap index (unat depth);\n          returnOk $ IssueIrqHandler irq target_ref dest_slot_cap_ref\n        odE \\<sqinter> throw\"\n\ndefinition\n  decode_irq_control_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_irq_control_intent \\<Rightarrow> cdl_irq_control_invocation except_monad\"\nwhere\n  \"decode_irq_control_invocation target target_ref caps intent \\<equiv> case intent of\n      \\<comment> \\<open>Create an IRQ handler cap for the given IRQ, placing it\n         in the specified CNode slot.\\<close>\n      IrqControlIssueIrqHandlerIntent irq index depth \\<Rightarrow>\n        doE\n          root \\<leftarrow> throw_on_none $ get_index caps 0;\n          cnode_cap \\<leftarrow> returnOk $ fst root;\n          dest_slot_cap_ref \\<leftarrow> lookup_slot_for_cnode_op cnode_cap index (unat depth);\n          returnOk $ IssueIrqHandler irq target_ref dest_slot_cap_ref\n        odE \\<sqinter> throw\n    | ArchIrqControlIssueIrqHandlerIntent arch_intent \\<Rightarrow> arch_decode_irq_control_invocation target target_ref caps arch_intent\"\n\ndefinition\n  decode_irq_handler_invocation :: \"cdl_cap \\<Rightarrow> cdl_cap_ref \\<Rightarrow> (cdl_cap \\<times> cdl_cap_ref) list \\<Rightarrow>\n      cdl_irq_handler_intent \\<Rightarrow> cdl_irq_handler_invocation except_monad\"\nwhere\n  \"decode_irq_handler_invocation target target_ref caps intent \\<equiv> case intent of\n    \\<comment> \\<open>Acknowledge an IRQ.\\<close>\n    IrqHandlerAckIntent \\<Rightarrow>\n      doE\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        returnOk $ AckIrq irq\n      odE \\<sqinter> throw\n\n    \\<comment> \\<open>Modify the IRQ so that it no longer sends to an endpoint.\\<close>\n    | IrqHandlerClearIntent \\<Rightarrow>\n      doE\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        returnOk $ ClearIrqHandler irq\n      odE \\<sqinter> throw\n\n    \\<comment> \\<open>Setup an IRQ to cause an endpoint to be sent to.\\<close>\n    | IrqHandlerSetEndpointIntent \\<Rightarrow>\n      doE\n        endpoint \\<leftarrow> throw_on_none $ get_index caps 0;\n        endpoint_cap \\<leftarrow> returnOk $ fst endpoint;\n        endpoint_cap_ref \\<leftarrow> returnOk $ snd endpoint;\n        irq \\<leftarrow> liftE $ assert_opt $ cdl_cap_irq target;\n        case endpoint_cap of\n              NotificationCap x _ _ \\<Rightarrow> returnOk ()\n              | _                    \\<Rightarrow> throw;\n        returnOk $ SetIrqHandler irq endpoint_cap endpoint_cap_ref\n      odE \\<sqinter> throw\n  \"\n\ndefinition\n  arch_invoke_irq_control :: \"arch_cdl_irq_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"arch_invoke_irq_control params \\<equiv> case params of\n      \\<comment> \\<open>Create a new IRQ handler cap.\\<close>\n      ARMIssueIrqHandler irq control_slot dest_slot trigger \\<Rightarrow>\n        insert_cap_child (IrqHandlerCap irq) control_slot dest_slot\n  \"\n\ndefinition\n  invoke_irq_control :: \"cdl_irq_control_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_irq_control params \\<equiv> case params of\n      \\<comment> \\<open>Create a new IRQ handler cap.\\<close>\n      IssueIrqHandler irq control_slot dest_slot \\<Rightarrow>\n        insert_cap_child (IrqHandlerCap irq) control_slot dest_slot\n    | ArchIssueIrqHandler arch_inv \\<Rightarrow>\n        arch_invoke_irq_control arch_inv\"\n\ndefinition\n  invoke_irq_handler :: \"cdl_irq_handler_invocation \\<Rightarrow> unit k_monad\"\nwhere\n  \"invoke_irq_handler params \\<equiv> case params of\n      \\<comment> \\<open>Acknowledge and unmask an IRQ.\\<close>\n      AckIrq irq \\<Rightarrow> return ()\n\n      \\<comment> \\<open>Attach an IRQ handler to write to an endpoint.\\<close>\n    | SetIrqHandler irq cap slot \\<Rightarrow>\n        do\n          irqslot \\<leftarrow> gets (get_irq_slot irq);\n          delete_cap_simple irqslot;\n          insert_cap_child cap slot irqslot \\<sqinter> insert_cap_sibling cap slot irqslot\n        od\n\n      \\<comment> \\<open>Deassociate this handler with all endpoints.\\<close>\n    | ClearIrqHandler irq \\<Rightarrow>\n        do\n          irqslot \\<leftarrow> gets (get_irq_slot irq);\n          delete_cap_simple irqslot\n        od\n  \"\n\n(* Handle an interrupt. *)\ndefinition\n  handle_interrupt :: \"cdl_irq \\<Rightarrow> unit k_monad\"\nwhere\n  \"handle_interrupt irq \\<equiv> if irq > maxIRQ then return () else\n    do\n      irq_slot \\<leftarrow> gets $ get_irq_slot irq;\n      c \\<leftarrow> gets $ opt_cap irq_slot;\n      case c of\n          None \\<Rightarrow> return ()\n        | Some cap \\<Rightarrow> (\n            case cap of\n              (NotificationCap obj _ rights) \\<Rightarrow>\n                  if (Write \\<in> rights) then send_signal obj else return ()\n              | _ \\<Rightarrow> return ()\n          )\n    od\n  \"\n\ndefinition\n  handle_pending_interrupts :: \"unit k_monad\"\nwhere\n  \"handle_pending_interrupts \\<equiv>\n    do\n      active \\<leftarrow> get_active_irq;\n      case active of\n          Some irq \\<Rightarrow> handle_interrupt irq\n        | None \\<Rightarrow> return ()\n    od\"\n\nend"}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory KernelInit_A (* FIXME: unused, out of date *)\nimports\n  Tcb_A\n  ArchVSpace_A\nbegin"}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "Parameters passed in from linker script", "subsection": "", "subsubsection": "", "code": "\ntranslations\n  (type) \"cslot_ptr\" <= (type) \"word32 \\<times> bool list\"\n\ntype_synonym slot_ptr = \"cslot_ptr\"\ntype_synonym slot_region_t = \"nat \\<times> nat\"\ntype_synonym bi_dev_reg_t = \"paddr \\<times> word32 \\<times> slot_region_t\"\n\ntext \\<open>Select from state S, throw ex if S is empty.\\<close>\ndefinition\n  \"throw_select S ex \\<equiv> doE\n     whenE (S = {}) (throwError ex);\n     liftE (select S)\n   odE\""}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "Kernel Init State", "subsection": "", "subsubsection": "", "code": "\nconsts\n  ki_boot_end :: paddr\n  arm_vector_table :: obj_ref\n  arm_kernel_stack :: obj_ref\n  idle_thread_start :: vspace_ref (* &idle_thread *)"}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "Kernel Init State", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Ghost state representing the contents of the boot info frame\\<close>\nrecord bi_frame_data =\n  bi_f_node_id :: word32\n  bi_f_num_nodes :: word32\n  bi_f_num_iopt_levels :: word32\n  bi_f_ipcbuf_vptr :: vspace_ref\n  bi_f_null_caps :: slot_region_t\n  bi_f_sh_frame_caps :: slot_region_t\n  bi_f_ui_frame_caps :: slot_region_t\n  bi_f_ui_pt_caps :: slot_region_t\n  bi_f_ut_obj_caps :: slot_region_t\n  bi_f_ut_obj_paddr_list :: \"paddr list\"\n  bi_f_ut_obj_size_bits_list :: \"word8 list\"\n  bi_f_it_cnode_size_bits :: word8\n  bi_f_num_dev_regs :: word32\n  bi_f_dev_reg_list :: \"bi_dev_reg_t list\"\n\ntype_synonym (* XXX: natural numbers represent components of kernel objects, for those\n              objects that can be subdivided *)\n  component = \"bool list\"\n\ntext \\<open>\n  For kernel initialisation, we need the basic kernel state plus some extra\n  information to keep track of, such as free memory.\n  At the concrete level, this is managed by region lists.\n\n  The ``available memory'' indicates memory that has been allocated (and thus\n  no longer free) but that has no objects in it, as it has not been retyped.\n  This is so we can state heap-consuming separation logic predicates which\n  assert that ``there's nothing here'', e.g. so-called untyped objects.\n\n  The components map should have the same domain as the abstract heap in the\n  kernel state, but indicate which components of the object we have permission\n  to access. The purpose is separation logic statements about heaps in which\n  objects can be split up, e.g. only one cap in a CNode.\n\\<close>\nrecord ('z) ki_state =\n  ki_kernel_state    :: \"'z state\"\n  ki_free_mem        :: \"obj_ref set\" (* ndks_boot.freemem representative? *)\n  ki_available_mem   :: \"obj_ref set\" (* ghost state *)\n  ki_bootinfo        :: bi_frame_data (* ghost state *)\n  ki_components      :: \"paddr \\<Rightarrow> component set\"\n  ndks_boot_slot_pos_cur :: nat\n  ndks_boot_slot_pos_max :: nat\n  ndks_boot_bi_frame :: paddr"}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "Kernel init monad", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  The kernel init monad can fail. The actual value of the failure is largely\n  irrelevant, just so long as we don't have assertion failures for no reason.\n\\<close>\n\ndatatype ki_failure = InitFailure\ntype_synonym ('a,'z) ki_monad = \"('z ki_state, ki_failure + 'a) nondet_monad\"\ntranslations\n  (type) \"'a ki_monad\" <=\n    (type) \"((ki_failure + 'a) \\<times> ki_state \\<Rightarrow> bool) \\<times> bool\"\n\ntext \\<open>Lift kernel state monad ops to the kernel init monad.\\<close>\ndefinition\n  do_kernel_op :: \"('a,'z::state_ext) s_monad \\<Rightarrow> ('a,'z) ki_monad\" where\n \"do_kernel_op kop \\<equiv> liftE $ do\n    ms \\<leftarrow> gets ki_kernel_state;\n    (r, ms') \\<leftarrow> select_f (kop ms);\n    modify (\\<lambda>ks. ks \\<lparr> ki_kernel_state := ms' \\<rparr>);\n    return r\n  od\""}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "Kernel constants", "subsection": "", "subsubsection": "", "code": "\ndefinition \"MIN_NUM_4K_UNTYPED_OBJ \\<equiv> 12 :: nat\"\ndefinition \"MAX_NUM_FREEMEM_REG \\<equiv> 2 :: nat\"\n\ntext \\<open>Fixed cap positions in root CNode (bootinfo.h)\\<close>\ndefinition \"BI_CAP_NULL         \\<equiv>  0 :: nat\"\ndefinition \"BI_CAP_IT_TCB       \\<equiv>  1 :: nat\"\ndefinition \"BI_CAP_IT_CNODE     \\<equiv>  2 :: nat\"\ndefinition \"BI_CAP_IT_PD        \\<equiv>  3 :: nat\"\ndefinition \"BI_CAP_IRQ_CTRL     \\<equiv>  4 :: nat\"\ndefinition \"BI_CAP_ASID_CTRL    \\<equiv>  5 :: nat\"\ndefinition \"BI_CAP_IT_ASID_POOL \\<equiv>  6 :: nat\"\ndefinition \"BI_CAP_IO_PORT      \\<equiv>  7 :: nat\"\ndefinition \"BI_CAP_IO_SPACE     \\<equiv>  8 :: nat\"\ndefinition \"BI_CAP_BI_FRAME     \\<equiv>  9 :: nat\"\ndefinition \"BI_CAP_IT_IPCBUF    \\<equiv> 10 :: nat\"\ndefinition \"BI_CAP_DYN_START    \\<equiv> 11 :: nat\"\n\ndefinition \"BI_FRAME_SIZE_BITS \\<equiv> pageBits\"\ndefinition \"ROOT_CNODE_SIZE_BITS \\<equiv> 12 :: nat\""}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "ARM constants", "subsection": "", "subsubsection": "", "code": "\ndefinition \"PPTR_VECTOR_TABLE \\<equiv> 0xffff0000 :: word32\"\ndefinition \"PPTR_GLOBALS_PAGE \\<equiv> 0xffffc000 :: word32\"\ndefinition \"PPTR_KERNEL_STACK \\<equiv> 0xfffff000 :: word32\"\n\ndefinition \"IT_ASID     \\<equiv> 1 :: asid\" (* initial thread ASID *)\n\ndefinition \"WORD_SIZE_BITS \\<equiv> 2 :: nat\"\ndefinition \"ASID_POOL_BITS \\<equiv> asid_low_bits :: nat\"\ndefinition \"ASID_POOL_SIZE_BITS \\<equiv> ASID_POOL_BITS + WORD_SIZE_BITS\"\n\ndefinition \"CTE_SIZE_BITS \\<equiv> 4 :: nat\" (* from ARM structures.h *)\n\ntext \\<open>in abstract, these do not have a direct equivalent\\<close>\ndefinition \"PD_BITS \\<equiv> 12 :: nat\"\ndefinition \"PT_BITS \\<equiv> 8 :: nat\"\n\ndefinition \"PDE_SIZE_BITS \\<equiv> 2 :: nat\"\ndefinition \"PTE_SIZE_BITS \\<equiv> 2 :: nat\"\n\ntext \\<open>in abstract, these are pd_bits and pt_bits respectively\\<close>\ndefinition \"PD_SIZE_BITS \\<equiv> PD_BITS + PDE_SIZE_BITS\"\ndefinition \"PT_SIZE_BITS \\<equiv> PT_BITS + PTE_SIZE_BITS\""}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "Platform constants (iMX31)", "subsection": "", "subsubsection": "", "code": "\ndefinition \"irqInvalid       \\<equiv> 255 :: irq\"\ndefinition \"INTERRUPT_PMU    \\<equiv> 23 :: irq\"\ndefinition \"INTERRUPT_EPIT1  \\<equiv> 28 :: irq\"\ndefinition \"KERNEL_TIMER_IRQ \\<equiv> INTERRUPT_EPIT1\"\n\ntext \\<open>Kernel devices for imx31\\<close>\ndefinition \"EPIT_PADDR \\<equiv> 0x53f94000 :: word32\"\ndefinition \"EPIT_PPTR  \\<equiv> 0xfff00000 :: word32\"\ndefinition \"AVIC_PADDR \\<equiv> 0x68000000 :: word32\"\ndefinition \"AVIC_PPTR  \\<equiv> 0xfff01000 :: word32\"\ndefinition \"L2CC_PADDR \\<equiv> 0x30000000 :: word32\"\ndefinition \"L2CC_PPTR  \\<equiv> 0xfff02000 :: word32\"\ndefinition \"UART_PADDR \\<equiv> 0x43f90000 :: word32\"\ndefinition \"UART_PPTR  \\<equiv> 0xfff03000 :: word32\"\n\ndefinition \"BASE_OFFSET = pptrBaseOffset\""}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "Functions cloned and modified for separation logic to work", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  These shadow the normal functions, but do not force a well-formedness\n  check for the cnodes, as wellformed\\_cnode\\_sz is non-local with respect\n  to individual caps, and so get\\_cap and set\\_cap are also.\\<close>\n\ndefinition\n  get_cap_local :: \"cslot_ptr \\<Rightarrow> (cap,'z::state_ext) s_monad\"\nwhere\n  \"get_cap_local \\<equiv> \\<lambda>(oref, cref). do\n     obj \\<leftarrow> get_object oref;\n     caps \\<leftarrow> case obj of\n             CNode sz cnode \\<Rightarrow> return cnode\n           | TCB tcb     \\<Rightarrow> return (tcb_cnode_map tcb)\n           | _ \\<Rightarrow> fail;\n     assert_opt (caps cref)\n   od\"\n\ndefinition\n  set_cap_local :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_cap_local cap \\<equiv> \\<lambda>(oref, cref). do\n     obj \\<leftarrow> get_object oref;\n     obj' \\<leftarrow> case obj of\n               CNode sz cn \\<Rightarrow> if cref \\<in> dom cn\n                                then return $ CNode sz $ cn (cref \\<mapsto> cap)\n                                else fail\n             | TCB tcb \\<Rightarrow>\n                   if cref = tcb_cnode_index 0 then\n                       return $ TCB $ tcb \\<lparr> tcb_ctable := cap \\<rparr>\n                   else if cref = tcb_cnode_index 1 then\n                       return $ TCB $ tcb \\<lparr> tcb_vtable := cap \\<rparr>\n                   else if cref = tcb_cnode_index 2 then\n                       return $ TCB $ tcb \\<lparr> tcb_reply := cap \\<rparr>\n                   else if cref = tcb_cnode_index 3 then\n                       return $ TCB $ tcb \\<lparr> tcb_caller := cap \\<rparr>\n                   else if cref = tcb_cnode_index 4 then\n                       return $ TCB $ tcb \\<lparr> tcb_ipcframe := cap \\<rparr>\n                   else\n                       fail\n             | _ \\<Rightarrow> fail;\n     set_object oref obj'\n  od\"\n\ndefinition\n  set_untyped_cap_as_full_local :: \"cap \\<Rightarrow> cap \\<Rightarrow> word32 \\<times> bool list\\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_untyped_cap_as_full_local src_cap new_cap src_slot \\<equiv>\n   if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n       \\<and> obj_ref_of src_cap = obj_ref_of new_cap \\<and> cap_bits_untyped src_cap = cap_bits_untyped new_cap)\n       then set_cap_local (max_free_index_update src_cap) src_slot else return ()\"\n\ndefinition\n  cap_insert_local :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"cap_insert_local new_cap src_slot dest_slot \\<equiv> do\n    src_cap \\<leftarrow> get_cap_local src_slot;\n\n    dest_original \\<leftarrow> return (if is_ep_cap new_cap then\n                                cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n                             else if is_ntfn_cap new_cap then\n                                cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n                             else if \\<exists>irq. new_cap = IRQHandlerCap irq then\n                                src_cap = IRQControlCap\n                             else is_untyped_cap new_cap);\n    old_cap \\<leftarrow> get_cap_local dest_slot;\n    assert (old_cap = NullCap);\n    set_untyped_cap_as_full_local src_cap new_cap src_slot;\n    set_cap_local new_cap dest_slot;\n\n    is_original \\<leftarrow> gets is_original_cap;\n    src_parent \\<leftarrow> return $\n       should_be_parent_of src_cap (is_original src_slot) new_cap dest_original;\n    src_p \\<leftarrow> gets (\\<lambda>s. cdt s src_slot);\n    dest_p \\<leftarrow> gets (\\<lambda>s. cdt s dest_slot);\n    update_cdt (\\<lambda>cdt. cdt (dest_slot := if src_parent\n                                        then Some src_slot\n                                        else cdt src_slot));\n    do_extended_op (cap_insert_ext src_parent src_slot dest_slot src_p dest_p);\n    set_original dest_slot dest_original\n  od\"\n\ndefinition\n  \"setup_reply_master_local thread \\<equiv> do\n     old_cap <- get_cap_local (thread, tcb_cnode_index 2);\n     when (old_cap = NullCap) $ do\n         set_original (thread, tcb_cnode_index 2) True;\n         set_cap_local (ReplyCap thread True) (thread, tcb_cnode_index 2)\n     od\n  od\""}
{"title": "./spec/abstract/KernelInit_A.thy", "section": "Kernel init functions", "subsection": "", "subsubsection": "", "code": "\nconsts (* TODO: serialise bi_frame_data and write it to the bootinfo frame *)\n  sync_bootinfo_frame :: \"paddr \\<Rightarrow> (unit,'z::state_ext) ki_monad\"\n\ndefinition (* C macro ROUND_DOWN *)\n   \"round_down w b \\<equiv> (w >> b) << b\"\n\ndefinition\n  alloc_region :: \"nat \\<Rightarrow> (obj_ref,'z) ki_monad\" where\n \"alloc_region bits \\<equiv> doE\n    free  \\<leftarrow> liftE $ gets ki_free_mem;\n    ptr   \\<leftarrow> throw_select\n              {ptr. is_aligned ptr bits \\<and> {ptr .. ptr + 2 ^ bits - 1} \\<subseteq> free}\n              InitFailure;\n    liftE $ modify (\\<lambda>s. s \\<lparr> ki_free_mem :=\n                              free - {ptr .. ptr + 2 ^ bits - 1} \\<rparr>);\n\n    (* Ghost state update: mark memory as available *)\n    avail \\<leftarrow> liftE $ gets ki_available_mem;\n    liftE $ modify (\\<lambda>s. s \\<lparr> ki_available_mem :=\n                              avail \\<union> {ptr .. ptr + 2 ^ bits - 1} \\<rparr>);\n\n    returnOk ptr\n  odE\"\n\ndefinition\n  init_freemem :: \"(paddr \\<times> paddr) \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"init_freemem ui_reg \\<equiv> doE\n\n     mem_regs \\<leftarrow> do_kernel_op $ do_machine_op getMemoryRegions;\n\n     free_addrs \\<leftarrow> returnOk $ foldl (\\<union>) {}\n                             $ map (\\<lambda>(start,end). {start..<end}) mem_regs;\n\n     (* subtract userland image addresses from the set of free addresses *)\n     free_addrs' \\<leftarrow> returnOk $ free_addrs - {fst ui_reg..<(snd ui_reg)};\n\n     (* now pick a subset of those vars, because the C has a limit on the\n        number of slots in ndks_boot.freemem[] (MAX_NUM_FREEMEM_REG) which\n        isn't represented in the abstract spec *)\n     free_addrs_sel \\<leftarrow> liftE $ select {s. s \\<subseteq> free_addrs'};\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_free_mem := free_addrs_sel \\<rparr>)\n   odE\"\n\ntext \\<open>\n  The @{text \"arm_global_pts\"} arch state field means something completely\n  different to the armKSGlobalPT in the C code. As such, the abstract spec as\n  it stands now must have a list of pts there. Since the kernel init abstract\n  spec is based on the actual C, we know there is only one such pt. To prevent\n  confusion, this function is meant as the canonical way to get the\n  armKSGlobalPT equivalent, whatever it ends up being.\n\n  This means that kernel init assumes the initial state will provide a PT\n  there that it can use.\\<close>\ndefinition\n  get_arm_global_pt :: \"(paddr,'z::state_ext) s_monad\" where\n  \"get_arm_global_pt \\<equiv> do\n     pt \\<leftarrow> gets (hd \\<circ> arm_global_pts \\<circ> arch_state);\n     return pt\n   od\"\n\ndefinition\n  write_slot :: \"slot_ptr \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"write_slot slot_ptr cap \\<equiv> do\n     set_cap_local cap slot_ptr;\n     set_original slot_ptr True\n   od\"\n\ndefinition\n  cap_slot_pptr :: \"cap \\<Rightarrow> nat \\<Rightarrow> cslot_ptr\" where\n  \"cap_slot_pptr cap position \\<equiv>\n     (obj_ref_of cap, nat_to_cref (bits_of cap) position)\"\n  (* corresponds to C code: SLOT_PTR(pptr_of_cap(cap), position) for cnodes\n     but NOT TCBs, for that use something like tcb_cnode_index *)\n\ndefinition\n  provide_cap :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"provide_cap root_cnode_cap cap \\<equiv> doE\n     slot_pos_cur \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n     slot_pos_max \\<leftarrow> liftE $ gets ndks_boot_slot_pos_max;\n\n     (* Ran out of free slots in root CNode? *)\n     whenE (slot_pos_cur \\<ge> slot_pos_max) $ throwError InitFailure;\n\n     do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap slot_pos_cur) cap;\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ndks_boot_slot_pos_cur := slot_pos_cur + 1 \\<rparr>)\n   odE\"\n\ndefinition\n  provide_untyped_cap :: \"cap \\<Rightarrow> paddr \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"provide_untyped_cap root_cnode_cap pptr size_bits slot_pos_before \\<equiv> doE\n\n     slot_pos_cur \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n     i \\<leftarrow> returnOk $ slot_pos_cur - slot_pos_before;\n\n     (* the C code writes to index i, but we append, so crosscheck that...\n        this might prove to be overkill, but it's better to remove it during\n        corres proof or such *)\n     ut_objs \\<leftarrow> liftE $ gets (bi_f_ut_obj_paddr_list \\<circ> ki_bootinfo);\n     assertE (length ut_objs = i);\n     ut_objs \\<leftarrow> liftE $ gets (bi_f_ut_obj_size_bits_list \\<circ> ki_bootinfo);\n     assertE (length ut_objs = i);\n\n     (* update ghost bootinfo frame and sync *)\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_ut_obj_paddr_list :=\n         (bi_f_ut_obj_paddr_list $ ki_bootinfo s) @ [pptr],\n       bi_f_ut_obj_size_bits_list :=\n         (bi_f_ut_obj_size_bits_list $ ki_bootinfo s) @ [of_nat size_bits]\n       \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame;\n\n     provide_cap root_cnode_cap $ UntypedCap pptr size_bits 0\n   odE\"\n\ndefinition\n  init_cpu :: \"(unit,'z::state_ext) s_monad\" where\n  \"init_cpu = do\n     do_machine_op cleanCache;\n     global_pd \\<leftarrow> gets (arm_global_pd \\<circ> arch_state);\n     do_machine_op $ setCurrentPD $ addrFromPPtr global_pd\n   od\"\n\ndefinition\n  init_plat :: \"(unit,'z::state_ext) s_monad\" where\n  \"init_plat \\<equiv> do\n     do_machine_op initTimer;\n     do_machine_op initL2Cache\n   od\"\n\ndefinition\n  init_irqs :: \"cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"init_irqs root_cnode_cap \\<equiv> do\n\n     mapM (set_irq_state IRQInactive) [0 .e. maxIRQ];\n     set_irq_state IRQTimer KERNEL_TIMER_IRQ;\n\n     write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IRQ_CTRL) IRQControlCap\n   od\"\n\ndefinition\n  arch_configure_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_configure_idle_thread tcb \\<equiv> do\n     as_user tcb $ set_register CPSR 0x1f;\n     as_user tcb $ setNextPC idle_thread_start\n   od\"\n\ndefinition\n  configure_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"configure_idle_thread tcb \\<equiv> do\n     arch_configure_idle_thread tcb;\n     set_thread_state tcb IdleThreadState\n   od\"\n\ndefinition\n  create_objects :: \"nat \\<Rightarrow> nat \\<Rightarrow> apiobject_type \\<Rightarrow> (paddr,'z::state_ext) ki_monad\"\n  where\n  \"create_objects bits ko_bits ko_typ \\<equiv> doE\n      pptr \\<leftarrow> alloc_region bits;\n      do_kernel_op $ retype_region pptr (bits div ko_bits) ko_bits ko_typ;\n\n      (* previously available memory now contains object: update ghost state *)\n      avail \\<leftarrow> liftE $ gets ki_available_mem;\n      liftE $ modify (\\<lambda>s. s \\<lparr> ki_available_mem :=\n                                avail - {pptr .. pptr + 2 ^ bits - 1} \\<rparr>);\n      (* FIXME: update ki_components ghost state !!! *)\n      returnOk pptr\n   odE\"\n\ndefinition\n  create_idle_thread :: \"(unit,'z::state_ext) ki_monad\" where\n  \"create_idle_thread \\<equiv> doE\n     pptr \\<leftarrow> create_objects (obj_bits $ TCB undefined)\n                           (obj_bits $ TCB undefined) TCBObject;\n     do_kernel_op $ do\n       modify (\\<lambda>s. s \\<lparr> idle_thread := pptr \\<rparr>);\n       configure_idle_thread pptr\n     od\n   odE\"\n\ndefinition\n  create_root_cnode :: \"(cap,'z::state_ext) ki_monad\" where\n  \"create_root_cnode \\<equiv>\n   let sz = (ROOT_CNODE_SIZE_BITS + CTE_SIZE_BITS) in\n   doE\n     liftE $ modify\n               (\\<lambda>s. s \\<lparr> ndks_boot_slot_pos_max := 2 ^ ROOT_CNODE_SIZE_BITS \\<rparr>);\n\n     pptr \\<leftarrow> create_objects sz sz CapTableObject;\n\n     let cap = CNodeCap pptr ROOT_CNODE_SIZE_BITS\n                             (replicate (32 - ROOT_CNODE_SIZE_BITS) False)\n     in (doE\n           do_kernel_op $ write_slot (cap_slot_pptr cap BI_CAP_IT_CNODE) cap;\n           returnOk cap\n         odE)\n   odE\"\n\ndefinition\n  create_irq_cnode :: \"(unit,'z::state_ext) ki_monad\" where\n  \"create_irq_cnode \\<equiv> doE\n     (* Make a page full of cnodes with one CTE each. At the C level\n        this is of course just an array of CTEs taking up the whole page. *)\n     pptr \\<leftarrow> create_objects pageBits CTE_SIZE_BITS CapTableObject;\n\n     (* Now associate each cnode with an irq *)\n     do_kernel_op $ modify\n               (\\<lambda>s. s \\<lparr> interrupt_irq_node :=\n                        (\\<lambda>irq. pptr + ucast irq * of_nat CTE_SIZE_BITS) \\<rparr>)\n   odE\"\n\ndefinition\n  create_it_frame_cap :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> asid option \\<Rightarrow> bool \\<Rightarrow> (cap,'z::state_ext) ki_monad\"\n  where\n  \"create_it_frame_cap pptr vptr asid use_large \\<equiv>\n   let sz = if use_large then ARMLargePage else ARMSmallPage in\n     returnOk $ ArchObjectCap $ PageCap pptr {AllowRead,AllowWrite}\n                                        sz (map_option (\\<lambda>a. (a, vptr)) asid)\"\n\ndefinition\n  create_ipcbuf_frame :: \"cap \\<Rightarrow> (vspace_ref \\<times> vspace_ref)\n                          \\<Rightarrow> (cap \\<times> vspace_ref,'z::state_ext) ki_monad\" where\n  \"create_ipcbuf_frame root_cnode_cap ui_v_reg \\<equiv>\n   let vptr = snd ui_v_reg (* ui_v_reg.end *)\n   in\n   doE\n     pptr \\<leftarrow> alloc_region pageBits;\n     do_kernel_op $ do_machine_op $ clearMemory pptr pageBits;\n\n     cap \\<leftarrow> create_it_frame_cap pptr vptr (Some IT_ASID) False;\n\n     do_kernel_op $\n       write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_IPCBUF) cap;\n\n     returnOk (cap, vptr)\n   odE\"\n\ndefinition\n  create_bi_frame :: \"cap \\<Rightarrow> (vspace_ref \\<times> vspace_ref) \\<Rightarrow> vspace_ref \\<Rightarrow> word32\n                      \\<Rightarrow> word32 \\<Rightarrow> (vspace_ref,'z::state_ext) ki_monad\" where\n  \"create_bi_frame root_cnode_cap ui_v_reg ipcbuf_vptr node_id num_nodes \\<equiv>\n   let vptr = ipcbuf_vptr + of_nat (2 ^ pageBits)\n   in\n   doE\n     pptr \\<leftarrow> alloc_region BI_FRAME_SIZE_BITS;\n\n     (* update in abstract representation of boot info frame *)\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_node_id := node_id,\n       bi_f_num_nodes := num_nodes,\n       bi_f_num_iopt_levels := 0,\n       bi_f_ipcbuf_vptr := ipcbuf_vptr,\n       bi_f_it_cnode_size_bits := of_nat ROOT_CNODE_SIZE_BITS \\<rparr>\\<rparr>);\n\n     (* synchronise abstract bootinfo with boot info frame *)\n     sync_bootinfo_frame pptr;\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ndks_boot_bi_frame := pptr,\n                             ndks_boot_slot_pos_cur := BI_CAP_DYN_START \\<rparr> );\n\n     cap \\<leftarrow> create_it_frame_cap pptr vptr (Some IT_ASID) False;\n     do_kernel_op $\n       write_slot (cap_slot_pptr root_cnode_cap BI_CAP_BI_FRAME) cap;\n\n     returnOk vptr\n   odE\"\n\ndefinition\n  create_it_asid_pool :: \"cap \\<Rightarrow> (cap,'z::state_ext) ki_monad\" where\n  \"create_it_asid_pool root_cnode_cap \\<equiv> doE\n\n     (* create ASID pool *)\n     ap_pptr \\<leftarrow> create_objects ASID_POOL_SIZE_BITS\n                              ASID_POOL_SIZE_BITS (ArchObject ASIDPoolObj);\n\n     ap_cap \\<leftarrow> returnOk $ ArchObjectCap $\n                 ASIDPoolCap ap_pptr (IT_ASID >> asid_low_bits);\n\n     do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap\n                                BI_CAP_IT_ASID_POOL) ap_cap;\n\n     (* create ASID control cap *)\n     do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap BI_CAP_ASID_CTRL)\n                               (ArchObjectCap ASIDControlCap);\n\n     returnOk ap_cap\n   odE\"\n\ndefinition\n  create_frames_of_region :: \"cap \\<Rightarrow> (paddr \\<times> paddr) \\<Rightarrow> bool \\<Rightarrow> word32\n                              \\<Rightarrow> (nat \\<times> nat,'z::state_ext) ki_monad\" where\n  \"create_frames_of_region root_cnode_cap reg do_map pv_offset \\<equiv> doE\n\n     slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     (swp mapME)\n       [(fst reg),(fst reg + of_nat (2 ^ pageBits)) .e. (snd reg - 1)]\n       (\\<lambda>f. doE\n              frame_cap \\<leftarrow> (if do_map\n                           then create_it_frame_cap f\n                                  (f - BASE_OFFSET - pv_offset) (Some IT_ASID) False\n                           else create_it_frame_cap f 0 None False);\n              provide_cap root_cnode_cap frame_cap\n            odE);\n\n     slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     returnOk (slot_pos_before, slot_pos_after)\n   odE\"\n\ndefinition\n  write_it_asid_pool :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"write_it_asid_pool it_ap_cap it_pd_cap \\<equiv>\n   let ap_ptr = obj_ref_of it_ap_cap;\n       pd_ptr = obj_ref_of it_pd_cap;\n       asid_idx = ucast (IT_ASID >> asid_low_bits)\n   in\n   do\n     ap \\<leftarrow> get_asid_pool ap_ptr;\n     ap' \\<leftarrow> return (ap (ucast IT_ASID \\<mapsto> pd_ptr));\n     set_asid_pool ap_ptr ap';\n\n     asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n     asid_table' \\<leftarrow> return (asid_table(asid_idx \\<mapsto> ap_ptr));\n     modify (\\<lambda>s. s \\<lparr> arch_state :=\n                      arch_state s \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>)\n\n   od\"\n\ndefinition\n  map_it_pt_cap :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"map_it_pt_cap pd_cap pt_cap \\<equiv> do\n\n     pd \\<leftarrow> return $ obj_ref_of pd_cap; (* C uses specific PD version *)\n\n     (pt,vptr) \\<leftarrow> return $ case the_arch_cap pt_cap\n                            of PageTableCap ref (Some (_, vref)) \\<Rightarrow> (ref,vref);\n\n     slot \\<leftarrow> return $ vptr >> pageBitsForSize ARMSection;\n\n     (* C code sets ParityEnable bit, which is apparently to enable ECC *)\n     pde \\<leftarrow> return $ PageTablePDE (addrFromPPtr pt) {ParityEnabled} 0;\n\n     pd_obj \\<leftarrow> get_object pd;\n     pd_obj' \\<leftarrow> return (case pd_obj\n                         of ArchObj (PageDirectory table)\n                            \\<Rightarrow> ArchObj (PageDirectory $ table(ucast slot := pde)\n                       ));\n     set_object pd pd_obj'\n   od\"\n\ndefinition\n  map_it_frame_cap :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"map_it_frame_cap pd_cap frame_cap \\<equiv> do\n\n     pd \\<leftarrow> return $ obj_ref_of pd_cap;\n\n     (frame, vptr) \\<leftarrow> return $ case the_arch_cap frame_cap\n                       of PageCap ref _ _ (Some (_, vptr)) \\<Rightarrow> (ref, vptr);\n\n     pd_obj \\<leftarrow> get_object pd;\n     pde \\<leftarrow> return $ case pd_obj\n                      of ArchObj (PageDirectory table)\n                         \\<Rightarrow> table (ucast (vptr >> pageBitsForSize ARMSection));\n\n     pt \\<leftarrow> return (case pde of PageTablePDE ref _ _ \\<Rightarrow> ptrFromPAddr ref);\n\n     slot \\<leftarrow> return $ (vptr && mask (pageBitsForSize ARMSection))\n                              >> pageBitsForSize ARMSmallPage;\n\n     pte \\<leftarrow> return $ SmallPagePTE (addrFromPPtr frame) {PageCacheable}\n                                 vm_read_write;\n     pt_obj \\<leftarrow> get_object pt;\n     pt_obj' \\<leftarrow> return (case pt_obj\n                         of ArchObj (PageTable table)\n                            \\<Rightarrow> ArchObj (PageTable $ table(ucast slot := pte)));\n     set_object pt pt_obj'\n   od\"\n\ndefinition\n  write_it_pd_pts :: \"cap \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"write_it_pd_pts root_cnode_cap it_pd_cap \\<equiv> doE\n\n     do_kernel_op $ copy_global_mappings $ obj_ref_of it_pd_cap;\n\n     (* map PTs into PD *)\n     (start, end) \\<leftarrow> liftE $ gets (bi_f_ui_pt_caps \\<circ> ki_bootinfo);\n\n     do_kernel_op $\n       (swp mapM)\n          [start..<end]\n          (\\<lambda>pos. do\n                   cap \\<leftarrow> get_cap_local $ cap_slot_pptr root_cnode_cap pos;\n                   map_it_pt_cap it_pd_cap cap\n                 od);\n\n     (* map frames into PTs *)\n     (start, end) \\<leftarrow> liftE $ gets (bi_f_ui_frame_caps \\<circ> ki_bootinfo);\n\n     do_kernel_op (do\n       (swp mapM)\n          [start..<end]\n          (\\<lambda>pos. do\n                   cap \\<leftarrow> get_cap_local $ cap_slot_pptr root_cnode_cap pos;\n                   map_it_frame_cap it_pd_cap cap\n                 od);\n\n       cap \\<leftarrow> get_cap_local $ cap_slot_pptr root_cnode_cap BI_CAP_IT_IPCBUF;\n       map_it_frame_cap it_pd_cap cap;\n       cap \\<leftarrow> get_cap_local $ cap_slot_pptr root_cnode_cap BI_CAP_BI_FRAME;\n       map_it_frame_cap it_pd_cap cap\n     od)\n   odE\"\n\ndefinition\n  bi_finalise :: \"(unit,'z::state_ext) ki_monad\" where\n  \"bi_finalise \\<equiv> doE\n     slot_pos_start \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n     slot_pos_end \\<leftarrow> liftE $ gets ndks_boot_slot_pos_max;\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_null_caps := (of_nat slot_pos_start, of_nat slot_pos_end) \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame\n   odE\"\n\ndefinition\n  create_it_pd_pts :: \"cap \\<Rightarrow> (vspace_ref \\<times> vspace_ref) \\<Rightarrow> vspace_ref\n                       \\<Rightarrow> vspace_ref \\<Rightarrow> (cap,'z::state_ext) ki_monad\" where\n  \"create_it_pd_pts root_cnode_cap ui_v_reg ipcbuf_vptr bi_frame_vptr \\<equiv> doE\n\n     (* create PD obj and cap *)\n     pd_pptr \\<leftarrow> create_objects PD_SIZE_BITS PD_SIZE_BITS\n                              (ArchObject PageDirectoryObj);\n     pd_cap \\<leftarrow> returnOk $ ArchObjectCap $\n                           PageDirectoryCap pd_pptr (Some IT_ASID);\n     do_kernel_op $ write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_PD)\n                               pd_cap;\n\n     (* include IPC buffer and bootinfo frames in the userland image *)\n     (ui_v_reg_start, ui_v_reg_end) \\<leftarrow>\n         returnOk (fst ui_v_reg, bi_frame_vptr + 2 ^ BI_FRAME_SIZE_BITS);\n\n     (* create all PT objs and caps necessary to cover userland image *)\n     slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     start \\<leftarrow> returnOk $ round_down ui_v_reg_start (PD_BITS + pageBits);\n     next \\<leftarrow> returnOk $ start + (2 ^ (PT_BITS + pageBits));\n\n     (swp mapME) [start,next .e. ui_v_reg_end] (\\<lambda>pt_vptr. doE\n\n       pt_pptr \\<leftarrow> alloc_region PT_SIZE_BITS;\n       do_kernel_op $ retype_region pt_pptr 1 PT_SIZE_BITS\n                                            (ArchObject PageTableObj);\n\n       provide_cap root_cnode_cap $\n         ArchObjectCap $ PageTableCap pt_pptr (Some (IT_ASID, pt_vptr))\n     odE);\n\n     slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_ui_pt_caps := (of_nat slot_pos_before, of_nat slot_pos_after) \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame;\n\n     returnOk pd_cap\n   odE\"\n\ndefinition\n  create_initial_thread :: \"cap \\<Rightarrow> cap \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref\n                            \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_initial_thread root_cnode_cap it_pd_cap ui_v_entry bi_frame_vptr\n                         ipcbuf_vptr ipcbuf_cap \\<equiv>\n   let tcb_bits = obj_bits $ TCB undefined\n   in\n   doE\n\n   (* allocate TCB *)\n   tcb_pptr \\<leftarrow> create_objects tcb_bits tcb_bits TCBObject;\n   (* Arch_initContext should be implicit in retype_region *)\n\n   do_kernel_op $ (do\n     cap_insert_local root_cnode_cap (cap_slot_pptr root_cnode_cap BI_CAP_IT_CNODE)\n                               (tcb_pptr, tcb_cnode_index 0); (* tcbCTable *)\n     cap_insert_local root_cnode_cap (cap_slot_pptr root_cnode_cap BI_CAP_IT_PD)\n                               (tcb_pptr, tcb_cnode_index 1); (* tcbVTable *)\n     cap_insert_local root_cnode_cap (cap_slot_pptr root_cnode_cap BI_CAP_IT_IPCBUF)\n                               (tcb_pptr, tcb_cnode_index 4); (* tcbBuffer *)\n\n     tcb_obj \\<leftarrow> get_object tcb_pptr;\n     tcb_obj' \\<leftarrow> return $\n                case tcb_obj\n                  of TCB tcb \\<Rightarrow> TCB (tcb\\<lparr>tcb_ipc_buffer := ipcbuf_vptr\\<rparr>);\n     set_object tcb_pptr tcb_obj';\n\n     as_user tcb_pptr $ set_register CPSR 0x1f;\n     as_user tcb_pptr $ setNextPC ui_v_entry;\n\n     (* TCB priority not in abstract spec *)\n     setup_reply_master_local tcb_pptr;\n     set_thread_state tcb_pptr Running;\n     (* scheduler action not in abstract spec *)\n     idle_thread \\<leftarrow> gets idle_thread;\n     modify (\\<lambda>s. s\\<lparr> cur_thread := idle_thread \\<rparr>);\n\n     switch_to_thread tcb_pptr;\n\n     cap \\<leftarrow> return $ ThreadCap tcb_pptr;\n     write_slot (cap_slot_pptr root_cnode_cap BI_CAP_IT_TCB) cap\n   od)\n   odE\"\n\ndefinition\n  create_device_frames :: \"cap \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_device_frames root_cnode_cap \\<equiv> doE\n     dev_regs \\<leftarrow> do_kernel_op $ do_machine_op getDeviceRegions;\n\n     (swp mapME) dev_regs (\\<lambda>(start,end). doE\n       (* use 1M frames if possible, else 4K frames *)\n       frame_size \\<leftarrow>\n         returnOk $ if (is_aligned start (pageBitsForSize ARMSection)\n                        \\<and> is_aligned end (pageBitsForSize ARMSection))\n                    then ARMSection\n                    else ARMSmallPage;\n\n       slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n       (swp mapME) [start,(start + 2^(pageBitsForSize frame_size))\n                       .e. (end - 1)]\n         (\\<lambda>f. doE\n                frame_cap \\<leftarrow> create_it_frame_cap f 0 None\n                                                (frame_size = ARMSection);\n                provide_cap root_cnode_cap frame_cap\n              odE);\n\n       slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n       bi_dev_reg \\<leftarrow> returnOk (addrFromPPtr start,\n                              of_nat (pageBitsForSize frame_size),\n                              (slot_pos_before, slot_pos_after));\n\n       liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n         bi_f_dev_reg_list := (bi_f_dev_reg_list $\n                                 ki_bootinfo s) @ [bi_dev_reg]\n         \\<rparr>\\<rparr>);\n\n       bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n       sync_bootinfo_frame bi_frame\n\n     odE);\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_num_dev_regs := of_nat $ length (bi_f_dev_reg_list $\n                                               ki_bootinfo s)\n       \\<rparr>\\<rparr>);\n\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame\n   odE\"\n\nfun (* for (ptr,bits)-style regions which don't straddle the end of memory *)\n  no_region_overlap :: \"(paddr \\<times> nat) \\<Rightarrow> (paddr \\<times> nat) \\<Rightarrow> bool\" where\n  \"no_region_overlap (ptr1,bits1) (ptr2,bits2) =\n     ({ptr1 .. ptr1 + 2 ^ bits1 - 1} \\<inter> {ptr2 .. ptr2 + 2 ^ bits2 - 1} = {})\"\n\ndefinition\n  freemem_regions :: \"obj_ref set \\<Rightarrow> ((paddr \\<times> nat) list,'z::state_ext) s_monad\" where\n  \"freemem_regions free \\<equiv> do\n     regs \\<leftarrow> select {lst. (\\<forall>(ptr,bits) \\<in> set lst. is_aligned ptr bits \\<and>\n                                           {ptr .. ptr + 2 ^ bits - 1} \\<subseteq> free)\n                         \\<and> distinct_prop no_region_overlap lst};\n     return regs\n   od\"\n\ndefinition\n  create_untyped_obj :: \"cap \\<Rightarrow> (paddr \\<times> paddr) \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"create_untyped_obj root_cnode_cap boot_mem_reuse_reg \\<equiv> doE\n\n     slot_pos_before \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     (* re-use boot code/data frames *)\n     (swp mapME) [fst boot_mem_reuse_reg,(fst boot_mem_reuse_reg + 2^pageBits)\n                   .e. (snd boot_mem_reuse_reg - 1)]\n                  (\\<lambda>i. provide_untyped_cap root_cnode_cap i pageBits\n                                           slot_pos_before);\n\n     (* allocate and provide the minimum number of 4K UT objects requested *)\n     slot_pos_cur \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n     (swp mapME) [(slot_pos_cur - slot_pos_before)..<MIN_NUM_4K_UNTYPED_OBJ]\n       (\\<lambda>i. doE\n              pptr \\<leftarrow> alloc_region pageBits;\n              provide_untyped_cap root_cnode_cap pptr pageBits slot_pos_before\n            odE);\n\n     (* convert remaining freemem into UT objects and provide the caps *)\n     (* using non-determinism to the max *)\n     freemem \\<leftarrow> liftE $ gets ki_free_mem;\n     freeregs \\<leftarrow> do_kernel_op $ freemem_regions freemem;\n\n     (swp mapME) (take MAX_NUM_FREEMEM_REG freeregs)\n       (\\<lambda>(start,bits). provide_untyped_cap root_cnode_cap start bits\n                                           slot_pos_before);\n\n     slot_pos_after \\<leftarrow> liftE $ gets ndks_boot_slot_pos_cur;\n\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_ut_obj_caps := (slot_pos_before, slot_pos_after) \\<rparr>\\<rparr>);\n\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame\n   odE\"\n\ndefinition\n  map_kernel_frame :: \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vm_rights \\<Rightarrow> vm_attributes\n                       \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"map_kernel_frame paddr vaddr vm_rights attributes \\<equiv> do\n\n     idx \\<leftarrow> return $ (vaddr && mask (pageBitsForSize ARMSection))\n                    >> pageBitsForSize ARMSmallPage;\n\n     global_pt \\<leftarrow> get_arm_global_pt;\n\n     pte \\<leftarrow> return $ SmallPagePTE paddr attributes vm_rights;\n\n     store_pte (global_pt + (idx << PTE_SIZE_BITS)) pte\n   od\"\n\n\ndefinition (* from plat/imx31/machine/hardware.c *)\n  map_kernel_devices :: \"(unit,'z::state_ext) s_monad\" where\n  \"map_kernel_devices \\<equiv> do\n     map_kernel_frame EPIT_PADDR EPIT_PPTR vm_kernel_only\n                      {ParityEnabled,PageCacheable};\n     map_kernel_frame AVIC_PADDR AVIC_PPTR vm_kernel_only\n                      {ParityEnabled,PageCacheable};\n     map_kernel_frame L2CC_PADDR L2CC_PPTR vm_kernel_only\n                      {ParityEnabled,PageCacheable}\n   od\"\n\ndefinition\n  map_kernel_window :: \"(unit,'z::state_ext) s_monad\" where\n  \"map_kernel_window \\<equiv> do\n\n     global_pd \\<leftarrow> gets (arm_global_pd \\<circ> arch_state);\n\n     (* initial index into the PD, guaranteed to be divisible by 16 *)\n     idx \\<leftarrow> return $ kernel_base >> pageBitsForSize ARMSection;\n     (* first physical address we'll map *)\n     phys \\<leftarrow> return $ physBase;\n\n     (* map physBase at kernel_base 16M at a time, but not final supersection *)\n\n     iterations \\<leftarrow> return ((2^(PD_BITS) - idx) >> 4);\n\n     (swp mapM) [0 .e. iterations - 1] (\\<lambda>i. do\n         idx' \\<leftarrow> return $ idx + i * 16;\n         phys' \\<leftarrow> return $ phys + i * (2^(pageBitsForSize(ARMSuperSection)));\n\n         pde \\<leftarrow> return $ SuperSectionPDE phys' {ParityEnabled,PageCacheable}\n                                         vm_kernel_only;\n\n         (* write 16 section entries for this supersection *)\n         mapM (\\<lambda>offs. store_pde (idx' + offs) pde) [0 .e. 15]\n       od);\n\n     (* advance idx and phys to match exit of C loop *)\n     idx \\<leftarrow> return $ idx + iterations * 16; (* should be 2^PD_BITS - 16 *)\n     phys \\<leftarrow> return $ phys + iterations * (2^pageBitsForSize(ARMSuperSection));\n\n     (* next 15M mapped using 1M frames *)\n\n     (swp mapM) [0 .e. 14] (\\<lambda>i. do\n         phys' \\<leftarrow> return $ phys + i * (2^(pageBitsForSize(ARMSection)));\n         pde \\<leftarrow> return $ SectionPDE phys' {ParityEnabled,PageCacheable} 0\n                                   vm_kernel_only;\n         store_pde (idx + i) pde\n       od);\n\n     (* advance idx and phys to match exit of C loop *)\n     idx \\<leftarrow> return $ idx + 15; (* should be 2^PD_BITS - 1 *)\n     phys \\<leftarrow> return $ phys + 15 * (2^pageBitsForSize(ARMSection));\n\n     (* now map global PT into last slot in global PD  *)\n     global_pt \\<leftarrow> get_arm_global_pt;\n     pde \\<leftarrow> return $ PageTablePDE (addrFromPPtr global_pt) {ParityEnabled} 0;\n     store_pde idx pde;\n\n     (* init the PT *)\n     retype_region global_pt 1 PT_SIZE_BITS\n                   (ArchObject PageTableObj);\n\n     (* map vector table *)\n     map_kernel_frame (addrFromPPtr arm_vector_table) PPTR_VECTOR_TABLE\n                      vm_kernel_only {ParityEnabled,PageCacheable};\n\n     (* map globals frame *)\n     globals_frame \\<leftarrow> gets (arm_globals_frame \\<circ> arch_state);\n     map_kernel_frame (addrFromPPtr globals_frame) PPTR_GLOBALS_PAGE\n                      vm_read_only {ParityEnabled,PageCacheable};\n\n     (* map stack frame *)\n     map_kernel_frame (addrFromPPtr arm_kernel_stack) PPTR_KERNEL_STACK\n                      vm_kernel_only {ParityEnabled,PageCacheable};\n\n     map_kernel_devices\n   od\"\n\n\n\ndefinition\n  paddr_to_pptr_reg :: \"(paddr \\<times> paddr) \\<Rightarrow> (paddr \\<times> paddr)\" where\n  \"paddr_to_pptr_reg p_reg \\<equiv> (fst p_reg + pptrBaseOffset,\n                              snd p_reg + pptrBaseOffset)\"\n\ndefinition\n  init_kernel :: \"paddr \\<Rightarrow> paddr \\<Rightarrow> word32 \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) ki_monad\" where\n  \"init_kernel ui_p_reg_start ui_p_reg_end pv_offset v_entry \\<equiv>\n   let ui_v_reg_start = ui_p_reg_start - pv_offset;\n       ui_v_reg_end = ui_p_reg_end - pv_offset;\n       ui_v_reg = (ui_v_reg_start, ui_v_reg_end);\n       ui_reg = paddr_to_pptr_reg (ui_p_reg_start, ui_p_reg_end)\n   in\n   doE\n     do_kernel_op $ map_kernel_window;\n     do_kernel_op $ init_cpu;\n     do_kernel_op $ init_plat;\n     init_freemem ui_reg;\n     root_cnode_cap \\<leftarrow> create_root_cnode;\n     create_irq_cnode;\n     do_kernel_op $ init_irqs root_cnode_cap;\n     (* create initial thread's ipc buffer *)\n     ipcbuf_ret \\<leftarrow> create_ipcbuf_frame root_cnode_cap ui_v_reg;\n\n     bi_frame_vptr \\<leftarrow> create_bi_frame root_cnode_cap ui_v_reg\n                                     (snd ipcbuf_ret) 0 1;\n\n     (* create userland image frame objs, store info in bootinfo frame *)\n     ui_fr_caps \\<leftarrow> create_frames_of_region root_cnode_cap ui_reg True pv_offset;\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_ui_frame_caps := ui_fr_caps \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame;\n\n     (* create/init PDs and PTs for userland image *)\n     it_pd_cap \\<leftarrow> create_it_pd_pts root_cnode_cap ui_v_reg (snd ipcbuf_ret)\n                                   bi_frame_vptr;\n     write_it_pd_pts root_cnode_cap it_pd_cap;\n\n     (* create/init initial thread's ASID pool *)\n     it_ap_cap \\<leftarrow> create_it_asid_pool root_cnode_cap;\n     do_kernel_op $ write_it_asid_pool it_ap_cap it_pd_cap;\n\n     create_idle_thread;\n\n     (* create_initial_thread *)\n     create_initial_thread root_cnode_cap it_pd_cap v_entry bi_frame_vptr\n                           (snd ipcbuf_ret) (fst ipcbuf_ret);\n\n     (* create_untyped_obj (reclaim boot code/data) *)\n     create_untyped_obj root_cnode_cap (kernel_base, ki_boot_end);\n\n     (* create_device_frames *)\n     create_device_frames root_cnode_cap;\n\n     (* no shared frame caps (ARM = no multikernel) *)\n     liftE $ modify (\\<lambda>s. s \\<lparr> ki_bootinfo := (ki_bootinfo s) \\<lparr>\n       bi_f_sh_frame_caps := (0,0) \\<rparr>\\<rparr>);\n     bi_frame \\<leftarrow> liftE $ gets ndks_boot_bi_frame;\n     sync_bootinfo_frame bi_frame;\n\n     bi_finalise;\n\n     do_kernel_op $ do_machine_op cleanCache\n   odE\n  \"\n\nend"}
{"title": "./spec/abstract/Invocations_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nData types for syscall invocations\n*)\n\nchapter \"Kernel Object Invocations\"\n\ntheory Invocations_A\nimports ArchInvocation_A\nbegin\n\narch_requalify_types (A)\n  arch_copy_register_sets\n  arch_irq_control_invocation\n  arch_invocation\n\ntext \\<open>These datatypes encode the arguments to the available system calls.\\<close>\n\ndatatype cnode_invocation =\n    InsertCall cap cslot_ptr cslot_ptr\n  | MoveCall cap cslot_ptr cslot_ptr\n  | RevokeCall cslot_ptr\n  | DeleteCall cslot_ptr\n  | RotateCall cap cap cslot_ptr cslot_ptr cslot_ptr\n  | SaveCall cslot_ptr\n  | CancelBadgedSendsCall cap\n\ndatatype untyped_invocation =\n    Retype cslot_ptr bool obj_ref obj_ref apiobject_type nat \"cslot_ptr list\" bool\n\ndatatype tcb_invocation =\n    WriteRegisters machine_word bool \"machine_word list\" arch_copy_register_sets\n  | ReadRegisters machine_word bool machine_word arch_copy_register_sets\n  | CopyRegisters machine_word machine_word bool bool bool bool arch_copy_register_sets\n  | ThreadControl (tc_target: machine_word) (tc_slot: cslot_ptr)\n                  (tc_new_fault_ep: \"cap_ref option\")\n                  (tc_new_mcpriority: \"(word8 * obj_ref) option\")\n                  (tc_new_priority: \"(word8 * obj_ref) option\")\n                  (tc_new_croot: \"(cap * cslot_ptr) option\")\n                  (tc_new_vroot: \"(cap * cslot_ptr) option\")\n                  (tc_new_buffer: \"(vspace_ref * (cap * cslot_ptr) option) option\")\n  | Suspend \"obj_ref\"\n  | Resume \"obj_ref\"\n  | NotificationControl \"obj_ref\" \"obj_ref option\"\n  | SetTLSBase obj_ref machine_word\n\ndatatype irq_control_invocation =\n    IRQControl irq cslot_ptr cslot_ptr\n  | ArchIRQControl arch_irq_control_invocation\n\ndatatype irq_handler_invocation =\n    ACKIrq irq\n  | SetIRQHandler irq cap cslot_ptr\n  | ClearIRQHandler irq\n\ndatatype invocation =\n    InvokeUntyped untyped_invocation\n  | InvokeEndpoint obj_ref machine_word bool bool\n  | InvokeNotification obj_ref machine_word\n  | InvokeReply obj_ref cslot_ptr bool\n  | InvokeTCB tcb_invocation\n  | InvokeDomain obj_ref word8\n  | InvokeCNode cnode_invocation\n  | InvokeIRQControl irq_control_invocation\n  | InvokeIRQHandler irq_handler_invocation\n  | InvokeArchObject arch_invocation\n\nend"}
{"title": "./spec/abstract/CSpaceAcc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nAccessor functions for capability spaces.\n*)\n\nchapter \"Accessing CSpace\"\n\ntheory CSpaceAcc_A\nimports KHeap_A\nbegin\n\ntext \\<open>\nThis theory contains basic definitions for manipulating capabilities and\nCDTs.\n\\<close>"}
{"title": "./spec/abstract/CSpaceAcc_A.thy", "section": "Accessing the capability derivation tree", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n Recall that a capability may reside in either a CNode, or inside a TCB;\nthe following definitions allow the kernel model to retrieve and update\ncapabilities in a uniform fashion.\\<close>\ndefinition\n  get_cap :: \"cslot_ptr \\<Rightarrow> (cap,'z::state_ext) s_monad\"\nwhere\n  \"get_cap \\<equiv> \\<lambda>(oref, cref). do\n     obj \\<leftarrow> get_object oref;\n     caps \\<leftarrow> case obj of\n             CNode sz cnode \\<Rightarrow> do\n                                assert (well_formed_cnode_n sz cnode);\n                                return cnode\n                              od\n           | TCB tcb     \\<Rightarrow> return (tcb_cnode_map tcb)\n           | _ \\<Rightarrow> fail;\n     assert_opt (caps cref)\n   od\"\n\ndefinition\n  set_cap :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_cap cap \\<equiv> \\<lambda>(oref, cref). do\n     obj \\<leftarrow> get_object oref;\n     obj' \\<leftarrow> case obj of\n               CNode sz cn \\<Rightarrow> if cref \\<in> dom cn \\<and> well_formed_cnode_n sz cn\n                                then return $ CNode sz $ cn (cref \\<mapsto> cap)\n                                else fail\n             | TCB tcb \\<Rightarrow>\n                   if cref = tcb_cnode_index 0 then\n                       return $ TCB $ tcb \\<lparr> tcb_ctable := cap \\<rparr>\n                   else if cref = tcb_cnode_index 1 then\n                       return $ TCB $ tcb \\<lparr> tcb_vtable := cap \\<rparr>\n                   else if cref = tcb_cnode_index 2 then\n                       return $ TCB $ tcb \\<lparr> tcb_reply := cap \\<rparr>\n                   else if cref = tcb_cnode_index 3 then\n                       return $ TCB $ tcb \\<lparr> tcb_caller := cap \\<rparr>\n                   else if cref = tcb_cnode_index 4 then\n                       return $ TCB $ tcb \\<lparr> tcb_ipcframe := cap \\<rparr>\n                   else\n                       fail\n             | _ \\<Rightarrow> fail;\n     set_object oref obj'\n  od\"\n\ntext \\<open>Ensure a capability slot is empty.\\<close>\ndefinition\n  ensure_empty :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"ensure_empty slot \\<equiv> doE\n    cap \\<leftarrow> liftE $ get_cap slot;\n    whenE (cap \\<noteq> NullCap) (throwError DeleteFirst)\n  odE\""}
{"title": "./spec/abstract/CSpaceAcc_A.thy", "section": "Accessing the capability derivation tree", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Set the capability derivation tree.\\<close>\ndefinition\n  set_cdt :: \"cdt \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_cdt t \\<equiv> do\n    s \\<leftarrow> get;\n    put $ s\\<lparr> cdt := t \\<rparr>\n  od\"\n\ntext \\<open>Update the capability derivation tree.\\<close>\ndefinition\n  update_cdt :: \"(cdt \\<Rightarrow> cdt) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"update_cdt f \\<equiv> do\n     t \\<leftarrow> gets cdt;\n     set_cdt (f t)\n  od\"\n\ntext \\<open>Set the original flag for a given cap slot.\\<close>\ndefinition\n  set_original :: \"cslot_ptr \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_original slot v \\<equiv> do\n     r \\<leftarrow> gets is_original_cap;\n     modify (\\<lambda>s. s \\<lparr> is_original_cap := r (slot := v) \\<rparr>)\n  od\"\n\ntext \\<open>Definitions and syntax for predicates on capability derivation.\\<close>\ndefinition\n  is_cdt_parent :: \"cdt \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\" where\n  \"is_cdt_parent t p c \\<equiv> t c = Some p\"\n\ndefinition\n  cdt_parent_rel :: \"cdt \\<Rightarrow> (cslot_ptr \\<times> cslot_ptr) set\" where\n  \"cdt_parent_rel t \\<equiv> {(p,c). is_cdt_parent t p c}\"\n\nabbreviation\n  parent_of :: \"cdt \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of _\" [60,0,60] 61)\nwhere\n  \"t \\<turnstile> p cdt_parent_of c \\<equiv> (p,c) \\<in> cdt_parent_rel t\"\n\nabbreviation\n  parent_of_trancl :: \"cdt \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>+ _\" [60,0,60] 61)\nwhere\n  \"t \\<turnstile> x cdt_parent_of\\<^sup>+ y \\<equiv> (x, y) \\<in> (cdt_parent_rel t)\\<^sup>+\"\n\nabbreviation\n  parent_of_rtrancl :: \"cdt \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\"\n  (\"_ \\<turnstile> _ cdt'_parent'_of\\<^sup>* _\" [60,0,60] 61)\nwhere\n  \"t \\<turnstile> x cdt_parent_of\\<^sup>* y \\<equiv> (x, y) \\<in> (cdt_parent_rel t)\\<^sup>*\"\n\n\nnotation\n  parent_of (\"_ \\<Turnstile> _ \\<leadsto> _\" [60,0,60] 60)\nand\n  parent_of_trancl (\"_ \\<Turnstile> _ \\<rightarrow> _\" [60,0,60] 60)\nand\n  parent_of_rtrancl (\"_ \\<Turnstile> _ \\<rightarrow>* _\" [60,0,60] 60)\n\ntext \\<open>The set of descendants of a particular slot in the CDT.\\<close>\ndefinition\n  descendants_of :: \"cslot_ptr \\<Rightarrow> cdt \\<Rightarrow> cslot_ptr set\" where\n  \"descendants_of p t \\<equiv> {q. (p,q) \\<in> (cdt_parent_rel t)\\<^sup>+}\"\n\nend"}
{"title": "./spec/abstract/Ipc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nSpecification of Inter-Process Communication.\n*)\n\nchapter \"IPC\"\n\ntheory Ipc_A\nimports Tcb_A ArchFault_A\nbegin\n\narch_requalify_consts (A)\n  lookup_ipc_buffer\n  make_arch_fault_msg\n  handle_arch_fault_reply"}
{"title": "./spec/abstract/Ipc_A.thy", "section": "IPC Capability Transfers", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  get_message_info :: \"obj_ref \\<Rightarrow> (message_info,'z::state_ext) s_monad\"\nwhere\n  \"get_message_info thread \\<equiv> do\n     x \\<leftarrow> as_user thread $ getRegister msg_info_register;\n     return $ data_to_message_info x\n   od\""}
{"title": "./spec/abstract/Ipc_A.thy", "section": "Fault Handling", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  remove_rights :: \"cap_rights \\<Rightarrow> cap \\<Rightarrow> cap\"\nwhere\n \"remove_rights rights cap \\<equiv> cap_rights_update (cap_rights cap - rights) cap\"\n\ntext \\<open>In addition to the data payload a message may also contain capabilities.\nWhen a thread requests additional capabilities be transferred the identities of\nthose capabilities are retreived from the thread's IPC buffer.\\<close>\ndefinition\n  buffer_cptr_index :: nat\nwhere\n \"buffer_cptr_index \\<equiv> (msg_max_length + 2)\"\n\nprimrec\n  get_extra_cptrs :: \"obj_ref option \\<Rightarrow> message_info \\<Rightarrow> (cap_ref list,'z::state_ext) s_monad\"\nwhere\n  \"get_extra_cptrs (Some buf) mi =\n    (liftM (map data_to_cptr) $ mapM (load_word_offs buf)\n        [buffer_cptr_index ..< buffer_cptr_index + (unat (mi_extra_caps mi))])\"\n| \"get_extra_cptrs None mi = return []\"\n\ndefinition\n  get_extra_cptr :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> (cap_ref,'z::state_ext) s_monad\"\nwhere\n  \"get_extra_cptr buffer n \\<equiv> liftM data_to_cptr\n      (load_word_offs buffer (n + buffer_cptr_index))\"\n\ntext \\<open>This function both looks up the addresses of the additional capabilities\nand retreives them from the sender's CSpace.\\<close>\ndefinition\n  lookup_extra_caps :: \"obj_ref \\<Rightarrow> data option \\<Rightarrow> message_info \\<Rightarrow> ((cap \\<times> cslot_ptr) list,'z::state_ext) f_monad\" where\n  \"lookup_extra_caps thread buffer mi \\<equiv> doE\n       cptrs \\<leftarrow> liftE $ get_extra_cptrs buffer mi;\n       mapME (\\<lambda>cptr. cap_fault_on_failure (of_bl cptr) False $ lookup_cap_and_slot thread cptr) cptrs\n  odE\"\n\ntext \\<open>Capability transfers. Capabilities passed along with a message are split\ninto two groups. Capabilities to the same endpoint as the message is passed\nthrough are not copied. Their badges are unwrapped and stored in the receiver's\nmessage buffer instead. Other capabilities are copied into the given slots.\n\nCapability unwrapping allows a client to efficiently demonstrate to a server\nthat it possesses authority to two or more services that server provides.\n\\<close>\ndefinition\n  set_extra_badge :: \"obj_ref \\<Rightarrow> machine_word \\<Rightarrow> nat \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_extra_badge buffer badge n \\<equiv>\n      store_word_offs buffer (buffer_cptr_index + n) badge\"\n\ntype_synonym transfer_caps_data = \"(cap \\<times> cslot_ptr) list \\<times> cslot_ptr list\"\n\nfun\n  transfer_caps_loop :: \"obj_ref option \\<Rightarrow> obj_ref \\<Rightarrow> nat\n                          \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> cslot_ptr list\n                          \\<Rightarrow> message_info \\<Rightarrow> (message_info,'z::state_ext) s_monad\"\nwhere\n  \"transfer_caps_loop ep rcv_buffer n [] slots\n      mi = return (MI (mi_length mi) (of_nat n) (mi_caps_unwrapped mi)\n                        (mi_label mi))\"\n| \"transfer_caps_loop ep rcv_buffer n ((cap, slot) # morecaps)\n         slots mi =\n  const_on_failure (MI (mi_length mi) (of_nat n) (mi_caps_unwrapped mi)\n                       (mi_label mi)) (doE\n    transfer_rest \\<leftarrow> returnOk $ transfer_caps_loop ep\n         rcv_buffer (n + 1) morecaps;\n    if (is_ep_cap cap \\<and> ep = Some (obj_ref_of cap))\n    then doE\n       liftE $ set_extra_badge rcv_buffer (cap_ep_badge cap) n;\n       liftE $ transfer_rest slots (MI (mi_length mi) (mi_extra_caps mi)\n         (mi_caps_unwrapped mi || (1 << n)) (mi_label mi))\n    odE\n    else if slots \\<noteq> []\n    then doE\n      cap' \\<leftarrow> derive_cap slot cap;\n      whenE (cap' = NullCap) $ throwError undefined;\n      liftE $ cap_insert cap' slot (hd slots);\n      liftE $ transfer_rest (tl slots) mi\n    odE\n    else returnOk (MI (mi_length mi) (of_nat n) (mi_caps_unwrapped mi)\n                       (mi_label mi))\n  odE)\"\n\ndefinition\n  transfer_caps :: \"message_info \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n                   obj_ref option \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow>\n                   (message_info,'z::state_ext) s_monad\"\nwhere\n  \"transfer_caps info caps endpoint receiver recv_buffer \\<equiv> do\n     dest_slots \\<leftarrow> get_receive_slots receiver recv_buffer;\n     mi' \\<leftarrow> return $ MI (mi_length info) 0 0 (mi_label info);\n     case recv_buffer of\n       None \\<Rightarrow> return mi'\n     | Some receive_buffer \\<Rightarrow>\n         transfer_caps_loop endpoint receive_buffer 0 caps dest_slots mi'\n   od\""}
{"title": "./spec/abstract/Ipc_A.thy", "section": "Fault Handling", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Threads fault when they attempt to access services that are not backed\nby any resources. Such a thread is then blocked and a fault messages is sent to\nits supervisor. When a reply to that message is sent the thread is reactivated.\n\\<close>\n\ntext \\<open>Format a message for a given fault type.\\<close>\nfun\n  make_fault_msg :: \"fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n  \"make_fault_msg (CapFault cptr rp lf) thread = (do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (1, pc # cptr # (if rp then 1 else 0) # msg_from_lookup_failure lf)\n   od)\"\n| \"make_fault_msg (UnknownSyscallException n) thread = (do\n     msg \\<leftarrow> as_user thread $ mapM getRegister syscallMessage;\n     return (2, msg @ [n])\n   od)\"\n| \"make_fault_msg (UserException exception code) thread = (do\n     msg \\<leftarrow> as_user thread $ mapM getRegister exceptionMessage;\n     return (3, msg @ [exception, code])\n   od)\"\n| \"make_fault_msg (ArchFault af) thread = make_arch_fault_msg af thread \" (* arch_fault *)\n\ntext \\<open>React to a fault reply. The reply message is interpreted in a manner\nthat depends on the type of the original fault. For some fault types a thread\nreconfiguration is performed. This is done entirely to save the fault message\nrecipient an additional system call. This function returns a boolean indicating\nwhether the thread should now be restarted.\\<close>\nfun\n  handle_fault_reply :: \"fault \\<Rightarrow> obj_ref \\<Rightarrow>\n                         data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_fault_reply (CapFault cptr rp lf) thread x y = return True\"\n| \"handle_fault_reply (UnknownSyscallException n) thread label msg = do\n     t \\<leftarrow> arch_get_sanitise_register_info thread;\n     as_user thread $ zipWithM_x\n         (\\<lambda>r v. setRegister r $ sanitise_register t r v)\n         syscallMessage msg;\n     return (label = 0)\n   od\"\n| \"handle_fault_reply (UserException exception code) thread label msg = do\n     t \\<leftarrow> arch_get_sanitise_register_info thread;\n     as_user thread $ zipWithM_x\n         (\\<lambda>r v. setRegister r $ sanitise_register t r v)\n         exceptionMessage msg;\n     return (label = 0)\n   od\"\n| \" handle_fault_reply (ArchFault af) thread label msg =\n    handle_arch_fault_reply af thread label msg\" (* arch_fault *)\n\ntext \\<open>Transfer a fault message from a faulting thread to its supervisor.\\<close>\ndefinition\n  do_fault_transfer :: \"data \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref\n                             \\<Rightarrow> obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"do_fault_transfer badge sender receiver buf \\<equiv> do\n    fault \\<leftarrow> thread_get tcb_fault sender;\n    f \\<leftarrow> (case fault of\n         Some f \\<Rightarrow> return f\n       | None \\<Rightarrow> fail);\n    (label, msg) \\<leftarrow> make_fault_msg f sender;\n    sent \\<leftarrow> set_mrs receiver buf msg;\n    set_message_info receiver $ MI sent 0 0 label;\n    as_user receiver $ setRegister badge_register badge\n  od\""}
{"title": "./spec/abstract/Ipc_A.thy", "section": "Synchronous Message Transfers", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Transfer a non-fault message.\\<close>\ndefinition\n  do_normal_transfer :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> obj_ref option\n                                    \\<Rightarrow> data \\<Rightarrow> bool \\<Rightarrow> obj_ref\n                                    \\<Rightarrow> obj_ref option\n                                    \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"do_normal_transfer sender sbuf endpoint badge grant\n                     receiver rbuf  \\<equiv>\n  do\n    mi \\<leftarrow> get_message_info sender;\n    caps \\<leftarrow> if grant then lookup_extra_caps sender sbuf mi <catch> K (return [])\n      else return [];\n    mrs_transferred \\<leftarrow> copy_mrs sender sbuf receiver rbuf (mi_length mi);\n    mi' \\<leftarrow> transfer_caps mi caps endpoint receiver rbuf;\n    set_message_info receiver $ MI mrs_transferred (mi_extra_caps mi')\n                                   (mi_caps_unwrapped mi') (mi_label mi);\n    as_user receiver $ setRegister badge_register badge\n  od\"\n\ntext \\<open>Transfer a message either involving a fault or not.\\<close>\ndefinition\n  do_ipc_transfer :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow>\n                       badge \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"do_ipc_transfer sender ep badge grant\n     receiver \\<equiv> do\n\n     recv_buffer \\<leftarrow> lookup_ipc_buffer True receiver;\n     fault \\<leftarrow> thread_get tcb_fault sender;\n\n     case fault\n        of None \\<Rightarrow> do\n            send_buffer \\<leftarrow> lookup_ipc_buffer False sender;\n            do_normal_transfer sender send_buffer ep badge grant\n                           receiver recv_buffer\n            od\n         | Some f \\<Rightarrow> do_fault_transfer badge sender receiver recv_buffer\n   od\"\n\ntext \\<open>Transfer a reply message and delete the one-use Reply capability.\\<close>\ndefinition\n  do_reply_transfer :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"do_reply_transfer sender receiver slot grant \\<equiv> do\n    state \\<leftarrow> get_thread_state receiver;\n    assert (state = BlockedOnReply);\n    fault \\<leftarrow> thread_get tcb_fault receiver;\n    case fault of\n      None \\<Rightarrow> do\n         do_ipc_transfer sender None 0 grant receiver;\n         cap_delete_one slot;\n         set_thread_state receiver Running;\n         do_extended_op (possible_switch_to receiver)\n      od\n    | Some f \\<Rightarrow> do\n         cap_delete_one slot;\n         mi \\<leftarrow> get_message_info sender;\n         buf \\<leftarrow> lookup_ipc_buffer False sender;\n         mrs \\<leftarrow> get_mrs sender buf mi;\n         restart \\<leftarrow> handle_fault_reply f receiver (mi_label mi) mrs;\n         thread_set (\\<lambda>tcb. tcb \\<lparr> tcb_fault := None \\<rparr>) receiver;\n         set_thread_state receiver (if restart then Restart else Inactive);\n         when restart $ do_extended_op (possible_switch_to receiver);\n         return ()\n       od\n  od\"\n\ntext \\<open>This function transfers a reply message to a thread when that message\nis generated by a kernel service.\\<close>\ndefinition\n  reply_from_kernel :: \"obj_ref \\<Rightarrow> (data \\<times> data list) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"reply_from_kernel thread x \\<equiv> do\n    (label, msg) \\<leftarrow> return x;\n    buf \\<leftarrow> lookup_ipc_buffer True thread;\n    as_user thread $ setRegister badge_register 0;\n    len \\<leftarrow> set_mrs thread buf msg;\n    set_message_info thread $ MI len 0 0 label\n  od\"\n\ntext \\<open>Install a one-use Reply capability.\\<close>\ndefinition\n  setup_caller_cap :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"setup_caller_cap sender receiver grant \\<equiv> do\n    set_thread_state sender BlockedOnReply;\n    cap_insert (ReplyCap sender False (if grant then {AllowGrant, AllowWrite} else {AllowWrite}))\n               (sender, tcb_cnode_index 2)\n      (receiver, tcb_cnode_index 3)\n  od\"\n\ntext \\<open>Handle a message send operation performed on an endpoint by a thread.\nIf a receiver is waiting then transfer the message. If no receiver is available\nand the thread is willing to block waiting to send then put it in the endpoint\nsending queue.\\<close>\ndefinition\n  send_ipc :: \"bool \\<Rightarrow> bool \\<Rightarrow> badge \\<Rightarrow> bool \\<Rightarrow> bool\n                \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"send_ipc block call badge can_grant can_grant_reply thread epptr \\<equiv> do\n     ep \\<leftarrow> get_endpoint epptr;\n     case (ep, block) of\n         (IdleEP, True) \\<Rightarrow> do\n               set_thread_state thread (BlockedOnSend epptr\n                                   \\<lparr> sender_badge = badge,\n                                     sender_can_grant = can_grant,\n                                     sender_can_grant_reply = can_grant_reply,\n                                     sender_is_call = call \\<rparr>);\n               set_endpoint epptr $ SendEP [thread]\n             od\n       | (SendEP queue, True) \\<Rightarrow> do\n               set_thread_state thread (BlockedOnSend epptr\n                                   \\<lparr> sender_badge = badge,\n                                     sender_can_grant = can_grant,\n                                     sender_can_grant_reply = can_grant_reply,\n                                     sender_is_call = call\\<rparr>);\n               set_endpoint epptr $ SendEP (queue @ [thread])\n             od\n       | (IdleEP, False) \\<Rightarrow> return ()\n       | (SendEP queue, False) \\<Rightarrow> return ()\n       | (RecvEP (dest # queue), _) \\<Rightarrow> do\n                set_endpoint epptr $ (case queue of [] \\<Rightarrow> IdleEP\n                                                     | _ \\<Rightarrow> RecvEP queue);\n                recv_state \\<leftarrow> get_thread_state dest;\n                reply_can_grant \\<leftarrow> case recv_state\n                  of (BlockedOnReceive x data) \\<Rightarrow> do\n                           do_ipc_transfer thread (Some epptr) badge can_grant dest;\n                           return (receiver_can_grant data)\n                           od\n                  | _ \\<Rightarrow> fail;\n                set_thread_state dest Running;\n                do_extended_op (possible_switch_to dest);\n                when call $\n                  if (can_grant \\<or> can_grant_reply)\n                  then setup_caller_cap thread dest reply_can_grant\n                  else set_thread_state thread Inactive\n                od\n\n       | (RecvEP [], _) \\<Rightarrow> fail\n   od\"\n\ntext \\<open>Handle a message receive operation performed on an endpoint by a thread.\nIf a sender is waiting then transfer the message, otherwise put the thread in\nthe endpoint receiving queue.\\<close>\ndefinition\n  isActive :: \"notification \\<Rightarrow> bool\"\nwhere\n  \"isActive ntfn \\<equiv> case ntfn_obj ntfn\n     of ActiveNtfn _ \\<Rightarrow> True\n      | _ \\<Rightarrow> False\"\n\n\ntext\\<open>Helper function for performing \\emph{signal} when receiving on a normal\nendpoint\\<close>\ndefinition\n  complete_signal :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"complete_signal ntfnptr tcb \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     case ntfn_obj ntfn of\n       ActiveNtfn badge \\<Rightarrow> do\n           as_user tcb $ setRegister badge_register badge;\n           set_notification ntfnptr $ ntfn_set_obj ntfn IdleNtfn\n         od\n     | _ \\<Rightarrow> fail\n   od\"\n\ndefinition\n  do_nbrecv_failed_transfer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"do_nbrecv_failed_transfer thread = do as_user thread $ setRegister badge_register 0; return () od\"\n\ndefinition\n  receive_ipc :: \"obj_ref \\<Rightarrow> cap \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"receive_ipc thread cap is_blocking \\<equiv> do\n     (epptr,rights) \\<leftarrow> (case cap\n                       of EndpointCap ref badge rights \\<Rightarrow> return (ref,rights)\n                        | _ \\<Rightarrow> fail);\n     ep \\<leftarrow> get_endpoint epptr;\n     ntfnptr \\<leftarrow> get_bound_notification thread;\n     ntfn \\<leftarrow> case_option (return default_notification) get_notification ntfnptr;\n     if (ntfnptr \\<noteq> None \\<and> isActive ntfn)\n     then\n       complete_signal (the ntfnptr) thread\n     else\n       case ep\n         of IdleEP \\<Rightarrow> (case is_blocking of\n              True \\<Rightarrow> do\n                  set_thread_state thread (BlockedOnReceive epptr\n                                           \\<lparr>receiver_can_grant = (AllowGrant \\<in> rights)\\<rparr>);\n                  set_endpoint epptr (RecvEP [thread])\n                od\n              | False \\<Rightarrow> do_nbrecv_failed_transfer thread)\n            | RecvEP queue \\<Rightarrow> (case is_blocking of\n              True \\<Rightarrow> do\n                  set_thread_state thread (BlockedOnReceive epptr\n                                           \\<lparr>receiver_can_grant = (AllowGrant \\<in> rights)\\<rparr>);\n                  set_endpoint epptr (RecvEP (queue @ [thread]))\n                od\n              | False \\<Rightarrow> do_nbrecv_failed_transfer thread)\n          | SendEP q \\<Rightarrow> do\n              assert (q \\<noteq> []);\n              queue \\<leftarrow> return $ tl q;\n              sender \\<leftarrow> return $ hd q;\n              set_endpoint epptr $\n                (case queue of [] \\<Rightarrow> IdleEP | _ \\<Rightarrow> SendEP queue);\n              sender_state \\<leftarrow> get_thread_state sender;\n              data \\<leftarrow> (case sender_state\n                       of BlockedOnSend ref data \\<Rightarrow> return data\n                        | _ \\<Rightarrow> fail);\n              do_ipc_transfer sender (Some epptr)\n                        (sender_badge data) (sender_can_grant data)\n                        thread;\n              if (sender_is_call data)\n              then\n                if (sender_can_grant data \\<or> sender_can_grant_reply data)\n                then setup_caller_cap sender thread (AllowGrant \\<in> rights)\n                else set_thread_state sender Inactive\n              else do\n                set_thread_state sender Running;\n                do_extended_op (possible_switch_to sender)\n              od\n            od\n   od\""}
{"title": "./spec/abstract/Ipc_A.thy", "section": "Asynchronous Message Transfers", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Helper function to handle a signal operation in the case\nwhere a receiver is waiting.\\<close>\ndefinition\n  update_waiting_ntfn :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref option \\<Rightarrow> badge \\<Rightarrow>\n                         (unit,'z::state_ext) s_monad\"\nwhere\n  \"update_waiting_ntfn ntfnptr queue bound_tcb badge \\<equiv> do\n     assert (queue \\<noteq> []);\n     (dest,rest) \\<leftarrow> return $ (hd queue, tl queue);\n     set_notification ntfnptr $ \\<lparr>\n         ntfn_obj = (case rest of [] \\<Rightarrow> IdleNtfn | _ \\<Rightarrow> WaitingNtfn rest),\n         ntfn_bound_tcb = bound_tcb \\<rparr>;\n     set_thread_state dest Running;\n     as_user dest $ setRegister badge_register badge;\n     do_extended_op (possible_switch_to dest)\n\n   od\"\n\ntext \\<open>Handle a message send operation performed on a notification object.\nIf a receiver is waiting then transfer the message, otherwise combine the new\nmessage with whatever message is currently waiting.\\<close>\n\n(* helper function for checking if thread is blocked *)\ndefinition\n  receive_blocked :: \"thread_state \\<Rightarrow> bool\"\nwhere\n  \"receive_blocked st \\<equiv> case st of\n       BlockedOnReceive _ _ \\<Rightarrow> True\n     | _ \\<Rightarrow> False\"\n\ndefinition\n  send_signal :: \"obj_ref \\<Rightarrow> badge \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"send_signal ntfnptr badge \\<equiv> do\n    ntfn \\<leftarrow> get_notification ntfnptr;\n    case (ntfn_obj ntfn, ntfn_bound_tcb ntfn) of\n          (IdleNtfn, Some tcb) \\<Rightarrow> do\n                  st \\<leftarrow> get_thread_state tcb;\n                  if (receive_blocked st)\n                  then do\n                      cancel_ipc tcb;\n                      set_thread_state tcb Running;\n                      as_user tcb $ setRegister badge_register badge;\n                      do_extended_op (possible_switch_to tcb)\n                    od\n                  else set_notification ntfnptr $ ntfn_set_obj ntfn (ActiveNtfn badge)\n            od\n       | (IdleNtfn, None) \\<Rightarrow> set_notification ntfnptr $ ntfn_set_obj ntfn (ActiveNtfn badge)\n       | (WaitingNtfn queue, bound_tcb) \\<Rightarrow> update_waiting_ntfn ntfnptr queue bound_tcb badge\n       | (ActiveNtfn badge', _) \\<Rightarrow>\n           set_notification ntfnptr $ ntfn_set_obj ntfn $\n             ActiveNtfn (combine_ntfn_badges badge badge')\n   od\"\n\n\ntext \\<open>Handle a receive operation performed on a notification object by a\nthread. If a message is waiting then perform the transfer, otherwise put the\nthread in the endpoint's receiving queue.\\<close>\ndefinition\n  receive_signal :: \"obj_ref \\<Rightarrow> cap \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n   \"receive_signal thread cap is_blocking \\<equiv> do\n    ntfnptr \\<leftarrow>\n      case cap\n        of NotificationCap ntfnptr badge rights \\<Rightarrow> return ntfnptr\n         | _ \\<Rightarrow> fail;\n    ntfn \\<leftarrow> get_notification ntfnptr;\n    case ntfn_obj ntfn\n      of IdleNtfn \\<Rightarrow>\n                   (case is_blocking of\n                     True \\<Rightarrow> do\n                          set_thread_state thread (BlockedOnNotification ntfnptr);\n                          set_notification ntfnptr $ ntfn_set_obj ntfn $ WaitingNtfn [thread]\n                        od\n                   | False \\<Rightarrow> do_nbrecv_failed_transfer thread)\n       | WaitingNtfn queue \\<Rightarrow>\n                   (case is_blocking of\n                     True \\<Rightarrow> do\n                          set_thread_state thread (BlockedOnNotification ntfnptr);\n                          set_notification ntfnptr $ ntfn_set_obj ntfn $ WaitingNtfn (queue @ [thread])\n                        od\n                   | False \\<Rightarrow> do_nbrecv_failed_transfer thread)\n       | ActiveNtfn badge \\<Rightarrow> do\n                     as_user thread $ setRegister badge_register badge;\n                     set_notification ntfnptr $ ntfn_set_obj ntfn IdleNtfn\n                   od\n    od\""}
{"title": "./spec/abstract/Ipc_A.thy", "section": "Sending Fault Messages", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>When a thread encounters a fault, retreive its fault handler capability\nand send a fault message.\\<close>\ndefinition\n  send_fault_ipc :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n  \"send_fault_ipc tptr fault \\<equiv> doE\n     handler_cptr \\<leftarrow> liftE $ thread_get tcb_fault_handler tptr;\n     handler_cap \\<leftarrow> cap_fault_on_failure (of_bl handler_cptr) False $\n         lookup_cap tptr handler_cptr;\n\n     let f = CapFault (of_bl handler_cptr) False (MissingCapability 0)\n     in\n     (case handler_cap\n       of EndpointCap ref badge rights \\<Rightarrow>\n           if AllowSend \\<in> rights \\<and> (AllowGrant \\<in> rights \\<or> AllowGrantReply \\<in> rights)\n           then liftE $ (do\n               thread_set (\\<lambda>tcb. tcb \\<lparr> tcb_fault := Some fault \\<rparr>) tptr;\n               send_ipc True True (cap_ep_badge handler_cap)\n                        (AllowGrant \\<in> rights) True tptr (cap_ep_ptr handler_cap)\n             od)\n           else throwError f\n        | _ \\<Rightarrow> throwError f)\n   odE\"\n\ntext \\<open>If a fault message cannot be sent then leave the thread inactive.\\<close>\ndefinition\n  handle_double_fault :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_double_fault tptr ex1 ex2 \\<equiv> set_thread_state tptr Inactive\"\n\ntext \\<open>Handle a thread fault by sending a fault message if possible.\\<close>\ndefinition\n  handle_fault :: \"obj_ref \\<Rightarrow> fault \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_fault thread ex \\<equiv> do\n     _ \\<leftarrow> gets_the $ get_tcb thread;\n     send_fault_ipc thread ex\n          <catch> handle_double_fault thread ex;\n     return ()\n   od\"\n\nend"}
{"title": "./spec/abstract/Decode_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDecoding system calls\n*)\n\nchapter \"Decoding System Calls\"\n\ntheory Decode_A\nimports\n  Interrupt_A\n  ArchDecode_A\n  \"ExecSpec.InvocationLabels_H\"\nbegin\n\narch_requalify_consts (A)\n  ArchDefaultExtraRegisters\n  check_valid_ipc_buffer\n  is_valid_vtable_root\n  arch_decode_irq_control_invocation\n  arch_data_to_obj_type\n  arch_decode_invocation\n  arch_check_irq\n\ntext \\<open>\n  This theory includes definitions describing how user arguments are\ndecoded into invocation structures; these structures are then used\nto perform the actual system call (see @{text \"perform_invocation\"}).\nIn addition, these definitions check the validity of these arguments,\nthrowing an error if given an invalid request.\n\n  As such, this theory describes the binary interface between the\nuser and the kernel, along with the preconditions on each argument.\n\\<close>"}
{"title": "./spec/abstract/Decode_A.thy", "section": "Threads", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition decodes CNode invocations.\\<close>\n\ndefinition\n  decode_cnode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap \\<Rightarrow> cap list \\<Rightarrow> (cnode_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_cnode_invocation label args cap excaps \\<equiv> doE\n  unlessE (gen_invocation_type label \\<in> set [CNodeRevoke .e. CNodeSaveCaller]) $\n    throwError IllegalOperation;\n  whenE (length args < 2) (throwError TruncatedMessage);\n  index \\<leftarrow> returnOk $ data_to_cptr $ args ! 0;\n  bits \\<leftarrow> returnOk $ data_to_nat $ args ! 1;\n  args \\<leftarrow> returnOk $ drop 2 args;\n  dest_slot \\<leftarrow> lookup_target_slot cap index bits;\n  if length args \\<ge> 2 \\<and> length excaps > 0\n        \\<and> gen_invocation_type label \\<in> set [CNodeCopy .e. CNodeMutate] then\n  doE\n    src_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 0;\n    src_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 1;\n    args \\<leftarrow> returnOk $ drop 2 args;\n    src_root_cap \\<leftarrow> returnOk $ excaps ! 0;\n    ensure_empty dest_slot;\n    src_slot \\<leftarrow>\n         lookup_source_slot src_root_cap src_index src_depth;\n    src_cap \\<leftarrow> liftE $ get_cap src_slot;\n    whenE (src_cap = NullCap) $\n         throwError $ FailedLookup True $ MissingCapability src_depth;\n    (rights, cap_data, is_move) \\<leftarrow> case (gen_invocation_type label, args) of\n      (CNodeCopy, rightsWord # _) \\<Rightarrow> doE\n                    rights \\<leftarrow> returnOk $ data_to_rights $ rightsWord;\n                    returnOk $ (rights, None, False)\n                odE\n     | (CNodeMint, rightsWord # capData # _) \\<Rightarrow> doE\n                    rights \\<leftarrow> returnOk $ data_to_rights $ rightsWord;\n                    returnOk $ (rights, Some capData, False)\n                odE\n     | (CNodeMove, _) \\<Rightarrow> returnOk (all_rights, None, True)\n     | (CNodeMutate, capData # _) \\<Rightarrow> returnOk (all_rights, Some capData, True)\n     | _ \\<Rightarrow> throwError TruncatedMessage;\n    src_cap \\<leftarrow> returnOk $ mask_cap rights src_cap;\n    new_cap \\<leftarrow> (if is_move then returnOk else derive_cap src_slot) (case cap_data of\n                  Some w \\<Rightarrow> update_cap_data is_move w src_cap\n                | None \\<Rightarrow> src_cap);\n    whenE (new_cap = NullCap) $ throwError IllegalOperation;\n    returnOk $ (if is_move then MoveCall else InsertCall) new_cap src_slot dest_slot\n  odE\n  else if gen_invocation_type label = CNodeRevoke then returnOk $ RevokeCall dest_slot\n  else if gen_invocation_type label = CNodeDelete then returnOk $ DeleteCall dest_slot\n  else if gen_invocation_type label = CNodeSaveCaller then doE\n    ensure_empty dest_slot;\n    returnOk $ SaveCall dest_slot\n  odE\n  else if gen_invocation_type label = CNodeCancelBadgedSends then doE\n    cap \\<leftarrow> liftE $ get_cap dest_slot;\n    unlessE (has_cancel_send_rights cap) $ throwError IllegalOperation;\n    returnOk $ CancelBadgedSendsCall cap\n  odE\n  else if gen_invocation_type label = CNodeRotate \\<and> length args > 5\n          \\<and> length excaps > 1 then\n  doE\n    pivot_new_data \\<leftarrow> returnOk $ args ! 0;\n    pivot_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 1;\n    pivot_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 2;\n    src_new_data \\<leftarrow> returnOk $ args ! 3;\n    src_index \\<leftarrow> returnOk $ data_to_cptr $ args ! 4;\n    src_depth \\<leftarrow> returnOk $ data_to_nat $ args ! 5;\n    pivot_root_cap <- returnOk $ excaps ! 0;\n    src_root_cap <- returnOk $ excaps ! 1;\n\n    src_slot <- lookup_source_slot src_root_cap src_index src_depth;\n    pivot_slot <- lookup_pivot_slot pivot_root_cap pivot_index pivot_depth;\n\n    whenE (pivot_slot = src_slot \\<or> pivot_slot = dest_slot) $\n      throwError IllegalOperation;\n\n    unlessE (src_slot = dest_slot) $ ensure_empty dest_slot;\n\n    src_cap <- liftE $ get_cap src_slot;\n    whenE (src_cap = NullCap) $\n      throwError $ FailedLookup True $ MissingCapability src_depth;\n\n    pivot_cap <- liftE $ get_cap pivot_slot;\n    whenE (pivot_cap = NullCap) $\n      throwError $ FailedLookup False $ MissingCapability pivot_depth;\n\n    new_src_cap \\<leftarrow> returnOk $ update_cap_data True src_new_data src_cap;\n    new_pivot_cap \\<leftarrow> returnOk $ update_cap_data True pivot_new_data pivot_cap;\n\n    whenE (new_src_cap = NullCap) $ throwError IllegalOperation;\n    whenE (new_pivot_cap = NullCap) $ throwError IllegalOperation;\n\n    returnOk $ RotateCall new_src_cap new_pivot_cap src_slot pivot_slot dest_slot\n  odE\n  else\n    throwError TruncatedMessage\nodE\""}
{"title": "./spec/abstract/Decode_A.thy", "section": "Threads", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The definitions in this section decode invocations\non TCBs.\n\\<close>\n\ntext \\<open>This definition checks whether the first argument is\nbetween the second and third.\n\\<close>\n\ndefinition\n  decode_read_registers :: \"data list \\<Rightarrow> cap \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_read_registers data cap \\<equiv> case data of\n  flags#n#_ \\<Rightarrow> doE\n    range_check n 1 $ of_nat (length frameRegisters + length gpRegisters);\n    p \\<leftarrow> case cap of ThreadCap p \\<Rightarrow> returnOk p;\n    self \\<leftarrow> liftE $ gets cur_thread;\n    whenE (p = self) $ throwError IllegalOperation;\n    returnOk $ ReadRegisters p (flags !! 0) n ArchDefaultExtraRegisters\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition\n  decode_copy_registers :: \"data list \\<Rightarrow> cap \\<Rightarrow> cap list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_copy_registers data cap extra_caps \\<equiv> case data of\n  flags#_ \\<Rightarrow>  doE\n    suspend_source \\<leftarrow> returnOk (flags !! 0);\n    resume_target \\<leftarrow> returnOk (flags !! 1);\n    transfer_frame \\<leftarrow> returnOk (flags !! 2);\n    transfer_integer \\<leftarrow> returnOk (flags !! 3);\n    whenE (extra_caps = []) $ throwError TruncatedMessage;\n    src_tcb \\<leftarrow> (case extra_caps of\n      ThreadCap p # _ \\<Rightarrow> returnOk p\n    | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n    p \\<leftarrow> case cap of ThreadCap p \\<Rightarrow> returnOk p;\n    returnOk $ CopyRegisters p src_tcb\n                             suspend_source resume_target\n                             transfer_frame transfer_integer\n                             ArchDefaultExtraRegisters\n  odE\n| _ \\<Rightarrow>  throwError TruncatedMessage\"\n\n\ndefinition\n  decode_write_registers :: \"data list \\<Rightarrow> cap \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_write_registers data cap \\<equiv> case data of\n  flags#n#values \\<Rightarrow> doE\n    whenE (length values < unat n) $ throwError TruncatedMessage;\n    p \\<leftarrow> case cap of ThreadCap p \\<Rightarrow> returnOk p;\n    self \\<leftarrow> liftE $ gets cur_thread;\n    whenE (p = self) $ throwError IllegalOperation;\n    returnOk $ WriteRegisters p (flags !! 0)\n               (take (unat n) values) ArchDefaultExtraRegisters\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\n\ndefinition\n  check_prio :: \"data \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"check_prio new_prio auth_tcb \\<equiv>\n    doE\n      mcp \\<leftarrow> liftE $ thread_get tcb_mcpriority auth_tcb;\n      whenE (new_prio > ucast mcp) $ throwError (RangeError 0 (ucast mcp))\n    odE\"\n\n\ndefinition\n  decode_set_priority :: \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_priority args cap slot extra_caps \\<equiv> doE\n     whenE (length args = 0 \\<or> length extra_caps = 0) $ throwError TruncatedMessage;\n     prio \\<leftarrow> returnOk $ ucast (args ! 0);\n     auth_tcb \\<leftarrow> case fst (extra_caps ! 0) of\n         ThreadCap tcb_ptr \\<Rightarrow> returnOk tcb_ptr\n       | _ \\<Rightarrow> throwError (InvalidCapability 1);\n     check_prio (args ! 0) auth_tcb;\n     returnOk (ThreadControl (obj_ref_of cap) slot None None\n                             (Some (prio, auth_tcb)) None None None)\n     odE\"\n\n\ndefinition\n  decode_set_mcpriority :: \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_mcpriority args cap slot extra_caps \\<equiv> doE\n     whenE (length args = 0 \\<or> length extra_caps = 0) $ throwError TruncatedMessage;\n     new_mcp \\<leftarrow> returnOk $ ucast $ args ! 0;\n     auth_tcb \\<leftarrow> case fst (extra_caps ! 0) of\n         ThreadCap tcb_ptr \\<Rightarrow> returnOk tcb_ptr\n       | _ \\<Rightarrow> throwError (InvalidCapability 1);\n     check_prio (args ! 0) auth_tcb;\n     returnOk (ThreadControl (obj_ref_of cap) slot None (Some (new_mcp, auth_tcb))\n                             None None None None)\n     odE\"\n\n\ndefinition\n  decode_set_sched_params :: \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_sched_params args cap slot extra_caps \\<equiv> doE\n     whenE (length args < 2) $ throwError TruncatedMessage;\n     whenE (length extra_caps = 0) $ throwError TruncatedMessage;\n     new_mcp \\<leftarrow> returnOk $ ucast $ args ! 0;\n     new_prio \\<leftarrow> returnOk $ ucast $ args ! 1;\n     auth_tcb \\<leftarrow> case fst (extra_caps ! 0) of\n         ThreadCap tcb_ptr \\<Rightarrow> returnOk tcb_ptr\n       | _ \\<Rightarrow> throwError (InvalidCapability 1);\n     check_prio (args ! 0) auth_tcb;\n     check_prio (args ! 1) auth_tcb;\n     returnOk (ThreadControl (obj_ref_of cap) slot None\n                             (Some (new_mcp, auth_tcb)) (Some (new_prio, auth_tcb)) None None None)\n     odE\"\n\n\ndefinition\n  decode_set_ipc_buffer ::\n  \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_set_ipc_buffer args cap slot excs \\<equiv> doE\n  whenE (length args = 0) $ throwError TruncatedMessage;\n  whenE (length excs = 0) $ throwError TruncatedMessage;\n  buffer \\<leftarrow> returnOk $ data_to_vref $ args ! 0;\n  (bcap, bslot) \\<leftarrow> returnOk $ excs ! 0;\n  newbuf \\<leftarrow> if buffer = 0 then returnOk None\n           else doE\n      buffer_cap \\<leftarrow> derive_cap bslot bcap;\n      check_valid_ipc_buffer buffer buffer_cap;\n      returnOk $ Some (buffer_cap, bslot)\n    odE;\n  returnOk $\n    ThreadControl (obj_ref_of cap) slot None None None None None (Some (buffer, newbuf))\nodE\"\n\n\ndefinition\n  decode_set_space\n  :: \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_space args cap slot excaps \\<equiv> doE\n   whenE (length args < 3 \\<or> length excaps < 2) $ throwError TruncatedMessage;\n   fault_ep \\<leftarrow> returnOk $ args ! 0;\n   croot_data  \\<leftarrow> returnOk $ args ! 1;\n   vroot_data  \\<leftarrow> returnOk $ args ! 2;\n   croot_arg  \\<leftarrow> returnOk $ excaps ! 0;\n   vroot_arg  \\<leftarrow> returnOk $ excaps ! 1;\n   can_chg_cr \\<leftarrow> liftE $ liftM Not $ slot_cap_long_running_delete\n                      $ get_tcb_ctable_ptr $ obj_ref_of cap;\n   can_chg_vr \\<leftarrow> liftE $ liftM Not $ slot_cap_long_running_delete\n                      $ get_tcb_vtable_ptr $ obj_ref_of cap;\n   unlessE (can_chg_cr \\<and> can_chg_vr) $ throwError IllegalOperation;\n\n   croot_cap  \\<leftarrow> returnOk $ fst croot_arg;\n   croot_slot \\<leftarrow> returnOk $ snd croot_arg;\n   croot_cap' \\<leftarrow> derive_cap croot_slot $\n                   (if croot_data = 0 then id else update_cap_data False croot_data)\n                   croot_cap;\n   unlessE (is_cnode_cap croot_cap') $ throwError IllegalOperation;\n   croot \\<leftarrow> returnOk (croot_cap', croot_slot);\n\n   vroot_cap  \\<leftarrow> returnOk $ fst vroot_arg;\n   vroot_slot \\<leftarrow> returnOk $ snd vroot_arg;\n   vroot_cap' \\<leftarrow> derive_cap vroot_slot $\n                   (if vroot_data = 0 then id else update_cap_data False vroot_data)\n                   vroot_cap;\n   unlessE (is_valid_vtable_root vroot_cap') $ throwError IllegalOperation;\n   vroot \\<leftarrow> returnOk (vroot_cap', vroot_slot);\n\n   returnOk $ ThreadControl (obj_ref_of cap) slot (Some (to_bl fault_ep)) None None\n                            (Some croot) (Some vroot) None\n odE\"\n\n\ndefinition\n  decode_tcb_configure ::\n  \"data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_tcb_configure args cap slot extra_caps \\<equiv> doE\n     whenE (length args < 4) $ throwError TruncatedMessage;\n     whenE (length extra_caps < 3) $ throwError TruncatedMessage;\n     fault_ep \\<leftarrow> returnOk $ args ! 0;\n     croot_data \\<leftarrow> returnOk $ args ! 1;\n     vroot_data \\<leftarrow> returnOk $ args ! 2;\n     crootvroot \\<leftarrow> returnOk $ take 2 extra_caps;\n     buffer_cap \\<leftarrow> returnOk $ extra_caps ! 2;\n     buffer \\<leftarrow> returnOk $ args ! 3;\n     set_params \\<leftarrow> decode_set_ipc_buffer [buffer] cap slot [buffer_cap];\n     set_space \\<leftarrow> decode_set_space [fault_ep, croot_data, vroot_data] cap slot crootvroot;\n     returnOk $ ThreadControl (obj_ref_of cap) slot (tc_new_fault_ep set_space)\n                              None None\n                              (tc_new_croot set_space) (tc_new_vroot set_space)\n                              (tc_new_buffer set_params)\n   odE\"\n\ndefinition\n  decode_bind_notification ::\n  \"cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_bind_notification cap extra_caps \\<equiv> case cap of\n    ThreadCap tcb \\<Rightarrow> doE\n     whenE (length extra_caps = 0) $ throwError TruncatedMessage;\n     nTFN \\<leftarrow> liftE $ get_bound_notification tcb;\n     case nTFN of\n         Some _ \\<Rightarrow> throwError IllegalOperation\n       | None \\<Rightarrow> returnOk ();\n     (ntfnptr, rights) \\<leftarrow> case fst (hd extra_caps) of\n         NotificationCap ptr _ r \\<Rightarrow> returnOk (ptr, r)\n       | _ \\<Rightarrow> throwError IllegalOperation;\n     whenE (AllowRecv \\<notin> rights) $ throwError IllegalOperation;\n     ntfn \\<leftarrow> liftE  $ get_notification ntfnptr;\n     case (ntfn_obj ntfn, ntfn_bound_tcb ntfn) of\n         (IdleNtfn, None) \\<Rightarrow> returnOk ()\n       | (ActiveNtfn _, None) \\<Rightarrow> returnOk ()\n       | _ \\<Rightarrow> throwError IllegalOperation;\n      returnOk $ NotificationControl tcb (Some ntfnptr)\n   odE\n | _ \\<Rightarrow> throwError IllegalOperation\"\n\n\ndefinition\n  decode_unbind_notification :: \"cap \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_unbind_notification cap \\<equiv> case cap of\n     ThreadCap tcb \\<Rightarrow> doE\n       nTFN \\<leftarrow> liftE $ get_bound_notification tcb;\n       case nTFN of\n           None \\<Rightarrow> throwError IllegalOperation\n         | Some _ \\<Rightarrow> returnOk ();\n       returnOk $ NotificationControl tcb None\n    odE\n | _ \\<Rightarrow> throwError IllegalOperation\"\n\ndefinition\n  decode_set_tls_base :: \"data list \\<Rightarrow> cap \\<Rightarrow> (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_set_tls_base args cap \\<equiv> doE\n     whenE (length args = 0) $ throwError TruncatedMessage;\n     returnOk (SetTLSBase (obj_ref_of cap) (ucast (args ! 0)))\n   odE\"\n\ndefinition\n  decode_tcb_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n  (tcb_invocation,'z::state_ext) se_monad\"\nwhere\n \"decode_tcb_invocation label args cap slot excs \\<equiv>\n  case gen_invocation_type label of\n      TCBReadRegisters \\<Rightarrow> decode_read_registers args cap\n    | TCBWriteRegisters \\<Rightarrow> decode_write_registers args cap\n    | TCBCopyRegisters \\<Rightarrow> decode_copy_registers args cap $ map fst excs\n    | TCBSuspend \\<Rightarrow> returnOk $ Suspend $ obj_ref_of cap\n    | TCBResume \\<Rightarrow> returnOk $ Resume $ obj_ref_of cap\n    | TCBConfigure \\<Rightarrow> decode_tcb_configure args cap slot excs\n    | TCBSetPriority \\<Rightarrow> decode_set_priority args cap slot excs\n    | TCBSetMCPriority \\<Rightarrow> decode_set_mcpriority args cap slot excs\n    | TCBSetSchedParams \\<Rightarrow> decode_set_sched_params args cap slot excs\n    | TCBSetIPCBuffer \\<Rightarrow> decode_set_ipc_buffer args cap slot excs\n    | TCBSetSpace \\<Rightarrow> decode_set_space args cap slot excs\n    | TCBBindNotification \\<Rightarrow> decode_bind_notification cap excs\n    | TCBUnbindNotification \\<Rightarrow> decode_unbind_notification cap\n    | TCBSetTLSBase \\<Rightarrow> decode_set_tls_base args cap\n    | _ \\<Rightarrow> throwError IllegalOperation\"\n\ndefinition\n  decode_domain_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    ((obj_ref \\<times> domain), 'z::state_ext) se_monad\"\nwhere\n  \"decode_domain_invocation label args excs \\<equiv> doE\n     whenE (gen_invocation_type label \\<noteq> DomainSetSet) $ throwError IllegalOperation;\n     domain \\<leftarrow> (case args of\n       x # xs \\<Rightarrow> doE\n         whenE (unat x \\<ge> numDomains) $ throwError $ InvalidArgument 0;\n         returnOk (ucast x)\n       odE\n       | _ \\<Rightarrow> throwError TruncatedMessage);\n     whenE (length excs = 0) $ throwError TruncatedMessage;\n     case (fst (hd excs)) of ThreadCap ptr \\<Rightarrow> returnOk $ (ptr, domain)\n       | _ \\<Rightarrow> throwError $ InvalidArgument 1\n   odE\""}
{"title": "./spec/abstract/Decode_A.thy", "section": "IRQ", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The following two definitions decode system calls for the\ninterrupt controller and interrupt handlers\\<close>\n\ndefinition\n  decode_irq_control_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list\n                                     \\<Rightarrow> (irq_control_invocation,'z::state_ext) se_monad\" where\n \"decode_irq_control_invocation label args src_slot cps \\<equiv>\n  (if gen_invocation_type label = IRQIssueIRQHandler\n    then if length args \\<ge> 3 \\<and> length cps \\<ge> 1\n      then let irq_word = args ! 0;\n               index = args ! 1;\n               depth = args ! 2;\n               cnode = cps ! 0;\n               irq = ucast irq_word\n      in doE\n        arch_check_irq irq_word;\n        irq_active \\<leftarrow> liftE $ is_irq_active irq;\n        whenE irq_active $ throwError RevokeFirst;\n\n        dest_slot \\<leftarrow> lookup_target_slot\n               cnode (data_to_cptr index) (unat depth);\n        ensure_empty dest_slot;\n\n        returnOk $ IRQControl irq dest_slot src_slot\n      odE\n    else throwError TruncatedMessage\n  else liftME ArchIRQControl $ arch_decode_irq_control_invocation label args src_slot cps)\"\n\ndefinition\n  decode_irq_handler_invocation :: \"data \\<Rightarrow> irq \\<Rightarrow> (cap \\<times> cslot_ptr) list\n                                     \\<Rightarrow> (irq_handler_invocation,'z::state_ext) se_monad\" where\n \"decode_irq_handler_invocation label irq cps \\<equiv>\n  if gen_invocation_type label = IRQAckIRQ\n    then returnOk $ ACKIrq irq\n  else if gen_invocation_type label = IRQSetIRQHandler\n    then if cps \\<noteq> []\n      then let (cap, slot) = hd cps in\n      if is_ntfn_cap cap \\<and> AllowSend \\<in> cap_rights cap\n      then returnOk $ SetIRQHandler irq cap slot\n      else throwError $ InvalidCapability 0\n    else throwError TruncatedMessage\n  else if gen_invocation_type label = IRQClearIRQHandler\n    then returnOk $ ClearIRQHandler irq\n  else throwError IllegalOperation\""}
{"title": "./spec/abstract/Decode_A.thy", "section": "Untyped", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The definitions in this section deal with decoding invocations\nof untyped memory capabilities.\n\\<close>\n\ndefinition\n  data_to_obj_type :: \"data \\<Rightarrow> (apiobject_type,'z::state_ext) se_monad\" where\n  \"data_to_obj_type type \\<equiv> doE\n    n \\<leftarrow> returnOk $ data_to_nat type;\n    if n = 0 then\n      returnOk $ Untyped\n    else if n = 1 then\n      returnOk $ TCBObject\n    else if n = 2 then\n      returnOk $ EndpointObject\n    else if n = 3 then\n      returnOk $ NotificationObject\n    else if n = 4 then\n      returnOk $ CapTableObject\n    else (case arch_data_to_obj_type (n - 5)\n       of Some tp \\<Rightarrow> returnOk (ArchObject tp)\n        | None \\<Rightarrow> throwError (InvalidArgument 0))\n  odE\"\n\ndefinition\n  decode_untyped_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap \\<Rightarrow> cap list \\<Rightarrow> (untyped_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_untyped_invocation label args slot cap excaps \\<equiv> doE\n  unlessE (gen_invocation_type label = UntypedRetype) $ throwError IllegalOperation;\n  whenE (length args < 6) $ throwError TruncatedMessage;\n  whenE (length excaps = 0) $ throwError TruncatedMessage;\n  root_cap \\<leftarrow> returnOk $ excaps ! 0;\n  new_type \\<leftarrow> data_to_obj_type (args!0);\n\n  user_obj_size \\<leftarrow> returnOk $ data_to_nat (args!1);\n  object_size \\<leftarrow> returnOk (obj_bits_api new_type user_obj_size);\n  unlessE (user_obj_size < word_bits \\<and> object_size \\<le> untyped_max_bits)\n    $ throwError (RangeError 0 (of_nat untyped_max_bits));\n  whenE (new_type = CapTableObject \\<and> user_obj_size = 0)\n    $ throwError (InvalidArgument 1);\n  whenE (new_type = Untyped \\<and> user_obj_size < untyped_min_bits)\n    $ throwError (InvalidArgument 1);\n  node_index \\<leftarrow> returnOk $ data_to_cptr (args!2);\n  node_depth \\<leftarrow> returnOk $ data_to_nat (args!3);\n\n  node_cap \\<leftarrow> if node_depth = 0\n        then returnOk root_cap\n        else doE\n            node_slot \\<leftarrow> lookup_target_slot\n                root_cap node_index node_depth;\n            liftE $ get_cap node_slot\n        odE;\n\n  if is_cnode_cap node_cap\n        then  returnOk ()\n        else  throwError $ FailedLookup False $ MissingCapability node_depth;\n\n  node_offset \\<leftarrow> returnOk $ data_to_nat (args ! 4);\n  node_window \\<leftarrow> returnOk $ data_to_nat (args ! 5);\n  radix_bits \\<leftarrow> returnOk $ bits_of node_cap;\n  node_size \\<leftarrow> returnOk (2 ^ radix_bits);\n\n  whenE (node_offset < 0 \\<or> node_offset > node_size - 1) $\n    throwError $ RangeError 0 (of_nat (node_size - 1));\n\n  whenE (node_window < 1 \\<or> node_window > unat retypeFanOutLimit) $ throwError $ RangeError 1 retypeFanOutLimit;\n\n  whenE (node_window < 1 \\<or> node_window > node_size - node_offset) $\n    throwError $ RangeError 1 (of_nat (node_size - node_offset));\n\n  oref \\<leftarrow> returnOk $ obj_ref_of node_cap;\n  offsets \\<leftarrow> returnOk $ map (nat_to_cref radix_bits)\n                           [node_offset ..< node_offset + node_window];\n  slots \\<leftarrow> returnOk $ map (\\<lambda>cref. (oref, cref)) offsets;\n\n  mapME_x ensure_empty slots;\n\n  reset \\<leftarrow> liftE $ const_on_failure False $ (doE\n    ensure_no_children slot;\n    returnOk True\n  odE);\n\n  free_index \\<leftarrow> returnOk (if reset then 0 else free_index_of cap);\n  free_ref \\<leftarrow> returnOk (get_free_ref (obj_ref_of cap) free_index);\n  aligned_free_ref \\<leftarrow> returnOk (alignUp free_ref object_size);\n  untyped_free_bytes \\<leftarrow> returnOk (obj_size cap - of_nat (free_index));\n\n  max_count \\<leftarrow> returnOk ( untyped_free_bytes >> object_size);\n  whenE (unat max_count < node_window) $\n        throwError $ NotEnoughMemory $ untyped_free_bytes;\n\n  not_frame \\<leftarrow> returnOk (\\<not> is_frame_type new_type);\n  (ptr, is_device) \\<leftarrow> case cap of\n                        UntypedCap dev p n f \\<Rightarrow> returnOk (p,dev)\n                      | _ \\<Rightarrow> fail;\n  whenE (is_device \\<and> not_frame \\<and> new_type \\<noteq> Untyped) $\n           throwError $ InvalidArgument 1;\n  returnOk $ Retype slot reset ptr aligned_free_ref new_type user_obj_size slots is_device\nodE\""}
{"title": "./spec/abstract/Decode_A.thy", "section": "Toplevel invocation decode.", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition is the toplevel decoding definition; it dispatches\nto the above definitions, after checking, in some cases, whether the\ninvocation is allowed.\n\\<close>\n\ndefinition\n  decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_invocation label args cap_index slot cap excaps \\<equiv>\n  case cap of\n    EndpointCap ptr badge rights \\<Rightarrow>\n      if AllowSend \\<in> rights then\n        returnOk $ InvokeEndpoint ptr badge (AllowGrant \\<in> rights) (AllowGrantReply \\<in> rights)\n      else throwError $ InvalidCapability 0\n  | NotificationCap ptr badge rights \\<Rightarrow>\n      if AllowSend \\<in> rights then\n        returnOk $ InvokeNotification ptr badge\n      else throwError $ InvalidCapability 0\n  | ReplyCap thread False rights \\<Rightarrow>\n      returnOk $ InvokeReply thread slot (AllowGrant \\<in> rights)\n  | IRQControlCap \\<Rightarrow>\n      liftME InvokeIRQControl\n        $ decode_irq_control_invocation label args slot (map fst excaps)\n  | IRQHandlerCap irq \\<Rightarrow>\n      liftME InvokeIRQHandler\n        $ decode_irq_handler_invocation label irq excaps\n  | ThreadCap ptr \\<Rightarrow>\n      liftME InvokeTCB $ decode_tcb_invocation label args cap slot excaps\n  | DomainCap \\<Rightarrow>\n      liftME (case_prod InvokeDomain) $ decode_domain_invocation label args excaps\n  | CNodeCap ptr bits _ \\<Rightarrow>\n      liftME InvokeCNode $ decode_cnode_invocation label args cap (map fst excaps)\n  | UntypedCap dev ptr sz fi \\<Rightarrow>\n      liftME InvokeUntyped $ decode_untyped_invocation label args slot cap (map fst excaps)\n  | ArchObjectCap arch_cap \\<Rightarrow>\n      liftME InvokeArchObject $\n        arch_decode_invocation label args cap_index slot arch_cap excaps\n  | _ \\<Rightarrow>\n      throwError $ InvalidCapability 0\"\n\nend"}
{"title": "./spec/abstract/IpcCancel_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFunctions for cancelling IPC.\n*)\n\nchapter \"IPC Cancelling\"\n\ntheory IpcCancel_A\nimports ArchIpcCancel_A\nbegin\n\narch_requalify_consts (A)\n  arch_post_cap_deletion\n  arch_gen_obj_refs\n  arch_cap_cleanup_opt\n\narch_requalify_consts\n  faultRegister\n  nextInstructionRegister\n\narch_requalify_types (A)\n  arch_gen_obj_ref\n\ntext \\<open>Getting and setting endpoint queues.\\<close>\ndefinition\n  get_ep_queue :: \"endpoint \\<Rightarrow> (obj_ref list,'z::state_ext) s_monad\"\nwhere\n \"get_ep_queue ep \\<equiv> case ep of SendEP q \\<Rightarrow> return q\n                              | RecvEP q \\<Rightarrow> return q\n                              | _ \\<Rightarrow> fail\"\n\nprimrec (nonexhaustive)\n  update_ep_queue :: \"endpoint \\<Rightarrow> obj_ref list \\<Rightarrow> endpoint\"\nwhere\n  \"update_ep_queue (RecvEP q) q' = RecvEP q'\"\n| \"update_ep_queue (SendEP q) q' = SendEP q'\"\n\n\ntext \\<open>Cancel all message operations on threads currently queued within this\nsynchronous message endpoint. Threads so queued are placed in the Restart state.\nOnce scheduled they will reattempt the operation that previously caused them\nto be queued here.\\<close>\ndefinition\n  cancel_all_ipc :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_all_ipc epptr \\<equiv> do\n     ep \\<leftarrow> get_endpoint epptr;\n     case ep of IdleEP \\<Rightarrow> return ()\n               | _ \\<Rightarrow> do\n                        queue \\<leftarrow> get_ep_queue ep;\n                        set_endpoint epptr IdleEP;\n                        mapM_x (\\<lambda>t. do set_thread_state t Restart;\n                                       do_extended_op (tcb_sched_action (tcb_sched_enqueue) t) od) $ queue;\n                        do_extended_op (reschedule_required)\n                     od\n   od\"\n\ntext \\<open>The badge stored by thread waiting on a message send operation.\\<close>\nprimrec (nonexhaustive)\n  blocking_ipc_badge :: \"thread_state \\<Rightarrow> badge\"\nwhere\n  \"blocking_ipc_badge (BlockedOnSend t payload) = sender_badge payload\"\n\ntext \\<open>Cancel all message send operations on threads queued in this endpoint\nand using a particular badge.\\<close>\ndefinition\n  cancel_badged_sends :: \"obj_ref \\<Rightarrow> badge \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_badged_sends epptr badge \\<equiv> do\n    ep \\<leftarrow> get_endpoint epptr;\n    case ep of\n          IdleEP \\<Rightarrow> return ()\n        | RecvEP _ \\<Rightarrow>  return ()\n        | SendEP queue \\<Rightarrow>  do\n            set_endpoint epptr IdleEP;\n            queue' \\<leftarrow> (swp filterM queue) (\\<lambda> t. do\n                st \\<leftarrow> get_thread_state t;\n                if blocking_ipc_badge st = badge then do\n                  set_thread_state t Restart;\n                  do_extended_op (tcb_sched_action (tcb_sched_enqueue) t);\n                  return False od\n                else return True\n            od);\n            ep' \\<leftarrow> return (case queue' of\n                           [] \\<Rightarrow> IdleEP\n                         | _ \\<Rightarrow> SendEP queue');\n            set_endpoint epptr ep';\n            do_extended_op (reschedule_required)\n        od\n  od\"\n\ntext \\<open>Cancel all message operations on threads queued in a notification\nendpoint.\\<close>\n\nabbreviation\n  do_unbind_notification :: \"obj_ref \\<Rightarrow> notification \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"do_unbind_notification ntfnptr ntfn tcbptr \\<equiv> do\n      ntfn' \\<leftarrow> return $ ntfn_set_bound_tcb ntfn None;\n      set_notification ntfnptr ntfn';\n      set_bound_notification tcbptr None\n    od\"\n\ndefinition\n  unbind_notification :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"unbind_notification tcb \\<equiv> do\n     ntfnptr \\<leftarrow> get_bound_notification tcb;\n     case ntfnptr of\n         Some ntfnptr' \\<Rightarrow> do\n             ntfn \\<leftarrow> get_notification ntfnptr';\n             do_unbind_notification ntfnptr' ntfn tcb\n          od\n       | None \\<Rightarrow> return ()\n   od\"\n\ndefinition\n  unbind_maybe_notification :: \"obj_ref \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"unbind_maybe_notification ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     (case ntfn_bound_tcb ntfn of\n       Some t \\<Rightarrow> do_unbind_notification ntfnptr ntfn t\n     | None \\<Rightarrow> return ())\n   od\"\n\ndefinition\n  cancel_all_signals :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_all_signals ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     case ntfn_obj ntfn of WaitingNtfn queue \\<Rightarrow> do\n                      _ \\<leftarrow> set_notification ntfnptr $ ntfn_set_obj ntfn IdleNtfn;\n                      mapM_x (\\<lambda>t. do set_thread_state t Restart;\n                                     do_extended_op (tcb_sched_action tcb_sched_enqueue t) od) queue;\n                      do_extended_op (reschedule_required)\n                     od\n               | _ \\<Rightarrow> return ()\n   od\"\n\ntext \\<open>The endpoint pointer stored by a thread waiting for a message to be\ntransferred in either direction.\\<close>\ndefinition\n  get_blocking_object :: \"thread_state \\<Rightarrow> (obj_ref,'z::state_ext) s_monad\"\nwhere\n \"get_blocking_object state \\<equiv>\n       case state of BlockedOnReceive epptr x \\<Rightarrow> return epptr\n                    | BlockedOnSend epptr x \\<Rightarrow> return epptr\n                    | _ \\<Rightarrow> fail\"\n\n\ntext \\<open>Cancel whatever IPC operation a thread is engaged in.\\<close>\ndefinition\n  blocked_cancel_ipc :: \"thread_state \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"blocked_cancel_ipc state tptr \\<equiv> do\n     epptr \\<leftarrow> get_blocking_object state;\n     ep \\<leftarrow> get_endpoint epptr;\n     queue \\<leftarrow> get_ep_queue ep;\n     queue' \\<leftarrow> return $ remove1 tptr queue;\n     ep' \\<leftarrow> return (case queue' of [] \\<Rightarrow> IdleEP\n                                |  _ \\<Rightarrow> update_ep_queue ep queue');\n     set_endpoint epptr ep';\n     set_thread_state tptr Inactive\n   od\"\n\ntext \\<open>Finalise a capability if the capability is known to be of the kind\nwhich can be finalised immediately. This is a simplified version of the\n@{text finalise_cap} operation.\\<close>\nfun\n  fast_finalise :: \"cap \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"fast_finalise NullCap                  final = return ()\"\n| \"fast_finalise (ReplyCap r m R)         final = return ()\"\n| \"fast_finalise (EndpointCap r b R)      final =\n      (when final $ cancel_all_ipc r)\"\n| \"fast_finalise (NotificationCap r b R) final =\n      (when final $ do\n          unbind_maybe_notification r;\n          cancel_all_signals r\n       od)\"\n| \"fast_finalise (CNodeCap r bits g)      final = fail\"\n| \"fast_finalise (ThreadCap r)            final = fail\"\n| \"fast_finalise DomainCap                final = fail\"\n| \"fast_finalise (Zombie r b n)           final = fail\"\n| \"fast_finalise IRQControlCap            final = fail\"\n| \"fast_finalise (IRQHandlerCap irq)      final = fail\"\n| \"fast_finalise (UntypedCap dev r n f)       final = fail\"\n| \"fast_finalise (ArchObjectCap a)        final = fail\"\n\ntext \\<open>The optional IRQ stored in a capability, presented either as an optional\nvalue or a set.\\<close>\ndefinition\n  cap_irq_opt :: \"cap \\<Rightarrow> irq option\" where\n \"cap_irq_opt cap \\<equiv> case cap of IRQHandlerCap irq \\<Rightarrow> Some irq | _ \\<Rightarrow> None\"\n\ndefinition\n  cap_irqs :: \"cap \\<Rightarrow> irq set\" where\n \"cap_irqs cap \\<equiv> set_option (cap_irq_opt cap)\"\n\ntext \\<open>A generic reference to an object. Used for the purposes of finalisation,\nwhere we want to be able to compare caps to decide if they refer to the \"same object\",\nwhich can be determined in several ways\\<close>\ndatatype gen_obj_ref =\n    ObjRef obj_ref\n  | IRQRef irq\n  | ArchRef arch_gen_obj_ref\n\ndefinition\n  arch_cap_set_map :: \"(arch_cap \\<Rightarrow> 'a set) \\<Rightarrow> cap \\<Rightarrow> 'a set\"\nwhere\n  \"arch_cap_set_map f cap \\<equiv> case cap of\n       ArchObjectCap acap \\<Rightarrow> f acap\n     | _ \\<Rightarrow> {}\"\n\nabbreviation\n  arch_gen_refs :: \"cap \\<Rightarrow> arch_gen_obj_ref set\"\nwhere\n  \"arch_gen_refs \\<equiv> arch_cap_set_map arch_gen_obj_refs\"\n\ndefinition\n  gen_obj_refs :: \"cap \\<Rightarrow> gen_obj_ref set\"\nwhere\n  \"gen_obj_refs c \\<equiv> ObjRef ` (obj_refs c)\n                      \\<union> IRQRef ` (cap_irqs c)\n                      \\<union> ArchRef ` (arch_gen_refs c)\"\n\ndefinition\n  cap_cleanup_opt :: \"cap \\<Rightarrow> cap\"\nwhere\n  \"cap_cleanup_opt c \\<equiv> case c of\n      IRQHandlerCap _ \\<Rightarrow> c\n    | ArchObjectCap acap \\<Rightarrow> arch_cap_cleanup_opt acap\n    | _ \\<Rightarrow> NullCap\"\n\n\ntext \\<open>Detect whether a capability is the final capability to a given object\nremaining in the system. Finalisation actions need to be taken when the final\ncapability to the object is deleted.\\<close>\ndefinition\n  is_final_cap' :: \"cap \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n \"is_final_cap' cap s \\<equiv>\n    \\<exists>cref. {cref. \\<exists>cap'. fst (get_cap cref s) = {(cap', s)}\n                       \\<and> (gen_obj_refs cap \\<inter> gen_obj_refs cap' \\<noteq> {})}\n         = {cref}\"\n\ndefinition\n  is_final_cap :: \"cap \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n  \"is_final_cap cap \\<equiv> gets (is_final_cap' cap)\"\n\ntext \\<open>Actions to be taken after an IRQ handler capability is deleted.\\<close>\ndefinition\n  deleted_irq_handler :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"deleted_irq_handler irq \\<equiv> set_irq_state IRQInactive irq\"\n\ntext \\<open>Actions to be taken after a cap is deleted\\<close>\ndefinition\n  post_cap_deletion :: \"cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"post_cap_deletion cap \\<equiv> case cap of\n       IRQHandlerCap irq \\<Rightarrow> deleted_irq_handler irq\n     | ArchObjectCap acap \\<Rightarrow> arch_post_cap_deletion acap\n     | _ \\<Rightarrow> return ()\"\n\ntext \\<open>Empty a capability slot assuming that the capability in it has been\nfinalised already.\\<close>\n\ndefinition\n  empty_slot :: \"cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"empty_slot slot cleanup_info \\<equiv> do\n      cap \\<leftarrow> get_cap slot;\n      if cap = NullCap then\n        return ()\n      else do\n        slot_p \\<leftarrow> gets (\\<lambda>s. cdt s slot);\n        cdt \\<leftarrow> gets cdt;\n        parent \\<leftarrow> return $ cdt slot;\n        set_cdt ((\\<lambda>p. if cdt p = Some slot\n                     then parent\n                     else cdt p) (slot := None));\n        do_extended_op (empty_slot_ext slot slot_p);\n        set_original slot False;\n        set_cap NullCap slot;\n\n        post_cap_deletion cleanup_info\n      od\n  od\"\n\ntext \\<open>Delete a capability with the assumption that the fast finalisation\nprocess will be sufficient.\\<close>\ndefinition\n  cap_delete_one :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"cap_delete_one slot \\<equiv> do\n    cap \\<leftarrow> get_cap slot;\n    unless (cap = NullCap) $ do\n      final \\<leftarrow> is_final_cap cap;\n      fast_finalise cap final;\n      empty_slot slot NullCap\n    od\n  od\"\n\ntext \\<open>Cancel the message receive operation of a thread waiting for a Reply\ncapability it has issued to be invoked.\\<close>\ndefinition\n  reply_cancel_ipc :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"reply_cancel_ipc tptr \\<equiv> do\n    thread_set (\\<lambda>tcb. tcb \\<lparr> tcb_fault := None \\<rparr>) tptr;\n    cap \\<leftarrow> get_cap (tptr, tcb_cnode_index 2);\n    descs \\<leftarrow> gets (descendants_of (tptr, tcb_cnode_index 2) o cdt);\n    when (descs \\<noteq> {}) $ do\n      assert (\\<exists>cslot_ptr. descs = {cslot_ptr});\n      cslot_ptr \\<leftarrow> select descs;\n      cap_delete_one cslot_ptr\n    od\n  od\"\n\ntext \\<open>Cancel the message receive operation of a thread queued in an\nnotification object.\\<close>\ndefinition\n  cancel_signal :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_signal threadptr ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     queue \\<leftarrow> (case ntfn_obj ntfn of WaitingNtfn queue \\<Rightarrow> return queue\n                        | _ \\<Rightarrow> fail);\n     queue' \\<leftarrow> return $ remove1 threadptr queue;\n     newNTFN \\<leftarrow> return $ ntfn_set_obj ntfn (case queue' of [] \\<Rightarrow> IdleNtfn\n                                                      | _  \\<Rightarrow> WaitingNtfn queue');\n     set_notification ntfnptr newNTFN;\n     set_thread_state threadptr Inactive\n   od\"\n\ntext \\<open>Cancel any message operations a given thread is waiting on.\\<close>\ndefinition\n  cancel_ipc :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cancel_ipc tptr \\<equiv> do\n     state \\<leftarrow> get_thread_state tptr;\n     case state\n       of\n          BlockedOnSend x y \\<Rightarrow> blocked_cancel_ipc state tptr\n        | BlockedOnReceive x y \\<Rightarrow> blocked_cancel_ipc state tptr\n        | BlockedOnNotification event \\<Rightarrow> cancel_signal tptr event\n        | BlockedOnReply \\<Rightarrow> reply_cancel_ipc tptr\n        | _ \\<Rightarrow> return ()\n   od\"\n\ntext \\<open>Currently, @{text update_restart_pc} can be defined generically up to\nthe actual register numbers.\\<close>\ndefinition\n  update_restart_pc :: \"obj_ref \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"update_restart_pc thread_ptr =\n        as_user thread_ptr (getRegister nextInstructionRegister\n                            >>= setRegister faultRegister)\"\n\ntext \\<open>Suspend a thread, cancelling any pending operations and preventing it\nfrom further execution by setting it to the Inactive state.\\<close>\ndefinition\n  suspend :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"suspend thread \\<equiv> do\n     cancel_ipc thread;\n     state \\<leftarrow> get_thread_state thread;\n     (if state = Running then update_restart_pc thread else return ());\n     set_thread_state thread Inactive;\n     do_extended_op (tcb_sched_action (tcb_sched_dequeue) thread)\n   od\"\n\nend"}
{"title": "./spec/abstract/CapRights_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDefinition of access rights.\n*)\n\nchapter \"Access Rights\"\n\ntheory CapRights_A\nimports Main\nbegin\n\ntext \\<open>The possible access-control rights that exist in the system.\n        Note that some rights are synonyms for others.\\<close>\ndatatype rights = AllowRead | AllowWrite | AllowGrant | AllowGrantReply\n\ndefinition\n  \"AllowSend \\<equiv> AllowWrite\"\ndefinition\n  \"AllowRecv \\<equiv> AllowRead\"\ndefinition\n  \"CanModify \\<equiv> AllowWrite\"\n\ntext \\<open>Cap rights are just a set of access rights\\<close>\ntype_synonym cap_rights = \"rights set\"\n\ntext \\<open>The set of all rights:\\<close>\ndefinition\n  all_rights :: cap_rights\nwhere\n \"all_rights \\<equiv> UNIV\"\n\nend"}
{"title": "./spec/abstract/TcbAcc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nTCB accessor functions\n*)\n\nchapter \"Accessors for Threads and TCBs\"\n\ntheory TcbAcc_A\nimports CSpace_A\nbegin\n\narch_requalify_consts (A)\n  in_user_frame\n\ntext \\<open>Store or load a word at an offset from an IPC buffer.\\<close>\ndefinition\n  store_word_offs :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"store_word_offs ptr offs v \\<equiv>\n    do s \\<leftarrow> get;\n       assert (in_user_frame (ptr + of_nat (offs * word_size)) s);\n       do_machine_op $ storeWord (ptr + of_nat (offs * word_size)) v\n    od\"\n\n\n(* Needed for page invocations. *)\ndefinition\n  set_message_info :: \"obj_ref \\<Rightarrow> message_info \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_message_info thread info \\<equiv>\n     as_user thread $ setRegister msg_info_register $\n                      message_info_to_data info\"\n\n\ndefinition\n  set_mrs :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> message list \\<Rightarrow> (length_type,'z::state_ext) s_monad\" where\n  \"set_mrs thread buf msgs \\<equiv>\n   do\n     tcb \\<leftarrow> gets_the $ get_tcb thread;\n     context \\<leftarrow> return (arch_tcb_get_registers (tcb_arch tcb));\n     new_regs \\<leftarrow> return (\\<lambda>reg. if reg \\<in> set (take (length msgs) msg_registers)\n                              then msgs ! (the_index msg_registers reg)\n                              else context reg);\n     set_object thread (TCB (tcb \\<lparr> tcb_arch := arch_tcb_set_registers new_regs (tcb_arch tcb) \\<rparr>));\n     remaining_msgs \\<leftarrow> return (drop (length msg_registers) msgs);\n     case buf of\n     None      \\<Rightarrow> return $ nat_to_len (min (length msg_registers) (length msgs))\n   | Some pptr \\<Rightarrow> do\n       zipWithM_x (\\<lambda>x. store_word_offs pptr x)\n          [length msg_registers + 1 ..< Suc msg_max_length] remaining_msgs;\n       return $ nat_to_len $ min (length msgs) msg_max_length\n     od\n   od\"\n\nend"}
{"title": "./spec/abstract/Structures_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nThe main architecture independent data types and type definitions in\nthe abstract model.\n*)\n\nchapter \"Basic Data Structures\"\n\ntheory Structures_A\nimports\n  Arch_Structs_A\n  \"ExecSpec.MachineExports\"\nbegin\n\narch_requalify_types (A)\n  aobject_type\n  arch_cap\n  arch_kernel_obj\n  arch_state\n  arch_tcb\n  aa_type\n\narch_requalify_consts (A)\n  acap_rights\n  acap_rights_update\n  arch_kobj_size\n  arch_obj_size\n  aobj_ref\n  arch_is_frame_type\n  badge_bits\n  default_arch_tcb\n  arch_tcb_context_get\n  arch_tcb_context_set\n  arch_tcb_set_registers\n  arch_tcb_get_registers\n  cte_level_bits\n  tcb_bits\n  endpoint_bits\n  ntfn_bits\n  aa_type\n  untyped_min_bits\n  untyped_max_bits\n  msg_label_bits\n\ntext \\<open>\n  User mode can request these objects to be created by retype:\n\\<close>\ndatatype apiobject_type =\n    Untyped\n  | TCBObject\n  | EndpointObject\n  | NotificationObject\n  | CapTableObject\n  | ArchObject aobject_type\n\ndefinition\n  is_frame_type :: \"apiobject_type \\<Rightarrow> bool\"\nwhere\n  \"is_frame_type obj \\<equiv> case obj of\n        ArchObject aobj \\<Rightarrow> arch_is_frame_type aobj\n      | _ \\<Rightarrow> False\"\n\n\ntext \\<open>These allow more informative type signatures for IPC operations.\\<close>\ntype_synonym badge = data\ntype_synonym msg_label = data\ntype_synonym message = data\n\n\ntext \\<open>This type models refences to capability slots. The first element\n  of the tuple points to the object the capability is contained in. The second\n  element is the index of the slot inside a slot-containing object. The default\n  slot-containing object is a cnode, thus the name @{text cnode_index}.\n\\<close>\ntype_synonym cnode_index = \"bool list\"\ntype_synonym cslot_ptr = \"obj_ref \\<times> cnode_index\"\n\n\ntext \\<open>Capabilities. Capabilities represent explicit authority to perform some\naction and are required for all system calls. Capabilities to Endpoint,\nNotification, Thread and CNode objects allow manipulation of standard kernel\nobjects. Untyped capabilities allow the creation and removal of kernel objects\nfrom a memory region. Reply capabilities allow sending a one-off message to\na thread waiting for a reply. IRQHandler and IRQControl caps allow a user to\nconfigure the way interrupts on one or all IRQs are handled. Capabilities to\narchitecture-specific facilities are provided through the @{text arch_cap} type.\nNull capabilities are the contents of empty capability slots; they confer no\nauthority and can be freely replaced. Zombie capabilities are stored when\nthe deletion of CNode and Thread objects is partially completed; they confer no\nauthority but cannot be replaced until the deletion is finished.\n\\<close>\n\ndatatype cap\n         = NullCap\n         | UntypedCap bool obj_ref nat nat\n           \\<comment> \\<open>device flag, pointer, size in bits (i.e. @{text \"size = 2^bits\"}) and freeIndex (i.e. @{text \"freeRef = obj_ref + (freeIndex * 2^4)\"})\\<close>\n         | EndpointCap obj_ref badge cap_rights\n         | NotificationCap obj_ref badge cap_rights\n         | ReplyCap obj_ref bool cap_rights\n         | CNodeCap obj_ref nat \"bool list\"\n           \\<comment> \\<open>CNode ptr, number of bits translated, guard\\<close>\n         | ThreadCap obj_ref\n         | DomainCap\n         | IRQControlCap\n         | IRQHandlerCap irq\n         | Zombie obj_ref \"nat option\" nat\n           \\<comment> \\<open>@{text \"cnode ptr * nat + tcb or cspace ptr\"}\\<close>\n         | ArchObjectCap (the_arch_cap: arch_cap)\n\nlemmas cap_cases =\n  cap.induct[where cap=cap and P=\"\\<lambda>cap'. cap' = cap \\<longrightarrow> P cap'\" for cap P, simplified, rule_format]\n\nlemmas cap_cases_asm =\ncap.induct[where cap=cap and P=\"\\<lambda>cap'. cap = cap' \\<longrightarrow> P cap' \\<longrightarrow> R\" for P R cap,\n  simplified, rule_format, rotated -1]\n\ntext \\<open>The CNode object is an array of capability slots. The domain of the\nfunction will always be the set of boolean lists of some specific length.\nEmpty slots contain a Null capability.\n\\<close>\ntype_synonym cnode_contents = \"cnode_index \\<Rightarrow> cap option\"\n\ntext \\<open>Various access functions for the cap type are defined for\nconvenience.\\<close>\ndefinition\n  the_cnode_cap :: \"cap \\<Rightarrow> obj_ref \\<times> nat \\<times> bool list\" where\n  \"the_cnode_cap cap \\<equiv>\n  case cap of\n    CNodeCap oref bits guard \\<Rightarrow> (oref, bits, guard)\"\n\nprimrec (nonexhaustive)\n  cap_ep_badge :: \"cap \\<Rightarrow> badge\"\nwhere\n  \"cap_ep_badge (EndpointCap _ badge _) = badge\"\n| \"cap_ep_badge (NotificationCap _ badge _) = badge\"\n\nprimrec (nonexhaustive)\n  cap_ep_ptr :: \"cap \\<Rightarrow> badge\"\nwhere\n  \"cap_ep_ptr (EndpointCap obj_ref _ _) = obj_ref\"\n| \"cap_ep_ptr (NotificationCap obj_ref _ _) = obj_ref\"\n\ndefinition\n  bits_of :: \"cap \\<Rightarrow> nat\" where\n  \"bits_of cap \\<equiv> case cap of\n    UntypedCap _ _ bits _ \\<Rightarrow> bits\n  | CNodeCap _ radix_bits _ \\<Rightarrow> radix_bits\"\n\ndefinition\n  free_index_of :: \"cap \\<Rightarrow> nat\" where\n  \"free_index_of cap \\<equiv> case cap of\n    UntypedCap _ _ _ free_index \\<Rightarrow> free_index\"\n\ndefinition\n  is_reply_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_reply_cap cap \\<equiv> case cap of ReplyCap _ m _ \\<Rightarrow> \\<not> m | _ \\<Rightarrow> False\"\ndefinition\n  is_master_reply_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_master_reply_cap cap \\<equiv> case cap of ReplyCap _ m _ \\<Rightarrow> m | _ \\<Rightarrow> False\"\ndefinition\n  is_zombie :: \"cap \\<Rightarrow> bool\" where\n  \"is_zombie cap \\<equiv> case cap of Zombie _ _ _ \\<Rightarrow> True | _ \\<Rightarrow> False\"\ndefinition\n  is_arch_cap :: \"cap \\<Rightarrow> bool\" where\n  \"is_arch_cap cap \\<equiv> case cap of ArchObjectCap _ \\<Rightarrow> True | _ \\<Rightarrow> False\"\n\ncontext\nnotes [[function_internals =true]]\nbegin\n\nfun is_cnode_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_cnode_cap (CNodeCap _ _ _) = True\"\n| \"is_cnode_cap _                = False\"\n\nfun is_thread_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_thread_cap (ThreadCap _) = True\"\n| \"is_thread_cap _             = False\"\n\nfun is_domain_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_domain_cap DomainCap = True\"\n| \"is_domain_cap _ = False\"\n\nfun is_untyped_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_untyped_cap (UntypedCap _ _ _ _) = True\"\n| \"is_untyped_cap _                  = False\"\n\nfun is_ep_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_ep_cap (EndpointCap _ _ _) = True\"\n| \"is_ep_cap _                   = False\"\n\nfun is_ntfn_cap :: \"cap \\<Rightarrow> bool\"\nwhere\n  \"is_ntfn_cap (NotificationCap _ _ _) = True\"\n| \"is_ntfn_cap _                        = False\"\n\nprimrec (nonexhaustive)\n  cap_rights :: \"cap \\<Rightarrow> cap_rights\"\nwhere\n  \"cap_rights (EndpointCap _ _ cr) = cr\"\n| \"cap_rights (NotificationCap _ _ cr) = cr\"\n| \"cap_rights (ReplyCap _ _ cr) = cr\"\n| \"cap_rights (ArchObjectCap acap) = acap_rights acap\"\nend\n\ntext \\<open>Various update functions for cap data common to various kinds of\ncap are defined here.\\<close>\ndefinition\n  cap_rights_update :: \"cap_rights \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"cap_rights_update cr' cap \\<equiv>\n   case cap of\n     EndpointCap oref badge cr \\<Rightarrow> EndpointCap oref badge cr'\n   | NotificationCap oref badge cr\n     \\<Rightarrow> NotificationCap oref badge (cr' - {AllowGrant, AllowGrantReply})\n   | ReplyCap t m cr \\<Rightarrow> ReplyCap t m (cr' - {AllowRead, AllowGrantReply} \\<union> {AllowWrite})\n   | ArchObjectCap acap \\<Rightarrow> ArchObjectCap (acap_rights_update cr' acap)\n   | _ \\<Rightarrow> cap\"\n\ndefinition\n  badge_update :: \"badge \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"badge_update data cap \\<equiv>\n   case cap of\n     EndpointCap oref badge cr \\<Rightarrow> EndpointCap oref (data && mask badge_bits) cr\n   | NotificationCap oref badge cr \\<Rightarrow> NotificationCap oref (data && mask badge_bits) cr\n   | _ \\<Rightarrow> cap\"\n\n\ndefinition\n  mask_cap :: \"cap_rights \\<Rightarrow> cap \\<Rightarrow> cap\" where\n  \"mask_cap rights cap \\<equiv> cap_rights_update (cap_rights cap \\<inter> rights) cap\""}
{"title": "./spec/abstract/Structures_A.thy", "section": "Kernel Objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The message info is the first thing interpreted on a user system call\nand determines the structure of the message the user thread is sending either to\nanother user or to a system service. It is also passed to user threads receiving\na message to indicate the structure of the message they have received. The\n@{text mi_length} parameter is the number of data words in the body of the\nmessage. The @{text mi_extra_caps} parameter is the number of caps to be passed\ntogether with the message. The @{text mi_caps_unwrapped} parameter is a bitmask\nallowing threads receiving a message to determine how extra capabilities were\ntransferred. The @{text mi_label} parameter is transferred directly from sender\nto receiver as part of the message.\n\\<close>\n\ndatatype message_info =\n  MI (mi_length: length_type)\n     (mi_extra_caps: length_type)\n     (mi_caps_unwrapped: data)\n     (mi_label: msg_label)\n\ntext \\<open>Message infos are encoded to or decoded from a data word.\\<close>\nprimrec\n  message_info_to_data :: \"message_info \\<Rightarrow> data\"\nwhere\n  \"message_info_to_data (MI len exc unw mlabel) =\n   (let\n        extra = exc << 7;\n        unwrapped = unw << 9;\n        label = mlabel << 12\n    in\n       label || extra || unwrapped || len)\"\n\ndefinition\n  data_to_message_info :: \"data \\<Rightarrow> message_info\"\nwhere\n  \"data_to_message_info w \\<equiv>\n   MI (let v = w && mask 7 in if v > 120 then 120 else v)\n      ((w >> 7) && mask 2)\n      ((w >> 9) && mask 3)\n      ((w >> 12) && mask msg_label_bits)\""}
{"title": "./spec/abstract/Structures_A.thy", "section": "Kernel Objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Endpoints are synchronous points of communication for threads. At any\ntime an endpoint may contain a queue of threads waiting to send, a queue of\nthreads waiting to receive or be idle. Whenever threads would be waiting to\nsend and receive simultaneously messages are transferred immediately.\n\\<close>\n\ndatatype endpoint\n           = IdleEP\n           | SendEP \"obj_ref list\"\n           | RecvEP \"obj_ref list\"\n\ntext \\<open>Notifications are sets of binary semaphores (stored in the\n\\emph{badge word}). Unlike endpoints, threads may choose to block waiting to\nreceive, but not to send.\\<close>\n\ndatatype ntfn\n           = IdleNtfn\n           | WaitingNtfn \"obj_ref list\"\n           | ActiveNtfn badge\n\nrecord notification =\n  ntfn_obj :: ntfn\n  ntfn_bound_tcb :: \"obj_ref option\"\n\n\ndefinition\n  default_ep :: endpoint where\n  \"default_ep \\<equiv> IdleEP\"\n\ndefinition\n  default_ntfn :: ntfn where\n  \"default_ntfn \\<equiv> IdleNtfn\"\n\ndefinition\n  default_notification :: notification where\n  \"default_notification \\<equiv> \\<lparr>\n     ntfn_obj = default_ntfn,\n     ntfn_bound_tcb = None \\<rparr>\"\n\n\ntext \\<open>Thread Control Blocks are the in-kernel representation of a thread.\n\nThreads which can execute are either in the Running state for normal execution,\nin the Restart state if their last operation has not completed yet or in the\nIdleThreadState for the unique system idle thread. Threads can also be blocked\nwaiting for any of the different kinds of system messages. The Inactive state\nindicates that the TCB is not currently used by a running thread.\n\nTCBs also contain some special-purpose capability slots. The CTable slot is a\ncapability to a CNode through which the thread accesses capabilities with which\nto perform system calls. The VTable slot is a capability to a virtual address\nspace (an architecture-specific capability type) in which the thread runs. If\nthe thread has issued a Reply cap to another thread and is awaiting a reply,\nthat cap will have a \"master\" Reply cap as its parent in the Reply slot. The\nCaller slot is used to initially store any Reply cap issued to this thread. The\nIPCFrame slot stores a capability to a memory frame (an architecture-specific\ncapability type) through which messages will be sent and received.\n\nIf the thread has encountered a fault and is waiting to send it to its\nsupervisor the fault is stored in @{text tcb_fault}. The user register file is\nstored in @{text tcb_context}, the pointer to the cap in the IPCFrame slot in\n@{text tcb_ipc_buffer} and the identity of the Endpoint cap through which faults\nare to be sent in @{text tcb_fault_handler}.\n\\<close>\n\nrecord sender_payload =\n sender_badge           :: badge\n sender_can_grant       :: bool\n sender_can_grant_reply :: bool\n sender_is_call         :: bool\n\nrecord receiver_payload =\n receiver_can_grant :: bool\n\ndatatype thread_state\n  = Running\n  | Inactive\n  | Restart\n  | BlockedOnReceive obj_ref receiver_payload\n  | BlockedOnSend obj_ref sender_payload\n  | BlockedOnReply\n  | BlockedOnNotification obj_ref\n  | IdleThreadState\n\ntype_synonym priority = word8\n\nrecord tcb =\n tcb_ctable        :: cap\n tcb_vtable        :: cap\n tcb_reply         :: cap\n tcb_caller        :: cap\n tcb_ipcframe      :: cap\n tcb_state         :: thread_state\n tcb_fault_handler :: cap_ref\n tcb_ipc_buffer    :: vspace_ref\n tcb_fault         :: \"fault option\"\n tcb_bound_notification     :: \"obj_ref option\"\n tcb_mcpriority    :: priority\n tcb_arch          :: arch_tcb (* arch_tcb must have a field for user context *)\n\n\ntext \\<open>Determines whether a thread in a given state may be scheduled.\\<close>\nprimrec\n  runnable :: \"Structures_A.thread_state \\<Rightarrow> bool\"\nwhere\n  \"runnable (Running)               = True\"\n| \"runnable (Inactive)              = False\"\n| \"runnable (Restart)               = True\"\n| \"runnable (BlockedOnReceive x y)  = False\"\n| \"runnable (BlockedOnSend x y)     = False\"\n| \"runnable (BlockedOnNotification x) = False\"\n| \"runnable (IdleThreadState)       = False\"\n| \"runnable (BlockedOnReply)        = False\"\n\n\ndefinition\n  default_tcb :: tcb where\n  \"default_tcb \\<equiv> \\<lparr>\n      tcb_ctable   = NullCap,\n      tcb_vtable   = NullCap,\n      tcb_reply    = NullCap,\n      tcb_caller   = NullCap,\n      tcb_ipcframe = NullCap,\n      tcb_state    = Inactive,\n      tcb_fault_handler = to_bl (0::machine_word),\n      tcb_ipc_buffer = 0,\n      tcb_fault      = None,\n      tcb_bound_notification  = None,\n      tcb_mcpriority = minBound,\n      tcb_arch       = default_arch_tcb\\<rparr>\"\n\ntext \\<open>\nAll kernel objects are CNodes, TCBs, Endpoints, Notifications or architecture\nspecific.\n\\<close>\ndatatype kernel_object\n         = CNode nat cnode_contents \\<comment> \\<open>size in bits, and contents\\<close>\n         | TCB tcb\n         | Endpoint endpoint\n         | Notification notification\n         | ArchObj (the_arch_obj: arch_kernel_obj)\n\nlemmas kernel_object_cases =\n  kernel_object.induct[where kernel_object=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P, simplified, rule_format]\n\nlemmas kernel_object_cases_asm =\nkernel_object.induct[where kernel_object=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n  simplified, rule_format, rotated -1]\n\ndefinition aobj_of :: \"kernel_object \\<Rightarrow> arch_kernel_obj option\"\n  where\n  \"aobj_of ko \\<equiv> case ko of ArchObj aobj \\<Rightarrow> Some aobj | _ \\<Rightarrow> None\"\n\ntext \\<open>Checks whether a cnode's contents are well-formed.\\<close>\n\ndefinition\n  well_formed_cnode_n :: \"nat \\<Rightarrow> cnode_contents \\<Rightarrow> bool\" where\n \"well_formed_cnode_n n \\<equiv> \\<lambda>cs. dom cs = {x. length x = n}\"\n\nprimrec\n  obj_bits :: \"kernel_object \\<Rightarrow> nat\"\nwhere\n  \"obj_bits (CNode sz cs) = cte_level_bits + sz\"\n| \"obj_bits (TCB t) = tcb_bits\"\n| \"obj_bits (Endpoint ep) = endpoint_bits\"\n| \"obj_bits (Notification ntfn) = ntfn_bits\"\n| \"obj_bits (ArchObj ao) = arch_kobj_size ao\"\n\nprimrec (nonexhaustive)\n  obj_size :: \"cap \\<Rightarrow> machine_word\"\nwhere\n  \"obj_size NullCap = 0\"\n| \"obj_size (UntypedCap dev r bits f) = 1 << bits\"\n| \"obj_size (EndpointCap r b R) = 1 << obj_bits (Endpoint undefined)\"\n| \"obj_size (NotificationCap r b R) = 1 << obj_bits (Notification undefined)\"\n| \"obj_size (CNodeCap r bits g) = 1 << (cte_level_bits + bits)\"\n| \"obj_size (ThreadCap r) = 1 << obj_bits (TCB undefined)\"\n| \"obj_size (Zombie r zb n) = (case zb of None \\<Rightarrow> 1 << obj_bits (TCB undefined)\n                                        | Some n \\<Rightarrow> 1 << (cte_level_bits + n))\"\n| \"obj_size (ArchObjectCap a) = 1 << arch_obj_size a\"\n\n\ntext \\<open>Object types:\\<close>\n\ndatatype a_type =\n    ATCB\n  | AEndpoint\n  | ANTFN\n  | ACapTable nat\n  | AGarbage nat \\<comment> \\<open>number of bytes of garbage\\<close>\n  | AArch aa_type\n\ndefinition\n  a_type :: \"kernel_object \\<Rightarrow> a_type\"\nwhere\n \"a_type ob \\<equiv> case ob of\n           CNode sz cspace           \\<Rightarrow> if well_formed_cnode_n sz cspace\n                                        then ACapTable sz else AGarbage (cte_level_bits + sz)\n         | TCB tcb                   \\<Rightarrow> ATCB\n         | Endpoint endpoint         \\<Rightarrow> AEndpoint\n         | Notification notification \\<Rightarrow> ANTFN\n         | ArchObj ao                \\<Rightarrow> AArch (aa_type ao)\""}
{"title": "./spec/abstract/Structures_A.thy", "section": "Kernel State", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The kernel's heap is a partial function containing kernel objects.\\<close>\ntype_synonym kheap = \"obj_ref \\<Rightarrow> kernel_object option\"\n\ntext \\<open>\nCapabilities are created either by cloning an existing capability or by creating\na subordinate capability from it. This results in a capability derivation tree\nor CDT. The kernel provides a Revoke operation which deletes all capabilities\nderived from one particular capability. To support this, the kernel stores the\nCDT explicitly. It is here stored as a tree, a partial mapping from\ncapability slots to parent capability slots.\n\\<close>\ntype_synonym cdt = \"cslot_ptr \\<Rightarrow> cslot_ptr option\"\n\ndatatype irq_state =\n   IRQInactive\n | IRQSignal\n | IRQTimer\n | IRQReserved\n\ntext \\<open>The kernel state includes a heap, a capability derivation tree\n(CDT), a bitmap used to determine if a capability is the original\ncapability to that object, a pointer to the current thread, a pointer\nto the system idle thread, the state of the underlying machine,\nper-irq pointers to cnodes (each containing one notification through which\ninterrupts are delivered), an array recording which\ninterrupts are used for which purpose, and the state of the\narchitecture-specific kernel module.\n\nNote: for each irq, @{text \"interrupt_irq_node irq\"} points to a cnode which\ncan contain the notification cap through which interrupts are delivered. In\nC, this all lives in a single array. In the abstract spec though, to prove\nsecurity, we can't have a single object accessible by everyone. Hence the need\nto separate irq handlers.\n\\<close>\nrecord abstract_state =\n  kheap              :: kheap\n  cdt                :: cdt\n  is_original_cap    :: \"cslot_ptr \\<Rightarrow> bool\"\n  cur_thread         :: obj_ref\n  idle_thread        :: obj_ref\n  machine_state      :: machine_state\n  interrupt_irq_node :: \"irq \\<Rightarrow> obj_ref\"\n  interrupt_states   :: \"irq \\<Rightarrow> irq_state\"\n  arch_state         :: arch_state\n\ntext \\<open>The following record extends the abstract kernel state with extra\nstate of type @{typ \"'a\"}. The specification operates over states of\nthis extended type. By choosing an appropriate concrete type for @{typ \"'a\"}\nwe may obtain different \\emph{instantiations} of the kernel specifications\nat differing levels of abstraction. See \\autoref{c:ext-spec} for further\ninformation.\n\\<close>\nrecord 'a state = abstract_state + exst :: 'a"}
{"title": "./spec/abstract/Structures_A.thy", "section": "Helper functions", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This wrapper lifts monadic operations on the underlying machine state to\nmonadic operations on the kernel state.\\<close>\ndefinition\n  do_machine_op :: \"(machine_state, 'a) nondet_monad \\<Rightarrow> ('z state, 'a) nondet_monad\"\nwhere\n \"do_machine_op mop \\<equiv> do\n    ms \\<leftarrow> gets machine_state;\n    (r, ms') \\<leftarrow> select_f (mop ms);\n    modify (\\<lambda>state. state \\<lparr> machine_state := ms' \\<rparr>);\n    return r\n  od\"\n\ntext \\<open>This function generates the cnode indices used when addressing the\ncapability slots within a TCB.\n\\<close>\ndefinition\n  tcb_cnode_index :: \"nat \\<Rightarrow> cnode_index\" where\n  \"tcb_cnode_index n \\<equiv> to_bl (of_nat n :: 3 word)\"\n\ntext \\<open>Zombie capabilities store the bit size of the CNode cap they were\ncreated from or None if they were created from a TCB cap. This function\ndecodes the bit-length of cnode indices into the relevant kernel objects.\n\\<close>\ndefinition\n  zombie_cte_bits :: \"nat option \\<Rightarrow> nat\" where\n \"zombie_cte_bits N \\<equiv> case N of Some n \\<Rightarrow> n | None \\<Rightarrow> 3\"\n\nlemma zombie_cte_bits_simps[simp]:\n \"zombie_cte_bits (Some n) = n\"\n \"zombie_cte_bits None     = 3\"\n  by (simp add: zombie_cte_bits_def)+\n\ntext \\<open>The first capability slot of the relevant kernel object.\\<close>\nprimrec (nonexhaustive)\n  first_cslot_of :: \"cap \\<Rightarrow> cslot_ptr\"\nwhere\n  \"first_cslot_of (ThreadCap oref) = (oref, tcb_cnode_index 0)\"\n| \"first_cslot_of (CNodeCap oref bits g) = (oref, replicate bits False)\"\n| \"first_cslot_of (Zombie oref bits n) = (oref, replicate (zombie_cte_bits bits) False)\"\n\ntext \\<open>The set of all objects referenced by a capability.\\<close>\nprimrec\n  obj_refs :: \"cap \\<Rightarrow> obj_ref set\"\nwhere\n  \"obj_refs NullCap = {}\"\n| \"obj_refs (ReplyCap r m cr) = {}\"\n| \"obj_refs IRQControlCap = {}\"\n| \"obj_refs (IRQHandlerCap irq) = {}\"\n| \"obj_refs (UntypedCap dev r s f) = {}\"\n| \"obj_refs (CNodeCap r bits guard) = {r}\"\n| \"obj_refs (EndpointCap r b cr) = {r}\"\n| \"obj_refs (NotificationCap r b cr) = {r}\"\n| \"obj_refs (ThreadCap r) = {r}\"\n| \"obj_refs DomainCap = {}\"\n| \"obj_refs (Zombie ptr b n) = {ptr}\"\n| \"obj_refs (ArchObjectCap x) = set_option (aobj_ref x)\"\n\ntext \\<open>\n  The partial definition below is sometimes easier to work with.\n  It also provides cases for UntypedCap and ReplyCap which are not\n  true object references in the sense of the other caps.\n\\<close>\nprimrec (nonexhaustive)\n  obj_ref_of :: \"cap \\<Rightarrow> obj_ref\"\nwhere\n  \"obj_ref_of (UntypedCap dev r s f) = r\"\n| \"obj_ref_of (ReplyCap r m cr) = r\"\n| \"obj_ref_of (CNodeCap r bits guard) = r\"\n| \"obj_ref_of (EndpointCap r b cr) = r\"\n| \"obj_ref_of (NotificationCap r b cr) = r\"\n| \"obj_ref_of (ThreadCap r) = r\"\n| \"obj_ref_of (Zombie ptr b n) = ptr\"\n| \"obj_ref_of (ArchObjectCap x) = the (aobj_ref x)\"\n\nprimrec (nonexhaustive)\n  cap_bits_untyped :: \"cap \\<Rightarrow> nat\"\nwhere\n  \"cap_bits_untyped (UntypedCap dev r s f) = s\"\n\ndefinition tcb_cnode_map :: \"tcb \\<Rightarrow> cnode_index \\<Rightarrow> cap option\"\n  where\n  \"tcb_cnode_map tcb \\<equiv>\n   [tcb_cnode_index 0 \\<mapsto> tcb_ctable tcb,\n    tcb_cnode_index 1 \\<mapsto> tcb_vtable tcb,\n    tcb_cnode_index 2 \\<mapsto> tcb_reply tcb,\n    tcb_cnode_index 3 \\<mapsto> tcb_caller tcb,\n    tcb_cnode_index 4 \\<mapsto> tcb_ipcframe tcb]\"\n\ndefinition cap_of :: \"kernel_object \\<Rightarrow> cnode_index \\<Rightarrow> cap option\"\n  where\n  \"cap_of kobj \\<equiv> case kobj of CNode _ cs \\<Rightarrow> cs | TCB tcb \\<Rightarrow> tcb_cnode_map tcb | _ \\<Rightarrow> Map.empty\"\n\ntext \\<open>The set of all caps contained in a kernel object.\\<close>\n\ndefinition\n  caps_of :: \"kernel_object \\<Rightarrow> cap set\" where\n  \"caps_of kobj \\<equiv> ran (cap_of kobj)\""}
{"title": "./spec/abstract/Structures_A.thy", "section": "Cap transfers", "subsection": "", "subsubsection": "", "code": "\nrecord captransfer =\n  ct_receive_root :: cap_ref\n  ct_receive_index :: cap_ref\n  ct_receive_depth :: data\n\ntext \\<open>A thread's IPC buffer capability must be to a page that is capable of\ncontaining the IPC buffer without the end of the buffer spilling into another\npage.\\<close>\ndefinition cap_transfer_data_size :: nat\n  where\n  \"cap_transfer_data_size \\<equiv> 3\"\n\ndefinition msg_max_length :: nat\n  where\n  \"msg_max_length \\<equiv> 120\"\n\ndefinition msg_max_extra_caps :: nat\n  where\n  \"msg_max_extra_caps \\<equiv> 3\"\n\ndefinition max_ipc_length :: nat\n  where\n  \"max_ipc_length \\<equiv> cap_transfer_data_size + msg_max_length + msg_max_extra_caps + 2\"\n\ndefinition msg_align_bits :: nat\n  where\n  \"msg_align_bits \\<equiv> word_size_bits + (LEAST n. max_ipc_length \\<le> 2 ^ n)\"\n\nlemma msg_align_bits':\n  \"msg_align_bits = word_size_bits + 7\"\nproof -\n  have \"(LEAST n. (cap_transfer_data_size + msg_max_length + msg_max_extra_caps + 2) \\<le> 2 ^ n) = 7\"\n  proof (rule Least_equality)\n    show \"(cap_transfer_data_size + msg_max_length + msg_max_extra_caps + 2)  \\<le> 2 ^ 7\"\n      by (simp add: cap_transfer_data_size_def msg_max_length_def msg_max_extra_caps_def)\n  next\n    fix y\n    assume \"(cap_transfer_data_size + msg_max_length + msg_max_extra_caps + 2) \\<le> 2 ^ y\"\n    hence \"(2 :: nat) ^ 7 \\<le> 2 ^ y\"\n      by (simp add: cap_transfer_data_size_def msg_max_length_def msg_max_extra_caps_def)\n    thus \"7 \\<le> y\"\n      by (rule power_le_imp_le_exp [rotated], simp)\n  qed\n  thus ?thesis unfolding msg_align_bits_def max_ipc_length_def by simp\nqed\n\nend"}
{"title": "./spec/abstract/CSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nAbstract model of CSpace.\n*)\n\nchapter \"CSpace\"\n\ntheory CSpace_A\nimports\n  ArchVSpace_A\n  IpcCancel_A\n  ArchCSpace_A\n  \"Monads.Nondet_Lemmas\"\n  \"HOL-Library.Prefix_Order\"\nbegin\n\narch_requalify_consts (A)\n  aobjs_of\n  arch_update_cap_data\n  arch_derive_cap\n  arch_finalise_cap\n  arch_is_physical\n  arch_same_region_as\n  same_aobject_as\n  prepare_thread_delete\n  update_cnode_cap_data\n  cnode_padding_bits\n  cnode_guard_size_bits\n  arch_is_cap_revocable\n\n\ntext \\<open>This theory develops an abstract model of \\emph{capability\nspaces}, or CSpace, in seL4. The CSpace of a thread can be thought of\nas the set of all capabilities it has access to. More precisely, it\nis a directed graph of CNodes starting in the CSpace slot of a TCB.\nCapabilities are accessed from the user side by specifying a path in this\ngraph. The kernel internally uses references to CNodes with an index into\nthe CNode to identify capabilities.\n\nThe following sections show basic manipulation of capabilities,\nresolving user-specified, path-based capability references into\ninternal kernel references, transfer, revokation, deletion,\nand finally toplevel capability invocations.\n\\<close>"}
{"title": "./spec/abstract/CSpace_A.thy", "section": "Resolving capability references", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Interpret a set of rights from a user data word.\\<close>\ndefinition\n  data_to_rights :: \"data \\<Rightarrow> cap_rights\" where\n  \"data_to_rights data \\<equiv> let\n    w = data_to_16 data\n   in {x. case x of AllowWrite \\<Rightarrow> w !! 0\n                  | AllowRead \\<Rightarrow> w !! 1\n                  | AllowGrant \\<Rightarrow> w !! 2\n                  | AllowGrantReply \\<Rightarrow> w !! 3}\"\n\ntext \\<open>Check that a capability stored in a slot is not a parent of any other\ncapability.\\<close>\ndefinition\n  ensure_no_children :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"ensure_no_children cslot_ptr \\<equiv> doE\n    cdt \\<leftarrow> liftE $ gets cdt;\n    whenE (\\<exists>c. cdt c = Some cslot_ptr) (throwError RevokeFirst)\n  odE\"\n\ndefinition\n  max_free_index :: \"nat \\<Rightarrow> nat\" where\n  \"max_free_index magnitude_bits \\<equiv> 2 ^ magnitude_bits\"\n\ndefinition\n  free_index_update :: \"(nat \\<Rightarrow> nat) \\<Rightarrow> cap \\<Rightarrow> cap\"\nwhere\n  \"free_index_update g cap \\<equiv>\n   case cap of UntypedCap dev ref sz f \\<Rightarrow> UntypedCap dev ref sz (g f) | _ \\<Rightarrow> cap\"\n\nprimrec (nonexhaustive)\n  untyped_sz_bits :: \"cap \\<Rightarrow> nat\"\nwhere\n  \"untyped_sz_bits (UntypedCap dev ref sz f) = sz\"\n\nabbreviation\n  max_free_index_update :: \"cap \\<Rightarrow> cap\"\nwhere\n  \"max_free_index_update cap \\<equiv> cap \\<lparr> free_index:= max_free_index (untyped_sz_bits cap) \\<rparr>\"\n\ndefinition\n  set_untyped_cap_as_full :: \"cap \\<Rightarrow> cap \\<Rightarrow> obj_ref \\<times> bool list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_untyped_cap_as_full src_cap new_cap src_slot \\<equiv>\n   if (is_untyped_cap src_cap \\<and> is_untyped_cap new_cap\n       \\<and> obj_ref_of src_cap = obj_ref_of new_cap \\<and> cap_bits_untyped src_cap = cap_bits_untyped new_cap)\n       then set_cap (max_free_index_update src_cap) src_slot else return ()\"\n\ntext \\<open>Derive a cap into a form in which it can be copied. For internal reasons\nnot all capability types can be copied at all times and not all capability types\ncan be copied unchanged.\\<close>\ndefinition\nderive_cap :: \"cslot_ptr \\<Rightarrow> cap \\<Rightarrow> (cap,'z::state_ext) se_monad\" where\n\"derive_cap slot cap \\<equiv>\n case cap of\n    ArchObjectCap c \\<Rightarrow> arch_derive_cap c\n    | UntypedCap dev ptr sz f \\<Rightarrow> doE ensure_no_children slot; returnOk cap odE\n    | Zombie ptr n sz \\<Rightarrow> returnOk NullCap\n    | ReplyCap ptr m cr \\<Rightarrow> returnOk NullCap\n    | IRQControlCap \\<Rightarrow> returnOk NullCap\n    | _ \\<Rightarrow> returnOk cap\"\n\ntext \\<open>Transform a capability on request from a user thread. The user-supplied\nargument word is interpreted differently for different cap types. If the\npreserve flag is set this transformation is being done in-place which means some\nchanges are disallowed because they would invalidate existing CDT relationships.\n\\<close>\ndefinition\n  update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> cap \\<Rightarrow> cap\" where\n\"update_cap_data preserve w cap \\<equiv>\n  if is_ep_cap cap then\n    if cap_ep_badge cap = 0 \\<and> \\<not> preserve then\n      badge_update w cap\n    else NullCap\n  else if is_ntfn_cap cap then\n    if cap_ep_badge cap = 0 \\<and> \\<not> preserve then\n      badge_update w cap\n    else NullCap\n  else if is_cnode_cap cap then\n    let\n        (oref, bits, guard) = the_cnode_cap cap;\n        (guard_size', guard'') = update_cnode_cap_data w;\n        guard' = drop (size guard'' - guard_size') (to_bl guard'')\n    in\n        if guard_size' + bits > word_bits\n        then NullCap\n        else CNodeCap oref bits guard'\n  else if is_arch_cap cap then\n    arch_update_cap_data preserve w (the_arch_cap cap)\n  else\n    cap\""}
{"title": "./spec/abstract/CSpace_A.thy", "section": "Transferring capabilities", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\nRecursively looks up a capability address to a CNode slot by walking over\nmultiple CNodes until all the bits in the address are used or there are\nno further CNodes.\n\\<close>\nfunction resolve_address_bits' :: \"'z itself \\<Rightarrow> cap \\<times> cap_ref \\<Rightarrow> (cslot_ptr \\<times> cap_ref,'z::state_ext) lf_monad\"\nwhere\n  \"resolve_address_bits' z (cap, cref) =\n  (case cap of\n     CNodeCap oref radix_bits guard  \\<Rightarrow>\n     if radix_bits + size guard = 0 then\n       fail \\<comment> \\<open>nothing is translated: table broken\\<close>\n     else doE\n       whenE (\\<not> guard \\<le> cref)\n             \\<comment> \\<open>guard does not match\\<close>\n             (throwError $ GuardMismatch (size cref) guard);\n\n       whenE (size cref < radix_bits + size guard)\n             \\<comment> \\<open>not enough bits to resolve: table malformed\\<close>\n             (throwError $ DepthMismatch (size cref) (radix_bits+size guard));\n\n       offset \\<leftarrow> returnOk $ take radix_bits (drop (size guard) cref);\n       rest \\<leftarrow> returnOk $ drop (radix_bits + size guard) cref;\n       if rest = [] then\n         returnOk ((oref,offset), [])\n       else doE\n         next_cap \\<leftarrow> liftE $ get_cap (oref, offset);\n         if is_cnode_cap next_cap then\n           resolve_address_bits' z (next_cap, rest)\n         else\n           returnOk ((oref,offset), rest)\n       odE\n     odE\n   | _ \\<Rightarrow> throwError InvalidRoot)\"\n  by auto\n\nlemma rab_termination:\n  \"\\<forall>cref guard radix_bits.\n    \\<not> length cref \\<le> radix_bits + length guard \\<and>\n    (0 < radix_bits \\<or> guard \\<noteq> []) \\<longrightarrow>\n      length cref - (radix_bits + length guard) < length cref\"\n  apply clarsimp\n  apply (erule disjE)\n   apply arith\n  apply (clarsimp simp: neq_Nil_conv)\n  apply arith\n  done\n\ntermination\n  apply (relation \"measure (\\<lambda>(z,cap, cs). size cs)\")\n  apply (auto simp: whenE_def returnOk_def return_def rab_termination)\n  done\n\ndeclare resolve_address_bits'.simps[simp del]\n\ndefinition resolve_address_bits where\n\"resolve_address_bits \\<equiv> resolve_address_bits' TYPE('z::state_ext)\"\n\ntext \\<open>Specialisations of the capability lookup process to various standard\ncases.\\<close>\ndefinition\n  lookup_slot_for_thread :: \"obj_ref \\<Rightarrow> cap_ref \\<Rightarrow> (cslot_ptr \\<times> cap_ref,'z::state_ext) lf_monad\"\nwhere\n  \"lookup_slot_for_thread thread cref \\<equiv> doE\n     tcb \\<leftarrow> liftE $ gets_the $ get_tcb thread;\n     resolve_address_bits (tcb_ctable tcb, cref)\n  odE\"\n\ndefinition\n  lookup_cap_and_slot :: \"obj_ref \\<Rightarrow> cap_ref \\<Rightarrow> (cap \\<times> cslot_ptr,'z::state_ext) lf_monad\" where\n  \"lookup_cap_and_slot thread cptr \\<equiv> doE\n      (slot, cr) \\<leftarrow> lookup_slot_for_thread thread cptr;\n      cap \\<leftarrow> liftE $ get_cap slot;\n      returnOk (cap, slot)\n  odE\"\n\ndefinition\n  lookup_cap :: \"obj_ref \\<Rightarrow> cap_ref \\<Rightarrow> (cap,'z::state_ext) lf_monad\" where\n  \"lookup_cap thread ref \\<equiv> doE\n     (ref', _) \\<leftarrow> lookup_slot_for_thread thread ref;\n     liftE $ get_cap ref'\n   odE\"\n\ndefinition\n  lookup_slot_for_cnode_op ::\n  \"bool \\<Rightarrow> cap \\<Rightarrow> cap_ref \\<Rightarrow> nat \\<Rightarrow> (cslot_ptr,'z::state_ext) se_monad\"\nwhere\n \"lookup_slot_for_cnode_op is_source croot ptr depth \\<equiv>\n  if is_cnode_cap croot then\n  doE\n    whenE (depth < 1 \\<or> depth > word_bits)\n      $ throwError (RangeError 1 (of_nat word_bits));\n    lookup_error_on_failure is_source $ doE\n      ptrbits_for_depth \\<leftarrow> returnOk $ drop (length ptr - depth) ptr;\n      (slot, rem) \\<leftarrow> resolve_address_bits (croot, ptrbits_for_depth);\n      case rem of\n        [] \\<Rightarrow> returnOk slot\n      | _  \\<Rightarrow> throwError $ DepthMismatch (length rem) 0\n    odE\n  odE\n  else\n    throwError (FailedLookup is_source InvalidRoot)\"\n\ndefinition\n  lookup_source_slot :: \"cap \\<Rightarrow> cap_ref \\<Rightarrow> nat \\<Rightarrow> (cslot_ptr,'z::state_ext) se_monad\"\nwhere\n \"lookup_source_slot \\<equiv> lookup_slot_for_cnode_op True\"\n\ndefinition\n  lookup_target_slot :: \"cap \\<Rightarrow> cap_ref \\<Rightarrow> nat \\<Rightarrow> (cslot_ptr,'z::state_ext) se_monad\"\nwhere\n \"lookup_target_slot \\<equiv> lookup_slot_for_cnode_op False\"\n\ndefinition\n  lookup_pivot_slot :: \"cap \\<Rightarrow> cap_ref \\<Rightarrow> nat \\<Rightarrow> (cslot_ptr,'z::state_ext) se_monad\"\nwhere\n \"lookup_pivot_slot  \\<equiv> lookup_slot_for_cnode_op True\""}
{"title": "./spec/abstract/CSpace_A.thy", "section": "Transferring capabilities", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>These functions are used in interpreting from user arguments the manner\nin which a capability transfer should take place.\\<close>\n\ndefinition\n  captransfer_from_words :: \"machine_word \\<Rightarrow> (captransfer,'z::state_ext) s_monad\"\nwhere\n  \"captransfer_from_words ptr \\<equiv> do\n     w0 \\<leftarrow> do_machine_op $ loadWord ptr;\n     w1 \\<leftarrow> do_machine_op $ loadWord (ptr + word_size);\n     w2 \\<leftarrow> do_machine_op $ loadWord (ptr + 2 * word_size);\n     return \\<lparr> ct_receive_root = data_to_cptr w0,\n              ct_receive_index = data_to_cptr w1,\n              ct_receive_depth = w2 \\<rparr>\n   od\"\n\ndefinition\n  load_cap_transfer :: \"obj_ref \\<Rightarrow> (captransfer,'z::state_ext) s_monad\" where\n \"load_cap_transfer buffer \\<equiv> do\n     offset \\<leftarrow> return $ msg_max_length + msg_max_extra_caps + 2;\n     captransfer_from_words (buffer + of_nat offset * word_size)\n  od\"\n\nfun\n  get_receive_slots :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow>\n                         (cslot_ptr list,'z::state_ext) s_monad\"\nwhere\n  \"get_receive_slots thread (Some buffer) = do\n     ct \\<leftarrow> load_cap_transfer buffer;\n\n     empty_on_failure $ doE\n       cnode \\<leftarrow> unify_failure $\n                  lookup_cap thread (ct_receive_root ct);\n       slot \\<leftarrow> unify_failure $ lookup_target_slot cnode\n                  (ct_receive_index ct) (unat (ct_receive_depth ct));\n\n       cap \\<leftarrow> liftE $ get_cap slot;\n\n       whenE (cap \\<noteq> NullCap) (throwError ());\n\n       returnOk [slot]\n     odE\n   od\"\n|  \"get_receive_slots x None = return []\""}
{"title": "./spec/abstract/CSpace_A.thy", "section": "Revoking and deleting capabilities", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Deletion of the final capability to any object is a long running\noperation if the capability is of these types.\\<close>\ndefinition\n  long_running_delete :: \"cap \\<Rightarrow> bool\" where\n \"long_running_delete cap \\<equiv> case cap of\n    CNodeCap ptr bits gd \\<Rightarrow> True\n  | Zombie ptr bits n \\<Rightarrow> True\n  | ThreadCap ptr \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"\n\n\ndefinition\n  slot_cap_long_running_delete :: \"cslot_ptr \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"slot_cap_long_running_delete slot \\<equiv> do\n     cap \\<leftarrow> get_cap slot;\n     case cap of\n         NullCap \\<Rightarrow> return False\n       | _ \\<Rightarrow> do\n           final \\<leftarrow> is_final_cap cap;\n           return (final \\<and> long_running_delete cap)\n         od\n   od\"\n\ntext \\<open>Swap the contents of two capability slots. The capability parameters are\nthe new states of the capabilities, as the user may request that the\ncapabilities are transformed as they are swapped.\\<close>\ndefinition\n  cap_swap :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cap_swap cap1 slot1 cap2 slot2 \\<equiv>\n  do\n    set_cap cap2 slot1;\n    set_cap cap1 slot2;\n    slot1_p \\<leftarrow> gets (\\<lambda>s. cdt s slot1);\n    slot2_p \\<leftarrow> gets (\\<lambda>s. cdt s slot2);\n    cdt \\<leftarrow> gets cdt;\n    \\<comment> \\<open>update children:\\<close>\n    cdt' \\<leftarrow> return (\\<lambda>n. if cdt n = Some slot1\n                        then Some slot2\n                        else if cdt n = Some slot2\n                        then Some slot1\n                        else cdt n);\n    \\<comment> \\<open>update parents:\\<close>\n    set_cdt (cdt' (slot1 := cdt' slot2, slot2 := cdt' slot1));\n    do_extended_op (cap_swap_ext slot1 slot2 slot1_p slot2_p);\n    is_original \\<leftarrow> gets is_original_cap;\n    set_original slot1 (is_original slot2);\n    set_original slot2 (is_original slot1)\n  od\"\n\ntext \\<open>Move a capability from one slot to another. Once again the new\ncapability is a parameter as it may be transformed while it is moved.\\<close>\ndefinition\n  cap_move :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cap_move new_cap src_slot dest_slot \\<equiv> do\n    set_cap new_cap dest_slot;\n    set_cap NullCap src_slot;\n    src_p \\<leftarrow> gets (\\<lambda>s. cdt s src_slot);\n    dest_p \\<leftarrow> gets (\\<lambda>s. cdt s dest_slot);\n    cdt \\<leftarrow> gets cdt;\n    parent \\<leftarrow> return $ cdt src_slot;\n    cdt' \\<leftarrow> return $ cdt(dest_slot := parent, src_slot := None);\n    set_cdt (\\<lambda>r. if cdt' r = Some src_slot then Some dest_slot else cdt' r);\n    do_extended_op (cap_move_ext src_slot dest_slot src_p dest_p);\n    is_original \\<leftarrow> gets is_original_cap;\n    set_original dest_slot (is_original src_slot);\n    set_original src_slot False\n  od\"\n\ntext \\<open>This version of capability swap does not change the capabilities that\nare swapped, passing the existing capabilities to the more general function.\\<close>\ndefinition\n  cap_swap_for_delete :: \"cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"cap_swap_for_delete slot1 slot2 \\<equiv>\n  when (slot1 \\<noteq> slot2) $ do\n    cap1 \\<leftarrow> get_cap slot1;\n    cap2 \\<leftarrow> get_cap slot2;\n    cap_swap cap1 slot1 cap2 slot2\n  od\"\n\ntext \\<open>The type of possible recursive deletes.\\<close>\ndatatype\n  rec_del_call\n  = CTEDeleteCall cslot_ptr bool\n  | FinaliseSlotCall cslot_ptr bool\n  | ReduceZombieCall cap cslot_ptr bool\n\ntext \\<open>Locate the nth capability beyond some base capability slot.\\<close>\ndefinition\n  locate_slot :: \"cslot_ptr \\<Rightarrow> nat \\<Rightarrow> cslot_ptr\" where\n \"locate_slot \\<equiv> \\<lambda>(a, b) n. (a, drop (32 - length b)\n                           (to_bl (of_bl b + of_nat n :: word32)))\"\n\ntext \\<open>Actions to be taken after deleting an IRQ Handler capability.\\<close>\ndefinition\n  deleting_irq_handler :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n \"deleting_irq_handler irq \\<equiv> do\n    slot \\<leftarrow> get_irq_slot irq;\n    cap_delete_one slot\n  od\"\n\ntext \\<open>Actions that must be taken when a capability is deleted. Returns two\ncapabilities: The first is a capability to be re-inserted into the slot in place\nof the deleted capability; in particular, this will be a Zombie if the deletion\nrequires a long-running operation. The second represents some further\npost-deletion action to be performed after the slot is cleared. For example,\nan IRQHandlerCap indicates an IRQ to be cleared. Arch capabilities may also be\nassociated with arch-specific post-deletion actions. For most cases, however,\nNullCap is used to indicate that no post-deletion action is required.\\<close>\n\nfun\n  finalise_cap :: \"cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"finalise_cap NullCap                  final = return (NullCap, NullCap)\"\n| \"finalise_cap (UntypedCap dev r bits f)    final = return (NullCap, NullCap)\"\n| \"finalise_cap (ReplyCap r m R)         final = return (NullCap, NullCap)\"\n| \"finalise_cap (EndpointCap r b R)      final =\n      (liftM (K (NullCap, NullCap)) $ when final $ cancel_all_ipc r)\"\n| \"finalise_cap (NotificationCap r b R)  final =\n      (liftM (K (NullCap, NullCap)) $ when final $ do\n          unbind_maybe_notification r;\n          cancel_all_signals r\n        od)\"\n| \"finalise_cap (CNodeCap r bits g)  final =\n      return (if final then Zombie r (Some bits) (2 ^ bits) else NullCap, NullCap)\"\n| \"finalise_cap (ThreadCap r)            final =\n      do\n         when final $ unbind_notification r;\n         when final $ suspend r;\n         when final $ prepare_thread_delete r;\n         return (if final then (Zombie r None 5) else NullCap, NullCap)\n      od\"\n| \"finalise_cap DomainCap                final = return (NullCap, NullCap)\"\n| \"finalise_cap (Zombie r b n)           final =\n      do assert final; return (Zombie r b n, NullCap) od\"\n| \"finalise_cap IRQControlCap            final = return (NullCap, NullCap)\"\n| \"finalise_cap (IRQHandlerCap irq)      final = (\n       if final then do\n         deleting_irq_handler irq;\n         return (NullCap, (IRQHandlerCap irq))\n       od\n       else return (NullCap, NullCap))\"\n| \"finalise_cap (ArchObjectCap a)        final =\n      (arch_finalise_cap a final)\"\n\ndefinition\n  can_fast_finalise :: \"cap \\<Rightarrow> bool\" where\n \"can_fast_finalise cap \\<equiv> case cap of\n    ReplyCap r m R \\<Rightarrow> True\n  | EndpointCap r b R \\<Rightarrow> True\n  | NotificationCap r b R \\<Rightarrow> True\n  | NullCap \\<Rightarrow> True\n  | _ \\<Rightarrow> False\"\n\ntext \\<open>This operation is used to delete a capability when it is known that a\nlong-running operation is impossible. It is equivalent to calling the regular\nfinalisation operation. It cannot be defined in that way as doing so\nwould create a circular definition.\\<close>\n\n\nlemma fast_finalise_def2:\n  \"fast_finalise cap final = do\n     assert (can_fast_finalise cap);\n     result \\<leftarrow> finalise_cap cap final;\n     assert (result = (NullCap, NullCap))\n   od\"\n  supply K_def[simp]\n  by (cases cap, simp_all add: liftM_def assert_def can_fast_finalise_def)\n\ntext \\<open>The finalisation process on a Zombie or Null capability is finished for\nall Null capabilities and for Zombies that cover no slots or only the slot they\nare currently stored in.\\<close>\nprimrec (nonexhaustive)\n  cap_removeable :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\"\nwhere\n  \"cap_removeable NullCap slot = True\"\n| \"cap_removeable (Zombie slot' bits n) slot =\n    ((n = 0) \\<or> (n = 1 \\<and> (slot', replicate (zombie_cte_bits bits) False) = slot))\"\n\ntext \\<open>Checks for Zombie capabilities that refer to the CNode or TCB they are\nstored in.\\<close>\ndefinition\n  cap_cyclic_zombie :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> bool\" where\n \"cap_cyclic_zombie cap slot \\<equiv> case cap of\n         Zombie slot' bits n \\<Rightarrow> (slot', replicate (zombie_cte_bits bits) False) = slot\n       | _ \\<Rightarrow> False\"\n\ntext \\<open>The complete recursive delete operation.\\<close>\nfunction (sequential)\n  rec_del :: \"rec_del_call \\<Rightarrow> (bool * cap,'z::state_ext) p_monad\"\nwhere\n  \"rec_del (CTEDeleteCall slot exposed) s =\n (doE\n    (success, cleanup_info) \\<leftarrow> rec_del (FinaliseSlotCall slot exposed);\n    without_preemption $ when (exposed \\<or> success) $ empty_slot slot cleanup_info;\n    returnOk undefined\n  odE) s\"\n|\n  \"rec_del (FinaliseSlotCall slot exposed) s =\n (doE\n    cap \\<leftarrow> without_preemption $ get_cap slot;\n    if (cap = NullCap)\n    then returnOk (True, NullCap)\n    else (doE\n      is_final \\<leftarrow> without_preemption $ is_final_cap cap;\n      (remainder, cleanup_info) \\<leftarrow> without_preemption $ finalise_cap cap is_final;\n      if (cap_removeable remainder slot)\n      then returnOk (True, cleanup_info)\n      else if (cap_cyclic_zombie remainder slot \\<and> \\<not> exposed)\n      then doE\n        without_preemption $ set_cap remainder slot;\n        returnOk (False, NullCap)\n      odE\n      else doE\n        without_preemption $ set_cap remainder slot;\n        rec_del (ReduceZombieCall remainder slot exposed);\n        preemption_point;\n        rec_del (FinaliseSlotCall slot exposed)\n      odE\n    odE)\n  odE) s\"\n\n| \"rec_del (ReduceZombieCall (Zombie ptr bits (Suc n)) slot False) s =\n (doE\n    cn \\<leftarrow> returnOk $ first_cslot_of (Zombie ptr bits (Suc n));\n    assertE (cn \\<noteq> slot);\n    without_preemption $ cap_swap_for_delete cn slot;\n    returnOk undefined\n  odE) s\"\n|\n \"rec_del (ReduceZombieCall (Zombie ptr bits (Suc n)) slot True) s =\n (doE\n    end_slot \\<leftarrow> returnOk (ptr, nat_to_cref (zombie_cte_bits bits) n);\n    rec_del (CTEDeleteCall end_slot False);\n    new_cap \\<leftarrow> without_preemption $ get_cap slot;\n    if (new_cap = Zombie ptr bits (Suc n))\n    then without_preemption $ set_cap (Zombie ptr bits n) slot\n    else assertE (new_cap = NullCap \\<or>\n                  is_zombie new_cap \\<and> first_cslot_of new_cap = slot\n                   \\<and> first_cslot_of (Zombie ptr bits (Suc n)) \\<noteq> slot);\n    returnOk undefined\n  odE) s\"\n|\n \"rec_del (ReduceZombieCall cap slot exposed) s =\n  fail s\"\n  by pat_completeness auto\n\ntext \\<open>Delete a capability by calling the recursive delete operation.\\<close>\ndefinition\n  cap_delete :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n \"cap_delete slot \\<equiv> doE rec_del (CTEDeleteCall slot True); returnOk () odE\"\n\ntext \\<open>Prepare the capability in a slot for deletion but do not delete it.\\<close>\ndefinition\n  finalise_slot :: \"cslot_ptr \\<Rightarrow> bool \\<Rightarrow> (bool * cap,'z::state_ext) p_monad\"\nwhere\n  \"finalise_slot p e \\<equiv> rec_del (FinaliseSlotCall p e)\"\n\ntext \\<open>Helper functions for the type of recursive delete calls.\\<close>\nprimrec\n  exposed_rdcall :: \"rec_del_call \\<Rightarrow> bool\"\nwhere\n  \"exposed_rdcall (CTEDeleteCall slot exposed) = exposed\"\n| \"exposed_rdcall (FinaliseSlotCall slot exposed) = exposed\"\n| \"exposed_rdcall (ReduceZombieCall cap slot exposed) = exposed\"\n\nprimrec\n  isCTEDeleteCall :: \"rec_del_call \\<Rightarrow> bool\"\nwhere\n  \"isCTEDeleteCall (CTEDeleteCall slot exposed) = True\"\n| \"isCTEDeleteCall (FinaliseSlotCall slot exposed) = False\"\n| \"isCTEDeleteCall (ReduceZombieCall cap slot exposed) = False\"\n\nprimrec\n  slot_rdcall :: \"rec_del_call \\<Rightarrow> cslot_ptr\"\nwhere\n  \"slot_rdcall (CTEDeleteCall slot exposed) = slot\"\n| \"slot_rdcall (FinaliseSlotCall slot exposed) = slot\"\n| \"slot_rdcall (ReduceZombieCall cap slot exposed) = slot\"\n\ntext \\<open>Revoke the derived capabilities of a given capability, deleting them\nall.\\<close>\n\nfunction cap_revoke :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n\"cap_revoke slot s = (doE\n    cap \\<leftarrow> without_preemption $ get_cap slot;\n    cdt \\<leftarrow> without_preemption $ gets cdt;\n    descendants \\<leftarrow> returnOk $ descendants_of slot cdt;\n    whenE (cap \\<noteq> NullCap \\<and> descendants \\<noteq> {}) (doE\n      child \\<leftarrow> without_preemption $ select_ext (next_revoke_cap slot) descendants;\n      cap \\<leftarrow> without_preemption $ get_cap child;\n      assertE (cap \\<noteq> NullCap);\n      cap_delete child;\n      preemption_point;\n      cap_revoke slot\n    odE)\nodE) s\"\nby auto"}
{"title": "./spec/abstract/CSpace_A.thy", "section": "Inserting and moving capabilities", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  get_badge :: \"cap \\<Rightarrow> badge option\" where\n \"get_badge cap \\<equiv> case cap of\n    NotificationCap oref badge cr \\<Rightarrow> Some badge\n  | EndpointCap oref badge cr      \\<Rightarrow> Some badge\n  | _                              \\<Rightarrow> None\"\n\n\ndefinition\n  is_physical :: \"cap \\<Rightarrow> bool\" where\n  \"is_physical cap \\<equiv> case cap of\n    NullCap \\<Rightarrow> False\n  | DomainCap \\<Rightarrow> False\n  | IRQControlCap \\<Rightarrow> False\n  | IRQHandlerCap _ \\<Rightarrow> False\n  | ReplyCap _ _ _ \\<Rightarrow> False\n  | ArchObjectCap c \\<Rightarrow> arch_is_physical c\n  | _ \\<Rightarrow> True\"\n\nfun\n  same_region_as :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"same_region_as NullCap c' = False\"\n| \"same_region_as (UntypedCap dev r bits free) c' =\n    (is_physical c' \\<and>\n     r \\<le> obj_ref_of c' \\<and>\n     obj_ref_of c' \\<le> obj_ref_of c' + obj_size c' - 1 \\<and>\n     obj_ref_of c' + obj_size c' - 1 \\<le> r + (1 << bits) - 1)\"\n| \"same_region_as (EndpointCap r b R) c' =\n    (is_ep_cap c' \\<and> obj_ref_of c' = r)\"\n| \"same_region_as (NotificationCap r b R) c' =\n    (is_ntfn_cap c' \\<and> obj_ref_of c' = r)\"\n| \"same_region_as (CNodeCap r bits g) c' =\n    (is_cnode_cap c' \\<and> obj_ref_of c' = r \\<and> bits_of c' = bits)\"\n| \"same_region_as (ReplyCap n m cr) c' = (\\<exists>m' cr. c' = ReplyCap n m' cr)\"\n| \"same_region_as (ThreadCap r) c' =\n    (is_thread_cap c' \\<and> obj_ref_of c' = r)\"\n| \"same_region_as (Zombie r b n) c' = False\"\n| \"same_region_as (IRQControlCap) c' =\n    (c' = IRQControlCap \\<or> (\\<exists>n. c' = IRQHandlerCap n))\"\n| \"same_region_as DomainCap c' = (c' = DomainCap)\"\n| \"same_region_as (IRQHandlerCap n) c' =\n    (c' = IRQHandlerCap n)\"\n| \"same_region_as (ArchObjectCap a) c' =\n    (case c' of ArchObjectCap a' \\<Rightarrow> arch_same_region_as a a' | _ \\<Rightarrow> False)\"\n\ntext \\<open>Check whether two capabilities are to the same object.\\<close>\ndefinition\n  same_object_as :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\" where\n \"same_object_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (UntypedCap dev r bits free, _) \\<Rightarrow> False\n    | (IRQControlCap, IRQHandlerCap n) \\<Rightarrow> False\n    | (ArchObjectCap ac, ArchObjectCap ac') \\<Rightarrow> same_aobject_as ac ac'\n    | _ \\<Rightarrow> same_region_as cp cp')\"\n\n\n\ntext \\<open>\nThe function @{text \"should_be_parent_of\"}\nchecks whether an existing capability should be a parent of\nanother to-be-inserted capability. The test is the following:\nFor capability @{term c} to be a parent of capability @{term c'},\n@{term c} needs to be the original capability to the object and needs\nto cover the same memory region as @{term c'} (i.e.\\ cover the same\nobject). In the case of endpoint capabilities, if @{term c} is a\nbadged endpoint cap (@{text \"badge \\<noteq> 0\"}), then it should be a parent\nof @{text c'} if @{text c'} has the same badge and is itself not an\noriginal badged endpoint cap.\n\n\\begin{figure}\n\\begin{center}\n\\includegraphics[width=0.8\\textwidth]{imgs/CDT}\n\\end{center}\n\\caption{Example capability derivation tree.}\\label{fig:CDT}\n\\end{figure}\n\nFigure \\ref{fig:CDT} shows an example capability derivation tree that\nillustrates a standard scenario: the top level is a large untyped\ncapability, the second level splits this capability into two regions\ncovered by their own untyped caps, both are children of the first\nlevel.  The third level on the left is a copy of the level 2 untyped\ncapability.  Untyped capabilities when copied always create children,\nnever siblings.  In this scenario, the untyped capability was typed\ninto two separate objects, creating two capabilities on level 4, both\nare the original capability to the respective object, both are\nchildren of the untyped capability they were created from.\n\n Ordinary original capabilities can have one level of derived capabilities\n(created, for instance, by the copy or mint operations). Further copies\nof these derived capabilities will create sibling, in this case\nremaining on level 5. There is an exception to this scheme for endpoint\ncapabilities --- they support an additional layer of depth with the\nconcept of badged and unbadged endpoints. The original endpoint\ncapability will be unbadged. Using the mint operation, a copy of\nthe capability with a specific badge can be created. This new, badged\ncapability to the same object is treated as an original capability\n(the ``original badged endpoint capability'') and supports one level\nof derived children like other capabilities.\n\\<close>\ndefinition\n  should_be_parent_of :: \"cap \\<Rightarrow> bool \\<Rightarrow> cap \\<Rightarrow> bool \\<Rightarrow> bool\" where\n  \"should_be_parent_of c original c' original' \\<equiv>\n   original \\<and>\n   same_region_as c c' \\<and>\n   (case c of\n      EndpointCap ref badge R \\<Rightarrow> badge \\<noteq> 0 \\<longrightarrow> cap_ep_badge c' = badge \\<and> \\<not>original'\n    | NotificationCap ref badge R \\<Rightarrow> badge \\<noteq> 0 \\<longrightarrow> cap_ep_badge c' = badge \\<and> \\<not>original'\n    | _ \\<Rightarrow> True)\"\n\ntext \\<open>This helper function determines if the new capability\nshould be counted as the original capability to the object. This test\nis usually false, apart from the exceptions listed (newly badged\nendpoint capabilities, irq handlers, untyped caps, and possibly some\narch caps).\\<close>\ndefinition\n  is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"is_cap_revocable new_cap src_cap \\<equiv> case new_cap of\n      ArchObjectCap acap \\<Rightarrow> arch_is_cap_revocable new_cap src_cap\n    | EndpointCap _ _ _ \\<Rightarrow> cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n    | NotificationCap _ _ _ \\<Rightarrow> cap_ep_badge new_cap \\<noteq> cap_ep_badge src_cap\n    | IRQHandlerCap _ \\<Rightarrow> src_cap = IRQControlCap\n    | UntypedCap _ _ _ _ \\<Rightarrow> True\n    | _ \\<Rightarrow> False\"\n\ntext \\<open>Insert a new capability as either a sibling or child of an\nexisting capability. The function @{const should_be_parent_of}\ndetermines which it will be.\n\nThe term for @{text dest_original} determines if the new capability\nshould be counted as the original capability to the object. This test\nis usually false, apart from the exceptions listed (newly badged\nendpoint capabilities, irq handlers, and untyped caps).\n\\<close>\n\n\ndefinition\n  cap_insert :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"cap_insert new_cap src_slot dest_slot \\<equiv> do\n    src_cap \\<leftarrow> get_cap src_slot;\n\n    dest_original \\<leftarrow> return $ is_cap_revocable new_cap src_cap;\n\n    old_cap \\<leftarrow> get_cap dest_slot;\n    assert (old_cap = NullCap);\n    set_untyped_cap_as_full src_cap new_cap src_slot;\n    set_cap new_cap dest_slot;\n\n    is_original \\<leftarrow> gets is_original_cap;\n    src_parent \\<leftarrow> return $\n       should_be_parent_of src_cap (is_original src_slot) new_cap dest_original;\n    src_p \\<leftarrow> gets (\\<lambda>s. cdt s src_slot);\n    dest_p \\<leftarrow> gets (\\<lambda>s. cdt s dest_slot);\n    update_cdt (\\<lambda>cdt. cdt (dest_slot := if src_parent\n                                        then Some src_slot\n                                        else cdt src_slot));\n    do_extended_op (cap_insert_ext src_parent src_slot dest_slot src_p dest_p);\n    set_original dest_slot dest_original\n  od\"\n\n\ndefinition\n  has_cancel_send_rights :: \"cap \\<Rightarrow> bool\" where\n  \"has_cancel_send_rights cap \\<equiv> case cap of\n   EndpointCap _ _ R \\<Rightarrow> R = all_rights\n   | _ \\<Rightarrow> False\"\n\ntext \\<open>Overwrite the capabilities stored in a TCB while preserving the register\nset and other fields.\\<close>\ndefinition\n  tcb_registers_caps_merge :: \"tcb \\<Rightarrow> tcb \\<Rightarrow> tcb\"\nwhere\n \"tcb_registers_caps_merge regtcb captcb \\<equiv>\n  regtcb \\<lparr> tcb_ctable := tcb_ctable captcb,\n           tcb_vtable := tcb_vtable captcb,\n           tcb_reply := tcb_reply captcb,\n           tcb_caller := tcb_caller captcb,\n           tcb_ipcframe := tcb_ipcframe captcb \\<rparr>\""}
{"title": "./spec/abstract/CSpace_A.thy", "section": "Invoking CNode capabilities", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The CNode capability confers authority to various methods\nwhich act on CNodes and the capabilities within them. Copies of\ncapabilities may be inserted in empty CNode slots by\nInsert. Capabilities may be moved to empty slots with Move or swapped\nwith others in a three way rotate by Rotate. A Reply capability stored\nin a thread's last-caller slot may be saved into a regular CNode slot\nwith Save.  The Revoke, Delete and Recycle methods may also be\ninvoked on the capabilities stored in the CNode.\\<close>\n\ndefinition\n  invoke_cnode :: \"cnode_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n  \"invoke_cnode i \\<equiv> case i of\n    RevokeCall dest_slot \\<Rightarrow> cap_revoke dest_slot\n  | DeleteCall dest_slot \\<Rightarrow> cap_delete dest_slot\n  | InsertCall cap src_slot dest_slot \\<Rightarrow>\n       without_preemption $ cap_insert cap src_slot dest_slot\n  | MoveCall cap src_slot dest_slot \\<Rightarrow>\n       without_preemption $ cap_move cap src_slot dest_slot\n  | RotateCall cap1 cap2 slot1 slot2 slot3 \\<Rightarrow>\n       without_preemption $\n       if slot1 = slot3 then\n         cap_swap cap1 slot1 cap2 slot2\n       else\n         do cap_move cap2 slot2 slot3; cap_move cap1 slot1 slot2 od\n  | SaveCall slot \\<Rightarrow> without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    src_slot \\<leftarrow> return (thread, tcb_cnode_index 3);\n    cap \\<leftarrow> get_cap src_slot;\n    (case cap of\n          NullCap \\<Rightarrow> return ()\n        | ReplyCap _ False _ \\<Rightarrow> cap_move cap src_slot slot\n        | _ \\<Rightarrow> fail) od\n  | CancelBadgedSendsCall (EndpointCap ep b R) \\<Rightarrow>\n    without_preemption $ when (b \\<noteq> 0) $ cancel_badged_sends ep b\n  | CancelBadgedSendsCall _ \\<Rightarrow> fail\""}
{"title": "./spec/abstract/CSpace_A.thy", "section": "Cap classification used to define invariants", "subsection": "", "subsubsection": "", "code": "\ndatatype capclass =\n  PhysicalClass | ReplyClass \"obj_ref\" | IRQClass | ASIDMasterClass | NullClass | DomainClass | IOPortClass\n\nend"}
{"title": "./spec/abstract/KHeap_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFunctions to access kernel memory.\n*)\n\nchapter \\<open>Accessing the Kernel Heap\\<close>\n\ntheory KHeap_A\nimports Exceptions_A\nbegin\n\ntext \\<open>This theory gives auxiliary getter and setter methods\nfor kernel objects.\\<close>"}
{"title": "./spec/abstract/KHeap_A.thy", "section": "TCBs", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  get_object :: \"obj_ref \\<Rightarrow> (kernel_object,'z::state_ext) s_monad\"\nwhere\n  \"get_object ptr \\<equiv> do\n     kh \\<leftarrow> gets kheap;\n     assert (kh ptr \\<noteq> None);\n     return $ the $ kh ptr\n   od\"\n\ndefinition\n  set_object :: \"obj_ref \\<Rightarrow> kernel_object \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_object ptr obj \\<equiv> do\n     kobj <- get_object ptr;\n     assert (a_type kobj = a_type obj);\n     s \\<leftarrow> get;\n     put (s\\<lparr>kheap := (kheap s)(ptr \\<mapsto> obj)\\<rparr>)\n   od\""}
{"title": "./spec/abstract/KHeap_A.thy", "section": "TCBs", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  get_tcb :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> tcb option\"\nwhere\n  \"get_tcb tcb_ref state \\<equiv>\n   case kheap state tcb_ref of\n      None      \\<Rightarrow> None\n    | Some kobj \\<Rightarrow> (case kobj of\n        TCB tcb \\<Rightarrow> Some tcb\n      | _       \\<Rightarrow> None)\"\n\ndefinition\n  thread_get :: \"(tcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> ('a,'z::state_ext) s_monad\"\nwhere\n  \"thread_get f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb tptr;\n     return $ f tcb\n   od\"\n\ndefinition\n  thread_set :: \"(tcb \\<Rightarrow> tcb) \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"thread_set f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb tptr;\n     set_object tptr $ TCB $ f tcb\n   od\"\n\ndefinition\n  arch_thread_get :: \"(arch_tcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> ('a,'z::state_ext) s_monad\"\nwhere\n  \"arch_thread_get f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb tptr;\n     return $ f (tcb_arch tcb)\n   od\"\n\ndefinition\n  arch_thread_set :: \"(arch_tcb \\<Rightarrow> arch_tcb) \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"arch_thread_set f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb tptr;\n     set_object tptr $ TCB $ tcb \\<lparr> tcb_arch := f (tcb_arch tcb) \\<rparr>\n   od\"\n\ndefinition\n  get_thread_state :: \"obj_ref \\<Rightarrow> (thread_state,'z::state_ext) s_monad\"\nwhere\n  \"get_thread_state ref \\<equiv> thread_get tcb_state ref\"\n\ndefinition\n  get_bound_notification :: \"obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\"\nwhere\n  \"get_bound_notification ref \\<equiv> thread_get tcb_bound_notification ref\"\n\ndefinition\n  set_bound_notification :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"set_bound_notification ref ntfn \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb ref;\n     set_object ref (TCB (tcb \\<lparr> tcb_bound_notification := ntfn \\<rparr>))\n   od\"\n\ndefinition set_thread_state_ext :: \"obj_ref \\<Rightarrow> unit det_ext_monad\" where\n  \"set_thread_state_ext t \\<equiv> do\n     ts \\<leftarrow> get_thread_state t;\n     cur \\<leftarrow> gets cur_thread;\n     action \\<leftarrow> gets scheduler_action;\n     when (\\<not> (runnable ts) \\<and> cur = t \\<and> action = resume_cur_thread) (set_scheduler_action choose_new_thread)\n   od\"\n\ndefinition\n  set_thread_state :: \"obj_ref \\<Rightarrow> thread_state \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_thread_state ref ts \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb ref;\n     set_object ref (TCB (tcb \\<lparr> tcb_state := ts \\<rparr>));\n     do_extended_op (set_thread_state_ext ref)\n   od\"\n\ndefinition\n  set_priority :: \"obj_ref \\<Rightarrow> priority \\<Rightarrow> unit det_ext_monad\" where\n  \"set_priority tptr prio \\<equiv> do\n     tcb_sched_action tcb_sched_dequeue tptr;\n     thread_set_priority tptr prio;\n     ts \\<leftarrow> get_thread_state tptr;\n     when (runnable ts) $ do\n       cur \\<leftarrow> gets cur_thread;\n       if tptr = cur then reschedule_required else possible_switch_to tptr\n     od\n   od\"\n\ndefinition\n  set_mcpriority :: \"obj_ref \\<Rightarrow> priority \\<Rightarrow> (unit, 'z::state_ext) s_monad\"  where\n  \"set_mcpriority ref mcp \\<equiv> thread_set (\\<lambda>tcb. tcb\\<lparr>tcb_mcpriority:=mcp\\<rparr>) ref \""}
{"title": "./spec/abstract/KHeap_A.thy", "section": "simple kernel objects", "subsection": "", "subsubsection": "", "code": "\n(* to be used for abstraction unifying kernel objects other than TCB and CNode *)\n\ndefinition\n  partial_inv :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> ('b \\<Rightarrow> 'a option)\"\nwhere\n  \"partial_inv f x = (if \\<exists>!y. f y = x then Some (THE y. f y = x) else None)\"\n\nlemma proj_inj: \"inj f \\<Longrightarrow> (partial_inv f ko = Some v) = (f v = ko)\"\n  by (auto simp: partial_inv_def the_equality injD)\n\nlemma inj_Endpoint: \"inj Endpoint\" by (auto intro: injI)\nlemma inj_Notification: \"inj Notification\"  by (auto intro: injI)\n\nlemmas proj_inj_ep[simp] = proj_inj[OF inj_Endpoint]\nlemma proj_ko_type_ep[simp]: \"(\\<exists>v. partial_inv Endpoint  ko = Some (v::endpoint)) = (a_type ko = AEndpoint)\"\n  by (cases ko; auto simp: partial_inv_def a_type_def)\n\nlemmas proj_inj_ntfn[simp] = proj_inj[OF inj_Notification]\nlemma proj_ko_type_ntfn[simp]:\n  \"(\\<exists>v. partial_inv Notification  ko = Some (v::notification)) = (a_type ko = ANTFN)\"\n  by (cases ko; auto simp: partial_inv_def a_type_def)\n\n\nabbreviation\n  \"is_simple_type \\<equiv> (\\<lambda>ob. a_type ob \\<in> {AEndpoint, ANTFN})\"\n\n\ndefinition\n  get_simple_ko :: \"('a \\<Rightarrow> kernel_object) \\<Rightarrow> obj_ref \\<Rightarrow> ('a,'z::state_ext) s_monad\"\nwhere\n  \"get_simple_ko f ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     assert (is_simple_type kobj);\n     (case partial_inv f kobj of Some e \\<Rightarrow> return e | _ \\<Rightarrow> fail)\n   od\"\n\n\ndefinition\n  set_simple_ko :: \"('a \\<Rightarrow> kernel_object) \\<Rightarrow> obj_ref \\<Rightarrow> 'a \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_simple_ko f ptr ep \\<equiv> do\n     obj \\<leftarrow> get_object ptr;\n     assert (is_simple_type obj);\n     assert (partial_inv f obj \\<noteq> None);\n     set_object ptr (f ep)\n   od\""}
{"title": "./spec/abstract/KHeap_A.thy", "section": "Synchronous and Asyncronous Endpoints", "subsection": "", "subsubsection": "", "code": "\nabbreviation\n  get_endpoint :: \"obj_ref \\<Rightarrow> (endpoint,'z::state_ext) s_monad\" where\n  \"get_endpoint \\<equiv> get_simple_ko Endpoint\"\n\nabbreviation\n  set_endpoint :: \"obj_ref \\<Rightarrow> endpoint \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_endpoint \\<equiv> set_simple_ko Endpoint\"\n\nabbreviation\n  get_notification :: \"obj_ref \\<Rightarrow> (notification,'z::state_ext) s_monad\" where\n  \"get_notification \\<equiv> get_simple_ko Notification\"\n\nabbreviation\n  set_notification :: \"obj_ref \\<Rightarrow> notification \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_notification \\<equiv> set_simple_ko Notification\"\n\nabbreviation\n  ntfn_set_bound_tcb :: \"notification \\<Rightarrow> obj_ref option \\<Rightarrow> notification\" where\n  \"ntfn_set_bound_tcb ntfn t \\<equiv> ntfn \\<lparr> ntfn_bound_tcb := t \\<rparr>\"\n\nabbreviation\n  ntfn_set_obj :: \"notification \\<Rightarrow> ntfn \\<Rightarrow> notification\" where\n  \"ntfn_set_obj ntfn a \\<equiv> ntfn \\<lparr> ntfn_obj := a \\<rparr>\""}
{"title": "./spec/abstract/KHeap_A.thy", "section": "IRQ State and Slot", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  get_irq_state :: \"irq \\<Rightarrow> (irq_state,'z::state_ext) s_monad\" where\n \"get_irq_state irq \\<equiv> gets (\\<lambda>s. interrupt_states s irq)\"\n\ndefinition\n  set_irq_state :: \"irq_state \\<Rightarrow> irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"set_irq_state state irq \\<equiv> do\n    modify (\\<lambda>s. s \\<lparr> interrupt_states := (interrupt_states s) (irq := state)\\<rparr>);\n    do_machine_op $ maskInterrupt (state = IRQInactive) irq\n  od\"\n\ndefinition\n  get_irq_slot :: \"irq \\<Rightarrow> (cslot_ptr,'z::state_ext) s_monad\" where\n \"get_irq_slot irq \\<equiv> gets (\\<lambda>st. (interrupt_irq_node st irq, []))\"\n\ntext \\<open>Tests whether an IRQ identifier is in use.\\<close>\ndefinition\n  is_irq_active :: \"irq \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n \"is_irq_active irq \\<equiv> liftM (\\<lambda>st. st \\<noteq> IRQInactive) $ get_irq_state irq\""}
{"title": "./spec/abstract/KHeap_A.thy", "section": "User Context", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  Changes user context of specified thread by running\n  specified user monad.\n\\<close>\ndefinition\n  as_user :: \"obj_ref \\<Rightarrow> 'a user_monad \\<Rightarrow> ('a,'z::state_ext) s_monad\"\nwhere\n  \"as_user tptr f \\<equiv> do\n    tcb \\<leftarrow> gets_the $ get_tcb tptr;\n    uc \\<leftarrow> return $ arch_tcb_context_get (tcb_arch tcb);\n    (a, uc') \\<leftarrow> select_f $ f uc;\n    new_tcb \\<leftarrow> return $ tcb \\<lparr> tcb_arch := arch_tcb_context_set uc' (tcb_arch tcb)\\<rparr>;\n    set_object tptr (TCB new_tcb);\n    return a\n  od\"\n\ntext \\<open>Raise an exception if a property does not hold.\\<close>\ndefinition\nthrow_on_false :: \"'e \\<Rightarrow> (bool,'z::state_ext) s_monad \\<Rightarrow> ('e + unit,'z::state_ext) s_monad\" where\n\"throw_on_false ex f \\<equiv> doE v \\<leftarrow> liftE f; unlessE v $ throwError ex odE\"\n\nend"}
{"title": "./spec/abstract/ExceptionTypes_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nTypes of exceptions in the abstract model.\n*)\n\nchapter \"Error and Fault Messages\"\n\ntheory ExceptionTypes_A\nimports MiscMachine_A\nbegin\n\narch_requalify_types (A) arch_fault\n\ntext \\<open>\n  There are two types of exceptions that can occur in the kernel:\n  faults and errors. Faults are reported to the user's fault handler.\n  Errors are reported to the user directly.\n\n  Capability lookup failures can be be either fault or error,\n  depending on context.\n\\<close>\n\ndatatype lookup_failure\n     = InvalidRoot\n     | MissingCapability nat\n     | DepthMismatch nat nat\n     | GuardMismatch nat \"bool list\"\n\ndatatype fault\n         = CapFault obj_ref bool lookup_failure\n         | UnknownSyscallException data\n         | UserException data data\n         | ArchFault arch_fault\n\ndatatype syscall_error\n         = InvalidArgument nat\n         | InvalidCapability nat\n         | IllegalOperation\n         | RangeError data data\n         | AlignmentError\n         | FailedLookup bool lookup_failure\n         | TruncatedMessage\n         | DeleteFirst\n         | RevokeFirst\n         | NotEnoughMemory data\n\ntext \\<open>Create a message from a system-call failure to be returned to the\nthread attempting the operation that failed.\\<close>\nprimrec\n  msg_from_lookup_failure :: \"lookup_failure \\<Rightarrow> data list\"\nwhere\n  \"msg_from_lookup_failure InvalidRoot           = [1]\"\n| \"msg_from_lookup_failure (MissingCapability n) = [2, of_nat n]\"\n| \"msg_from_lookup_failure (DepthMismatch n m)   = [3, of_nat n, of_nat m]\"\n| \"msg_from_lookup_failure (GuardMismatch n g)   = [4, of_nat n, of_bl g, of_nat (size g)]\"\n\nprimrec\n  msg_from_syscall_error :: \"syscall_error \\<Rightarrow> (data \\<times> data list)\"\nwhere\n  \"msg_from_syscall_error (InvalidArgument n)    = (1, [of_nat n])\"\n| \"msg_from_syscall_error (InvalidCapability n)  = (2, [of_nat n])\"\n| \"msg_from_syscall_error IllegalOperation       = (3, [])\"\n| \"msg_from_syscall_error (RangeError minv maxv) = (4, [minv, maxv])\"\n| \"msg_from_syscall_error AlignmentError         = (5, [])\"\n| \"msg_from_syscall_error (FailedLookup s lf)    = (6, [if s then 1 else 0]@(msg_from_lookup_failure lf))\"\n| \"msg_from_syscall_error TruncatedMessage       = (7, [])\"\n| \"msg_from_syscall_error DeleteFirst            = (8, [])\"\n| \"msg_from_syscall_error RevokeFirst            = (9, [])\"\n| \"msg_from_syscall_error (NotEnoughMemory n)    = (10, [n])\"\n\nend"}
{"title": "./spec/abstract/Deterministic_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Abstract Specification Instantiations\"\n\ntheory Deterministic_A\nimports\n  Structures_A\n  \"Lib.List_Lib\"\n\nbegin\n\ntext \\<open>\n\\label{c:ext-spec}\n\nThe kernel specification operates over states of type @{typ \"'a state\"}, which\nincludes all of the abstract kernel state plus an extra field, @{term exst}\nof type @{typ \"'a\"}. By choosing an appropriate concrete type for @{typ \"'a\"},\nwe obtain different \\emph{instantiations} of this specification, at differing\nlevels of abstraction. The abstract specification is thus \\emph{extensible}.\nThe basic technique, and its motivation, are described in~\\cite{Matichuk_Murray_12}.\n\nHere, we define two such instantiations. The first yields a\nlargely-deterministic specification by instantiating @{typ \"'a\"} with\na record that includes concrete scheduler state and\ninformation about sibling ordering in the capability derivation tree (CDT).\nWe call the resulting\nspecification the \\emph{deterministic abstract specification} and it is\ndefined below in \\autoref{s:det-spec}.\n\nThe second instantiation uses the type @{typ unit} for @{typ 'a}, yielding\na specification that is far more nondeterministic. In particular, the\nscheduling behaviour and the order in which capabilities are deleted during\na \\emph{revoke} system call both become completely nondeterministic.\nWe call this second instantiation the\n\\emph{nondeterministic abstract specification} and it is defined below in\n\\autoref{s:nondet-spec}.\n\\<close>\n\ntext \\<open>Translate a state of type @{typ \"'a state\"} to one of type @{typ \"'b state\"}\n  via a function @{term t} from @{typ \"'a\"} to @{typ \"'b\"}.\n\\<close>\ndefinition trans_state :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> 'a state \\<Rightarrow> 'b state\" where\n\"trans_state t s = \\<lparr>kheap = kheap s, cdt = cdt s, is_original_cap = is_original_cap s,\n                     cur_thread = cur_thread s, idle_thread = idle_thread s,\n                     machine_state = machine_state s,\n                     interrupt_irq_node = interrupt_irq_node s,\n                     interrupt_states = interrupt_states s, arch_state = arch_state s,\n                     exst = t(exst s)\\<rparr>\"\n\n(*<*)\nlemma trans_state[simp]: \"kheap (trans_state t s) = kheap s\"\n                            \"cdt (trans_state t s) = cdt s\"\n                            \"is_original_cap (trans_state t s) = is_original_cap s\"\n                            \"cur_thread (trans_state t s) = cur_thread s\"\n                            \"idle_thread (trans_state t s) = idle_thread s\"\n                            \"machine_state (trans_state t s) = machine_state s\"\n                            \"interrupt_irq_node (trans_state t s) = interrupt_irq_node s\"\n                           \"interrupt_states (trans_state t s) = interrupt_states s\"\n                            \"arch_state (trans_state t s) = arch_state s\"\n                            \"exst (trans_state t s) = (t (exst s))\"\n                            \"exst (trans_state (\\<lambda>_. e) s) = e\"\n  apply (simp add: trans_state_def)+\n  done\n\nlemma trans_state_update[simp]:\n \"trans_state t (kheap_update f s) = kheap_update f (trans_state t s)\"\n \"trans_state t (cdt_update g s) = cdt_update g (trans_state t s)\"\n \"trans_state t (is_original_cap_update h s) = is_original_cap_update h (trans_state t s)\"\n \"trans_state t (cur_thread_update i s) = cur_thread_update i (trans_state t s)\"\n \"trans_state t (idle_thread_update j s) = idle_thread_update j (trans_state t s)\"\n \"trans_state t (machine_state_update k s) = machine_state_update k (trans_state t s)\"\n \"trans_state t (interrupt_irq_node_update l s) = interrupt_irq_node_update l (trans_state t s)\"\n \"trans_state t (arch_state_update m s) = arch_state_update m (trans_state t s)\"\n \"trans_state t (interrupt_states_update p s) = interrupt_states_update p (trans_state t s)\"\n  apply (simp add: trans_state_def)+\n  done\n\n\nlemma trans_state_update':\n  \"trans_state f = exst_update f\"\n  apply (rule ext)\n  apply simp\n  done\n\nlemma trans_state_update''[simp]:\n  \"trans_state t' (trans_state t s) = trans_state (\\<lambda>e. t' (t e)) s\"\n  apply simp\n  done\n(*>*)\n\ntext \\<open>Truncate an extended state of type @{typ \"'a state\"}\n  by effectively throwing away all the @{typ \"'a\"} information.\n\\<close>\nabbreviation \"truncate_state \\<equiv> trans_state (\\<lambda>_. ())\""}
{"title": "./spec/abstract/Deterministic_A.thy", "section": "Nondeterministic Abstract Specification", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\\label{s:det-spec}\n  The deterministic abstract specification tracks the state of the scheduler\nand ordering information about sibling nodes in the CDT.\\<close>\n\ntext \\<open>The current scheduler action,\n  which is part of the scheduling state.\\<close>\ndatatype scheduler_action =\n    resume_cur_thread\n  | switch_thread (sch_act_target : obj_ref)\n  | choose_new_thread\n\ntype_synonym domain = word8\n\nrecord etcb =\n tcb_priority :: \"priority\"\n tcb_time_slice :: \"nat\"\n tcb_domain :: \"domain\"\n\ndefinition default_priority :: \"priority\" where\n  \"default_priority \\<equiv> minBound\"\n\ndefinition default_domain :: \"domain\" where\n  \"default_domain \\<equiv> minBound\"\n\ndefinition default_etcb :: \"etcb\" where\n  \"default_etcb \\<equiv> \\<lparr>tcb_priority = default_priority, tcb_time_slice = timeSlice, tcb_domain = default_domain\\<rparr>\"\n\ntype_synonym ready_queue = \"obj_ref list\"\n\ntext \\<open>\n  For each entry in the CDT, we record an ordered list of its children.\n  This encodes the order of sibling nodes in the CDT.\n\\<close>\ntype_synonym cdt_list = \"cslot_ptr \\<Rightarrow> cslot_ptr list\"\n\ndefinition work_units_limit :: \"machine_word\" where\n  \"work_units_limit = 0x64\"\ntext \\<open>\n  The extended state of the deterministic abstract specification.\n\\<close>\nrecord det_ext =\n   work_units_completed_internal :: \"machine_word\"\n   scheduler_action_internal :: scheduler_action\n   ekheap_internal :: \"obj_ref \\<Rightarrow> etcb option\"\n   domain_list_internal :: \"(domain \\<times> machine_word) list\"\n   domain_index_internal :: nat\n   cur_domain_internal :: domain\n   domain_time_internal :: \"machine_word\"\n   ready_queues_internal :: \"domain \\<Rightarrow> priority \\<Rightarrow> ready_queue\"\n   cdt_list_internal :: cdt_list\n\ntext \\<open>\n  The state of the deterministic abstract specification extends the\n  abstract state with the @{typ det_ext} record.\n\\<close>\ntype_synonym det_state = \"det_ext state\"\n\ntext \\<open>Accessor and update functions for the extended state of the\n  deterministic abstract specification.\n\\<close>\nabbreviation\n  \"work_units_completed (s::det_state) \\<equiv> work_units_completed_internal (exst s)\"\n\nabbreviation\n  \"work_units_completed_update f (s::det_state) \\<equiv>  trans_state (work_units_completed_internal_update f) s\"\n\nabbreviation\n  \"scheduler_action (s::det_state) \\<equiv> scheduler_action_internal (exst s)\"\n\nabbreviation\n  \"scheduler_action_update f (s::det_state) \\<equiv>  trans_state (scheduler_action_internal_update f) s\"\n\nabbreviation\n  \"ekheap (s::det_state) \\<equiv> ekheap_internal (exst s)\"\n\nabbreviation\n  \"ekheap_update f (s::det_state) \\<equiv> trans_state (ekheap_internal_update f) s\"\n\nabbreviation\n  \"domain_list (s::det_state) \\<equiv> domain_list_internal (exst s)\"\n\nabbreviation\n  \"domain_list_update f (s::det_state) \\<equiv> trans_state (domain_list_internal_update f) s\"\n\nabbreviation\n  \"domain_index (s::det_state) \\<equiv> domain_index_internal (exst s)\"\n\nabbreviation\n  \"domain_index_update f (s::det_state) \\<equiv> trans_state (domain_index_internal_update f) s\"\n\nabbreviation\n  \"cur_domain (s::det_state) \\<equiv> cur_domain_internal (exst s)\"\n\nabbreviation\n  \"cur_domain_update f (s::det_state) \\<equiv> trans_state (cur_domain_internal_update f) s\"\n\nabbreviation\n  \"domain_time (s::det_state) \\<equiv> domain_time_internal (exst s)\"\n\nabbreviation\n  \"domain_time_update f (s::det_state) \\<equiv> trans_state (domain_time_internal_update f) s\"\n\nabbreviation\n  \"ready_queues (s::det_state) \\<equiv> ready_queues_internal (exst s)\"\n\nabbreviation\n  \"ready_queues_update f (s::det_state) \\<equiv> trans_state (ready_queues_internal_update f) s\"\n\nabbreviation\n  \"cdt_list (s::det_state) \\<equiv> cdt_list_internal (exst s)\"\n\nabbreviation\n  \"cdt_list_update f (s::det_state) \\<equiv> trans_state (cdt_list_internal_update f) s\"\n\ntype_synonym 'a det_ext_monad = \"(det_state,'a) nondet_monad\"\n\ntext \\<open>\n  Basic monadic functions for operating on the extended state of the\n  deterministic abstract specification.\n\\<close>\ndefinition\n  get_etcb :: \"obj_ref \\<Rightarrow> det_state \\<Rightarrow> etcb option\"\nwhere\n  \"get_etcb tcb_ref es \\<equiv> ekheap es tcb_ref\"\n\ndefinition\n  ethread_get :: \"(etcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> 'a det_ext_monad\"\nwhere\n  \"ethread_get f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_etcb tptr;\n     return $ f tcb\n   od\"\n\n(* For infoflow, we want to avoid certain read actions, such as reading the priority of the\n   current thread when it could be idle. Then we need to make sure we do not rely on the result.\n   undefined is the closest we have to a result that can't be relied on *)\ndefinition\n  ethread_get_when :: \"bool \\<Rightarrow> (etcb \\<Rightarrow> 'a) \\<Rightarrow> obj_ref \\<Rightarrow> 'a det_ext_monad\"\nwhere\n  \"ethread_get_when b f tptr \\<equiv> if b then (ethread_get f tptr) else return undefined\"\n\ndefinition set_eobject :: \"obj_ref \\<Rightarrow> etcb \\<Rightarrow> unit det_ext_monad\"\n  where\n \"set_eobject ptr obj \\<equiv>\n  do es \\<leftarrow> get;\n    ekh \\<leftarrow> return $ (ekheap es)(ptr \\<mapsto> obj);\n    put (es\\<lparr>ekheap := ekh\\<rparr>)\n  od\"\n\ndefinition\n  ethread_set :: \"(etcb \\<Rightarrow> etcb) \\<Rightarrow> obj_ref \\<Rightarrow> unit det_ext_monad\"\nwhere\n  \"ethread_set f tptr \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_etcb tptr;\n     set_eobject tptr $ f tcb\n   od\"\n\ndefinition\n  set_scheduler_action :: \"scheduler_action \\<Rightarrow> unit det_ext_monad\" where\n  \"set_scheduler_action action \\<equiv>\n     modify (\\<lambda>es. es\\<lparr>scheduler_action := action\\<rparr>)\"\n\ndefinition\n  thread_set_priority :: \"obj_ref \\<Rightarrow> priority \\<Rightarrow> unit det_ext_monad\" where\n  \"thread_set_priority tptr prio \\<equiv> ethread_set (\\<lambda>tcb. tcb\\<lparr>tcb_priority := prio\\<rparr>) tptr\"\n\ndefinition\n  thread_set_time_slice :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> unit det_ext_monad\" where\n  \"thread_set_time_slice tptr time \\<equiv> ethread_set (\\<lambda>tcb. tcb\\<lparr>tcb_time_slice := time\\<rparr>) tptr\"\n\ndefinition\n  thread_set_domain :: \"obj_ref \\<Rightarrow> domain \\<Rightarrow> unit det_ext_monad\" where\n  \"thread_set_domain tptr domain \\<equiv> ethread_set (\\<lambda>tcb. tcb\\<lparr>tcb_domain := domain\\<rparr>) tptr\"\n\n\ndefinition\n  get_tcb_queue :: \"domain \\<Rightarrow> priority \\<Rightarrow> ready_queue det_ext_monad\" where\n  \"get_tcb_queue d prio \\<equiv> do\n     queues \\<leftarrow> gets ready_queues;\n     return (queues d prio)\n   od\"\n\ndefinition\n  set_tcb_queue :: \"domain \\<Rightarrow> priority \\<Rightarrow> ready_queue \\<Rightarrow> unit det_ext_monad\" where\n  \"set_tcb_queue d prio queue \\<equiv>\n     modify (\\<lambda>es. es\\<lparr> ready_queues :=\n      (\\<lambda>d' p. if d' = d \\<and> p = prio then queue else ready_queues es d' p)\\<rparr>)\"\n\n\ndefinition\n  tcb_sched_action :: \"(obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref list) \\<Rightarrow> obj_ref  \\<Rightarrow> unit det_ext_monad\" where\n  \"tcb_sched_action action thread \\<equiv> do\n     d \\<leftarrow> ethread_get tcb_domain thread;\n     prio \\<leftarrow> ethread_get tcb_priority thread;\n     queue \\<leftarrow> get_tcb_queue d prio;\n     set_tcb_queue d prio (action thread queue)\n   od\"\n\ndefinition\n  tcb_sched_enqueue :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref list\" where\n  \"tcb_sched_enqueue thread queue \\<equiv> if (thread \\<notin> set queue) then thread # queue else queue\"\n\ndefinition\n  tcb_sched_append :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref list\" where\n  \"tcb_sched_append thread queue \\<equiv> if (thread \\<notin> set queue) then queue @ [thread] else queue\"\n\ndefinition\n  tcb_sched_dequeue :: \"obj_ref \\<Rightarrow> obj_ref list \\<Rightarrow> obj_ref list\" where\n  \"tcb_sched_dequeue thread queue \\<equiv> filter (\\<lambda>x. x \\<noteq> thread) queue\"\n\n\ndefinition reschedule_required :: \"unit det_ext_monad\" where\n  \"reschedule_required \\<equiv> do\n     action \\<leftarrow> gets scheduler_action;\n     case action of switch_thread t \\<Rightarrow> tcb_sched_action (tcb_sched_enqueue) t | _ \\<Rightarrow> return ();\n     set_scheduler_action choose_new_thread\n   od\"\n\ndefinition\n  possible_switch_to :: \"obj_ref \\<Rightarrow> unit det_ext_monad\" where\n  \"possible_switch_to target \\<equiv> do\n     cur_dom \\<leftarrow> gets cur_domain;\n     target_dom \\<leftarrow> ethread_get tcb_domain target;\n     action \\<leftarrow> gets scheduler_action;\n\n     if (target_dom \\<noteq> cur_dom) then\n       tcb_sched_action tcb_sched_enqueue target\n     else if (action \\<noteq> resume_cur_thread) then\n       do\n         reschedule_required;\n         tcb_sched_action tcb_sched_enqueue target\n       od\n     else\n       set_scheduler_action $ switch_thread target\n   od\"\n\ndefinition\n  next_domain :: \"unit det_ext_monad\" where\n  \"next_domain \\<equiv>\n    modify (\\<lambda>s.\n      let domain_index' = (domain_index s + 1) mod length (domain_list s) in\n      let next_dom = (domain_list s)!domain_index'\n      in s\\<lparr> domain_index := domain_index',\n            cur_domain := fst next_dom,\n            domain_time := snd next_dom,\n            work_units_completed := 0\\<rparr>)\"\n\ndefinition\n  dec_domain_time :: \"unit det_ext_monad\" where\n  \"dec_domain_time = modify (\\<lambda>s. s\\<lparr>domain_time := domain_time s - 1\\<rparr>)\"\n\ndefinition set_cdt_list :: \"cdt_list \\<Rightarrow> (det_state, unit) nondet_monad\" where\n  \"set_cdt_list t \\<equiv> do\n    s \\<leftarrow> get;\n    put $ s\\<lparr> cdt_list := t \\<rparr>\n  od\"\n\ndefinition\n  update_cdt_list :: \"(cdt_list \\<Rightarrow> cdt_list) \\<Rightarrow> (det_state, unit) nondet_monad\"\nwhere\n  \"update_cdt_list f \\<equiv> do\n     t \\<leftarrow> gets cdt_list;\n     set_cdt_list (f t)\n  od\"\n\n\ntext \\<open>The CDT in the implementation is stored in prefix traversal order.\n  The following functions traverse its abstract representation here to\n  yield corresponding information.\n\\<close>\ndefinition next_child :: \"cslot_ptr \\<Rightarrow> cdt_list \\<Rightarrow> cslot_ptr option\" where\n  \"next_child slot t \\<equiv> case (t slot) of [] \\<Rightarrow> None |\n                                        x # xs \\<Rightarrow> Some x\"\n\ndefinition next_sib :: \"cslot_ptr \\<Rightarrow> cdt_list \\<Rightarrow> cdt \\<Rightarrow> cslot_ptr option\" where\n  \"next_sib slot t m \\<equiv> case m slot of None \\<Rightarrow> None |\n                       Some p \\<Rightarrow> after_in_list (t p) slot\"\n\n\nfunction (domintros) next_not_child :: \"cslot_ptr \\<Rightarrow> cdt_list \\<Rightarrow> cdt \\<Rightarrow> cslot_ptr option\" where\n  \"next_not_child slot t m = (if next_sib slot t m = None\n                             then (case m slot of\n                               None \\<Rightarrow> None |\n                               Some p \\<Rightarrow> next_not_child p t m)\n                             else next_sib slot t m)\"\n  by auto\n\n(* next_slot traverses the cdt, replicating mdb_next in the Haskell spec.\n        The cdt is traversed child first, by next_child\n        going to a nodes first child when it exists,\n        otherwise next_not_child looks up the tree until it finds\n        a new node to visit as a sibling of its self or some ancestor *)\n\ndefinition next_slot :: \"cslot_ptr \\<Rightarrow> cdt_list \\<Rightarrow> cdt \\<Rightarrow> cslot_ptr option\" where\n  \"next_slot slot t m \\<equiv> if t slot \\<noteq> []\n                        then next_child slot t\n                        else next_not_child slot t m\"\n\ntext \\<open>\\emph{Extended operations} for the deterministic abstract specification.\\<close>\n\ndefinition max_non_empty_queue :: \"(priority \\<Rightarrow> ready_queue) \\<Rightarrow> ready_queue\" where\n  \"max_non_empty_queue queues \\<equiv> queues (Max {prio. queues prio \\<noteq> []})\"\n\n\ndefinition default_ext :: \"apiobject_type \\<Rightarrow> domain \\<Rightarrow> etcb option\" where\n  \"default_ext type cdom \\<equiv>\n      case type of TCBObject \\<Rightarrow> Some (default_etcb\\<lparr>tcb_domain := cdom\\<rparr>)\n                         | _ \\<Rightarrow> None\"\n\ndefinition retype_region_ext :: \"obj_ref list \\<Rightarrow> apiobject_type \\<Rightarrow> unit det_ext_monad\" where\n  \"retype_region_ext ptrs type \\<equiv>  do\n                                     ekh \\<leftarrow> gets ekheap;\n                                     cdom \\<leftarrow> gets cur_domain;\n                                     ekh' \\<leftarrow> return $ foldr (\\<lambda>p ekh. (ekh(p := default_ext type cdom))) ptrs ekh;\n                                     modify (\\<lambda>s. s\\<lparr>ekheap := ekh'\\<rparr>)\n                                  od\"\n\ndefinition cap_swap_ext where\n\"cap_swap_ext \\<equiv> (\\<lambda> slot1 slot2 slot1_op slot2_op.\n      do\n       update_cdt_list (\\<lambda>list. list(slot1 := list slot2, slot2 := list slot1));\n       update_cdt_list\n        (\\<lambda>list. case if slot2_op = Some slot1 then Some slot2\n                     else if slot2_op = Some slot2 then Some slot1 else slot2_op of\n                None \\<Rightarrow> (case if slot1_op = Some slot1 then Some slot2\n                            else if slot1_op = Some slot2 then Some slot1 else slot1_op of\n                       None \\<Rightarrow> list\n                       | Some slot2_p \\<Rightarrow> list(slot2_p := list_replace (list slot2_p) slot1 slot2))\n                | Some slot1_p \\<Rightarrow>\n                    (case if slot1_op = Some slot1 then Some slot2\n                         else if slot1_op = Some slot2 then Some slot1 else slot1_op of\n                    None \\<Rightarrow> list(slot1_p := list_replace (list slot1_p) slot2 slot1)\n                    | Some slot2_p \\<Rightarrow>\n                        if slot1_p = slot2_p\n                        then list(slot1_p := list_swap (list slot1_p) slot1 slot2)\n                        else list(slot1_p := list_replace (list slot1_p) slot2 slot1,\n                                  slot2_p := list_replace (list slot2_p) slot1 slot2)))\n    od)\"\n\ndefinition cap_move_ext where\n\"cap_move_ext \\<equiv> (\\<lambda> src_slot dest_slot src_p dest_p.\n do\n\n    update_cdt_list (\\<lambda>list. case (dest_p) of\n      None \\<Rightarrow> list |\n      Some p \\<Rightarrow> list (p := list_remove (list p) dest_slot));\n\n   if (src_slot = dest_slot) then return () else\n\n    (do\n    update_cdt_list (\\<lambda>list. case (src_p) of\n      None \\<Rightarrow> list |\n      Some p \\<Rightarrow> list (p := list_replace (list p) src_slot dest_slot));\n\n    update_cdt_list (\\<lambda>list. list (src_slot := [], dest_slot := (list src_slot) @ (list dest_slot)))\n    od)\n\n  od)\"\n\n\ndefinition cap_insert_ext where\n\"cap_insert_ext \\<equiv> (\\<lambda> src_parent src_slot dest_slot src_p dest_p.\n do\n\n update_cdt_list (\\<lambda>list. case (dest_p) of\n      None \\<Rightarrow> list |\n      Some p \\<Rightarrow> (list (p := list_remove (list p) dest_slot)));\n\n    update_cdt_list (\\<lambda>list. case (src_p) of\n      None \\<Rightarrow> list (\n        src_slot := if src_parent then [dest_slot] @ (list src_slot) else list src_slot) |\n      Some p \\<Rightarrow> list (\n        src_slot := if src_parent then [dest_slot] @ (list src_slot) else list src_slot,\n        p := if (src_parent \\<and> p \\<noteq> src_slot) then (list p) else if (src_slot \\<noteq> dest_slot) then (list_insert_after (list p) src_slot dest_slot) else (dest_slot # (list p))))\n od)\"\n\ndefinition empty_slot_ext where\n\"empty_slot_ext \\<equiv> (\\<lambda> slot slot_p.\n\n    update_cdt_list (\\<lambda>list. case slot_p of None \\<Rightarrow> list (slot := []) |\n      Some p \\<Rightarrow> if (p = slot) then list(p := list_remove (list p) slot) else list (p := list_replace_list (list p) slot (list slot), slot := [])))\"\n\ndefinition create_cap_ext where\n\"create_cap_ext \\<equiv> (\\<lambda> untyped dest dest_p. do\n\n    update_cdt_list (\\<lambda>list. case dest_p of\n      None \\<Rightarrow> list |\n      Some p \\<Rightarrow> (list (p := list_remove (list p) dest)));\n\n    update_cdt_list (\\<lambda>list. list (untyped := [dest] @ (list untyped)))\n  od)\"\n\ndefinition next_revoke_cap where\n\"next_revoke_cap \\<equiv> (\\<lambda>slot ext. the (next_child slot (cdt_list ext)))\"\n\ndefinition\n  free_asid_select :: \"(asid_high_index \\<rightharpoonup> 'a) \\<Rightarrow> asid_high_index\"\nwhere\n  \"free_asid_select \\<equiv> \\<lambda>asid_table. fst (hd (filter (\\<lambda>(x,y). x \\<le> 2 ^ asid_high_bits - 1 \\<and> y = None) (assocs asid_table)))\"\n\ndefinition\n  free_asid_pool_select :: \"(asid_low_index \\<rightharpoonup> 'a) \\<Rightarrow> asid \\<Rightarrow> asid_low_index\"\nwhere\n  \"free_asid_pool_select \\<equiv> (\\<lambda>pool base.\n     fst (hd ((filter (\\<lambda> (x,y). ucast x + base \\<noteq> 0 \\<and> y = None) (assocs pool)))))\"\n\ndefinition update_work_units where\n  \"update_work_units \\<equiv>\n     modify (\\<lambda>s. s\\<lparr>work_units_completed := work_units_completed s + 1\\<rparr>)\"\n\ndefinition reset_work_units where\n  \"reset_work_units \\<equiv>\n     modify (\\<lambda>s. s\\<lparr>work_units_completed := 0\\<rparr>)\"\n\ndefinition work_units_limit_reached where\n  \"work_units_limit_reached \\<equiv> do\n     work_units \\<leftarrow> gets work_units_completed;\n     return (work_units_limit \\<le> work_units)\n   od\"\n\ntext \\<open>\n  A type class for all instantiations of the abstract specification. In\n  practice, this is restricted to basically allow only two sensible\n  implementations at present: the deterministic abstract specification and\n  the nondeterministic one.\n\\<close>\nclass state_ext =\n fixes unwrap_ext :: \"'a state \\<Rightarrow> det_ext state\"\n fixes wrap_ext :: \"(det_ext \\<Rightarrow> det_ext) \\<Rightarrow> ('a \\<Rightarrow> 'a)\"\n fixes wrap_ext_op :: \"unit det_ext_monad \\<Rightarrow> ('a state,unit) nondet_monad\"\n fixes wrap_ext_bool :: \"bool det_ext_monad \\<Rightarrow> ('a state,bool) nondet_monad\"\n fixes select_switch :: \"'a \\<Rightarrow> bool\"\n fixes ext_init :: \"'a\"\n\ndefinition detype_ext :: \"obj_ref set \\<Rightarrow> 'z::state_ext \\<Rightarrow> 'z\" where\n \"detype_ext S \\<equiv> wrap_ext (\\<lambda>s. s\\<lparr>ekheap_internal := (\\<lambda>x. if x \\<in> S then None else ekheap_internal s x)\\<rparr>)\"\n\ninstantiation  det_ext_ext :: (type) state_ext\nbegin\n\ndefinition \"unwrap_ext_det_ext_ext == (\\<lambda>x. x) :: det_ext state \\<Rightarrow> det_ext state\"\n\ndefinition \"wrap_ext_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext \\<Rightarrow> det_ext) \\<Rightarrow> det_ext \\<Rightarrow> det_ext\"\n\ndefinition \"wrap_ext_op_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext state \\<Rightarrow> ((unit \\<times> det_ext state) set) \\<times> bool)\n  \\<Rightarrow> det_ext state  \\<Rightarrow> ((unit \\<times> det_ext state) set) \\<times> bool\"\n\ndefinition \"wrap_ext_bool_det_ext_ext == (\\<lambda>x. x) ::\n  (det_ext state \\<Rightarrow> ((bool \\<times> det_ext state) set) \\<times> bool)\n  \\<Rightarrow> det_ext state \\<Rightarrow> ((bool \\<times> det_ext state) set) \\<times> bool\"\n\ndefinition \"select_switch_det_ext_ext == (\\<lambda>_. True)  :: det_ext\\<Rightarrow> bool\"\n\n(* this probably doesn't satisfy the invariants *)\ndefinition \"ext_init_det_ext_ext \\<equiv>\n     \\<lparr>work_units_completed_internal = 0,\n      scheduler_action_internal = resume_cur_thread,\n      ekheap_internal = Map.empty (idle_thread_ptr \\<mapsto> default_etcb),\n      domain_list_internal = [(0,15)],\n      domain_index_internal = 0,\n      cur_domain_internal = 0,\n      domain_time_internal = 15,\n      ready_queues_internal = const (const []),\n      cdt_list_internal = const []\\<rparr> :: det_ext\"\n\ninstance ..\n\nend"}
{"title": "./spec/abstract/Deterministic_A.thy", "section": "Nondeterministic Abstract Specification", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\\label{s:nondet-spec}\nThe nondeterministic abstract specification instantiates the extended state\nwith the unit type -- i.e. it doesn't have any meaningful extended state.\n\\<close>\n\ninstantiation unit :: state_ext\nbegin\n\n\ndefinition \"unwrap_ext_unit == (\\<lambda>_. undefined) :: unit state \\<Rightarrow> det_ext state\"\n\ndefinition \"wrap_ext_unit == (\\<lambda>f s. ()) :: (det_ext \\<Rightarrow> det_ext) \\<Rightarrow> unit \\<Rightarrow> unit\"\n\n\ndefinition \"wrap_ext_op_unit == (\\<lambda>m. return ()) ::\n  (det_ext state \\<Rightarrow> ((unit \\<times> det_ext state) set) \\<times> bool) \\<Rightarrow> unit state \\<Rightarrow> ((unit \\<times> unit state) set) \\<times> bool\"\n\ndefinition \"wrap_ext_bool_unit == (\\<lambda>m. select UNIV) ::\n  (det_ext state \\<Rightarrow> ((bool \\<times> det_ext state ) set) \\<times> bool) \\<Rightarrow> unit state \\<Rightarrow> ((bool \\<times> unit state) set) \\<times> bool\"\n\ndefinition \"select_switch_unit == (\\<lambda>s. False) :: unit \\<Rightarrow> bool\"\n\ndefinition \"ext_init_unit \\<equiv> () :: unit\"\n\ninstance ..\n\nend\n\ntext \\<open>Run an extended operation over the extended state without\n  modifying it and use the return value to choose between two computations\n  to run.\n\\<close>\nlemmas ext_init_def = ext_init_det_ext_ext_def ext_init_unit_def\n\ndefinition OR_choice :: \"bool det_ext_monad \\<Rightarrow> ('z::state_ext state,'a) nondet_monad \\<Rightarrow> ('z state,'a) nondet_monad \\<Rightarrow> ('z state,'a) nondet_monad\" where\n\"OR_choice c f g \\<equiv>\n  do\n    ex \\<leftarrow> get;\n    (rv,_) \\<leftarrow> select_f (mk_ef ((wrap_ext_bool c) ex));\n    if rv then f else g\n  od\"\n\ndefinition OR_choiceE :: \"bool det_ext_monad \\<Rightarrow> ('z::state_ext state,'e + 'a) nondet_monad \\<Rightarrow> ('z state,'e + 'a) nondet_monad \\<Rightarrow> ('z state,'e + 'a) nondet_monad\" where\n\"OR_choiceE c f g \\<equiv>\n  doE\n    ex \\<leftarrow> liftE get;\n    (rv,_) \\<leftarrow> liftE $ select_f (mk_ef ((wrap_ext_bool c) ex));\n    if rv then f else g\n  odE\"\n\ntext \\<open>Run an extended operation over the extended state to update the\n  extended state, ignoring any return value that the extended operation might\n  yield.\n\\<close>\n\ndefinition do_extended_op :: \"unit det_ext_monad \\<Rightarrow> ('z::state_ext state,unit) nondet_monad\" where\n \"do_extended_op eop \\<equiv> do\n                         ex \\<leftarrow> get;\n                         (_,es') \\<leftarrow> select_f (mk_ef ((wrap_ext_op eop) ex));\n                         modify (\\<lambda> state. state\\<lparr>exst := (exst es')\\<rparr>)\n                        od\"\n\ntext \\<open>\n  Use the extended state to choose a value from a bounding set @{term S} when\n  @{term select_switch} is true. Otherwise just select from @{term S}.\n\\<close>\ndefinition select_ext :: \"(det_ext state \\<Rightarrow> 'd) \\<Rightarrow> ('d set) \\<Rightarrow> ('a::state_ext state,'d) nondet_monad\" where\n  \"select_ext a S \\<equiv> do\n                      s \\<leftarrow> get;\n                      x \\<leftarrow> if (select_switch (exst s)) then (return (a (unwrap_ext s)))\n                          else (select S);\n                      assert (x \\<in> S);\n                      return x\n                    od\"\n\n(*Defined here because it's asserted before empty_slot*)\ndefinition valid_list_2 :: \"cdt_list \\<Rightarrow> cdt \\<Rightarrow> bool\" where\n  \"valid_list_2 t m \\<equiv> (\\<forall>p. set (t p) = {c. m c = Some p}) \\<and> (\\<forall>p. distinct (t p))\"\n\nabbreviation valid_list :: \"det_ext state \\<Rightarrow> bool\" where\n  \"valid_list s \\<equiv> valid_list_2 (cdt_list s) (cdt s)\"\n\nend"}
{"title": "./spec/abstract/Retype_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nRetyping and untyped invocation\n*)\n\nchapter \"Retyping and Untyped Invocations\"\n\ntheory Retype_A\nimports\n  CSpaceAcc_A\n  ArchVSpaceAcc_A\n  Invocations_A\n  ArchRetype_A\nbegin\n\narch_requalify_consts (A)\n  arch_default_cap\n  default_arch_object\n  init_arch_objects"}
{"title": "./spec/abstract/Retype_A.thy", "section": "Creating Objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The original capability created when an object of a given type is\ncreated with a particular address and size.\\<close>\nprimrec\n  default_cap :: \"apiobject_type  \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> cap\"\nwhere\n  \"default_cap CapTableObject oref s _ = CNodeCap oref s []\"\n| \"default_cap Untyped oref s dev = UntypedCap dev oref s 0\"\n| \"default_cap TCBObject oref s _ = ThreadCap oref\"\n| \"default_cap EndpointObject oref s _ = EndpointCap oref 0 UNIV\"\n| \"default_cap NotificationObject oref s _ =\n     NotificationCap oref 0 {AllowRead, AllowWrite}\"\n| \"default_cap (ArchObject aobj) oref s dev = ArchObjectCap (arch_default_cap aobj oref s dev)\"\n\ntext \\<open>Create and install a new capability to a newly created object.\\<close>\ndefinition\n  create_cap ::\n  \"apiobject_type \\<Rightarrow> nat \\<Rightarrow> cslot_ptr \\<Rightarrow> bool \\<Rightarrow> cslot_ptr \\<times> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"create_cap type bits untyped is_device \\<equiv> \\<lambda>(dest,oref). do\n    dest_p \\<leftarrow> gets (\\<lambda>s. cdt s dest);\n    cdt \\<leftarrow> gets cdt;\n    set_cdt (cdt (dest \\<mapsto> untyped));\n    do_extended_op (create_cap_ext untyped dest dest_p);\n    set_original dest True;\n    set_cap (default_cap type oref bits is_device) dest\n   od\""}
{"title": "./spec/abstract/Retype_A.thy", "section": "Creating Objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Properties of an empty CNode object.\\<close>\ndefinition\n  empty_cnode :: \"nat \\<Rightarrow> cnode_contents\" where\n  \"empty_cnode bits \\<equiv> \\<lambda>x. if length x = bits then Some NullCap else None\"\n\n\ntext \\<open>The initial state objects of various types are in when created.\\<close>\ndefinition\n  default_object :: \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> kernel_object\" where\n  \"default_object api dev n \\<equiv> case api of\n           Untyped \\<Rightarrow> undefined\n         | CapTableObject \\<Rightarrow> CNode n (empty_cnode n)\n         | TCBObject \\<Rightarrow> TCB default_tcb\n         | EndpointObject \\<Rightarrow> Endpoint default_ep\n         | NotificationObject \\<Rightarrow> Notification default_notification\n         | ArchObject aobj \\<Rightarrow> ArchObj (default_arch_object aobj dev n)\"\n\ntext \\<open>The size in bits of the objects that will be created when a given type\nand size is requested.\\<close>\ndefinition\n  obj_bits_api :: \"apiobject_type \\<Rightarrow> nat \\<Rightarrow> nat\" where\n  \"obj_bits_api type obj_size_bits \\<equiv> case type of\n           Untyped \\<Rightarrow> obj_size_bits\n         | CapTableObject \\<Rightarrow> obj_size_bits + slot_bits\n         | TCBObject \\<Rightarrow> obj_bits (TCB default_tcb)\n         | EndpointObject \\<Rightarrow> obj_bits (Endpoint undefined)\n         | NotificationObject \\<Rightarrow> obj_bits (Notification undefined)\n         | ArchObject aobj \\<Rightarrow> obj_bits $ ArchObj $ default_arch_object aobj False obj_size_bits\""}
{"title": "./spec/abstract/Retype_A.thy", "section": "Main Retype Implementation", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\nCreate @{text \"numObjects\"} objects, starting from\n@{text obj_ref}, return of list pointers to them. For some types, each\nreturned pointer points to a group of objects.\n\\<close>\n\ndefinition\n  retype_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> apiobject_type \\<Rightarrow> bool \\<Rightarrow> (obj_ref list,'z::state_ext) s_monad\"\nwhere\n  \"retype_region ptr numObjects o_bits type dev \\<equiv> do\n    obj_size \\<leftarrow> return $ 2 ^ obj_bits_api type o_bits;\n    ptrs \\<leftarrow> return $ map (\\<lambda>p. ptr_add ptr (p * obj_size)) [0..< numObjects];\n    when (type \\<noteq> Untyped) (do\n      kh \\<leftarrow> gets kheap;\n      kh' \\<leftarrow> return $ foldr (\\<lambda>p kh. kh(p \\<mapsto> default_object type dev o_bits)) ptrs kh;\n      do_extended_op (retype_region_ext ptrs type);\n      modify $ kheap_update (K kh')\n    od);\n    return $ ptrs\n  od\""}
{"title": "./spec/abstract/Retype_A.thy", "section": "Invoking Untyped Capabilities", "subsection": "", "subsubsection": "", "code": "\nabbreviation (input) \"extended_state_update \\<equiv> trans_state\"\n\ntext \\<open>Remove objects from a region of the heap.\\<close>\ndefinition\n  detype :: \"(obj_ref set) \\<Rightarrow> 'z::state_ext state \\<Rightarrow> 'z::state_ext state\" where\n \"detype S s \\<equiv> s \\<lparr> kheap := (\\<lambda>x. if x \\<in> S then None else kheap s x), extended_state := detype_ext S (exst s)\\<rparr>\"\n\ntext \\<open>Delete objects within a specified region.\\<close>\ndefinition\n  delete_objects :: \"machine_word \\<Rightarrow> nat \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"delete_objects ptr bits = do\n     do_machine_op (freeMemory ptr bits);\n     modify (detype {ptr..ptr + 2 ^ bits - 1})\n  od\"\n\ndefinition\n  get_free_ref :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> obj_ref\" where\n  \"get_free_ref base free_index \\<equiv> base +  (of_nat free_index)\"\n\ndefinition\n  get_free_index :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> nat\" where\n  \"get_free_index base free \\<equiv> unat $ (free - base)\"\n\nprimrec(nonexhaustive) is_device_untyped_cap\nwhere\n  \"is_device_untyped_cap (UntypedCap isdev _ _ _) = isdev\"\n\ntext \\<open>Untyped capabilities note a currently free region. Sometimes this\nregion is reset during a Retype operation. This progressively clears the\nunderlying memory and also the object level representation, moving the free\nregion pointer back to the start of the newly cleared region each time.\\<close>\ndefinition\n  reset_untyped_cap :: \"cslot_ptr \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"reset_untyped_cap src_slot = doE\n  cap \\<leftarrow> liftE $ get_cap src_slot;\n  sz \\<leftarrow> returnOk $ bits_of cap;\n  base \\<leftarrow> returnOk $ obj_ref_of cap;\n  if free_index_of cap = 0\n    then returnOk ()\n  else doE\n    liftE $ delete_objects base sz;\n  dev \\<leftarrow> returnOk $ is_device_untyped_cap cap;\n\n  if dev \\<or> sz < resetChunkBits\n      then liftE $ do\n        unless dev $ do_machine_op $ clearMemory base (2 ^ sz);\n        set_cap (UntypedCap dev base sz 0) src_slot\n      od\n    else mapME_x (\\<lambda>i. doE\n          liftE $ do_machine_op $ clearMemory (base + (of_nat i << resetChunkBits))\n              (2 ^ resetChunkBits);\n          liftE $ set_cap (UntypedCap dev base sz\n              (i * 2 ^ resetChunkBits)) src_slot;\n          preemption_point\n        odE) (rev [i \\<leftarrow> [0 ..< 2 ^ (sz - resetChunkBits)].\n            i * 2 ^ resetChunkBits < free_index_of cap])\n    odE\n  odE\"\n\ntext \\<open>Untyped capabilities confer authority to the Retype method. This\nclears existing objects from a region, creates new objects of the requested type,\ninitialises them and installs new capabilities to them.\\<close>\ndefinition\n  invoke_untyped :: \"untyped_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n\"invoke_untyped ui \\<equiv> case ui\n    of Retype src_slot reset base retype_base new_type obj_sz slots is_device \\<Rightarrow>\ndoE\n  whenE reset $ reset_untyped_cap src_slot;\n  liftE $ do\n\n  cap \\<leftarrow> get_cap src_slot;\n\n  \\<comment> \\<open>Update the untyped cap to track the amount of space used.\\<close>\n  total_object_size \\<leftarrow> return $ (of_nat (length slots) << (obj_bits_api new_type obj_sz));\n  free_ref \\<leftarrow> return $ retype_base + total_object_size;\n  set_cap (UntypedCap is_device base (bits_of cap) (unat (free_ref - base))) src_slot;\n\n  \\<comment> \\<open>Create new objects.\\<close>\n  orefs \\<leftarrow> retype_region retype_base (length slots) obj_sz new_type is_device;\n  init_arch_objects new_type is_device retype_base (length slots) obj_sz orefs;\n  sequence_x (map (create_cap new_type obj_sz src_slot is_device) (zip slots orefs))\nod odE\"\n\nend"}
{"title": "./spec/abstract/Exceptions_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nMonad instantiations, handling of faults, errors, and interrupts.\n*)\n\nchapter \"Basic Kernel and Exception Monads\"\n\ntheory Exceptions_A\nimports Deterministic_A\nbegin\n\ntext \\<open>This theory contains abbreviations for the monadic types used\nin the specification and a number of lifting functions between them.\\<close>\n\ntext \\<open>The basic kernel monad without faults, interrupts, or errors.\\<close>\ntype_synonym ('a,'z) s_monad = \"('z state, 'a) nondet_monad\"\n\ntext \\<open>The fault monad: may throw a @{text fault} exception which\nwill usually be reported to the current thread's fault handler.\\<close>\ntype_synonym ('a,'z) f_monad = \"(fault + 'a,'z) s_monad\"\n\nterm \"a::(unit,'a) s_monad\"\n\ntext \\<open>The error monad: may throw a @{text syscall_error} exception\nwhich will usually be reported to the current thread as system call\nresult.\\<close>\ntype_synonym ('a,'z) se_monad = \"(syscall_error + 'a,'z) s_monad\"\n\ntext \\<open>The lookup failure monad: may throw a @{text lookup_failure}\nexception. Depending on context it may either be reported directly to\nthe current thread or to its fault handler.\n\\<close>\ntype_synonym ('a,'z) lf_monad = \"(lookup_failure + 'a,'z) s_monad\"\n\ntext \\<open>The preemption monad. May throw an interrupt exception.\\<close>\ntype_synonym ('a,'z) p_monad = \"(unit + 'a,'z) s_monad\"\n\n\ntext \\<open>\n  Printing abbreviations for the above types.\n\\<close>\ntranslations\n  (type) \"'a s_monad\" <= (type) \"state \\<Rightarrow> (('a \\<times> state) \\<Rightarrow> bool) \\<times> bool\"\n  (type) \"'a f_monad\" <= (type) \"(fault + 'a) s_monad\"\n  (type) \"'a se_monad\" <= (type) \"(syscall_error + 'a) s_monad\"\n  (type) \"'a lf_monad\" <= (type) \"(lookup_failure + 'a) s_monad\"\n  (type) \"'a p_monad\" <=(type) \"(unit + 'a) s_monad\"\n\ntext \\<open>Perform non-preemptible operations within preemptible blocks.\\<close>\ndefinition\n  without_preemption :: \"('a,'z::state_ext) s_monad \\<Rightarrow> ('a,'z::state_ext) p_monad\"\nwhere without_preemption_def[simp]:\n \"without_preemption \\<equiv> liftE\"\n\ntext \\<open>Allow preemption at this point.\\<close>\ndefinition\n  preemption_point :: \"(unit,'z::state_ext) p_monad\" where\n \"preemption_point \\<equiv> doE liftE $ do_extended_op update_work_units;\n                         OR_choiceE (work_units_limit_reached)\n                           (doE liftE $ do_extended_op reset_work_units;\n                                irq_opt \\<leftarrow> liftE $ do_machine_op (getActiveIRQ True);\n                                case_option (returnOk ()) (K (throwError $ ())) irq_opt\n                           odE) (returnOk ())\n                     odE\"\n\ntext \\<open>Lift one kind of exception monad into another by converting the error\ninto various other kinds of error or return value.\\<close>\ndefinition\n  cap_fault_on_failure :: \"obj_ref \\<Rightarrow> bool \\<Rightarrow> ('a,'z::state_ext) lf_monad \\<Rightarrow> ('a,'z::state_ext) f_monad\" where\n \"cap_fault_on_failure cptr rp m \\<equiv> handleE' m (throwError \\<circ> CapFault cptr rp)\"\n\ndefinition\n  lookup_error_on_failure ::  \"bool \\<Rightarrow> ('a,'z::state_ext) lf_monad \\<Rightarrow> ('a,'z::state_ext) se_monad\" where\n \"lookup_error_on_failure s m \\<equiv> handleE' m (throwError \\<circ> FailedLookup s)\"\n\ndefinition\n  null_cap_on_failure :: \"(cap,'z::state_ext) lf_monad \\<Rightarrow> (cap,'z::state_ext) s_monad\" where\n \"null_cap_on_failure \\<equiv> liftM (case_sum (\\<lambda>x. NullCap) id)\"\n\ndefinition\n  unify_failure :: \"('f + 'a,'z::state_ext) s_monad \\<Rightarrow> (unit + 'a,'z::state_ext) s_monad\" where\n \"unify_failure m \\<equiv> handleE' m (\\<lambda>x. throwError ())\"\n\ndefinition\n  empty_on_failure :: \"('f + 'a list,'z::state_ext) s_monad \\<Rightarrow> ('a list,'z::state_ext) s_monad\" where\n \"empty_on_failure m \\<equiv> m <catch> (\\<lambda>x. return [])\"\n\ndefinition\n  const_on_failure :: \"'a \\<Rightarrow> ('f + 'a,'z::state_ext) s_monad \\<Rightarrow> ('a,'z::state_ext) s_monad\" where\n \"const_on_failure c m \\<equiv> m <catch> (\\<lambda>x. return c)\"\n\ntext \\<open>Checks whether first argument is between second and third (inclusive).\\<close>\n\ndefinition\n  range_check :: \"machine_word \\<Rightarrow> machine_word \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"range_check v min_v max_v \\<equiv>\n    unlessE (v \\<ge> min_v \\<and> v \\<le> max_v) $ throwError $ RangeError min_v max_v\"\n\nend"}
{"title": "./spec/abstract/Syscall_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nTop-level system call interface.\n*)\n\nchapter \"System Calls\"\n\ntheory Syscall_A\nimports\n  \"ExecSpec.Event_H\"\n  Decode_A\n  Init_A\n  Hypervisor_A\nbegin\n\narch_requalify_consts (A)\n  arch_perform_invocation\n  handle_vm_fault\n  handle_hypervisor_fault\n\n\ntext\\<open>\n\\label{c:syscall}\n\nThis theory defines the entry point to the kernel, @{term\ncall_kernel}, which is called by the assembly stubs after\nswitching into kernel mode and saving registers.\nThere are five kinds of events that end up in a switch to\nkernel mode. These events are described by the enumerated type @{term\nevent}, defined in \\autoref{sec:Event_H}. One of the five events is an\nactual system call by the user, the other four are related to faults\nand interrupts. There are seven different kinds of user system calls,\ndescribed by the enumerated type @{term syscall}, also defined in\n\\autoref{sec:Event_H}.\n\nThe @{text call_kernel} function delegates the event-specific behaviour\nto @{text handle_event} which in turn further dispatches to system-call\nspecific handler functions.\n\nIn particular, two of the system calls, namely @{term SysSend} and\n@{term SysCall}, correspond to a method invocation on capabilities.\nThey are handled in the @{term handle_invocation} operation, which is\nmade up of\nthree phases: first checking if the caller has the capabilities to\nperform the operation, then decoding the arguments received from the\nuser (using the @{term decode_invocation} operation), and finally\nactually performing the invocation (using the @{term\nperform_invocation}).  These three phases are wrapped into a more\ngeneric @{term syscall} framework function described below.\n\\<close>"}
{"title": "./spec/abstract/Syscall_A.thy", "section": "System call entry point", "subsection": "", "subsubsection": "", "code": "\ntext\\<open>The @{term syscall} operation generically describes the usual\nexecution of system calls in three phases, where the first phase may\nresult in a fault, the second phase may result in an error and the third\nphase may be interrupted. The first two phases are used for argument decoding\nand checking. The last phase commits and executes the system call.\n\nThe @{term syscall} operation has five arguments:\n\\begin{itemize}\n\\item the first operation @{text m_fault} to execute, that may\nresult in a fault;\n\\item the fault handler @{text h_fault} to execute if the first\noperation resulted in a fault;\n\\item the second operation @{text m_error} to execute (if no fault\noccurred in the first operation); this second operation may result in\nan error;\n\\item the error handler @{text h_error} to execute if the second\noperation resulted in an error;\n\\item the third and last operation @{text m_finalise} to execute (if\nno error occurred in the second operation); this operation may be\ninterrupted.\n\\end{itemize}\n\\<close>\n\ndefinition\n  syscall :: \"('a,'z::state_ext) f_monad\n                  \\<Rightarrow> (fault \\<Rightarrow> ('c,'z::state_ext) s_monad)\n                  \\<Rightarrow> ('a \\<Rightarrow> ('b,'z::state_ext) se_monad)\n                  \\<Rightarrow> (syscall_error \\<Rightarrow> ('c,'z::state_ext) s_monad)\n               \\<Rightarrow> ('b \\<Rightarrow> ('c,'z::state_ext) p_monad) \\<Rightarrow> ('c,'z::state_ext) p_monad\"\nwhere\n\"syscall m_fault h_fault m_error h_error m_finalise \\<equiv> doE\n    r_fault \\<leftarrow> without_preemption $ m_fault;\n    case r_fault of\n          Inl f \\<Rightarrow>   without_preemption $ h_fault f\n        | Inr a \\<Rightarrow>   doE\n            r_error \\<leftarrow> without_preemption $ m_error a;\n            case r_error of\n                  Inl e \\<Rightarrow>   without_preemption $ h_error e\n                | Inr b \\<Rightarrow>   m_finalise b\n        odE\nodE\""}
{"title": "./spec/abstract/Syscall_A.thy", "section": "System call entry point", "subsection": "", "subsubsection": "", "code": "\ntext\\<open>The kernel user can perform seven kinds of system calls,\ndescribed by the enumerated type @{term syscall}, defined in \\autoref{s:spec_syscall}.\nThese seven system calls can be categorised into two broad\nfamilies: sending messages and receiving messages, the two main\nservices provided by the kernel.\n\nThe usual case for sending messages (@{text Send} event) consists of the user\nsending a message to an object, without expecting any answer. The sender is\nblocked until the receiver is waiting to receive. In case the\nreceiver is not trusted, an explicit non-blocking send operation can\nbe used (@{text NBSend} event). If a reply is requested from the\nreceiver, the Call operation can be used (@{text Call} event). The Call operation\nwill automatically provide a @{text Reply} capability to the receiver.\n\nAll three sending operations are handled by the @{text\nhandle_invocation} operation, which takes two boolean arguments, one\nto indicate if a reply is requested and the other to indicate if the\nsend is blocking or not.\n\nThe other direction is the reception of messages. This is done by\nperforming a Recv operation on an endpoint kernel object. The receiver\nis then blocked until a sender performs a Send operation on the\nendpoint object, resulting in a message transfer between the sender\nand the receiver. The receiver may also perform a Reply operation\n(@{text Reply} event) in response to a @{text Call}, which is always\nnon-blocking. When the receiver is a user-level server, it generally\nruns a loop waiting for messages. On handling a received message, the\nserver will send a reply and then return to waiting. To avoid\nexcessive switching between user and kernel mode, the kernel provides\na ReplyRecv operation, which is simply a Reply followed by Recv.\n\nFinally, the last event, @{text Yield}, enables the user to donate its\nremaining timeslice.\\<close>\n\ntext\\<open>The invocation is made up of three phases. The first phase\ncorresponds to a lookup of capabilities to check that the invocation\nis valid. This phase can result in a fault if a given CSpace address\nis invalid (see the function @{text \"resolve_address_bits\"}). The\nsecond phase is the decoding of the arguments given by the user. This\nis handled by the @{text decode_invocation} operation. This operation\ncan result in an error if, for example, the number of arguments is\nless than required by the operation, or if some argument capability\nhas the wrong type. Finally, the actual invocation is performed, using\nthe @{text perform_invocation} function. Note that this last phase is\npreemptable.\n\\<close>\n\nfun\n  perform_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\nwhere\n  \"perform_invocation block call (InvokeUntyped i) =\n    doE\n      invoke_untyped i;\n      returnOk []\n    odE\"\n\n| \"perform_invocation block call (InvokeEndpoint ep badge canGrant canGrantReply) =\n    (without_preemption $ do\n       thread \\<leftarrow> gets cur_thread;\n       send_ipc block call badge canGrant canGrantReply thread ep;\n       return []\n     od)\"\n\n| \"perform_invocation block call (InvokeNotification ep badge) =\n    doE\n      without_preemption $ send_signal ep badge;\n      returnOk []\n    odE\"\n\n| \"perform_invocation block call (InvokeTCB i) = invoke_tcb i\"\n\n| \"perform_invocation block call (InvokeDomain tptr d) = invoke_domain tptr d\"\n\n| \"perform_invocation block call (InvokeReply thread slot grant) =\n    liftE (do\n      sender \\<leftarrow> gets cur_thread;\n      do_reply_transfer sender thread slot grant;\n      return []\n    od)\"\n\n| \"perform_invocation block call (InvokeCNode i) =\n    doE\n      invoke_cnode i;\n      returnOk []\n    odE\"\n\n| \"perform_invocation block call (InvokeIRQControl i) =\n   doE\n     invoke_irq_control i;\n     returnOk []\n   odE\"\n\n| \"perform_invocation block call (InvokeIRQHandler i) =\n   doE\n     liftE $ invoke_irq_handler i;\n     returnOk []\n   odE\"\n\n| \"perform_invocation block call (InvokeArchObject i) =\n    arch_perform_invocation i\"\n\n\ndefinition\n  handle_invocation :: \"bool \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"handle_invocation calling blocking \\<equiv> doE\n    thread \\<leftarrow> liftE $ gets cur_thread;\n    info \\<leftarrow> without_preemption $ get_message_info thread;\n    ptr \\<leftarrow> without_preemption $ liftM data_to_cptr $\n          as_user thread $ getRegister cap_register;\n    syscall\n      (doE\n         (cap, slot) \\<leftarrow> cap_fault_on_failure (of_bl ptr) False $\n                           lookup_cap_and_slot thread ptr;\n         buffer \\<leftarrow> liftE $ lookup_ipc_buffer False thread;\n         extracaps \\<leftarrow> lookup_extra_caps thread buffer info;\n         returnOk (slot, cap, extracaps, buffer)\n       odE)\n      (\\<lambda>fault. when blocking $ handle_fault thread fault)\n      (\\<lambda>(slot,cap,extracaps,buffer). doE\n            args \\<leftarrow> liftE $ get_mrs thread buffer info;\n            decode_invocation (mi_label info) args ptr slot cap extracaps\n       odE)\n      (\\<lambda>err. when calling $\n            reply_from_kernel thread $ msg_from_syscall_error err)\n      (\\<lambda>oper. doE\n            without_preemption $ set_thread_state thread Restart;\n            reply \\<leftarrow> perform_invocation blocking calling oper;\n            without_preemption $ do\n                state \\<leftarrow> get_thread_state thread;\n                case state of\n                      Restart \\<Rightarrow> do\n                          when calling $\n                              reply_from_kernel thread (0, reply);\n                          set_thread_state thread Running\n                      od\n                    | _ \\<Rightarrow>  return ()\n            od\n       odE)\n  odE\"\n\n\ndefinition\n  handle_yield :: \"(unit,'z::state_ext) s_monad\" where\n  \"handle_yield \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n     do_extended_op (tcb_sched_action (tcb_sched_dequeue) thread);\n     do_extended_op (tcb_sched_action (tcb_sched_append) thread);\n     do_extended_op (reschedule_required)\n   od\"\n\ndefinition\n  handle_send :: \"bool \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n  \"handle_send bl \\<equiv> handle_invocation False bl\"\n\ndefinition\n  handle_call :: \"(unit,'z::state_ext) p_monad\" where\n \"handle_call \\<equiv> handle_invocation True True\"\n\ndefinition\n  delete_caller_cap :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"delete_caller_cap t \\<equiv> cap_delete_one (t, tcb_cnode_index 3)\"\n\ndefinition\n  handle_recv :: \"bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"handle_recv is_blocking \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n\n     ep_cptr \\<leftarrow> liftM data_to_cptr $ as_user thread $\n                 getRegister cap_register;\n\n     (cap_fault_on_failure (of_bl ep_cptr) True $ doE\n        ep_cap \\<leftarrow> lookup_cap thread ep_cptr;\n\n        let flt = (throwError $ MissingCapability 0)\n        in\n        case ep_cap\n          of EndpointCap ref badge rights \\<Rightarrow>\n             (if AllowRecv \\<in> rights\n              then liftE $ do\n                 delete_caller_cap thread;\n                 receive_ipc thread ep_cap is_blocking\n                od\n              else flt)\n           | NotificationCap ref badge rights \\<Rightarrow>\n             (if AllowRecv \\<in> rights\n              then doE\n                ntfn \\<leftarrow> liftE $ get_notification ref;\n                boundTCB \\<leftarrow> returnOk $ ntfn_bound_tcb ntfn;\n                if boundTCB = Some thread \\<or> boundTCB = None\n                then liftE $ receive_signal thread ep_cap is_blocking\n                else flt\n               odE\n              else flt)\n           | _ \\<Rightarrow> flt\n      odE)\n      <catch> handle_fault thread\n   od\"\n\ndefinition\n  handle_reply :: \"(unit,'z::state_ext) s_monad\" where\n \"handle_reply \\<equiv> do\n    thread \\<leftarrow> gets cur_thread;\n    caller_cap \\<leftarrow> get_cap (thread, tcb_cnode_index 3);\n    case caller_cap of\n      ReplyCap caller False R \\<Rightarrow>\n        do_reply_transfer thread caller (thread, tcb_cnode_index 3) (AllowGrant \\<in> R)\n    | NullCap \\<Rightarrow> return ()\n    | _ \\<Rightarrow> fail\n  od\""}
{"title": "./spec/abstract/Syscall_A.thy", "section": "Top-level event handling", "subsection": "", "subsubsection": "", "code": "\nfun\n  handle_event :: \"event \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"handle_event (SyscallEvent call) =\n   (case call of\n          SysSend \\<Rightarrow> handle_send True\n        | SysNBSend \\<Rightarrow> handle_send False\n        | SysCall \\<Rightarrow> handle_call\n        | SysRecv \\<Rightarrow> without_preemption $ handle_recv True\n        | SysYield \\<Rightarrow> without_preemption handle_yield\n        | SysReply \\<Rightarrow> without_preemption handle_reply\n        | SysReplyRecv \\<Rightarrow> without_preemption $ do\n            handle_reply;\n            handle_recv True\n          od\n        | SysNBRecv \\<Rightarrow> without_preemption $ handle_recv False)\"\n\n| \"handle_event (UnknownSyscall n) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_fault thread $ UnknownSyscallException $ of_nat n;\n    return ()\n  od)\"\n\n| \"handle_event (UserLevelFault w1 w2) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_fault thread $ UserException (w1 && mask 32) (w2 && mask 28);\n    return ()\n  od)\"\n\n| \"handle_event Interrupt = (without_preemption $ do\n    active \\<leftarrow> do_machine_op $ getActiveIRQ False;\n    case active of\n       Some irq \\<Rightarrow> handle_interrupt irq\n     | None \\<Rightarrow> return ()\n  od)\"\n\n| \"handle_event (VMFaultEvent fault_type) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_vm_fault thread fault_type <catch> handle_fault thread;\n    return ()\n  od)\"\n\n| \"handle_event (HypervisorEvent hypfault_type) = (without_preemption $ do\n    thread \\<leftarrow> gets cur_thread;\n    handle_hypervisor_fault thread hypfault_type\n  od)\""}
{"title": "./spec/abstract/Syscall_A.thy", "section": "Kernel entry point", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  This function is the main kernel entry point. The main event loop of the\n  kernel handles events, handles a potential preemption interrupt, schedules\n  and switches back to the active thread.\n\\<close>\n\ndefinition\n  call_kernel :: \"event \\<Rightarrow> (unit,'z::state_ext_sched) s_monad\" where\n  \"call_kernel ev \\<equiv> do\n       handle_event ev <handle>\n           (\\<lambda>_. without_preemption $ do\n                  irq \\<leftarrow> do_machine_op $ getActiveIRQ True;\n                  when (irq \\<noteq> None) $ handle_interrupt (the irq)\n                od);\n       schedule;\n       activate_thread\n   od\"\n\nend"}
{"title": "./spec/abstract/Intro_Doc.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDocumentation file, introduction to the abstract specification.\n*)\n\nchapter \"Introduction\"\n\n(*<*)\ntheory Intro_Doc\nimports Main\nbegin\n(*>*)\ntext \\<open>\n\nThe seL4 microkernel is an operating system kernel designed to be a\nsecure, safe, and reliable foundation for systems in a wide variety of\napplication domains. As a microkernel, seL4 provides a minimal number of\nservices to applications. This small number of services directly\ntranslates to a small implementation of approximately $8700$ lines of C code,\nwhich has allowed the kernel to be formally proven in the Isabelle/HOL\ntheorem prover to adhere to a formal specification.\n\nThis document gives the text version of the formal Isabelle/HOL\nspecification used in this proof. The document starts by giving a brief\noverview of the seL4 microkernel design, followed by text generated from\nthe Isabelle/HOL definitions.\n\nThis document is not a user manual to seL4, nor is it intended to\nbe read as such. Instead, it is a precise reference to the\nbehaviour of the seL4 kernel.\n\nFurther information on the models and verification techniques\ncan be found in previous publications~\\cite{Boyton_09,Cock_08,Cock_KS_08,Derrin_EKCC_06,Elkaduwe_GE_07,Elkaduwe_GE_08,Elphinstone_KDRH_07,Heiser_EKKP_07,Klein_09,Klein_DE_09,Klein_EHACDEEKNSTW_09,Klein_EHACDEEKNSTW_10,Tuch_08,Tuch_09,Tuch_KH_05,Tuch_KN_07,Tuch_Klein_05,Tuch:phd,Winwood_KSACN_09}.\n\n\n\\section{The seL4 Microkernel}\n\nThe seL4 microkernel is a small operating system kernel of the L4\nfamily. SeL4 provides a minimal number of services to applications, such\nas abstractions for virtual address spaces, threads, inter-process\ncommunication (IPC).\n\nSeL4 uses a capability-based access-control model. All memory, devices,\nand microkernel-provided services require an associated\n\\emph{capability} (access right) to utilise them\n\\cite{Dennis_VanHorn_66}. The set of capabilities an application\npossesses determines what resources that application can directly\naccess. SeL4 enforces this access control by using the hardware's memory\nmanagement unit (MMU) to ensure that userspace applications only have\naccess to memory they possess capabilities to.\n\n\\autoref{fig:sample} shows a representative seL4-based system. It\ndepicts the microkernel executing on top of the hardware as the only\nsoftware running in privileged mode of the processor. The first\napplication to execute is the supervisor OS. The supervisor OS (also\ntermed a \\emph{booter} for simple scenarios) is responsible for\ninitialising, configuring and delegating authority to the specific\nsystem layered on top.\n\n\\begin{figure}[tb]\n  \\centering\n  \\includegraphics[width=6cm]{imgs/seL4-background_01}\n  \\caption{Sample seL4 based system}\n  \\label{fig:sample}\n\\end{figure}\n\nIn \\autoref{fig:sample}, the example system set up by the supervisor consists\nof an instance of Linux on the left, and several instances of trusted or\nsensitive applications on the right. The group of applications on the left and\nthe group on the right are unable to directly communicate or interfere with\neach other without explicit involvement of the supervisor (and the\nmicrokernel) --- a barrier is thus created between the untrusted left and the\ntrusted right, as indicated in the figure. The supervisor has a\nkernel-provided mechanism to determine the relationship between applications\nand the presence or absence of any such barriers.\n\n\\subsection{Kernel Services}\n\\label{s:kernel_services}\n\nA limited number of service primitives are provided by the\nmicrokernel; more complex services may be implemented as applications\non top of these primitives. In this way, the functionality of the\nsystem can be extended without increasing the code and complexity in\nprivileged mode, while still supporting a potentially wide number of\nservices for varied application domains.\n\nThe basic services the microkernel provides are as follows:\n\\begin{description}\n\\item[Threads] are an abstraction of CPU execution that support running\n  software;\n\\item[Address Spaces] are virtual memory spaces that each contain an\n  application. Applications are limited to accessing memory in their\n  address space;\n\\item[Interprocess Communication] (IPC) via \\emph{endpoints} allows\nthreads to communicate using message passing;\n\\item[Device Primitives] allow device drivers to be implemented as unprivileged\n  applications.  The kernel exports hardware device interrupts\n  via IPC messages; and\n\\item[Capability Spaces] store capabilities (i.e., access rights) to kernel services along\nwith their book-keeping information.\n\\end{description}\n\nAll kernel services are accessed using kernel-provided system calls\nthat \\emph{invoke} a capability;\nthe semantics of the system call depends upon the type of the\ncapability invoked.  For example, invoking the \\meth{Call} system call on a\nthread control block (TCB) with certain arguments will suspend the\ntarget thread, while invoking \\meth{Call} on an endpoint will result\nin a message being sent.  In general, the message sent to a capability\nwill have an entry indicating the desired operation, along with any\narguments.\n\nThe kernel provides to clients the following system calls:\n\\begin{description}\n\\item[\\meth{Send}] delivers the system call arguments to the target object\nand allows the application to continue. If the\ntarget object is unable to receive and/or process the arguments\nimmediately, the sending application will be blocked until the arguments\ncan be delivered.\n\n\\item[\\meth{NBSend}] performs non-blocking send in a similar fashion\nto \\meth{Send} except that if the object is unable to receive the\narguments immediately, the message is silently dropped.\n\n\\item[\\meth{Call}] is a \\meth{Send} that blocks the application until the\nobject provides a response, or the receiving application replies. In\nthe case of delivery to an application (via an \\obj{Endpoint}), an\nadditional capability is added to the arguments and delivered to the\nreceiver to give it the right to respond to the sender.\n\n\\item[\\meth{Recv}] is used by an application to block until the target\nobject is ready.\n\n\\item[\\meth{Reply}] is used to respond to a \\meth{Call}, using the\ncapability generated by the \\meth{Call} operation.\n\n\\item[\\meth{ReplyRecv}] is a combination of \\meth{Reply} and\n\\meth{Recv}. It exists for efficiency reasons: the common case of\nreplying to a request and waiting for the next can be performed in a\nsingle kernel system call instead of two.\n\\end{description}\n\n\\subsection{Capability-based Access Control}\n\\label{s:sel4_cap_access_control}\n\n\nThe seL4 microkernel provides a capability-based access control model.\nAccess control governs all kernel services; in order to perform any\nsystem call, an application must invoke a capability in its possession\nthat has sufficient access rights for the requested service.  With\nthis, the system can be configured to isolate software components from\neach other, and also to enable authorised controlled communication\nbetween components by selectively granting specific communication\ncapabilities.  This enables software component isolation with a high\ndegree of assurance, as only those operations explicitly authorised by\ncapability possession are permitted.\n\nA capability is an unforgeable token that references a specific kernel\nobject (such as a thread control block) and carries access\nrights that control what operations may be performed when it is invoked.\nConceptually, a capability resides in an application's\n\\emph{capability space}; an address in this space refers to a\n\\emph{slot} which may or may not contain a capability.  An application\nmay refer to a capability --- to request a kernel service, for example\n--- using the address of the slot holding that capability.  The seL4\ncapability model is an instance of a \\emph{segregated} (or\n\\emph{partitioned}) capability\nmodel, where capabilities are managed by the kernel.\n\nCapability spaces are implemented as a directed graph of kernel-managed\n\\emph{capability nodes} (\\obj{CNode}s).  A \\obj{CNode} is a table of\nslots, where each slot may contain further \\obj{CNode} capabilities.\nAn address in a capability space is then the concatenation of the\nindices of the \\obj{CNode} capabilities forming the path to the\ndestination slot; we discuss \\obj{CNode} objects further in\n\\autoref{s:cnode_obj}.\n\nCapabilities can be copied and moved within capability spaces, and\nalso sent via IPC. This allows creation of applications with specific\naccess rights, the delegation of authority to another application, and\npassing to an application authority to a newly created (or selected)\nkernel service. Furthermore, capabilities can be \\emph{minted} to\ncreate a derived capability with a subset of the rights of the\noriginal capability (never with more rights). A newly minted\ncapability can be used for partial delegation of authority.\n\nCapabilities can also be revoked in their entirety to withdraw\nauthority. Revocation includes any capabilities that may have\nbeen derived from the original capabilities. The propagation of\ncapabilities through the system is controlled by a\n\\emph{take-grant}-based model~\\cite{Elkaduwe_GE_07}.\n\n\\subsection{Kernel Objects}\n\\label{s:sel4_internals}\n\nIn this section we give a brief overview of the kernel implemented\nobjects that can be invoked by applications. The interface to these\nobjects forms the interface to the kernel itself. The creation and use\nof the high-level kernel services is achieved by the creation,\nmanipulation, and combination of these kernel objects.\n\n\\subsubsection{\\obj{CNodes}}\n\\label{s:cnode_obj}\n\nAs mentioned in the previous section, capabilities in seL4 are stored\nin kernel objects called \\obj{CNodes}. A \\obj{CNode} has a fixed\nnumber of slots, always a power of two, determined when the\n\\obj{CNode} is created. Slots can be empty or contain a capability.\n\n\\begin{figure}[htb]\n  \\centering\n  \\includegraphics[height=5cm]{imgs/sel4objects_01.pdf}\n  \\caption{\\obj{CNodes} forming a \\obj{CSpace}}\n  \\label{fig:cnode}\n\\end{figure}\n\n\n\\obj{CNodes} have the following operations:\n\\begin{description}\n\\item[\\meth{Mint}] creates a new capability in a specified \\obj{CNode} slot\nfrom an existing capability.  The newly created capability may have fewer rights than the original.\n\\item[\\meth{Copy}] is similar to \\meth{Mint}, but the newly created capability\n  has the same rights as the original.\n\\item[\\meth{Move}] moves a capability between two specified capability slots.\n\\item[\\meth{Mutate}] is an atomic combination of \\meth{Move} and\n  \\meth{Mint}. It is a performance optimisation.\n\\item[\\meth{Rotate}] moves two capabilities between three specified\n  capability slots. It is essentially two \\meth{Move} operations: one\n  from the second specified slot to the first, and one from the third\n  to the second. The first and third specified slots may be the same,\n  in which case the capability in it is swapped with the capability in\n  the second slot. The operation is atomic; either both or neither capabilities\n  are moved.\n\\item[\\meth{Delete}] removes a capability from the specified slot.\n\\item[\\meth{Revoke}] is equivalent to calling \\meth{Delete} on each\n  derived child of the specified capability. It has no effect on the\n  capability itself.\n\\item[\\meth{SaveCaller}] moves a kernel-generated reply capability of the\n  current thread from the special \\obj{TCB} slot it was created in, into\n  the designated \\obj{CSpace} slot.\n\\item[\\meth{Recycle}] is equivalent to \\meth{Revoke}, except that it\n  also resets most aspects of the object to its initial state.\n\\end{description}\n\n\\subsubsection{IPC Endpoints and Notifications}\n\nThe seL4 microkernel supports \\emph{synchronous} IPC (\\obj{EP}) endpoints,\nused to facilitate\ninterprocess communication between threads. Capabilities to endpoints\ncan be restricted to be send-only or receive-only. They can also\nspecify whether capabilities can be passed through the endpoint.\n\nEndpoints allow both data and capabilities to be\ntransferred between threads, depending on the rights on the endpoint\ncapability.  Sending a message will block the sender until the message\nhas been received; similarly, a waiting thread will be blocked until a\nmessage is available (but see \\meth{NBSend} above).\n\nWhen only notification of an event is required, notification objects can\nbe used. These have the following invocations:\n%\n\\begin{description}\n\\item[\\meth{Notify}] simply sets the given set of semaphore bits in the\nnotification object.\nMultiple \\meth{Notify} system calls without an intervening \\meth{Recv}\nresult in the bits being ``or-ed'' with any bits already set. As such,\n\\meth{Notify} is always non-blocking, and has no indication of whether\na receiver has received the notification.\n\\end{description}\n%\nAdditionally, the \\meth{Recv} system call may be used with an\nnotification object, allowing the calling thread to retrieve all set\nbits from the notification object. By default, if no \\meth{Notify}\noperations have taken place since the last \\meth{Recv} call, the\ncalling thread will block until the next \\meth{Notify} takes place.\nThere is also a non-blocking (polling) variant of this invocaction.\n\n\\subsubsection{\\obj{TCB}}\n\nThe \\emph{thread control block} (\\obj{TCB}) object represents a thread\nof execution in seL4. Threads are the unit of execution that is\nscheduled, blocked, unblocked, etc., depending on the applications\ninteraction with other threads.\n\nAs illustrated in\n\\autoref{fig:sel4_internals}, a thread needs both a \\obj{CSpace} and a\n\\obj{VSpace} in which to execute to form an application (plus some\nadditional information not represented here). The \\obj{CSpace}\nprovides the capabilities (authority) required to manipulated kernel\nobjects, in order to send messages to another application for example. The\n\\obj{VSpace} provides the virtual memory environment required to\ncontain the code and data of the application. A \\obj{CSpace} is\nassociated with a thread by installing a capability to the root\n\\obj{CNode} of a \\obj{CSpace} into the \\obj{TCB}. Likewise, a\n\\obj{VSpace} is associated with a thread by installing a capability to\na \\obj{Page Directory} (described shortly) into the \\obj{TCB}. Note that multiple threads\ncan share the same \\obj{CSpace} and \\obj{VSpace}.\n\n\\begin{figure}[htb]\n  \\centering\n  \\includegraphics[width=0.8\\textwidth]{imgs/sel4_internals_01}\n  \\caption{Internal representation of an application in seL4}\n  \\label{fig:sel4_internals}\n\\end{figure}\n\nThe TCB object has the following methods:\n\n\\begin{description}\n\\item[\\meth{CopyRegisters}] is used for copying the state of a\n  thread. The method is given an additional capability argument, which\n  must refer to a \\obj{TCB} that will be used as the source of the\n  transfer; the invoked thread is the destination. The caller may\n  select which of several subsets of the register context will be\n  transferred between the threads. The operation may also suspend the\n  source thread, and resume the destination thread.\n\n  Two subsets of the context that might be copied (if indicated by the\n  caller) include: firstly, the parts of the register state that are used or preserved\n  by system calls, including the instruction and stack pointers, and\n  the argument and message registers; and secondly, the\n  remaining integer registers. Other subsets are architecture-defined,\n  and typically include coprocessor registers such as the floating\n  point registers.  Note that many integer registers are modified or\n  destroyed by system calls, so it is not generally useful to use\n  \\meth{CopyRegisters} to copy integer registers to or from the\n  current thread.\n\\item[\\meth{ReadRegisters}] is a variant of \\meth{CopyRegisters} for\n  which the destination is the calling thread. It uses the message\n  registers to transfer the two subsets of the integer registers; the\n  message format has the more commonly transferred instruction\n  pointer, stack pointer and argument registers at the start, and will\n  be truncated at the caller's request if the other registers are not\n  required.\n\\item[\\meth{WriteRegisters}] is a variant of \\meth{CopyRegisters} for\n  which the source is the calling thread. It uses the message\n  registers to transfer the integer registers, in the same order used\n  by \\meth{ReadRegisters}. It may be truncated if the later registers\n  are not required; an explicit length argument is given to allow\n  error detection when the message is inadvertently truncated by a\n  missing IPC buffer.\n\\item[\\meth{SetPriority}] configures the thread's scheduling\n  parameters. In the current version of seL4, this is simply a\n  priority for the round-robin scheduler.\n\\item[\\meth{SetIPCBuffer}] configures the thread's local storage,\n  particularly the IPC buffer used for sending parts of the message\n  payload that don't fit in hardware registers.\n\\item[\\meth{SetSpace}] configures the thread's virtual memory and\n  capability address spaces. It sets the roots of the trees (or other\n  architecture-specific page table structures) that represent the two\n  address spaces, and also nominates the \\obj{Endpoint} that the kernel uses\n  to notify the thread's pager\\footnote{A \\emph{pager} is a term for a\n    thread that manages the \\obj{VSpace} of another application. For\n    example, Linux would be called the pager of its applications.} of\n  faults and exceptions.\n\\item[\\meth{Configure}] is a batched version of the three\n  configuration system calls: \\meth{SetPriority}, \\meth{SetIPCBuffer},\n  and \\meth{SetSpace}. \\meth{Configure} is simply a performance\n  optimisation.\n\\item[\\meth{Suspend}] makes a thread inactive. The thread will not\n  be scheduled again until a \\meth{Resume} operation is performed on\n  it.  A \\meth{CopyRegisters} or \\meth{ReadRegisters} operation may\n  optionally include a \\meth{Suspend} operation on the source thread.\n\\item[\\meth{Resume}] resumes execution of a thread that is\n  inactive or waiting for a kernel operation to complete. If the\n  invoked thread is waiting for a kernel operation, \\meth{Resume} will\n  modify the thread's state so that it will attempt to perform the\n  faulting or aborted operation again. \\meth{Resume}-ing a thread that\n  is already ready has no effect. \\meth{Resume}-ing a thread that is\n  in the waiting phase of a \\meth{Call} operation may cause the\n  sending phase to be performed again, even if it has previously\n  succeeded.\n\n  A \\meth{CopyRegisters} or \\meth{WriteRegisters} operation may\n  optionally include a \\meth{Resume} operation on the destination\n  thread.\n\\end{description}\n\n\\subsubsection{Virtual Memory}\n\nA virtual address space in seL4 is called a \\obj{VSpace}. In a similar\nway to \\obj{CSpaces}, a \\obj{VSpace} is composed of objects provided\nby the microkernel. Unlike \\obj{CSpaces}, these objects for managing\nvirtual memory largely directly correspond to those of the hardware,\nthat is, a page directory pointing to page tables, which in turn map\nphysical frames.  The kernel also includes \\obj{ASID Pool} and\n\\obj{ASID Control} objects for tracking the status of address spaces.\n\n\\autoref{fig:vspace} illustrates a \\obj{VSpace} with the requisite\ncomponents required to implement a virtual address space.\n\n\\begin{figure}[htb]\n  \\centering\n   \\includegraphics[height=5cm]{imgs/sel4objects_05.pdf}\n  \\caption{Virtual Memory in seL4.}\n  \\label{fig:vspace}\n\\end{figure}\n\nThese \\obj{VSpace}-related objects are sufficient to implement the\nhardware data structures required to create, manipulate, and destroy\nvirtual memory address spaces. It should be noted that, as usual, the\nmanipulator of a virtual memory space needs the appropriate\ncapabilities to the required objects.\n\n\\paragraph{\\obj{Page Directory}}\n\nThe \\obj{Page Directory} (PD) is the top-level page table of the ARM\ntwo-level page table structure. It has a hardware defined format, but\nconceptually contains 1024 page directory entries (PDE), which are one\nof a pointer to a page table, a 4 megabyte \\obj{Page}, or an invalid\nentry . The \\obj{Page Directory} has no methods itself, but it is used\nas an argument to several other virtual memory related object calls.\n\n\\paragraph{\\obj{Page Table}} The \\obj{Page Table} object forms the\nsecond level of the ARM page table. It contains 1024 slots, each of which\ncontains a page table entry (PTE). A page table entry contains either an\ninvalid entry, or a pointer to a 4 kilobyte \\obj{Page}.\n\n\\obj{Page Table} objects possess only a single method:\n\\begin{description}\n\\item[\\meth{Map}] takes a \\obj{Page Directory}\n  capability as an argument, and installs a reference to the invoked\n  \\obj{Page Table} to a specified slot in the \\obj{Page\n    Directory}.\n\\end{description}\n\n\\paragraph{\\obj{Page}}\n\nA \\obj{Page} object is a region of physical memory that is used to\nimplement virtual memory pages in a virtual address space. The\n\\obj{Page} object has the following methods:\n\\begin{description}\n\\item[\\meth{Map}] takes a\n  \\obj{Page Directory} or a \\obj{Page Table} capability as an argument\n  and installs a PDE or PTE referring to the \\obj{Page} in the\n  specified location, respectively. In addition, \\meth{Map} has a\n  remapping mode which is used to change the access permissions on an\n  existing mapping.\n\\item[\\meth{Unmap}] removes an existing mapping.\n\\end{description}\n\n\\paragraph{\\obj{ASID Control}}\n\nFor internal kernel book-keeping purposes, there is a fixed maximum\nnumber of applications the system can support.  In order to manage\nthis limited resource, the microkernel provides an \\obj{ASID Control}\ncapability. The \\obj{ASID Control} capability is used to generate a\ncapability that authorises the use of a subset of available address\nspace identifiers. This newly created capability is called an\n\\obj{ASID Pool}. \\obj{ASID Control} only has a single method:\n\\begin{description}\n\\item[\\meth{MakePool}] together with a capability to\n\\obj{Untyped Memory} (described shortly) as argument creates an \\obj{ASID Pool}.\n\\end{description}\n\n\\paragraph{\\obj{ASID Pool}}\n\nAn \\obj{ASID Pool} confers the right to create a subset of the available\nmaximum applications. For a \\obj{VSpace} to be usable by an application, it\nmust be assigned to an ASID. This is done using a capability to an\n\\obj{ASID Pool}. The \\obj{ASID Pool} object has a single method:\n\\begin{description}\n\\item[\\meth{Assign}] assigns an ASID to the \\obj{VSpace}\n  associated with the \\obj{Page Directory} passed in as an argument.\n\\end{description}\n\n\\subsubsection{Interrupt Objects}\n\nDevice driver applications need the ability to receive and acknowledge\ninterrupts from hardware devices.\n\nA capability to \\obj{IRQControl} has the ability to create a new\ncapability to manage a specific interrupt source associated with a\nspecific device. The new capability is then delegated to a device\ndriver to access an interrupt source. \\obj{IRQControl} has one method:\n\\begin{description}\n\\item[\\meth{Get}] creates an \\obj{IRQHandler} capability for the\n  specified interrupt source.\n\\end{description}\n\nAn \\obj{IRQHandler} object is used by driver application to handle\ninterrupts for the device it manages. It has three methods:\n\\begin{description}\n\\item[\\meth{SetEndpoint}] specifies the \\obj{NTFN} that a\n  \\meth{Notify} should be sent to when an interrupt occurs. The driver\n  application usually \\meth{Recv}-s on this endpoint for interrupts to\n  process.\n\\item[\\meth{Ack}] informs the kernel that the userspace driver has finished\n  processing the interrupt and the microkernel can send further pending\n  or new interrupts to the application.\n\\item[\\meth{Clear}] de-registers the \\obj{NTFN} from the\n  \\obj{IRQHandler} object.\n\\end{description}\n\n\\subsubsection{\\obj{Untyped Memory}}\n\nThe \\obj{Untyped Memory} object is the foundation of memory allocation\nin the seL4 kernel.  Untyped memory capabilities have a single method:\n\\begin{description}\n \\item[\\meth{Retype}] creates a number of new kernel objects.  If this\nmethod succeeds, it returns capabilities to the newly-created objects.\n\\end{description}\n\nIn particular, untyped memory objects can be divided into a group of\nsmaller untyped memory objects.  We discuss memory management in\ngeneral in the following section.\n\n\\subsection{Kernel Memory Allocation}\n\\label{sec:kernmemalloc}\n\nThe seL4 microkernel has no internal memory allocator: all kernel\nobjects must be explicitly created from application controlled memory\nregions via \\obj{Untyped Memory} capabilities.  Applications must have\nexplicit authority to memory (via \\obj{Untyped Memory} capabilities)\nin order to create other services, and services consume no extra\nmemory once created (other than the amount of untyped memory from\nwhich they were originally created). The mechanisms can be used to\nprecisely control the specific amount of physical memory available to\napplications, including being able to enforce isolation of physical\nmemory access between applications or a device.  Thus, there are no\narbitrary resource limits in the kernel apart from those dictated by\nthe hardware\\footnote{The treatment of virtual ASIDs imposes a fixed\nnumber of address spaces, but this limitation is to be removed in\nfuture versions of seL4.}, and so many denial-of-service attacks via\nresource exhaustion are obviated.\n\nAt boot time, seL4 pre-allocates all the memory required for the\nkernel itself, including the code, data, and stack sections (seL4 is a\nsingle kernel-stack operating system). The remainder of the memory is\ngiven to the first task in the form of capabilities to \\obj{Untyped\nMemory}, and some additional capabilities to kernel objects that were\nrequired to bootstrap the supervisor task.  These objects can then be\nsplit into smaller untyped memory regions or other kernel objects\nusing the \\meth{Retype} method; the created objects are termed\n\\emph{children} of the original untyped memory object.\n\nSee \\autoref{fig:alloc2} for an\nexample.\n\n\\begin{figure}[htb]\n  \\centering\n   \\includegraphics[width=7cm]{imgs/seL4-background_03}\n  \\caption{Memory layout at boot time}\n  \\label{fig:alloc2}\n\\end{figure}\n\n\\begin{figure}[htb]\n  \\centering\n  \\includegraphics[width=7cm]{imgs/seL4-background_04}\n  \\caption{Memory layout after supervisor creates kernel services.}\n  \\label{fig:alloc-sup}\n\\end{figure}\n\nThe user-level application that creates an object using \\meth{Retype}\nreceives full authority over the resulting object. It can then\ndelegate all or part of the authority it possesses over this object to\none or more of its clients.  This is done by selectively granting each\nclient a capability to the kernel object, thereby allowing the client\nto obtain kernel services by invoking the object.\n\nFor obvious security reasons, kernel data must be protected from user\naccess.  The seL4 kernel prevents such access by using two mechanisms.\nFirst, the above allocation policy guarantees that typed objects never\noverlap.  Second, the kernel ensures that each physical frame mapped\nby the MMU at a user-accessible address corresponds to a\n\\obj{Page} object (described above); \\obj{Page} objects contain no kernel\ndata, so direct\nuser access to kernel data is not possible. All other kernel objects\nare only indirectly manipulated via their corresponding capabilities.\n\n\\subsubsection{Re-using Memory}\n\\label{s:memRevoke}\n\nThe model described thus far is sufficient for applications to\nallocate kernel objects, distribute authority among client\napplications, and obtain various kernel services provided by these\nobjects.  This alone is sufficient for a simple static system\nconfiguration.\n\nThe seL4 kernel also allows memory re-use.  Reusing a region of memory\nis sound only when there are no dangling references (e.g.\\\ncapabilities) left to the objects implemented by that memory.  The\nkernel tracks \\emph{capability derivations}, that is, the children\ngenerated by various \\obj{CNode} methods (\\meth{Retype}, \\meth{Mint},\n\\meth{Copy}, and \\meth{Mutate}).  Whenever a user requests that the\nkernel create new objects in an untyped memory region, the kernel uses\nthis information to check that there are no children in the region,\nand thus no live capability references.\n\nThe tree structure so generated is termed the \\emph{capability\nderivation tree} (CDT)\\footnote{Although we model the CDT as a\nseparate data structure, it is implemented as part of the CNode object\nand so requires no additional kernel meta-data.}.  For example, when a\nuser creates new kernel objects by retyping untyped memory, the newly\ncreated capabilities would be inserted into the CDT as children of the\nuntyped memory capability.\n\nFinally, recall that the \\meth{Revoke} operation destroys all\ncapabilities derived from the argument capability.  Revoking the last\ncapability to a kernel object is easily detectable, and triggers the\n\\emph{destroy} operation on the now unreferenced object. Destroy\nsimply deactivates the object if it was active, and cleans up any\nin-kernel dependencies between it and other objects.\n\nBy calling \\meth{Revoke} on the original\ncapability to an untyped memory object, the user removes all of the\nuntyped memory object's children --- that is, all capabilities pointing to\nobjects in the untyped memory region.\nThus, after this operation there are no valid references\nto any object within the untyped region, and the region may be\nsafely retyped and reused.\n\n\\section{Summary}\n\\label{s:backsum}\n\nThis chapter has given an overview of the seL4 microkernel. The\nfollowing chapters are generated from the formal Isabelle/HOL\ndefinitions that comprise the formal specification of the seL4 kernel\non the ARM11 architecture. The specification does not cover any other\narchitectures or platforms.\n\nThe order of definitions in this document is as processed by\nIsabelle/HOL: bottom up. All concepts are defined before first used.\nThis means the first chapters mainly introduce basic data types and\nstructures while the top-level kernel entry point is defined in the\nlast chapter (\\autoref{c:syscall}). The following section shows\nthe dependency graph between the theory modules in this specification.\nWe assume a familiarity with Isabelle syntax; see Nipkow et\nal.~\\cite{LNCS2283} for an introduction. In addition to the standard\nIsabelle/HOL notation, we sometimes write @{text \"f $ x\"} for\n@{text \"(f x)\"} and use monadic do-notation extensively. The latter\nis defined in \\autoref{c:monads}.\n\n\\section{Theory Dependencies}\n\n\\centerline{\\includegraphics[height=0.8\\textheight]{session_graph}}\n\n\\<close>\n(*<*)\nend\n(*>*)"}
{"title": "./spec/abstract/InvocationLabels_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\n Generic functions for invocation labels\n*)\n\nchapter \"Kernel Object Invocations\"\n\ntheory InvocationLabels_A\nimports\n  MiscMachine_A\n  \"ExecSpec.ArchLabelFuns_H\"\nbegin\n\ndefinition\n  invocation_type :: \"data \\<Rightarrow> invocation_label\"\nwhere\n \"invocation_type x \\<equiv> if \\<exists>(v :: invocation_label). fromEnum v = data_to_nat x\n                      then toEnum (data_to_nat x) else GenInvocationLabel InvalidInvocation\"\n\ndefinition\n  gen_invocation_type :: \"data \\<Rightarrow> gen_invocation_labels\"\nwhere\n \"gen_invocation_type x \\<equiv>\n   case invocation_type x of\n     GenInvocationLabel l \\<Rightarrow> l\n   | ArchInvocationLabel _ \\<Rightarrow> InvalidInvocation\"\n\nend"}
{"title": "./spec/abstract/Schedule_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nNon-deterministic scheduler functionality.\n*)\n\nchapter \"Scheduler\"\n\ntheory Schedule_A\nimports Arch_A\nbegin\n\narch_requalify_consts (A)\n  arch_switch_to_thread\n  arch_switch_to_idle_thread\n\nabbreviation\n  \"idle st \\<equiv> st = Structures_A.IdleThreadState\"\n\ntext \\<open>Gets the TCB at an address if the thread can be scheduled.\\<close>\ndefinition\n  getActiveTCB :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> tcb option\"\nwhere\n  \"getActiveTCB tcb_ref state \\<equiv>\n   case (get_tcb tcb_ref state)\n     of None           \\<Rightarrow> None\n      | Some tcb       \\<Rightarrow> if (runnable $ tcb_state tcb)\n                         then Some tcb else None\"\n\ntext \\<open>Gets all schedulable threads in the system.\\<close>\ndefinition\n  allActiveTCBs :: \"(obj_ref set,'z::state_ext) s_monad\" where\n  \"allActiveTCBs \\<equiv> do\n    state \\<leftarrow> get;\n    return {x. getActiveTCB x state \\<noteq> None}\n   od\"\n\ntext \\<open>Switches the current thread to the specified one.\\<close>\ndefinition\n  switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"switch_to_thread t \\<equiv> do\n     state \\<leftarrow> get;\n     assert (get_tcb t state \\<noteq> None);\n     arch_switch_to_thread t;\n     do_extended_op (tcb_sched_action (tcb_sched_dequeue) t);\n     modify (\\<lambda>s. s \\<lparr> cur_thread := t \\<rparr>)\n   od\"\n\ntext \\<open>Asserts that a thread is runnable before switching to it.\\<close>\ndefinition guarded_switch_to :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"guarded_switch_to thread \\<equiv> do ts \\<leftarrow> get_thread_state thread;\n                    assert (runnable ts);\n                    switch_to_thread thread\n                 od\"\n\ntext \\<open>Switches to the idle thread.\\<close>\ndefinition\n  switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n  \"switch_to_idle_thread \\<equiv> do\n     thread \\<leftarrow> gets idle_thread;\n     arch_switch_to_idle_thread;\n     modify (\\<lambda>s. s \\<lparr> cur_thread := thread \\<rparr>)\n   od\"\n\nclass state_ext_sched = state_ext +\n  fixes schedule :: \"(unit,'a) s_monad\"\n\ndefinition choose_thread :: \"det_ext state \\<Rightarrow> (unit \\<times> det_ext state) set \\<times> bool\" where\n\"choose_thread \\<equiv>\n      do\n        d \\<leftarrow> gets cur_domain;\n        queues \\<leftarrow> gets (\\<lambda>s. ready_queues s d);\n        if (\\<forall>prio. queues prio = []) then (switch_to_idle_thread)\n        else (guarded_switch_to (hd (max_non_empty_queue queues)))\n      od\"\n\ntext \\<open>\n  Determine whether given priority is highest among queued ready threads in given domain.\n  Trivially true if no threads are ready.\\<close>\ndefinition\n  is_highest_prio :: \"domain \\<Rightarrow> priority \\<Rightarrow> det_ext state \\<Rightarrow> bool\"\nwhere\n  \"is_highest_prio d p s \\<equiv>\n    (\\<forall>prio. ready_queues s d prio = [])\n    \\<or> p \\<ge> Max {prio. ready_queues s d prio \\<noteq> []}\"\n\ninstantiation  det_ext_ext :: (type) state_ext_sched\nbegin\n\ndefinition\n  \"schedule_switch_thread_fastfail ct it ct_prio target_prio \\<equiv>\n     if ct \\<noteq> it\n     then return (target_prio < ct_prio)\n     else return True\"\n\ndefinition\n  \"schedule_choose_new_thread \\<equiv> do\n     dom_time \\<leftarrow> gets domain_time;\n     when (dom_time = 0) next_domain;\n     choose_thread;\n     set_scheduler_action resume_cur_thread\n   od\"\n\ndefinition\n  \"schedule_det_ext_ext \\<equiv> do\n     ct \\<leftarrow> gets cur_thread;\n     ct_st \\<leftarrow> get_thread_state ct;\n     ct_runnable \\<leftarrow> return $ runnable ct_st;\n     action \\<leftarrow> gets scheduler_action;\n     (case action\n       of resume_cur_thread \\<Rightarrow> do\n            id \\<leftarrow> gets idle_thread;\n            assert (ct_runnable \\<or> ct = id);\n            return ()\n         od\n       | choose_new_thread \\<Rightarrow> do\n           when ct_runnable (tcb_sched_action tcb_sched_enqueue ct);\n           schedule_choose_new_thread\n         od\n       | switch_thread candidate \\<Rightarrow> do\n           when ct_runnable (tcb_sched_action tcb_sched_enqueue ct);\n\n           it \\<leftarrow> gets idle_thread;\n           target_prio \\<leftarrow> ethread_get tcb_priority candidate;\n\n           \\<comment> \\<open>Infoflow does not like asking about the idle thread's priority or domain.\\<close>\n           ct_prio \\<leftarrow> ethread_get_when (ct \\<noteq> it) tcb_priority ct;\n           \\<comment> \\<open>When to look at the bitmaps. This optimisation is used in the C fast path,\n              but there we know @{text cur_thread} is not idle.\\<close>\n           fastfail \\<leftarrow> schedule_switch_thread_fastfail ct it ct_prio target_prio;\n\n           cur_dom \\<leftarrow> gets cur_domain;\n           highest \\<leftarrow> gets (is_highest_prio cur_dom target_prio);\n           if (fastfail \\<and> \\<not>highest)\n           then do\n               \\<comment> \\<open>Candidate is not best candidate, choose a new thread\\<close>\n               tcb_sched_action tcb_sched_enqueue candidate;\n               set_scheduler_action choose_new_thread;\n               schedule_choose_new_thread\n             od\n           else if (ct_runnable \\<and> ct_prio = target_prio)\n           then do\n               \\<comment> \\<open>Current thread was runnable and candidate is not strictly better\n                  want current thread to run next, so append the candidate to end of queue\n                  and choose again\\<close>\n               tcb_sched_action tcb_sched_append candidate;\n               set_scheduler_action choose_new_thread;\n               schedule_choose_new_thread\n             od\n           else do\n             guarded_switch_to candidate;\n             \\<comment> \\<open>Duplication assists in wp proof under different scheduler actions\\<close>\n             set_scheduler_action resume_cur_thread\n           od\n        od)\n    od\"\n\ninstance ..\nend\n\n\ninstantiation unit :: state_ext_sched\nbegin\n\n\ntext \\<open>\n  The scheduler is heavily underspecified.\n  It is allowed to pick any active thread or the idle thread.\n  If the thread the scheduler picked is the current thread, it\n  may omit the call to @{const switch_to_thread}. Likewise it\n  may omit the call to @{const switch_to_idle_thread} if the\n  idle thread is the current thread.\n\\<close>\ndefinition schedule_unit :: \"(unit,unit) s_monad\" where\n\"schedule_unit \\<equiv> (do\n   cur \\<leftarrow> gets cur_thread;\n   threads \\<leftarrow> allActiveTCBs;\n   thread \\<leftarrow> select threads;\n   (if thread = cur then\n     return () \\<sqinter> switch_to_thread thread\n   else\n     switch_to_thread thread)\n od) \\<sqinter>\n (do\n   cur \\<leftarrow> gets cur_thread;\n   idl \\<leftarrow> gets idle_thread;\n   if idl = cur then\n     return () \\<sqinter> switch_to_idle_thread\n   else switch_to_idle_thread\n  od)\"\n\ninstance ..\nend\n\n\nlemmas schedule_def = schedule_det_ext_ext_def schedule_unit_def\n\nend"}
{"title": "./spec/abstract/MiscMachine_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nUtilities for the machine level which are not machine-dependent.\n*)\n\nchapter \"Machine Accessor Functions\"\n\ntheory MiscMachine_A\nimports Machine_A \"ExecSpec.MachineExports\"\nbegin\n\narch_requalify_types\n  user_context\n  user_monad\n\narch_requalify_types (A)\n  data\n  obj_ref\n  asid_high_len\n  asid_high_index\n  asid_low_len\n  asid_low_index\n  asid_len\n  asid_rep_len\n  asid\n  cap_ref\n  length_type\n  vspace_ref\n\narch_requalify_consts (A)\n  nat_to_cref\n  msg_info_register\n  msg_registers\n  cap_register\n  badge_register\n  frame_registers\n  gp_registers\n  exception_message\n  syscall_message\n  new_context\n  slot_bits\n  oref_to_data\n  data_to_oref\n  vref_to_data\n  data_to_vref\n  nat_to_len\n  data_to_nat\n  data_to_16\n  data_to_cptr\n  combine_ntfn_badges\n\n(* Needs to be done here after plain type names are exported *)\ntranslations\n  (type) \"'a user_monad\" <= (type) \"user_context \\<Rightarrow> ('a \\<times> user_context) set \\<times> bool\"\n\ndefinition\n  asid_high_bits :: nat\nwhere\n  \"asid_high_bits \\<equiv> LENGTH(asid_high_len)\"\n\ndefinition\n  asid_low_bits :: nat\nwhere\n  \"asid_low_bits \\<equiv> LENGTH(asid_low_len)\"\n\ndefinition\n  asid_bits :: nat\nwhere\n  \"asid_bits \\<equiv> LENGTH(asid_len)\"\n\nlemmas asid_bits_defs =\n  asid_bits_def asid_high_bits_def asid_low_bits_def\n\n(* Sanity checks. *)\nlemma asid_bits_len_checks:\n  \"asid_bits = asid_high_bits + asid_low_bits\"\n  \"asid_bits \\<le> LENGTH(asid_rep_len)\"\n  unfolding asid_bits_defs by auto\n\ndefinition ipa_size :: nat where\n  \"ipa_size \\<equiv> if config_ARM_PA_SIZE_BITS_40 then 40 else 44\"\n\nend"}
{"title": "./spec/abstract/Interrupt_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFormalisation of interrupt handling.\n*)\n\nchapter \"Interrupts\"\n\ntheory Interrupt_A\nimports ArchInterrupt_A\nbegin\n\narch_requalify_consts (A)\n  arch_invoke_irq_control\n  arch_invoke_irq_handler\n  handle_reserved_irq\n  arch_mask_irq_signal\n\ntext \\<open>The IRQControl capability can be used to create a new IRQHandler\ncapability as well as to perform whatever architecture specific interrupt\nactions are available.\\<close>\nfun\n  invoke_irq_control :: \"irq_control_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"invoke_irq_control (IRQControl irq handler_slot control_slot) =\n     liftE (do set_irq_state IRQSignal irq;\n               cap_insert (IRQHandlerCap irq) control_slot handler_slot od)\"\n| \"invoke_irq_control (ArchIRQControl invok) =\n     arch_invoke_irq_control invok\"\n\ntext \\<open>The IRQHandler capability may be used to configure how interrupts on an\nIRQ are delivered and to acknowledge a delivered interrupt. Interrupts are\ndelivered when Notification capabilities are installed in the relevant per-IRQ\nslot. The IRQHandler operations load or clear those capabilities.\\<close>\n\nfun\n  invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"invoke_irq_handler (ACKIrq irq) = arch_invoke_irq_handler (ACKIrq irq)\"\n| \"invoke_irq_handler (SetIRQHandler irq cap slot) = (do\n     irq_slot \\<leftarrow> get_irq_slot irq;\n     cap_delete_one irq_slot;\n     cap_insert cap slot irq_slot\n   od)\"\n| \"invoke_irq_handler (ClearIRQHandler irq) = (do\n     irq_slot \\<leftarrow> get_irq_slot irq;\n     cap_delete_one irq_slot\n   od)\"\n\ntext \\<open>Handle an interrupt occurence. Timing and scheduling details are not\nincluded in this model, so no scheduling action needs to be taken on timer\nticks. If the IRQ has a valid Notification cap loaded a message is\ndelivered.\\<close>\n\ndefinition timer_tick :: \"unit det_ext_monad\" where\n  \"timer_tick \\<equiv> do\n     cur \\<leftarrow> gets cur_thread;\n     state \\<leftarrow> get_thread_state cur;\n     case state of Running \\<Rightarrow> do\n       ts \\<leftarrow> ethread_get tcb_time_slice cur;\n       let ts' = ts - 1 in\n       if (ts' > 0) then thread_set_time_slice cur ts' else do\n         thread_set_time_slice cur timeSlice;\n         tcb_sched_action tcb_sched_append cur;\n         reschedule_required\n       od\n     od\n     | _ \\<Rightarrow> return ();\n     when (numDomains > 1) (do\n       dec_domain_time;\n       dom_time \\<leftarrow> gets domain_time;\n       when (dom_time = 0) reschedule_required\n     od)\n   od\"\n\ndefinition\n  handle_interrupt :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"handle_interrupt irq \\<equiv>\n   if irq > maxIRQ then do_machine_op $ do\n    maskInterrupt True irq;\n    ackInterrupt irq\n    od\n  else do\n   st \\<leftarrow> get_irq_state irq;\n   case st of\n     IRQSignal \\<Rightarrow> do\n       slot \\<leftarrow> get_irq_slot irq;\n       cap \\<leftarrow> get_cap slot;\n       when (is_ntfn_cap cap \\<and> AllowSend \\<in> cap_rights cap)\n         $ send_signal (obj_ref_of cap) (cap_ep_badge cap);\n       arch_mask_irq_signal irq\n     od\n   | IRQTimer \\<Rightarrow> do\n       do_extended_op timer_tick;\n       do_machine_op resetTimer\n     od\n   | IRQInactive \\<Rightarrow> fail \\<comment> \\<open>not meant to be able to get IRQs from inactive lines\\<close>\n   | IRQReserved \\<Rightarrow> handle_reserved_irq irq;\n   do_machine_op $ ackInterrupt irq\n   od\"\n\nend"}
{"title": "./spec/abstract/VMRights_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Virtual-Memory Rights\"\n\ntheory VMRights_A\nimports CapRights_A\nbegin\n\ntext \\<open>\nThis theory provides architecture-specific definitions and datatypes for virtual-memory support.\n\\<close>\n\ntext \\<open>Page access rights.\\<close>\n\ntype_synonym vm_rights = cap_rights\n\ndefinition vm_kernel_only :: vm_rights\nwhere\n  \"vm_kernel_only \\<equiv> {}\"\n\ndefinition vm_read_only :: vm_rights\nwhere\n  \"vm_read_only \\<equiv> {AllowRead}\"\n\ndefinition vm_read_write :: vm_rights\nwhere\n  \"vm_read_write \\<equiv> {AllowRead,AllowWrite}\"\n\ntext \\<open>\n  Note that only the above combinations of virtual-memory rights are permitted.\n  We introduce the following definitions to reflect this fact:\n  The predicate @{text valid_vm_rights} holds iff a given set of rights is valid\n  (i.e., a permitted combination).\n  The function @{text validate_vm_rights} takes an arbitrary set of rights and\n  returns the largest permitted subset.\n\\<close>\ndefinition valid_vm_rights :: \"vm_rights set\"\nwhere\n  \"valid_vm_rights \\<equiv> {vm_read_write, vm_read_only, vm_kernel_only}\"\n\ndefinition validate_vm_rights :: \"vm_rights \\<Rightarrow> vm_rights\"\nwhere\n  \"validate_vm_rights rs \\<equiv>\n     if AllowRead \\<in> rs\n     then if AllowWrite \\<in> rs then vm_read_write else vm_read_only\n     else vm_kernel_only\"\n\ntext \\<open>On the abstract level, capability and VM rights share the same type.\n  Nevertheless, a simple set intersection might lead to an invalid value like\n  @{term \"{AllowWrite}\"}.  Hence, @{const validate_vm_rights}.\\<close>\ndefinition mask_vm_rights :: \"vm_rights \\<Rightarrow> cap_rights \\<Rightarrow> vm_rights\"\nwhere\n  \"mask_vm_rights V R \\<equiv> validate_vm_rights (V \\<inter> R)\"\n\nend"}
{"title": "./spec/abstract/Glossary_Doc.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nGlossary. Documentation only.\n\n\n\nThis file is a running glossary of technical nouns used in\ndocumenting the abstract model.\n\nThe entries should be listed alphabetically.\nEach has three details:\n   1. a short name, e.g. cnode\n   2. a long name, e.g. capability node\n   3. a reference to the section where it is first discussed.\n\nThe long name (2) should only be used when the term is first\ndiscussed, i.e. at (3).\nIt should be followed by the short name (1) in parantheses and a\nlabel command of the form: \\label{glos:<shortname>}.\nThat label should be used to generate the reference (3).\n\ne.g. A \\emph{capability node} (cnode)\\label{glos:cnode} is a ...\n\nA fourth optional argument can give additional information of one\nor more of the following types:\n   - names that should not be used.\n   - a list of historical terms that mean the same thing.\n*)\n\nchapter \"Glossary\"\n\n(*<*)\n\ntheory Glossary_Doc\nimports \"Syscall_A\"\nbegin\n\n(*>*)\ntext \\<open>\n\\newcommand{\\glossaryentry}[4][\\null]\n    {\\begin{list}{\\null}{\\setlength{\\leftmargin}{0pt}\n                         \\setlength{\\rightmargin}{0pt}\n                         \\setlength{\\labelwidth}{0pt}\n                         \\setlength{\\itemindent}{0pt}\n                         \\setlength{\\topsep}{1.0em}}\n     \\item  \\parbox[t]{.18\\textwidth}{\\raggedright{\\bf #2}}%\n            \\hfill\\parbox[t]{.75\\textwidth}{\\raggedright{#3}}%\n            \\hfill\\parbox[t]{.05\\textwidth}{\\raggedright{%\\autoref{#4}\n}}%\n     \\ifx#1\\null\\relax\\else%\n        \\item\\nopagebreak\\hfill\n             \\begin{minipage}[t]{.775\\textwidth}{\\it #1}\\end{minipage}\n     \\fi\n     \\end{list}}\n\n\\glossaryentry\n  {ntfn, Notification}\n  {A \\emph{notification} object. A kernel object in seL4 consisting\n  of a set of binary semaphores, used for sending (signalling)\n  notifications to other threads.}\n  {glos:ntfn}\n\n\\glossaryentry\n  {asid, asid pool}\n  {Address Space Identifier. ASIDs are associated with page\n  directories (PDs) and define the virtual address space of a\n  thread. Multiple threads may be in the same address space.\n  Since ARM hardware supports only 255 different ASIDs, seL4 on ARM\n  supports the concept of virtual ASIDs that are mapped to hardware ASIDS\n  managed in a two-level structure. The user manages only the second\n  level of this structure: the asid pool. An asid pool can be seen as\n  a set of virtual ASIDs that can be connected to and disconnected from\n  page directories.}\n  {}\n\n\n\\glossaryentry\n  {badge}\n  {A badge is a piece of extra information stored in an endpoint\n  capability. It can be used by applications to identify caps\n  previously handed out to clients.}\n  {glos:badge}\n\n\\glossaryentry\n  {cap, capability}\n  {The main access control concept in seL4. A capability conceptually\n  is a reference to a kernel object together with a set of access\n  rights. Most seL4 capabilities store additional bits of\n  information. Some of this additional information may be\n  exposed to the user, but the bulk of it is kernel-internal\n  book-keeping information. Capabilities are stored in CNodes and\n  TCBs.}\n  {glos:cap}\n\n\\glossaryentry\n  {cdt}\n  {Capability Derivation Tree. A kernel-internal data structure that\n  tracks the child/parent relationship between capabilities. Capabilities\n  to new objects are children of the Untyped capability the object was\n  created from. Capabilities can also be copied; in this case the user may\n  specify if the operation should produce children or siblings of\n  the source capability. The revoke operation will delete all children\n  of the invoked capability.}\n  {}\n\n\\glossaryentry\n  {cnode}\n  {Capability Node. Kernel-controlled storage that holds capabilities.\n   Capability nodes can be created in different sizes and be shared\n   between CSpaces. CNodes can be pointed to by capabilities themselves.}\n  {glos:cnode}\n\n\\glossaryentry\n  {cspace}\n  {A directed graph of CNodes. The CSpace of a thread defines the set\n  of capabilities it has access to. The root of the graph is the CNode\n  capability in the CSpace slot of the thread. The edges of the graph\n  are the CNode capabilities residing in the CNodes spanned by this root.}\n  {glos:cspace}\n\n\\glossaryentry\n  {cptr}\n  {Capability Pointer. A user-level reference to a capability,\n  relative to a specified root CNode or the thread's CSpace root. In\n  this specification, a user-level capability pointer is a sequence of\n  bits that define a path in the CSpace graph that should end in a\n  capability slot. The kernel resolves user-level capability pointers\n  into capability slot pointers (cslot\\_ptr).}\n  {glos:cptr}\n\n\\glossaryentry\n  {cslot\\_ptr}\n  {Capability Slot Pointer. A kernel-internal reference to a capability. It\n  identifies the kernel object the capability resides in as well as\n  the location (slot) of the capability inside this object. }\n  {glos:cptr}\n\n\\glossaryentry\n  {ep}\n  {Endpoint. Without further qualifier refers to a synchronous\n  communications (IPC) endpoint in seL4.}\n  {glos:ep}\n\n\\glossaryentry\n  {guard}\n  {Guard of a CNode capability. From the user's perspetive the CSpace\n  of a thread is organised as a guardedage table. The kernel will\n  resolve user capability pointers into internal capability slot pointers.\n  The guard of one link/edge in the CSpace graph defines a sequence of bits\n  that will be stripped from the user-level capability pointer before\n  resolving resumes at the next CNode.}\n  {}\n\n\\glossaryentry\n  {ipc}\n  {Inter Process Communication. In seL4: sending short synchronous messages\n  between threads. To communicate via IPC in seL4, the\n  receiver listens at an endpoint object and the sender sends to the\n  same endpoint object. There is a separate mechanism for\n  notifications between threads.}\n  {}\n\n\\glossaryentry\n  {kheap}\n  {Kernel Heap. This is not an actual C heap in the sense that it\n  supports malloc and free. Rather, it is the kernel virtual memory\n  view of physical memory in the machine. }\n  {}\n\n\\glossaryentry\n  {pd}\n  {Page Directory. The first level of an ARM virtual memory page\n  table. A page directory can be seen as an array of page directory\n  entries (PDEs).}\n  {}\n\n\\glossaryentry\n  {pde}\n  {Page Directory Entry. One entry in the page directory. It either\n  is invalid, contains a translation to a frame, or a translation to\n  a second level page table.}\n  {}\n\n\\glossaryentry\n  {pt}\n  {Page Table. The second level of an ARM virtual memory page\n  table. It can be seen as an array of page table entries.}\n  {}\n\n\\glossaryentry\n  {pte}\n  {Page Table Entry. One entry of a second level ARM page table. It is\n  either invalid or contains a translation to a frame.}\n  {}\n\n\\glossaryentry\n  {replycap}\n  {Reply Capability. Reply capabilities are created automatically\n  in the receiver of a Call IPC. The reply capability points back\n  to the sender of the call and can be used to send a reply efficiently\n  without having to explicitly set up a return channel. Reply capabilities\n  can be invoked only once. Internally, reply capabilities are created\n  as copies of so-called Master Reply Capabilities that are always\n  present in the master reply slot of the sender's TCB.}\n  {}\n\n\\glossaryentry\n  {tcb}\n  {Thread Control Block. The kernel object that stores management data\n  for threads, such as the thread's CSpace, VSpace, thread state, or user\n  registers.}\n  {}\n\n\\glossaryentry\n  {thread}\n  {The CPU execution abstraction of seL4.}\n  {}\n\n\\glossaryentry\n  {vm}\n  {Virtual Memory. The concept of translating virutal memory addresses\n  to physical frames. SeL4 uses the MMU (Memory Management Unit) to\n  provide controlled virtual memory mechanisms to the user, to protect\n  kernel data and code from users, and to enforce separation between\n  users (if set up correctly). }\n  {}\n\n\\glossaryentry\n  {vspace}\n  {In analogy to CSpace, the virtual memory space of a thread. In the\n  ARM case, the VSpace of a thread is defined by its top-level page\n  directory and that page directory's ASID.}\n  {}\n\n\\glossaryentry\n  {zombie}\n  {Zombie Capability. This capability is not accessible to the\n  user. It stores continuation information for the preemtable\n  capability delete operation.}\n  {}\n\\<close>\n\n(*<*)\nend\n(*>*)"}
{"title": "./spec/abstract/Tcb_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nThe TCB and thread related specifications.\n*)\n\nchapter \"Threads and TCBs\"\n\ntheory Tcb_A\nimports TcbAcc_A Schedule_A ArchTcb_A\nbegin\n\narch_requalify_consts (A)\n  arch_activate_idle_thread\n  sanitise_register\n  arch_get_sanitise_register_info\n  arch_post_modify_registers"}
{"title": "./spec/abstract/Tcb_A.thy", "section": "Thread Message Formats", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Threads that are active always have a master Reply capability to\nthemselves stored in their reply slot. This is so that a derived Reply\ncapability can be generated immediately if they wish to issue one. This function\nsets up a new master Reply capability if one does not exist.\\<close>\ndefinition\n  \"setup_reply_master thread \\<equiv> do\n     old_cap <- get_cap (thread, tcb_cnode_index 2);\n     when (old_cap = NullCap) $ do\n         set_original (thread, tcb_cnode_index 2) True;\n         set_cap (ReplyCap thread True {AllowGrant, AllowWrite}) (thread, tcb_cnode_index 2)\n     od\n  od\"\n\ntext \\<open>Reactivate a thread if it is not already running.\\<close>\ndefinition\n  restart :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"restart thread \\<equiv> do\n    state \\<leftarrow> get_thread_state thread;\n    when (\\<not> runnable state \\<and> \\<not> idle state) $ do\n      cancel_ipc thread;\n      setup_reply_master thread;\n      set_thread_state thread Restart;\n      do_extended_op (tcb_sched_action (tcb_sched_enqueue) thread);\n      do_extended_op (possible_switch_to thread)\n    od\n  od\"\n\ntext \\<open>This action is performed at the end of a system call immediately before\ncontrol is restored to a used thread. If it needs to be restarted then its\nprogram counter is set to the operation it was performing rather than the next\noperation. The idle thread is handled specially.\\<close>\ndefinition\n  activate_thread :: \"(unit,'z::state_ext) s_monad\" where\n  \"activate_thread \\<equiv> do\n     thread \\<leftarrow> gets cur_thread;\n     state \\<leftarrow> get_thread_state thread;\n     (case state\n       of Running \\<Rightarrow> return ()\n        | Restart \\<Rightarrow> (do\n            pc \\<leftarrow> as_user thread getRestartPC;\n            as_user thread $ setNextPC pc;\n            set_thread_state thread Running\n          od)\n        | IdleThreadState \\<Rightarrow> arch_activate_idle_thread thread\n        | _ \\<Rightarrow> fail)\n   od\""}
{"title": "./spec/abstract/Tcb_A.thy", "section": "Thread Message Formats", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  load_word_offs :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> (machine_word,'z::state_ext) s_monad\" where\n \"load_word_offs ptr offs \\<equiv>\n    do_machine_op $ loadWord (ptr + of_nat (offs * word_size))\"\ndefinition\n  load_word_offs_word :: \"obj_ref \\<Rightarrow> data \\<Rightarrow> (machine_word,'z::state_ext) s_monad\" where\n \"load_word_offs_word ptr offs \\<equiv>\n    do_machine_op $ loadWord (ptr + (offs * word_size))\"\n\ntext \\<open>Copy message registers from one thread to another.\\<close>\ndefinition\n  copy_mrs :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> obj_ref \\<Rightarrow>\n               obj_ref option \\<Rightarrow> length_type \\<Rightarrow> (length_type,'z::state_ext) s_monad\" where\n  \"copy_mrs sender sbuf receiver rbuf n \\<equiv>\n   do\n     hardware_mrs \\<leftarrow> return $ take (unat n) msg_registers;\n     mapM (\\<lambda>r. do\n         v \\<leftarrow> as_user sender $ getRegister r;\n         as_user receiver $ setRegister r v\n       od) hardware_mrs;\n     buf_mrs \\<leftarrow> case (sbuf, rbuf) of\n       (Some sb_ptr, Some rb_ptr) \\<Rightarrow> mapM (\\<lambda>x. do\n                                       v \\<leftarrow> load_word_offs sb_ptr x;\n                                       store_word_offs rb_ptr x v\n                                     od)\n               [length msg_registers + 1 ..< Suc (unat n)]\n     | _ \\<Rightarrow> return [];\n     return $ min n $ nat_to_len $ length hardware_mrs + length buf_mrs\n   od\"\n\ntext \\<open>The ctable and vtable slots of the TCB.\\<close>\ndefinition\n  get_tcb_ctable_ptr :: \"obj_ref \\<Rightarrow> cslot_ptr\" where\n  \"get_tcb_ctable_ptr tcb_ref \\<equiv> (tcb_ref, tcb_cnode_index 0)\"\n\ndefinition\n  get_tcb_vtable_ptr :: \"obj_ref \\<Rightarrow> cslot_ptr\" where\n  \"get_tcb_vtable_ptr tcb_ref \\<equiv> (tcb_ref, tcb_cnode_index 1)\"\n\ntext \\<open>Optionally update the tcb at an address.\\<close>\ndefinition\n  option_update_thread :: \"obj_ref \\<Rightarrow> ('a \\<Rightarrow> tcb \\<Rightarrow> tcb) \\<Rightarrow> 'a option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"option_update_thread thread fn \\<equiv> case_option (return ()) (\\<lambda>v. thread_set (fn v) thread)\"\n\ntext \\<open>Check that a related capability is at an address. This is done before\ncalling @{const cap_insert} to avoid a corner case where the would-be parent of\nthe cap to be inserted has been moved or deleted.\\<close>\ndefinition\n  check_cap_at :: \"cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"check_cap_at cap slot m \\<equiv> do\n    cap' \\<leftarrow> get_cap slot;\n    when (same_object_as cap cap') m\n  od\"\n\n\ntext \\<open>Helper function for binding notifications\\<close>\ndefinition\n  bind_notification :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"bind_notification tcbptr ntfnptr \\<equiv> do\n     ntfn \\<leftarrow> get_notification ntfnptr;\n     ntfn' \\<leftarrow> return $ ntfn_set_bound_tcb ntfn (Some tcbptr);\n     set_notification ntfnptr ntfn';\n     set_bound_notification tcbptr $ Some ntfnptr\n   od\"\n\ntext \\<open>TCB capabilities confer authority to perform seven actions. A thread can\nrequest to yield its timeslice to another, to suspend or resume another, to\nreconfigure another thread, or to copy register sets into, out of or between\nother threads.\\<close>\nfun\n  invoke_tcb :: \"tcb_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\nwhere\n  \"invoke_tcb (Suspend thread) = liftE (do suspend thread; return [] od)\"\n| \"invoke_tcb (Resume thread) = liftE (do restart thread; return [] od)\"\n\n| \"invoke_tcb (ThreadControl target slot faultep mcp priority croot vroot buffer)\n   = doE\n    liftE $ option_update_thread target (tcb_fault_handler_update o K) faultep;\n    liftE $  case mcp of None \\<Rightarrow> return()\n     | Some (newmcp, _) \\<Rightarrow> set_mcpriority target newmcp;\n    (case croot of None \\<Rightarrow> returnOk ()\n     | Some (new_cap, src_slot) \\<Rightarrow> doE\n      cap_delete (target, tcb_cnode_index 0);\n      liftE $ check_cap_at new_cap src_slot\n            $ check_cap_at (ThreadCap target) slot\n            $ cap_insert new_cap src_slot (target, tcb_cnode_index 0)\n    odE);\n    (case vroot of None \\<Rightarrow> returnOk ()\n     | Some (new_cap, src_slot) \\<Rightarrow> doE\n      cap_delete (target, tcb_cnode_index 1);\n      liftE $ check_cap_at new_cap src_slot\n            $ check_cap_at (ThreadCap target) slot\n            $ cap_insert new_cap src_slot (target, tcb_cnode_index 1)\n    odE);\n    (case buffer of None \\<Rightarrow> returnOk ()\n     | Some (ptr, frame) \\<Rightarrow> doE\n      cap_delete (target, tcb_cnode_index 4);\n      liftE $ thread_set (\\<lambda>t. t \\<lparr> tcb_ipc_buffer := ptr \\<rparr>) target;\n      liftE $ case frame of None \\<Rightarrow> return ()\n       | Some (new_cap, src_slot) \\<Rightarrow>\n            check_cap_at new_cap src_slot\n          $ check_cap_at (ThreadCap target) slot\n          $ cap_insert new_cap src_slot (target, tcb_cnode_index 4);\n      cur \\<leftarrow> liftE $ gets cur_thread;\n      liftE $ when (target = cur) (do_extended_op reschedule_required)\n    odE);\n    liftE $ case priority\n              of None \\<Rightarrow> return()\n               | Some (prio, _) \\<Rightarrow> do_extended_op (set_priority target prio);\n    returnOk []\n  odE\"\n\n| \"invoke_tcb (CopyRegisters dest src suspend_source resume_target transfer_frame transfer_integer transfer_arch) =\n  (liftE $ do\n    when suspend_source $ suspend src;\n    when resume_target $ restart dest;\n    when transfer_frame $ do\n        mapM_x (\\<lambda>r. do\n                v \\<leftarrow> as_user src $ getRegister r;\n                as_user dest $ setRegister r v\n        od) frame_registers;\n        pc \\<leftarrow> as_user dest getRestartPC;\n        as_user dest $ setNextPC pc\n    od;\n    when transfer_integer $\n        mapM_x (\\<lambda>r. do\n                v \\<leftarrow> as_user src $ getRegister r;\n                as_user dest $ setRegister r v\n        od) gpRegisters;\n    cur \\<leftarrow> gets cur_thread;\n    arch_post_modify_registers cur dest;\n    when (dest = cur) (do_extended_op reschedule_required);\n    return []\n  od)\"\n\n| \"invoke_tcb (ReadRegisters src suspend_source n arch) =\n  (liftE $ do\n    when suspend_source $ suspend src;\n    self \\<leftarrow> gets cur_thread;\n    regs \\<leftarrow> return (take (unat n) $ frame_registers @ gp_registers);\n    as_user src $ mapM getRegister regs\n  od)\"\n\n| \"invoke_tcb (WriteRegisters dest resume_target values arch) =\n  (liftE $ do\n    self \\<leftarrow> gets cur_thread;\n    b \\<leftarrow> arch_get_sanitise_register_info dest;\n    as_user dest $ do\n        zipWithM (\\<lambda>r v. setRegister r (sanitise_register b r v))\n            (frameRegisters @ gpRegisters) values;\n        pc \\<leftarrow> getRestartPC;\n        setNextPC pc\n    od;\n    arch_post_modify_registers self dest;\n    when resume_target $ restart dest;\n    when (dest = self) (do_extended_op reschedule_required);\n    return []\n  od)\"\n\n| \"invoke_tcb (NotificationControl tcb (Some ntfnptr)) =\n  (liftE $ do\n    bind_notification tcb ntfnptr;\n    return []\n  od)\"\n\n| \"invoke_tcb (NotificationControl tcb None) =\n  (liftE $ do\n    unbind_notification tcb;\n    return []\n  od)\"\n\n| \"invoke_tcb (SetTLSBase tcb tls_base) =\n  (liftE $ do\n    as_user tcb $ setRegister tlsBaseRegister tls_base;\n    cur \\<leftarrow> gets cur_thread;\n    when (tcb = cur) (do_extended_op reschedule_required);\n    return []\n  od)\"\n\ndefinition\n  set_domain :: \"obj_ref \\<Rightarrow> domain \\<Rightarrow> unit det_ext_monad\" where\n  \"set_domain tptr new_dom \\<equiv> do\n     cur \\<leftarrow> gets cur_thread;\n     tcb_sched_action tcb_sched_dequeue tptr;\n     thread_set_domain tptr new_dom;\n     ts \\<leftarrow> get_thread_state tptr;\n     when (runnable ts) (tcb_sched_action tcb_sched_enqueue tptr);\n     when (tptr = cur) reschedule_required\n   od\"\n\ndefinition invoke_domain:: \"obj_ref \\<Rightarrow> domain \\<Rightarrow> (data list,'z::state_ext) p_monad\"\nwhere\n  \"invoke_domain thread domain \\<equiv>\n     liftE (do do_extended_op (set_domain thread domain); return [] od)\"\n\ntext \\<open>Get all of the message registers, both from the sending thread's current\nregister file and its IPC buffer.\\<close>\ndefinition\n  get_mrs :: \"obj_ref \\<Rightarrow> obj_ref option \\<Rightarrow> message_info \\<Rightarrow>\n              (message list,'z::state_ext) s_monad\" where\n  \"get_mrs thread buf info \\<equiv> do\n     context \\<leftarrow> thread_get (arch_tcb_get_registers o tcb_arch) thread;\n     cpu_mrs \\<leftarrow> return (map context msg_registers);\n     buf_mrs \\<leftarrow> case buf\n       of None      \\<Rightarrow> return []\n        | Some pptr \\<Rightarrow> mapM (\\<lambda>x. load_word_offs pptr x)\n               [length msg_registers + 1 ..< Suc msg_max_length];\n     return (take (unat (mi_length info)) $ cpu_mrs @ buf_mrs)\n   od\"\n\nend"}
{"title": "./spec/abstract/ARM/ArchInterrupt_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFormalisation of interrupt handling.\n*)\n\nchapter \"Arch-specific Interrupts\"\n\ntheory ArchInterrupt_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition handle_reserved_irq :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where \"handle_reserved_irq irq = return ()\"\n\nfun arch_invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_invoke_irq_handler (ACKIrq irq) = (do_machine_op $ maskInterrupt False irq)\"\n| \"arch_invoke_irq_handler _ = return ()\"\n\ndefinition arch_mask_irq_signal :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_mask_irq_signal irq \\<equiv> do_machine_op $ maskInterrupt True irq\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM/Arch_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nEntry point for architecture dependent definitions.\n*)\n\nchapter \"Toplevel ARM Definitions\"\n\ntheory Arch_A\nimports TcbAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition \"page_bits \\<equiv> pageBits\"\n\nfun\n  arch_invoke_irq_control :: \"arch_irq_control_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"arch_invoke_irq_control (ArchIRQControlIssue irq handler_slot control_slot trigger) = without_preemption (do\n    do_machine_op $ setIRQTrigger irq trigger;\n    set_irq_state IRQSignal (irq);\n    cap_insert (IRQHandlerCap (irq)) control_slot handler_slot\n  od)\"\n\ntext \\<open>Switch to a thread's virtual address space context. Clear the load-exclusive monitor.\\<close>\ndefinition\n  arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> do\n     set_vm_root t;\n     do_machine_op $ clearExMonitor\n   od\"\n\ntext \\<open>The idle thread does not need to be handled specially on ARM.\\<close>\n(* Clear the globals frame when switching to the idle thread. This is\n    specificially to ease infoflow reasoning VER-207 *)\ndefinition\n   arch_switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n   \"arch_switch_to_idle_thread \\<equiv> do\n     thread \\<leftarrow> gets idle_thread;\n     set_vm_root thread\n   od\"\n\ndefinition\n  arch_activate_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_activate_idle_thread t \\<equiv> return ()\"\n\ntext \\<open>The ASIDControl capability confers the authority to create a new ASID\npool object. This operation creates the new ASID pool, provides a capability\nto it and connects it to the global virtual ASID table.\\<close>\ndefinition\nperform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_control_invocation iv \\<equiv> case iv of\n  MakePool frame slot parent base \\<Rightarrow> do\n    delete_objects frame page_bits;\n    pcap \\<leftarrow> get_cap parent;\n    set_cap (max_free_index_update pcap) parent;\n    retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n    cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n    assert (base && mask asid_low_bits = 0);\n    asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n    modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>arm_asid_table := asid_table'\\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>The ASIDPool capability confers the authority to assign a virtual ASID\nto a page directory.\\<close>\ndefinition\nperform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_pool_invocation iv \\<equiv> case iv of Assign asid pool_ptr ct_slot \\<Rightarrow>\ndo\n    pd_cap \\<leftarrow> get_cap ct_slot;\n    case pd_cap of\n      ArchObjectCap (PageDirectoryCap pd_base _) \\<Rightarrow> do\n        pool \\<leftarrow> get_asid_pool pool_ptr;\n        pool' \\<leftarrow> return (pool (ucast asid \\<mapsto> pd_base));\n        set_cap (ArchObjectCap $ PageDirectoryCap pd_base (Some asid)) ct_slot;\n        set_asid_pool pool_ptr pool'\n      od\n    | _ \\<Rightarrow> fail\nod\"\n\ntext \\<open>The PageDirectory capability confers the authority to flush cache entries\nassociated with that PD\\<close>\ndefinition\n  perform_page_directory_invocation :: \"page_directory_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_page_directory_invocation iv \\<equiv> case iv of\n       PageDirectoryFlush typ start end pstart pd asid \\<Rightarrow>\n         when (start < end) $ do\n           root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n           do_machine_op $ do_flush typ start end pstart;\n           when root_switched $ do\n             tcb \\<leftarrow> gets cur_thread;\n             set_vm_root tcb\n           od\n        od\n     | PageDirectoryNothing \\<Rightarrow> return ()\"\n\ndefinition\n  pte_check_if_mapped :: \"32 word \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pte_check_if_mapped slot \\<equiv> do\n     pt \\<leftarrow> get_master_pte slot;\n     return (pt \\<noteq> InvalidPTE)\n  od\"\n\ndefinition\n  pde_check_if_mapped :: \"32 word \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pde_check_if_mapped slot \\<equiv> do\n     pd \\<leftarrow> get_master_pde slot;\n     return (pd \\<noteq> InvalidPDE)\n  od\"\n\n\ntext \\<open>The Page capability confers the authority to map, unmap and flush the\n  memory page.\\<close>\ndefinition\nperform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n\"perform_page_invocation iv \\<equiv> case iv of\n  PageMap asid cap ct_slot entries \\<Rightarrow> do\n    set_cap cap ct_slot;\n    case entries of\n          Inl (pte, slots) \\<Rightarrow> do\n            flush \\<leftarrow> pte_check_if_mapped (hd slots);\n            store_pte (hd slots) pte;\n            mapM (swp store_pte InvalidPTE) (tl slots);\n            do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                (addrFromPPtr (hd slots));\n            if flush then (invalidate_tlb_by_asid asid) else return ()\n          od\n        | Inr (pde, slots) \\<Rightarrow> do\n            flush \\<leftarrow> pde_check_if_mapped (hd slots);\n            store_pde (hd slots) pde;\n            mapM (swp store_pde InvalidPDE) (tl slots);\n            do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                (addrFromPPtr (hd slots));\n            if flush then (invalidate_tlb_by_asid asid) else return ()\n          od;\n    return []\n  od\n| PageUnmap cap ct_slot \\<Rightarrow>\n    (case cap of\n      PageCap dev p R vp_size vp_mapped_addr \\<Rightarrow> do\n        case vp_mapped_addr of\n            Some (asid, vaddr) \\<Rightarrow> unmap_page vp_size asid vaddr p\n          | None \\<Rightarrow> return ();\n        cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n        set_cap (ArchObjectCap $ update_map_data cap None) ct_slot;\n        return []\n      od\n    | _ \\<Rightarrow> fail)\n| PageFlush typ start end pstart pd asid \\<Rightarrow> do\n    when (start < end) $ do\n      root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n      do_machine_op $ do_flush typ start end pstart;\n      when root_switched $ do\n        tcb \\<leftarrow> gets cur_thread;\n        set_vm_root tcb\n      od\n    od;\n    return []\n  od\n| PageGetAddr ptr \\<Rightarrow>\n    return [addrFromPPtr ptr]\n  \"\n\ntext \\<open>PageTable capabilities confer the authority to map and unmap page\ntables.\\<close>\ndefinition\nperform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_table_invocation iv \\<equiv>\ncase iv of PageTableMap cap ct_slot pde pd_slot \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pde pd_slot pde;\n    do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot)\n  od\n  | PageTableUnmap (ArchObjectCap (PageTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_page_table asid vaddr p;\n      pte_bits \\<leftarrow> return 2;\n      slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 << pt_bits) - 1];\n      mapM_x (swp store_pte InvalidPTE) slots;\n      do_machine_op $ cleanCacheRange_PoU p (p + (1 << pt_bits) - 1)\n                                          (addrFromPPtr p)\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"\n\ntext \\<open>Top level system call despatcher for all ARM-specific system calls.\\<close>\ndefinition\n  arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\" where\n  \"arch_perform_invocation i \\<equiv> liftE $\n    case i of\n      InvokePageTable oper \\<Rightarrow> do\n        perform_page_table_invocation oper;\n        return []\n      od\n    | InvokePageDirectory oper \\<Rightarrow> do\n        perform_page_directory_invocation oper;\n        return []\n      od\n    | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n    | InvokeASIDControl oper \\<Rightarrow> do\n        perform_asid_control_invocation oper;\n        return []\n      od\n    | InvokeASIDPool oper \\<Rightarrow> do\n        perform_asid_pool_invocation oper;\n        return []\n      od\n  \"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM/Hypervisor_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Handle Hyperviser Fault Event\"\n\ntheory Hypervisor_A\nimports Exceptions_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"word32 \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n\"handle_hypervisor_fault thread ARMNoHypFaults = return ()\"\n\n\nend\nend"}
{"title": "./spec/abstract/ARM/ArchRetype_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nRetyping and untyped invocation\n*)\n\nchapter \"Retyping and Untyped Invocations\"\n\ntheory ArchRetype_A\nimports\n  ArchVSpaceAcc_A\n  ArchInvocation_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>This is a placeholder function. We may wish to extend the specification\n  with explicitly tagging kernel data regions in memory.\\<close>\ndefinition\n  reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"\n\ntext \\<open>Initialise architecture-specific objects.\\<close>\n\ndefinition vs_apiobj_size where\n  \"vs_apiobj_size ty \\<equiv>\n     case ty of\n       ArchObject SmallPageObj \\<Rightarrow> pageBitsForSize ARMSmallPage\n     | ArchObject LargePageObj \\<Rightarrow> pageBitsForSize ARMLargePage\n     | ArchObject SectionObj \\<Rightarrow> pageBitsForSize ARMSection\n     | ArchObject SuperSectionObj \\<Rightarrow> pageBitsForSize ARMSuperSection\n     | ArchObject PageTableObj \\<Rightarrow> pt_bits\n     | ArchObject PageDirectoryObj \\<Rightarrow> pd_bits\"\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv> do\n     when (new_type = ArchObject PageDirectoryObj) $ mapM_x copy_global_mappings refs;\n     if \\<not>is_device \\<and>\n        new_type \\<in> {ArchObject SmallPageObj, ArchObject LargePageObj,\n                    ArchObject SectionObj, ArchObject SuperSectionObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_RAM ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else if new_type \\<in> {ArchObject PageTableObj, ArchObject PageDirectoryObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_PoU ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else\n       return ()\n   od\"\n\ndefinition\n  empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context \\<rparr>\"\n\n\nend\n\nend"}
{"title": "./spec/abstract/ARM/ArchIpcCancel_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch Functions for cancelling IPC.\n*)\n\nchapter \\<open>Arch IPC Cancelling\\<close>\n\ntheory ArchIpcCancel_A\nimports CSpaceAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>Actions to be taken after a cap is deleted\\<close>\ndefinition\n  arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arch_post_cap_deletion _ \\<equiv> return ()\"\n\ntext \\<open>Arch specific generic object references not covered by generic references\\<close>\ndatatype arch_gen_obj_ref = unit\n\ndefinition\n  arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\"\nwhere\n  \"arch_gen_obj_refs _ = {}\"\n\ndefinition\n  arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend"}
{"title": "./spec/abstract/ARM/Init_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDummy initial kernel state. Real kernel boot up is more complex.\n*)\n\nchapter \"An Initial Kernel State\"\n\ntheory Init_A\nimports Retype_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This is not a specification of true kernel\n  initialisation. This theory describes a dummy initial state only, to\n  show that the invariants and refinement relation are consistent.\n\\<close>\n\ndefinition\n  init_tcb_ptr :: word32 where\n  \"init_tcb_ptr = kernel_base + 0x2000\"\n\ndefinition\n  init_irq_node_ptr :: word32 where\n  \"init_irq_node_ptr = kernel_base + 0x8000\"\n\n(* It is easy to remove a memory slot here, but once if we want to reserve other slots of memory, we have to do the proof of disjoint for example state again.\n   Comment is left here so that next time we need 4k memory, we don't need to fix example state and can simply change its name. *)\ndefinition\n  init_globals_frame :: word32 where\n  \"init_globals_frame = kernel_base + 0x5000\"\n\ndefinition\n  init_global_pd :: word32 where\n  \"init_global_pd = kernel_base + 0x60000\"\n\ndefinition\n  \"init_arch_state \\<equiv> \\<lparr>\n    arm_asid_table = Map.empty,\n    arm_hwasid_table = Map.empty,\n    arm_next_asid = 0,\n    arm_asid_map = Map.empty,\n    arm_global_pd = init_global_pd,\n    arm_global_pts = [],\n    arm_kernel_vspace = \\<lambda>ref.\n      if ref \\<in> {kernel_base .. kernel_base + mask 20}\n      then ArmVSpaceKernelWindow\n      else ArmVSpaceInvalidRegion\n  \\<rparr>\"\n\ndefinition\n  [simp]:\n  \"global_pd \\<equiv> (\\<lambda>_. InvalidPDE)( ucast (kernel_base >> 20) := SectionPDE (addrFromPPtr kernel_base) {} 0 {})\"\n\ndefinition\n  \"init_kheap \\<equiv>\n  (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n       then Some (CNode 0 (empty_cnode 0)) else None)\n  (idle_thread_ptr \\<mapsto> TCB \\<lparr>\n    tcb_ctable = NullCap,\n    tcb_vtable = NullCap,\n    tcb_reply = NullCap,\n    tcb_caller = NullCap,\n    tcb_ipcframe = NullCap,\n    tcb_state = IdleThreadState,\n    tcb_fault_handler = replicate word_bits False,\n    tcb_ipc_buffer = 0,\n    tcb_fault = None,\n    tcb_bound_notification = None,\n    tcb_mcpriority = minBound,\n    tcb_arch = init_arch_tcb\n  \\<rparr>,\n  init_globals_frame \\<mapsto> ArchObj (DataPage False ARMSmallPage), \\<comment> \\<open>same reason as why we kept the definition of @{term init_globals_frame}\\<close>\n  init_global_pd \\<mapsto> ArchObj (PageDirectory global_pd)\n  )\"\n\ndefinition\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. Structures_A.IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\n\n\nend"}
{"title": "./spec/abstract/ARM/ArchVSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nHigher level functions for manipulating virtual address spaces\n*)\n\nchapter \"ARM VSpace Functions\"\n\ntheory ArchVSpace_A\nimports Retype_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>Save the set of entries that would be inserted into a page table or\npage directory to map various different sizes of frame at a given virtual\naddress.\\<close>\n\ndefinition largePagePTE_offsets :: \"obj_ref list\"\n  where\n  \"largePagePTE_offsets \\<equiv>\n    let pts = of_nat 2\n    in [0, 2 ^ pts  .e.  (15 << 2)]\"\n\ndefinition superSectionPDE_offsets :: \"obj_ref list\"\n  where\n  \"superSectionPDE_offsets \\<equiv>\n    let pts = of_nat 2\n    in [0, 2 ^ pts  .e.  (15 << 2)]\"\n\nfun create_mapping_entries ::\n  \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vm_rights \\<Rightarrow> vm_attributes \\<Rightarrow> word32 \\<Rightarrow>\n  ((pte * word32 list) + (pde * word32 list),'z::state_ext) se_monad\"\nwhere\n  \"create_mapping_entries base vptr ARMSmallPage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (SmallPagePTE base (attrib - {Global, ParityEnabled})\n                                 vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMLargePage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (LargePagePTE base (attrib - {Global, ParityEnabled})\n                                 vm_rights, map (\\<lambda>x. x + p) largePagePTE_offsets)\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SectionPDE base (attrib - {Global}) 0 vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSuperSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SuperSectionPDE base (attrib - {Global}) vm_rights, map (\\<lambda>x. x + p) superSectionPDE_offsets)\n  odE\"\n\ndefinition get_master_pde :: \"word32 \\<Rightarrow> (pde,'z::state_ext)s_monad\"\n  where \"get_master_pde ptr \\<equiv> do\n    pde \\<leftarrow> (get_pde (ptr && ~~ mask 6));\n    (case pde of SuperSectionPDE _ _ _ \\<Rightarrow> return pde\n    | _ \\<Rightarrow> get_pde ptr)\n  od\"\n\ndefinition get_master_pte :: \"word32 \\<Rightarrow> (pte, 'z::state_ext)s_monad\"\n  where \"get_master_pte ptr \\<equiv> do\n    pte \\<leftarrow> (get_pte (ptr && ~~ mask 6));\n    (case pte of LargePagePTE _ _ _ \\<Rightarrow> return pte\n    | _ \\<Rightarrow> get_pte ptr)\n  od\"\n\ntext \\<open>Placing an entry which maps a frame within the set of entries that map a\nlarger frame is unsafe. This function checks that given entries replace either\ninvalid entries or entries of the same granularity.\\<close>\nfun ensure_safe_mapping ::\n  \"(pte * word32 list) + (pde * word32 list) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n\"ensure_safe_mapping (Inl (InvalidPTE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inl (SmallPagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda>slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | SmallPagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inl (LargePagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | LargePagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inr (InvalidPDE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inr (PageTablePDE _ _ _, _)) = fail\"\n|\n\"ensure_safe_mapping (Inr (SectionPDE _ _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SectionPDE _ _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"\n|\n\"ensure_safe_mapping (Inr (SuperSectionPDE _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SuperSectionPDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"\n\ntext \\<open>Look up a thread's IPC buffer and check that the thread has the right\nauthority to read or (in the receiver case) write to it.\\<close>\ndefinition\nlookup_ipc_buffer :: \"bool \\<Rightarrow> word32 \\<Rightarrow> (word32 option,'z::state_ext) s_monad\" where\n\"lookup_ipc_buffer is_receiver thread \\<equiv> do\n    buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n    buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n    buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n    (case buffer_cap of\n      ArchObjectCap (PageCap _ p R vms _) \\<Rightarrow>\n        if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n        then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n        else return None\n    | _ \\<Rightarrow> return None)\nod\"\n\ntext \\<open>Locate the page directory associated with a given virtual ASID.\\<close>\ndefinition\nfind_pd_for_asid :: \"asid \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"find_pd_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pd \\<leftarrow> returnOk (pool (ucast asid));\n    (case pd of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"\n\ntext \\<open>Locate the page directory and check that this process succeeds and\nreturns a pointer to a real page directory.\\<close>\ndefinition\nfind_pd_for_asid_assert :: \"asid \\<Rightarrow> (word32,'z::state_ext) s_monad\" where\n\"find_pd_for_asid_assert asid \\<equiv> do\n   pd \\<leftarrow> find_pd_for_asid asid <catch> K fail;\n   get_pde pd;\n   return pd\n od\"\n\ntext \\<open>Format a VM fault message to be passed to a thread's supervisor after\nit encounters a page fault.\\<close>\nfun\nhandle_vm_fault :: \"word32 \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n\"handle_vm_fault thread ARMDataAbort = doE\n    addr \\<leftarrow> liftE $ do_machine_op getFAR;\n    fault \\<leftarrow> liftE $ do_machine_op getDFSR;\n    throwError $ ArchFault $ VMFault addr [0, fault && mask 14]\nodE\"\n|\n\"handle_vm_fault thread ARMPrefetchAbort = doE\n    pc \\<leftarrow> liftE $ as_user thread $ getRestartPC;\n    fault \\<leftarrow> liftE $ do_machine_op getIFSR;\n    throwError $ ArchFault $ VMFault pc [1, fault && mask 14]\nodE\"\n\ntext \\<open>Load the optional hardware ASID currently associated with this virtual\nASID.\\<close>\ndefinition\nload_hw_asid :: \"asid \\<Rightarrow> (hardware_asid option,'z::state_ext) s_monad\" where\n\"load_hw_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    return $ option_map fst $ asid_map asid\nod\"\n\ntext \\<open>Associate a hardware ASID with a virtual ASID.\\<close>\ndefinition\nstore_hw_asid :: \"asid \\<Rightarrow> hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"store_hw_asid asid hw_asid \\<equiv> do\n    pd \\<leftarrow> find_pd_for_asid_assert asid;\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid \\<mapsto> (hw_asid, pd)));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>);\n    hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid \\<mapsto> asid));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>Clear all TLB mappings associated with this virtual ASID.\\<close>\ndefinition\ninvalidate_tlb_by_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_tlb_by_asid asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"\n\ntext \\<open>Flush all cache and TLB entries associated with this virtual ASID.\\<close>\ndefinition\nflush_space :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_space asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    do_machine_op cleanCaches_PoU;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"\n\ntext \\<open>Remove any mapping from this virtual ASID to a hardware ASID.\\<close>\ndefinition\ninvalidate_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>Remove any mapping from this hardware ASID to a virtual ASID.\\<close>\ndefinition\ninvalidate_hw_asid_entry :: \"hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_hw_asid_entry hw_asid \\<equiv> do\n  hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n  hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid:= None));\n  modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>Remove virtual to physical mappings in either direction involving this\nvirtual ASID.\\<close>\ndefinition\ninvalidate_asid_entry :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid_entry asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  when (maybe_hw_asid \\<noteq> None) $ invalidate_hw_asid_entry (the maybe_hw_asid);\n  invalidate_asid asid\nod\"\n\ntext \\<open>Locate a hardware ASID that is not in use, if necessary by reclaiming\none from another virtual ASID in a round-robin manner.\\<close>\ndefinition\nfind_free_hw_asid :: \"(hardware_asid,'z::state_ext) s_monad\" where\n\"find_free_hw_asid \\<equiv> do\n    hw_asid_table \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    next_asid \\<leftarrow> gets (arm_next_asid \\<circ> arch_state);\n    maybe_asid \\<leftarrow> return (find (\\<lambda>a. hw_asid_table a = None)\n                    (take (length [minBound :: hardware_asid .e. maxBound])\n                        ([next_asid .e. maxBound] @ [minBound .e. next_asid])));\n    (case maybe_asid of\n       Some hw_asid \\<Rightarrow> return hw_asid\n     | None \\<Rightarrow>  do\n            invalidate_asid $ the $ hw_asid_table next_asid;\n            do_machine_op $ invalidateLocalTLB_ASID next_asid;\n            invalidate_hw_asid_entry next_asid;\n            new_next_asid \\<leftarrow> return (next_asid + 1);\n            modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_next_asid := new_next_asid \\<rparr>\\<rparr>);\n            return next_asid\n       od)\nod\"\n\ntext \\<open>Get the hardware ASID associated with a virtual ASID, assigning one if\nnone is already assigned.\\<close>\ndefinition\nget_hw_asid :: \"asid \\<Rightarrow> (hardware_asid,'z::state_ext) s_monad\" where\n\"get_hw_asid asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  (case maybe_hw_asid of\n    Some hw_asid \\<Rightarrow> return hw_asid\n  | None \\<Rightarrow>  do\n      new_hw_asid \\<leftarrow> find_free_hw_asid;\n      store_hw_asid asid new_hw_asid;\n      return new_hw_asid\n  od)\nod\"\n\n\nabbreviation\n  \"arm_context_switch_hwasid pd hwasid \\<equiv> do\n              set_current_pd $ addrFromPPtr pd;\n              setHardwareASID hwasid\n          od\"\n\ndefinition\n  arm_context_switch :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arm_context_switch pd asid \\<equiv> do\n      hwasid \\<leftarrow> get_hw_asid asid;\n      do_machine_op $ arm_context_switch_hwasid pd hwasid\n    od\"\n\ntext \\<open>Switch into the address space of a given thread or the global address\nspace if none is correctly configured.\\<close>\ndefinition\n  set_vm_root :: \"word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow> doE\n           pd' \\<leftarrow> find_pd_for_asid asid;\n           whenE (pd \\<noteq> pd') $ throwError InvalidRoot;\n           liftE $ arm_context_switch pd asid\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_pd \\<leftarrow> gets (arm_global_pd \\<circ> arch_state);\n       do_machine_op $ set_current_pd $ addrFromKPPtr global_pd\n    od)\nod\"\n\ntext \\<open>Before deleting an ASID pool object we must deactivate all page\ndirectories that are installed in it.\\<close>\ndefinition\ndelete_asid_pool :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid_pool base ptr \\<equiv> do\n  assert (base && mask asid_low_bits = 0);\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n    pool \\<leftarrow> get_asid_pool ptr;\n    mapM (\\<lambda>offset. (when (pool (ucast offset) \\<noteq> None) $ do\n                          flush_space $ base + offset;\n                          invalidate_asid_entry $ base + offset\n                    od)) [0  .e.  (1 << asid_low_bits) - 1];\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>);\n    tcb \\<leftarrow> gets cur_thread;\n    set_vm_root tcb\n  od\nod\"\n\ntext \\<open>When deleting a page directory from an ASID pool we must deactivate\nit.\\<close>\ndefinition\ndelete_asid :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pd \\<equiv> do\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  (case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (ucast asid) = Some pd) $ do\n                flush_space asid;\n                invalidate_asid_entry asid;\n                pool' \\<leftarrow> return (pool (ucast asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od)\nod\"\n\ntext \\<open>Switch to a particular address space in order to perform a flush\noperation.\\<close>\ndefinition\nset_vm_root_for_flush :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"set_vm_root_for_flush pd asid \\<equiv> do\n    tcb \\<leftarrow> gets cur_thread;\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    not_is_pd \\<leftarrow> (case thread_root of\n                    ArchObjectCap (PageDirectoryCap cur_pd (Some _)) \\<Rightarrow> return (cur_pd \\<noteq> pd)\n                  | _ \\<Rightarrow> return True);\n    (if not_is_pd then do\n        arm_context_switch pd asid;\n        return True\n    od\n    else return False)\nod\"\n\ndefinition\ndo_flush :: \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\" where\n\"do_flush flush_type vstart vend pstart \\<equiv>\n    case flush_type of\n       Clean \\<Rightarrow> cleanCacheRange_RAM vstart vend pstart\n     | Invalidate \\<Rightarrow> invalidateCacheRange_RAM vstart vend pstart\n     | CleanInvalidate \\<Rightarrow> cleanInvalidateCacheRange_RAM vstart vend pstart\n     | Unify \\<Rightarrow> do\n         cleanCacheRange_PoU vstart vend pstart;\n         dsb;\n         invalidateCacheRange_I vstart vend pstart;\n         branchFlushRange vstart vend pstart;\n         isb\n     od\"\n\ntext \\<open>Flush mappings associated with a page table.\\<close>\ndefinition\nflush_table :: \"word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_table pd asid vptr pt \\<equiv> do\n    assert (vptr && mask (pageBitsForSize ARMSection) = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_ASID hw_asid;\n      when root_switched $ do\n        tcb \\<leftarrow> gets cur_thread;\n        set_vm_root tcb\n      od\n    od\nod\"\n\ntext \\<open>Flush mappings associated with a given page.\\<close>\ndefinition\nflush_page :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_page page_size pd asid vptr\\<equiv> do\n    assert (vptr && mask pageBits = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_VAASID (vptr || ucast hw_asid);\n      when root_switched $ do\n          tcb \\<leftarrow> gets cur_thread;\n          set_vm_root tcb\n      od\n   od\nod\"\n\ntext \\<open>Return the optional page directory a page table is mapped in.\\<close>\ndefinition\npage_table_mapped :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n\"page_table_mapped asid vaddr pt \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    pd_slot \\<leftarrow> returnOk $ lookup_pd_slot pd vaddr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    case pde of\n      PageTablePDE addr _ _ \\<Rightarrow> returnOk $\n             if addrFromPPtr pt = addr then Some pd else None\n    | _ \\<Rightarrow> returnOk None\nodE <catch> (K $ return None)\"\n\ntext \\<open>Unmap a page table from its page directory.\\<close>\ndefinition\nunmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page_table asid vaddr pt \\<equiv> do\n    pdOpt \\<leftarrow> page_table_mapped asid vaddr pt;\n    case pdOpt of\n      None \\<Rightarrow> return ()\n    | Some pd \\<Rightarrow> do\n        pd_slot \\<leftarrow> return $ lookup_pd_slot pd vaddr;\n        store_pde pd_slot InvalidPDE;\n        do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot);\n        flush_table pd asid vaddr pt\n    od\nod\"\n\ntext \\<open>Check that a given frame is mapped by a given mapping entry.\\<close>\ndefinition\ncheck_mapping_pptr :: \"obj_ref \\<Rightarrow> vmpage_size \\<Rightarrow> (obj_ref + obj_ref) \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"check_mapping_pptr pptr pgsz tablePtr \\<equiv> case tablePtr of\n   Inl ptePtr \\<Rightarrow> do\n     pte \\<leftarrow> get_pte ptePtr;\n     return $ case pte of\n       SmallPagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSmallPage\n     | LargePagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMLargePage\n     | _ \\<Rightarrow> False\n   od\n | Inr pdePtr \\<Rightarrow> do\n     pde \\<leftarrow> get_pde pdePtr;\n     return $ case pde of\n       SectionPDE x _ _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSection\n     | SuperSectionPDE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSuperSection\n     | _ \\<Rightarrow> False\n   od\"\n\n\ndefinition\n  \"last_byte_pte x \\<equiv> let pte_bits = 2 in x + ((1 << pte_bits) - 1)\"\n\ndefinition\n  \"last_byte_pde x \\<equiv> let pde_bits = 2 in x + ((1 << pde_bits) - 1)\"\n\ntext \\<open>Unmap a mapped page if the given mapping details are still current.\\<close>\ndefinition\nunmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page pgsz asid vptr pptr \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    (case pgsz of\n          ARMSmallPage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                store_pte p InvalidPTE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMLargePage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                assert $ p && mask 6 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) [0, 4  .e.  60]);\n                mapM (swp store_pte InvalidPTE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE\n        | ARMSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                store_pde p InvalidPDE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMSuperSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                assert $ p && mask 6 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) [0, 4  .e.  60]);\n                mapM (swp store_pde InvalidPDE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE);\n    liftE $ flush_page pgsz pd asid vptr\nodE <catch> (K $ return ())\"\n\n\ntext \\<open>PageDirectory and PageTable capabilities cannot be copied until they\nhave a virtual ASID and location assigned. This is because page directories\ncannot have multiple current virtual ASIDs and page tables cannot be shared\nbetween address spaces or virtual locations.\\<close>\ndefinition\n  arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\"\nwhere\n  \"arch_derive_cap c \\<equiv> case c of\n     PageTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageTableCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageDirectoryCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageDirectoryCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageCap dev r R pgs x \\<Rightarrow> returnOk (ArchObjectCap (PageCap dev r R pgs None))\n   | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n   | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\"\n\ntext \\<open>No user-modifiable data is stored in ARM-specific capabilities.\\<close>\ndefinition\n  arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"\n\n\ntext \\<open>Actions that must be taken on finalisation of ARM-specific\ncapabilities.\\<close>\ndefinition\n  arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n    (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n    delete_asid_pool b ptr;\n    return (NullCap, NullCap)\n    od\n  | (PageDirectoryCap ptr (Some a), True) \\<Rightarrow> do\n    delete_asid a ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n    unmap_page_table a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageCap _ ptr _ s (Some (a, v)), _) \\<Rightarrow> do\n     unmap_page s a v ptr;\n     return (NullCap, NullCap)\n  od\n  | _ \\<Rightarrow> return (NullCap, NullCap)\"\n\n\ndefinition (* prepares a thread for deletion; nothing to do for ARM *)\n  prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"prepare_thread_delete p \\<equiv> return ()\"\n\n\ntext \\<open>A thread's virtual address space capability must be to a page directory\nto be valid on the ARM architecture.\\<close>\ndefinition\n  is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv> \\<exists>r a. c = ArchObjectCap (PageDirectoryCap r (Some a))\"\n\ndefinition\ncheck_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n\"check_valid_ipc_buffer vptr c \\<equiv> case c of\n  (ArchObjectCap (PageCap False _ _ _ _)) \\<Rightarrow> doE\n    whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError;\n    returnOk ()\n  odE\n| _ \\<Rightarrow> throwError IllegalOperation\"\n\ntext \\<open>Decode a user argument word describing the kind of VM attributes a\nmapping is to have.\\<close>\ndefinition\nattribs_from_word :: \"word32 \\<Rightarrow> vm_attributes\" where\n\"attribs_from_word w \\<equiv>\n  let V = (if w !!0 then {PageCacheable} else {});\n      V' = (if w!!1 then insert ParityEnabled V else V)\n  in if w!!2 then insert XNever V' else V'\"\n\ntext \\<open>Update the mapping data saved in a page or page table capability.\\<close>\ndefinition\n  update_map_data :: \"arch_cap \\<Rightarrow> (word32 \\<times> word32) option \\<Rightarrow> arch_cap\" where\n  \"update_map_data cap m \\<equiv> case cap of PageCap dev p R sz _ \\<Rightarrow> PageCap dev p R sz m\n                                     | PageTableCap p _ \\<Rightarrow> PageTableCap p m\"\n\ntext \\<open>Get information about the frame of a given virtual address\\<close>\ndefinition\n  resolve_vaddr :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> ((vmpage_size \\<times> obj_ref) option, 'z::state_ext) s_monad\"\nwhere\n  \"resolve_vaddr pd vaddr \\<equiv> do\n     pd_slot \\<leftarrow> return $ lookup_pd_slot pd vaddr;\n     pde \\<leftarrow> get_master_pde pd_slot;\n     case pde of\n         SectionPDE f _ _ _ \\<Rightarrow> return $ Some (ARMSection, f)\n       | SuperSectionPDE f _ _ \\<Rightarrow> return $ Some (ARMSuperSection, f)\n       | PageTablePDE t _ _ \\<Rightarrow> (do\n           pt \\<leftarrow> return $ ptrFromPAddr t;\n           pte_slot \\<leftarrow> return $ lookup_pt_slot_no_fail pt vaddr;\n           pte \\<leftarrow> get_master_pte pte_slot;\n           case pte of\n               LargePagePTE f _ _ \\<Rightarrow> return $ Some (ARMLargePage, f)\n             | SmallPagePTE f _ _ \\<Rightarrow> return $ Some (ARMSmallPage, f)\n             | _ \\<Rightarrow> return None\n         od)\n       | _ \\<Rightarrow> return None\n   od\"\n\ntext \\<open>\n  A pointer is inside a user frame if its top bits point to a @{text DataPage}.\n\\<close>\ndefinition\n  in_user_frame :: \"word32 \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n  \"in_user_frame p s \\<equiv>\n   \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) =\n        Some (ArchObj (DataPage False sz))\"\n\ntext \\<open>Make numeric value of @{const msg_align_bits} visible.\\<close>\nlemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\nend\nend"}
{"title": "./spec/abstract/ARM/ArchVSpaceAcc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nAccessor functions for architecture specific parts of the specification.\n*)\n\nchapter \"Accessing the ARM VSpace\"\n\ntheory ArchVSpaceAcc_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This part of the specification is fairly concrete as the machine architecture\n  is visible to the user in seL4 and therefore needs to be described.\n  The abstraction compared to the implementation is in the data types for\n  kernel objects. The interface which is rich in machine details remains the same.\n\\<close>"}
{"title": "./spec/abstract/ARM/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The high bits of a virtual ASID.\\<close>\ndefinition\n  asid_high_bits_of :: \"asid \\<Rightarrow> 7 word\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"\n\nlocale_abbrev\n  \"asid_table \\<equiv> \\<lambda>s. arm_asid_table (arch_state s)\""}
{"title": "./spec/abstract/ARM/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Manipulate ASID pools, page directories and page tables in the kernel\nheap.\\<close>\n(* declared in Arch as workaround for VER-1099 *)\nlocale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\"\n  where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"\n\ndefinition\n  get_asid_pool :: \"obj_ref \\<Rightarrow> (10 word \\<rightharpoonup> obj_ref,'z::state_ext) s_monad\" where\n  \"get_asid_pool ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (ASIDPool pool) \\<Rightarrow> return pool\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_asid_pool :: \"obj_ref \\<Rightarrow> (10 word \\<rightharpoonup> obj_ref) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"set_asid_pool ptr pool \\<equiv> set_object ptr (ArchObj (arch_kernel_obj.ASIDPool pool))\"\n\ndefinition\n  get_pd :: \"obj_ref \\<Rightarrow> (12 word \\<Rightarrow> pde,'z::state_ext) s_monad\" where\n  \"get_pd ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageDirectory pd) \\<Rightarrow> return pd\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pd :: \"obj_ref \\<Rightarrow> (12 word \\<Rightarrow> pde) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pd ptr pd \\<equiv> set_object ptr (ArchObj (PageDirectory pd))\"\n\ndefinition\n  set_current_pd :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_current_pd pd \\<equiv> do\n     dsb;\n     writeTTBR0 ((pd && 0xffffe000) || 0x18);\n     isb\n   od\"\n\ntext \\<open>The following function takes a pointer to a PDE in kernel memory\n  and returns the actual PDE.\\<close>\ndefinition\n  get_pde :: \"obj_ref \\<Rightarrow> (pde,'z::state_ext) s_monad\" where\n  \"get_pde ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pd_bits);\n     offset \\<leftarrow> return ((ptr && mask pd_bits) >> 2);\n     pd \\<leftarrow> get_pd base;\n     return $ pd (ucast offset)\n   od\"\n\ndefinition\n  store_pde :: \"obj_ref \\<Rightarrow> pde \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pde p pde \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pd_bits);\n    offset \\<leftarrow> return ((p && mask pd_bits) >> 2);\n    pd \\<leftarrow> get_pd base;\n    pd' \\<leftarrow> return $ pd (ucast offset := pde);\n    set_pd base pd'\n  od\"\n\n\ndefinition\n  get_pt :: \"obj_ref \\<Rightarrow> (word8 \\<Rightarrow> pte,'z::state_ext) s_monad\" where\n  \"get_pt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pt :: \"obj_ref \\<Rightarrow> (word8 \\<Rightarrow> pte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pt ptr pt \\<equiv> set_object ptr (ArchObj (PageTable pt))\"\n\ntext \\<open>The following function takes a pointer to a PTE in kernel memory\n  and returns the actual PTE.\\<close>\ndefinition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> 2);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> 2);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\""}
{"title": "./spec/abstract/ARM/ArchVSpaceAcc_A.thy", "section": "Basic Operations", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The kernel window is mapped into every virtual address space from the\n@{term kernel_base} pointer upwards. This function copies the mappings which\ncreate the kernel window into a new page directory object.\\<close>\ndefinition\ncopy_global_mappings :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"copy_global_mappings new_pd \\<equiv> do\n    global_pd \\<leftarrow> gets (arm_global_pd \\<circ> arch_state);\n    pde_bits \\<leftarrow> return 2;\n    pd_size \\<leftarrow> return (1 << (pd_bits - pde_bits));\n    mapM_x (\\<lambda>index. do\n        offset \\<leftarrow> return (index << pde_bits);\n        pde \\<leftarrow> get_pde (global_pd + offset);\n        store_pde (new_pd + offset) pde\n    od) [kernel_base >> 20  .e.  pd_size - 1]\nod\"\n\ntext \\<open>Walk the page directories and tables in software.\\<close>\n\ntext \\<open>The following function takes a page-directory reference as well as\n  a virtual address and then computes a pointer to the PDE in kernel memory\\<close>\ndefinition\nlookup_pd_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> word32\" where\n\"lookup_pd_slot pd vptr \\<equiv>\n    let pd_index = vptr >> 20\n    in pd + (pd_index << 2)\"\n\ntext \\<open>The following function takes a page-directory reference as well as\n  a virtual address and then computes a pointer to the PTE in kernel memory.\n  Note that the function fails if the virtual address is mapped on a section or\n  super section.\\<close>\ndefinition\nlookup_pt_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"lookup_pt_slot pd vptr \\<equiv> doE\n    pd_slot \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    (case pde of\n          PageTablePDE ptab _ _ \\<Rightarrow>   (doE\n            pt \\<leftarrow> returnOk (ptrFromPAddr ptab);\n            pt_index \\<leftarrow> returnOk ((vptr >> 12) && 0xff);\n            pt_slot \\<leftarrow> returnOk (pt + (pt_index << 2));\n            returnOk pt_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability 20)\nodE\"\n\n\ntext \\<open>A non-failing version of @{const lookup_pt_slot} when the pd is already known\\<close>\ndefinition\n  lookup_pt_slot_no_fail :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> word32\"\nwhere\n  \"lookup_pt_slot_no_fail pt vptr \\<equiv>\n     let pt_index = ((vptr >> 12) && 0xff)\n     in pt + (pt_index << 2)\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM/ArchDecode_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDecoding system calls\n*)\n\nchapter \"Decoding Architecture-specific System Calls\"\n\ntheory ArchDecode_A\nimports\n  Interrupt_A\n  InvocationLabels_A\nbegin\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/ARM/ArchDecode_A.thy", "section": "Architecture calls", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition ensures that the given pointer is aligned\nto the given page size.\\<close>\n\ndefinition\n  check_vp_alignment :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $\n       throwError AlignmentError\"\n\ntext \\<open>This definition converts a user-supplied argument into an\ninvocation label, used to determine the method to invoke.\n\\<close>\n\ndefinition\n  label_to_flush_type :: \"invocation_label \\<Rightarrow> flush_type\"\nwhere\n  \"label_to_flush_type label \\<equiv> case label of\n       ArchInvocationLabel ARMPDClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPageClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPDInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPageInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPDCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPageCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPDUnify_Instruction \\<Rightarrow> Unify\n     | ArchInvocationLabel ARMPageUnify_Instruction \\<Rightarrow> Unify\""}
{"title": "./spec/abstract/ARM/ArchDecode_A.thy", "section": "Architecture calls", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition decodes architecture-specific invocations.\n\\<close>\n\ndefinition\n  page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\nwhere\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"\n\n\ndefinition\n  arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n\"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n\n  PageDirectoryCap _ _ \\<Rightarrow>\n    if isPDFlushLabel (invocation_type label) then\n    if length args > 1\n    then let start = args ! 0;\n             end = args ! 1\n    in doE\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            whenE (start \\<ge> kernel_base \\<or> end > kernel_base) $ throwError IllegalOperation;\n            (pd,asid) \\<leftarrow> (case cap of\n                    PageDirectoryCap pd (Some asid) \\<Rightarrow> returnOk (pd,asid)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 0);\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 0;\n            frame_info \\<leftarrow> liftE $ resolve_vaddr pd start;\n            case frame_info of\n                None \\<Rightarrow> returnOk $ InvokePageDirectory PageDirectoryNothing\n              | Some (frame_size, frame_base) \\<Rightarrow>\n                    let base_start = page_base start frame_size;\n                        base_end = page_base (end - 1) frame_size;\n                        offset = start && mask (pageBitsForSize frame_size);\n                        pstart = frame_base + offset\n                    in doE\n                        whenE (base_start \\<noteq> base_end) $ throwError $\n                            RangeError start (base_start + mask (pageBitsForSize frame_size));\n                        returnOk $ InvokePageDirectory $\n                            PageDirectoryFlush (label_to_flush_type (invocation_type label))\n                            start (end - 1) pstart pd asid\n                    odE\n    odE\n    else throwError TruncatedMessage\n    else throwError IllegalOperation\n\n| PageTableCap p mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageTableMap then\n    if length args > 1 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             attr = args ! 1;\n             pd_cap = fst (extra_caps ! 0)\n    in doE\n            whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            whenE (vaddr \\<ge> kernel_base) $ throwError $ InvalidArgument 0;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            pd_index \\<leftarrow> returnOk (shiftr vaddr 20);\n            vaddr' \\<leftarrow> returnOk (vaddr && ~~ mask 20);\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << 2));\n            oldpde \\<leftarrow> liftE $ get_master_pde pd_slot;\n            unlessE (oldpde = InvalidPDE) $ throwError DeleteFirst;\n            pde \\<leftarrow> returnOk (PageTablePDE (addrFromPPtr p)\n                               (attribs_from_word attr \\<inter> {ParityEnabled}) 0);\n            returnOk $ InvokePageTable $\n                PageTableMap\n                (ArchObjectCap $ PageTableCap p (Some (asid, vaddr')))\n                cte pde pd_slot\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageTableUnmap\n    then doE\n            final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n            unlessE final $ throwError RevokeFirst;\n            returnOk $ InvokePageTable $ PageTableUnmap (ArchObjectCap cap) cte\n    odE\n    else throwError IllegalOperation\n\n| PageCap dev p R pgsz mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageMap then\n    if length args > 2 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             rights_mask = args ! 1;\n             attr = args ! 2;\n             pd_cap = fst (extra_caps ! 0)\n        in doE\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            case mapped_address of\n              Some (asid', vaddr') \\<Rightarrow> doE\n                whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n                whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0)\n              odE\n            | None \\<Rightarrow> doE\n                vtop \\<leftarrow> returnOk (vaddr + (1 << (pageBitsForSize pgsz)) - 1);\n                whenE (vtop \\<ge> kernel_base) $ throwError $ InvalidArgument 0\n              odE;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            vm_rights \\<leftarrow> returnOk (mask_vm_rights R (data_to_rights rights_mask));\n            check_vp_alignment pgsz vaddr;\n            entries \\<leftarrow> create_mapping_entries (addrFromPPtr p)\n                                              vaddr pgsz vm_rights\n                                              (attribs_from_word attr) pd;\n            ensure_safe_mapping entries;\n            returnOk $ InvokePage $ PageMap asid\n                (ArchObjectCap $ PageCap dev p R pgsz (Some (asid, vaddr)))\n                cte entries\n        odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageUnmap\n    then  returnOk $ InvokePage $ PageUnmap cap cte\n    else if isPageFlushLabel (invocation_type label) then\n        if length args > 1\n        then let start = args ! 0;\n                 end = args ! 1\n        in doE\n            (asid, vaddr) \\<leftarrow> (case mapped_address of\n                Some a \\<Rightarrow> returnOk a\n              | _ \\<Rightarrow> throwError IllegalOperation);\n            pd \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            page_size \\<leftarrow> returnOk $ 1 << pageBitsForSize pgsz;\n            whenE (start \\<ge> page_size \\<or> end > page_size) $ throwError $ InvalidArgument 0;\n            returnOk $ InvokePage $ PageFlush\n                (label_to_flush_type (invocation_type label)) (start + vaddr)\n                (end + vaddr - 1) (addrFromPPtr p + start) pd asid\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageGetAddress\n    then returnOk $ InvokePage $ PageGetAddr p\n  else  throwError IllegalOperation\n\n| ASIDControlCap \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMASIDControlMakePool then\n    if length args > 1 \\<and> length extra_caps > 1\n    then let index = args ! 0;\n             depth = args ! 1;\n             (untyped, parent_slot) = extra_caps ! 0;\n             root = fst (extra_caps ! 1)\n         in doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            free_set \\<leftarrow> returnOk (- dom asid_table \\<inter> {x. x \\<le> 2 ^ asid_high_bits - 1});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n            base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n            (p,n) \\<leftarrow> (case untyped of UntypedCap False p n f \\<Rightarrow> returnOk (p,n)\n                                    | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            frame \\<leftarrow> (if n = pageBits\n                      then doE\n                        ensure_no_children parent_slot;\n                        returnOk p\n                      odE\n                      else  throwError $ InvalidCapability 1);\n            dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n            ensure_empty dest_slot;\n            returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n        odE\n    else  throwError TruncatedMessage\n    else  throwError IllegalOperation\n\n| ASIDPoolCap p base \\<Rightarrow>\n  if invocation_type label = ArchInvocationLabel ARMASIDPoolAssign then\n  if length extra_caps > 0\n  then\n    let (pd_cap, pd_cap_slot) = extra_caps ! 0\n     in case pd_cap of\n          ArchObjectCap (PageDirectoryCap _ None) \\<Rightarrow> doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n            whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n            whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n            pool \\<leftarrow> liftE $ get_asid_pool p;\n            free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n            returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pd_cap_slot\n          odE\n        | _ \\<Rightarrow>  throwError $ InvalidCapability 1\n  else  throwError TruncatedMessage\n  else  throwError IllegalOperation\"\n\n\ndefinition\n  arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n \"arch_data_to_obj_type n \\<equiv>\n  if n = 0 then Some PageDirectoryObj\n  else if n = 1 then Some SmallPageObj\n  else if n = 2 then Some LargePageObj\n  else if n = 3 then Some SectionObj\n  else if n = 4 then Some SuperSectionObj\n  else if n = 5 then Some PageTableObj\n  else None\"\n\ndefinition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> whenE (irq > maxIRQ) $ throwError (RangeError 0 maxIRQ)\"\n\ndefinition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n    (if invocation_type label = ArchInvocationLabel ARMIRQIssueIRQHandler\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n\n          returnOk $ ArchIRQControlIssue irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM/ArchInvocation_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch specific object invocations\n*)\n\nchapter \"ARM Object Invocations\"\n\ntheory ArchInvocation_A\nimports Structures_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>These datatypes encode the arguments to the various possible\nARM-specific system calls. Selectors are defined for various fields\nfor convenience elsewhere.\\<close>\n\ndatatype flush_type = Clean | Invalidate | CleanInvalidate | Unify\n\ndatatype page_directory_invocation =\n    PageDirectoryFlush (pd_flush_type: flush_type) (pd_flush_start: vspace_ref)\n                       (pd_flush_end: vspace_ref) (pd_flush_pstart: word32)\n                       (pd_flush_pd: obj_ref) (pd_flush_asid: asid)\n  | PageDirectoryNothing\n\ndatatype page_table_invocation =\n    PageTableMap cap cslot_ptr pde obj_ref\n  | PageTableUnmap cap cslot_ptr\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation\n     = PageMap\n         (page_map_asid: asid)\n         (page_map_cap: cap)\n         (page_map_ct_slot: cslot_ptr)\n         (page_map_entries: \"pte \\<times> (obj_ref list) + pde \\<times> (obj_ref list)\")\n     | PageUnmap\n         (page_unmap_cap: arch_cap)\n         (page_unmap_cap_slot: cslot_ptr)\n     | PageFlush\n         (page_flush_type: flush_type)\n         (page_flush_start: vspace_ref)\n         (page_flush_end: vspace_ref)\n         (page_flush_pstart: word32)\n         (page_flush_pd: obj_ref)\n         (page_flush_asid: asid)\n     | PageGetAddr\n         (page_get_paddr: obj_ref)\n\ndatatype arch_invocation\n     = InvokePageTable page_table_invocation\n     | InvokePageDirectory page_directory_invocation\n     | InvokePage page_invocation\n     | InvokeASIDControl asid_control_invocation\n     | InvokeASIDPool asid_pool_invocation\n\ndatatype arch_copy_register_sets = ARMNoExtraRegisters\n\ndefinition \"ArchDefaultExtraRegisters \\<equiv> ARMNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    ArchIRQControlIssue irq cslot_ptr cslot_ptr bool\n\nend\n\nend"}
{"title": "./spec/abstract/ARM/Arch_Structs_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nARM specific data types\n*)\n\nchapter \"ARM-Specific Data Types\"\n\ntheory Arch_Structs_A\nimports\n  \"ExecSpec.Arch_Structs_B\"\n  ExceptionTypes_A\n  VMRights_A\n  ExecSpec.Arch_Kernel_Config_Lemmas\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\nThis theory provides architecture-specific definitions and datatypes\nincluding architecture-specific capabilities and objects.\n\\<close>"}
{"title": "./spec/abstract/ARM/Arch_Structs_A.thy", "section": "Architecture-specific capabilities", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>An ASID is simply a word.\\<close>\ntype_synonym asid = \"word32\"\n\ndatatype vm_attribute = ParityEnabled | PageCacheable | Global | XNever\ntype_synonym vm_attributes = \"vm_attribute set\""}
{"title": "./spec/abstract/ARM/Arch_Structs_A.thy", "section": "Architecture-specific objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The ARM kernel supports capabilities for ASID pools and an ASID controller capability,\nalong with capabilities for page directories, page tables, and page mappings.\\<close>\n\ndatatype arch_cap =\n   ASIDPoolCap obj_ref asid\n | ASIDControlCap\n | PageCap bool obj_ref cap_rights vmpage_size \"(asid * vspace_ref) option\"\n | PageTableCap obj_ref \"(asid * vspace_ref) option\"\n | PageDirectoryCap obj_ref \"asid option\"\n\nlemmas arch_cap_cases =\n  arch_cap.induct[where arch_cap=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P, simplified, rule_format]\n\nlemmas arch_cap_cases_asm =\narch_cap.induct[where arch_cap=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n  simplified, rule_format, rotated -1]\n\ndefinition\n  is_page_cap :: \"arch_cap \\<Rightarrow> bool\" where\n  \"is_page_cap c \\<equiv> \\<exists>x0 x1 x2 x3 x4. c = PageCap x0 x1 x2 x3 x4\""}
{"title": "./spec/abstract/ARM/Arch_Structs_A.thy", "section": "Architecture-specific objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This section gives the types and auxiliary definitions for the\narchitecture-specific objects: a page directory entry (@{text \"pde\"})\ncontains either an invalid entry, a page table reference, a section\nreference, or a super-section reference; a page table entry contains\neither an invalid entry, a large page, or a small page mapping;\nfinally, an architecture-specific object is either an ASID pool, a\npage table, a page directory, or a data page used to model user\nmemory.\n\\<close>\n\ndatatype pde =\n   InvalidPDE\n | PageTablePDE obj_ref vm_attributes machine_word\n | SectionPDE obj_ref vm_attributes machine_word cap_rights\n | SuperSectionPDE obj_ref vm_attributes cap_rights\n\ndatatype pte =\n   InvalidPTE\n | LargePagePTE obj_ref vm_attributes cap_rights\n | SmallPagePTE obj_ref vm_attributes cap_rights\n\ndatatype arch_kernel_obj =\n   ASIDPool \"10 word \\<rightharpoonup> obj_ref\"\n | PageTable \"word8 \\<Rightarrow> pte\"\n | PageDirectory \"12 word \\<Rightarrow> pde\"\n | DataPage bool vmpage_size\n\nlemmas arch_kernel_obj_cases =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P,\n                         simplified, rule_format]\n\nlemmas arch_kernel_obj_cases_asm =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n                         simplified, rule_format, rotated -1]\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 4\"\n\nprimrec\n  arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\nwhere\n  \"arch_obj_size (ASIDPoolCap p as) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (PageCap dev x rs sz as4) = pageBitsForSize sz\"\n| \"arch_obj_size (PageDirectoryCap x as2) = 14\"\n| \"arch_obj_size (PageTableCap x as3) = 10\"\n\nprimrec\n  arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_cap_is_device (PageCap dev x rs sz as4) = dev\"\n| \"arch_cap_is_device ASIDControlCap = False\"\n| \"arch_cap_is_device (ASIDPoolCap p as) = False\"\n| \"arch_cap_is_device (PageTableCap x as3) = False\"\n| \"arch_cap_is_device (PageDirectoryCap x as2) = False\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 9\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 4\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 29\"\n\nprimrec\n  arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\nwhere\n  \"arch_kobj_size (ASIDPool p) = pageBits\"\n| \"arch_kobj_size (PageTable pte) = 10\"\n| \"arch_kobj_size (PageDirectory pde) = 14\"\n| \"arch_kobj_size (DataPage dev sz) = pageBitsForSize sz\"\n\nprimrec\n  aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\nwhere\n  \"aobj_ref (ASIDPoolCap p as) = Some p\"\n| \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref (PageCap dev x rs sz as4) = Some x\"\n| \"aobj_ref (PageDirectoryCap x as2) = Some x\"\n| \"aobj_ref (PageTableCap x as3) = Some x\"\n\nprimrec (nonexhaustive)\n  acap_rights :: \"arch_cap \\<Rightarrow> cap_rights\"\nwhere\n \"acap_rights (PageCap dev x rs sz as) = rs\"\n\ndefinition\n  acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n \"acap_rights_update rs ac \\<equiv> case ac of\n    PageCap dev x rs' sz as \\<Rightarrow> PageCap dev x (validate_vm_rights rs) sz as\n  | _                   \\<Rightarrow> ac\""}
{"title": "./spec/abstract/ARM/Arch_Structs_A.thy", "section": "Architecture-specific object types and default objects", "subsection": "", "subsubsection": "", "code": "\ndatatype\n  aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | SectionObj\n  | SuperSectionObj\n  | PageTableObj\n  | PageDirectoryObj\n  | ASIDPoolObj\n\ndefinition\n  arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\"\nwhere\n  \"arch_is_frame_type aobj \\<equiv> case aobj of\n         SmallPageObj \\<Rightarrow> True\n       | LargePageObj \\<Rightarrow> True\n       | SectionObj \\<Rightarrow> True\n       | SuperSectionObj \\<Rightarrow> True\n       | _ \\<Rightarrow> False\"\n\ndefinition\n  arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\" where\n \"arch_default_cap tp r n dev \\<equiv> case tp of\n  SmallPageObj \\<Rightarrow> PageCap dev r vm_read_write ARMSmallPage None\n  | LargePageObj \\<Rightarrow> PageCap dev r vm_read_write ARMLargePage None\n  | SectionObj \\<Rightarrow> PageCap dev r vm_read_write ARMSection None\n  | SuperSectionObj \\<Rightarrow> PageCap dev r vm_read_write ARMSuperSection None\n  | PageTableObj \\<Rightarrow> PageTableCap r None\n  | PageDirectoryObj \\<Rightarrow> PageDirectoryCap r None\n  | ASIDPoolObj \\<Rightarrow> ASIDPoolCap r 0\" (* unused *)\n\ndefinition\n  default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\" where\n \"default_arch_object tp dev n \\<equiv> case tp of\n    SmallPageObj \\<Rightarrow> DataPage dev ARMSmallPage\n  | LargePageObj \\<Rightarrow> DataPage dev ARMLargePage\n  | SectionObj \\<Rightarrow> DataPage dev ARMSection\n  | SuperSectionObj \\<Rightarrow> DataPage dev ARMSuperSection\n  | PageTableObj \\<Rightarrow> PageTable (\\<lambda>x. InvalidPTE)\n  | PageDirectoryObj \\<Rightarrow> PageDirectory (\\<lambda>x. InvalidPDE)\n  | ASIDPoolObj \\<Rightarrow> ASIDPool (\\<lambda>_. None)\"\n\ntype_synonym hw_asid = word8\n\ntype_synonym arm_vspace_region_uses = \"vspace_ref \\<Rightarrow> arm_vspace_region_use\""}
{"title": "./spec/abstract/ARM/Arch_Structs_A.thy", "section": "Architecture-specific state", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The architecture-specific state for the ARM model\nconsists of the first level of the ASID table (@{text \"arm_asid_table\"}), a\nmap from hardware ASIDs to seL4 ASIDs (@{text \"arm_hwasid_table\"}),\nthe next hardware ASID to preempt (@{text \"arm_next_asid\"}), the\ninverse map from seL4 ASIDs to hardware ASIDs (first component of\n@{text \"arm_asid_map\"}), and the address of the page directory and\npage tables mapping the shared address space, along with a description\nof this space (@{text \"arm_global_pd\"}, @{text \"arm_global_pts\"}, and\n@{text \"arm_kernel_vspace\"} respectively).\n\nHardware ASIDs are only ever associated with seL4 ASIDs that have a\ncurrently active page directory. The second component of\n@{text \"arm_asid_map\"} values is the address of that page directory.\n\\<close>\n\nend\n\nqualify ARM_A (in Arch)\n\nrecord arch_state =\n  arm_asid_table    :: \"7 word \\<rightharpoonup> obj_ref\"\n  arm_hwasid_table  :: \"ARM_A.hw_asid \\<rightharpoonup> ARM_A.asid\"\n  arm_next_asid     :: ARM_A.hw_asid\n  arm_asid_map      :: \"ARM_A.asid \\<rightharpoonup> (ARM_A.hw_asid \\<times> obj_ref)\"\n  arm_global_pd     :: obj_ref\n  arm_global_pts    :: \"obj_ref list\"\n  arm_kernel_vspace :: ARM_A.arm_vspace_region_uses\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  pd_bits :: \"nat\" where\n  \"pd_bits \\<equiv> pageBits + 2\"\n\ndefinition\n  pt_bits :: \"nat\" where\n  \"pt_bits \\<equiv> pageBits - 2\""}
{"title": "./spec/abstract/ARM/Arch_Structs_A.thy", "section": "Type declarations for invariant definitions", "subsection": "", "subsubsection": "", "code": "\ndatatype aa_type =\n    AASIDPool\n  | APageTable\n  | APageDirectory\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\"\nwhere\n \"aa_type ao \\<equiv> (case ao of\n           PageTable pt             \\<Rightarrow> APageTable\n         | PageDirectory pd         \\<Rightarrow> APageDirectory\n         | DataPage dev sz          \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n         | ASIDPool f               \\<Rightarrow> AASIDPool)\"\n\n\ntext \\<open>For implementation reasons the badge word has differing amounts of bits\\<close>\ndefinition\n  badge_bits :: nat where\n  badge_bits_def [simp]: \"badge_bits \\<equiv> 28\"\nend"}
{"title": "./spec/abstract/ARM/Arch_Structs_A.thy", "section": "Arch-specific tcb", "subsection": "", "subsubsection": "", "code": "\nqualify ARM_A (in Arch)\n\n(* arch specific part of tcb: this must have a field for user context *)\nrecord arch_tcb =\n tcb_context       :: user_context\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  default_arch_tcb :: arch_tcb where\n  \"default_arch_tcb \\<equiv> \\<lparr>\n      tcb_context    = new_context\\<rparr>\"\n\ntext \\<open>\n  Accessors for @{text \"tcb_context\"} inside @{text \"arch_tcb\"}. These are later used to\n  implement @{text as_user}, i.e.\\ need to be compatible with @{text user_monad}.\\<close>\ndefinition\n  arch_tcb_context_set :: \"user_context \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_context_set uc a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := uc \\<rparr>\"\n\ndefinition\n  arch_tcb_context_get :: \"arch_tcb \\<Rightarrow> user_context\"\nwhere\n  \"arch_tcb_context_get a_tcb \\<equiv> tcb_context a_tcb\"\n\n(* FIXME: the following means that we break the set/getRegister abstraction\n          and should move some of this into the machine interface (same as X64) *)\ntext \\<open>\n  Accessors for the user register part of the @{text \"arch_tcb\"}.\n  (Because @{typ \"register \\<Rightarrow> machine_word\"} might not be equal to @{typ user_context}).\\<close>\ndefinition\n  arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_set_registers regs a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := UserContext regs \\<rparr>\"\n\ndefinition\n  arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\"\nwhere\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM/ArchFault_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFunctions for fault handling.\n*)\n\nchapter \\<open>arch fault related functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData) od\"\n\ndefinition\n  handle_arch_fault_reply :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_arch_fault_reply vmf thread x y \\<equiv> return True\"\n\n\nend\n\nend"}
{"title": "./spec/abstract/ARM/ArchTcb_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"sanitise_register t r v \\<equiv> case r of\n      CPSR \\<Rightarrow> (v && 0xf8000000) || 0x150\n    | _    \\<Rightarrow> v\"\n\n\ndefinition\n  arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\nwhere\n  \"arch_get_sanitise_register_info t \\<equiv> return False\"\n\ndefinition\n  arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\nwhere\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend"}
{"title": "./spec/abstract/ARM/ArchCSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"ArchCSpace\"\n\ntheory ArchCSpace_A\nimports\n  ArchVSpace_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition cnode_guard_size_bits :: \"nat\"\nwhere\n  cnode_guard_size_bits_def [simp]: \"cnode_guard_size_bits \\<equiv> 5\"\n\ndefinition cnode_padding_bits :: \"nat\"\nwhere\n  cnode_padding_bits_def [simp]: \"cnode_padding_bits \\<equiv> 3\"\n\ntext \\<open>On a user request to modify a cnode capability, extract new guard bits and guard.\\<close>\ndefinition\n  update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 18;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"\n\ntext \\<open>For some purposes capabilities to physical objects are treated\ndifferently to others.\\<close>\ndefinition\n  arch_is_physical :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_is_physical cap \\<equiv> case cap of ASIDControlCap \\<Rightarrow> False | _ \\<Rightarrow> True\"\n\ntext \\<open>Check whether the second capability is to the same object or an object\ncontained in the region of the first one.\\<close>\nfun\n  arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_same_region_as (PageCap dev r R s x) (PageCap dev' r' R' s' x') =\n   (let\n     topA = r + (1 << pageBitsForSize s) - 1;\n     topB = r' + (1 << pageBitsForSize s') - 1\n   in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB)\"\n| \"arch_same_region_as (PageTableCap r x) (PageTableCap r' x') = (r' = r)\"\n| \"arch_same_region_as (PageDirectoryCap r x) (PageDirectoryCap r' x') = (r' = r)\"\n| \"arch_same_region_as ASIDControlCap ASIDControlCap = True\"\n| \"arch_same_region_as (ASIDPoolCap r a) (ASIDPoolCap r' a') = (r' = r)\"\n| \"arch_same_region_as _ _ = False\"\n\n\ntext \\<open>Check whether two arch capabilities are to the same object.\\<close>\ndefinition\n  same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n \"same_aobject_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (PageCap dev ref _ pgsz _,PageCap dev' ref' _ pgsz' _)\n          \\<Rightarrow> (dev, ref, pgsz) = (dev', ref', pgsz')\n              \\<and> ref \\<le> ref + 2 ^ pageBitsForSize pgsz - 1\n    | _ \\<Rightarrow> arch_same_region_as cp cp')\"\n\n(* Proofs don't want to see this definition *)\ndeclare same_aobject_as_def[simp]\n\ndefinition\n  arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"arch_is_cap_revocable c c' \\<equiv> False\"\n\nend\nend"}
{"title": "./spec/abstract/ARM/Machine_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nTypes and operations to access the underlying machine, instantiated\nfor ARM.\n*)\n\nchapter \"ARM Machine Instantiation\"\n\ntheory Machine_A\nimports\n  \"ExecSpec.MachineOps\"\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  The specification is written with abstract type names for object\n  references, user pointers, word-based data, cap references, and so\n  on. This theory provides an instantiation of these names to concrete\n  types for the ARM architecture. Other architectures may have slightly\n  different instantiations.\n\\<close>\ntype_synonym obj_ref            = machine_word\ntype_synonym vspace_ref         = machine_word\n\ntype_synonym data               = machine_word\ntype_synonym cap_ref            = \"bool list\"\ntype_synonym length_type        = machine_word\n\ntype_synonym asid_low_len       = 10\ntype_synonym asid_low_index    = \"asid_low_len word\"\n\ntype_synonym asid_high_len      = 7\ntype_synonym asid_high_index    = \"asid_high_len word\"\n\n(* It might be nice if asid was \"17 word\", but Refine is easier if it is a machine_word.  *)\n(* Making asid a machine_word means that we need invariants that the extra bits are zero. *)\ntype_synonym asid_len           = 17\ntype_synonym asid_rep_len       = machine_word_len\ntype_synonym asid               = \"asid_rep_len word\"\n\ntext \\<open>With the definitions above, most conversions between abstract\ntype names boil down to just the identity function, some convert from\n@{text word} to @{typ nat} and others between different word sizes\nusing @{const ucast}.\\<close>\ndefinition\n  oref_to_data   :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_oref   :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition\n  vref_to_data   :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_vref   :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition\n  nat_to_len     :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition\n  data_to_nat    :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition\n  data_to_16     :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition\n  data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition\n  combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition\n  combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"\n\n\ntext \\<open>These definitions will be unfolded automatically in proofs.\\<close>\nlemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def\n\n\ntext \\<open>The following definitions provide architecture-dependent sizes\n  such as the standard page size and capability size of the underlying\n  machine.\n\\<close>\ndefinition\n  slot_bits :: nat where\n  \"slot_bits \\<equiv> 4\"\n\ndefinition\n  msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 20\"\n\ndefinition\n  new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext ((\\<lambda>r. 0) (CPSR := 0x150))\"\n\ntext \\<open>The lowest virtual address in the kernel window. The kernel reserves the\nvirtual addresses from here up in every virtual address space.\\<close>\ndefinition\n  kernel_base :: \"vspace_ref\" where\n  \"kernel_base \\<equiv> 0xe0000000\"\n\ndefinition\n  idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = kernel_base + 0x1000\"\n\nend\n\narch_requalify_consts (A) kernel_base idle_thread_ptr\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>Miscellaneous definitions of constants used in modelling machine\noperations.\\<close>\n\ndefinition\n  nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\" where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len)\n                           (to_bl (of_nat n :: machine_word))\"\n\ndefinition\n \"msg_info_register \\<equiv> msgInfoRegister\"\ndefinition\n \"msg_registers \\<equiv> msgRegisters\"\ndefinition\n \"cap_register \\<equiv> capRegister\"\ndefinition\n \"badge_register \\<equiv> badgeRegister\"\ndefinition\n \"frame_registers \\<equiv> frameRegisters\"\ndefinition\n \"gp_registers \\<equiv> gpRegisters\"\ndefinition\n \"exception_message \\<equiv> exceptionMessage\"\ndefinition\n \"syscall_message \\<equiv> syscallMessage\"\n\ndatatype arch_fault\n    = VMFault vspace_ref \"machine_word list\"\n\nend\n\nend"}
{"title": "./spec/abstract/X64/ArchInterrupt_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFormalisation of interrupt handling.\n*)\n\nchapter \"Arch-specific Interrupts\"\n\ntheory ArchInterrupt_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition handle_reserved_irq :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where \"handle_reserved_irq irq = return ()\"\n\nfun arch_invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_invoke_irq_handler (ACKIrq irq) = (do_machine_op $ maskInterrupt False irq)\"\n| \"arch_invoke_irq_handler _ = return ()\"\n\ndefinition arch_mask_irq_signal :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_mask_irq_signal irq \\<equiv> do_machine_op $ maskInterrupt True irq\"\n\nend\n\n(* On Arm architectures, maxIRQ is defined in Kernel_Config. On X64 it is defined manually. *)\narch_requalify_consts\n  maxIRQ\n\nend"}
{"title": "./spec/abstract/X64/Arch_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nEntry point for architecture dependent definitions.\n*)\n\nchapter \"Toplevel x64 Definitions\"\n\ntheory Arch_A\nimports TcbAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition \"page_bits \\<equiv> pageBits\"\n\ndefinition\n  updateIRQState :: \"irq \\<Rightarrow> X64IRQState \\<Rightarrow> ('a abstract_state_scheme, unit) nondet_monad\" where\n  \"updateIRQState irq irqState \\<equiv> do\n     irq_states \\<leftarrow> gets (x64_irq_state o arch_state);\n     modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>x64_irq_state := irq_states (irq := irqState)\\<rparr>\\<rparr>)\n  od\"\n\ndefinition\n  arch_invoke_irq_control :: \"arch_irq_control_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n  \"arch_invoke_irq_control aic \\<equiv> (case aic of\n    IssueIRQHandlerIOAPIC irq dest src ioapic pin level polarity vector \\<Rightarrow> without_preemption (do\n      do_machine_op $ ioapicMapPinToVector ioapic pin level polarity vector;\n      irq_state \\<leftarrow> return $ IRQIOAPIC (ioapic && mask 5) (pin && mask 5) (level && 1) (polarity && 1) True;\n      updateIRQState irq irq_state;\n      set_irq_state IRQSignal (IRQ irq);\n      cap_insert (IRQHandlerCap (IRQ irq)) src dest\n    od) |\n    IssueIRQHandlerMSI irq dest src bus dev func handle \\<Rightarrow> without_preemption (do\n      irq_state \\<leftarrow> return $ IRQMSI (bus && mask 8) (dev && mask 5) (func && mask 3) (handle && mask 32);\n      updateIRQState irq irq_state;\n      set_irq_state IRQSignal (IRQ irq);\n      cap_insert (IRQHandlerCap (IRQ irq)) src dest\n    od)\n   )\"\n\ntext \\<open>Switch to a thread's virtual address space context.\\<close>\n\ndefinition\n  arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> set_vm_root t\"\n\ndefinition\n   arch_switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n   \"arch_switch_to_idle_thread \\<equiv> do\n     thread \\<leftarrow> gets idle_thread;\n     set_vm_root thread\n   od\"\n\ndefinition\n  arch_activate_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_activate_idle_thread t \\<equiv> return ()\"\n\ndefinition\n  \"store_asid_pool_entry pool_ptr asid pml4base \\<equiv> do\n    pool \\<leftarrow> get_asid_pool pool_ptr;\n    pool' \\<leftarrow> return (pool(asid_low_bits_of asid := pml4base));\n    set_asid_pool pool_ptr pool'\n  od\"\n\ntext \\<open>The ASIDControl capability confers the authority to create a new ASID\npool object. This operation creates the new ASID pool, provides a capability\nto it and connects it to the global virtual ASID table.\\<close>\ndefinition\nperform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_control_invocation iv \\<equiv> case iv of\n  MakePool frame slot parent base \\<Rightarrow> do\n    delete_objects frame page_bits;\n    pcap \\<leftarrow> get_cap parent;\n    set_cap (max_free_index_update pcap) parent;\n    retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n    cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n    assert (asid_low_bits_of base = 0);\n    asid_table \\<leftarrow> gets (x64_asid_table \\<circ> arch_state);\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n    modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>x64_asid_table := asid_table'\\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>The ASIDPool capability confers the authority to assign a virtual ASID\nto a page directory.\\<close>\ndefinition\nperform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_pool_invocation iv \\<equiv> case iv of Assign asid pool_ptr ct_slot \\<Rightarrow>\ndo\n    pml4_cap \\<leftarrow> get_cap ct_slot;\n    case pml4_cap of\n      ArchObjectCap (PML4Cap pml4_base _) \\<Rightarrow> do\n        set_cap (ArchObjectCap $ PML4Cap pml4_base (Some asid)) ct_slot;\n        store_asid_pool_entry pool_ptr asid (Some pml4_base)\n      od\n    | _ \\<Rightarrow> fail\nod\"\n\n\ndefinition\n  pte_check_if_mapped :: \"obj_ref \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pte_check_if_mapped slot \\<equiv> do\n     pt \\<leftarrow> get_pte slot;\n     return (pt \\<noteq> InvalidPTE)\n  od\"\n\ndefinition\n  pde_check_if_mapped :: \"obj_ref \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pde_check_if_mapped slot \\<equiv> do\n     pd \\<leftarrow> get_pde slot;\n     return (pd \\<noteq> InvalidPDE)\n  od\"\n\ndefinition\n  perform_page_invocation_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_page_invocation_unmap cap ct_slot \\<equiv>\n      (case cap\n         of PageCap dev base rights map_type sz mapped \\<Rightarrow> do\n            case mapped of Some (asid, vaddr) \\<Rightarrow> unmap_page sz asid vaddr base\n                          | None \\<Rightarrow> return ();\n            cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n            set_cap (ArchObjectCap $ update_map_data cap None (Some VMNoMap)) ct_slot\n          od\n      | _ \\<Rightarrow> fail)\"\n\ntext \\<open>The Page capability confers the authority to map, unmap and flush the\n  memory page.\\<close>\ndefinition\nperform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n\"perform_page_invocation iv \\<equiv> case iv of\n    PageMap cap ct_slot entries vspace \\<Rightarrow> do\n      set_cap cap ct_slot;\n      case entries of\n          (VMPTE pte, slot) \\<Rightarrow> store_pte slot pte\n        | (VMPDE pde, slot) \\<Rightarrow> store_pde slot pde\n        | (VMPDPTE pdpte, slot) \\<Rightarrow> store_pdpte slot pdpte;\n      asid \\<leftarrow> case cap of\n                  ArchObjectCap (PageCap _ _ _ _ _ (Some (as, _))) \\<Rightarrow> return as\n                | _ \\<Rightarrow> fail;\n      invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid;\n      return []\n    od\n  | PageUnmap cap ct_slot \\<Rightarrow>\n      (case cap of\n        PageCap dev base rights map_type sz mapped \\<Rightarrow> do\n            case mapped of\n              Some _ \\<Rightarrow> (case map_type of\n                          VMVSpaceMap \\<Rightarrow> perform_page_invocation_unmap cap ct_slot\n                        | _ \\<Rightarrow> fail)\n            | None \\<Rightarrow> return ();\n            return []\n        od\n      | _ \\<Rightarrow> fail)\n\\<^cancel>\\<open>| PageIOMap asid cap ct_slot entries \\<Rightarrow> undefined\\<close>\n  | PageGetAddr ptr \\<Rightarrow>\n      return [addrFromPPtr ptr]\"\n\ntext \\<open>PageTable capabilities confer the authority to map and unmap page tables.\\<close>\ndefinition\nperform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_table_invocation iv \\<equiv>\ncase iv of PageTableMap cap ct_slot pde pd_slot vspace \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pde pd_slot pde;\n    asid <- case cap of ArchObjectCap (PageTableCap  _ (Some (as, _))) \\<Rightarrow> return as\n            | _ \\<Rightarrow> fail;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\n  | PageTableUnmap (ArchObjectCap (PageTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_page_table asid vaddr p;\n      pte_bits \\<leftarrow> return word_size_bits;\n      slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 <<  pt_bits) - 1];\n      mapM_x (swp store_pte InvalidPTE) slots\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"\n\ntext \\<open>PageDirectory capabilities confer the authority to map and unmap page\ntables.\\<close>\ndefinition\nperform_page_directory_invocation :: \"page_directory_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_directory_invocation iv \\<equiv>\ncase iv of PageDirectoryMap cap ct_slot pdpte pdpt_slot vspace \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pdpte pdpt_slot pdpte;\n    asid <- case cap of ArchObjectCap (PageDirectoryCap _ (Some (as, _))) \\<Rightarrow> return as\n            | _ \\<Rightarrow> fail;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\n  | PageDirectoryUnmap (ArchObjectCap (PageDirectoryCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_pd asid vaddr p;\n      pde_bits \\<leftarrow> return word_size_bits;\n      slots \\<leftarrow> return [p, p + (1 << pde_bits) .e. p + (1 << pd_bits) - 1];\n      mapM_x (swp store_pde InvalidPDE) slots\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"\n\ntext \\<open>PageDirectory capabilities confer the authority to map and unmap page\ntables.\\<close>\ndefinition\nperform_pdpt_invocation :: \"pdpt_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_pdpt_invocation iv \\<equiv>\ncase iv of PDPTMap cap ct_slot pml4e pml4_slot vspace \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pml4e pml4_slot pml4e;\n    asid <- case cap of ArchObjectCap (PDPointerTableCap _ (Some (as, _))) \\<Rightarrow> return as\n            | _ \\<Rightarrow> fail;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\n  | PDPTUnmap (ArchObjectCap (PDPointerTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_pdpt asid vaddr p;\n      pdept_bits \\<leftarrow> return word_size_bits;\n      slots \\<leftarrow> return [p, p + (1 << pdept_bits) .e. p + (1 << pdpt_bits) - 1];\n      mapM_x (swp store_pdpte InvalidPDPTE) slots\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"\n\ndefinition\n  port_out :: \"('a word \\<Rightarrow> unit machine_monad) \\<Rightarrow> ('a word) \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"port_out f w = do\n    do_machine_op $ f w;\n    return []\n  od\"\n\ndefinition\n  port_in :: \"(data machine_monad) \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"port_in f = do\n    res \\<leftarrow> do_machine_op f;\n    return [res]\n  od\"\n\ndefinition\n  perform_io_port_invocation :: \"io_port_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_io_port_invocation i \\<equiv> (\n    case i of (IOPortInvocation port port_data) \\<Rightarrow> (\n      case port_data of\n        IOPortIn8 \\<Rightarrow> port_in (in8 port)\n      | IOPortIn16 \\<Rightarrow> port_in (in16 port)\n      | IOPortIn32 \\<Rightarrow> port_in (in32 port)\n      | IOPortOut8 w \\<Rightarrow> port_out (out8 port) w\n      | IOPortOut16 w \\<Rightarrow> port_out (out16 port) w\n      | IOPortOut32 w \\<Rightarrow> port_out (out32 port) w\n    )\n    )\"\n\ndefinition\n  perform_ioport_control_invocation :: \"io_port_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_ioport_control_invocation i \\<equiv>\n    case i of (IOPortControlInvocation f l dest_slot control_slot) \\<Rightarrow> do\n      set_ioport_mask f l True;\n      c \\<leftarrow> return $ ArchObjectCap $ IOPortCap f l;\n      cap_insert (ArchObjectCap (IOPortCap f l)) control_slot dest_slot\n    od\"\n\nabbreviation\n  arch_no_return :: \"(unit, 'z::state_ext) s_monad \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\nwhere\n  \"arch_no_return oper \\<equiv> do oper; return [] od\"\n\ntext \\<open>Top level system call despatcher for all x64-specific system calls.\\<close>\ndefinition\n  arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\" where\n  \"arch_perform_invocation i \\<equiv> liftE $\n    case i of\n          InvokePageTable oper \\<Rightarrow> arch_no_return $ perform_page_table_invocation oper\n        | InvokePageDirectory oper \\<Rightarrow> arch_no_return $ perform_page_directory_invocation oper\n        | InvokePDPT oper \\<Rightarrow> arch_no_return $ perform_pdpt_invocation oper\n        | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n        | InvokeASIDControl oper \\<Rightarrow> arch_no_return $ perform_asid_control_invocation oper\n        | InvokeASIDPool oper \\<Rightarrow> arch_no_return $ perform_asid_pool_invocation oper\n        | InvokeIOPort oper \\<Rightarrow> perform_io_port_invocation oper\n        | InvokeIOPortControl oper \\<Rightarrow> arch_no_return $ perform_ioport_control_invocation oper\"\n\nend\nend"}
{"title": "./spec/abstract/X64/Hypervisor_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Handle Hyperviser Fault Event\"\n\ntheory Hypervisor_A\nimports Exceptions_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"machine_word \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n\"handle_hypervisor_fault thread X64NoHypFaults = return ()\"\n\n\nend\nend"}
{"title": "./spec/abstract/X64/ArchRetype_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nRetyping and untyped invocation\n*)\n\nchapter \"Retyping and Untyped Invocations\"\n\ntheory ArchRetype_A\nimports\n  ArchVSpaceAcc_A\n  ArchInvocation_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>This is a placeholder function. We may wish to extend the specification\n  with explicitly tagging kernel data regions in memory.\\<close>\ndefinition\n  reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"\n\ntext \\<open>Initialise architecture-specific objects.\\<close>\n\ndefinition\n  init_arch_objects :: \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list\n   \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs\n    \\<equiv> when (new_type = ArchObject PML4Obj) (mapM_x copy_global_mappings refs)\"\n\ndefinition\n  empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0) (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context \\<rparr>\"\n\nend\nend"}
{"title": "./spec/abstract/X64/ArchIpcCancel_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch Functions for cancelling IPC.\n*)\n\nchapter \\<open>Arch IPC Cancelling\\<close>\n\ntheory ArchIpcCancel_A\nimports CSpaceAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  set_ioport_mask :: \"io_port \\<Rightarrow> io_port \\<Rightarrow> bool \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"set_ioport_mask f l val \\<equiv> do\n    allocated_ports \\<leftarrow> gets (x64_allocated_io_ports \\<circ> arch_state);\n    ap' \\<leftarrow> return (\\<lambda>p. if p \\<ge> f \\<and> p \\<le> l then val else allocated_ports p);\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> x64_allocated_io_ports := ap' \\<rparr>\\<rparr>)\n  od\"\n\ndefinition\n  free_ioport_range :: \"io_port \\<Rightarrow> io_port \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"free_ioport_range f l \\<equiv> set_ioport_mask f l False\"\n\ntext \\<open>Actions to be taken after a cap is deleted\\<close>\ndefinition\n  arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arch_post_cap_deletion ac \\<equiv> case ac of\n       IOPortCap f l \\<Rightarrow> free_ioport_range f l\n     | _ \\<Rightarrow> return ()\"\n\ntext \\<open>Arch specific generic object references not covered by generic references\\<close>\ndatatype arch_gen_obj_ref = IOPortRef io_port\n\ndefinition\n  arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\"\nwhere\n  \"arch_gen_obj_refs ac \\<equiv> case ac of\n      IOPortCap f l \\<Rightarrow> IOPortRef ` {f}\n    | _ \\<Rightarrow> {}\"\n\ndefinition\n  arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_cap_cleanup_opt ac \\<equiv> case ac of IOPortCap f l \\<Rightarrow> ArchObjectCap (IOPortCap f l) | _ \\<Rightarrow> NullCap\"\n\nend\nend"}
{"title": "./spec/abstract/X64/Init_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDummy initial kernel state. Real kernel boot up is more complex.\n*)\n\nchapter \"An Initial Kernel State\"\n\ntheory Init_A\nimports Retype_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This is not a specification of true kernel\n  initialisation. This theory describes a dummy initial state only, to\n  show that the invariants and refinement relation are consistent.\n\\<close>\n\n(* 8KiB *)\ndefinition\n  init_irq_node_ptr :: obj_ref where\n  \"init_irq_node_ptr = kernel_base + 0x2000\"\n\n(* 4KiB *)\ndefinition\n  init_global_pml4 :: obj_ref where\n  \"init_global_pml4 = kernel_base + 0x4000\"\n\n(* 4KiB *)\ndefinition\n  init_global_pdpt :: obj_ref where\n  \"init_global_pdpt = kernel_base + 0x5000\"\n\n(* 4KiB *)\ndefinition\n  init_global_pd :: obj_ref where\n  \"init_global_pd = kernel_base + 0x6000\"\n\ndefinition\n  \"init_arch_state \\<equiv> \\<lparr>\n    x64_asid_table = Map.empty,\n    x64_global_pml4 = init_global_pml4,\n    x64_kernel_vspace =\n      \\<lambda>ref. if ref \\<in> {pptr_base .. pptr_base + mask pml4_shift_bits}\n              then X64VSpaceKernelWindow\n              else X64VSpaceInvalidRegion,\n    x64_global_pts = [],\n    x64_global_pdpts = [init_global_pdpt],\n    x64_global_pds = [init_global_pd],\n    x64_current_cr3 = cr3 0 0,\n    x64_allocated_io_ports = \\<lambda>_. False,\n    x64_num_ioapics = 1,\n    x64_ioapic_nirqs = \\<lambda>_. ucast ioapicIRQLines,\n    x64_irq_state = K IRQFree\n   \\<rparr>\"\n\ndefinition [simp]:\n  \"global_pml4 \\<equiv> (\\<lambda>_ :: 9 word. InvalidPML4E)\n    (0x1FF := PDPointerTablePML4E (addrFromPPtr init_global_pdpt) {} {})\"\n\n(* The kernel uses huge page mappings in the global PDPT to get a view of all physical memory.\n   The exception is the upper-most PDPT entry, which maps to the global page directory. *)\ndefinition [simp]:\n  \"global_pdpt \\<equiv> (\\<lambda> i :: 9 word. HugePagePDPTE (ucast i << 30) {} {})\n                    (0x1FF := PageDirectoryPDPTE (addrFromPPtr init_global_pd) {} {})\"\n\n(* C kernel initialisation refines this down to small pages for devices, but we'll stop here. *)\ndefinition [simp]:\n  \"global_pd \\<equiv> (\\<lambda> i :: 9 word. LargePagePDE (0x03FE00 + ucast i << 21) {} {})\"\n\ndefinition\n  \"init_kheap \\<equiv>\n    (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n           then Some (CNode 0 (empty_cnode 0))\n           else None)\n    (idle_thread_ptr \\<mapsto>\n       TCB \\<lparr>\n         tcb_ctable = NullCap,\n         tcb_vtable = NullCap,\n         tcb_reply = NullCap,\n         tcb_caller = NullCap,\n         tcb_ipcframe = NullCap,\n         tcb_state = IdleThreadState,\n         tcb_fault_handler = replicate word_bits False,\n         tcb_ipc_buffer = 0,\n         tcb_fault = None,\n         tcb_bound_notification = None,\n         tcb_mcpriority = minBound,\n         tcb_arch = init_arch_tcb\n         \\<rparr>,\n     init_global_pml4 \\<mapsto> ArchObj (PageMapL4 global_pml4),\n     init_global_pdpt \\<mapsto> ArchObj (PDPointerTable global_pdpt),\n     init_global_pd \\<mapsto> ArchObj (PageDirectory global_pd)\n    )\"\n\ndefinition\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. Structures_A.IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\nend"}
{"title": "./spec/abstract/X64/ArchVSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nHigher level functions for manipulating virtual address spaces\n*)\n\nchapter \"x64 VSpace Functions\"\n\ntheory ArchVSpace_A\nimports Retype_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\ntext \\<open>\n  These attributes are always set to @{const False} when pages are mapped.\n\\<close>\ndefinition\n  \"attr_mask = {Global,Dirty,PTAttr Accessed,PTAttr ExecuteDisable}\"\n\ndefinition\n  \"attr_mask' = attr_mask \\<union> {PAT}\"\n\ntext \\<open>Save the set of entries that would be inserted into a page table or\npage directory to map various different sizes of frame at a given virtual\naddress.\\<close>\nprimrec create_mapping_entries ::\n  \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vm_rights \\<Rightarrow> frame_attrs \\<Rightarrow> obj_ref \\<Rightarrow>\n  (vm_page_entry * obj_ref,'z::state_ext) se_monad\"\nwhere\n  \"create_mapping_entries base vptr X64SmallPage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ (VMPTE (SmallPagePTE base (attrib - attr_mask) vm_rights), p)\n  odE\"\n\n| \"create_mapping_entries base vptr X64LargePage vm_rights attrib pdpt =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pd_slot pdpt vptr;\n    returnOk $ (VMPDE (LargePagePDE base (attrib - attr_mask) vm_rights), p)\n  odE\"\n\n| \"create_mapping_entries base vptr X64HugePage vm_rights attrib pml4 =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pdpt_slot pml4 vptr;\n    returnOk $ (VMPDPTE (HugePagePDPTE base (attrib - attr_mask') vm_rights), p)\n  odE\"\n\n\ntext \\<open>This function checks that given entries are either invalid entries (for unmapping)\nor replace invalid entries (for mapping).\\<close>\nfun ensure_safe_mapping ::\n  \"(vm_page_entry * obj_ref) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n\"ensure_safe_mapping (VMPTE InvalidPTE, _) = returnOk ()\"\n|\n\"ensure_safe_mapping (VMPDE InvalidPDE, _) = returnOk ()\"\n|\n\"ensure_safe_mapping (VMPDPTE InvalidPDPTE, _) = returnOk ()\"\n|\n\"ensure_safe_mapping (VMPTE (SmallPagePTE _ _ _), pt_slot) = returnOk ()\"\n|\n\"ensure_safe_mapping (VMPDE (LargePagePDE _ _ _), pd_slot) =\n    doE\n        pde \\<leftarrow> liftE $ get_pde pd_slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | LargePagePDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE\"\n|\n\"ensure_safe_mapping (VMPDPTE (HugePagePDPTE _ _ _), pdpt_slot) =\n    doE\n        pdpt \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n        (case pdpt of\n              InvalidPDPTE \\<Rightarrow> returnOk ()\n            | HugePagePDPTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE\"\n|\n\"ensure_safe_mapping (VMPDE (PageTablePDE _ _ _), _) = fail\"\n|\n\"ensure_safe_mapping (VMPDPTE (PageDirectoryPDPTE _ _ _), _) = fail\"\n\ntext \\<open>Look up a thread's IPC buffer and check that the thread has the right\nauthority to read or (in the receiver case) write to it.\\<close>\ndefinition\nlookup_ipc_buffer :: \"bool \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n\"lookup_ipc_buffer is_receiver thread \\<equiv> do\n    buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n    buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n    buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n    (case buffer_cap of\n      ArchObjectCap (PageCap _ p R _ vms _) \\<Rightarrow>\n        if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n        then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n        else return None\n    | _ \\<Rightarrow> return None)\nod\"\n\ntext \\<open>Locate the page directory associated with a given virtual ASID.\\<close>\ndefinition\nfind_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"find_vspace_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (x64_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pml4 \\<leftarrow> returnOk (pool (asid_low_bits_of asid));\n    (case pml4 of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"\n\n\ntext \\<open>Locate the page directory and check that this process succeeds and\nreturns a pointer to a real page directory.\\<close>\ndefinition\nfind_vspace_for_asid_assert :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) s_monad\" where\n\"find_vspace_for_asid_assert asid \\<equiv> do\n   pml4 \\<leftarrow> find_vspace_for_asid asid <catch> K fail;\n   get_pml4 pml4;\n   return pml4\n od\"\n\ntext \\<open>Format a VM fault message to be passed to a thread's supervisor after\nit encounters a page fault.\\<close>\ndefinition\nhandle_vm_fault :: \"obj_ref \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n\"handle_vm_fault thread fault_type = doE\n    addr \\<leftarrow> liftE $ do_machine_op getFaultAddress;\n    fault \\<leftarrow> liftE $ as_user thread $ getRegister ErrorRegister;\n    case fault_type of\n        X64DataFault \\<Rightarrow> throwError $ ArchFault $ VMFault addr [0, fault && mask 5]\n      | X64InstructionFault \\<Rightarrow> throwError $ ArchFault $ VMFault addr [1, fault && mask 5]\nodE\"\n\ndefinition\n  get_current_cr3 :: \"(cr3, 'z::state_ext) s_monad\"\nwhere\n  \"get_current_cr3 \\<equiv> gets (x64_current_cr3 \\<circ> arch_state)\"\n\ndefinition\n  set_current_cr3 :: \"cr3 \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_current_cr3 c \\<equiv>\n     modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>x64_current_cr3 := c\\<rparr>\\<rparr>)\"\n\ndefinition\n  invalidate_page_structure_cache_asid :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"invalidate_page_structure_cache_asid vspace asid \\<equiv>\n     do_machine_op $ invalidateLocalPageStructureCacheASID vspace (ucast asid)\"\n\ndefinition\n  getCurrentVSpaceRoot :: \"(obj_ref, 'z::state_ext) s_monad\"\nwhere\n  \"getCurrentVSpaceRoot \\<equiv> do\n      cur \\<leftarrow> get_current_cr3;\n      return $ cr3_base_address cur\n   od\"\n\ndefinition\n  \"cr3_addr_mask \\<equiv> mask pml4_shift_bits << asid_bits\"\n\ndefinition\n  make_cr3 :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> cr3\"\nwhere\n  \"make_cr3 vspace asid \\<equiv> cr3 (vspace && cr3_addr_mask) asid\"\n\ndefinition\n  set_current_vspace_root :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"set_current_vspace_root vspace asid \\<equiv> set_current_cr3 $ make_cr3 vspace asid\"\n\ntext \\<open>Switch into the address space of a given thread or the global address\nspace if none is correctly configured.\\<close>\ndefinition\n  set_vm_root :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PML4Cap pml4 (Some asid)) \\<Rightarrow> doE\n           pml4' \\<leftarrow> find_vspace_for_asid asid;\n           whenE (pml4 \\<noteq> pml4') $ throwError InvalidRoot;\n           cur_cr3 \\<leftarrow> liftE $ get_current_cr3;\n           whenE (cur_cr3 \\<noteq> make_cr3 (addrFromPPtr pml4) asid) $\n              liftE $ set_current_cr3 $ make_cr3 (addrFromPPtr pml4) asid\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_pml4 \\<leftarrow> gets (x64_global_pml4 \\<circ> arch_state);\n       set_current_vspace_root (addrFromKPPtr global_pml4) 0\n    od)\nod\"\n\ntext \\<open>Remove virtual to physical mappings in either direction involving this\nvirtual ASID.\\<close>\ndefinition\nhw_asid_invalidate :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"hw_asid_invalidate asid vspace \\<equiv>\n  do_machine_op $ invalidateASID vspace (ucast asid)\"\n\ndefinition\ndelete_asid_pool :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid_pool base ptr \\<equiv> do\n  assert (asid_low_bits_of base = 0);\n  asid_table \\<leftarrow> gets (x64_asid_table \\<circ> arch_state);\n  when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n    pool \\<leftarrow> get_asid_pool ptr;\n    mapM (\\<lambda>offset. (when (pool (ucast offset) \\<noteq> None) $\n                          hw_asid_invalidate (base + offset) (the (pool (ucast offset)))))\n                    [0 .e. (1 << asid_low_bits) - 1];\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> x64_asid_table := asid_table' \\<rparr>\\<rparr>);\n    tcb \\<leftarrow> gets cur_thread;\n    set_vm_root tcb\n  od\nod\"\n\ntext \\<open>When deleting a page map level 4 from an ASID pool we must deactivate\nit.\\<close>\ndefinition\ndelete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pml4 \\<equiv> do\n  asid_table \\<leftarrow> gets (x64_asid_table \\<circ> arch_state);\n  case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (asid_low_bits_of asid) = Some pml4) $ do\n                hw_asid_invalidate asid pml4;\n                pool' \\<leftarrow> return (pool (asid_low_bits_of asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od\nod\"\n\ndefinition\n  flush_all :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_all vspace asid \\<equiv> do_machine_op $ invalidateASID vspace (ucast asid)\"\n\nabbreviation\n  flush_pdpt :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_pdpt \\<equiv> flush_all\"\n\nabbreviation\n  flush_pd :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"flush_pd \\<equiv> flush_all\"\n\ntext \\<open>Flush mappings associated with a page table.\\<close>\ndefinition\nflush_table :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_table pml4_ref vptr pt_ref asid \\<equiv> do\n    assert (vptr && mask (ptTranslationBits + pageBits) = 0);\n           pt \\<leftarrow> get_pt pt_ref;\n           forM_x [0 .e. (-1::9 word)] (\\<lambda>index. do\n             pte \\<leftarrow> return $ pt index;\n             case pte of\n               InvalidPTE \\<Rightarrow> return ()\n             | _ \\<Rightarrow> do_machine_op $ invalidateTranslationSingleASID (vptr + (ucast index << pageBits)) (ucast asid)\n           od)\nod\"\n\n\ntext \\<open>Unmap a Page Directory Pointer Table from a PML4.\\<close>\ndefinition\nunmap_pdpt :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_pdpt asid vaddr pdpt \\<equiv> doE\n  vspace \\<leftarrow> find_vspace_for_asid asid;\n  pm_slot \\<leftarrow> returnOk $ lookup_pml4_slot vspace vaddr;\n  pml4e \\<leftarrow> liftE $ get_pml4e pm_slot;\n  case pml4e of\n    PDPointerTablePML4E pt' _ _ \\<Rightarrow>\n      if pt' = addrFromPPtr pdpt then returnOk () else throwError InvalidRoot\n    | _ \\<Rightarrow> throwError InvalidRoot;\n  liftE $ do\n    flush_pdpt vspace asid;\n    store_pml4e pm_slot InvalidPML4E\n  od\nodE <catch> (K $ return ())\"\n\ntext \\<open>Unmap a Page Directory from a Page Directory Pointer Table.\\<close>\ndefinition\nunmap_pd :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_pd asid vaddr pd \\<equiv> doE\n  vspace \\<leftarrow> find_vspace_for_asid asid;\n  pdpt_slot \\<leftarrow> lookup_pdpt_slot vspace vaddr;\n  pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n  case pdpte of\n    PageDirectoryPDPTE pd' _ _ \\<Rightarrow>\n      if pd' = addrFromPPtr pd then returnOk () else throwError InvalidRoot\n    | _ \\<Rightarrow> throwError InvalidRoot;\n  liftE $ do\n    flush_pd vspace asid;\n    store_pdpte pdpt_slot InvalidPDPTE;\n    invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n  od\nodE <catch> (K $ return ())\"\n\ntext \\<open>Unmap a page table from its page directory.\\<close>\ndefinition\nunmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page_table asid vaddr pt \\<equiv> doE\n    vspace \\<leftarrow> find_vspace_for_asid asid;\n    pd_slot \\<leftarrow> lookup_pd_slot vspace vaddr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    case pde of\n      PageTablePDE addr _ _ \\<Rightarrow>\n        if addrFromPPtr pt = addr then returnOk () else throwError InvalidRoot\n      | _ \\<Rightarrow> throwError InvalidRoot;\n    liftE $ do\n      flush_table vspace vaddr pt asid;\n      store_pde pd_slot InvalidPDE;\n      invalidate_page_structure_cache_asid (addrFromPPtr vspace) asid\n    od\nodE <catch> (K $ return ())\"\n\ntext \\<open>Check that a given frame is mapped by a given mapping entry.\\<close>\ndefinition\ncheck_mapping_pptr :: \"machine_word \\<Rightarrow> vm_page_entry \\<Rightarrow> bool\" where\n\"check_mapping_pptr pptr entry \\<equiv> case entry of\n   VMPTE (SmallPagePTE base _ _) \\<Rightarrow> base = addrFromPPtr pptr\n | VMPDE (LargePagePDE base _ _) \\<Rightarrow> base = addrFromPPtr pptr\n | VMPDPTE (HugePagePDPTE base _ _) \\<Rightarrow> base = addrFromPPtr pptr\n | _ \\<Rightarrow> False\"\n\n\ntext \\<open>Unmap a mapped page if the given mapping details are still current.\\<close>\ndefinition\nunmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page pgsz asid vptr pptr \\<equiv> doE\n    vspace \\<leftarrow> find_vspace_for_asid asid;\n    case pgsz of\n          X64SmallPage \\<Rightarrow> doE\n            pt_slot \\<leftarrow> lookup_pt_slot vspace vptr;\n            pte \\<leftarrow> liftE $ get_pte pt_slot;\n            unlessE (check_mapping_pptr pptr (VMPTE pte)) $ throwError InvalidRoot;\n            liftE $ store_pte pt_slot InvalidPTE\n          odE\n        | X64LargePage \\<Rightarrow> doE\n            pd_slot \\<leftarrow> lookup_pd_slot vspace vptr;\n            pde \\<leftarrow> liftE $ get_pde pd_slot;\n            unlessE (check_mapping_pptr pptr (VMPDE pde)) $ throwError InvalidRoot;\n            liftE $ store_pde pd_slot InvalidPDE\n          odE\n        | X64HugePage \\<Rightarrow> doE\n            pdpt_slot \\<leftarrow> lookup_pdpt_slot vspace vptr;\n            pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n            unlessE (check_mapping_pptr pptr (VMPDPTE pdpte)) $ throwError InvalidRoot;\n            liftE $ store_pdpte pdpt_slot InvalidPDPTE\n          odE;\n    liftE $ do_machine_op $ invalidateTranslationSingleASID vptr (ucast asid)\nodE <catch> (K $ return ())\"\n\n\ntext \\<open>Page table structure capabilities cannot be copied until they\nhave a virtual ASID and location assigned. This is because they\ncannot have multiple current virtual ASIDs and cannot be shared\nbetween address spaces or virtual locations.\\<close>\ndefinition\n  arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\"\nwhere\n  \"arch_derive_cap c \\<equiv> case c of\n     PageTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageTableCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageDirectoryCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageDirectoryCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PDPointerTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PDPointerTableCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PML4Cap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PML4Cap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageCap dev r R mt pgs x \\<Rightarrow> returnOk $ ArchObjectCap (PageCap dev r R VMNoMap pgs None)\n   | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n   | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\n\\<^cancel>\\<open>FIXME x64-vtd:\n   | IOSpaceCap _ _ \\<Rightarrow> returnOk c\n   | IOPageTableCap _ _ _ \\<Rightarrow> returnOk c\\<close>\n   | IOPortCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\n   | IOPortControlCap \\<Rightarrow> returnOk NullCap\"\n\ntext \\<open>No user-modifiable data is stored in x64-specific capabilities.\\<close>\ndefinition\n  arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"\n\n\ntext \\<open>Actions that must be taken on finalisation of x64-specific\ncapabilities.\\<close>\ndefinition\n  arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n    (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n    delete_asid_pool b ptr;\n    return (NullCap, NullCap)\n    od\n  | (PML4Cap ptr (Some a), True) \\<Rightarrow> do\n    delete_asid a ptr;\n    return (NullCap, NullCap)\n  od\n  | (PDPointerTableCap ptr (Some (a,v)), True) \\<Rightarrow> do\n    unmap_pdpt a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageDirectoryCap ptr (Some (a,v)), True) \\<Rightarrow> do\n    unmap_pd a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n    unmap_page_table a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageCap _ ptr _ _ s (Some (a, v)), _) \\<Rightarrow> do\n     unmap_page s a v ptr;\n     return (NullCap, NullCap)\n  od\n  | (IOPortCap f l, True) \\<Rightarrow> return (NullCap, (ArchObjectCap (IOPortCap f l)))\n  \\<comment> \\<open>FIXME x64-vtd: IOSpaceCap and IOPageTableCap for @{text arch_finalise_cap}\\<close>\n  | _ \\<Rightarrow> return (NullCap, NullCap)\"\n\n\n\ntext \\<open>A thread's virtual address space capability must be to a mapped PML4 (page map level 4)\nto be valid on the x64 architecture.\\<close>\ndefinition\n  is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv> \\<exists>r a. c = ArchObjectCap (PML4Cap r (Some a))\"\n\ndefinition\ncheck_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n\"check_valid_ipc_buffer vptr c \\<equiv> case c of\n  (ArchObjectCap (PageCap False _ _ _ _ _)) \\<Rightarrow> doE\n    whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError;\n    returnOk ()\n  odE\n| _ \\<Rightarrow> throwError IllegalOperation\"\n\ntext \\<open>Decode a user argument word describing the kind of VM attributes a\nmapping is to have.\\<close>\ndefinition\nattribs_from_word :: \"machine_word \\<Rightarrow> frame_attrs\" where\n\"attribs_from_word w \\<equiv>\n  let V = (if w !!0 then {PTAttr WriteThrough} else {});\n      V' = (if w!!1 then insert (PTAttr CacheDisabled) V else V)\n  in if w!!2 then insert PAT V' else V'\"\n\n\ntext \\<open>Update the mapping data saved in a page or page table capability.\\<close>\ndefinition\n  update_map_data :: \"arch_cap \\<Rightarrow> (asid \\<times> vspace_ref) option \\<Rightarrow> vmmap_type option \\<Rightarrow> arch_cap\" where\n  \"update_map_data cap m mt \\<equiv> case cap of\n     PageCap dev p R _ sz _ \\<Rightarrow> PageCap dev p R (the mt) sz m\n   | PageTableCap p _ \\<Rightarrow> PageTableCap p m\n   | PageDirectoryCap p _ \\<Rightarrow> PageDirectoryCap p m\n   | PDPointerTableCap p _ \\<Rightarrow> PDPointerTableCap p m\"\n\ntext \\<open>\n  A pointer is inside a user frame if its top bits point to a @{text DataPage}.\n\\<close>\ndefinition\n  in_user_frame :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n  \"in_user_frame p s \\<equiv>\n   \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) =\n        Some (ArchObj (DataPage False sz))\"\n\ndefinition\n  fpu_thread_delete :: \"obj_ref \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"fpu_thread_delete thread_ptr \\<equiv> do\n    using_fpu \\<leftarrow> do_machine_op (nativeThreadUsingFPU thread_ptr);\n    when using_fpu $ do_machine_op (switchFpuOwner 0 0)\n  od\"\n\ndefinition\n  prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"prepare_thread_delete thread_ptr \\<equiv> fpu_thread_delete thread_ptr\"\n\ntext \\<open>Make numeric value of @{const msg_align_bits} visible.\\<close>\nlemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\nend\nend"}
{"title": "./spec/abstract/X64/ArchVSpaceAcc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nAccessor functions for architecture specific parts of the specification.\n*)\n\nchapter \"Accessing the x64 VSpace\"\n\ntheory ArchVSpaceAcc_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This part of the specification is fairly concrete as the machine architecture\n  is visible to the user in seL4 and therefore needs to be described.\n  The abstraction compared to the implementation is in the data types for\n  kernel objects. The interface which is rich in machine details remains the same.\n\\<close>"}
{"title": "./spec/abstract/X64/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The high bits of a virtual ASID.\\<close>\ndefinition\n  asid_high_bits_of :: \"asid \\<Rightarrow> asid_high_index\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"\n\ntext \\<open>The low bits of a virtual ASID.\\<close>\ndefinition\n  asid_low_bits_of :: \"asid \\<Rightarrow> asid_low_index\" where\n  \"asid_low_bits_of asid \\<equiv> ucast asid\"\n\nlemmas asid_bits_of_defs =\n  asid_high_bits_of_def asid_low_bits_of_def"}
{"title": "./spec/abstract/X64/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Manipulate ASID pools, page directories and page tables in the kernel\nheap.\\<close>\n(* declared in Arch as workaround for VER-1099 *)\nlocale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\"\n  where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"\n\ndefinition\n  get_asid_pool :: \"obj_ref \\<Rightarrow> (asid_low_index \\<rightharpoonup> obj_ref, 'z::state_ext) s_monad\" where\n  \"get_asid_pool ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (ASIDPool pool) \\<Rightarrow> return pool\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_asid_pool :: \"obj_ref \\<Rightarrow> (asid_low_index \\<rightharpoonup> obj_ref) \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n \"set_asid_pool ptr pool \\<equiv> set_object ptr (ArchObj (ASIDPool pool))\"\n\ndefinition\n  get_pd :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pde,'z::state_ext) s_monad\" where\n  \"get_pd ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageDirectory pd) \\<Rightarrow> return pd\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pd :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pde) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pd ptr pd \\<equiv> set_object ptr (ArchObj (PageDirectory pd))\"\n\ntext \\<open>The following function takes a pointer to a PDE in kernel memory\n  and returns the actual PDE.\\<close>\ndefinition\n  get_pde :: \"obj_ref \\<Rightarrow> (pde,'z::state_ext) s_monad\" where\n  \"get_pde ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pd_bits);\n     offset \\<leftarrow> return ((ptr && mask pd_bits) >> word_size_bits);\n     pd \\<leftarrow> get_pd base;\n     return $ pd (ucast offset)\n   od\"\n\ndefinition\n  store_pde :: \"obj_ref \\<Rightarrow> pde \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pde p pde \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pd_bits);\n    offset \\<leftarrow> return ((p && mask pd_bits) >> word_size_bits);\n    pd \\<leftarrow> get_pd base;\n    pd' \\<leftarrow> return $ pd (ucast offset := pde);\n    set_pd base pd'\n  od\"\n\n\ndefinition\n  get_pt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pte,'z::state_ext) s_monad\" where\n  \"get_pt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pt ptr pt \\<equiv> set_object ptr (ArchObj (PageTable pt))\"\n\ntext \\<open>The following function takes a pointer to a PTE in kernel memory\n  and returns the actual PTE.\\<close>\ndefinition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\"\n\ndefinition\n  get_pdpt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pdpte,'z::state_ext) s_monad\" where\n  \"get_pdpt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PDPointerTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pdpt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pdpte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pdpt ptr pt \\<equiv> set_object ptr (ArchObj (PDPointerTable pt))\"\n\ntext \\<open>The following function takes a pointer to a PDPTE in kernel memory\n  and returns the actual PDPTE.\\<close>\ndefinition\n  get_pdpte :: \"obj_ref \\<Rightarrow> (pdpte,'z::state_ext) s_monad\" where\n  \"get_pdpte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pdpt_bits);\n     offset \\<leftarrow> return ((ptr && mask pdpt_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pdpt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pdpte :: \"obj_ref \\<Rightarrow> pdpte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pdpte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pdpt_bits);\n    offset \\<leftarrow> return ((p && mask pdpt_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pdpt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pdpt base pt'\n  od\"\n\ndefinition\n  get_pml4 :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pml4e,'z::state_ext) s_monad\" where\n  \"get_pml4 ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageMapL4 pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pml4 :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pml4e) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pml4 ptr pt \\<equiv> set_object ptr (ArchObj (PageMapL4 pt))\"\n\ntext \\<open>The following function takes a pointer to a PML4E in kernel memory\n  and returns the actual PML4E.\\<close>\ndefinition\n  get_pml4e :: \"obj_ref \\<Rightarrow> (pml4e,'z::state_ext) s_monad\" where\n  \"get_pml4e ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pml4_bits);\n     offset \\<leftarrow> return ((ptr && mask pml4_bits) >> word_size_bits);\n     pt \\<leftarrow> get_pml4 base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pml4e :: \"obj_ref \\<Rightarrow> pml4e \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pml4e p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pml4_bits);\n    offset \\<leftarrow> return ((p && mask pml4_bits) >> word_size_bits);\n    pt \\<leftarrow> get_pml4 base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pml4 base pt'\n  od\""}
{"title": "./spec/abstract/X64/ArchVSpaceAcc_A.thy", "section": "Basic Operations", "subsection": "", "subsubsection": "", "code": "\ndefinition\nget_pt_index :: \"vspace_ref \\<Rightarrow> machine_word\" where\n\"get_pt_index vptr \\<equiv> (vptr >> pt_shift_bits) && mask ptTranslationBits\"\n\ndefinition\nget_pd_index :: \"vspace_ref \\<Rightarrow> machine_word\" where\n\"get_pd_index vptr \\<equiv> (vptr >> (pd_shift_bits)) && mask ptTranslationBits\"\n\ndefinition\nget_pdpt_index :: \"vspace_ref \\<Rightarrow> machine_word\" where\n\"get_pdpt_index vptr \\<equiv> (vptr >> (pdpt_shift_bits)) && mask ptTranslationBits\"\n\ndefinition\nget_pml4_index :: \"vspace_ref \\<Rightarrow> machine_word\" where\n\"get_pml4_index vptr \\<equiv> (vptr >> pml4_shift_bits) && mask ptTranslationBits\"\n\ntext \\<open>The kernel window is mapped into every virtual address space from the\n@{term pptr_base} pointer upwards. This function copies the mappings which\ncreate the kernel window into a new page directory object.\\<close>\n\ndefinition\ncopy_global_mappings :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"copy_global_mappings new_pm \\<equiv> do\n    global_pm \\<leftarrow> gets (x64_global_pml4 \\<circ> arch_state);\n    base \\<leftarrow> return $ get_pml4_index pptr_base;\n    pme_bits \\<leftarrow> return word_size_bits;\n    pm_size \\<leftarrow> return (1 << ptTranslationBits);\n    mapM_x (\\<lambda>index. do\n        offset \\<leftarrow> return (index << pme_bits);\n        pme \\<leftarrow> get_pml4e (global_pm + offset);\n        store_pml4e (new_pm + offset) pme\n    od) [base  .e.  pm_size - 1]\n  od\"\n\ntext \\<open>Walk the page directories and tables in software.\\<close>\n\ndefinition\nlookup_pml4_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\" where\n\"lookup_pml4_slot pm vptr \\<equiv> let pm_index = get_pml4_index vptr\n                             in pm + (pm_index << word_size_bits)\"\n\ndefinition\nlookup_pdpt_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"lookup_pdpt_slot pd vptr \\<equiv> doE\n    pml4_slot \\<leftarrow> returnOk (lookup_pml4_slot pd vptr);\n    pml4e \\<leftarrow> liftE $ get_pml4e pml4_slot;\n    (case pml4e of\n          PDPointerTablePML4E tab _ _ \\<Rightarrow> (doE\n            pd \\<leftarrow> returnOk (ptrFromPAddr tab);\n            pd_index \\<leftarrow> returnOk (get_pdpt_index vptr);\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << word_size_bits));\n            returnOk pd_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability pml4_shift_bits)\n odE\"\n\ntext \\<open>A non-failing version of @{const lookup_pdpt_slot} when the pml4 is already known\\<close>\ndefinition\n  lookup_pdpt_slot_no_fail :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\nwhere\n  \"lookup_pdpt_slot_no_fail pdpt vptr \\<equiv>\n     pdpt + (get_pdpt_index vptr << word_size_bits)\"\n\ntext \\<open>The following function takes a page-directory reference as well as\n  a virtual address and then computes a pointer to the PDE in kernel memory\\<close>\ndefinition\nlookup_pd_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"lookup_pd_slot pd vptr \\<equiv> doE\n    pdpt_slot \\<leftarrow> lookup_pdpt_slot pd vptr;\n    pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n    (case pdpte of\n          PageDirectoryPDPTE tab _ _ \\<Rightarrow> (doE\n            pd \\<leftarrow> returnOk (ptrFromPAddr tab);\n            pd_index \\<leftarrow> returnOk (get_pd_index vptr);\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << word_size_bits));\n            returnOk pd_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability pdpt_shift_bits)\n odE\"\n\ntext \\<open>A non-failing version of @{const lookup_pd_slot} when the pdpt is already known\\<close>\ndefinition\n  lookup_pd_slot_no_fail :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\nwhere\n  \"lookup_pd_slot_no_fail pd vptr \\<equiv>\n     pd + (get_pd_index vptr << word_size_bits)\"\n\ntext \\<open>The following function takes a page-directory reference as well as\n  a virtual address and then computes a pointer to the PTE in kernel memory.\n  Note that the function fails if the virtual address is mapped on a section or\n  super section.\\<close>\ndefinition\nlookup_pt_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n\"lookup_pt_slot vspace vptr \\<equiv> doE\n    pd_slot \\<leftarrow> lookup_pd_slot vspace vptr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    (case pde of\n          PageTablePDE ptab _ _ \\<Rightarrow>   (doE\n            pt \\<leftarrow> returnOk (ptrFromPAddr ptab);\n            pt_index \\<leftarrow> returnOk (get_pt_index vptr);\n            pt_slot \\<leftarrow> returnOk (pt + (pt_index << word_size_bits));\n            returnOk pt_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability pd_shift_bits)\n   odE\"\n\ntext \\<open>A non-failing version of @{const lookup_pt_slot} when the pd is already known\\<close>\ndefinition\n  lookup_pt_slot_no_fail :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\nwhere\n  \"lookup_pt_slot_no_fail pt vptr \\<equiv>\n     pt + (get_pt_index vptr << word_size_bits)\"\n\n(* FIXME x64-vtd:\ntext {* The following functions helped us locating the actual iopte *}\ndefinition\n  get_iopt :: \"obj_ref \\<Rightarrow> (16 word \\<Rightarrow> iopte,'z::state_ext) s_monad\" where\n  \"get_iopt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (IOPageTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_iopt :: \"obj_ref \\<Rightarrow> (16 word \\<Rightarrow> iopte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_iopt ptr pt \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     assert (case kobj of ArchObj (PageTable _) \\<Rightarrow> True | _ \\<Rightarrow> False);\n     set_object ptr (ArchObj (IOPageTable pt))\n   od\"\n\ndefinition  get_iopte :: \"obj_ref \\<Rightarrow> (iopte,'z::state_ext) s_monad\" where\n  \"get_iopte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask iopt_bits);\n     offset \\<leftarrow> return ((ptr && mask iopt_bits) >> 2);\n     pt \\<leftarrow> get_iopt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_iopte :: \"obj_ref \\<Rightarrow> iopte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_iopte p iopte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask iopt_bits);\n    offset \\<leftarrow> return ((p && mask iopt_bits) >> 8);\n    pt \\<leftarrow> get_iopt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := iopte);\n    set_iopt base pt'\n  od\"\n\ndefinition\n  get_iort :: \"obj_ref \\<Rightarrow> (16 word \\<Rightarrow> iorte,'z::state_ext) s_monad\" where\n  \"get_iort ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (IORootTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_iort :: \"obj_ref \\<Rightarrow> (16 word \\<Rightarrow> iorte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_iort ptr pt \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     assert (case kobj of ArchObj (IORootTable _) \\<Rightarrow> True | _ \\<Rightarrow> False);\n     set_object ptr (ArchObj (IORootTable pt))\n   od\"\n\ndefinition  get_iorte :: \"obj_ref \\<Rightarrow> (iorte,'z::state_ext) s_monad\" where\n  \"get_iorte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask iopt_bits);\n     offset \\<leftarrow> return ((ptr && mask iopt_bits) >> 2);\n     pt \\<leftarrow> get_iort base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_iorte :: \"obj_ref \\<Rightarrow> iorte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_iorte p iorte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask iopt_bits);\n    offset \\<leftarrow> return ((p && mask iopt_bits) >> 8);\n    rt \\<leftarrow> get_iort base;\n    rt' \\<leftarrow> return $ rt (ucast offset := iorte);\n    set_iort base rt'\n  od\"\n\ndefinition\n  get_ioct :: \"obj_ref \\<Rightarrow> (16 word \\<Rightarrow> iocte,'z::state_ext) s_monad\" where\n  \"get_ioct ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (IOContextTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_ioct :: \"obj_ref \\<Rightarrow> (16 word \\<Rightarrow> iocte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_ioct ptr ct \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     assert (case kobj of ArchObj (IOContextTable _) \\<Rightarrow> True | _ \\<Rightarrow> False);\n     set_object ptr (ArchObj (IOContextTable ct))\n   od\"\n\ndefinition  get_iocte :: \"obj_ref \\<Rightarrow> (iocte,'z::state_ext) s_monad\" where\n  \"get_iocte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask iopt_bits);\n     offset \\<leftarrow> return ((ptr && mask iopt_bits) >> 8);\n     ct \\<leftarrow> get_ioct base;\n     return $ ct (ucast offset)\n   od\"\n\n\ndefinition\n  store_iocte :: \"obj_ref \\<Rightarrow> iocte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_iocte p iocte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask iopt_bits);\n    offset \\<leftarrow> return ((p && mask iopt_bits) >> 8);\n    pt \\<leftarrow> get_ioct base;\n    pt' \\<leftarrow> return $ pt (ucast offset := iocte);\n    set_ioct base pt'\n  od\"\n\ndefinition get_pci_fun :: \"io_asid \\<Rightarrow> machine_word\" where\n\"get_pci_fun asid \\<equiv> fromIntegral asid && 0x7\"\n\ndefinition get_pci_bus :: \"io_asid \\<Rightarrow> machine_word\" where\n\"get_pci_bus asid \\<equiv> fromIntegral $ (asid >> 8) && 0xFF\"\n\ndefinition get_pci_dev :: \"io_asid \\<Rightarrow> machine_word\" where\n\"get_pci_dev asid \\<equiv> fromIntegral $ (asid >> 3) && 0x1F\"\n\ndefinition lookup_io_context_slot :: \"io_asid \\<Rightarrow> (obj_ref,'z::state_ext) s_monad\" where\n\"lookup_io_context_slot pci_request_id \\<equiv> do\n    rtptr <- gets (x64_io_root_table \\<circ> arch_state);\n    root_index <- return $ get_pci_bus pci_request_id;\n    rte_ptr <- return $ rtptr + root_index;\n    rte <- get_iorte rte_ptr;\n    ct_pptr <- return $ ptrFromPAddr (context_table rte);\n    cte_ptr <- return $ ((get_pci_dev pci_request_id) << vtd_cte_size_bits)\n              || get_pci_fun pci_request_id;\n    return $ ct_pptr + ( cte_ptr << vtd_cte_size_bits)\n  od\"\n\ndefinition get_vtd_pte_offset ::  \"64 word \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> 64 word\"\nwhere \"get_vtd_pte_offset translation levels_to_resolve levels_remaining \\<equiv>\n  let lvldiff = levels_to_resolve - levels_remaining\n  in (translation >> (vtd_pt_bits * (x64_num_io_pt_levels - 1 - lvldiff)))\n      && (mask vtd_pt_bits)\"\n\n\nfun lookup_io_ptr_resolve_levels :: \"obj_ref \\<Rightarrow> 64 word\\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow>\n ((obj_ref \\<times> nat),'z::state_ext) lf_monad\"\nwhere \"lookup_io_ptr_resolve_levels iopt_ref translation levels_to_resolve\n  levels_remaining = doE\n    offset <- returnOk $ get_vtd_pte_offset translation\n      levels_to_resolve levels_remaining;\n    pte_ptr <- returnOk $ iopt_ref + offset;\n    if levels_remaining = 0\n      then returnOk $ (pte_ptr, 0)\n      else (doE\n        iopte <- liftE $ get_iopte pte_ptr;\n        slot <- returnOk $ ptrFromPAddr (frame_ptr iopte);\n        if (io_pte_rights iopte = vm_read_write)\n          then returnOk (pte_ptr, levels_remaining)\n          else lookup_io_ptr_resolve_levels slot translation levels_to_resolve\n            (levels_remaining - 1)\n      odE)\n  odE\"\n\ndefinition lookup_io_pt_slot :: \"obj_ref \\<Rightarrow> 64 word \\<Rightarrow>  ((obj_ref \\<times> nat),'z::state_ext) lf_monad\"\nwhere \"lookup_io_pt_slot pte_ref ioaddr \\<equiv> lookup_io_ptr_resolve_levels pte_ref  (ioaddr >> pageBits)\n  (x64_num_io_pt_levels - 1) (x64_num_io_pt_levels - 1)\"\n\n*)\n\n\nend\nend"}
{"title": "./spec/abstract/X64/ArchDecode_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDecoding system calls\n*)\n\nchapter \"Decoding Architecture-specific System Calls\"\n\ntheory ArchDecode_A\nimports\n  Interrupt_A\n  InvocationLabels_A\n  \"ExecSpec.InvocationLabels_H\"\nbegin\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/X64/ArchDecode_A.thy", "section": "Architecture calls", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition ensures that the given pointer is aligned\nto the given page size.\\<close>\n\ndefinition\n  check_vp_alignment :: \"vmpage_size \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $\n       throwError AlignmentError\"\n\ntext \\<open>This definition converts a user-supplied argument into an\ninvocation label, used to determine the method to invoke.\n\\<close>"}
{"title": "./spec/abstract/X64/ArchDecode_A.thy", "section": "Architecture calls", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition decodes architecture-specific invocations.\n\\<close>\n\ndefinition\n  page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\nwhere\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"\n\n\n(* this needs to be rewritten when arch IRQ handling is redone *)\ndefinition\n  arch_decode_irq_control_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list\n                                     \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\" where\n \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n  (if invocation_type label = ArchInvocationLabel X64IRQIssueIRQHandlerIOAPIC\n    then (if length args \\<ge> 7 \\<and> length cps \\<ge> 1\n      then let pre_irq = args ! 6; index = args ! 0; depth = args ! 1;\n               cnode = cps ! 0;\n               irqv = ucast pre_irq + minUserIRQ;\n               ioapic = args ! 2;\n               pin = args ! 3;\n               level = args ! 4;\n               polarity = args ! 5;\n               vector = ucast irqv + irqIntOffset\n        in doE\n\n        whenE (pre_irq > ucast (maxUserIRQ - minUserIRQ)) $ throwError (RangeError 0 (ucast (maxUserIRQ - minUserIRQ)));\n        irq_active \\<leftarrow> liftE $ is_irq_active irqv;\n        whenE irq_active $ throwError RevokeFirst;\n        dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n        ensure_empty dest_slot;\n\n        numIOAPICs \\<leftarrow> liftE $ gets (x64_num_ioapics \\<circ> arch_state);\n        ioapic_nirqs \\<leftarrow> liftE $ gets (x64_ioapic_nirqs \\<circ> arch_state);\n        whenE (numIOAPICs = 0) $ throwError IllegalOperation;\n        whenE (ioapic > numIOAPICs - 1) $ throwError (RangeError 0 (numIOAPICs-1));\n        whenE (pin > ucast (ioapic_nirqs ioapic - 1)) $ throwError (RangeError 0 (ucast (ioapic_nirqs ioapic - 1)));\n        whenE (level > 1) $ throwError (RangeError 0 1);\n        whenE (polarity > 1) $ throwError (RangeError 0 1);\n\n        returnOk $ IssueIRQHandlerIOAPIC irqv dest_slot src_slot\n                     ioapic pin level polarity vector\n      odE\n    else throwError TruncatedMessage)\n  else (if invocation_type label = ArchInvocationLabel X64IRQIssueIRQHandlerMSI\n    then (if length args \\<ge> 7 \\<and> length cps \\<ge> 1\n      then let pre_irq = args ! 6; index = args ! 0; depth = args ! 1;\n               cnode = cps ! 0; irqv = ucast pre_irq + minUserIRQ;\n               bus = args ! 2; dev = args ! 3; func = args ! 4; handle = args ! 5\n        in doE\n\n        whenE (pre_irq > ucast (maxUserIRQ - minUserIRQ)) $ throwError (RangeError 0 (ucast (maxUserIRQ - minUserIRQ)));\n        irq_active \\<leftarrow> liftE $ is_irq_active irqv;\n        whenE irq_active $ throwError RevokeFirst;\n\n        dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n        ensure_empty dest_slot;\n\n       \\<comment> \\<open>Following should be wrapped in to a function like what c did\n          since it is pc99 related, problem is where to put this function\\<close>\n        whenE (bus > maxPCIBus) $ throwError (RangeError 0 maxPCIBus);\n        whenE (dev > maxPCIDev) $ throwError (RangeError 0 maxPCIDev);\n        whenE (func > maxPCIFunc) $ throwError (RangeError 0 maxPCIFunc);\n\n        returnOk $ IssueIRQHandlerMSI irqv dest_slot src_slot bus dev func handle\n      odE\n    else throwError TruncatedMessage)\n  else throwError IllegalOperation))\"\n\nabbreviation (input)\n  args_at_least :: \"nat \\<Rightarrow> data list \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"args_at_least n args \\<equiv>  whenE (n > length args) $ throwError TruncatedMessage\"\n\ndefinition\n  ensure_port_operation_allowed :: \"arch_cap \\<Rightarrow> 32 word \\<Rightarrow> nat \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"ensure_port_operation_allowed cap start_port sz \\<equiv> case cap of\n    IOPortCap first_allowed last_allowed \\<Rightarrow> doE\n      end_port \\<leftarrow> returnOk $ start_port + of_nat sz - 1;\n      assertE (first_allowed \\<le> last_allowed);\n      assertE (start_port \\<le> end_port);\n      whenE ((start_port < ucast first_allowed) \\<or> (end_port > ucast last_allowed)) $ throwError IllegalOperation\n    odE\n  | _ \\<Rightarrow> fail\"\n\ndefinition\n  decode_port_invocation ::\n    \"data \\<Rightarrow> data list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_port_invocation label args cap \\<equiv> case (invocation_type label) of\n    (ArchInvocationLabel X64IOPortIn8) \\<Rightarrow> doE\n      args_at_least 1 args;\n      port \\<leftarrow> returnOk $ ucast $ args ! 0;\n      ensure_port_operation_allowed cap (ucast port) 1;\n      returnOk $ InvokeIOPort $ IOPortInvocation port $ IOPortIn8\n    odE\n  | (ArchInvocationLabel X64IOPortIn16) \\<Rightarrow> doE\n      args_at_least 1 args;\n      port \\<leftarrow> returnOk $ ucast $ args ! 0;\n      ensure_port_operation_allowed cap (ucast port) 2;\n      returnOk $ InvokeIOPort $ IOPortInvocation port $ IOPortIn16\n    odE\n  | (ArchInvocationLabel X64IOPortIn32) \\<Rightarrow> doE\n      args_at_least 1 args;\n      port \\<leftarrow> returnOk $ ucast $ args ! 0;\n      ensure_port_operation_allowed cap (ucast port) 4;\n      returnOk $ InvokeIOPort $ IOPortInvocation port $ IOPortIn32\n    odE\n  | (ArchInvocationLabel X64IOPortOut8) \\<Rightarrow> doE\n      args_at_least 2 args;\n      port \\<leftarrow> returnOk $ ucast $ args ! 0;\n      ensure_port_operation_allowed cap (ucast port) 1;\n      output_data \\<leftarrow> returnOk $ ucast $ args ! 1;\n      returnOk $ InvokeIOPort $ IOPortInvocation port $ IOPortOut8 output_data\n    odE\n  | (ArchInvocationLabel X64IOPortOut16) \\<Rightarrow> doE\n      args_at_least 2 args;\n      port \\<leftarrow> returnOk $ ucast $ args ! 0;\n      ensure_port_operation_allowed cap (ucast port) 2;\n      output_data \\<leftarrow> returnOk $ ucast $ args ! 1;\n      returnOk $ InvokeIOPort $ IOPortInvocation port $ IOPortOut16 output_data\n    odE\n  | (ArchInvocationLabel X64IOPortOut32) \\<Rightarrow> doE\n      args_at_least 2 args;\n      port \\<leftarrow> returnOk $ ucast $ args ! 0;\n      ensure_port_operation_allowed cap (ucast port) 4;\n      output_data \\<leftarrow> returnOk $ ucast $ args ! 1;\n      returnOk $ InvokeIOPort $ IOPortInvocation port $ IOPortOut32 output_data\n      odE\n  | _ \\<Rightarrow> throwError IllegalOperation\"\n\ndefinition\n  is_ioport_range_free :: \"io_port \\<Rightarrow> io_port \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"is_ioport_range_free f l \\<equiv> do\n     alloc_ports \\<leftarrow> gets (x64_allocated_io_ports \\<circ> arch_state);\n     return $ {f..l} \\<inter> (Collect alloc_ports) = {}\n  od\"\n\ndefinition\n  decode_ioport_control_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                                    cap list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_ioport_control_invocation label args slot cap extra_caps \\<equiv>\n    if invocation_type label = ArchInvocationLabel X64IOPortControlIssue then\n      if length args \\<ge> 4 \\<and> length extra_caps \\<ge> 1 then\n        let first_port = ucast (args ! 0); last_port = ucast (args ! 1);\n            index = args ! 2; depth = args ! 3; cnode = extra_caps ! 0\n        in doE\n          whenE (first_port > last_port) $ throwError $ InvalidArgument 1;\n          check \\<leftarrow> liftE $ is_ioport_range_free first_port last_port;\n          whenE (\\<not>check) $ throwError RevokeFirst;\n\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n          returnOk $ InvokeIOPortControl $ IOPortControlInvocation first_port last_port dest_slot slot\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation\"\n\n(*X64STUB*)\ndefinition\n  decode_io_unmap_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                            (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_io_unmap_invocation label args cte cap extra_caps \\<equiv> undefined\"\n\n\ndefinition page_cap_set_vmmap_type :: \"arch_cap \\<Rightarrow> vmmap_type \\<Rightarrow> arch_cap\"\nwhere \"page_cap_set_vmmap_type cap t \\<equiv> (case cap of\n  PageCap dev p R map_type pgsz mapped_address \\<Rightarrow> PageCap dev p R t pgsz mapped_address\n  | _ \\<Rightarrow> undefined)\"\n\ndefinition\n  get_iovm_rights :: \"vm_rights \\<Rightarrow> vm_rights \\<Rightarrow> vm_rights\"\nwhere \"get_iovm_rights cover base \\<equiv>\n     (if cover = {AllowRead} then  (if AllowRead \\<in> base then {AllowRead} else {}) else\n     (if AllowRead \\<in> cover then  {AllowRead} \\<union> (if AllowWrite \\<in> base then {AllowWrite} else {})\n     else (if AllowWrite \\<in> base then {AllowWrite} else {})))\"\n\n(* FIXME x64-vtd:\ndefinition\n  pci_request_id_from_cap :: \"cap \\<Rightarrow> (16 word, 'z::state_ext) s_monad\"\n  where \"pci_request_id_from_cap cap \\<equiv>\n    case cap of\n      ArchObjectCap (IOSpaceCap _ (Some deviceid)) \\<Rightarrow> return $ ucast deviceid\n    | ArchObjectCap (IOPageTableCap _ _ (Some asid)) \\<Rightarrow> return $ fst asid\n    | _\\<Rightarrow> fail\"\n\n\ndefinition\n  decode_io_pt_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                            (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_io_pt_invocation label args cptr cap extra_caps \\<equiv> (case cap of\n  IOPageTableCap bptr level mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel  X64IOPageTableMap\n    then\n      let paddr = addrFromPPtr bptr;\n          ioaddr = args ! 0;\n          vmrights = args ! 1;\n          iospace_cap = fst (extra_caps ! 0)\n      in doE\n      whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n      (deviceid,domainid) <- (case iospace_cap of\n             ArchObjectCap (IOSpaceCap domainid (Some deviceid))\n                 \\<Rightarrow> returnOk $ (deviceid,domainid)\n             | _ \\<Rightarrow> throwError $ InvalidCapability 0);\n      pci_request_id \\<leftarrow> liftE $ pci_request_id_from_cap iospace_cap;\n      iocteslot \\<leftarrow> liftE $ lookup_io_context_slot pci_request_id;\n      iocte \\<leftarrow> liftE $ get_iocte iocteslot;\n      case iocte of\n        VTDCTE did rmrr aw slptr tt False \\<Rightarrow> doE\n          vtdcte <- returnOk $ VTDCTE did False (x64_num_io_pt_levels - 2)\n                                          paddr NotTranslated True;\n          cap' <- returnOk $ IOPageTableCap bptr 0 (Some (deviceid, ioaddr));\n          returnOk $ InvokeIOPT $ IOPageTableMapContext (ArchObjectCap cap')\n            cptr vtdcte iocteslot\n        odE\n      | VTDCTE did rmrr aw slptr tt True \\<Rightarrow> doE\n          (slot, level) \\<leftarrow> lookup_error_on_failure False $\n              lookup_io_pt_slot (ptrFromPAddr slptr) ioaddr;\n           level <- returnOk $ x64_num_io_pt_levels - level;\n           pte <- liftE $ get_iopte slot;\n           cap' <- returnOk $ IOPageTableCap bptr level (Some (deviceid, ioaddr));\n           case pte of\n             InvalidIOPTE \\<Rightarrow> returnOk $ InvokeIOPT $ IOPageTableMap (ArchObjectCap cap')\n             cptr (VTDPTE paddr vm_read_write) slot\n           | _ \\<Rightarrow> throwError $ InvalidCapability 0\n        odE\n      odE\n    else if invocation_type label = ArchInvocationLabel X64IOPageTableUnmap\n    then\n      returnOk $ InvokeIOPT $ IOPageTableUnmap (ArchObjectCap cap) cptr\n    else throwError $ IllegalOperation\n  | _ \\<Rightarrow> undefined)\"\n\ndefinition\n  decode_io_frame_map_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                            (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_io_frame_map_invocation label args cptr cap extra_caps \\<equiv> (case cap of\n  PageCap p R map_tyhpe pgsz mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel X64PageMapIO\n    then\n      let paddr = addrFromPPtr p;\n          ioaddr = args ! 0;\n          vmrights = args ! 1;\n          iospace_cap = fst (extra_caps ! 0);\n          vm_right_mask = get_iovm_rights R (data_to_rights vmrights)\n      in doE\n      whenE (pgsz \\<noteq> X64SmallPage) $ throwError $ InvalidCapability 0;\n      whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n      deviceid \\<leftarrow> (case iospace_cap of\n                 ArchObjectCap (IOSpaceCap _ (Some deviceid)) \\<Rightarrow> returnOk $ ucast deviceid\n                 | _ \\<Rightarrow> throwError $ InvalidCapability 0);\n      pci_request_id \\<leftarrow> liftE $ pci_request_id_from_cap iospace_cap;\n\n      iocteslot \\<leftarrow> liftE $ lookup_io_context_slot pci_request_id;\n      iocte \\<leftarrow> liftE $ get_iocte iocteslot;\n      (slot, level) \\<leftarrow> (case iocte of\n                 VTDCTE did rmrr aw slptr tt True \\<Rightarrow>\n                     lookup_error_on_failure False $ lookup_io_pt_slot (ptrFromPAddr slptr) ioaddr\n                 | _ \\<Rightarrow> throwError $ FailedLookup False InvalidRoot);\n      whenE (level \\<noteq> 0) $ throwError $ InvalidCapability 0;\n      iopte <- liftE $ get_iopte slot;\n      whenE (iopte \\<noteq> InvalidIOPTE) $ throwError DeleteFirst;\n      vtdpte <- returnOk $ VTDPTE paddr vm_right_mask;\n      cap' <- returnOk $ PageCap p R VMIOSpaceMap pgsz (Just (deviceid, ioaddr));\n      returnOk $ InvokePage $ PageIOMap (ArchObjectCap cap') cptr vtdpte slot\n    odE\n    else throwError $ IllegalOperation\n  | _ \\<Rightarrow> undefined)\"\n\n\ndefinition\n  decode_io_map_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                            (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_io_map_invocation label args cte cap extra_caps \\<equiv> undefined\"\n(*X64STUB*)\n*)\n\ndefinition\ndecode_page_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap\n                            \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_page_invocation label args cte cap extra_caps \\<equiv> (case cap of\n  PageCap dev p R map_type pgsz mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel X64PageMap then\n    if length args > 2 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             rights_mask = args ! 1;\n             attr = args ! 2;\n             vspace_cap = fst (extra_caps ! 0)\n         in doE\n             (vspace, asid) \\<leftarrow> (case vspace_cap of\n                                   ArchObjectCap (PML4Cap pm (Some asid)) \\<Rightarrow>\n                                         returnOk (pm, asid)\n                                 | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n             case mapped_address of\n               Some (asid', vaddr') \\<Rightarrow> doE\n                 whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n                 whenE (map_type \\<noteq> VMVSpaceMap) $ throwError IllegalOperation;\n                 whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0)\n               odE\n             | None \\<Rightarrow> doE\n                 vtop \\<leftarrow> returnOk $ vaddr + bit (pageBitsForSize pgsz);\n                 whenE (vaddr > user_vtop \\<or> vtop > user_vtop) $ throwError $ InvalidArgument 0\n               odE;\n             vspace' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n             whenE (vspace' \\<noteq> vspace) $ throwError $ InvalidCapability 1;\n             vm_rights \\<leftarrow> returnOk $ mask_vm_rights R $ data_to_rights rights_mask;\n             check_vp_alignment pgsz vaddr;\n             entries \\<leftarrow> create_mapping_entries (addrFromPPtr p) vaddr pgsz vm_rights\n                                               (attribs_from_word attr) vspace;\n             ensure_safe_mapping entries;\n             returnOk $ InvokePage $ PageMap\n               (ArchObjectCap $ PageCap dev p R VMVSpaceMap pgsz (Some (asid,vaddr))) cte entries vspace\n          odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel X64PageUnmap then\n             \\<^cancel>\\<open>case map_type of\n                 VMIOSpaceMap \\<Rightarrow> decode_io_unmap_invocation label args cte cap extra_caps\n               | _ \\<Rightarrow>\\<close> returnOk $ InvokePage $ PageUnmap cap cte\n    \\<^cancel>\\<open>FIXME x64-vtd:\n    else if invocation_type label = ArchInvocationLabel X64PageMapIO\n    then decode_io_map_invocation label args cte cap extra_caps \\<close>\n    else if invocation_type label = ArchInvocationLabel X64PageGetAddress\n    then returnOk $ InvokePage $ PageGetAddr p\n  else throwError IllegalOperation\n | _ \\<Rightarrow> fail)\"\n\ndefinition filter_frame_attrs :: \"frame_attrs \\<Rightarrow> table_attrs\"\nwhere\n  \"filter_frame_attrs attrs \\<equiv> {s. \\<exists>s' \\<in> attrs. s' = PTAttr s}\"\n\ndefinition\n  decode_page_table_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                                  (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_page_table_invocation label args cte cap extra_caps \\<equiv> (case cap of\n    PageTableCap p mapped_address \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64PageTableMap then\n      if length args > 1 \\<and> length extra_caps > 0\n      then let vaddr = args ! 0;\n               attr = args ! 1;\n               pml4_cap = fst (extra_caps ! 0)\n      in doE\n               whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n               vaddr' \\<leftarrow> returnOk $ vaddr && ~~ mask pd_shift_bits;\n               (pml4, asid) \\<leftarrow> (case pml4_cap of\n                   ArchObjectCap (PML4Cap pml4 (Some asid)) \\<Rightarrow> returnOk (pml4, asid)\n                   | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n               whenE (user_vtop < vaddr') $ throwError $ InvalidArgument 0;\n               pml4' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n               whenE (pml4' \\<noteq> pml4) $ throwError $ InvalidCapability 1;\n               pd_slot \\<leftarrow> lookup_error_on_failure False $ lookup_pd_slot pml4 vaddr';\n               old_pde \\<leftarrow> liftE $ get_pde pd_slot;\n               unlessE (old_pde = InvalidPDE) $ throwError DeleteFirst;\n               pde \\<leftarrow> returnOk (PageTablePDE (addrFromPPtr p)\n                                  (filter_frame_attrs $ attribs_from_word attr) vm_read_write);\n               cap' <- returnOk $ ArchObjectCap $ PageTableCap p $ Some (asid, vaddr');\n               returnOk $ InvokePageTable $ PageTableMap cap' cte pde pd_slot pml4\n            odE\n      else throwError TruncatedMessage\n      else if invocation_type label = ArchInvocationLabel X64PageTableUnmap then doE\n               final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n               unlessE final $ throwError RevokeFirst;\n               returnOk $ InvokePageTable $ PageTableUnmap (ArchObjectCap cap) cte\n        odE\n      else throwError IllegalOperation\n  | _ \\<Rightarrow> fail)\"\n\ndefinition\n  decode_page_directory_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                                      (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_page_directory_invocation label args cte cap extra_caps \\<equiv> (case cap of\n    PageDirectoryCap p mapped_address \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64PageDirectoryMap then\n      if length args > 1 \\<and> length extra_caps > 0\n      then let vaddr = args ! 0;\n               attr = args ! 1;\n               pml4_cap = fst (extra_caps ! 0)\n      in doE\n               whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n               vaddr' \\<leftarrow> returnOk $ vaddr && ~~ mask pdpt_shift_bits;\n               (pml4, asid) \\<leftarrow> (case pml4_cap of\n                       ArchObjectCap (PML4Cap pml4 (Some asid)) \\<Rightarrow> returnOk (pml4, asid)\n                       | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n               whenE (user_vtop < vaddr') $ throwError $ InvalidArgument 0;\n               pml4' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n               whenE (pml4' \\<noteq> pml4) $ throwError $ InvalidCapability 1;\n               pdpt_slot \\<leftarrow> lookup_error_on_failure False $ lookup_pdpt_slot pml4 vaddr';\n               old_pdpte \\<leftarrow> liftE $ get_pdpte pdpt_slot;\n               unlessE (old_pdpte = InvalidPDPTE) $ throwError DeleteFirst;\n               pdpte \\<leftarrow> returnOk (PageDirectoryPDPTE (addrFromPPtr p)\n                          (filter_frame_attrs $ attribs_from_word attr) vm_read_write);\n               cap' <- returnOk $ ArchObjectCap $ PageDirectoryCap p $ Some (asid, vaddr');\n               returnOk $ InvokePageDirectory $ PageDirectoryMap cap' cte pdpte pdpt_slot pml4\n        odE\n      else throwError TruncatedMessage\n      else if invocation_type label = ArchInvocationLabel X64PageDirectoryUnmap then doE\n               final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n               unlessE final $ throwError RevokeFirst;\n               returnOk $ InvokePageDirectory $ PageDirectoryUnmap (ArchObjectCap cap) cte\n            odE\n      else throwError IllegalOperation\n  | _ \\<Rightarrow> fail)\"\n\ndefinition\n  decode_pdpt_invocation :: \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow>\n                                      (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_pdpt_invocation label args cte cap extra_caps \\<equiv> (case cap of\n    PDPointerTableCap p mapped_address \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64PDPTMap then\n      if length args > 1 \\<and> length extra_caps > 0\n      then let vaddr = args ! 0;\n               attr = args ! 1;\n               pml4_cap = fst (extra_caps ! 0)\n      in doE\n               whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n               vaddr' \\<leftarrow> returnOk $ vaddr && ~~ mask pml4_shift_bits;\n               (pml4 ,asid) \\<leftarrow> (case pml4_cap of\n                       ArchObjectCap (PML4Cap pml4 (Some asid)) \\<Rightarrow> returnOk (pml4, asid)\n                       | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n               whenE (user_vtop < vaddr') $ throwError $ InvalidArgument 0;\n               pml4' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid (asid);\n               whenE (pml4' \\<noteq> pml4) $ throwError $ InvalidCapability 1;\n               pml_slot \\<leftarrow> returnOk $ lookup_pml4_slot pml4 vaddr';\n               old_pml4e \\<leftarrow> liftE $ get_pml4e pml_slot;\n               unlessE (old_pml4e = InvalidPML4E) $ throwError DeleteFirst;\n               pml4e \\<leftarrow> returnOk (PDPointerTablePML4E (addrFromPPtr p)\n                          (filter_frame_attrs $ attribs_from_word attr) vm_read_write);\n               cap' <- returnOk $ ArchObjectCap $ PDPointerTableCap p $ Some (asid, vaddr');\n               returnOk $ InvokePDPT $ PDPTMap cap' cte pml4e pml_slot pml4\n            odE\n      else throwError TruncatedMessage\n      else if invocation_type label = ArchInvocationLabel X64PDPTUnmap then doE\n               final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n               unlessE final $ throwError RevokeFirst;\n               returnOk $ InvokePDPT $ PDPTUnmap (ArchObjectCap cap) cte\n         odE\n      else throwError IllegalOperation\n  | _ \\<Rightarrow> fail)\"\n\ndefinition\n  arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n    PDPointerTableCap _ _ \\<Rightarrow> decode_pdpt_invocation label args cte cap extra_caps\n  | PageDirectoryCap _ _ \\<Rightarrow> decode_page_directory_invocation label args cte cap extra_caps\n  | PageTableCap _ _ \\<Rightarrow> decode_page_table_invocation label args cte cap extra_caps\n  | PageCap _ _ _ _ _ _ \\<Rightarrow> decode_page_invocation label args cte cap extra_caps\n  | ASIDControlCap \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64ASIDControlMakePool then\n      if length args > 1 \\<and> length extra_caps > 1\n      then let index = args ! 0;\n               depth = args ! 1;\n               (untyped, parent_slot) = extra_caps ! 0;\n               root = fst (extra_caps ! 1)\n      in doE\n               asid_table \\<leftarrow> liftE $ gets (x64_asid_table \\<circ> arch_state);\n               free_set \\<leftarrow> returnOk (- dom asid_table);\n               whenE (free_set = {}) $ throwError DeleteFirst;\n               free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n               base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n               (p,n) \\<leftarrow> (case untyped of UntypedCap False p n f \\<Rightarrow> returnOk (p,n)\n                                        | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n               frame \\<leftarrow> (if n = pageBits\n                        then doE\n                            ensure_no_children parent_slot;\n                            returnOk p\n                          odE\n                        else  throwError $ InvalidCapability 1);\n               dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n               ensure_empty dest_slot;\n               returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n           odE\n   else throwError TruncatedMessage\n   else throwError IllegalOperation\n\n  | ASIDPoolCap p base \\<Rightarrow>\n      if invocation_type label = ArchInvocationLabel X64ASIDPoolAssign then\n      if length extra_caps > 0\n      then let (pd_cap, pd_cap_slot) = extra_caps ! 0 in\n            case pd_cap of\n               ArchObjectCap (PML4Cap _ None) \\<Rightarrow> doE\n                  asid_table \\<leftarrow> liftE $ gets (x64_asid_table \\<circ> arch_state);\n                  pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n                  whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n                  whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n                  pool \\<leftarrow> liftE $ get_asid_pool p;\n                  free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n                  whenE (free_set = {}) $ throwError DeleteFirst;\n                  offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n                  returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pd_cap_slot\n              odE\n            | _ \\<Rightarrow> throwError $ InvalidCapability 1\n      else throwError TruncatedMessage\n      else throwError IllegalOperation\n\n  | IOPortCap f l \\<Rightarrow> decode_port_invocation label args (IOPortCap f l)\n  | IOPortControlCap \\<Rightarrow> decode_ioport_control_invocation label args cte cap (map fst extra_caps)\n  | PML4Cap a b \\<Rightarrow> throwError IllegalOperation\"\n\ndefinition\n  arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n \"arch_data_to_obj_type n \\<equiv>\n  if      n = 0 then Some PDPTObj\n  else if n = 1 then Some PML4Obj\n  else if n = 2 then Some HugePageObj\n  else if n = 3 then Some SmallPageObj\n  else if n = 4 then Some LargePageObj\n  else if n = 5 then Some PageTableObj\n  else if n = 6 then Some PageDirectoryObj\n  else None\"\n\ndefinition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> throwError IllegalOperation\"\n\nend (* context Arch *)\n\nend"}
{"title": "./spec/abstract/X64/ArchInvocation_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch specific object invocations\n*)\n\nchapter \"x64 Object Invocations\"\n\ntheory ArchInvocation_A\nimports Structures_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>These datatypes encode the arguments to the various possible\nx64-specific system calls. Selectors are defined for various fields\nfor convenience elsewhere.\\<close>\n\ndatatype pdpt_invocation =\n    PDPTMap cap cslot_ptr pml4e obj_ref obj_ref\n  | PDPTUnmap cap cslot_ptr\n\ndatatype page_directory_invocation =\n    PageDirectoryMap cap cslot_ptr pdpte obj_ref obj_ref\n  | PageDirectoryUnmap cap cslot_ptr\n\ndatatype page_table_invocation =\n    PageTableMap cap cslot_ptr pde obj_ref obj_ref\n  | PageTableUnmap cap cslot_ptr\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation\n     = PageMap\n         (page_map_cap: cap)\n         (page_map_ct_slot: cslot_ptr)\n         (page_map_entries: \"vm_page_entry \\<times> obj_ref\")\n         (page_map_vspace: obj_ref)\n     | PageUnmap\n         (page_unmap_cap: arch_cap)\n         (page_unmap_cap_slot: cslot_ptr)\n(*     | PageIOMap\n         (page_iomap_cap: cap)\n         (page_iomap_ct_clot: cslot_ptr)\n         (page_iomap_asid: iopte)\n         (page_iomap_entries: \"obj_ref\") *)\n     | PageGetAddr\n         (page_get_paddr: obj_ref)\n\ndatatype io_port_invocation_data\n  = IOPortIn8 | IOPortIn16 | IOPortIn32\n  | IOPortOut8 \"8 word\" | IOPortOut16 \"16 word\" | IOPortOut32 \"32 word\"\n\ndatatype io_port_invocation = IOPortInvocation io_port io_port_invocation_data\n\ndatatype io_port_control_invocation = IOPortControlInvocation io_port io_port cslot_ptr cslot_ptr\n\n(*\ndatatype io_pt_invocation\n     = IOPageTableMapContext cap cslot_ptr iocte obj_ref\n     | IOPageTableMap cap cslot_ptr iopte obj_ref\n     | IOPageTableUnmap cap cslot_ptr *)\n\ndatatype arch_invocation\n     = InvokePageTable page_table_invocation\n     | InvokePageDirectory page_directory_invocation\n     | InvokePDPT pdpt_invocation\n     | InvokePage page_invocation\n     | InvokeASIDControl asid_control_invocation\n     | InvokeASIDPool asid_pool_invocation\n     | InvokeIOPort io_port_invocation\n     | InvokeIOPortControl io_port_control_invocation\n     (*| InvokeIOPT io_pt_invocation*)\n\ndatatype arch_copy_register_sets = X64NoExtraRegisters\n\ndefinition \"ArchDefaultExtraRegisters \\<equiv> X64NoExtraRegisters\"\n\ndatatype arch_irq_control_invocation\n  = IssueIRQHandlerIOAPIC irq cslot_ptr cslot_ptr\n      machine_word machine_word machine_word machine_word machine_word\n  | IssueIRQHandlerMSI irq cslot_ptr cslot_ptr\n      machine_word machine_word machine_word machine_word\n\nend\nend"}
{"title": "./spec/abstract/X64/Arch_Structs_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"x64-Specific Data Types\"\n\ntheory Arch_Structs_A\nimports\n  \"ExecSpec.Arch_Structs_B\"\n  ExceptionTypes_A\n  VMRights_A\n  ExecSpec.Arch_Kernel_Config_Lemmas\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\nThis theory provides architecture-specific definitions and datatypes\nincluding architecture-specific capabilities and objects.\n\\<close>"}
{"title": "./spec/abstract/X64/Arch_Structs_A.thy", "section": "Architecture-specific capabilities", "subsection": "", "subsubsection": "", "code": "\ntype_synonym io_port = \"16 word\"\ntype_synonym io_asid = \"16 word\""}
{"title": "./spec/abstract/X64/Arch_Structs_A.thy", "section": "Architecture-specific objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The x64 kernel supports capabilities for ASID pools and an ASID controller capability,\nalong with capabilities for IO ports and spaces, as well as virtual memory mappings.\\<close>\n\ndatatype arch_cap =\n   ASIDPoolCap (acap_asid_pool : obj_ref) (acap_asid_base : asid)\n | ASIDControlCap\n | IOPortCap (acap_io_port_first_port : io_port) (acap_io_port_last_port : io_port)\n | IOPortControlCap\n(* FIXME x64-vtd:\n | IOSpaceCap (cap_io_domain_id : \"16 word\") (cap_io_pci_device : \"io_asid option\")\n | IOPageTableCap (cap_iopt_base_ptr : obj_ref) (cap_io_pt_level : nat) (cap_iopt_mapped_address : \"(io_asid * vspace_ref) option\")\n*)\n | PageCap bool obj_ref (acap_rights : cap_rights) vmmap_type vmpage_size \"(asid * vspace_ref) option\"\n | PageTableCap obj_ref \"(asid * vspace_ref) option\"\n | PageDirectoryCap obj_ref \"(asid * vspace_ref) option\"\n | PDPointerTableCap obj_ref \"(asid * vspace_ref) option\"\n | PML4Cap obj_ref \"asid option\"\n\n(* cr3 Stuff *)\ndatatype cr3 = cr3 obj_ref asid\n\nprimrec\n  cr3_base_address :: \"cr3 \\<Rightarrow> obj_ref\"\nwhere\n  \"cr3_base_address (cr3 addr _) = addr\"\n\nprimrec\n  cr3_pcid :: \"cr3 \\<Rightarrow> asid\"\nwhere\n  \"cr3_pcid (cr3 _ pcid) = pcid\""}
{"title": "./spec/abstract/X64/Arch_Structs_A.thy", "section": "Architecture-specific objects", "subsection": "", "subsubsection": "", "code": "\ndatatype table_attr = Accessed | CacheDisabled | WriteThrough | ExecuteDisable\ntype_synonym table_attrs = \"table_attr set\"\n\ndatatype frame_attr = PTAttr table_attr | Global | PAT | Dirty\ntype_synonym frame_attrs = \"frame_attr set\"\n\ndatatype pml4e\n     = InvalidPML4E\n     | PDPointerTablePML4E\n         (pml4_table : obj_ref)\n         (pml4e_attrs : table_attrs)\n         (pml4e_rights : vm_rights)\n\ndatatype pdpte\n     = InvalidPDPTE\n     | PageDirectoryPDPTE\n         (pdpt_table : obj_ref)\n         (pdpt_table_attrs : table_attrs)\n         (pdpt_rights : vm_rights)\n     | HugePagePDPTE\n         (pdpt_frame : obj_ref)\n         (pdpt_frame_attrs : frame_attrs)\n         (pdpt_rights : vm_rights)\n\ndatatype pde\n      = InvalidPDE\n      | PageTablePDE\n         obj_ref\n         (pt_attrs : table_attrs)\n         (pde_rights : cap_rights)\n      | LargePagePDE\n         obj_ref\n         (pde_page_attrs : frame_attrs)\n         (pde_rights: cap_rights)\n\ndatatype pte\n      = InvalidPTE\n      | SmallPagePTE\n         (pte_frame: obj_ref)\n         (pte_frame_attrs : frame_attrs)\n         (pte_rights : cap_rights)\n\n\ndatatype vm_page_entry = VMPTE pte | VMPDE pde | VMPDPTE pdpte\n\ndatatype translation_type = NotTranslated | Translated\n\ndatatype iocte =\n   InvalidIOCTE\n | VTDCTE\n   (domain_id : word16)\n   (res_mem_reg: bool)\n   (address_width: nat)\n   (next_level_ptr: obj_ref)\n   (translation_type: translation_type)\n   (iocte_present : bool)\n\ndatatype iopte =\n   InvalidIOPTE\n | VTDPTE\n   (frame_ptr : obj_ref)\n   (io_pte_rights  : vm_rights)\n\ndatatype iorte =\n   InvalidIORTE\n | VTDRTE\n   (context_table : obj_ref)\n   (iorte_present : bool)\n\ndatatype arch_kernel_obj =\n   ASIDPool \"9 word \\<rightharpoonup> obj_ref\"\n | PageTable \"9 word \\<Rightarrow> pte\"\n | PageDirectory \"9 word \\<Rightarrow> pde\"\n | PDPointerTable \"9 word \\<Rightarrow> pdpte\"\n | PageMapL4 \"9 word \\<Rightarrow> pml4e\"\n | DataPage bool vmpage_size\n(* FIXME x64-vtd:\n | IORootTable \"16 word \\<Rightarrow> iorte\"\n | IOContextTable \"16 word \\<Rightarrow> iocte\"\n | IOPageTable \"16 word \\<Rightarrow> iopte\" *)\n\ndefinition table_size :: nat where\n  \"table_size = ptTranslationBits + word_size_bits\"\n\ndefinition iotable_size :: nat where\n  \"iotable_size = ptTranslationBits + 2*word_size_bits\"\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 5\"\n\nprimrec\n  arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\nwhere\n  \"arch_obj_size (ASIDPoolCap _ _) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (IOPortCap _ _) = 0\"\n| \"arch_obj_size IOPortControlCap = 0\"\n(* FIXME x64-vtd:\n| \"arch_obj_size (IOSpaceCap _ _) = 0\"\n| \"arch_obj_size (IOPageTableCap _ _ _) = iotable_size\" *)\n| \"arch_obj_size (PageCap _ _ _ _ sz _) = pageBitsForSize sz\"\n| \"arch_obj_size (PageTableCap _ _) = table_size\"\n| \"arch_obj_size (PageDirectoryCap _ _) = table_size\"\n| \"arch_obj_size (PDPointerTableCap _ _) = table_size\"\n| \"arch_obj_size (PML4Cap _ _) = table_size\"\n\nprimrec\n  arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_cap_is_device (ASIDPoolCap _ _) = False\"\n| \"arch_cap_is_device ASIDControlCap = False\"\n| \"arch_cap_is_device (IOPortCap _ _) = False\"\n| \"arch_cap_is_device IOPortControlCap = False\"\n(* FIXME x64-vtd:\n| \"arch_cap_is_device (IOSpaceCap _ _) = False\"\n| \"arch_cap_is_device (IOPageTableCap _ _ _) = False\" *)\n| \"arch_cap_is_device (PageCap is_dev _ _ _ _ _) = is_dev\"\n| \"arch_cap_is_device (PageTableCap _ _) = False\"\n| \"arch_cap_is_device (PageDirectoryCap _ _) = False\"\n| \"arch_cap_is_device (PDPointerTableCap _ _) = False\"\n| \"arch_cap_is_device (PML4Cap _ _) = False\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 11\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 5\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 47\"\n\nprimrec\n  arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\nwhere\n  \"arch_kobj_size (ASIDPool _) = pageBits\"\n| \"arch_kobj_size (PageTable _) = table_size\"\n| \"arch_kobj_size (PageDirectory _) = table_size\"\n| \"arch_kobj_size (PDPointerTable _) = table_size\"\n| \"arch_kobj_size (PageMapL4 _) = table_size\"\n| \"arch_kobj_size (DataPage _ sz) = pageBitsForSize sz\"\n\nprimrec\n  aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\nwhere\n  \"aobj_ref (ASIDPoolCap x _) = Some x\"\n| \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref (IOPortCap _ _) = None\"\n| \"aobj_ref IOPortControlCap = None\"\n(* FIXME x64-vtd:\n| \"aobj_ref (IOSpaceCap _ _) = None\"\n| \"aobj_ref (IOPageTableCap x _ _) = Some x\" *)\n| \"aobj_ref (PageCap _ x _ _ _ _) = Some x\"\n| \"aobj_ref (PageDirectoryCap x _) = Some x\"\n| \"aobj_ref (PageTableCap x _) = Some x\"\n| \"aobj_ref (PDPointerTableCap x _) = Some x\"\n| \"aobj_ref (PML4Cap x _) = Some x\"\n\n\ndefinition\n  acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n \"acap_rights_update rs ac \\<equiv> case ac of\n    PageCap dev x rs' m sz as \\<Rightarrow> PageCap dev x (validate_vm_rights rs) m sz as\n  | _                   \\<Rightarrow> ac\""}
{"title": "./spec/abstract/X64/Arch_Structs_A.thy", "section": "Architecture-specific object types and default objects", "subsection": "", "subsubsection": "", "code": "\ndatatype\n  aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | HugePageObj\n  | PageTableObj\n  | PageDirectoryObj\n  | PDPTObj\n  | PML4Obj\n  | ASIDPoolObj\n\ndatatype X64IRQState =\n   IRQFree\n | IRQReserved\n | IRQMSI\n      (MSIBus : machine_word)\n      (MSIDev : machine_word)\n      (MSIFunc : machine_word)\n      (MSIHandle : machine_word)\n | IRQIOAPIC\n      (IRQioapic : machine_word)\n      (IRQPin : machine_word)\n      (IRQLevel : machine_word)\n      (IRQPolarity : machine_word)\n      (IRQMasked : bool)\n\ndefinition\n  arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\"\nwhere\n  \"arch_is_frame_type aobj \\<equiv> case aobj of\n         SmallPageObj \\<Rightarrow> True\n       | LargePageObj \\<Rightarrow> True\n       | HugePageObj \\<Rightarrow> True\n       | _ \\<Rightarrow> False\"\n\ndefinition\n  arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\" where\n \"arch_default_cap tp r n dev \\<equiv> case tp of\n    SmallPageObj \\<Rightarrow> PageCap dev r vm_read_write VMNoMap X64SmallPage None\n  | LargePageObj \\<Rightarrow> PageCap dev r vm_read_write VMNoMap X64LargePage None\n  | HugePageObj \\<Rightarrow> PageCap dev r vm_read_write VMNoMap X64HugePage None\n  | PageTableObj \\<Rightarrow> PageTableCap r None\n  | PageDirectoryObj \\<Rightarrow> PageDirectoryCap r None\n  | PDPTObj \\<Rightarrow> PDPointerTableCap r None\n  | PML4Obj \\<Rightarrow> PML4Cap r None\n  | ASIDPoolObj \\<Rightarrow> ASIDPoolCap r 0\" (* unused *)\n\ndefinition\n  default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\" where\n \"default_arch_object tp dev n \\<equiv> case tp of\n    SmallPageObj \\<Rightarrow> DataPage dev X64SmallPage\n  | LargePageObj \\<Rightarrow> DataPage dev X64LargePage\n  | HugePageObj \\<Rightarrow> DataPage dev X64HugePage\n  | PageTableObj \\<Rightarrow> PageTable (\\<lambda>x. InvalidPTE)\n  | PageDirectoryObj \\<Rightarrow> PageDirectory (\\<lambda>x. InvalidPDE)\n  | PDPTObj \\<Rightarrow> PDPointerTable (\\<lambda>x. InvalidPDPTE)\n  | PML4Obj \\<Rightarrow> PageMapL4 (\\<lambda>x. InvalidPML4E)\n  | ASIDPoolObj \\<Rightarrow> ASIDPool (\\<lambda>_. None)\"\n\ntype_synonym x64_vspace_region_uses = \"vspace_ref \\<Rightarrow> x64vspace_region_use\"\n\nend\n\nqualify X64_A (in Arch)"}
{"title": "./spec/abstract/X64/Arch_Structs_A.thy", "section": "Architecture-specific state", "subsection": "", "subsubsection": "", "code": "\nrecord arch_state =\n  x64_asid_table            :: \"3 word \\<rightharpoonup> obj_ref\"\n  x64_global_pml4           :: obj_ref\n  x64_kernel_vspace         :: X64_A.x64_vspace_region_uses\n  x64_global_pts            :: \"obj_ref list\"\n  x64_global_pdpts          :: \"obj_ref list\"\n  x64_global_pds            :: \"obj_ref list\"\n  x64_current_cr3           :: \"X64_A.cr3\"\n  x64_allocated_io_ports    :: \"X64_A.io_port \\<Rightarrow> bool\"\n  x64_num_ioapics           :: \"64 word\"\n  x64_ioapic_nirqs          :: \"machine_word \\<Rightarrow> 8 word\"\n  x64_irq_state             :: \"8 word \\<Rightarrow> X64_A.X64IRQState\"\n\n(* FIXME x64-vtd:\n  x64_num_io_domain_bits    :: \"16 word\"\n  x64_first_valid_io_domain :: \"16 word\"\n  x64_num_io_domain_id_bits :: \"32 word\"\n  x64_io_root_table         :: obj_ref *)\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  pd_shift_bits :: \"nat\" where\n  \"pd_shift_bits \\<equiv> pageBits + ptTranslationBits\"\n\ndefinition\n  pt_shift_bits :: \"nat\" where\n  \"pt_shift_bits \\<equiv> pageBits\"\n\ndefinition\n  pdpt_shift_bits :: \"nat\" where\n  \"pdpt_shift_bits \\<equiv> pageBits + ptTranslationBits + ptTranslationBits\"\n\ndefinition\n  pml4_shift_bits :: \"nat\" where\n  \"pml4_shift_bits \\<equiv> pageBits + ptTranslationBits + ptTranslationBits + ptTranslationBits\"\n\ndefinition\n  pt_bits :: \"nat\" where\n  \"pt_bits \\<equiv> table_size\"\n\ndefinition\n  pd_bits :: \"nat\" where\n  \"pd_bits \\<equiv> table_size\"\n\ndefinition\n  pdpt_bits :: \"nat\" where\n  \"pdpt_bits \\<equiv> table_size\"\n\ndefinition\n  pml4_bits :: \"nat\" where\n  \"pml4_bits \\<equiv> table_size\"\n\ndefinition\n  iopt_bits :: \"nat\" where\n  \"iopt_bits \\<equiv> iotable_size\"\n\ndefinition\n  vtd_cte_size_bits :: \"nat\" where\n  \"vtd_cte_size_bits \\<equiv> 8\"\n\ndefinition\n  vtd_pt_bits :: \"nat\" where\n  \"vtd_pt_bits \\<equiv> iotable_size\"\n\ndefinition\n  x64_num_io_pt_levels :: \"nat\" where\n  \"x64_num_io_pt_levels \\<equiv> 4\""}
{"title": "./spec/abstract/X64/Arch_Structs_A.thy", "section": "Type declarations for invariant definitions", "subsection": "", "subsubsection": "", "code": "\n(* FIXME x64-vtd: add *)\ndatatype aa_type =\n    AASIDPool\n  | APageTable\n  | APageDirectory\n  | APDPointerTable\n  | APageMapL4\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\n(* FIXME x64-vtd: add *)\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\"\nwhere\n \"aa_type ao \\<equiv> (case ao of\n           PageTable pt             \\<Rightarrow> APageTable\n         | PageDirectory pd         \\<Rightarrow> APageDirectory\n         | DataPage dev sz          \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n         | ASIDPool f               \\<Rightarrow> AASIDPool\n         | PDPointerTable pdpt      \\<Rightarrow> APDPointerTable\n         | PageMapL4 pm             \\<Rightarrow> APageMapL4)\"\n\ntext \\<open>For implementation reasons the badge word has differing amounts of bits\\<close>\ndefinition\n  badge_bits :: nat where\n  \"badge_bits \\<equiv> 64\"\n\nend"}
{"title": "./spec/abstract/X64/Arch_Structs_A.thy", "section": "Arch-specific TCB", "subsection": "", "subsubsection": "", "code": "\nqualify X64_A (in Arch)\n\ntext \\<open> Arch-specific part of a TCB: this must have at least a field for user context. \\<close>\nrecord arch_tcb =\n  tcb_context :: user_context\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  default_arch_tcb :: arch_tcb where\n  \"default_arch_tcb \\<equiv> \\<lparr>tcb_context = new_context\\<rparr>\"\n\ntext \\<open> Accessors for @{text \"tcb_context\"} inside @{text \"arch_tcb\"}.\n  These are later used to implement @{text as_user}, i.e.\\ need to be\n  compatible with @{text user_monad}.\\<close>\ndefinition\n  arch_tcb_context_set :: \"user_context \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_context_set uc a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := uc \\<rparr>\"\n\ndefinition\n  arch_tcb_context_get :: \"arch_tcb \\<Rightarrow> user_context\"\nwhere\n  \"arch_tcb_context_get a_tcb \\<equiv> tcb_context a_tcb\"\n\n(* FIXME: the following means that we break the set/getRegister abstraction\n          and should move some of this into the machine interface *)\ntext \\<open>\n Accessors for the user register part of the @{text \"arch_tcb\"}.\n (Because @{typ \"register \\<Rightarrow> machine_word\"} may not be equal to @{typ user_context}).\n\\<close>\ndefinition\n  arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_set_registers regs a_tcb \\<equiv>\n    a_tcb \\<lparr> tcb_context := UserContext (fpu_state (tcb_context a_tcb)) regs \\<rparr>\"\n\ndefinition\n  arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\"\nwhere\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\n\nend"}
{"title": "./spec/abstract/X64/ArchFault_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFunctions for fault handling.\n*)\n\nchapter \\<open>arch fault related functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData) od\"\n\ndefinition\n  handle_arch_fault_reply :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_arch_fault_reply vmf thread x y \\<equiv> return True\"\n\n\nend\n\nend"}
{"title": "./spec/abstract/X64/ArchTcb_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  sanitise_or_flags :: machine_word\nwhere\n  \"sanitise_or_flags \\<equiv> bit 1 || bit 9\"\n\ndefinition\n  sanitise_and_flags :: machine_word\nwhere\n  \"sanitise_and_flags \\<equiv> mask 12 && ~~ bit 8 && ~~ bit 3 && ~~ bit 5\"\n\ndefinition\n  sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"sanitise_register t r v \\<equiv>\n    let val = (if r = FaultIP \\<or> r = NextIP \\<or> r = FS_BASE \\<or> r = GS_BASE\n               then if v > 0x00007fffffffffff \\<and> v < 0xffff800000000000 then 0 else v\n               else v)\n    in\n      if r = FLAGS then (val || sanitise_or_flags) && sanitise_and_flags else val\"\n\ndefinition\n  arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\nwhere\n  \"arch_get_sanitise_register_info t \\<equiv> return False\"\n\ndefinition\n  arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\nwhere\n  \"arch_post_modify_registers cur t \\<equiv> when (t \\<noteq> cur) $ as_user t $ setRegister ErrorRegister 0\"\n\nend\nend"}
{"title": "./spec/abstract/X64/ArchCSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"ArchCSpace\"\n\ntheory ArchCSpace_A\nimports\n  ArchVSpace_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition cnode_guard_size_bits :: \"nat\"\nwhere\n  \"cnode_guard_size_bits \\<equiv> 6\"\n\ndefinition cnode_padding_bits :: \"nat\"\nwhere\n  \"cnode_padding_bits \\<equiv> 0\"\n\ntext \\<open>On a user request to modify a cnode capability, extract new guard bits and guard.\\<close>\ndefinition\n  update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 58;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"\n\ntext \\<open>For some purposes capabilities to physical objects are treated\ndifferently to others.\\<close>\ndefinition\n  arch_is_physical :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_is_physical cap \\<equiv> case cap of\n                            ASIDControlCap \\<Rightarrow> False\n                          | IOPortCap _ _ \\<Rightarrow> False\n                          | IOPortControlCap \\<Rightarrow> False\n                          | _ \\<Rightarrow> True\"\n\ntext \\<open>Check whether the second capability is to the same object or an object\ncontained in the region of the first one.\\<close>\nfun\n  arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_same_region_as (PageCap dev r R t s m) c' =\n   (\\<exists> dev' r' R' t' s' m'. c' = PageCap dev' r' R' t' s' m' \\<and>\n   (let\n      topA = r + (1 << pageBitsForSize s) - 1;\n      topB = r' + (1 << pageBitsForSize s') - 1\n    in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB))\"\n| \"arch_same_region_as (PageTableCap r _) c' = (\\<exists>r' d'. c' = PageTableCap r' d' \\<and> r = r')\"\n| \"arch_same_region_as (PageDirectoryCap r _) c' = (\\<exists>r' d'. c' = PageDirectoryCap r' d' \\<and> r = r')\"\n| \"arch_same_region_as (PDPointerTableCap r _) c' = (\\<exists>r' d'. c' = PDPointerTableCap r' d' \\<and> r = r')\"\n| \"arch_same_region_as (PML4Cap r _) c' = (\\<exists>r' d'. c' = PML4Cap r' d' \\<and> r = r')\"\n| \"arch_same_region_as ASIDControlCap c' = (c' = ASIDControlCap)\"\n| \"arch_same_region_as (ASIDPoolCap r _) c' = (\\<exists>r' d'. c' = ASIDPoolCap r' d' \\<and> r = r')\"\n(* FIXME x64-vtd:\n| \"arch_same_region_as (IOPageTableCap r _ _) c = (is_IOPageTableCap c \\<and> aobj_ref c = Some r)\"\n| \"arch_same_region_as (IOSpaceCap d_id pci_d) c = (is_IOSpaceCap c \\<and> cap_io_pci_device c = pci_d)\"\n  FIXME x64-vtd: should this also check domain id equality? C kernel does not\"\n*)\n| \"arch_same_region_as (IOPortCap frst lst) c' =\n   (\\<exists>frst' lst'. c' = IOPortCap frst' lst' \\<and> frst' = frst \\<and> lst' = lst)\"\n| \"arch_same_region_as IOPortControlCap c' = (c' = IOPortControlCap \\<or> (\\<exists>f l. c' = IOPortCap f l))\"\n\ntext \\<open>Check whether two arch capabilities are to the same object.\\<close>\ndefinition\n  same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n \"same_aobject_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (PageCap dev ref _ _ pgsz _, PageCap dev' ref' _ _ pgsz' _)\n          \\<Rightarrow> (dev, ref, pgsz) = (dev', ref', pgsz')\n              \\<and> ref \\<le> ref + 2 ^ pageBitsForSize pgsz - 1\n    | (IOPortControlCap, IOPortCap f' l') \\<Rightarrow> False\n    | _ \\<Rightarrow> arch_same_region_as cp cp')\"\n\ndeclare same_aobject_as_def[simp]\n\ndefinition\n  arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"arch_is_cap_revocable new_cap src_cap \\<equiv>\n           if \\<exists>f l. new_cap = ArchObjectCap (IOPortCap f l)\n             then src_cap = ArchObjectCap IOPortControlCap\n             else False\"\n\nend\nend"}
{"title": "./spec/abstract/X64/Machine_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nTypes and operations to access the underlying machine, instantiated\nfor x64.\n*)\n\nchapter \"x64 Machine Instantiation\"\n\ntheory Machine_A\nimports\n  \"Monads.Nondet_Monad\"\n  \"ExecSpec.MachineTypes\"\n  \"ExecSpec.MachineOps\"\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  The specification is written with abstract type names for object\n  references, user pointers, word-based data, cap references, and so\n  on. This theory provides an instantiation of these names to concrete\n  types for the x64 architecture. Other architectures may have slightly\n  different instantiations.\n\\<close>\ntype_synonym obj_ref            = machine_word\ntype_synonym vspace_ref         = machine_word\n\ntype_synonym data               = machine_word\ntype_synonym cap_ref            = \"bool list\"\ntype_synonym length_type        = machine_word\n\ntype_synonym asid_low_len      = 9\ntype_synonym asid_low_index    = \"asid_low_len word\"\n\ntype_synonym asid_high_len      = 3\ntype_synonym asid_high_index    = \"asid_high_len word\"\n\n(* It might be nice if asid was \"12 word\", but Refine is easier if it is a machine_word.  *)\n(* Making asid a machine_word means that we need invariants that the extra bits are zero. *)\ntype_synonym asid_len           = 12\ntype_synonym asid_rep_len       = machine_word_len\ntype_synonym asid               = \"asid_rep_len word\"\n\ntext \\<open>With the definitions above, most conversions between abstract\ntype names boil down to just the identity function, some convert from\n@{text word} to @{typ nat} and others between different word sizes\nusing @{const ucast}.\\<close>\ndefinition\n  oref_to_data   :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_oref   :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition\n  vref_to_data   :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_vref   :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition\n  nat_to_len     :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition\n  data_to_nat    :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition\n  data_to_16     :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition\n  data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition\n  combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition\n  combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"\n\n\ntext \\<open>These definitions will be unfolded automatically in proofs.\\<close>\nlemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def\n\n\ntext \\<open>The following definitions provide architecture-dependent sizes\n  such as the standard page size and capability size of the underlying\n  machine.\n\\<close>\ndefinition\n  slot_bits :: nat where\n  \"slot_bits \\<equiv> 5\"\n\ndefinition\n  msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 52\"\n\ndefinition\n  new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext FPUNullState ((\\<lambda>r. 0)(CS := selCS3, SS := selDS3, FLAGS := 0x202))\"\n\ndefinition\n  pptr_base :: \"machine_word\" where\n  \"pptr_base = Platform.X64.pptrBase\"\n\n(* Virtual address space available to users. *)\ndefinition\n  user_vtop :: \"machine_word\" where\n  \"user_vtop = Platform.X64.pptrUserTop\"\n\ntext \\<open>The lowest virtual address in the kernel window. The kernel reserves the\nvirtual addresses from here up in every virtual address space.\\<close>\ndefinition\n  kernel_base :: \"vspace_ref\" where\n  \"kernel_base \\<equiv> 0xffffffff80000000\"\n\ndefinition\n  idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = kernel_base + 0x1000\"\n\nend\n\narch_requalify_consts (A) idle_thread_ptr\n\ncontext Arch begin arch_global_naming (A)\n\n(* is nat_to_cref arch specific ? *)\ndefinition\n  nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\" where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len)\n                           (to_bl (of_nat n :: machine_word))\"\ndefinition\n \"msg_info_register \\<equiv> msgInfoRegister\"\ndefinition\n \"msg_registers \\<equiv> msgRegisters\"\ndefinition\n \"cap_register \\<equiv> capRegister\"\ndefinition\n \"badge_register \\<equiv> badgeRegister\"\ndefinition\n \"frame_registers \\<equiv> frameRegisters\"\ndefinition\n \"gp_registers \\<equiv> gpRegisters\"\ndefinition\n \"exception_message \\<equiv> exceptionMessage\"\ndefinition\n \"syscall_message \\<equiv> syscallMessage\"\n\ndatatype arch_fault\n  = VMFault vspace_ref \"machine_word list\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchInterrupt_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Arch-specific Interrupts\"\n\ntheory ArchInterrupt_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition handle_reserved_irq :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"handle_reserved_irq irq = return ()\"\n\nfun arch_invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_invoke_irq_handler (ACKIrq irq) = (do_machine_op $ plic_complete_claim irq)\"\n| \"arch_invoke_irq_handler _ = return ()\"\n\ndefinition arch_mask_irq_signal :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_mask_irq_signal irq \\<equiv> return ()\"\n\nend\n\n(* On Arm architectures, maxIRQ is defined in Kernel_Config. On RISCV64 it is defined manually. *)\narch_requalify_consts\n  maxIRQ\n\nend"}
{"title": "./spec/abstract/RISCV64/Arch_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Toplevel RISCV64 Definitions\"\n\ntheory Arch_A\nimports TcbAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition page_bits :: nat\n  where\n  \"page_bits \\<equiv> pageBits\"\n\nfun arch_invoke_irq_control :: \"arch_irq_control_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\"\n  where\n  \"arch_invoke_irq_control (RISCVIRQControlInvocation irq handler_slot control_slot trigger) =\n     without_preemption (do\n       do_machine_op $ setIRQTrigger irq trigger;\n       set_irq_state IRQSignal (irq);\n       cap_insert (IRQHandlerCap (irq)) control_slot handler_slot\n  od)\"\n\ndefinition arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_switch_to_thread t \\<equiv> set_vm_root t\"\n\ndefinition arch_switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\"\n  where\n  \"arch_switch_to_idle_thread \\<equiv> do\n    thread \\<leftarrow> gets idle_thread;\n    set_vm_root thread\n  od\"\n\ndefinition arch_activate_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_activate_idle_thread t \\<equiv> return ()\"\n\ndefinition store_asid_pool_entry :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> obj_ref option \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\n  where\n  \"store_asid_pool_entry pool_ptr asid ptr \\<equiv> do\n    pool \\<leftarrow> get_asid_pool pool_ptr;\n    pool' \\<leftarrow> return $ pool(asid_low_bits_of asid := ptr);\n    set_asid_pool pool_ptr pool'\n  od\"\n\ntext \\<open>\n  The ASIDControl capability confers the authority to create a new ASID pool object. This\n  operation creates the new ASID pool, provides a capability to it and connects it to the global\n  virtual ASID table.\n\\<close>\ndefinition perform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_asid_control_invocation iv \\<equiv> case iv of\n     MakePool frame slot parent base \\<Rightarrow> do\n       delete_objects frame pageBits;\n       pcap \\<leftarrow> get_cap parent;\n       set_cap (max_free_index_update pcap) parent;\n       retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n       cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n       assert (asid_low_bits_of base = 0);\n       asid_table \\<leftarrow> gets (riscv_asid_table \\<circ> arch_state);\n       asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n       modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>riscv_asid_table := asid_table'\\<rparr>\\<rparr>)\n     od\"\n\ntext \\<open>The ASIDPool capability confers the authority to assign an ASID to a top-level page table.\\<close>\ndefinition perform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_asid_pool_invocation iv \\<equiv> case iv of\n     Assign asid pool_ptr ct_slot \\<Rightarrow> do\n       pt_cap \\<leftarrow> get_cap ct_slot;\n       assert $ is_ArchObjectCap pt_cap;\n       acap \\<leftarrow> return $ the_arch_cap pt_cap;\n       assert $ is_PageTableCap acap;\n       set_cap (ArchObjectCap $ update_map_data acap $ Some (asid,0)) ct_slot;\n       pt_base \\<leftarrow> return $ acap_obj acap;\n       copy_global_mappings pt_base;\n       store_asid_pool_entry pool_ptr asid (Some pt_base)\n     od\"\n\ndefinition perform_pg_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_pg_inv_unmap cap ct_slot \\<equiv> do\n     assert $ is_FrameCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> unmap_page (acap_fsize cap) asid vaddr (acap_obj cap)\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data (the_arch_cap old_cap) None) ct_slot\n   od\"\n\ndefinition perform_pg_inv_map :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_pg_inv_map cap ct_slot pte slot \\<equiv> do\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte slot pte;\n     do_machine_op sfence\n   od\"\n\ndefinition perform_pg_inv_get_addr :: \"obj_ref \\<Rightarrow> (data list,'z::state_ext) s_monad\"\n  where\n  \"perform_pg_inv_get_addr ptr \\<equiv> return [addrFromPPtr ptr]\"\n\ntext \\<open>The Frame capability confers the authority to map and unmap memory.\\<close>\ndefinition perform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\"\n  where\n  \"perform_page_invocation iv \\<equiv> case iv of\n     PageMap cap ct_slot (pte,slot) \\<Rightarrow> do perform_pg_inv_map cap ct_slot pte slot; return [] od\n   | PageUnmap cap ct_slot \\<Rightarrow> do perform_pg_inv_unmap cap ct_slot; return [] od\n   | PageGetAddr ptr \\<Rightarrow> perform_pg_inv_get_addr ptr\"\n\n\ndefinition perform_pt_inv_map :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_pt_inv_map cap ct_slot pte slot = do\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte slot pte;\n     do_machine_op sfence\n   od\"\n\ndefinition perform_pt_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_pt_inv_unmap cap ct_slot = do\n     assert $ is_PageTableCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> do\n         p \\<leftarrow> return $ acap_obj cap;\n         unmap_page_table asid vaddr p;\n         slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 << pt_bits) - 1];\n         mapM_x (swp store_pte InvalidPTE) slots\n       od\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data old_cap None) ct_slot\n   od\"\n\ntext \\<open>PageTable capabilities confer the authority to map and unmap page tables.\\<close>\ndefinition perform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_page_table_invocation iv \\<equiv> case iv of\n     PageTableMap cap ct_slot pte slot \\<Rightarrow> perform_pt_inv_map cap ct_slot pte slot\n   | PageTableUnmap cap ct_slot \\<Rightarrow> perform_pt_inv_unmap cap ct_slot\"\n\nlocale_abbrev arch_no_return :: \"(unit, 'z::state_ext) s_monad \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\n  where\n  \"arch_no_return oper \\<equiv> do oper; return [] od\"\n\ntext \\<open>Top level system call dispatcher for all RISCV64-specific system calls.\\<close>\ndefinition arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\n  where\n  \"arch_perform_invocation i \\<equiv> liftE $ case i of\n     InvokePageTable oper \\<Rightarrow> arch_no_return $ perform_page_table_invocation oper\n   | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n   | InvokeASIDControl oper \\<Rightarrow> arch_no_return $ perform_asid_control_invocation oper\n   | InvokeASIDPool oper \\<Rightarrow> arch_no_return $ perform_asid_pool_invocation oper\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/Hypervisor_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Handle Hypervisor Fault Events\"\n\ntheory Hypervisor_A\nimports Exceptions_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"machine_word \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\n  where\n  \"handle_hypervisor_fault thread RISCVNoHypFaults = return ()\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchRetype_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture specific Retype definitions\"\n\ntheory ArchRetype_A\nimports\n  ArchVSpaceAcc_A\n  ArchInvocation_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This is a placeholder function. We may wish to extend the specification\n  with explicitly tagging kernel data regions in memory.\n\\<close>\ndefinition reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"\n\ntext \\<open>Initialise architecture-specific objects.\\<close>\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv> return ()\"\n\ndefinition empty_context :: user_context\n  where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb\n  where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context \\<rparr>\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchIpcCancel_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>Arch IPC Cancelling\\<close>\n\ntheory ArchIpcCancel_A\nimports CSpaceAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>Actions to be taken after a cap is deleted\\<close>\ndefinition arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\n  where\n  \"arch_post_cap_deletion ac \\<equiv> return ()\"\n\ntext \\<open>Arch specific generic object references not covered by generic references\\<close>\ndatatype arch_gen_obj_ref = unit\n\ndefinition arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\"\n  where\n  \"arch_gen_obj_refs ac \\<equiv> {}\"\n\ndefinition arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\"\n  where\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/Init_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"An Initial Kernel State\"\n\ntheory Init_A\nimports\n  Retype_A\n  \"Lib.SplitRule\"\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This is not a specification of true kernel initialisation. This theory describes a dummy\n  initial state only, to show that the invariants and refinement relation are consistent.\n\\<close>\n\n(* Some address sufficiently aligned address for one page *)\ndefinition riscv_global_pt_ptr :: obj_ref\n  where\n  \"riscv_global_pt_ptr = pptr_base + 0x2000\"\n\n(* Sufficiently aligned for irq type + cte_level_bits *)\ndefinition init_irq_node_ptr :: obj_ref\n  where\n  \"init_irq_node_ptr = pptr_base + 0x3000\"\n\n(* The highest user-level virtual address that is still canonical.\n   It can be larger than user_vtop, which is the highest address we allow to be mapped.\n   We need canonical_user, because the page tables have to have valid mappings there. *)\ndefinition canonical_user :: \"vspace_ref\" where\n  \"canonical_user \\<equiv> mask canonical_bit\"\n\n(* Kernel and ELF window are constructed so that they can be covered with one max_pt_level entry\n   each. This is not the layout the real kernel uses, but we are only trying to show that\n   the invariants are consistent.\n\n   The values we pick here for the size of these regions constrain pptr_base and kernel_elf_base in\n   real kernel configurations, so we pick relatively small values that are reasonable lower bounds\n   for real platforms and that are still large enough to work for the examples. In particular, the\n   InfoFlow example gives a constraint that the kernel window is at least large enough to contain a\n   RISCVLargePage and a minimal set of other objects. This leads to picking values of:\n   4M physical memory (1 << 22) and one page (1 << pageBits) for the kernel elf region. *)\ndefinition kernel_window_bits :: nat where\n  \"kernel_window_bits \\<equiv> 22\"\n\ndefinition init_vspace_uses :: \"vspace_ref \\<Rightarrow> riscvvspace_region_use\"\n  where\n  \"init_vspace_uses p \\<equiv>\n     if p \\<in> {pptr_base ..< pptr_base + (1 << kernel_window_bits)} then RISCVVSpaceKernelWindow\n     else if p \\<in> {kernel_elf_base ..< kernel_elf_base + (1 << pageBits)} then RISCVVSpaceKernelELFWindow\n     else if p \\<le> canonical_user then RISCVVSpaceUserRegion\n     else RISCVVSpaceInvalidRegion\"\n\ndefinition init_arch_state :: arch_state\n  where\n  \"init_arch_state \\<equiv> \\<lparr>\n     riscv_asid_table = Map.empty,\n     riscv_global_pts = (\\<lambda>level. if level = max_pt_level then {riscv_global_pt_ptr} else {}),\n     riscv_kernel_vspace = init_vspace_uses\n   \\<rparr>\"\n\ndefinition toplevel_bits :: nat\n  where\n  \"toplevel_bits = pt_bits_left max_pt_level\"\n\ndefinition elf_index :: pt_index\n  where\n  \"elf_index = ucast (pt_index max_pt_level kernel_elf_base)\"\n\n(* {pptr_base ..< pptr_base + (1 << kernel_window_bits)} is pt index 0x100 at max_pt_level,\n   {kernel_elf_base ..< kernel_elf_base + (1 << pageBits)} comes out to elf_index.\n   The rest is constructed such that the translation lines up with what the invariants want. *)\ndefinition global_pte :: \"pt_index \\<Rightarrow> pte\"\n  where\n  \"global_pte idx \\<equiv>\n     if idx = 0x100\n     then PagePTE ((ucast (idx && mask (ptTranslationBits - 1)) << ptTranslationBits * size max_pt_level))\n                  {} vm_kernel_only\n     else if idx = elf_index\n     then PagePTE (ucast ((kernelELFPAddrBase && ~~mask toplevel_bits) >> pageBits)) {} vm_kernel_only\n     else InvalidPTE\"\n\ndefinition init_global_pt :: kernel_object\n  where\n  \"init_global_pt \\<equiv> ArchObj $ PageTable (\\<lambda>idx. if idx \\<in> kernel_mapping_slots\n                                                then global_pte idx\n                                                else InvalidPTE)\"\n\ndefinition init_kheap :: kheap\n  where\n  \"init_kheap \\<equiv>\n    (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n           then Some (CNode 0 (empty_cnode 0))\n           else None)\n    (idle_thread_ptr \\<mapsto>\n       TCB \\<lparr>\n         tcb_ctable = NullCap,\n         tcb_vtable = NullCap,\n         tcb_reply = NullCap,\n         tcb_caller = NullCap,\n         tcb_ipcframe = NullCap,\n         tcb_state = IdleThreadState,\n         tcb_fault_handler = replicate word_bits False,\n         tcb_ipc_buffer = 0,\n         tcb_fault = None,\n         tcb_bound_notification = None,\n         tcb_mcpriority = minBound,\n         tcb_arch = init_arch_tcb\n         \\<rparr>,\n      riscv_global_pt_ptr \\<mapsto> init_global_pt\n    )\"\n\ndefinition init_cdt :: cdt\n  where\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition init_ioc :: \"cslot_ptr \\<Rightarrow> bool\"\n  where\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition init_A_st :: \"'z::state_ext state\"\n  where\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchVSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"RISCV64 VSpace Functions\"\n\ntheory ArchVSpace_A\nimports Retype_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  Look up a thread's IPC buffer and check that the thread has the authority to read or (in the\n  receiver case) write to it.\n\\<close>\ndefinition lookup_ipc_buffer :: \"bool \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\"\n  where\n  \"lookup_ipc_buffer is_receiver thread \\<equiv> do\n     buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n     buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n     buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n     case buffer_cap of\n       ArchObjectCap (FrameCap p R vms False _) \\<Rightarrow>\n         if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n         then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n         else return None\n     | _ \\<Rightarrow> return None\n   od\"\n\ndefinition pool_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\"\n  where\n  \"pool_for_asid asid \\<equiv> \\<lambda>s. riscv_asid_table (arch_state s) (asid_high_bits_of asid)\"\n\ndefinition vspace_for_pool :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (obj_ref \\<rightharpoonup> asid_pool) \\<Rightarrow> obj_ref option\"\n  where\n  \"vspace_for_pool pool_ptr asid \\<equiv> do {\n     pool \\<leftarrow> oapply pool_ptr;\n     K $ pool (asid_low_bits_of asid)\n   }\"\n\ndefinition vspace_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\"\n  where\n  \"vspace_for_asid asid = do {\n     oassert (0 < asid);\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     vspace_for_pool pool_ptr asid \\<circ> asid_pools_of\n   }\"\n\ntext \\<open>Locate the top-level page table associated with a given virtual ASID.\\<close>\ndefinition find_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\"\n  where\n  \"find_vspace_for_asid asid \\<equiv> doE\n    vspace_opt \\<leftarrow> liftE $ gets $ vspace_for_asid asid;\n    throw_opt InvalidRoot vspace_opt\n  odE\"\n\ntext \\<open>\n  Format a VM fault message to be passed to a thread's supervisor after it encounters a page fault.\n\\<close>\ndefinition handle_vm_fault :: \"obj_ref \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\n  where\n  \"handle_vm_fault thread fault_type = doE\n    addr \\<leftarrow> liftE $ do_machine_op read_stval;\n    let\n      loadf = (\\<lambda>a. throwError $ ArchFault $ VMFault a [0, vmFaultTypeFSR RISCVLoadAccessFault]);\n      storef = (\\<lambda>a. throwError $ ArchFault $ VMFault a [0, vmFaultTypeFSR RISCVStoreAccessFault]);\n      instrf = (\\<lambda>a. throwError $ ArchFault $ VMFault a [1, vmFaultTypeFSR RISCVInstructionAccessFault])\n    in\n      case fault_type of\n        RISCVLoadPageFault \\<Rightarrow> loadf addr\n      | RISCVLoadAccessFault \\<Rightarrow> loadf addr\n      | RISCVStorePageFault \\<Rightarrow> storef addr\n      | RISCVStoreAccessFault \\<Rightarrow> storef addr\n      | RISCVInstructionPageFault \\<Rightarrow> instrf addr\n      | RISCVInstructionAccessFault \\<Rightarrow> instrf addr\n  odE\"\n\ntext \\<open>\n  Switch into the address space of a given thread or the global address space if none is correctly\n  configured.\n\\<close>\ndefinition set_vm_root :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PageTableCap pt (Some (asid, _))) \\<Rightarrow> doE\n           pt' \\<leftarrow> find_vspace_for_asid asid;\n           whenE (pt \\<noteq> pt') $ throwError InvalidRoot;\n           liftE $ do_machine_op $ setVSpaceRoot (addrFromPPtr pt) (ucast asid)\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_pt \\<leftarrow> gets global_pt;\n       do_machine_op $ setVSpaceRoot (addrFromKPPtr global_pt) 0\n    od)\n  od\"\n\n\ndefinition delete_asid_pool :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"delete_asid_pool base ptr \\<equiv> do\n     assert (asid_low_bits_of base = 0);\n     asid_table \\<leftarrow> gets (riscv_asid_table \\<circ> arch_state);\n     when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n       pool \\<leftarrow> get_asid_pool ptr;\n       asid_table' \\<leftarrow> return $ asid_table (asid_high_bits_of base:= None);\n       modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> riscv_asid_table := asid_table' \\<rparr>\\<rparr>);\n       tcb \\<leftarrow> gets cur_thread;\n       set_vm_root tcb\n     od\n   od\"\n\n\ndefinition delete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"delete_asid asid pt \\<equiv> do\n     asid_table \\<leftarrow> gets (riscv_asid_table \\<circ> arch_state);\n     case asid_table (asid_high_bits_of asid) of\n       None \\<Rightarrow> return ()\n     | Some pool_ptr \\<Rightarrow> do\n         pool \\<leftarrow> get_asid_pool pool_ptr;\n         when (pool (asid_low_bits_of asid) = Some pt) $ do\n           do_machine_op $ hwASIDFlush (ucast asid);\n           pool' \\<leftarrow> return $ pool (asid_low_bits_of asid := None);\n           set_asid_pool pool_ptr pool';\n           tcb \\<leftarrow> gets cur_thread;\n           set_vm_root tcb\n         od\n       od\n   od\"\n\ndefinition unmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"unmap_page_table asid vaddr pt \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     pt_slot \\<leftarrow> pt_lookup_from_level max_pt_level top_level_pt vaddr pt;\n     liftE $ store_pte pt_slot InvalidPTE;\n     liftE $ do_machine_op sfence\n   odE <catch> (K $ return ())\"\n\ntext \\<open>\n  Look up an @{text \"asid+vspace_ref\"} down to the provided level in the page table.\n  For level @{term bot_level}, return a pointer to a table at the returned level.\n  The level can be higher than @{term bot_level} if the lookup terminates early because\n  it hit a page or an invalid entry.\n\\<close>\ndefinition vs_lookup_table :: \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"vs_lookup_table bot_level asid vptr \\<equiv> do {\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     if bot_level = asid_pool_level\n     then oreturn (asid_pool_level, pool_ptr)\n     else do {\n       top_level_pt \\<leftarrow> vspace_for_pool pool_ptr asid \\<circ> asid_pools_of;\n       pt_walk max_pt_level bot_level top_level_pt vptr \\<circ> ptes_of\n     }\n   }\"\n\ntext \\<open>\n  Same as @{const vs_lookup_table}, but return a pointer to a slot in a table at the returned level.\n  For @{prop \"bot_level = asid_pool_level\"}, still return the pointer to the ASID pool (not a slot\n  inside it, since there are no slot functions for ASID pools).\n\\<close>\ndefinition vs_lookup_slot :: \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"vs_lookup_slot bot_level asid vref \\<equiv> do {\n     (level', table) \\<leftarrow> vs_lookup_table bot_level asid vref;\n     if level' = asid_pool_level then\n       oreturn (level', table)\n     else\n       oreturn (level', pt_slot_offset level' table vref)\n   }\"\n\ntext \\<open>Unmap a mapped page if the given mapping details are still current.\\<close>\ndefinition unmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"unmap_page pgsz asid vptr pptr \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     (lev, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot top_level_pt vptr \\<circ> ptes_of;\n     unlessE (pt_bits_left lev = pageBitsForSize pgsz) $ throwError InvalidRoot;\n     pte \\<leftarrow> liftE $ get_pte slot;\n     unlessE (is_PagePTE pte \\<and> pptr_from_pte pte = pptr) $ throwError InvalidRoot;\n     liftE $ store_pte slot InvalidPTE;\n     liftE $ do_machine_op sfence\n   odE <catch> (K $ return ())\"\n\ntext \\<open>\n  Page table structure capabilities cannot be copied until they have an ASID and location\n  assigned. This is because they cannot have multiple current ASIDs and cannot be shared between\n  address spaces or virtual locations.\n\\<close>\ndefinition arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\"\n  where\n  \"arch_derive_cap c \\<equiv>\n     case c of\n       PageTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n     | PageTableCap _ None \\<Rightarrow> throwError IllegalOperation\n     | FrameCap r R sz dev mp \\<Rightarrow> returnOk $ ArchObjectCap (FrameCap r R sz dev None)\n     | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n     | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\"\n\ntext \\<open>No user-modifiable data is stored in RISCV64-specific capabilities.\\<close>\ndefinition arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\n  where\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"\n\n\ntext \\<open>Actions that must be taken on finalisation of RISCV64-specific capabilities.\\<close>\ndefinition arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\n  where\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n     (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n       delete_asid_pool b ptr;\n       return (NullCap, NullCap)\n     od\n   | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n       doE\n         vroot \\<leftarrow> find_vspace_for_asid a;\n         if vroot = ptr then liftE $ delete_asid a ptr else throwError InvalidRoot\n       odE <catch>\n       (\\<lambda>_. unmap_page_table a v ptr);\n       return (NullCap, NullCap)\n     od\n   | (FrameCap ptr _ sz _ (Some (a, v)), _) \\<Rightarrow> do\n       unmap_page sz a v ptr;\n       return (NullCap, NullCap)\n     od\n   | _ \\<Rightarrow> return (NullCap, NullCap)\"\n\n\ntext \\<open>\n  A thread's virtual address space capability must be to a mapped page table to be valid on\n  the RISCV64 architecture.\n\\<close>\ndefinition is_valid_vtable_root :: \"cap \\<Rightarrow> bool\"\n  where\n  \"is_valid_vtable_root c \\<equiv>\n     case c of ArchObjectCap (PageTableCap _ (Some _)) \\<Rightarrow> True | _ \\<Rightarrow> False\"\n\ntext \\<open>Make numeric value of @{const msg_align_bits} visible.\\<close>\nlemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\ndefinition check_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_valid_ipc_buffer vptr c \\<equiv>\n     case c of\n       ArchObjectCap (FrameCap _ _ _ False _) \\<Rightarrow>\n         whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError\n     | _ \\<Rightarrow> throwError IllegalOperation\"\n\ntext \\<open>A pointer is inside a user frame if its top bits point to a @{const DataPage}.\\<close>\ndefinition in_user_frame :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\"\n  where\n  \"in_user_frame p s \\<equiv>\n     \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) = Some (ArchObj (DataPage False sz))\"\n\ndefinition prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"prepare_thread_delete thread_ptr \\<equiv> return ()\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchVSpaceAcc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Accessing the RISCV64 VSpace\"\n\ntheory ArchVSpaceAcc_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This part of the specification is fairly concrete as the machine architecture is visible to\n  the user in seL4 and therefore needs to be described. The abstraction compared to the\n  implementation is in the data types for kernel objects. The interface which is rich in machine\n  details remains the same.\n\\<close>"}
{"title": "./spec/abstract/RISCV64/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The high bits of a virtual ASID.\\<close>\ndefinition asid_high_bits_of :: \"asid \\<Rightarrow> asid_high_index\"\n  where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"\n\ntext \\<open>The low bits of a virtual ASID.\\<close>\ndefinition asid_low_bits_of :: \"asid \\<Rightarrow> asid_low_index\"\n  where\n  \"asid_low_bits_of asid \\<equiv> ucast asid\"\n\nlemmas asid_bits_of_defs = asid_high_bits_of_def asid_low_bits_of_def\n\nlocale_abbrev\n  \"asid_table \\<equiv> \\<lambda>s. riscv_asid_table (arch_state s)\""}
{"title": "./spec/abstract/RISCV64/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\n(* declared in Arch as workaround for VER-1099 *)\nlocale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\"\n  where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"\n\ntext \\<open>Manipulate ASID pools, page directories and page tables in the kernel heap.\\<close>\n\nlocale_abbrev asid_pools_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> asid_pool\"\n  where\n  \"asid_pools_of \\<equiv> \\<lambda>s. aobjs_of s |> asid_pool_of\"\n\nlocale_abbrev get_asid_pool :: \"obj_ref \\<Rightarrow> (asid_low_index \\<rightharpoonup> obj_ref, 'z::state_ext) s_monad\"\n  where\n  \"get_asid_pool \\<equiv> gets_map asid_pools_of\"\n\ndefinition set_asid_pool :: \"obj_ref \\<Rightarrow> (asid_low_index \\<rightharpoonup> obj_ref) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_asid_pool ptr pool \\<equiv> do\n     get_asid_pool ptr;\n     set_object ptr (ArchObj (ASIDPool pool))\n   od\"\n\nlocale_abbrev pts_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> pt\"\n  where\n  \"pts_of \\<equiv> \\<lambda>s. aobjs_of s |> pt_of\"\n\nlocale_abbrev get_pt :: \"obj_ref \\<Rightarrow> (pt_index \\<Rightarrow> pte,'z::state_ext) s_monad\"\n  where\n  \"get_pt \\<equiv> gets_map pts_of\"\n\ndefinition set_pt :: \"obj_ref \\<Rightarrow> (pt_index \\<Rightarrow> pte) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"set_pt ptr pt \\<equiv> do\n     get_pt ptr;\n     set_object ptr (ArchObj (PageTable pt))\n   od\"\n\n(* The base address of the table a page table entry at p is in (assuming alignment) *)\nlocale_abbrev table_base :: \"obj_ref \\<Rightarrow> obj_ref\" where\n  \"table_base p \\<equiv> p && ~~mask pt_bits\"\n\n(* The index within the page table that a page table entry at p addresses *)\nlocale_abbrev table_index :: \"obj_ref \\<Rightarrow> pt_index\" where\n  \"table_index p \\<equiv> ucast (p && mask pt_bits >> pte_bits)\"\n\n(* p is the address of the pte,\n   which consists of base (for the pt) and offset (for the index inside the pt).\n   We assert that we avoid addresses between ptes. *)\ndefinition pte_of :: \"obj_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pt) \\<rightharpoonup> pte\"\n  where\n  \"pte_of p \\<equiv> do {\n     oassert (is_aligned p pte_bits);\n     pt \\<leftarrow> oapply (table_base p);\n     oreturn $ pt (table_index p)\n   }\"\n\nlocale_abbrev ptes_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> pte\"\n  where\n  \"ptes_of s \\<equiv> \\<lambda>p. pte_of p (pts_of s)\"\n\ntext \\<open>The following function takes a pointer to a PTE in kernel memory and returns the PTE.\\<close>\nlocale_abbrev get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\"\n  where\n  \"get_pte \\<equiv> gets_map ptes_of\"\n\ndefinition store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"store_pte p pte \\<equiv> do\n     assert (is_aligned p pte_bits);\n     base \\<leftarrow> return $ table_base p;\n     index \\<leftarrow> return $ table_index p;\n     pt \\<leftarrow> get_pt (table_base p);\n     pt' \\<leftarrow> return $ pt (index := pte);\n     set_pt base pt'\n   od\""}
{"title": "./spec/abstract/RISCV64/ArchVSpaceAcc_A.thy", "section": "Basic Operations", "subsection": "", "subsubsection": "", "code": "\ndefinition pt_bits_left :: \"vm_level \\<Rightarrow> nat\"\n  where\n  \"pt_bits_left level = ptTranslationBits * size level + pageBits\"\n\ndefinition pt_index :: \"vm_level \\<Rightarrow> vspace_ref \\<Rightarrow> machine_word\"\n  where\n  \"pt_index level vptr \\<equiv> (vptr >> pt_bits_left level) && mask ptTranslationBits\"\n\ntext \\<open>Interface function to extract the single top-level global page table:\\<close>\ndefinition riscv_global_pt :: \"arch_state \\<Rightarrow> obj_ref\"\n  where\n  \"riscv_global_pt s = the_elem (riscv_global_pts s max_pt_level)\"\n\nlocale_abbrev global_pt :: \"'z state \\<Rightarrow> obj_ref\"\n  where\n  \"global_pt s \\<equiv> riscv_global_pt (arch_state s)\"\n\ntext \\<open>\n  The kernel window is mapped into every virtual address space from the @{term pptr_base}\n  pointer upwards. This function copies the mappings which create the kernel window into a new\n  top-level page table object.\n\\<close>\ndefinition copy_global_mappings :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"copy_global_mappings new_pm \\<equiv> do\n    global_pt \\<leftarrow> gets global_pt;\n    base \\<leftarrow> return $ pt_index max_pt_level pptr_base;\n    pt_size \\<leftarrow> return $ 1 << ptTranslationBits;\n    mapM_x (\\<lambda>index. do\n        offset \\<leftarrow> return (index << pte_bits);\n        pme \\<leftarrow> get_pte (global_pt + offset);\n        store_pte (new_pm + offset) pme\n    od) [base  .e.  pt_size - 1]\n  od\"\n\ntext \\<open>Walk page tables in software.\\<close>\n\n(* pte addresses will always be at least page aligned *)\ndefinition pptr_from_pte :: \"pte \\<Rightarrow> vspace_ref\"\n  where\n  \"pptr_from_pte pte \\<equiv> ptrFromPAddr (addr_from_pte pte)\"\n\ndefinition pt_slot_offset :: \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\"\n  where\n  \"pt_slot_offset level pt_ptr vptr = pt_ptr + (pt_index level vptr << pte_bits)\"\n\ntext \\<open>\n  This is the base function for walking a page table structure.\n  The walk proceeds from higher-level tables at the provided @{term level} (e.g. 2) to lower\n  level tables, down to @{term bot_level} (e.g. 0). It returns a pointer to the page table where\n  the walk stopped and the level of that table. The lookup stops when @{term bot_level} or a\n  page is reached.\n\\<close>\nfun pt_walk ::\n  \"vm_level \\<Rightarrow> vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pte) \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"pt_walk level bot_level pt_ptr vptr = do {\n     if bot_level < level\n     then do {\n       pte \\<leftarrow> oapply (pt_slot_offset level pt_ptr vptr);\n       if is_PageTablePTE pte\n         then pt_walk (level - 1) bot_level (pptr_from_pte pte) vptr\n         else oreturn (level, pt_ptr)\n     }\n     else oreturn (level, pt_ptr)\n   }\"\n\ndeclare pt_walk.simps[simp del]\n\ntext \\<open>\n  Looking up a slot in a page table structure. The function returns a level and an object\n  pointer. The pointer is to a slot in a table at the returned level. If the returned level is 0,\n  this slot is either an @{const InvalidPTE} or a @{const PagePTE}. If the returned level is higher\n  the slot may also be a @{const PageTablePTE}.\n\\<close>\ndefinition pt_lookup_slot_from_level ::\n  \"vm_level \\<Rightarrow> vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pte) \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"pt_lookup_slot_from_level level bot_level pt_ptr vptr = do {\n     (level', pt_ptr') \\<leftarrow> pt_walk level bot_level pt_ptr vptr;\n     oreturn (level', pt_slot_offset level' pt_ptr' vptr)\n   }\"\n\ndefinition pt_lookup_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pte) \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"pt_lookup_slot = pt_lookup_slot_from_level max_pt_level 0\"\n\n(* Returns the slot that points to target_pt_ptr *)\nfun pt_lookup_from_level ::\n  \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (machine_word, 'z::state_ext) lf_monad\"\n  where\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr s = (doE\n     unlessE (0 < level) $ throwError InvalidRoot;\n     slot <- returnOk $ pt_slot_offset level pt_ptr vptr;\n     pte <- liftE $ gets_the $ oapply slot o ptes_of;\n     unlessE (is_PageTablePTE pte) $ throwError InvalidRoot;\n     ptr <- returnOk (pptr_from_pte pte);\n     if ptr = target_pt_ptr\n       then returnOk slot\n       else pt_lookup_from_level (level - 1) ptr vptr target_pt_ptr\n   odE) s\"\n(* We apply \"s\" to avoid a type variable warning, and increase in global freeindex counter,\n   which we would get without the application *)\n\ndeclare pt_lookup_from_level.simps[simp del]\n\n(* Recover simp rule without state applied: *)\nschematic_goal pt_lookup_from_level_simps:\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr = ?rhs\"\n  by (rule ext, rule pt_lookup_from_level.simps)\n\n(* Kernel mappings go from pptr base to top of virtual memory. This definition encompasses\n   the kernel window, kernel ELF window, and kernel device window.\n   These indices identify the relevant top level table slots. *)\ndefinition kernel_mapping_slots :: \"pt_index set\" where\n  \"kernel_mapping_slots \\<equiv> {i. i \\<ge> ucast (pptr_base >> pt_bits_left max_pt_level)}\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchDecode_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Decoding Architecture-specific System Calls\"\n\ntheory ArchDecode_A\nimports\n  Interrupt_A\n  InvocationLabels_A\n  \"ExecSpec.InvocationLabels_H\"\nbegin\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/RISCV64/ArchDecode_A.thy", "section": "Architecture-specific Decode Functions", "subsection": "", "subsubsection": "", "code": "\ndefinition check_vp_alignment :: \"vmpage_size \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $ throwError AlignmentError\"\n\ndefinition page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\n  where\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\""}
{"title": "./spec/abstract/RISCV64/ArchDecode_A.thy", "section": "Interface Functions used in Decode", "subsection": "", "subsubsection": "", "code": "\ndefinition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> whenE (irq > ucast maxIRQ \\<or> irq = ucast irqInvalid) $\n                          throwError (RangeError 1 (ucast maxIRQ))\"\n\ndefinition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n     (if invocation_type label = ArchInvocationLabel RISCVIRQIssueIRQHandler\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n          returnOk $ RISCVIRQControlInvocation irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\ndefinition attribs_from_word :: \"machine_word \\<Rightarrow> vm_attributes\"\n  where\n  \"attribs_from_word w \\<equiv> if \\<not> w!!0 then {Execute} else {}\"\n\ndefinition make_user_pte :: \"vspace_ref \\<Rightarrow> vm_attributes \\<Rightarrow> vm_rights \\<Rightarrow> pte\"\n  where\n  \"make_user_pte addr attr rights \\<equiv>\n    if rights = {} \\<and> attr = {}\n    then InvalidPTE\n    else PagePTE (ucast (addr >> pageBits)) (attr \\<union> {User}) rights\"\n\ndefinition check_slot :: \"obj_ref \\<Rightarrow> (pte \\<Rightarrow> bool) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_slot slot test = doE\n     pte \\<leftarrow> liftE $ get_pte slot;\n     unlessE (test pte) $ throwError DeleteFirst\n   odE\"\n\ntype_synonym 'z arch_decoder =\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    (arch_invocation,'z) se_monad\"\n\ndefinition decode_fr_inv_map :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_fr_inv_map label args cte cap extra_caps \\<equiv> case cap of\n     FrameCap p R pgsz dev mapped_address \\<Rightarrow>\n       if length args > 2 \\<and> length extra_caps > 0\n       then let\n           vaddr = args ! 0;\n           rights_mask = args ! 1;\n           attr = args ! 2;\n           vspace_cap = fst (extra_caps ! 0)\n         in doE\n           (pt, asid) \\<leftarrow> case vspace_cap of\n                           ArchObjectCap (PageTableCap pt (Some (asid, _))) \\<Rightarrow> returnOk (pt, asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1;\n           pt' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n           whenE (pt' \\<noteq> pt) $ throwError $ InvalidCapability 1;\n           pg_bits \\<leftarrow> returnOk $ pageBitsForSize pgsz;\n           vtop \\<leftarrow> returnOk $ vaddr + mask (pageBitsForSize pgsz);\n           whenE (vtop \\<ge> user_vtop) $ throwError $ InvalidArgument 0;\n           check_vp_alignment pgsz vaddr;\n           (level, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot pt vaddr \\<circ> ptes_of;\n           unlessE (pt_bits_left level = pg_bits) $\n             throwError $ FailedLookup False $ MissingCapability $ pt_bits_left level;\n           case mapped_address of\n             Some (asid', vaddr') \\<Rightarrow> doE\n               whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n               whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0);\n               check_slot slot (Not \\<circ> is_PageTablePTE)\n             odE\n           | None \\<Rightarrow> check_slot slot ((=) InvalidPTE);\n           vm_rights \\<leftarrow> returnOk $ mask_vm_rights R (data_to_rights rights_mask);\n           attribs \\<leftarrow> returnOk $ attribs_from_word attr;\n           pte \\<leftarrow> returnOk $ make_user_pte (addrFromPPtr p) attribs vm_rights;\n           returnOk $ InvokePage $ PageMap (FrameCap p R pgsz dev (Some (asid,vaddr))) cte (pte,slot)\n         odE\n       else throwError TruncatedMessage\n     | _ \\<Rightarrow> fail\"\n\ndefinition decode_frame_invocation :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_frame_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel RISCVPageMap\n     then decode_fr_inv_map label args cte cap extra_caps\n     else if invocation_type label = ArchInvocationLabel RISCVPageUnmap\n     then returnOk $ InvokePage $ PageUnmap cap cte\n     else if invocation_type label = ArchInvocationLabel RISCVPageGetAddress\n     then returnOk $ InvokePage $ PageGetAddr (acap_obj cap)\n     else throwError IllegalOperation\"\n\ndefinition decode_pt_inv_map :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_pt_inv_map label args cte cap extra_caps \\<equiv> case cap of\n     PageTableCap p mapped_address \\<Rightarrow>\n       if length args > 1 \\<and> length extra_caps > 0\n       then let\n           vaddr = args ! 0;\n           attr = args ! 1;\n           vspace_cap = fst (extra_caps ! 0)\n         in doE\n           whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n           (pt, asid) \\<leftarrow> case vspace_cap of\n                           ArchObjectCap (PageTableCap pt (Some (asid,_))) \\<Rightarrow> returnOk (pt, asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1;\n           whenE (user_vtop \\<le> vaddr) $ throwError $ InvalidArgument 0;\n           pt' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n           whenE (pt' \\<noteq> pt) $ throwError $ InvalidCapability 1;\n           (level, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot pt vaddr \\<circ> ptes_of;\n           old_pte \\<leftarrow> liftE $ get_pte slot;\n           whenE (pt_bits_left level = pageBits \\<or> old_pte \\<noteq> InvalidPTE) $ throwError DeleteFirst;\n           pte \\<leftarrow> returnOk $ PageTablePTE (ucast (addrFromPPtr p >> pageBits)) {};\n           cap' <- returnOk $ PageTableCap p $ Some (asid, vaddr && ~~mask (pt_bits_left level));\n           returnOk $ InvokePageTable $ PageTableMap cap' cte pte slot\n         odE\n       else throwError TruncatedMessage\n     | _ \\<Rightarrow> fail\"\n\ndefinition decode_page_table_invocation :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_page_table_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel RISCVPageTableMap\n     then decode_pt_inv_map label args cte cap extra_caps\n     else if invocation_type label = ArchInvocationLabel RISCVPageTableUnmap\n     then doE\n       final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n       unlessE final $ throwError RevokeFirst;\n       case cap of\n         PageTableCap pt (Some (asid, _)) \\<Rightarrow> doE\n             \\<comment> \\<open>cannot invoke unmap on top level page table\\<close>\n             pt_opt \\<leftarrow> liftE $ gets $ vspace_for_asid asid;\n             whenE (pt_opt = Some pt) $ throwError RevokeFirst\n           odE\n       | _ \\<Rightarrow> returnOk ();\n       returnOk $ InvokePageTable $ PageTableUnmap cap cte\n     odE\n     else throwError IllegalOperation\"\n\ndefinition decode_asid_control_invocation :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_asid_control_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel RISCVASIDControlMakePool\n     then if length args > 1 \\<and> length extra_caps > 1\n     then let\n         index = args ! 0;\n         depth = args ! 1;\n         (untyped, parent_slot) = extra_caps ! 0;\n         root = fst (extra_caps ! 1)\n       in doE\n         asid_table \\<leftarrow> liftE $ gets (riscv_asid_table \\<circ> arch_state);\n         free_set \\<leftarrow> returnOk (- dom asid_table);\n         whenE (free_set = {}) $ throwError DeleteFirst;\n         free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n         base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n         (p,n) \\<leftarrow> case untyped of\n                    UntypedCap False p n _ \\<Rightarrow> returnOk (p,n)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 1;\n         frame \\<leftarrow> if n = pageBits then doE\n                    ensure_no_children parent_slot;\n                    returnOk p\n                  odE\n                  else throwError $ InvalidCapability 1;\n         dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n         ensure_empty dest_slot;\n         returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n       odE\n     else throwError TruncatedMessage\n     else throwError IllegalOperation\"\n\ndefinition decode_asid_pool_invocation :: \"'z::state_ext arch_decoder\"\n  where\n  \"decode_asid_pool_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel RISCVASIDPoolAssign\n     then if length extra_caps > 0\n     then let\n         (pt_cap, pt_cap_slot) = extra_caps ! 0;\n         p = acap_obj cap;\n         base = acap_asid_base cap\n       in case pt_cap of\n         ArchObjectCap (PageTableCap _ None) \\<Rightarrow> doE\n           asid_table \\<leftarrow> liftE $ gets (riscv_asid_table \\<circ> arch_state);\n           pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n           whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n           whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n           pool \\<leftarrow> liftE $ get_asid_pool p;\n           free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n           whenE (free_set = {}) $ throwError DeleteFirst;\n           offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n           returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pt_cap_slot\n         odE\n       | _ \\<Rightarrow> throwError $ InvalidCapability 1\n     else throwError TruncatedMessage\n     else throwError IllegalOperation\"\n\ndefinition arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n     PageTableCap _ _   \\<Rightarrow> decode_page_table_invocation label args cte cap extra_caps\n   | FrameCap _ _ _ _ _ \\<Rightarrow> decode_frame_invocation label args cte cap extra_caps\n   | ASIDControlCap     \\<Rightarrow> decode_asid_control_invocation label args cte cap extra_caps\n   | ASIDPoolCap _ _    \\<Rightarrow> decode_asid_pool_invocation label args cte cap extra_caps\""}
{"title": "./spec/abstract/RISCV64/ArchDecode_A.thy", "section": "Interface Functions used in Decode", "subsection": "", "subsubsection": "", "code": "\ndefinition arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\"\n  where\n  \"arch_data_to_obj_type n \\<equiv>\n     if      n = 0 then Some HugePageObj\n     else if n = 1 then Some SmallPageObj\n     else if n = 2 then Some LargePageObj\n     else if n = 3 then Some PageTableObj\n     else None\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchInvocation_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"RISCV64 Object Invocations\"\n\ntheory ArchInvocation_A\nimports Structures_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>These datatypes encode the arguments to the various possible RISCV64-specific system calls.\nSelectors are defined for various fields for convenience elsewhere.\\<close>\ndatatype page_table_invocation =\n    PageTableMap\n      (pt_inv_cap : arch_cap)\n      (pt_inv_cslot : cslot_ptr)\n      (pt_map_pte : pte)\n      (pt_map_slot : obj_ref)\n  | PageTableUnmap\n      (pt_inv_cap : arch_cap)\n      (pt_inv_cslot : cslot_ptr)\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation =\n    PageMap\n      (pg_inv_cap : arch_cap)\n      (pg_inv_cslot : cslot_ptr)\n      (pg_inv_entries : \"pte \\<times> obj_ref\")\n  | PageUnmap\n      (pg_inv_cap : arch_cap)\n      (pg_inv_cslot : cslot_ptr)\n  | PageGetAddr\n      (pg_get_paddr : obj_ref)\n\ndatatype arch_invocation =\n    InvokePageTable page_table_invocation\n  | InvokePage page_invocation\n  | InvokeASIDControl asid_control_invocation\n  | InvokeASIDPool asid_pool_invocation\n\ndatatype arch_copy_register_sets =\n    RISCVNoExtraRegisters\n\ndefinition ArchDefaultExtraRegisters :: arch_copy_register_sets\n  where\n  \"ArchDefaultExtraRegisters = RISCVNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    RISCVIRQControlInvocation irq cslot_ptr cslot_ptr bool\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"RISCV64-Specific Data Types\"\n\ntheory Arch_Structs_A\nimports\n  \"ExecSpec.Arch_Structs_B\"\n  ExceptionTypes_A\n  VMRights_A\n  ExecSpec.Arch_Kernel_Config_Lemmas\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This theory provides architecture-specific definitions and datatypes including\n  architecture-specific capabilities and objects.\n\\<close>"}
{"title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "section": "Architecture-specific objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  The RISCV64 kernel supports capabilities for ASID pools and an ASID controller capability,\n  along with capabilities for virtual memory mappings.\n\\<close>\n\ndatatype arch_cap =\n    ASIDPoolCap (acap_obj : obj_ref) (acap_asid_base : asid)\n  | ASIDControlCap\n  | FrameCap\n      (acap_obj : obj_ref)\n      (acap_rights : cap_rights)\n      (acap_fsize : vmpage_size)\n      (acap_is_device : bool)\n      (acap_map_data : \"(asid \\<times> vspace_ref) option\")\n  | PageTableCap (acap_obj : obj_ref) (acap_map_data : \"(asid \\<times> vspace_ref) option\")\n\n\ntext \\<open>Update the mapping data saved in a frame or page table capability.\\<close>\ndefinition update_map_data :: \"arch_cap \\<Rightarrow> (asid \\<times> vspace_ref) option \\<Rightarrow> arch_cap\"\n  where\n  \"update_map_data cap m \\<equiv> case cap of\n     FrameCap p R sz dev _  \\<Rightarrow> FrameCap p R sz dev m\n   | PageTableCap p _ \\<Rightarrow> PageTableCap p m\""}
{"title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "section": "Architecture-specific object types and default objects", "subsection": "", "subsubsection": "", "code": "\n(* This datatype does not match up with the executable spec directly:\n   This one here models all \"things\" one can set on a page or page table entry.\n   The attributes accessible to users are the ones returned by attribs_from_word. *)\ndatatype vm_attribute = Global | Execute | User\ntype_synonym vm_attributes = \"vm_attribute set\"\n\n(* The address of the target object is stored shifted right by pt_bits and stored as a ppn (page\n   number). To get the address, use addr_from_pte *)\ntype_synonym pte_ppn_len = 52 (* machine_word_len - pt_bits *)\ntype_synonym pte_ppn = \"pte_ppn_len word\"\n\ndefinition ppn_len :: nat where\n  \"ppn_len \\<equiv> LENGTH(pte_ppn_len)\"\n\ndatatype pte =\n    InvalidPTE\n  | PagePTE (pte_ppn : pte_ppn) (pte_attr : vm_attributes) (pte_rights : vm_rights)\n  | PageTablePTE (pte_ppn : pte_ppn) (pte_attr : vm_attributes)\n\ntype_synonym pt_index_len = 9\ntype_synonym pt_index = \"pt_index_len word\"\n\ntext \\<open>Sanity check:\\<close>\nlemma \"LENGTH(pt_index_len) = ptTranslationBits\"\n  by (simp add: ptTranslationBits_def)\n\ntype_synonym asid_pool = \"asid_low_index \\<rightharpoonup> obj_ref\"\ntype_synonym pt = \"pt_index \\<Rightarrow> pte\"\n\n(* produce discriminators and selectors even though no field names are mentioned *)\ndatatype (discs_sels) arch_kernel_obj =\n    ASIDPool asid_pool\n  | PageTable pt\n  | DataPage bool vmpage_size\n\ndefinition asid_pool_of :: \"arch_kernel_obj \\<rightharpoonup> asid_pool\"\n  where\n  \"asid_pool_of ko \\<equiv> case ko of ASIDPool pool \\<Rightarrow> Some pool | _ \\<Rightarrow> None\"\n\ndefinition pt_of :: \"arch_kernel_obj \\<rightharpoonup> pt\"\n  where\n  \"pt_of ko \\<equiv> case ko of PageTable pt \\<Rightarrow> Some pt | _ \\<Rightarrow> None\"\n\ndefinition pte_bits :: nat\n  where\n  \"pte_bits = word_size_bits\"\n\ndefinition table_size :: nat\n  where\n  \"table_size = ptTranslationBits + pte_bits\"\n\ndefinition pt_bits :: \"nat\"\n  where\n  \"pt_bits \\<equiv> table_size\"\n\ndefinition addr_from_ppn :: \"pte_ppn \\<Rightarrow> paddr\"\n  where\n  \"addr_from_ppn ppn = ucast ppn << pt_bits\"\n\nabbreviation addr_from_pte :: \"pte \\<Rightarrow> paddr\"\n  where\n  \"addr_from_pte pte \\<equiv> addr_from_ppn (pte_ppn pte)\"\n\nprimrec arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\n  where\n  \"arch_obj_size (ASIDPoolCap _ _) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (FrameCap _ _ sz _ _) = pageBitsForSize sz\"\n| \"arch_obj_size (PageTableCap _ _ ) = table_size\"\n\nfun arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\n  where\n  \"arch_cap_is_device (FrameCap _ _ _ is_dev _) = is_dev\"\n| \"arch_cap_is_device _ = False\"\n\ndefinition cte_level_bits :: nat\n  where\n  \"cte_level_bits \\<equiv> 5\"\n\ndefinition tcb_bits :: nat\n  where\n  \"tcb_bits \\<equiv> 10\"\n\ndefinition endpoint_bits :: nat\n  where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat\n  where\n  \"ntfn_bits \\<equiv> 5\"\n\ndefinition untyped_min_bits :: nat\n  where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat\n  where\n  \"untyped_max_bits \\<equiv> 38\"\n\nprimrec arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\n  where\n  \"arch_kobj_size (ASIDPool _) = pageBits\"\n| \"arch_kobj_size (PageTable _) = table_size\"\n| \"arch_kobj_size (DataPage _ sz) = pageBitsForSize sz\"\n\nfun aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\n  where\n  \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref c = Some (acap_obj c)\"\n\ndefinition acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\"\n  where\n  \"acap_rights_update R acap \\<equiv>\n    case acap of\n      FrameCap ref cR sz dev as \\<Rightarrow> FrameCap ref (validate_vm_rights R) sz dev as\n    | _ \\<Rightarrow> acap\"\n\ntext \\<open>Sanity check:\\<close>\nlemma \"LENGTH(pte_ppn_len) = word_bits - pt_bits\"\n  by (simp add: pte_bits_def ptTranslationBits_def word_size_bits_def word_bits_def\n                pt_bits_def table_size_def)"}
{"title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "section": "Architecture-specific state", "subsection": "", "subsubsection": "", "code": "\ndatatype aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | HugePageObj\n  | PageTableObj\n  | ASIDPoolObj\n\ndefinition arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\"\n  where\n  \"arch_is_frame_type aobj \\<equiv> aobj \\<noteq> PageTableObj\"\n\ndefinition arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\"\n  where\n  \"arch_default_cap tp r n dev \\<equiv> case tp of\n     SmallPageObj \\<Rightarrow> FrameCap r vm_read_write RISCVSmallPage dev None\n   | LargePageObj \\<Rightarrow> FrameCap r vm_read_write RISCVLargePage dev None\n   | HugePageObj  \\<Rightarrow> FrameCap r vm_read_write RISCVHugePage dev None\n   | PageTableObj \\<Rightarrow> PageTableCap r None\n   | ASIDPoolObj  \\<Rightarrow> ASIDPoolCap r 0\" (* unused, but nicer properties when defined *)\n\ndefinition default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\"\n  where\n  \"default_arch_object tp dev n \\<equiv> case tp of\n     SmallPageObj \\<Rightarrow> DataPage dev RISCVSmallPage\n   | LargePageObj \\<Rightarrow> DataPage dev RISCVLargePage\n   | HugePageObj  \\<Rightarrow> DataPage dev RISCVHugePage\n   | PageTableObj \\<Rightarrow> PageTable (\\<lambda>_. InvalidPTE)\n   | ASIDPoolObj  \\<Rightarrow> ASIDPool Map.empty\"\n\ntype_synonym riscv_vspace_region_uses = \"vspace_ref \\<Rightarrow> riscvvspace_region_use\"\n\ntext \\<open>\n  The number of levels over all virtual memory tables.\n  For RISC-V, we have three page table levels plus the ASID pool level.\n\n  The top level (with the highest number) contains ASID pools, the next levels contain the\n  top-level page tables, and level 1 page tables. The bottom-level page tables (level 0)\n  contains only InvalidPTEs or PagePTEs.\n\\<close>\ntype_synonym vm_level = 4\n\ndefinition asid_pool_level :: vm_level\n  where\n  \"asid_pool_level = maxBound\"\n\ndefinition max_pt_level :: vm_level\n  where\n  \"max_pt_level = asid_pool_level - 1\"\n\nend\n\nqualify RISCV64_A (in Arch)"}
{"title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "section": "Architecture-specific state", "subsection": "", "subsubsection": "", "code": "\nrecord arch_state =\n  riscv_asid_table :: \"asid_high_index \\<rightharpoonup> obj_ref\"\n  riscv_global_pts :: \"RISCV64_A.vm_level \\<Rightarrow> obj_ref set\"\n  riscv_kernel_vspace :: \"obj_ref \\<Rightarrow> RISCV64_H.riscvvspace_region_use\"\n\ntext \\<open>\n  The @{const riscv_global_pts} generalise the concept of global page tables.\n  The invariants will constrain the set of tables for @{term max_pt_level} to a\n  singleton, and for @{term asid_pool_level} to empty. All other levels may contain\n  multiple or no tables, depending on how kernel initialisation sets up the kernel window.\n\\<close>\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "section": "Type declarations for invariant definitions", "subsection": "", "subsubsection": "", "code": "\ndatatype aa_type =\n    AASIDPool\n  | APageTable\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\"\n  where\n  \"aa_type ao \\<equiv> case ao of\n     PageTable pt    \\<Rightarrow> APageTable\n   | DataPage dev sz \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n   | ASIDPool f      \\<Rightarrow> AASIDPool\"\n\ndefinition badge_bits :: nat\n  where\n  \"badge_bits \\<equiv> 64\"\n\nend"}
{"title": "./spec/abstract/RISCV64/Arch_Structs_A.thy", "section": "Arch-specific TCB", "subsection": "", "subsubsection": "", "code": "\nqualify RISCV64_A (in Arch)\n\ntext \\<open> Arch-specific part of a TCB: this must have at least a field for user context. \\<close>\nrecord arch_tcb =\n  tcb_context :: user_context\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition default_arch_tcb :: arch_tcb\n  where\n  \"default_arch_tcb \\<equiv> \\<lparr>tcb_context = new_context\\<rparr>\"\n\ntext \\<open>\n  Accessors for @{text \"tcb_context\"} inside @{text \"arch_tcb\"}. These are later used to\n  implement @{text as_user}, i.e.\\ need to be compatible with @{text user_monad}.\n\\<close>\ndefinition arch_tcb_context_set :: \"user_context \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\n  where\n  \"arch_tcb_context_set uc a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := uc \\<rparr>\"\n\ndefinition arch_tcb_context_get :: \"arch_tcb \\<Rightarrow> user_context\"\n  where\n  \"arch_tcb_context_get a_tcb \\<equiv> tcb_context a_tcb\"\n\ntext \\<open>\n  Accessors for the user register part of the @{text \"arch_tcb\"}.\n  (Because @{typ \"register \\<Rightarrow> machine_word\"} might not be equal to @{typ user_context}).\n\\<close>\ndefinition arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\n  where\n  \"arch_tcb_set_registers regs a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := UserContext regs \\<rparr>\"\n\ndefinition arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\"\n  where\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchFault_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>Architecture-specific Fault-handling Functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\n  where\n  \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData)\n   od\"\n\ndefinition handle_arch_fault_reply ::\n  \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\n  where\n  \"handle_arch_fault_reply vmf thread x y \\<equiv> return True\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchTcb_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\n  where\n  \"sanitise_register t r v \\<equiv> v\"\n\ndefinition arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\n  where\n  \"arch_get_sanitise_register_info t \\<equiv> return False\"\n\ndefinition arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\n  where\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/ArchCSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Functions for CSpace\"\n\ntheory ArchCSpace_A\nimports\n  ArchVSpace_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition cnode_guard_size_bits :: \"nat\"\n  where\n  \"cnode_guard_size_bits \\<equiv> 6\"\n\ndefinition cnode_padding_bits :: \"nat\"\n  where\n  \"cnode_padding_bits \\<equiv> 0\"\n\ntext \\<open>On a user request to modify a CNode capability, extract new guard bits and guard.\\<close>\ndefinition update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\"\n  where\n  \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 58;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"\n\ntext \\<open>For some purposes capabilities to physical objects are treated differently to others.\\<close>\ndefinition arch_is_physical :: \"arch_cap \\<Rightarrow> bool\"\n  where\n  \"arch_is_physical cap \\<equiv> case cap of ASIDControlCap \\<Rightarrow> False | _ \\<Rightarrow> True\"\n\ntext \\<open>\n  Check whether the second capability is to the same object or an object\n  contained in the region of the first one.\n\\<close>\nfun arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\n  where\n  \"arch_same_region_as (FrameCap r _ sz _ _) c' =\n   (is_FrameCap c' \\<and>\n     (let\n        r' = acap_obj c';\n        sz' = acap_fsize c';\n        topA = r + (1 << pageBitsForSize sz) - 1;\n        topB = r' + (1 << pageBitsForSize sz') - 1\n      in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB))\"\n| \"arch_same_region_as (PageTableCap r _) c' = (\\<exists>r' d'. c' = PageTableCap r' d' \\<and> r = r')\"\n| \"arch_same_region_as ASIDControlCap c' = (c' = ASIDControlCap)\"\n| \"arch_same_region_as (ASIDPoolCap r _) c' = (\\<exists>r' d'. c' = ASIDPoolCap r' d' \\<and> r = r')\"\n\n\ntext \\<open>Check whether two arch capabilities are to the same object.\\<close>\ndefinition same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\n  where\n  \"same_aobject_as cap cap' \\<equiv>\n     case (cap, cap') of\n       (FrameCap ref _ sz dev _, FrameCap ref' _ sz' dev' _) \\<Rightarrow>\n         (dev, ref, sz) = (dev', ref', sz') \\<and> ref \\<le> ref + 2 ^ pageBitsForSize sz - 1\n     | _ \\<Rightarrow> arch_same_region_as cap cap'\"\n\ndeclare same_aobject_as_def[simp]\n\ndefinition arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\n  where\n  \"arch_is_cap_revocable new_cap src_cap \\<equiv> False\"\n\nend\nend"}
{"title": "./spec/abstract/RISCV64/Machine_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"RISCV64 Machine Instantiation\"\n\ntheory Machine_A\nimports\n  \"ExecSpec.MachineOps\"\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  The specification is written with abstract type names for object references, user pointers,\n  word-based data, cap references, and so on. This theory provides an instantiation of these names\n  to concrete types for the RISCV64 architecture. Other architectures may have slightly different\n  instantiations.\n\\<close>\n\ntype_synonym obj_ref         = machine_word\ntype_synonym vspace_ref      = machine_word\n\ntype_synonym data            = machine_word\ntype_synonym cap_ref         = \"bool list\"\ntype_synonym length_type     = machine_word\n\ntype_synonym asid_low_len    = 9\ntype_synonym asid_low_index  = \"asid_low_len word\"\n\ntype_synonym asid_high_len   = 7\ntype_synonym asid_high_index = \"asid_high_len word\"\n\ntype_synonym asid_len        = 16\ntype_synonym asid_rep_len    = asid_len\ntype_synonym asid            = \"asid_rep_len word\"\n\ntext \\<open>\n  With the definitions above, most conversions between abstract type names boil down to just\n  the identity function, some convert from @{text word} to @{typ nat} and others between different\n  word sizes using @{const ucast}.\n\\<close>\n\ndefinition oref_to_data :: \"obj_ref \\<Rightarrow> data\"\n  where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition data_to_oref :: \"data \\<Rightarrow> obj_ref\"\n  where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition vref_to_data :: \"vspace_ref \\<Rightarrow> data\"\n  where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition data_to_vref :: \"data \\<Rightarrow> vspace_ref\"\n  where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition nat_to_len :: \"nat \\<Rightarrow> length_type\"\n  where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition data_to_nat :: \"data \\<Rightarrow> nat\"\n  where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition data_to_16 :: \"data \\<Rightarrow> 16 word\"\n  where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition data_to_cptr :: \"data \\<Rightarrow> cap_ref\"\n  where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\"\n  where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\"\n  where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"\n\n\ntext \\<open>These definitions will be unfolded automatically in proofs.\\<close>\nlemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def\n\n\ntext \\<open>\n  The following definitions provide architecture-dependent sizes such as the standard page\n  size and capability size of the underlying machine.\n\\<close>\n\ndefinition slot_bits :: nat\n  where\n  \"slot_bits \\<equiv> 5\"\n\ndefinition msg_label_bits :: nat\n  where\n  [simp]: \"msg_label_bits \\<equiv> 52\"\n\ndefinition new_context :: \"user_context\"\n  where\n  \"new_context \\<equiv> UserContext ((\\<lambda>_. 0) (SSTATUS := sstatusSPIE))\"\n\ntext \\<open>\n  The lowest virtual address in the kernel window. The kernel reserves the virtual addresses\n  from here up in every virtual address space.\n\\<close>\ndefinition pptr_base :: \"machine_word\"\n  where\n  \"pptr_base = Platform.RISCV64.pptrBase\"\n\ntext \"Virtual address space available to users.\"\ndefinition user_vtop :: \"machine_word\"\n  where\n  \"user_vtop = Platform.RISCV64.pptrUserTop\"\n\ntext \\<open>\n  Virtual address for start of kernel device mapping region in highest 1GiB of memory.\n\\<close>\ndefinition kdev_base :: \"machine_word\"\n  where\n  \"kdev_base = Platform.RISCV64.kdevBase\"\n\ntext \\<open>\n  The virtual address the kernel code is mapped.\n\\<close>\ndefinition kernel_elf_base :: \"vspace_ref\"\n  where\n  \"kernel_elf_base \\<equiv> Platform.RISCV64.kernelELFBase\"\n\ntext \\<open>\n  Currently an arbitrary aligned address for the idle thread.\n  Only has to exists, does not have to match up with the concrete value in C.\n\\<close>\ndefinition idle_thread_ptr :: vspace_ref\n  where\n  \"idle_thread_ptr = pptr_base + 0x1000\"\n\n(* FIXME: nat_to_cref is not arch specific *)\ndefinition nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\"\n  where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len) (to_bl (of_nat n :: machine_word))\"\n\ndefinition msg_info_register :: register\n  where\n  \"msg_info_register \\<equiv> msgInfoRegister\"\n\ndefinition msg_registers :: \"register list\"\n  where\n  \"msg_registers \\<equiv> msgRegisters\"\n\ndefinition cap_register :: register\n  where\n  \"cap_register \\<equiv> capRegister\"\n\ndefinition badge_register :: register\n  where\n  \"badge_register \\<equiv> badgeRegister\"\n\ndefinition frame_registers :: \"register list\"\n  where\n  \"frame_registers \\<equiv> frameRegisters\"\n\ndefinition gp_registers :: \"register list\"\n  where\n  \"gp_registers \\<equiv> gpRegisters\"\n\ndefinition exception_message :: \"register list\"\n  where\n  \"exception_message \\<equiv> exceptionMessage\"\n\ndefinition syscall_message :: \"register list\"\n  where\n  \"syscall_message \\<equiv> syscallMessage\"\n\ndatatype arch_fault\n  = VMFault (vm_fault_address : vspace_ref) (vm_fault_arch_data : \"machine_word list\")\n\nend\n\narch_requalify_consts (A) idle_thread_ptr\n\nend"}
{"title": "./spec/abstract/AARCH64/VCPU_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>VCPU\\<close>\n\ntheory VCPU_A\nimports\n  TcbAcc_A\n  InvocationLabels_A\nbegin\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/AARCH64/VCPU_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This is used by some decode functions. VCPU decode functions are the first that need to bounds\n  check IRQs from the user.\\<close>\ndefinition arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"arch_check_irq irq \\<equiv> whenE (irq > maxIRQ \\<or> irq < ucast minIRQ)\n                          $ throwError (RangeError (ucast minIRQ) maxIRQ)\""}
{"title": "./spec/abstract/AARCH64/VCPU_A.thy", "section": "", "subsection": "VCPU: Read/Write Registers", "subsubsection": "", "code": "\ndefinition decode_vcpu_set_tcb ::\n  \"arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_set_tcb cap extras \\<equiv> case (cap, extras) of\n     (VCPUCap v, fs#_) \\<Rightarrow> (case fs of\n           (ThreadCap t, _) \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUSetTCB v t\n         | _ \\<Rightarrow> throwError IllegalOperation)\n   | (VCPUCap v, _) \\<Rightarrow> throwError TruncatedMessage\n   | _ \\<Rightarrow> throwError IllegalOperation\"\n\ntext \\<open>VCPU objects can be associated with and dissociated from TCBs.\n  It is not possible to dissociate a VCPU and a TCB by using setTCB.\n  Final outcome has to be an associated TCB and VCPU.\n  The only way to get lasting dissociation is to delete the TCB or the VCPU. See ArchVSpace\\_A.\\<close>"}
{"title": "./spec/abstract/AARCH64/VCPU_A.thy", "section": "", "subsection": "VCPU: Read/Write Registers", "subsubsection": "", "code": "\ndefinition read_vcpu_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word,'z::state_ext) s_monad\" where\n  \"read_vcpu_register vcpu_ptr reg \\<equiv> do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (on_cur_vcpu, active) \\<leftarrow> return (case cur_vcpu of\n         Some (vcpu_ptr', a) \\<Rightarrow> (vcpu_ptr' = vcpu_ptr, a)\n       | _ \\<Rightarrow> (False, False));\n\n     if on_cur_vcpu\n       then if vcpuRegSavedWhenDisabled reg \\<and> \\<not>active\n              then vcpu_read_reg vcpu_ptr reg\n              else do_machine_op $ readVCPUHardwareReg reg\n       else vcpu_read_reg vcpu_ptr reg\n  od\"\n\ndefinition\n  write_vcpu_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"write_vcpu_register vcpu_ptr reg val \\<equiv>\n  do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu o arch_state);\n     (on_cur_vcpu, active) \\<leftarrow> return (case cur_vcpu of\n         Some (cv, a) \\<Rightarrow> (cv = vcpu_ptr, a)\n       | _ \\<Rightarrow> (False, False));\n\n     if on_cur_vcpu\n       then if vcpuRegSavedWhenDisabled reg \\<and> \\<not>active\n         then vcpu_write_reg vcpu_ptr reg val\n         else do_machine_op $ writeVCPUHardwareReg reg val\n       else vcpu_write_reg vcpu_ptr reg val\n  od\"\n\ndefinition decode_vcpu_read_register ::\n  \"machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_read_register args cap \\<equiv> case (args, cap) of\n      (reg#_, VCPUCap p) \\<Rightarrow> if fromEnum (maxBound::vcpureg) < unat reg\n                           then throwError (InvalidArgument 1)\n                           else returnOk $ InvokeVCPU $ VCPUReadRegister p $ toEnum (unat reg)\n    | (_, _) \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition decode_vcpu_write_register :: \"machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_write_register args cap \\<equiv> case (args, cap) of\n    (reg#val#_, VCPUCap p) \\<Rightarrow> if fromEnum (maxBound::vcpureg) < unat reg\n                              then throwError (InvalidArgument 1)\n                              else returnOk $ InvokeVCPU $ VCPUWriteRegister p (toEnum (unat reg)) val\n  | (_, _) \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_read_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\n  where\n  \"invoke_vcpu_read_register v reg \\<equiv> do\n     val \\<leftarrow> read_vcpu_register v reg;\n     return [val]\n   od\"\n\ndefinition\n  invoke_vcpu_write_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"invoke_vcpu_write_register v reg val \\<equiv>  write_vcpu_register v reg val\"\n\ntext \\<open>VCPU : inject IRQ\\<close>\n\n(* This following function does not correspond to exactly what the C does, but\n   it is the value that is stored inside of lr in the vgic  *)\ndefinition make_virq :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> virq\" where\n  \"make_virq grp prio irq \\<equiv>\n    let\n      groupShift = 30;\n      prioShift = 23;\n      irqPending = 1 << 28;\n      eoiirqen = 1 << 19\n    in ((grp && 1) << groupShift) || ((prio && 0x1F) << prioShift) || (irq && 0x3FF)\n       || irqPending || eoiirqen\"\n\ndefinition virq_type :: \"virq \\<Rightarrow> nat\" where\n  \"virq_type virq \\<equiv> unat ((virq >> 28) && 3)\"\n\ndefinition is_virq_active :: \"virq \\<Rightarrow> bool\" where\n  \"is_virq_active virq \\<equiv> virq_type virq = 2\"\n\ndefinition decode_vcpu_inject_irq ::\n  \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_inject_irq ptrs cap \\<equiv> case (ptrs, cap) of\n  (mr0 # _, VCPUCap p) \\<Rightarrow> doE\n     vid \\<leftarrow> returnOk (mr0 && 0xFFFF);\n     priority \\<leftarrow> returnOk ((mr0 >> 16) && 0xFF);\n     group \\<leftarrow> returnOk ((mr0 >> 24) && 0xFF);\n     index \\<leftarrow> returnOk ((mr0 >> 32) && 0xFF);\n     range_check vid 0 ((1 << 10) - 1);\n     range_check priority 0 31;\n     range_check group 0 1;\n     num_list_regs \\<leftarrow> liftE $ gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     whenE (index \\<ge> of_nat num_list_regs) $\n        (throwError $ RangeError 0 (of_nat num_list_regs - 1));\n\n     vcpu \\<leftarrow> liftE $ get_vcpu p;\n     vcpuLR \\<leftarrow> returnOk (vgic_lr $ vcpu_vgic $ vcpu);\n\n     whenE (is_virq_active (vcpuLR (unat index))) $ throwError DeleteFirst;\n\n     virq \\<leftarrow> returnOk (make_virq group priority vid);\n     returnOk $ InvokeVCPU $ VCPUInjectIRQ p (unat index) virq\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_inject_irq :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invoke_vcpu_inject_irq vr index virq \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    if (cur_v \\<noteq> None \\<and> fst (the cur_v) = vr)\n    then do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat index) virq\n    else vgic_update_lr vr index virq\n   od\"\n\ntext \\<open>VCPU : acknowledge VPPI\\<close>\n\ndefinition decode_vcpu_ack_vppi ::\n  \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_ack_vppi mrs cap \\<equiv>\n     case (mrs, cap)\n       of (mr0 # _, VCPUCap vcpu_ptr) \\<Rightarrow> doE\n           arch_check_irq mr0;\n           (case irq_vppi_event_index (ucast mr0)\n            of None \\<Rightarrow> throwError $ InvalidArgument 0\n             | Some vppi \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUAckVPPI vcpu_ptr vppi)\n         odE\n       | _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_ack_vppi :: \"obj_ref \\<Rightarrow> vppievent_irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invoke_vcpu_ack_vppi vcpu_ptr vppi =\n     vcpu_update vcpu_ptr\n                 (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := False) \\<rparr>)\"\n\ntext \\<open>VCPU perform and decode main functions\\<close>\n\ndefinition\n  perform_vcpu_invocation :: \"vcpu_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_vcpu_invocation iv \\<equiv> case iv of\n     VCPUSetTCB vcpu tcb \\<Rightarrow> do associate_vcpu_tcb vcpu tcb; return [] od\n   | VCPUReadRegister vcpu reg \\<Rightarrow> invoke_vcpu_read_register vcpu reg\n   | VCPUWriteRegister vcpu reg val \\<Rightarrow> do invoke_vcpu_write_register vcpu reg val; return [] od\n   | VCPUInjectIRQ vcpu index vir \\<Rightarrow> do invoke_vcpu_inject_irq vcpu index vir; return [] od\n   | VCPUAckVPPI vcpu vppi \\<Rightarrow> do invoke_vcpu_ack_vppi vcpu vppi; return [] od\"\n\ndefinition decode_vcpu_invocation ::\n  \"machine_word \\<Rightarrow> machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_invocation label args cap extras \\<equiv> case cap of\n  VCPUCap _ \\<Rightarrow> (case invocation_type label of\n      ArchInvocationLabel ARMVCPUSetTCB \\<Rightarrow> decode_vcpu_set_tcb cap extras\n    | ArchInvocationLabel ARMVCPUReadReg \\<Rightarrow> decode_vcpu_read_register args cap\n    | ArchInvocationLabel ARMVCPUWriteReg \\<Rightarrow> decode_vcpu_write_register args cap\n    | ArchInvocationLabel ARMVCPUInjectIRQ \\<Rightarrow> decode_vcpu_inject_irq args cap\n    | ArchInvocationLabel ARMVCPUAckVPPI \\<Rightarrow> decode_vcpu_ack_vppi args cap\n    |  _ \\<Rightarrow> throwError IllegalOperation)\n  | _ \\<Rightarrow> throwError IllegalOperation\"\n\nend\n\nend"}
{"title": "./spec/abstract/AARCH64/ArchInterrupt_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Arch-specific Interrupts\"\n\ntheory ArchInterrupt_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition virqSetEOIIRQEN :: \"virq \\<Rightarrow> machine_word \\<Rightarrow> virq\" where\n  \"virqSetEOIIRQEN virq v \\<equiv>\n     if virq_type virq = 3\n     then virq\n     else (virq && ~~0x80000) || ((v << 19) && 0x80000)\"\n\ndefinition vgic_maintenance :: \"(unit,'z::state_ext) s_monad\" where\n  \"vgic_maintenance = do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     case cur_vcpu\n       of Some (vcpu_ptr, True) \\<Rightarrow> do\n            eisr0 \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_eisr0;\n            eisr1 \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_eisr1;\n            flags \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_misr;\n            vgic_misr_eoi \\<leftarrow> return $ vgicHCREN;\n            irq_idx \\<leftarrow> return (if eisr0 \\<noteq> 0 then word_ctz eisr0 else word_ctz eisr1 + 32);\n            gic_vcpu_num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs o arch_state);\n            fault \\<leftarrow> if flags && vgic_misr_eoi \\<noteq> 0\n                    then\n                      if eisr0 = 0 \\<and> eisr1 = 0 \\<or> irq_idx \\<ge> gic_vcpu_num_list_regs\n                      then return $ VGICMaintenance None\n                      else do\n                        virq <- do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat irq_idx);\n                        virqen <- return $ virqSetEOIIRQEN virq 0;\n                        do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat irq_idx) virqen;\n                        vgic_update_lr vcpu_ptr irq_idx virqen;\n                        return $ VGICMaintenance $ Some $ of_nat irq_idx\n                      od\n                    else return $ VGICMaintenance None;\n\n            ct \\<leftarrow> gets cur_thread;\n            st \\<leftarrow> get_thread_state ct;\n            \\<comment> \\<open>until a proof links active current vcpu to runnable current thread, we need this\n               check: @{term handle_fault} needs a runnable current thread\\<close>\n            when (runnable st) $ handle_fault ct $ ArchFault fault\n          od\n        | _ \\<Rightarrow> return ()\n   od\"\n\ndefinition vppi_event :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vppi_event irq = do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     case cur_vcpu\n       of Some (vcpu_ptr, True) \\<Rightarrow> do\n            do_machine_op $ maskInterrupt True irq;\n            vppi \\<leftarrow> return $ the $ irq_vppi_event_index irq;\n            vcpu_update vcpu_ptr\n                        (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := True) \\<rparr>);\n            ct \\<leftarrow> gets cur_thread;\n            st \\<leftarrow> get_thread_state ct;\n            \\<comment> \\<open>until a proof links active current vcpu to runnable current thread, we need this\n               check: @{term handle_fault} needs a runnable current thread\\<close>\n            when (runnable st) $ handle_fault ct $ ArchFault $ VPPIEvent irq\n          od\n        | _ \\<Rightarrow> return ()\n   od\"\n\ndefinition handle_reserved_irq :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"handle_reserved_irq irq \\<equiv> do\n     when (irq = irqVGICMaintenance) vgic_maintenance;\n     when (irq_vppi_event_index irq \\<noteq> None) $ vppi_event irq\n   od\"\n\nfun arch_invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_invoke_irq_handler (ACKIrq irq) = (do_machine_op $ maskInterrupt False irq)\"\n| \"arch_invoke_irq_handler _ = return ()\"\n\ndefinition arch_mask_irq_signal :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_mask_irq_signal irq \\<equiv> do_machine_op $ maskInterrupt True irq\"\n\nend\n\nend"}
{"title": "./spec/abstract/AARCH64/Arch_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Toplevel AARCH64 Definitions\"\n\ntheory Arch_A\nimports TcbAcc_A VCPU_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun arch_invoke_irq_control :: \"arch_irq_control_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\" where\n  \"arch_invoke_irq_control (ARMIRQControlInvocation irq handler_slot control_slot trigger) =\n     without_preemption (do\n       do_machine_op $ setIRQTrigger irq trigger;\n       set_irq_state IRQSignal (irq);\n       cap_insert (IRQHandlerCap (irq)) control_slot handler_slot\n  od)\"\n\ndefinition arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> do\n     tcb \\<leftarrow> gets_the $ get_tcb t;\n     vcpu_switch $ tcb_vcpu $ tcb_arch tcb;\n     set_vm_root t\n   od\"\n\ndefinition arch_switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_idle_thread \\<equiv> do\n    vcpu_switch None;\n    set_global_user_vspace\n  od\"\n\ndefinition arch_activate_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_activate_idle_thread t \\<equiv> return ()\"\n\ndefinition store_asid_pool_entry ::\n  \"obj_ref \\<Rightarrow> asid \\<Rightarrow> asid_pool_entry option \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n  \"store_asid_pool_entry pool_ptr asid entry \\<equiv> do\n    pool \\<leftarrow> get_asid_pool pool_ptr;\n    pool' \\<leftarrow> return $ pool(asid_low_bits_of asid := entry);\n    set_asid_pool pool_ptr pool'\n  od\"\n\ntext \\<open>\n  The ASIDControl capability confers the authority to create a new ASID pool object. This\n  operation creates the new ASID pool, provides a capability to it and connects it to the global\n  virtual ASID table.\n\\<close>\ndefinition perform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_asid_control_invocation iv \\<equiv> case iv of\n     MakePool frame slot parent base \\<Rightarrow> do\n       delete_objects frame pageBits;\n       pcap \\<leftarrow> get_cap parent;\n       set_cap (max_free_index_update pcap) parent;\n       retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n       cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n       assert (asid_low_bits_of base = 0);\n       asid_table \\<leftarrow> gets asid_table;\n       asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n       modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>arm_asid_table := asid_table'\\<rparr>\\<rparr>)\n     od\"\n\ntext \\<open>The ASIDPool capability confers the authority to assign an ASID to a top-level page table.\\<close>\ndefinition perform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_asid_pool_invocation iv \\<equiv> case iv of\n     Assign asid pool_ptr ct_slot \\<Rightarrow> do\n       pt_cap \\<leftarrow> get_cap ct_slot;\n       assert $ is_ArchObjectCap pt_cap;\n       acap \\<leftarrow> return $ the_arch_cap pt_cap;\n       assert $ is_PageTableCap acap;\n       set_cap (ArchObjectCap $ update_map_data acap $ Some (asid,0)) ct_slot;\n       pt_base \\<leftarrow> return $ acap_obj acap;\n       store_asid_pool_entry pool_ptr asid (Some (ASIDPoolVSpace None pt_base))\n     od\"\n\ndefinition perform_pg_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pg_inv_unmap cap ct_slot \\<equiv> do\n     assert $ is_FrameCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> unmap_page (acap_fsize cap) asid vaddr (acap_obj cap)\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data (the_arch_cap old_cap) None) ct_slot\n   od\"\n\ndefinition perform_pg_inv_map ::\n  \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> vm_level \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pg_inv_map cap ct_slot pte slot level \\<equiv> do\n     old_pte \\<leftarrow> get_pte level slot;\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte level slot pte;\n     do_machine_op $ cleanByVA_PoU slot (addrFromPPtr slot);\n     when (old_pte \\<noteq> InvalidPTE) $ do\n        (asid, vaddr) \\<leftarrow> assert_opt $ acap_map_data cap;\n        invalidate_tlb_by_asid_va asid vaddr\n     od\n   od\"\n\ndefinition perform_pg_inv_get_addr ::\n  \"obj_ref \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_pg_inv_get_addr ptr \\<equiv> return [addrFromPPtr ptr]\"\n\ndefinition do_flush :: \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\" where\n  \"do_flush type vstart vend pstart \\<equiv>\n     case type of\n       Clean \\<Rightarrow> cleanCacheRange_RAM vstart vend pstart\n     | Invalidate \\<Rightarrow> invalidateCacheRange_RAM vstart vend pstart\n     | CleanInvalidate \\<Rightarrow> cleanInvalidateCacheRange_RAM vstart vend pstart\n     | Unify \\<Rightarrow> do\n         cleanCacheRange_PoU vstart vend pstart;\n         dsb;\n         invalidateCacheRange_I vstart vend pstart;\n         isb\n       od\"\n\n(* Used for both, vspace and page invocation; distinction is in the flush type *)\ndefinition perform_flush ::\n  \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_flush type vstart vend pstart space asid \\<equiv> do\n     start \\<leftarrow> return $ ptrFromPAddr pstart;\n     end \\<leftarrow> return $ start + (vend - vstart);\n     when (start < end) $ do_machine_op $ do_flush type start end pstart\n   od\"\n\ntext \\<open>\n  The Frame capability confers the authority to map and unmap memory, to query the physical\n  address of a page and to flush.\n\\<close>\ndefinition perform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n  \"perform_page_invocation iv \\<equiv> case iv of\n     PageMap cap ct_slot (pte,slot,level) \\<Rightarrow> do\n       perform_pg_inv_map cap ct_slot pte slot level;\n       return []\n     od\n   | PageUnmap cap ct_slot \\<Rightarrow> do perform_pg_inv_unmap cap ct_slot; return [] od\n   | PageGetAddr ptr \\<Rightarrow> perform_pg_inv_get_addr ptr\n   | PageFlush type start end pstart space asid \\<Rightarrow> do\n       perform_flush type start end pstart space asid;\n       return []\n     od\"\n\n\ndefinition perform_pt_inv_map ::\n  \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> pte \\<Rightarrow> obj_ref \\<Rightarrow> vm_level \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pt_inv_map cap ct_slot pte slot level = do\n     set_cap (ArchObjectCap cap) ct_slot;\n     store_pte level slot pte;\n     do_machine_op $ cleanByVA_PoU slot (addrFromPPtr slot)\n   od\"\n\ndefinition perform_pt_inv_unmap :: \"arch_cap \\<Rightarrow> cslot_ptr \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_pt_inv_unmap cap ct_slot = do\n     assert $ is_PageTableCap cap;\n     case acap_map_data cap of\n       Some (asid, vaddr) \\<Rightarrow> do\n         p \\<leftarrow> return $ acap_obj cap;\n         unmap_page_table asid vaddr p;\n         slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + mask (pt_bits (acap_pt_type cap))];\n         mapM_x (swp (store_pte (acap_pt_type cap)) InvalidPTE) slots;\n         do_machine_op $ cleanCacheRange_PoU p (p + mask (pt_bits (acap_pt_type cap)))\n                                             (addrFromPPtr p)\n       od\n     | _ \\<Rightarrow> return ();\n     old_cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n     set_cap (ArchObjectCap $ update_map_data old_cap None) ct_slot\n   od\"\n\ntext \\<open>PageTable capabilities confer the authority to map and unmap page tables.\\<close>\ndefinition perform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"perform_page_table_invocation iv \\<equiv> case iv of\n     PageTableMap cap ct_slot pte slot level \\<Rightarrow> perform_pt_inv_map cap ct_slot pte slot level\n   | PageTableUnmap cap ct_slot \\<Rightarrow> perform_pt_inv_unmap cap ct_slot\"\n\ntext \\<open>VSpace capabilities confer the authority to flush.\\<close>\ndefinition perform_vspace_invocation :: \"vspace_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"perform_vspace_invocation iv \\<equiv> case iv of\n     VSpaceNothing \\<Rightarrow> return ()\n   | VSpaceFlush type start end pstart space asid \\<Rightarrow> perform_flush type start end pstart space asid\"\n\nlocale_abbrev arch_no_return :: \"(unit, 'z::state_ext) s_monad \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\n  where\n  \"arch_no_return oper \\<equiv> do oper; return [] od\"\n\ntext \\<open>Top level system call dispatcher for all AARCH64-specific system calls.\\<close>\ndefinition arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\"\n  where\n  \"arch_perform_invocation i \\<equiv> liftE $ case i of\n     InvokeVSpace oper \\<Rightarrow> arch_no_return $ perform_vspace_invocation oper\n   | InvokePageTable oper \\<Rightarrow> arch_no_return $ perform_page_table_invocation oper\n   | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n   | InvokeASIDControl oper \\<Rightarrow> arch_no_return $ perform_asid_control_invocation oper\n   | InvokeASIDPool oper \\<Rightarrow> arch_no_return $ perform_asid_pool_invocation oper\n   | InvokeVCPU oper \\<Rightarrow> perform_vcpu_invocation oper\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/Hypervisor_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>Handle Hypervisor Fault Events\\<close>\n\ntheory Hypervisor_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"machine_word \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\n  where\n  \"handle_hypervisor_fault thread (ARMVCPUFault hsr) = do\n     fpu_enabled \\<leftarrow> do_machine_op isFpuEnable;\n     if \\<not>fpu_enabled\n     then fail\n     else if hsr = 0x2000000 \\<comment> \\<open>@{text UNKNOWN_FAULT}\\<close>\n          then do\n            esr \\<leftarrow> do_machine_op getESR;\n            handle_fault thread (UserException (esr && mask 32) 0)\n          od\n          else handle_fault thread (ArchFault $ VCPUFault (ucast hsr))\n   od\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchRetype_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture specific Retype definitions\"\n\ntheory ArchRetype_A\nimports\n  ArchVSpaceAcc_A\n  ArchInvocation_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This is a placeholder function. We may wish to extend the specification\n  with explicitly tagging kernel data regions in memory.\n\\<close>\ndefinition reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"\n\ntext \\<open>Initialise architecture-specific objects.\\<close>\n\ndefinition vs_apiobj_size where\n  \"vs_apiobj_size ty \\<equiv>\n     case ty of\n       ArchObject SmallPageObj \\<Rightarrow> pageBitsForSize ARMSmallPage\n     | ArchObject LargePageObj \\<Rightarrow> pageBitsForSize ARMLargePage\n     | ArchObject HugePageObj \\<Rightarrow> pageBitsForSize ARMHugePage\n     | ArchObject PageTableObj \\<Rightarrow> table_size NormalPT_T\n     | ArchObject VSpaceObj \\<Rightarrow> table_size VSRootPT_T\"\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv>\n     if \\<not>is_device \\<and>\n        new_type \\<in> {ArchObject SmallPageObj, ArchObject LargePageObj, ArchObject HugePageObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_RAM ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else if new_type \\<in> {ArchObject PageTableObj, ArchObject VSpaceObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_PoU ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else\n       return ()\"\n\ndefinition empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (FPUState (\\<lambda>_. 0) 0 0) (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context, tcb_vcpu = None \\<rparr>\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchIpcCancel_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>Arch IPC Cancelling\\<close>\n\ntheory ArchIpcCancel_A\nimports CSpaceAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>Actions to be taken after a cap is deleted\\<close>\ndefinition arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n  \"arch_post_cap_deletion ac \\<equiv> return ()\"\n\ntext \\<open>Arch specific generic object references not covered by generic references\\<close>\ndatatype arch_gen_obj_ref = unit\n\ndefinition arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\" where\n  \"arch_gen_obj_refs ac \\<equiv> {}\"\n\ndefinition arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\" where\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/Init_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"An Initial Kernel State\"\n\ntheory Init_A\nimports\n  Retype_A\n  \"Lib.SplitRule\"\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This is not a specification of true kernel initialisation. This theory describes a dummy\n  initial state only, to show that the invariants and refinement relation are consistent.\n\\<close>\n\n(* Some address sufficiently aligned for one page *)\ndefinition arm_global_pt_ptr :: obj_ref where\n  \"arm_global_pt_ptr = pptr_base + 0x2000\"\n\n(* Sufficiently aligned for irq type + cte_level_bits *)\ndefinition init_irq_node_ptr :: obj_ref where\n  \"init_irq_node_ptr = pptr_base + 0xc000\"\n\n(* The highest user-virtual address that is still canonical.\n   It can be larger than user_vtop, which is the highest address we allow to be mapped.\n   For AArch64-hyp, user-virtual addresses are IPAs and since there is no sign extension,\n   the value is the top of the entire IPA address space. *)\ndefinition canonical_user :: \"vspace_ref\" where\n  \"canonical_user \\<equiv> mask ipa_size\"\n\n(* This is not the layout the real kernel uses, but we are only trying to show that\n   the invariants are consistent. These apply to the mappings of the (separate) kernel-level\n   page table in hyp mode, not the user-level page tables, which have no kernel mappings. *)\ndefinition init_vspace_uses :: \"vspace_ref \\<Rightarrow> arm_vspace_region_use\" where\n  \"init_vspace_uses p \\<equiv>\n     if p \\<in> {pptr_base ..< pptr_base + (1 << 30)} then ArmVSpaceKernelWindow\n     else ArmVSpaceInvalidRegion\"\n\n\ndefinition init_arch_state :: arch_state where\n  \"init_arch_state \\<equiv> \\<lparr>\n     arm_asid_table = Map.empty,\n     arm_kernel_vspace = init_vspace_uses,\n     arm_vmid_table = Map.empty,\n     arm_next_vmid = 0,\n     arm_us_global_vspace = arm_global_pt_ptr,\n     arm_current_vcpu = None,\n     arm_gicvcpu_numlistregs = undefined\n   \\<rparr>\"\n\n\n(* The user-level global table in hyp mode is entirely empty.\n   Kernel-level mappings are in a separate kernel page table, which is not modeled here. *)\ndefinition global_pt_obj :: arch_kernel_obj where\n  \"global_pt_obj \\<equiv> PageTable (VSRootPT (\\<lambda>_. InvalidPTE))\"\n\ndefinition init_kheap :: kheap where\n  \"init_kheap \\<equiv>\n    (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n           then Some (CNode 0 (empty_cnode 0))\n           else None)\n    (idle_thread_ptr \\<mapsto>\n       TCB \\<lparr>\n         tcb_ctable = NullCap,\n         tcb_vtable = NullCap,\n         tcb_reply = NullCap,\n         tcb_caller = NullCap,\n         tcb_ipcframe = NullCap,\n         tcb_state = IdleThreadState,\n         tcb_fault_handler = replicate word_bits False,\n         tcb_ipc_buffer = 0,\n         tcb_fault = None,\n         tcb_bound_notification = None,\n         tcb_mcpriority = minBound,\n         tcb_arch = init_arch_tcb\n         \\<rparr>,\n     arm_global_pt_ptr \\<mapsto> ArchObj global_pt_obj\n    )\"\n\ndefinition init_cdt :: cdt where\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition init_ioc :: \"cslot_ptr \\<Rightarrow> bool\" where\n  \"init_ioc \\<equiv>\n     \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                    (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition init_A_st :: \"'z::state_ext state\"\n  where\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n \nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchVSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"AARCH64 VSpace Functions\"\n\ntheory ArchVSpace_A\nimports\n  Retype_A\n  VCPUAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  Look up a thread's IPC buffer and check that the thread has the authority to read or (in the\n  receiver case) write to it.\\<close>\ndefinition lookup_ipc_buffer :: \"bool \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n  \"lookup_ipc_buffer is_receiver thread \\<equiv> do\n     buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n     buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n     buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n     case buffer_cap of\n       ArchObjectCap (FrameCap p R vms False _) \\<Rightarrow>\n         if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n         then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n         else return None\n     | _ \\<Rightarrow> return None\n   od\"\n\ndefinition pool_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\" where\n  \"pool_for_asid asid \\<equiv> \\<lambda>s. asid_table s (asid_high_bits_of asid)\"\n\ndefinition entry_for_pool :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (obj_ref \\<rightharpoonup> asid_pool) \\<Rightarrow> asid_pool_entry option\"\n  where\n  \"entry_for_pool pool_ptr asid \\<equiv> do {\n     pool \\<leftarrow> oapply pool_ptr;\n     K $ pool (asid_low_bits_of asid)\n   }\"\n\ndefinition vspace_for_pool :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (obj_ref \\<rightharpoonup> asid_pool) \\<Rightarrow> obj_ref option\" where\n  \"vspace_for_pool pool_ptr asid \\<equiv> do {\n     entry \\<leftarrow> entry_for_pool pool_ptr asid;\n     oreturn $ ap_vspace entry\n   }\"\n\n(* this is what asid_map encodes in ARM/ARM_HYP; getASIDPoolEntry in Haskell *)\ndefinition entry_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> asid_pool_entry option\" where\n  \"entry_for_asid asid = do {\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     entry_for_pool pool_ptr asid \\<circ> asid_pools_of\n   }\"\n\n(* update an entry in the asid map *)\ndefinition update_asid_pool_entry ::\n  \"(asid_pool_entry \\<rightharpoonup> asid_pool_entry) \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n  \"update_asid_pool_entry f asid \\<equiv> do\n     pool_ptr \\<leftarrow> gets_the $ pool_for_asid asid;\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     idx \\<leftarrow> return $ asid_low_bits_of asid;\n     entry \\<leftarrow> assert_opt $ pool idx;\n     set_asid_pool pool_ptr (pool (idx := f entry))\n   od\"\n\ndefinition vspace_for_asid :: \"asid \\<Rightarrow> 'z::state_ext state \\<Rightarrow> obj_ref option\" where\n  \"vspace_for_asid asid = do {\n     oassert (0 < asid);\n     entry \\<leftarrow> entry_for_asid asid;\n     oreturn $ ap_vspace entry\n   }\"\n\ntext \\<open>Locate the top-level page table associated with a given virtual ASID.\\<close>\ndefinition find_vspace_for_asid :: \"asid \\<Rightarrow> (obj_ref,'z::state_ext) lf_monad\" where\n  \"find_vspace_for_asid asid \\<equiv> doE\n     vspace_opt \\<leftarrow> liftE $ gets $ vspace_for_asid asid;\n     throw_opt InvalidRoot vspace_opt\n   odE\"\n\ndefinition load_vmid :: \"asid \\<Rightarrow> (vmid option, 'z::state_ext) s_monad\" where\n  \"load_vmid asid \\<equiv> do\n     entry \\<leftarrow> gets_the $ entry_for_asid asid;\n     return $ ap_vmid entry\n   od\"\n\ntext \\<open>Associate a VMID with an ASID.\\<close>\ndefinition store_vmid :: \"asid \\<Rightarrow> vmid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_vmid asid hw_asid \\<equiv> do\n     update_asid_pool_entry (\\<lambda>entry. Some $ ASIDPoolVSpace (Some hw_asid) (ap_vspace entry)) asid;\n     vmid_table \\<leftarrow> gets (arm_vmid_table \\<circ> arch_state);\n     vmid_table' \\<leftarrow> return $ vmid_table (hw_asid \\<mapsto> asid);\n     modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_vmid_table := vmid_table' \\<rparr>\\<rparr>)\n   od\"\n\ntext \\<open>Clear all TLB mappings associated with this ASID.\\<close>\ndefinition invalidate_tlb_by_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_tlb_by_asid asid \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     case maybe_vmid of\n       None \\<Rightarrow> return ()\n     | Some vmid \\<Rightarrow> do_machine_op $ invalidateTranslationASID (ucast vmid)\n   od\"\n\ntext \\<open>Clear all TLB mappings associated with this ASID and virtual address.\\<close>\ndefinition invalidate_tlb_by_asid_va :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_tlb_by_asid_va asid vaddr \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     case maybe_vmid of\n       None \\<Rightarrow> return ()\n     | Some vmid \\<Rightarrow>\n         do_machine_op $\n           invalidateTranslationSingle $ (ucast vmid << word_bits-asid_bits) || (vaddr >> pageBits)\n   od\"\n\ntext \\<open>Remove any mapping from this virtual ASID to a VMID.\\<close>\ndefinition invalidate_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_asid asid \\<equiv>\n     update_asid_pool_entry (\\<lambda>entry. Some $ ASIDPoolVSpace None (ap_vspace entry)) asid\"\n\ntext \\<open>Remove any mapping from this VMID to an ASID.\\<close>\ndefinition invalidate_vmid_entry :: \"vmid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_vmid_entry vmid \\<equiv> do\n     vmid_table \\<leftarrow> gets (arm_vmid_table \\<circ> arch_state);\n     vmid_table' \\<leftarrow> return (vmid_table (vmid := None));\n     modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_vmid_table := vmid_table' \\<rparr>\\<rparr>)\n  od\"\n\ntext \\<open>Remove mappings in either direction involving this ASID.\\<close>\ndefinition invalidate_asid_entry :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"invalidate_asid_entry asid \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     when (maybe_vmid \\<noteq> None) $ invalidate_vmid_entry (the maybe_vmid);\n     invalidate_asid asid\n  od\"\n\ntext \\<open>Locate a VMID that is not in use, if necessary by reclaiming one already assigned to an ASID.\\<close>\ndefinition find_free_vmid :: \"(vmid,'z::state_ext) s_monad\" where\n  \"find_free_vmid \\<equiv> do\n     vmid_table \\<leftarrow> gets (arm_vmid_table \\<circ> arch_state);\n     next_vmid \\<leftarrow> gets (arm_next_vmid \\<circ> arch_state);\n     maybe_vmid \\<leftarrow> return $ find (\\<lambda>a. vmid_table a = None)\n                                 (take (length [minBound :: vmid .e. maxBound])\n                                       ([next_vmid .e. maxBound] @ [minBound .e. next_vmid]));\n     case maybe_vmid of\n       Some vmid \\<Rightarrow> return vmid\n     | None \\<Rightarrow> do\n         invalidate_asid $ the $ vmid_table next_vmid;\n         do_machine_op $ invalidateTranslationASID (ucast next_vmid);\n         invalidate_vmid_entry next_vmid;\n         modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_next_vmid := next_vmid + 1 \\<rparr>\\<rparr>);\n         return next_vmid\n       od\n   od\"\n\ntext \\<open>Get the VMID associated with an ASID, assigning one if none is already assigned.\\<close>\ndefinition get_vmid :: \"asid \\<Rightarrow> (vmid, 'z::state_ext) s_monad\" where\n  \"get_vmid asid \\<equiv> do\n     maybe_vmid \\<leftarrow> load_vmid asid;\n     case maybe_vmid of\n       Some vmid \\<Rightarrow> return vmid\n     | None \\<Rightarrow>  do\n         new_hw_asid \\<leftarrow> find_free_vmid;\n         store_vmid asid new_hw_asid;\n         return new_hw_asid\n       od\n   od\"\n\ntext \\<open>\n  Format a VM fault message to be passed to a thread's supervisor after it encounters a page fault.\\<close>\ndefinition handle_vm_fault :: \"obj_ref \\<Rightarrow> vmfault_type \\<Rightarrow> (unit, 'z::state_ext) f_monad\" where\n  \"handle_vm_fault thread fault \\<equiv> case fault of\n     ARMDataAbort \\<Rightarrow> doE\n       addr \\<leftarrow> liftE $ do_machine_op getFAR;\n       fault \\<leftarrow> liftE $ do_machine_op getESR;\n       cur_v \\<leftarrow> liftE $ gets (arm_current_vcpu \\<circ> arch_state);\n       addr \\<leftarrow> if (\\<exists>v. cur_v = Some (v, True)) \\<comment> \\<open>VCPU active\\<close>\n              then doE\n                  \\<comment> \\<open>address bits of PAR register after S1 translation\\<close>\n                  par_el1_mask \\<leftarrow> returnOk $ 0xfffffffff000;\n                  addr' \\<leftarrow> liftE $ do_machine_op $ addressTranslateS1 addr;\n                  returnOk $ (addr' && par_el1_mask) || (addr && mask pageBits)\n                odE\n              else returnOk addr;\n       \\<comment> \\<open>32 is the width of the FSR field in the C VMFault structure\\<close>\n       throwError $ ArchFault $ VMFault addr [0, fault && mask 32]\n     odE\n   | ARMPrefetchAbort \\<Rightarrow> doE\n       pc \\<leftarrow> liftE $ as_user thread $ getRestartPC;\n       fault \\<leftarrow> liftE $ do_machine_op getESR;\n       cur_v \\<leftarrow> liftE $ gets (arm_current_vcpu \\<circ> arch_state);\n       pc \\<leftarrow> if (\\<exists>v. cur_v = Some (v, True)) \\<comment> \\<open>VCPU active\\<close>\n            then doE\n                \\<comment> \\<open>address bits of PAR register after S1 translation\\<close>\n                par_el1_mask \\<leftarrow> returnOk $ 0xfffffffff000;\n                pc' \\<leftarrow> liftE $ do_machine_op $ addressTranslateS1 pc;\n                returnOk $ (pc' && par_el1_mask) || (pc && mask pageBits)\n              odE\n            else returnOk pc;\n       \\<comment> \\<open>32 is the width of the FSR field in the C VMFault structure\\<close>\n       throwError $ ArchFault $ VMFault pc [1, fault && mask 32]\n     odE\"\n\n\ntext \\<open>Switch to given address space, using VMID associated with provided ASID.\\<close>\ndefinition arm_context_switch :: \"obj_ref \\<Rightarrow> asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arm_context_switch vspace asid = do\n     vmid <- get_vmid asid;\n     do_machine_op $ setVSpaceRoot (addrFromPPtr vspace) (ucast vmid)\n   od\"\n\n\ntext \\<open>Switch to global user address space, using VMID 0.\\<close>\ndefinition set_global_user_vspace :: \"(unit,'z::state_ext) s_monad\" where\n  \"set_global_user_vspace = do\n     global <- gets (arm_us_global_vspace \\<circ> arch_state);\n     do_machine_op $ setVSpaceRoot (addrFromKPPtr global) 0\n   od\"\n\ntext \\<open>\n  Switch into the address space of a given thread or the global address space if none is correctly\n  configured.\\<close>\ndefinition set_vm_root :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_vm_root tcb \\<equiv> do\n     thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n     thread_root \\<leftarrow> get_cap thread_root_slot;\n     (case thread_root of\n        ArchObjectCap (PageTableCap pt VSRootPT_T (Some (asid, _))) \\<Rightarrow> doE\n          pt' \\<leftarrow> find_vspace_for_asid asid;\n          whenE (pt \\<noteq> pt') $ throwError InvalidRoot;\n          liftE $ arm_context_switch pt asid\n        odE\n      | _ \\<Rightarrow> throwError InvalidRoot) <catch> (\\<lambda>_. set_global_user_vspace)\n  od\"\n\n\ndefinition delete_asid_pool :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"delete_asid_pool base ptr \\<equiv> do\n     assert (asid_low_bits_of base = 0);\n     asid_table \\<leftarrow> gets asid_table;\n     when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n       pool \\<leftarrow> get_asid_pool ptr;\n       mapM (\\<lambda>offset. when (pool (ucast offset) \\<noteq> None) $ do\n                            invalidate_tlb_by_asid $ base + offset;\n                            invalidate_asid_entry $ base + offset\n                      od) [0  .e.  mask asid_low_bits];\n       asid_table' \\<leftarrow> return $ asid_table (asid_high_bits_of base:= None);\n       modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>);\n       tcb \\<leftarrow> gets cur_thread;\n       set_vm_root tcb\n     od\n   od\"\n\n\ndefinition delete_asid :: \"asid \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"delete_asid asid pt \\<equiv> do\n     pool_ptr_op \\<leftarrow> gets (pool_for_asid asid);\n     case pool_ptr_op of\n       None \\<Rightarrow> return ()\n     | Some pool_ptr \\<Rightarrow> do\n         pool \\<leftarrow> get_asid_pool pool_ptr;\n         when (\\<exists>vmid. pool (asid_low_bits_of asid) = Some (ASIDPoolVSpace vmid pt)) $ do\n           invalidate_tlb_by_asid asid;\n           invalidate_asid_entry asid;\n           \\<comment> \\<open>re-read here, because @{text invalidate_asid_entry} changes the ASID pool:\\<close>\n           pool \\<leftarrow> get_asid_pool pool_ptr;\n           pool' \\<leftarrow> return $ pool (asid_low_bits_of asid := None);\n           set_asid_pool pool_ptr pool';\n           tcb \\<leftarrow> gets cur_thread;\n           set_vm_root tcb\n         od\n       od\n   od\"\n\n\ndefinition unmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"unmap_page_table asid vaddr pt \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     (pt_slot, level) \\<leftarrow> pt_lookup_from_level max_pt_level top_level_pt vaddr pt;\n     liftE $ store_pte (level_type level) pt_slot InvalidPTE;\n     liftE $ do_machine_op $ cleanByVA_PoU pt_slot (addrFromPPtr pt_slot);\n     liftE $ invalidate_tlb_by_asid asid\n   odE <catch> (K $ return ())\"\n\ntext \\<open>\n  Look up an @{text \"asid+vspace_ref\"} down to the provided level in the page table.\n  For level @{term bot_level}, return a pointer to a table at the returned level.\n  The level can be higher than @{term bot_level} if the lookup terminates early because\n  it hit a page or an invalid entry.\\<close>\ndefinition vs_lookup_table ::\n  \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"vs_lookup_table bot_level asid vptr \\<equiv> do {\n     pool_ptr \\<leftarrow> pool_for_asid asid;\n     if bot_level = asid_pool_level\n     then oreturn (asid_pool_level, pool_ptr)\n     else do {\n       top_level_pt \\<leftarrow> vspace_for_pool pool_ptr asid \\<circ> asid_pools_of;\n       pt_walk max_pt_level bot_level top_level_pt vptr \\<circ> ptes_of\n     }\n   }\"\n\ntext \\<open>\n  Same as @{const vs_lookup_table}, but return a pointer to a slot in a table at the returned level.\n  For @{prop \"bot_level = asid_pool_level\"}, still return the pointer to the ASID pool (not a slot\n  inside it, since there are no slot functions for ASID pools).\\<close>\ndefinition vs_lookup_slot ::\n  \"vm_level \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"vs_lookup_slot bot_level asid vref \\<equiv> do {\n     (level', table) \\<leftarrow> vs_lookup_table bot_level asid vref;\n     if level' = asid_pool_level then\n       oreturn (level', table)\n     else\n       oreturn (level', pt_slot_offset level' table vref)\n   }\"\n\ntext \\<open>Unmap a mapped page if the given mapping details are still current.\\<close>\ndefinition unmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"unmap_page pgsz asid vptr pptr \\<equiv> doE\n     top_level_pt \\<leftarrow> find_vspace_for_asid asid;\n     (lev, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot top_level_pt vptr \\<circ> ptes_of;\n     unlessE (pt_bits_left lev = pageBitsForSize pgsz) $ throwError InvalidRoot;\n     pte \\<leftarrow> liftE $ get_pte lev slot;\n     unlessE (is_PagePTE pte \\<and> pptr_from_pte pte = pptr) $ throwError InvalidRoot;\n     liftE $ store_pte lev slot InvalidPTE;\n     liftE $ do_machine_op $ cleanByVA_PoU slot (addrFromPPtr slot);\n     liftE $ invalidate_tlb_by_asid_va asid vptr\n   odE <catch> (K $ return ())\"\n\ntext \\<open>\n  Page table structure capabilities cannot be copied until they have an ASID and location\n  assigned. This is because they cannot have multiple current ASIDs and cannot be shared between\n  address spaces or virtual locations.\\<close>\ndefinition arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\" where\n  \"arch_derive_cap c \\<equiv>\n     case c of\n       PageTableCap _ _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n     | PageTableCap _ _ None \\<Rightarrow> throwError IllegalOperation\n     | FrameCap r R sz dev mp \\<Rightarrow> returnOk $ ArchObjectCap (FrameCap r R sz dev None)\n     | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n     | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\n     | VCPUCap _ \\<Rightarrow> returnOk (ArchObjectCap c)\"\n\ntext \\<open>No user-modifiable data is stored in AARCH64-specific capabilities.\\<close>\ndefinition arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\" where\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"\n\n\ntext \\<open>Actions that must be taken on finalisation of AARCH64-specific capabilities.\\<close>\ndefinition arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\" where\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n     (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n       delete_asid_pool b ptr;\n       return (NullCap, NullCap)\n     od\n   | (PageTableCap ptr VSRootPT_T (Some (a, v)), True) \\<Rightarrow> do\n       delete_asid a ptr;\n       return (NullCap, NullCap)\n     od\n   | (PageTableCap ptr NormalPT_T (Some (a, v)), True) \\<Rightarrow> do\n       unmap_page_table a v ptr;\n       return (NullCap, NullCap)\n     od\n   | (FrameCap ptr _ sz _ (Some (a, v)), _) \\<Rightarrow> do\n       unmap_page sz a v ptr;\n       return (NullCap, NullCap)\n     od\n   | (VCPUCap vcpu_ref, True) \\<Rightarrow> do\n      vcpu_finalise vcpu_ref;\n      return (NullCap, NullCap)\n     od\n   | _ \\<Rightarrow> return (NullCap, NullCap)\"\n\n\ntext \\<open>\n  A thread's virtual address space capability must be to a mapped page table to be valid on\n  the AARCH64 architecture.\\<close>\ndefinition is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv>\n     case c of ArchObjectCap (PageTableCap _ VSRootPT_T (Some _)) \\<Rightarrow> True | _ \\<Rightarrow> False\"\n\ntext \\<open>Make numeric value of @{const msg_align_bits} visible.\\<close>\nlemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\ndefinition check_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_valid_ipc_buffer vptr c \\<equiv>\n     case c of\n       ArchObjectCap (FrameCap _ _ _ False _) \\<Rightarrow>\n         whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError\n     | _ \\<Rightarrow> throwError IllegalOperation\"\n\ntext \\<open>A pointer is inside a user frame if its top bits point to a @{const DataPage}.\\<close>\ndefinition in_user_frame :: \"obj_ref \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n  \"in_user_frame p s \\<equiv>\n     \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) = Some (ArchObj (DataPage False sz))\"\n\ndefinition fpu_thread_delete :: \"obj_ref \\<Rightarrow> (unit, 'z::state_ext) s_monad\" where\n  \"fpu_thread_delete thread_ptr \\<equiv> do_machine_op (fpuThreadDeleteOp thread_ptr)\"\n\ndefinition prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"prepare_thread_delete thread_ptr \\<equiv> do\n     fpu_thread_delete thread_ptr;\n     t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu thread_ptr;\n     case t_vcpu of\n       Some v \\<Rightarrow> dissociate_vcpu_tcb v thread_ptr\n     | None \\<Rightarrow> return ()\n   od\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchVSpaceAcc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Accessing the AARCH64 VSpace\"\n\ntheory ArchVSpaceAcc_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This part of the specification is fairly concrete as the machine architecture is visible to\n  the user in seL4 and therefore needs to be described. The abstraction compared to the\n  implementation is in the data types for kernel objects. The interface which is rich in machine\n  details remains the same.\n\\<close>"}
{"title": "./spec/abstract/AARCH64/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The high bits of a virtual ASID.\\<close>\ndefinition asid_high_bits_of :: \"asid \\<Rightarrow> asid_high_index\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\"\n\ntext \\<open>The low bits of a virtual ASID.\\<close>\ndefinition asid_low_bits_of :: \"asid \\<Rightarrow> asid_low_index\" where\n  \"asid_low_bits_of asid \\<equiv> ucast asid\"\n\nlemmas asid_bits_of_defs = asid_high_bits_of_def asid_low_bits_of_def\n\nlocale_abbrev asid_table :: \"'z::state_ext state \\<Rightarrow> asid_high_index \\<rightharpoonup> obj_ref\" where\n  \"asid_table \\<equiv> \\<lambda>s. arm_asid_table (arch_state s)\""}
{"title": "./spec/abstract/AARCH64/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\n(* declared in Arch as workaround for VER-1099 *)\nlocale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\" where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"\n\ntext \\<open>Manipulate ASID pools, page directories and page tables in the kernel heap.\\<close>\n\nlocale_abbrev asid_pools_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> asid_pool\" where\n  \"asid_pools_of \\<equiv> \\<lambda>s. aobjs_of s |> asid_pool_of\"\n\nlocale_abbrev get_asid_pool :: \"obj_ref \\<Rightarrow> (asid_pool, 'z::state_ext) s_monad\" where\n  \"get_asid_pool \\<equiv> gets_map asid_pools_of\"\n\ndefinition set_asid_pool :: \"obj_ref \\<Rightarrow> asid_pool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_asid_pool ptr pool \\<equiv> do\n     get_asid_pool ptr;\n     set_object ptr (ArchObj (ASIDPool pool))\n   od\"\n\nlocale_abbrev pts_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> pt\" where\n  \"pts_of \\<equiv> \\<lambda>s. aobjs_of s |> pt_of\"\n\nlocale_abbrev get_pt :: \"obj_ref \\<Rightarrow> (pt,'z::state_ext) s_monad\" where\n  \"get_pt \\<equiv> gets_map pts_of\"\n\ndefinition set_pt :: \"obj_ref \\<Rightarrow> pt \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pt ptr pt \\<equiv> do\n     get_pt ptr;\n     set_object ptr (ArchObj (PageTable pt))\n   od\"\n\ntext \\<open>The base address of the table a page table entry at p is in (assuming alignment)\\<close>\nlocale_abbrev table_base :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref\" where\n  \"table_base pt_t p \\<equiv> p && ~~mask (pt_bits pt_t)\"\n\ntext \\<open>The index within the page table that a page table entry at p addresses. We return a\n  @{typ machine_word}, which is the slice of the provided address that represents the index in the\n  table of the specified table type.\\<close>\nlocale_abbrev table_index :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> machine_word\" where\n  \"table_index pt_t p \\<equiv> p && mask (pt_bits pt_t) >> pte_bits\"\n\ntext \\<open>Use an index computed by @{const table_index} and apply it to a page table. Bits higher than\n  the table index width will be ignored.\\<close>\ndefinition pt_apply :: \"pt \\<Rightarrow> machine_word \\<Rightarrow> pte\" where\n  \"pt_apply pt idx \\<equiv> case pt of NormalPT npt \\<Rightarrow> npt (ucast idx) | VSRootPT vs \\<Rightarrow> vs (ucast idx)\"\n\ntext \\<open>Extract a PTE from the page table of a specific level\\<close>\ndefinition level_pte_of :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref \\<rightharpoonup> pt) \\<rightharpoonup> pte\" where\n  \"level_pte_of pt_t p \\<equiv> do {\n      oassert (is_aligned p pte_bits);\n      pt \\<leftarrow> oapply (table_base pt_t p);\n      oassert (pt_type pt = pt_t);\n      oreturn $ pt_apply pt (table_index pt_t p)\n   }\"\n\ntype_synonym ptes_of = \"pt_type \\<Rightarrow> obj_ref \\<rightharpoonup> pte\"\n\nlocale_abbrev ptes_of :: \"'z::state_ext state \\<Rightarrow> ptes_of\" where\n  \"ptes_of s pt_t p \\<equiv> level_pte_of pt_t p (pts_of s)\"\n\nlemmas ptes_of_def = level_pte_of_def\n\ntext \\<open>The following function takes a pointer to a PTE in kernel memory and returns the PTE.\\<close>\nlocale_abbrev get_pte :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte pt_t \\<equiv> gets_map (swp ptes_of pt_t)\"\n\n\ntext \\<open>The update function that corresponds to @{const pt_apply}. Also expects an index computed\n  with @{const table_index} for the correct page table type.\\<close>\ndefinition pt_upd :: \"pt \\<Rightarrow> machine_word \\<Rightarrow> pte \\<Rightarrow> pt\" where\n  \"pt_upd pt idx pte \\<equiv> case pt of\n                         VSRootPT vs \\<Rightarrow> VSRootPT (vs(ucast idx := pte))\n                       | NormalPT pt \\<Rightarrow> NormalPT (pt(ucast idx := pte))\"\n\ndefinition store_pte :: \"pt_type \\<Rightarrow> obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte pt_t p pte \\<equiv> do\n     assert (is_aligned p pte_bits);\n     base \\<leftarrow> return $ table_base pt_t p;\n     pt \\<leftarrow> get_pt base;\n     assert (pt_type pt = pt_t);\n     set_pt base (pt_upd pt (table_index pt_t p) pte)\n   od\""}
{"title": "./spec/abstract/AARCH64/ArchVSpaceAcc_A.thy", "section": "Basic Operations", "subsection": "", "subsubsection": "", "code": "\n(* During pt_walk, we will only call this with level \\<le> max_pt_level, but in the invariants we\n   also make use of this function for level = asid_pool_level. *)\ndefinition pt_bits_left :: \"vm_level \\<Rightarrow> nat\" where\n  \"pt_bits_left level =\n    (if level = asid_pool_level\n     then ptTranslationBits VSRootPT_T + ptTranslationBits NormalPT_T * size max_pt_level\n     else ptTranslationBits NormalPT_T * size level)\n    + pageBits\"\n\ndefinition pt_index :: \"vm_level \\<Rightarrow> vspace_ref \\<Rightarrow> machine_word\" where\n  \"pt_index level vptr \\<equiv>\n     (vptr >> pt_bits_left level) && mask (ptTranslationBits level)\"\n\n\nlocale_abbrev global_pt :: \"'z state \\<Rightarrow> obj_ref\" where\n  \"global_pt s \\<equiv> arm_us_global_vspace (arch_state s)\""}
{"title": "./spec/abstract/AARCH64/ArchVSpaceAcc_A.thy", "section": "Basic Operations", "subsection": "", "subsubsection": "", "code": "\ndefinition pptr_from_pte :: \"pte \\<Rightarrow> vspace_ref\" where\n  \"pptr_from_pte pte \\<equiv> ptrFromPAddr (pte_base_addr pte)\"\n\ndefinition pt_slot_offset :: \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref\" where\n  \"pt_slot_offset level pt_ptr vptr = pt_ptr + (pt_index level vptr << pte_bits)\"\n\ntext \\<open>\n  This is the base function for walking a page table structure.\n  The walk proceeds from higher-level tables at the provided @{term level} (e.g. 2) to lower\n  level tables, down to @{term bot_level} (e.g. 0). It returns a pointer to the page table where\n  the walk stopped and the level of that table. The lookup stops when @{term bot_level} or a\n  page is reached.\n\\<close>\nfun pt_walk ::\n  \"vm_level \\<Rightarrow> vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> ptes_of \\<Rightarrow> (vm_level \\<times> obj_ref) option\"\n  where\n  \"pt_walk level bot_level pt_ptr vptr = do {\n     if bot_level < level\n     then do {\n       pte \\<leftarrow> oapply2 (level_type level) (pt_slot_offset level pt_ptr vptr);\n       if is_PageTablePTE pte\n         then pt_walk (level - 1) bot_level (pptr_from_pte pte) vptr\n         else oreturn (level, pt_ptr)\n     }\n     else oreturn (level, pt_ptr)\n   }\"\n\ndeclare pt_walk.simps[simp del]\n\ntext \\<open>\n  Looking up a slot in a page table structure. The function returns a level and an object\n  pointer. The pointer is to a slot in a table at the returned level. If the returned level is 0,\n  this slot is either an @{const InvalidPTE} or a @{const PagePTE}. If the returned level is higher\n  the slot may also be a @{const PageTablePTE}.\n\\<close>\ndefinition pt_lookup_slot_from_level ::\n  \"vm_level \\<Rightarrow> vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> ptes_of \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"pt_lookup_slot_from_level level bot_level pt_ptr vptr = do {\n     (level', pt_ptr') \\<leftarrow> pt_walk level bot_level pt_ptr vptr;\n     oreturn (level', pt_slot_offset level' pt_ptr' vptr)\n   }\"\n\ndefinition pt_lookup_slot :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> ptes_of \\<Rightarrow> (vm_level \\<times> obj_ref) option\" where\n  \"pt_lookup_slot = pt_lookup_slot_from_level max_pt_level 0\"\n\ntext \\<open>Returns the slot that points to @{text target_pt_ptr}\\<close>\nfun pt_lookup_from_level ::\n  \"vm_level \\<Rightarrow> obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (machine_word \\<times> vm_level, 'z::state_ext) lf_monad\"\n  where\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr s = (doE\n     unlessE (0 < level) $ throwError InvalidRoot;\n     slot <- returnOk $ pt_slot_offset level pt_ptr vptr;\n     pte <- liftE $ gets_the $ oapply slot o swp ptes_of level;\n     unlessE (is_PageTablePTE pte) $ throwError InvalidRoot;\n     ptr <- returnOk (pptr_from_pte pte);\n     if ptr = target_pt_ptr\n       then returnOk (slot, level)\n       else pt_lookup_from_level (level - 1) ptr vptr target_pt_ptr\n   odE) s\"\n(* We apply \"s\" to avoid a type variable warning, and increase in global freeindex counter,\n   which we would get without the application *)\n\ndeclare pt_lookup_from_level.simps[simp del]\n\n(* Recover simp rule without state applied: *)\nschematic_goal pt_lookup_from_level_simps:\n  \"pt_lookup_from_level level pt_ptr vptr target_pt_ptr = ?rhs\"\n  by (rule ext, rule pt_lookup_from_level.simps)\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchDecode_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Decoding Architecture-specific System Calls\"\n\ntheory ArchDecode_A\nimports\n  Interrupt_A\n  InvocationLabels_A\n  \"ExecSpec.InvocationLabels_H\"\nbegin\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/AARCH64/ArchDecode_A.thy", "section": "Architecture-specific Decode Functions", "subsection": "", "subsubsection": "", "code": "\ndefinition check_vp_alignment :: \"vmpage_size \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) se_monad\"\n  where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $ throwError AlignmentError\"\n\ndefinition page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\" where\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\""}
{"title": "./spec/abstract/AARCH64/ArchDecode_A.thy", "section": "Interface Functions used in Decode", "subsection": "", "subsubsection": "", "code": "\ndefinition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n     (if invocation_type label = ArchInvocationLabel ARMIRQIssueIRQHandlerTrigger\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n          returnOk $ ARMIRQControlInvocation irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\ndefinition attribs_from_word :: \"machine_word \\<Rightarrow> vm_attributes\" where\n  \"attribs_from_word w \\<equiv> {attr.  \\<not>w!!0 \\<and> attr = Device \\<or> \\<not>w !! 2 \\<and> attr = Execute}\"\n\ndefinition make_user_pte :: \"paddr \\<Rightarrow> vm_attributes \\<Rightarrow> vm_rights \\<Rightarrow> vmpage_size \\<Rightarrow> pte\" where\n  \"make_user_pte addr attr rights vm_size \\<equiv>\n     PagePTE addr (vm_size = ARMSmallPage) (attr - {Global}) rights\"\n\ndefinition check_vspace_root :: \"cap \\<Rightarrow> nat \\<Rightarrow> (obj_ref \\<times> asid, 'z) se_monad\" where\n  \"check_vspace_root cap arg_no \\<equiv>\n     case cap of\n       ArchObjectCap (PageTableCap pt VSRootPT_T (Some (asid, _))) \\<Rightarrow> returnOk (pt, asid)\n     | _ \\<Rightarrow> throwError $ InvalidCapability arg_no\"\n\ntype_synonym 'z arch_decoder =\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    (arch_invocation,'z) se_monad\"\n\ndefinition decode_fr_inv_map :: \"'z::state_ext arch_decoder\" where\n  \"decode_fr_inv_map label args cte cap extra_caps \\<equiv> case cap of\n     FrameCap p R pgsz dev mapped_address \\<Rightarrow>\n       if length args > 2 \\<and> length extra_caps > 0\n       then let\n           vaddr = args ! 0;\n           rights_mask = args ! 1;\n           attr = args ! 2;\n           vspace_cap = fst (extra_caps ! 0)\n         in doE\n           (pt, asid) \\<leftarrow> check_vspace_root vspace_cap 1;\n           pt' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n           whenE (pt' \\<noteq> pt) $ throwError $ InvalidCapability 1;\n           check_vp_alignment pgsz vaddr;\n           pg_bits \\<leftarrow> returnOk $ pageBitsForSize pgsz;\n           case mapped_address of\n             Some (asid', vaddr') \\<Rightarrow> doE\n               whenE (asid' \\<noteq> asid) $ throwError $ InvalidCapability 1;\n               whenE (vaddr' \\<noteq> vaddr) $ throwError $ InvalidArgument 0\n             odE\n           | None \\<Rightarrow> doE\n               vtop \\<leftarrow> returnOk $ vaddr + mask (pageBitsForSize pgsz);\n               whenE (vtop > user_vtop) $ throwError $ InvalidArgument 0\n             odE;\n           (level, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot pt vaddr \\<circ> ptes_of;\n           unlessE (pt_bits_left level = pg_bits) $\n             throwError $ FailedLookup False $ MissingCapability $ pt_bits_left level;\n           vm_rights \\<leftarrow> returnOk $ mask_vm_rights R (data_to_rights rights_mask);\n           attribs \\<leftarrow> returnOk $ attribs_from_word attr;\n           pte \\<leftarrow> returnOk $ make_user_pte (addrFromPPtr p) attribs vm_rights pgsz;\n           returnOk $ InvokePage $ PageMap (FrameCap p R pgsz dev (Some (asid,vaddr))) cte\n                                           (pte,slot,level)\n         odE\n       else throwError TruncatedMessage\n     | _ \\<Rightarrow> fail\"\n\ndefinition label_to_flush_type :: \"data \\<Rightarrow> flush_type\" where\n  \"label_to_flush_type label \\<equiv>\n     case invocation_type label of\n       ArchInvocationLabel ARMVSpaceClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPageClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMVSpaceInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPageInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMVSpaceCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPageCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMVSpaceUnify_Instruction \\<Rightarrow> Unify\n     | ArchInvocationLabel ARMPageUnify_Instruction \\<Rightarrow> Unify\"\n\ndefinition decode_fr_inv_flush :: \"'z::state_ext arch_decoder\" where\n  \"decode_fr_inv_flush label args cte cap extra_caps \\<equiv> case cap of\n     FrameCap p R pgsz dev mapped_address \\<Rightarrow>\n        if length args > 1\n        then let\n          start = args ! 0;\n          end = args ! 1\n        in doE\n          (asid, vaddr) \\<leftarrow> case mapped_address of\n                             Some a \\<Rightarrow> returnOk a\n                           | _ \\<Rightarrow> throwError IllegalOperation;\n          vspace \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n          whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n          page_size \\<leftarrow> returnOk $ 1 << pageBitsForSize pgsz;\n          whenE (start \\<ge> page_size \\<or> end > page_size) $ throwError $ InvalidArgument 0;\n          pstart \\<leftarrow> returnOk $ addrFromPPtr p + start;\n          \\<comment> \\<open>flush only inside the kernel window:\\<close>\n          whenE (pstart < paddrBase \\<or> ((end - start) + pstart > paddrTop)) $\n            throwError IllegalOperation;\n          returnOk $ InvokePage $\n            PageFlush (label_to_flush_type label)\n                      (vaddr + start) (vaddr + end - 1)\n                      pstart vspace asid\n        odE\n        else throwError TruncatedMessage\n   | _ \\<Rightarrow> fail\"\n\n\ndefinition decode_frame_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_frame_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel ARMPageMap\n     then decode_fr_inv_map label args cte cap extra_caps\n     else if invocation_type label = ArchInvocationLabel ARMPageUnmap\n     then returnOk $ InvokePage $ PageUnmap cap cte\n     else if invocation_type label = ArchInvocationLabel ARMPageGetAddress\n     then returnOk $ InvokePage $ PageGetAddr (acap_obj cap)\n     else if isPageFlushLabel (invocation_type label)\n     then decode_fr_inv_flush label args cte cap extra_caps\n     else throwError IllegalOperation\"\n\ndefinition decode_pt_inv_map :: \"'z::state_ext arch_decoder\" where\n  \"decode_pt_inv_map label args cte cap extra_caps \\<equiv> case cap of\n     PageTableCap p t mapped_address \\<Rightarrow>\n       if length args > 1 \\<and> length extra_caps > 0\n       then let\n           vaddr = args ! 0;\n           attr = args ! 1;\n           vspace_cap = fst (extra_caps ! 0)\n         in doE\n           whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n           (pt, asid) \\<leftarrow> check_vspace_root vspace_cap 1;\n           whenE (user_vtop < vaddr) $ throwError $ InvalidArgument 0;\n           pt' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n           whenE (pt' \\<noteq> pt) $ throwError $ InvalidCapability 1;\n           (level, slot) \\<leftarrow> liftE $ gets_the $ pt_lookup_slot pt vaddr \\<circ> ptes_of;\n           old_pte \\<leftarrow> liftE $ get_pte (level_type level) slot;\n           whenE (pt_bits_left level = pageBits \\<or> old_pte \\<noteq> InvalidPTE) $ throwError DeleteFirst;\n           pte \\<leftarrow> returnOk $ PageTablePTE (ppn_from_pptr p);\n           cap' <- returnOk $ PageTableCap p t $ Some (asid, vaddr && ~~mask (pt_bits_left level));\n           returnOk $ InvokePageTable $ PageTableMap cap' cte pte slot level\n         odE\n       else throwError TruncatedMessage\n     | _ \\<Rightarrow> fail\"\n\ndefinition decode_page_table_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_page_table_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel ARMPageTableMap\n     then decode_pt_inv_map label args cte cap extra_caps\n     else if invocation_type label = ArchInvocationLabel ARMPageTableUnmap\n     then doE\n       final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n       unlessE final $ throwError RevokeFirst;\n       returnOk $ InvokePageTable $ PageTableUnmap cap cte\n     odE\n     else throwError IllegalOperation\"\n\ndefinition level_of_vmsize :: \"vmpage_size \\<Rightarrow> vm_level\" where\n  \"level_of_vmsize vmsz \\<equiv>\n     case vmsz of\n       ARMSmallPage \\<Rightarrow> 0\n     | ARMLargePage \\<Rightarrow> 1\n     | ARMHugePage \\<Rightarrow> 2\"\n\ndefinition vmsize_of_level :: \"vm_level \\<Rightarrow> vmpage_size\" where\n  \"vmsize_of_level level \\<equiv>\n     if level = 0 then ARMSmallPage\n     else if level = 1 then ARMLargePage\n     else ARMHugePage\"\n\ndefinition lookup_frame :: \"obj_ref \\<Rightarrow> vspace_ref \\<Rightarrow> ptes_of \\<Rightarrow> (vmpage_size \\<times> paddr) option\" where\n  \"lookup_frame vspace vaddr = do {\n     (level, slot) \\<leftarrow> pt_lookup_slot vspace vaddr;\n     pte \\<leftarrow> oapply2 (level_type level) slot;\n     oassert (is_PagePTE pte);\n     oassert (level \\<le> 2);\n     oreturn (vmsize_of_level level, pte_base_addr pte)\n   }\"\n\ndefinition decode_vs_inv_flush :: \"'z::state_ext arch_decoder\" where\n  \"decode_vs_inv_flush label args cte cap extra_caps \\<equiv> case cap of\n     PageTableCap p VSRootPT_T mapped_address \\<Rightarrow>\n        if length args > 1\n        then let\n          start = args ! 0;\n          end = args ! 1\n        in doE\n          whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n          whenE (end > pptrUserTop) $ throwError $ IllegalOperation;\n          (vspace, asid) \\<leftarrow> check_vspace_root (ArchObjectCap cap) 0;\n          vspace' \\<leftarrow> lookup_error_on_failure False $ find_vspace_for_asid asid;\n          whenE (vspace' \\<noteq> vspace) $ throwError $ InvalidCapability 0;\n          frame_info \\<leftarrow> liftE $ gets $ lookup_frame p start \\<circ> ptes_of;\n          case frame_info of\n            None \\<Rightarrow> returnOk $ InvokeVSpace VSpaceNothing\n          | Some (pgsz, paddr) \\<Rightarrow> doE\n              bits_left  \\<leftarrow> returnOk $ pt_bits_left (level_of_vmsize pgsz);\n              base_start \\<leftarrow> returnOk $ page_base start pgsz;\n              base_end \\<leftarrow> returnOk $ page_base (end - 1) pgsz;\n              whenE (base_start \\<noteq> base_end) $\n                throwError $ RangeError start (base_start + mask bits_left);\n              pstart \\<leftarrow> returnOk $ paddr + (start && mask bits_left);\n              returnOk $ InvokeVSpace $\n                VSpaceFlush (label_to_flush_type label) start (end - 1) pstart vspace asid\n            odE\n        odE\n        else throwError TruncatedMessage\n   | _ \\<Rightarrow> fail\"\n\ndefinition decode_vspace_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_vspace_invocation label args cte cap extra_caps \\<equiv>\n     if isVSpaceFlushLabel (invocation_type label)\n     then decode_vs_inv_flush label args cte cap extra_caps\n     else throwError IllegalOperation\"\n\ndefinition decode_asid_control_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_asid_control_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel ARMASIDControlMakePool\n     then if length args > 1 \\<and> length extra_caps > 1\n     then let\n         index = args ! 0;\n         depth = args ! 1;\n         (untyped, parent_slot) = extra_caps ! 0;\n         root = fst (extra_caps ! 1)\n       in doE\n         asid_table \\<leftarrow> liftE $ gets asid_table;\n         free_set \\<leftarrow> returnOk (- dom asid_table);\n         whenE (free_set = {}) $ throwError DeleteFirst;\n         free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n         base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n         (p,n) \\<leftarrow> case untyped of\n                    UntypedCap False p n _ \\<Rightarrow> returnOk (p,n)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 1;\n         frame \\<leftarrow> if n = pageBits then doE\n                    ensure_no_children parent_slot;\n                    returnOk p\n                  odE\n                  else throwError $ InvalidCapability 1;\n         dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n         ensure_empty dest_slot;\n         returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n       odE\n     else throwError TruncatedMessage\n     else throwError IllegalOperation\"\n\ndefinition decode_asid_pool_invocation :: \"'z::state_ext arch_decoder\" where\n  \"decode_asid_pool_invocation label args cte cap extra_caps \\<equiv>\n     if invocation_type label = ArchInvocationLabel ARMASIDPoolAssign\n     then if length extra_caps > 0\n     then let\n         (pt_cap, pt_cap_slot) = extra_caps ! 0;\n         p = acap_obj cap;\n         base = acap_asid_base cap\n       in case pt_cap of\n         ArchObjectCap (PageTableCap _ VSRootPT_T None) \\<Rightarrow> doE\n           asid_table \\<leftarrow> liftE $ gets asid_table;\n           pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n           whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n           whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n           pool \\<leftarrow> liftE $ get_asid_pool p;\n           free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n           whenE (free_set = {}) $ throwError DeleteFirst;\n           offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n           returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pt_cap_slot\n         odE\n       | _ \\<Rightarrow> throwError $ InvalidCapability 1\n     else throwError TruncatedMessage\n     else throwError IllegalOperation\"\n\ndefinition arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n    (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n     PageTableCap _ VSRootPT_T _ \\<Rightarrow> decode_vspace_invocation label args cte cap extra_caps\n   | PageTableCap _ NormalPT_T _ \\<Rightarrow> decode_page_table_invocation label args cte cap extra_caps\n   | FrameCap _ _ _ _ _        \\<Rightarrow> decode_frame_invocation label args cte cap extra_caps\n   | ASIDControlCap            \\<Rightarrow> decode_asid_control_invocation label args cte cap extra_caps\n   | ASIDPoolCap _ _           \\<Rightarrow> decode_asid_pool_invocation label args cte cap extra_caps\n   | VCPUCap _                 \\<Rightarrow> decode_vcpu_invocation label args cap extra_caps\""}
{"title": "./spec/abstract/AARCH64/ArchDecode_A.thy", "section": "Interface Functions used in Decode", "subsection": "", "subsubsection": "", "code": "\ndefinition arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n  \"arch_data_to_obj_type n \\<equiv>\n     if      n = 0 then Some HugePageObj\n     else if n = 1 then Some VSpaceObj\n     else if n = 2 then Some SmallPageObj\n     else if n = 3 then Some LargePageObj\n     else if n = 4 then Some PageTableObj\n     else if n = 5 then Some VCPUObj\n     else None\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/VCPUAcc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"AARCH64 VCPU Accessor Functions\"\n\ntheory VCPUAcc_A\nimports\n  ArchVSpaceAcc_A\n  ArchTcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/AARCH64/VCPUAcc_A.thy", "section": "Manipulation of VCPU-related state and registers", "subsection": "", "subsubsection": "", "code": "\nlocale_abbrev vcpus_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> vcpu\" where\n  \"vcpus_of \\<equiv> \\<lambda>s. aobjs_of s |> vcpu_of\"\n\ndefinition get_vcpu :: \"obj_ref \\<Rightarrow> (vcpu,'z::state_ext) s_monad\" where\n  \"get_vcpu \\<equiv> gets_map vcpus_of\"\n\ndefinition set_vcpu :: \"obj_ref \\<Rightarrow> vcpu \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_vcpu ptr vcpu \\<equiv> set_object ptr (ArchObj (VCPU vcpu))\""}
{"title": "./spec/abstract/AARCH64/VCPUAcc_A.thy", "section": "Manipulation of VCPU-related state and registers", "subsection": "", "subsubsection": "", "code": "\ndefinition vcpu_update :: \"obj_ref \\<Rightarrow> (vcpu \\<Rightarrow> vcpu) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_update vr f \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    set_vcpu vr (f vcpu)\n  od\"\n\ndefinition vgic_update ::\n  \"obj_ref \\<Rightarrow> (gic_vcpu_interface \\<Rightarrow> gic_vcpu_interface) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vgic_update vr f \\<equiv> vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_vgic := f (vcpu_vgic vcpu) \\<rparr> )\"\n\ndefinition vgic_update_lr :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vgic_update_lr vr irq_idx virq \\<equiv>\n    vgic_update vr (\\<lambda>vgic. vgic \\<lparr> vgic_lr := (vgic_lr vgic)(irq_idx := virq) \\<rparr>)\"\n\ndefinition vcpu_save_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_save_reg vr reg \\<equiv> do\n    rval \\<leftarrow> do_machine_op (readVCPUHardwareReg reg);\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := rval) \\<rparr> )\n  od\"\n\ndefinition vcpu_save_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_save_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_save_reg vr reg) [from .e. to]\"\n\ndefinition vcpu_restore_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_restore_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    do_machine_op (writeVCPUHardwareReg reg (vcpu_regs vcpu reg))\n  od\"\n\ndefinition vcpu_restore_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"vcpu_restore_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_restore_reg vr reg) [from .e. to]\"\n\ndefinition vcpu_read_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word, 'z::state_ext) s_monad\" where\n  \"vcpu_read_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    return (vcpu_regs vcpu reg)\n  od\"\n\ndefinition vcpu_write_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"vcpu_write_reg vr reg val \\<equiv>\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := val) \\<rparr> )\"\n\ndefinition save_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"save_virt_timer vcpu_ptr \\<equiv> do\n     vcpu_save_reg vcpu_ptr VCPURegCNTV_CTL;\n     do_machine_op $ writeVCPUHardwareReg VCPURegCNTV_CTL 0;\n     vcpu_save_reg vcpu_ptr VCPURegCNTV_CVAL;\n     vcpu_save_reg vcpu_ptr VCPURegCNTVOFF;\n     vcpu_save_reg vcpu_ptr VCPURegCNTKCTL_EL1;\n     do_machine_op check_export_arch_timer;\n     cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu_update vcpu_ptr (\\<lambda>vcpu. vcpu\\<lparr>vcpu_vtimer := VirtTimer cntpct \\<rparr>)\n   od\"\n\ndefinition irq_vppi_event_index :: \"irq \\<rightharpoonup> vppievent_irq\" where\n  \"irq_vppi_event_index irq \\<equiv>\n     if irq = irqVTimerEvent\n     then Some VPPIEventIRQ_VTimer\n     else None\"\n\ndefinition restore_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"restore_virt_timer vcpu_ptr \\<equiv> do\n     vcpu_restore_reg vcpu_ptr VCPURegCNTV_CVAL;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTKCTL_EL1;\n     current_cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu \\<leftarrow> get_vcpu vcpu_ptr;\n     last_pcount \\<leftarrow> return $ vtimerLastPCount $ vcpu_vtimer vcpu;\n     delta \\<leftarrow> return $ current_cntpct - last_pcount;\n     cntvoff \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTVOFF;\n     offset \\<leftarrow> return $ cntvoff + ucast delta;\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFF offset;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTVOFF;\n     \\<comment> \\<open>read again, so we don't have to reason about @{const vcpu_write_reg} changes in CRefine\\<close>\n     vcpu \\<leftarrow> get_vcpu vcpu_ptr;\n     masked \\<leftarrow> return $ (vcpu_vppi_masked vcpu (the $ irq_vppi_event_index irqVTimerEvent));\n     \\<comment> \\<open>we do not know here that irqVTimerEvent is IRQReserved, therefore not IRQInactive,\n        so the only way to prove we don't unmask an inactive interrupt is to check\\<close>\n     safe_to_unmask \\<leftarrow> is_irq_active irqVTimerEvent;\n     when safe_to_unmask $ do_machine_op $ maskInterrupt masked irqVTimerEvent;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTV_CTL\n   od\"\n\ntext \\<open>Turn VPCU mode off on the hardware level.\\<close>\ndefinition vcpu_disable :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_disable vo \\<equiv> do\n    do_machine_op dsb;\n    case vo of\n      Some vr \\<Rightarrow> do\n        hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n        vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n        vcpu_save_reg vr VCPURegSCTLR;\n        vcpu_save_reg vr VCPURegCPACR; \\<comment> \\<open>since FPU enabled\\<close>\n        do_machine_op isb\n      od\n    | _ \\<Rightarrow> return ();\n    do_machine_op $ do\n        set_gic_vcpu_ctrl_hcr 0; \\<comment> \\<open>turn VGIC off\\<close>\n        isb;\n        setSCTLR sctlrDefault; \\<comment> \\<open>turn S1 MMU off\\<close>\n        isb;\n        setHCR hcrNative;\n        isb;\n        \\<comment> \\<open>allow FPU instructions in EL0 and EL1 for native threads\\<close>\n        enableFpuEL01\n      od;\n    case vo of\n      Some vr \\<Rightarrow> do\n          save_virt_timer vr;\n          do_machine_op $ maskInterrupt True irqVTimerEvent\n        od\n    | _ \\<Rightarrow> return ()\n    od\"\n\ntext \\<open>Turn VCPU mode on, on the hardware level.\\<close>\ndefinition vcpu_enable :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_enable vr \\<equiv> do\n     vcpu_restore_reg vr VCPURegSCTLR;\n     vcpu \\<leftarrow> get_vcpu vr;\n     do_machine_op $ do\n        setHCR hcrVCPU;\n        isb;\n        set_gic_vcpu_ctrl_hcr (vgic_hcr $ vcpu_vgic vcpu)\n     od;\n     vcpu_restore_reg vr VCPURegCPACR; \\<comment> \\<open>FPU\\<close>\n     restore_virt_timer vr\n   od\"\n\ntext \\<open>Prepare the current VCPU for removal.\\<close>\ndefinition vcpu_invalidate_active :: \"(unit,'z::state_ext) s_monad\" where\n  \"vcpu_invalidate_active \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    case cur_v of\n      Some (vr, True) \\<Rightarrow> vcpu_disable None\n    | _ \\<Rightarrow> return ();\n    modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := None \\<rparr>\\<rparr>)\n  od\"\n\ntext \\<open>Register + context save for VCPUs\\<close>\ndefinition vcpu_save :: \"(obj_ref \\<times> bool) option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_save vb \\<equiv>\n     case vb\n     of Some (vr, active) \\<Rightarrow> do\n          do_machine_op dsb;\n\n          when active $ do\n            vcpu_save_reg vr VCPURegSCTLR;\n            hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n            vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n            save_virt_timer vr\n          od;\n\n          vmcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_vmcr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_vmcr := vmcr\\<rparr>);\n\n          apr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_apr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_apr := apr\\<rparr>);\n\n          num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n          gicIndices \\<leftarrow> return [0..<num_list_regs];\n\n          mapM (\\<lambda>vreg. do\n                    val \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat vreg);\n                    vgic_update_lr vr vreg val\n                  od)\n            gicIndices;\n\n          \\<comment> \\<open>armvVCPUSave\\<close>\n          vcpu_save_reg_range vr VCPURegTTBR0 VCPURegSPSR_EL1\n       od\n     | _ \\<Rightarrow> fail\"\n\ntext \\<open>Register + context restore for VCPUs\\<close>\ndefinition vcpu_restore :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_restore vr \\<equiv> do\n     do_machine_op $ set_gic_vcpu_ctrl_hcr 0;  \\<comment> \\<open>turn off VGIC\\<close>\n     do_machine_op $ isb;\n     vcpu \\<leftarrow> get_vcpu vr;  \\<comment> \\<open>restore GIC VCPU control state\\<close>\n     vgic \\<leftarrow> return (vcpu_vgic vcpu);\n     num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     gicIndices \\<leftarrow> return [0..<num_list_regs];\n     do_machine_op $ do\n         set_gic_vcpu_ctrl_vmcr (vgic_vmcr vgic);\n         set_gic_vcpu_ctrl_apr (vgic_apr vgic);\n         mapM (\\<lambda>p. set_gic_vcpu_ctrl_lr (of_nat (fst p)) (snd p))\n              (map (\\<lambda>i. (i, (vgic_lr vgic) i)) gicIndices)\n     od;\n    \\<comment> \\<open>restore banked VCPU registers except SCTLR (that's in VCPUEnable)\\<close>\n     vcpu_restore_reg_range vr VCPURegTTBR0 VCPURegSPSR_EL1;\n     vcpu_enable vr\n  od\"\n\ntext \\<open>\n  Make a new VCPU the active/current VCPU. If passed None, will mark the current VCPU as\n  not active, and disable VCPU mode, but leave the rest intact caching for the case where\n  we switch back to the same VCPU soon.\\<close>\ndefinition vcpu_switch :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_switch v \\<equiv> case v of\n     None \\<Rightarrow> do\n       cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n       (case cur_v of\n          None \\<Rightarrow> return () \\<comment> \\<open>both null, current cannot be active\\<close>\n        | Some (vr, active) \\<Rightarrow> do \\<comment> \\<open>switch to thread without vcpu\\<close>\n            when active $ do  \\<comment> \\<open> save state if not saved already\\<close>\n              vcpu_disable (Some vr);\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (vr, False) \\<rparr>\\<rparr>)\n            od;\n            return ()\n          od)\n       od\n   | Some new \\<Rightarrow> do\n       cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n       (case cur_v of\n          None \\<Rightarrow> do \\<comment> \\<open>switch to the new vcpu with no current one\\<close>\n            vcpu_restore new;\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n          od\n        | Some (vr, active) \\<Rightarrow> \\<comment> \\<open>switch from an existing vcpu\\<close>\n            (if vr \\<noteq> new\n            then do \\<comment> \\<open>different vcpu\\<close>\n              vcpu_save cur_v;\n              vcpu_restore new;\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n            od\n            else \\<comment> \\<open>same vcpu\\<close>\n              when (\\<not> active) $ do\n                do_machine_op isb;\n                vcpu_enable new;\n                modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n              od))\n     od\"\n\n\ntext \\<open>VCPU objects can be associated with and dissociated from TCBs.\\<close>\n\ntext \\<open>Removing the connection between a TCB and VCPU:\\<close>\ndefinition dissociate_vcpu_tcb :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"dissociate_vcpu_tcb vr t \\<equiv> do\n     t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n     v \\<leftarrow> get_vcpu vr;\n     assert (t_vcpu = Some vr \\<and> vcpu_tcb v = Some t); \\<comment> \\<open>make sure they were associated\\<close>\n     cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     when (\\<exists>a. cur_v = Some (vr,a)) vcpu_invalidate_active;\n     arch_thread_set (\\<lambda>x. x \\<lparr> tcb_vcpu := None \\<rparr>) t;\n     set_vcpu vr (v\\<lparr> vcpu_tcb := None \\<rparr>);\n     as_user t $ do\n       sr \\<leftarrow> getRegister SPSR_EL1;\n       setRegister SPSR_EL1 $ sanitise_register False SPSR_EL1 sr\n     od\n   od\"\n\ntext \\<open>Associating a TCB and VCPU, removing any potentially existing associations:\\<close>\ndefinition associate_vcpu_tcb :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"associate_vcpu_tcb vcpu_ptr t \\<equiv> do\n     t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n     case t_vcpu of\n       Some p \\<Rightarrow> dissociate_vcpu_tcb p t\n     | _ \\<Rightarrow> return ();\n     v \\<leftarrow> get_vcpu vcpu_ptr;\n     case vcpu_tcb v of\n       Some p \\<Rightarrow> dissociate_vcpu_tcb vcpu_ptr p\n     | _ \\<Rightarrow> return ();\n     arch_thread_set (\\<lambda>x. x \\<lparr> tcb_vcpu := Some vcpu_ptr \\<rparr>) t;\n     set_vcpu vcpu_ptr (v\\<lparr> vcpu_tcb := Some t \\<rparr>);\n     ct \\<leftarrow> gets cur_thread;\n     when (t = ct) $ vcpu_switch (Some vcpu_ptr)\n  od\"\n\ntext \\<open>\n  Prepare a given VCPU for removal: dissociate it, and clean up current VCPU state\n  if necessary.\\<close>\ndefinition vcpu_finalise :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vcpu_finalise vr \\<equiv> do\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of\n      Some t \\<Rightarrow> dissociate_vcpu_tcb vr t\n    | None \\<Rightarrow> return ()\n   od\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchInvocation_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>AARCH64 Object Invocations\\<close>\n\ntheory ArchInvocation_A\nimports Structures_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  These datatypes encode the arguments to the various possible AARCH64-specific system calls.\n  Selectors are defined for various fields for convenience elsewhere.\n\\<close>\n\ndatatype vspace_invocation =\n    VSpaceNothing\n  | VSpaceFlush\n      (vs_flush_type : flush_type)\n      (vs_flush_start : vspace_ref)\n      (vs_flush_end : vspace_ref)\n      (vs_flush_pstart : paddr)\n      (vs_flush_space : obj_ref)\n      (vs_flush_asid : asid)\n\ndatatype page_table_invocation =\n    PageTableMap\n      (pt_inv_cap : arch_cap)\n      (pt_inv_cslot : cslot_ptr)\n      (pt_map_pte : pte)\n      (pt_map_slot : obj_ref)\n      (pt_map_level : vm_level)\n  | PageTableUnmap\n      (pt_inv_cap : arch_cap)\n      (pt_inv_cslot : cslot_ptr)\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation =\n    PageMap\n      (pg_inv_cap : arch_cap)\n      (pg_inv_cslot : cslot_ptr)\n      (pg_inv_entries : \"pte \\<times> obj_ref \\<times> vm_level\")\n  | PageUnmap\n      (pg_inv_cap : arch_cap)\n      (pg_inv_cslot : cslot_ptr)\n  | PageGetAddr\n      (pg_get_paddr : obj_ref)\n  | PageFlush\n      (pg_flush_type : flush_type)\n      (pg_flush_start : vspace_ref)\n      (pg_flush_end : vspace_ref)\n      (pg_flush_pStart : paddr)\n      (pg_flush_space : obj_ref)\n      (pg_flush_asid : asid)\n\ndatatype vcpu_invocation =\n    VCPUSetTCB\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_tcb : obj_ref)\n  | VCPUInjectIRQ\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_idx : nat)\n      (vcpu_inv_irq : virq)\n  | VCPUReadRegister\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_reg : vcpureg)\n  | VCPUWriteRegister\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_reg : vcpureg)\n      (vcpu_inv_val : machine_word)\n  | VCPUAckVPPI\n      (vcpu_inv_vcpu : obj_ref)\n      (vcpu_inv_eirq : vppievent_irq)\n\ndatatype arch_invocation =\n    InvokeVSpace vspace_invocation\n  | InvokePageTable page_table_invocation\n  | InvokePage page_invocation\n  | InvokeASIDControl asid_control_invocation\n  | InvokeASIDPool asid_pool_invocation\n  | InvokeVCPU vcpu_invocation\n\ndatatype arch_copy_register_sets =\n    ARMNoExtraRegisters\n\ndefinition ArchDefaultExtraRegisters :: arch_copy_register_sets where\n  \"ArchDefaultExtraRegisters = ARMNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    ARMIRQControlInvocation irq cslot_ptr cslot_ptr bool\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"AARCH64-Specific Data Types\"\n\ntheory Arch_Structs_A\nimports\n  \"ExecSpec.Arch_Structs_B\"\n  ExceptionTypes_A\n  VMRights_A\n  ExecSpec.Arch_Kernel_Config_Lemmas\nbegin\n\ncontext begin interpretation Arch . (* code equations must be added via interpretation *)\nlemmas [code] = pageBits_def ipa_size_def\nend\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This theory provides architecture-specific definitions and datatypes including\n  architecture-specific capabilities and objects.\n\\<close>"}
{"title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "section": "Architecture-specific objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  The AARCH64 kernel supports capabilities for ASID pools and an ASID controller capability,\n  along with capabilities for virtual memory mappings.\n\\<close>\n\ndatatype arch_cap =\n    ASIDPoolCap\n      (acap_obj : obj_ref)\n      (acap_asid_base : asid)\n  | ASIDControlCap\n  | FrameCap\n      (acap_obj : obj_ref)\n      (acap_rights : cap_rights)\n      (acap_fsize : vmpage_size)\n      (acap_is_device : bool)\n      (acap_map_data : \"(asid \\<times> vspace_ref) option\")\n  | PageTableCap\n      (acap_obj : obj_ref)\n      (acap_pt_type : pt_type)\n      (acap_map_data : \"(asid \\<times> vspace_ref) option\")\n  | VCPUCap\n      (acap_obj : obj_ref)\n\n\ntext \\<open>Update the mapping data saved in a frame or page table capability.\\<close>\ndefinition update_map_data :: \"arch_cap \\<Rightarrow> (asid \\<times> vspace_ref) option \\<Rightarrow> arch_cap\" where\n  \"update_map_data cap m \\<equiv> case cap of\n     FrameCap p R sz dev _  \\<Rightarrow> FrameCap p R sz dev m\n   | PageTableCap p t _ \\<Rightarrow> PageTableCap p t m\""}
{"title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "section": "Architecture-specific object types and default objects", "subsection": "VCPU", "subsubsection": "", "code": "\n(* This datatype does not match up with the executable spec directly:\n   This one here models all \"things\" one can set on a page entry.\n   The attributes accessible to users are the ones returned by attribs_from_word. *)\ndatatype vm_attribute = Global | Execute | Device\ntype_synonym vm_attributes = \"vm_attribute set\"\n\ntext \\<open>\n  The C field @{text base_addr} for next-level tables of @{text PagePTE}s is a 36 bit field-high\n  value, i.e., a 48-bit word with the bottom 12 bits always set to 0. (They must be 0 due to\n  alignment). Since Arm does not specify a name, we are re-using the RISC-V name @{text ppn}\n  (physical page number) for the concept of encoding only the significant bits of this address.\n\n  In addition to the bottom 12 bits being 0 (where 12 = @{const pageBits}), we also know that\n  the base address of the next level table is a physical address and therefore has the same width\n  as intermediate physical addresses (@{const ipa_size}). We can therefore be more precise in the\n  encoding here: the significant bits of the next-level page table address go from @{const ipa_size}\n  at the top to @{const pageBits} at the bottom. Similar to the ppn on RISC-V we store a word\n  of that size, and shift by @{const pageBits} to get the address. This encodes both a size invariant\n  and an alignment invariant in the type, which functions like @{text pt_walk} rely on.\n\n  To provide the same field name as in C, we define @{text pte_base_addr} as the main accessor\n  function.\\<close>\nvalue_type ppn_len = \"ipa_size - pageBits\"\ntype_synonym ppn = \"ppn_len word\"\n\ntext \\<open>This lemma encodes @{typ ppn_len} value above as a term, so we can use it generically:\\<close>\nlemma ppn_len_def':\n  \"ppn_len = ipa_size - pageBits\"\n  by (simp add: ppn_len_val pageBits_def ipa_size_def Kernel_Config.config_ARM_PA_SIZE_BITS_40_def)\n\ndatatype pte =\n    InvalidPTE\n  | PagePTE\n      (pte_page_addr : paddr)\n      (pte_is_small_page : bool)\n      (pte_attr : vm_attributes)\n      (pte_rights : vm_rights)\n  | PageTablePTE\n      (pte_ppn : ppn)\n\ndefinition paddr_from_ppn :: \"ppn \\<Rightarrow> paddr\" where\n  \"paddr_from_ppn addr \\<equiv> ucast addr << pageBits\"\n\ndefinition pte_base_addr :: \"pte \\<Rightarrow> paddr\" where\n  \"pte_base_addr pte \\<equiv>\n    if is_PageTablePTE pte then paddr_from_ppn (pte_ppn pte) else pte_page_addr pte\"\n\ndefinition ppn_from_pptr :: \"obj_ref \\<Rightarrow> ppn\" where\n  \"ppn_from_pptr p = ucast (addrFromPPtr p >> pageBits)\"\n\n(* Sanity check for page table type sizes -- ptTranslationBits not yet available at definition site *)\nlemma vs_index_ptTranslationBits:\n  \"ptTranslationBits VSRootPT_T = LENGTH(vs_index_len)\"\n  by (simp add: ptTranslationBits_def vs_index_bits_def)\n\nlemma pt_index_ptTranslationBits:\n  \"ptTranslationBits NormalPT_T = LENGTH(pt_index_len)\"\n  by (simp add: ptTranslationBits_def)\n\n(* This could also be a record, but we expect further alternatives to be added for SMMU *)\ndatatype asid_pool_entry = ASIDPoolVSpace (ap_vmid : \"vmid option\") (ap_vspace : obj_ref)\n\ntype_synonym asid_pool = \"asid_low_index \\<rightharpoonup> asid_pool_entry\"\n\ndatatype pt =\n    VSRootPT (the_vs : \"vs_index \\<Rightarrow> pte\")\n  | NormalPT (the_pt : \"pt_index \\<Rightarrow> pte\")\n\ndefinition pt_type :: \"pt \\<Rightarrow> pt_type\" where\n  \"pt_type pt \\<equiv> case pt of VSRootPT _ \\<Rightarrow> VSRootPT_T | NormalPT _ \\<Rightarrow> NormalPT_T\""}
{"title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "section": "Architecture-specific object types and default objects", "subsection": "VCPU", "subsubsection": "", "code": "\ntype_synonym virq = machine_word\n\nend\n\nqualify AARCH64_A (in Arch)\n\nrecord  gic_vcpu_interface =\n  vgic_hcr  :: word32\n  vgic_vmcr :: word32\n  vgic_apr  :: word32\n  vgic_lr   :: \"nat \\<Rightarrow> AARCH64_A.virq\"\n\nrecord vcpu =\n  vcpu_tcb  :: \"obj_ref option\"\n  vcpu_vgic :: \"gic_vcpu_interface\"\n  vcpu_regs :: \"vcpureg \\<Rightarrow> machine_word\"\n  vcpu_vppi_masked :: \"vppievent_irq \\<Rightarrow> bool\"\n  vcpu_vtimer :: virt_timer\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition \"vcpu_sctlr vcpu \\<equiv> vcpu_regs vcpu VCPURegSCTLR\"\n\ndefinition default_gic_vcpu_interface :: gic_vcpu_interface where\n  \"default_gic_vcpu_interface \\<equiv> \\<lparr>\n      vgic_hcr  = vgicHCREN,\n      vgic_vmcr = 0,\n      vgic_apr  = 0,\n      vgic_lr   = \\<lambda>_. 0\n   \\<rparr>\"\n\ndefinition\n  default_vcpu :: vcpu where\n  \"default_vcpu \\<equiv> \\<lparr>\n      vcpu_tcb    = None,\n      vcpu_vgic   = default_gic_vcpu_interface,\n      vcpu_regs   = (\\<lambda>_. 0) (VCPURegSCTLR := sctlrEL1VM),\n      vcpu_vppi_masked = (\\<lambda>_. False),\n      vcpu_vtimer = VirtTimer 0\n   \\<rparr>\"\n\n(* produce discriminators and selectors even though no field names are mentioned *)\ndatatype (discs_sels) arch_kernel_obj =\n    ASIDPool asid_pool\n  | PageTable pt\n  | DataPage bool vmpage_size\n  | VCPU vcpu\n\ndefinition asid_pool_of :: \"arch_kernel_obj \\<rightharpoonup> asid_pool\" where\n  \"asid_pool_of ko \\<equiv> case ko of ASIDPool pool \\<Rightarrow> Some pool | _ \\<Rightarrow> None\"\n\ndefinition pt_of :: \"arch_kernel_obj \\<rightharpoonup> pt\" where\n  \"pt_of ko \\<equiv> case ko of PageTable pt \\<Rightarrow> Some pt | _ \\<Rightarrow> None\"\n\ndefinition vcpu_of :: \"arch_kernel_obj \\<rightharpoonup> vcpu\" where\n  \"vcpu_of ko \\<equiv> case ko of VCPU vcpu \\<Rightarrow> Some vcpu | _ \\<Rightarrow> None\"\n\ndefinition pte_bits :: nat where\n  \"pte_bits = word_size_bits\"\n\ndefinition table_size :: \"pt_type \\<Rightarrow> nat\" where\n  \"table_size pt_t = ptTranslationBits pt_t + pte_bits\"\n\ndefinition pt_bits :: \"pt_type \\<Rightarrow> nat\" where\n  \"pt_bits pt_t \\<equiv> table_size pt_t\"\n\n(* sanity check *)\nlemma ppn_len:\n  \"LENGTH(ppn_len) = ipa_size - pt_bits NormalPT_T\"\n  by (simp add: pt_bits_def table_size_def ptTranslationBits_def pte_bits_def word_size_bits_def\n                ipa_size_def Kernel_Config.config_ARM_PA_SIZE_BITS_40_def)\n\nprimrec arch_obj_size :: \"arch_cap \\<Rightarrow> nat\" where\n  \"arch_obj_size (ASIDPoolCap _ _) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (FrameCap _ _ sz _ _) = pageBitsForSize sz\"\n| \"arch_obj_size (PageTableCap _ pt_t _ ) = table_size pt_t\"\n| \"arch_obj_size (VCPUCap _) = vcpuBits\"\n\nfun arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_cap_is_device (FrameCap _ _ _ is_dev _) = is_dev\"\n| \"arch_cap_is_device _ = False\"\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 5\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 11\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 5\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 47\"\n\nprimrec arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\" where\n  \"arch_kobj_size (ASIDPool _) = pageBits\"\n| \"arch_kobj_size (PageTable pt) = table_size (pt_type pt)\"\n| \"arch_kobj_size (DataPage _ sz) = pageBitsForSize sz\"\n| \"arch_kobj_size (VCPU _) = vcpuBits\"\n\nfun aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\" where\n  \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref c = Some (acap_obj c)\"\n\ndefinition acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n  \"acap_rights_update R acap \\<equiv>\n    case acap of\n      FrameCap ref cR sz dev as \\<Rightarrow> FrameCap ref (validate_vm_rights R) sz dev as\n    | _ \\<Rightarrow> acap\""}
{"title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "section": "Architecture-specific state", "subsection": "VCPU", "subsubsection": "", "code": "\ndatatype aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | HugePageObj\n  | PageTableObj\n  | VSpaceObj\n  | ASIDPoolObj (* used internally, not on API level *)\n  | VCPUObj\n\ndefinition arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\" where\n  \"arch_is_frame_type aobj \\<equiv> case aobj of\n     SmallPageObj \\<Rightarrow> True\n   | LargePageObj \\<Rightarrow> True\n   | HugePageObj \\<Rightarrow> True\n   | _ \\<Rightarrow> False\"\n\ndefinition arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\" where\n  \"arch_default_cap tp r n dev \\<equiv> case tp of\n     SmallPageObj \\<Rightarrow> FrameCap r vm_read_write ARMSmallPage dev None\n   | LargePageObj \\<Rightarrow> FrameCap r vm_read_write ARMLargePage dev None\n   | HugePageObj  \\<Rightarrow> FrameCap r vm_read_write ARMHugePage dev None\n   | PageTableObj \\<Rightarrow> PageTableCap r NormalPT_T None\n   | VSpaceObj    \\<Rightarrow> PageTableCap r VSRootPT_T None\n   | VCPUObj      \\<Rightarrow> VCPUCap r\n   | ASIDPoolObj  \\<Rightarrow> ASIDPoolCap r 0\" (* unused, but nicer properties when defined *)\n\ndefinition default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\" where\n  \"default_arch_object tp dev n \\<equiv> case tp of\n     SmallPageObj \\<Rightarrow> DataPage dev ARMSmallPage\n   | LargePageObj \\<Rightarrow> DataPage dev ARMLargePage\n   | HugePageObj  \\<Rightarrow> DataPage dev ARMHugePage\n   | PageTableObj \\<Rightarrow> PageTable (NormalPT (\\<lambda>_. InvalidPTE))\n   | VSpaceObj    \\<Rightarrow> PageTable (VSRootPT (\\<lambda>_. InvalidPTE))\n   | VCPUObj \\<Rightarrow> VCPU default_vcpu\n   | ASIDPoolObj  \\<Rightarrow> ASIDPool Map.empty\"\n\ntype_synonym arm_vspace_region_uses = \"vspace_ref \\<Rightarrow> arm_vspace_region_use\"\n\ntext \\<open>\n  The number of levels over all virtual memory tables.\n  For AARCH64 in hyp without @{const config_ARM_PA_SIZE_BITS_40}, we have four page table\n  levels plus the ASID pool level.\n\n  The top level (with the highest number) contains ASID pools, the next levels contain the\n  top-level page tables, and level 1 page tables. The bottom-level page tables (level 0)\n  contains only InvalidPTEs or PagePTEs.\n\\<close>\nvalue_type vm_level = \"if config_ARM_PA_SIZE_BITS_40 then 4 else (5::int)\"\n\ndefinition asid_pool_level :: vm_level where\n  \"asid_pool_level = maxBound\"\n\ndefinition max_pt_level :: vm_level where\n  \"max_pt_level = asid_pool_level - 1\"\n\ndefinition level_type :: \"vm_level \\<Rightarrow> pt_type\" where\n  \"level_type level \\<equiv> if level = max_pt_level then VSRootPT_T else NormalPT_T\"\n\ndeclare [[coercion_enabled]]\ndeclare [[coercion level_type]]\n\nend\n\nqualify AARCH64_A (in Arch)"}
{"title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "section": "Architecture-specific state", "subsection": "VCPU", "subsubsection": "", "code": "\nrecord arch_state =\n  arm_asid_table :: \"asid_high_index \\<rightharpoonup> obj_ref\"\n  arm_kernel_vspace :: \"AARCH64_A.arm_vspace_region_uses\"\n  arm_vmid_table :: \"AARCH64_A.vmid \\<rightharpoonup> asid\"\n  arm_next_vmid :: AARCH64_A.vmid\n  arm_us_global_vspace :: \"obj_ref\"\n  arm_current_vcpu    :: \"(obj_ref \\<times> bool) option\"\n  arm_gicvcpu_numlistregs :: nat\n\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "section": "Type declarations for invariant definitions", "subsection": "VCPU", "subsubsection": "", "code": "\ndatatype aa_type =\n    AASIDPool\n  | APageTable (a_pt_t : pt_type)\n  | AVCPU\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\" where\n  \"aa_type ao \\<equiv> case ao of\n     PageTable pt    \\<Rightarrow> APageTable (pt_type pt)\n   | DataPage dev sz \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n   | ASIDPool _      \\<Rightarrow> AASIDPool\n   | VCPU _          \\<Rightarrow> AVCPU\"\n\ndefinition badge_bits :: nat where\n  \"badge_bits \\<equiv> 64\"\n\nend"}
{"title": "./spec/abstract/AARCH64/Arch_Structs_A.thy", "section": "Arch-specific TCB", "subsection": "VCPU", "subsubsection": "", "code": "\nqualify AARCH64_A (in Arch)\n\ntext \\<open> Arch-specific part of a TCB: this must have at least a field for user context. \\<close>\nrecord arch_tcb =\n  tcb_context :: user_context\n  tcb_vcpu    :: \"obj_ref option\"\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition default_arch_tcb :: arch_tcb where\n  \"default_arch_tcb \\<equiv> \\<lparr>tcb_context = new_context, tcb_vcpu = None\\<rparr>\"\n\ntext \\<open>\n  Accessors for @{text \"tcb_context\"} inside @{text \"arch_tcb\"}. These are later used to\n  implement @{text as_user}, i.e.\\ need to be compatible with @{text user_monad}.\n\\<close>\ndefinition arch_tcb_context_set :: \"user_context \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\" where\n  \"arch_tcb_context_set uc a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := uc \\<rparr>\"\n\ndefinition arch_tcb_context_get :: \"arch_tcb \\<Rightarrow> user_context\" where\n  \"arch_tcb_context_get a_tcb \\<equiv> tcb_context a_tcb\"\n\ntext \\<open>\n  Accessors for the user register part of the @{text \"arch_tcb\"}.\n  (Because @{typ \"register \\<Rightarrow> machine_word\"} might not be equal to @{typ user_context}).\n\\<close>\ndefinition arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\" where\n  \"arch_tcb_set_registers regs a_tcb \\<equiv>\n    a_tcb \\<lparr> tcb_context := UserContext (fpu_state (tcb_context a_tcb)) regs \\<rparr>\"\n\ndefinition arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\" where\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchFault_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>Architecture-specific Fault-handling Functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\" where\n  \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData)\n   od\"\n| \"make_arch_fault_msg (VCPUFault hsr) thread = return (7, [hsr])\"\n| \"make_arch_fault_msg (VPPIEvent irq) thread = return (8, [ucast irq])\"\n| \"make_arch_fault_msg (VGICMaintenance archData) thread = do\n      msg \\<leftarrow> return $ (case archData of None \\<Rightarrow> [-1] | Some idx \\<Rightarrow> [idx]);\n      return (6, msg)\n   od\"\n\ndefinition handle_arch_fault_reply ::\n  \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\n  where\n  \"handle_arch_fault_reply vmf thread x y \\<equiv> return True\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchTcb_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \\<open>Architecture-specific TCB functions\\<close>\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\" where\n  \"sanitise_register b r v \\<equiv> case r of\n     SPSR_EL1 \\<Rightarrow> if b \\<and> v && 0x1f \\<in> {0,4,5} then v else v && 0xf0000000 || 0x140\n   | _ \\<Rightarrow> v\"\n\ndefinition arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\" where\n  \"arch_get_sanitise_register_info t \\<equiv> do\n     vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n     return (vcpu \\<noteq> None)\n   od\"\n\ndefinition arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\" where\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/ArchCSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Architecture-specific Functions for CSpace\"\n\ntheory ArchCSpace_A\nimports\n  ArchVSpace_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition cnode_guard_size_bits :: \"nat\" where\n  \"cnode_guard_size_bits \\<equiv> 6\"\n\ndefinition cnode_padding_bits :: \"nat\" where\n  \"cnode_padding_bits \\<equiv> 0\"\n\ntext \\<open>On a user request to modify a CNode capability, extract new guard bits and guard.\\<close>\ndefinition update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n  \"update_cnode_cap_data w \\<equiv>\n     let\n       guard_bits = 58;\n       guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n       guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n     in (guard_size', guard'')\"\n\ntext \\<open>For some purposes capabilities to physical objects are treated differently to others.\\<close>\ndefinition arch_is_physical :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_is_physical cap \\<equiv> case cap of ASIDControlCap \\<Rightarrow> False | _ \\<Rightarrow> True\"\n\ntext \\<open>\n  Check whether the second capability is to the same object or an object\n  contained in the region of the first one.\n\\<close>\nfun arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n  \"arch_same_region_as (FrameCap r _ sz _ _) c' =\n   (is_FrameCap c' \\<and>\n     (let\n        r' = acap_obj c';\n        sz' = acap_fsize c';\n        topA = r + (1 << pageBitsForSize sz) - 1;\n        topB = r' + (1 << pageBitsForSize sz') - 1\n      in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB))\"\n| \"arch_same_region_as (PageTableCap r pt_t _) c' = (\\<exists>r' d'. c' = PageTableCap r' pt_t d' \\<and> r = r')\"\n| \"arch_same_region_as ASIDControlCap c' = (c' = ASIDControlCap)\"\n| \"arch_same_region_as (ASIDPoolCap r _) c' = (\\<exists>r' d'. c' = ASIDPoolCap r' d' \\<and> r = r')\"\n| \"arch_same_region_as (VCPUCap r) c' = (\\<exists>r'. c' = VCPUCap r' \\<and> r = r')\"\n\n\ntext \\<open>Check whether two arch capabilities are to the same object.\\<close>\ndefinition same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n  \"same_aobject_as cap cap' \\<equiv>\n     case (cap, cap') of\n       (FrameCap ref _ sz dev _, FrameCap ref' _ sz' dev' _) \\<Rightarrow>\n         (dev, ref, sz) = (dev', ref', sz') \\<and> ref \\<le> ref + 2 ^ pageBitsForSize sz - 1\n     | _ \\<Rightarrow> arch_same_region_as cap cap'\"\n\ndeclare same_aobject_as_def[simp]\n\ndefinition arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\" where\n  \"arch_is_cap_revocable new_cap src_cap \\<equiv> False\"\n\nend\nend"}
{"title": "./spec/abstract/AARCH64/Machine_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"AARCH64 Machine Instantiation\"\n\ntheory Machine_A\nimports\n  \"ExecSpec.MachineOps\"\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  The specification is written with abstract type names for object references, user pointers,\n  word-based data, cap references, and so on. This theory provides an instantiation of these names\n  to concrete types for the AARCH64 architecture. Other architectures may have slightly different\n  instantiations.\n\\<close>\n\ntype_synonym obj_ref         = machine_word\ntype_synonym vspace_ref      = machine_word\n\ntype_synonym data            = machine_word\ntype_synonym cap_ref         = \"bool list\"\ntype_synonym length_type     = machine_word\n\ntype_synonym asid_low_len    = 9\ntype_synonym asid_low_index  = \"asid_low_len word\"\n\ntype_synonym asid_high_len   = 7\ntype_synonym asid_high_index = \"asid_high_len word\"\n\ntype_synonym asid_len        = 16\ntype_synonym asid_rep_len    = asid_len\ntype_synonym asid            = \"asid_rep_len word\"\n\ntype_synonym vmid            = \"8 word\"\n\n\ntext \\<open>\n  With the definitions above, most conversions between abstract type names boil down to just\n  the identity function, some convert from @{text word} to @{typ nat} and others between different\n  word sizes using @{const ucast}.\n\\<close>\n\ndefinition oref_to_data :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition data_to_oref :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition vref_to_data :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition data_to_vref :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition nat_to_len :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition data_to_nat :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition data_to_16 :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"\n\n\ntext \\<open>These definitions will be unfolded automatically in proofs.\\<close>\nlemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def\n\n\ntext \\<open>\n  The following definitions provide architecture-dependent sizes such as the standard page\n  size and capability size of the underlying machine.\n\\<close>\n\ndefinition slot_bits :: nat where\n  \"slot_bits \\<equiv> 5\"\n\ndefinition msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 52\"\n\ndefinition new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext (FPUState (\\<lambda>_. 0) 0 0) ((\\<lambda>_. 0) (SPSR_EL1 := pstateUser))\"\n\ntext \\<open>\n  The lowest virtual address in the kernel window. The kernel reserves the virtual addresses\n  from here up in every virtual address space.\n\\<close>\ndefinition pptr_base :: \"machine_word\" where\n  \"pptr_base = Platform.AARCH64.pptrBase\"\n\ntext \"Virtual address space available to users.\"\ndefinition user_vtop :: \"machine_word\" where\n  \"user_vtop = Platform.AARCH64.pptrUserTop\"\n\ntext \\<open>\n  Virtual address for start of kernel device mapping region in highest 1GiB of memory.\n\\<close>\ndefinition kdev_base :: \"machine_word\" where\n  \"kdev_base = Platform.AARCH64.kdevBase\"\n\ntext \\<open>\n  The virtual address the kernel code is mapped.\n\\<close>\ndefinition kernel_elf_base :: \"vspace_ref\" where\n  \"kernel_elf_base \\<equiv> Platform.AARCH64.kernelELFBase\"\n\ntext \\<open>\n  Currently an arbitrary aligned address for the idle thread.\n  Only has to exist, does not have to match up with the concrete value in C.\n\\<close>\ndefinition idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = pptr_base + 0x1000\"\n\n(* FIXME: nat_to_cref is not arch specific *)\ndefinition nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\" where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len) (to_bl (of_nat n :: machine_word))\"\n\ndefinition msg_info_register :: register where\n  \"msg_info_register \\<equiv> msgInfoRegister\"\n\ndefinition msg_registers :: \"register list\" where\n  \"msg_registers \\<equiv> msgRegisters\"\n\ndefinition cap_register :: register where\n  \"cap_register \\<equiv> capRegister\"\n\ndefinition badge_register :: register where\n  \"badge_register \\<equiv> badgeRegister\"\n\ndefinition frame_registers :: \"register list\" where\n  \"frame_registers \\<equiv> frameRegisters\"\n\ndefinition gp_registers :: \"register list\" where\n  \"gp_registers \\<equiv> gpRegisters\"\n\ndefinition exception_message :: \"register list\" where\n  \"exception_message \\<equiv> exceptionMessage\"\n\ndefinition syscall_message :: \"register list\" where\n  \"syscall_message \\<equiv> syscallMessage\"\n\ndatatype arch_fault\n  = VMFault (vm_fault_address : vspace_ref) (vm_fault_arch_data : \"machine_word list\")\n  | VCPUFault (vcpu_hsr : data)\n  | VPPIEvent (vppi_irq : irq)\n  | VGICMaintenance (vgic_maintenance_data : \"data option\")\n\n\nend\n\narch_requalify_consts (A) idle_thread_ptr\n\nend"}
{"title": "./spec/abstract/ARM_HYP/VCPU_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFunctions to access kernel memory.\n*)\n\nchapter \\<open>VCPU\\<close>\n\ntheory VCPU_A\nimports\n  Structures_A\n  TcbAcc_A\n  InvocationLabels_A\nbegin\n\ntext \\<open>\n  Some parts of some registers cannot be written by the user.\n  Bits set in the mask will be preserved (used in vcpu\\_write\\_register).\n\\<close>\nconsts\n  register_mask :: \"machine_word option\" (* no need for option? *)\n\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/ARM_HYP/VCPU_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  This is used by some decode functions. VCPU decode functions are the first that need to bounds\n  check IRQs from the user.\n  \\<close>\n\ndefinition\n  arch_check_irq :: \"data \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n  \"arch_check_irq irq \\<equiv> whenE (irq > maxIRQ) $ throwError (RangeError 0 maxIRQ)\""}
{"title": "./spec/abstract/ARM_HYP/VCPU_A.thy", "section": "", "subsection": "VCPU: Read/Write Registers", "subsubsection": "", "code": "\ndefinition decode_vcpu_set_tcb :: \"arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere \"decode_vcpu_set_tcb cap extras \\<equiv> case (cap, extras) of\n  (VCPUCap v, fs#_) \\<Rightarrow> (case fs of\n        (ThreadCap t, _) \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUSetTCB v t\n      | _ \\<Rightarrow> throwError IllegalOperation)\n |(VCPUCap v, _) \\<Rightarrow> throwError TruncatedMessage\n | _ \\<Rightarrow> throwError IllegalOperation\"\n\ntext \\<open>VCPU objects can be associated with and dissociated from TCBs.\\<close>\ntext \\<open>It is not possible to dissociate a VCPU and a TCB by using SetTCB.\nFinal outcome has to be an associated TCB and VCPU.\nThe only way to get lasting dissociation is to delete the TCB or the VCPU. See ArchVSpace\\_A.\\<close>"}
{"title": "./spec/abstract/ARM_HYP/VCPU_A.thy", "section": "", "subsection": "VCPU: Read/Write Registers", "subsubsection": "", "code": "\ndefinition\n  read_vcpu_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word,'z::state_ext) s_monad\"\nwhere\n  \"read_vcpu_register vcpu_ptr reg \\<equiv> do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (on_cur_vcpu, active) \\<leftarrow> return (case cur_vcpu of\n         Some (vcpu_ptr', a) \\<Rightarrow> (vcpu_ptr' = vcpu_ptr, a)\n       | _ \\<Rightarrow> (False, False));\n\n     if on_cur_vcpu\n       then if vcpuRegSavedWhenDisabled reg \\<and> \\<not>active\n              then vcpu_read_reg vcpu_ptr reg\n              else do_machine_op $ readVCPUHardwareReg reg\n       else vcpu_read_reg vcpu_ptr reg\n  od\"\n\ndefinition\n  write_vcpu_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"write_vcpu_register vcpu_ptr reg val \\<equiv>\n  do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu o arch_state);\n     (on_cur_vcpu, active) \\<leftarrow> return (case cur_vcpu of\n         Some (cv, a) \\<Rightarrow> (cv = vcpu_ptr, a)\n       | _ \\<Rightarrow> (False, False));\n\n     if on_cur_vcpu\n       then if vcpuRegSavedWhenDisabled reg \\<and> \\<not>active\n         then vcpu_write_reg vcpu_ptr reg val\n         else do_machine_op $ writeVCPUHardwareReg reg val\n       else vcpu_write_reg vcpu_ptr reg val\n  od\"\n\ndefinition decode_vcpu_read_register :: \"machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_vcpu_read_register args cap \\<equiv> case (args, cap) of\n      (reg#_, VCPUCap p) \\<Rightarrow> if fromEnum (maxBound::vcpureg) < unat reg\n                           then throwError (InvalidArgument 1)\n                           else returnOk $ InvokeVCPU $ VCPUReadRegister p $ toEnum (unat reg)\n    | (_, _) \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition decode_vcpu_write_register :: \"machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_vcpu_write_register args cap \\<equiv> case (args, cap) of\n    (reg#val#_, VCPUCap p) \\<Rightarrow> if fromEnum (maxBound::vcpureg) < unat reg\n                              then throwError (InvalidArgument 1)\n                              else returnOk $ InvokeVCPU $ VCPUWriteRegister p (toEnum (unat reg)) val\n  | (_, _) \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_read_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (data list, 'z::state_ext) s_monad\"\nwhere \"invoke_vcpu_read_register v reg \\<equiv> do\n   val \\<leftarrow> read_vcpu_register v reg;\n   return [val]\nod\"\n\ndefinition\n  invoke_vcpu_write_register :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"invoke_vcpu_write_register v reg val \\<equiv>  write_vcpu_register v reg val\"\n\ntext \\<open>VCPU : inject IRQ\\<close>\n\n(* This following function does not correspond to exactly what the C does, but\nit is the value that is stored inside of lr in the vgic  *)\ndefinition make_virq :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> virq\" where\n  \"make_virq grp prio irq \\<equiv>\n  let\n    groupShift = 30;\n    prioShift = 23;\n    irqPending = 1 << 28;\n    eoiirqen = 1 << 19\n  in ((grp && 1) << groupShift) || ((prio && 0x1F) << prioShift) || (irq && 0x3FF) || irqPending || eoiirqen\"\n\n\ndefinition decode_vcpu_inject_irq :: \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_vcpu_inject_irq ptrs cap \\<equiv> case (ptrs, cap) of\n  (mr0 # mr1 # _, VCPUCap p) \\<Rightarrow> doE\n     vid \\<leftarrow> returnOk (mr0 && 0xFFFF);\n     priority \\<leftarrow> returnOk ((mr0 >> 16) && 0xFF);\n     group \\<leftarrow> returnOk ((mr0 >> 24) && 0xFF);\n     index \\<leftarrow> returnOk (mr1 && 0xFF);\n     range_check vid 0 ((1 << 10) - 1);\n     range_check priority 0 31;\n     range_check group 0 1;\n     num_list_regs \\<leftarrow> liftE $ gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     whenE (index \\<ge> of_nat num_list_regs) $\n        (throwError $ RangeError 0 (of_nat num_list_regs - 1));\n\n     vcpu \\<leftarrow> liftE $ get_vcpu p;\n     vcpuLR \\<leftarrow> returnOk (vgic_lr $ vcpu_vgic $ vcpu);\n\n     whenE (vcpuLR (unat index) && vgic_irq_mask = vgic_irq_active) $ throwError DeleteFirst;\n\n     virq \\<leftarrow> returnOk (make_virq group priority vid);\n     returnOk $ InvokeVCPU $ VCPUInjectIRQ p (unat index) virq\n  odE\n| _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition\n  invoke_vcpu_inject_irq :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"invoke_vcpu_inject_irq vr index virq \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    if (cur_v \\<noteq> None \\<and> fst (the cur_v) = vr)\n    then do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat index) virq\n    else vgic_update_lr vr index virq\n   od\"\n\ntext \\<open>VCPU : acknowledge VPPI\\<close>\n\ndefinition decode_vcpu_ack_vppi ::\n  \"obj_ref list \\<Rightarrow> arch_cap \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\n  where\n  \"decode_vcpu_ack_vppi mrs cap \\<equiv>\n     case (mrs, cap)\n       of (mr0 # _, VCPUCap vcpu_ptr) \\<Rightarrow> doE\n           arch_check_irq mr0;\n           (case irq_vppi_event_index (ucast mr0)\n            of None \\<Rightarrow> throwError $ InvalidArgument 0\n             | Some vppi \\<Rightarrow> returnOk $ InvokeVCPU $ VCPUAckVPPI vcpu_ptr vppi)\n         odE\n       | _ \\<Rightarrow> throwError TruncatedMessage\"\n\ndefinition invoke_vcpu_ack_vppi :: \"obj_ref \\<Rightarrow> vppievent_irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"invoke_vcpu_ack_vppi vcpu_ptr vppi =\n     vcpu_update vcpu_ptr\n                 (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := False) \\<rparr>)\"\n\ntext \\<open>VCPU perform and decode main functions\\<close>\n\n\ndefinition\nperform_vcpu_invocation :: \"vcpu_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n\"perform_vcpu_invocation iv \\<equiv> case iv of\n    VCPUSetTCB vcpu tcb \\<Rightarrow> do associate_vcpu_tcb vcpu tcb; return [] od\n  | VCPUReadRegister vcpu reg \\<Rightarrow> invoke_vcpu_read_register vcpu reg\n  | VCPUWriteRegister vcpu reg val \\<Rightarrow> do invoke_vcpu_write_register vcpu reg val; return [] od\n  | VCPUInjectIRQ vcpu index vir \\<Rightarrow> do invoke_vcpu_inject_irq vcpu index vir; return [] od\n  | VCPUAckVPPI vcpu vppi \\<Rightarrow> do invoke_vcpu_ack_vppi vcpu vppi; return [] od\"\n\n\ndefinition decode_vcpu_invocation ::\n\"machine_word \\<Rightarrow> machine_word list \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow> (arch_invocation,'z::state_ext) se_monad\"\nwhere\n\"decode_vcpu_invocation label args cap extras \\<equiv> case cap of\nVCPUCap _ \\<Rightarrow> (case invocation_type label of\n    ArchInvocationLabel ARMVCPUSetTCB \\<Rightarrow> decode_vcpu_set_tcb cap extras\n  | ArchInvocationLabel ARMVCPUReadReg \\<Rightarrow> decode_vcpu_read_register args cap\n  | ArchInvocationLabel ARMVCPUWriteReg \\<Rightarrow> decode_vcpu_write_register args cap\n  | ArchInvocationLabel ARMVCPUInjectIRQ \\<Rightarrow> decode_vcpu_inject_irq args cap\n  | ArchInvocationLabel ARMVCPUAckVPPI \\<Rightarrow> decode_vcpu_ack_vppi args cap\n  |  _ \\<Rightarrow> throwError IllegalOperation)\n| _ \\<Rightarrow> throwError IllegalOperation\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchInterrupt_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFormalisation of interrupt handling.\n*)\n\nchapter \"Arch-specific Interrupts\"\n\ntheory ArchInterrupt_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>VGIC Maintenance\\<close>\n\ndefinition\n  virqSetEOIIRQEN :: \"virq \\<Rightarrow> 32 word \\<Rightarrow> virq\"\nwhere\n  \"virqSetEOIIRQEN virq v =\n    (if ((virq >> 28) && 3 = 3)\n    then virq\n    else (virq && ~~0x80000) || ((v << 19) && 0x80000))\"\n\ndefinition\n  vgic_maintenance :: \"(unit,'z::state_ext) s_monad\"\nwhere\n  \"vgic_maintenance = do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     case cur_vcpu\n       of Some (vcpu_ptr, True) \\<Rightarrow> do\n            eisr0 \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_eisr0;\n            eisr1 \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_eisr1;\n            flags \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_misr;\n            vgic_misr_eoi \\<leftarrow> return $ 1;\n            irq_idx \\<leftarrow> return (if eisr0 \\<noteq> 0 then word_ctz eisr0 else word_ctz eisr1 + 32);\n            gic_vcpu_num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs o arch_state);\n            fault \\<leftarrow> if flags && vgic_misr_eoi \\<noteq> 0\n                    then\n                      if eisr0 = 0 \\<and> eisr1 = 0 \\<or> irq_idx \\<ge> gic_vcpu_num_list_regs\n                      then return $ VGICMaintenance None\n                      else do\n                        virq <- do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat irq_idx);\n                        virqen <- return $ virqSetEOIIRQEN virq 0;\n                        do_machine_op $ set_gic_vcpu_ctrl_lr (of_nat irq_idx) virqen;\n                        vgic_update_lr vcpu_ptr irq_idx virqen;\n                        return $ VGICMaintenance $ Some $ of_nat irq_idx\n                      od\n                    else return $ VGICMaintenance None;\n\n            ct \\<leftarrow> gets cur_thread;\n            st \\<leftarrow> get_thread_state ct;\n            \\<comment> \\<open>until a proof links active current vcpu to runnable current thread, we need this\n               check: @{term handle_fault} needs a runnable current thread\\<close>\n            when (runnable st) $ handle_fault ct $ ArchFault fault\n          od\n        | _ \\<Rightarrow> return ()\n   od\"\n\ndefinition vppi_event :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"vppi_event irq = do\n     cur_vcpu \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     case cur_vcpu\n       of Some (vcpu_ptr, True) \\<Rightarrow> do\n            do_machine_op $ maskInterrupt True irq;\n            vppi \\<leftarrow> return $ the $ irq_vppi_event_index irq;\n            vcpu_update vcpu_ptr\n                        (\\<lambda>vcpu. vcpu\\<lparr> vcpu_vppi_masked := (vcpu_vppi_masked vcpu)(vppi := True) \\<rparr>);\n            ct \\<leftarrow> gets cur_thread;\n            st \\<leftarrow> get_thread_state ct;\n            \\<comment> \\<open>until a proof links active current vcpu to runnable current thread, we need this\n               check: @{term handle_fault} needs a runnable current thread\\<close>\n            when (runnable st) $ handle_fault ct $ ArchFault $ VPPIEvent irq\n          od\n        | _ \\<Rightarrow> return ()\n   od\"\n\ndefinition\n  handle_reserved_irq :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"handle_reserved_irq irq \\<equiv>\n     if irq = irqVGICMaintenance then vgic_maintenance\n     else if irq_vppi_event_index irq \\<noteq> None then vppi_event irq\n     else return ()\"\n\nfun arch_invoke_irq_handler :: \"irq_handler_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_invoke_irq_handler (ACKIrq irq) = (do_machine_op $ maskInterrupt False irq)\"\n| \"arch_invoke_irq_handler _ = return ()\"\n\ndefinition arch_mask_irq_signal :: \"irq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"arch_mask_irq_signal irq \\<equiv> do_machine_op $ maskInterrupt True irq\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/Arch_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nEntry point for architecture dependent definitions.\n*)\n\nchapter \"Toplevel ARM Definitions\"\n\ntheory Arch_A\nimports TcbAcc_A VCPU_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition \"page_bits \\<equiv> pageBits\"\n\nfun\n  arch_invoke_irq_control :: \"arch_irq_control_invocation \\<Rightarrow> (unit,'z::state_ext) p_monad\"\nwhere\n  \"arch_invoke_irq_control (ArchIRQControlIssue irq handler_slot control_slot trigger) = without_preemption (do\n    do_machine_op $ setIRQTrigger irq trigger;\n    set_irq_state IRQSignal (irq);\n    cap_insert (IRQHandlerCap (irq)) control_slot handler_slot\n  od)\"\n\ntext \\<open>Switch to a thread's virtual address space context. Clear the load-exclusive monitor.\\<close>\ndefinition\n  arch_switch_to_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_switch_to_thread t \\<equiv> do\n     t' \\<leftarrow> gets_the $ get_tcb t;\n     vcpu_switch $ tcb_vcpu $ tcb_arch t';\n     set_vm_root t;\n     do_machine_op $ clearExMonitor\n   od\"\n\ntext \\<open>The idle thread does not need to be handled specially on ARM.\\<close>\ndefinition\n   arch_switch_to_idle_thread :: \"(unit,'z::state_ext) s_monad\" where\n   \"arch_switch_to_idle_thread \\<equiv> do\n     vcpu_switch None;\n     t \\<leftarrow> gets idle_thread;\n     set_vm_root t\n   od\"\n\ndefinition\n  arch_activate_idle_thread :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"arch_activate_idle_thread t \\<equiv> return ()\"\n\ntext \\<open>The ASIDControl capability confers the authority to create a new ASID\npool object. This operation creates the new ASID pool, provides a capability\nto it and connects it to the global virtual ASID table.\\<close>\ndefinition\nperform_asid_control_invocation :: \"asid_control_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_control_invocation iv \\<equiv> case iv of\n  MakePool frame slot parent base \\<Rightarrow> do\n    delete_objects frame page_bits;\n    pcap \\<leftarrow> get_cap parent;\n    set_cap (max_free_index_update pcap) parent;\n    retype_region frame 1 0 (ArchObject ASIDPoolObj) False;\n    cap_insert (ArchObjectCap $ ASIDPoolCap frame base) parent slot;\n    assert (base && mask asid_low_bits = 0);\n    asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base \\<mapsto> frame));\n    modify (\\<lambda>s. s \\<lparr>arch_state := (arch_state s) \\<lparr>arm_asid_table := asid_table'\\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>The ASIDPool capability confers the authority to assign a virtual ASID\nto a page directory.\\<close>\ndefinition\nperform_asid_pool_invocation :: \"asid_pool_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_asid_pool_invocation iv \\<equiv> case iv of Assign asid pool_ptr ct_slot \\<Rightarrow>\ndo\n    pd_cap \\<leftarrow> get_cap ct_slot;\n    case pd_cap of\n      ArchObjectCap (PageDirectoryCap pd_base _) \\<Rightarrow> do\n        pool \\<leftarrow> get_asid_pool pool_ptr;\n        pool' \\<leftarrow> return (pool (ucast asid \\<mapsto> pd_base));\n        set_cap (ArchObjectCap $ PageDirectoryCap pd_base (Some asid)) ct_slot;\n        set_asid_pool pool_ptr pool'\n      od\n    | _ \\<Rightarrow> fail\nod\"\n\ntext \\<open>The PageDirectory capability confers the authority to flush cache entries\nassociated with that PD\\<close>\ndefinition\n  perform_page_directory_invocation :: \"page_directory_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"perform_page_directory_invocation iv \\<equiv> case iv of\n       PageDirectoryFlush typ start end pstart pd asid \\<Rightarrow>\n         when (start < end) $ do\n           root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n           do_machine_op $ do_flush typ start end pstart;\n           when root_switched $ do\n             tcb \\<leftarrow> gets cur_thread;\n             set_vm_root tcb\n           od\n        od\n     | PageDirectoryNothing \\<Rightarrow> return ()\"\n\ndefinition\n  pte_check_if_mapped :: \"32 word \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pte_check_if_mapped slot \\<equiv> do\n     pt \\<leftarrow> get_master_pte slot;\n     return (pt \\<noteq> InvalidPTE)\n  od\"\n\ndefinition\n  pde_check_if_mapped :: \"32 word \\<Rightarrow> (bool, 'z::state_ext) s_monad\"\nwhere\n  \"pde_check_if_mapped slot \\<equiv> do\n     pd \\<leftarrow> get_master_pde slot;\n     return (pd \\<noteq> InvalidPDE)\n  od\"\n\n\ntext \\<open>The Page capability confers the authority to map, unmap and flush the\n  memory page.\\<close>\ndefinition\nperform_page_invocation :: \"page_invocation \\<Rightarrow> (data list,'z::state_ext) s_monad\" where\n\"perform_page_invocation iv \\<equiv> case iv of\n  PageMap asid cap ct_slot entries \\<Rightarrow> do\n    set_cap cap ct_slot;\n    case entries of\n          Inl (pte, slots) \\<Rightarrow> do\n            flush \\<leftarrow> pte_check_if_mapped (hd slots);\n            store_pte (hd slots) pte;\n            mapM (swp store_pte InvalidPTE) (tl slots);\n            do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                (addrFromPPtr (hd slots));\n            if flush then (invalidate_tlb_by_asid asid) else return ()\n          od\n        | Inr (pde, slots) \\<Rightarrow> do\n            flush \\<leftarrow> pde_check_if_mapped (hd slots);\n            store_pde (hd slots) pde;\n            mapM (swp store_pde InvalidPDE) (tl slots);\n            do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                (addrFromPPtr (hd slots));\n            if flush then (invalidate_tlb_by_asid asid) else return ()\n          od;\n    return []\n  od\n| PageUnmap cap ct_slot \\<Rightarrow>\n    (case cap of\n      PageCap dev p R vp_size vp_mapped_addr \\<Rightarrow> do\n        case vp_mapped_addr of\n            Some (asid, vaddr) \\<Rightarrow> unmap_page vp_size asid vaddr p\n          | None \\<Rightarrow> return ();\n        cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n        set_cap (ArchObjectCap $ update_map_data cap None) ct_slot;\n        return []\n      od\n    | _ \\<Rightarrow> fail)\n| PageFlush typ start end pstart pd asid \\<Rightarrow> do\n    when (start < end) $ do\n      root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n      do_machine_op $ do_flush typ start end pstart;\n      when root_switched $ do\n        tcb \\<leftarrow> gets cur_thread;\n        set_vm_root tcb\n      od\n    od;\n    return []\n  od\n| PageGetAddr ptr \\<Rightarrow>\n    return [addrFromPPtr ptr]\n  \"\n\ntext \\<open>PageTable capabilities confer the authority to map and unmap page\ntables.\\<close>\ndefinition\nperform_page_table_invocation :: \"page_table_invocation \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"perform_page_table_invocation iv \\<equiv>\ncase iv of PageTableMap cap ct_slot pde pd_slot \\<Rightarrow> do\n    set_cap cap ct_slot;\n    store_pde pd_slot pde;\n    do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot)\n  od\n  | PageTableUnmap (ArchObjectCap (PageTableCap p mapped_address)) ct_slot \\<Rightarrow> do\n    case mapped_address of Some (asid, vaddr) \\<Rightarrow> do\n      unmap_page_table asid vaddr p;\n      slots \\<leftarrow> return [p, p + (1 << pte_bits) .e. p + (1 << pt_bits) - 1];\n      mapM_x (swp store_pte InvalidPTE) slots;\n      do_machine_op $ cleanCacheRange_PoU p (p + (1 << pt_bits) - 1)\n                                          (addrFromPPtr p)\n    od | None \\<Rightarrow> return ();\n    cap \\<leftarrow> liftM the_arch_cap $ get_cap ct_slot;\n    set_cap (ArchObjectCap $ update_map_data cap None) ct_slot\n  od\n  | _ \\<Rightarrow> fail\"\n\n\ntext \\<open>Top level system call despatcher for all ARM-specific system calls.\\<close>\ndefinition\n  arch_perform_invocation :: \"arch_invocation \\<Rightarrow> (data list,'z::state_ext) p_monad\" where\n  \"arch_perform_invocation i \\<equiv> liftE $\n    case i of\n          InvokePageTable oper \\<Rightarrow> do perform_page_table_invocation oper; return [] od\n        | InvokePageDirectory oper \\<Rightarrow> do perform_page_directory_invocation oper; return [] od\n        | InvokePage oper \\<Rightarrow> perform_page_invocation oper\n        | InvokeASIDControl oper \\<Rightarrow> do perform_asid_control_invocation oper; return [] od\n        | InvokeASIDPool oper \\<Rightarrow> do perform_asid_pool_invocation oper; return [] od\n        | InvokeVCPU oper \\<Rightarrow> perform_vcpu_invocation oper\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/Hypervisor_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\nchapter \"Handle Hypervisor Fault Event\"\n\ntheory Hypervisor_A\nimports Ipc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun handle_hypervisor_fault :: \"word32 \\<Rightarrow> hyp_fault_type \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n\"handle_hypervisor_fault thread (ARMVCPUFault hsr) =\n   handle_fault thread (ArchFault $ VCPUFault hsr)\"\n\n\nend\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchRetype_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nRetyping and untyped invocation\n*)\n\nchapter \"Retyping and Untyped Invocations\"\n\ntheory ArchRetype_A\nimports\n  ArchVSpaceAcc_A\n  ArchInvocation_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>This is a placeholder function. We may wish to extend the specification\n  with explicitly tagging kernel data regions in memory.\\<close>\ndefinition\n  reserve_region :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"reserve_region ptr byteLength is_kernel \\<equiv> return ()\"\n\ntext \\<open>Initialise architecture-specific objects.\\<close>\n\ndefinition vs_apiobj_size where\n  \"vs_apiobj_size ty \\<equiv>\n     case ty of\n       ArchObject SmallPageObj \\<Rightarrow> pageBitsForSize ARMSmallPage\n     | ArchObject LargePageObj \\<Rightarrow> pageBitsForSize ARMLargePage\n     | ArchObject SectionObj \\<Rightarrow> pageBitsForSize ARMSection\n     | ArchObject SuperSectionObj \\<Rightarrow> pageBitsForSize ARMSuperSection\n     | ArchObject PageTableObj \\<Rightarrow> pt_bits\n     | ArchObject PageDirectoryObj \\<Rightarrow> pd_bits\"\n\ndefinition init_arch_objects ::\n  \"apiobject_type \\<Rightarrow> bool \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> nat \\<Rightarrow> obj_ref list \\<Rightarrow> (unit,'z::state_ext) s_monad\"\n  where\n  \"init_arch_objects new_type is_device ptr num_objects obj_sz refs \\<equiv> do\n     when (new_type = ArchObject PageDirectoryObj) $ mapM_x copy_global_mappings refs;\n     if \\<not>is_device \\<and>\n        new_type \\<in> {ArchObject SmallPageObj, ArchObject LargePageObj,\n                    ArchObject SectionObj, ArchObject SuperSectionObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_RAM ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else if new_type \\<in> {ArchObject PageTableObj, ArchObject PageDirectoryObj}\n     then\n       mapM_x (\\<lambda>ref. do_machine_op $\n                       cleanCacheRange_PoU ref (ref + mask (vs_apiobj_size new_type))\n                                           (addrFromPPtr ref))\n              refs\n     else\n       return ()\n   od\"\n\ndefinition\n  empty_context :: user_context where\n  \"empty_context \\<equiv> UserContext (\\<lambda>_. 0)\"\n\ndefinition init_arch_tcb :: arch_tcb where\n  \"init_arch_tcb \\<equiv> \\<lparr> tcb_context = empty_context, tcb_vcpu = None \\<rparr>\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchIpcCancel_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch Functions for cancelling IPC.\n*)\n\nchapter \\<open>Arch IPC Cancelling\\<close>\n\ntheory ArchIpcCancel_A\nimports CSpaceAcc_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>Actions to be taken after a cap is deleted\\<close>\ndefinition\n  arch_post_cap_deletion :: \"arch_cap \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arch_post_cap_deletion _ \\<equiv> return ()\"\n\ntext \\<open>Arch specific generic object references not covered by generic references\\<close>\ndatatype arch_gen_obj_ref = unit\n\ndefinition\n  arch_gen_obj_refs :: \"arch_cap \\<Rightarrow> arch_gen_obj_ref set\"\nwhere\n  \"arch_gen_obj_refs _ = {}\"\n\ndefinition\n  arch_cap_cleanup_opt :: \"arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_cap_cleanup_opt ac \\<equiv> NullCap\"\n\nend\nend"}
{"title": "./spec/abstract/ARM_HYP/Init_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDummy initial kernel state. Real kernel boot up is more complex.\n*)\n\nchapter \"An Initial Kernel State\"\n\ntheory Init_A\nimports Retype_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This is not a specification of true kernel\n  initialisation. This theory describes a dummy initial state only, to\n  show that the invariants and refinement relation are consistent.\n\\<close>\n\n(* Moved to Deterministic_A\ndefinition\n  idle_thread_ptr :: word32 where\n  \"idle_thread_ptr = kernel_base + 0x1000\"\n*)\n\ndefinition\n  init_tcb_ptr :: word32 where\n  \"init_tcb_ptr = kernel_base + 0x2000\"\n\ndefinition\n  init_irq_node_ptr :: word32 where\n  \"init_irq_node_ptr = kernel_base + 0x8000\"\n\ndefinition\n  init_globals_frame :: word32 where\n  \"init_globals_frame = kernel_base + 0x5000\"\n\ndefinition\n  \"us_global_pd_ptr = kernel_base + 0x60000\"\n\ndefinition\n  \"init_arch_state \\<equiv> \\<lparr>\n    arm_asid_table = Map.empty,\n    arm_hwasid_table = Map.empty,\n    arm_next_asid = 0,\n    arm_asid_map = Map.empty,\n    arm_current_vcpu = None,\n    arm_gicvcpu_numlistregs = undefined,\n    arm_kernel_vspace = (\\<lambda>ref.\n      if ref \\<in> {kernel_base .. kernel_base + mask 20}\n      then ArmVSpaceKernelWindow\n      else ArmVSpaceInvalidRegion),\n    arm_us_global_pd = us_global_pd_ptr\n  \\<rparr>\"\n\ndefinition [simp]: \"us_global_pd \\<equiv> ArchObj (PageDirectory (\\<lambda>_. InvalidPDE))\"\n\ndefinition\n  \"init_kheap \\<equiv>\n  (\\<lambda>x. if \\<exists>irq :: irq. init_irq_node_ptr + (ucast irq << cte_level_bits) = x\n       then Some (CNode 0 (empty_cnode 0)) else None)\n  (idle_thread_ptr \\<mapsto> TCB \\<lparr>\n    tcb_ctable = NullCap,\n    tcb_vtable = NullCap,\n    tcb_reply = NullCap,\n    tcb_caller = NullCap,\n    tcb_ipcframe = NullCap,\n    tcb_state = IdleThreadState,\n    tcb_fault_handler = replicate word_bits False,\n    tcb_ipc_buffer = 0,\n    tcb_fault = None,\n    tcb_bound_notification = None,\n    tcb_mcpriority = minBound,\n    tcb_arch = init_arch_tcb\n  \\<rparr>,\n  us_global_pd_ptr \\<mapsto> us_global_pd)\"\n\ndefinition\n  \"init_cdt \\<equiv> Map.empty\"\n\ndefinition\n  \"init_ioc \\<equiv>\n   \\<lambda>(a,b). (\\<exists>obj. init_kheap a = Some obj \\<and>\n                  (\\<exists>cap. cap_of obj b = Some cap \\<and> cap \\<noteq> cap.NullCap))\"\n\ndefinition\n  \"init_A_st \\<equiv> \\<lparr>\n    kheap = init_kheap,\n    cdt = init_cdt,\n    is_original_cap = init_ioc,\n    cur_thread = idle_thread_ptr,\n    idle_thread = idle_thread_ptr,\n    machine_state = init_machine_state,\n    interrupt_irq_node = \\<lambda>irq. init_irq_node_ptr + (ucast irq << cte_level_bits),\n    interrupt_states = \\<lambda>_. Structures_A.IRQInactive,\n    arch_state = init_arch_state,\n    exst = ext_init\n  \\<rparr>\"\n\nend\n\n\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchVSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2022, Proofcraft Pty Ltd\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nHigher level functions for manipulating virtual address spaces\n*)\n\nchapter \"ARM VSpace Functions\"\n\ntheory ArchVSpace_A\nimports\n  Retype_A\n  ArchTcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>Save the set of entries that would be inserted into a page table or\npage directory to map various different sizes of frame at a given virtual\naddress.\\<close>\n\ndefinition largePagePTE_offsets :: \"obj_ref list\"\n  where\n  \"largePagePTE_offsets \\<equiv>\n    let pts = of_nat pte_bits\n    in [0, 2 ^ pts  .e.  (15 << pte_bits)]\"\n\ndefinition superSectionPDE_offsets :: \"obj_ref list\"\n  where\n  \"superSectionPDE_offsets \\<equiv>\n    let pts = of_nat pde_bits\n    in [0, 2 ^ pts  .e.  (15 << pde_bits)]\"\n\nfun create_mapping_entries ::\n  \"paddr \\<Rightarrow> vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vm_rights \\<Rightarrow> vm_attributes \\<Rightarrow> word32 \\<Rightarrow>\n  ((pte * word32 list) + (pde * word32 list),'z::state_ext) se_monad\"\nwhere\n  \"create_mapping_entries base vptr ARMSmallPage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (SmallPagePTE base attrib vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMLargePage vm_rights attrib pd =\n  doE\n    p \\<leftarrow> lookup_error_on_failure False $ lookup_pt_slot pd vptr;\n    returnOk $ Inl (LargePagePTE base attrib vm_rights, map (\\<lambda>x. x + p) largePagePTE_offsets)\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SectionPDE base attrib vm_rights, [p])\n  odE\"\n\n| \"create_mapping_entries base vptr ARMSuperSection vm_rights attrib pd =\n  doE\n    p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    returnOk $ Inr (SuperSectionPDE base attrib vm_rights, map (\\<lambda>x. x + p) superSectionPDE_offsets)\n  odE\"\n\ndefinition get_master_pde :: \"word32 \\<Rightarrow> (pde,'z::state_ext)s_monad\"\n  where \"get_master_pde ptr \\<equiv> do\n    pde \\<leftarrow> (get_pde (ptr && ~~ mask 7));\n    (case pde of SuperSectionPDE _ _ _ \\<Rightarrow> return pde\n    | _ \\<Rightarrow> get_pde ptr)\n  od\"\n\ndefinition get_master_pte :: \"word32 \\<Rightarrow> (pte, 'z::state_ext)s_monad\"\n  where \"get_master_pte ptr \\<equiv> do\n    pte \\<leftarrow> (get_pte (ptr && ~~ mask 7));\n    (case pte of LargePagePTE _ _ _ \\<Rightarrow> return pte\n    | _ \\<Rightarrow> get_pte ptr)\n  od\"\n\ntext \\<open>Placing an entry which maps a frame within the set of entries that map a\nlarger frame is unsafe. This function checks that given entries replace either\ninvalid entries or entries of the same granularity.\\<close>\nfun ensure_safe_mapping ::\n  \"(pte * word32 list) + (pde * word32 list) \\<Rightarrow> (unit,'z::state_ext) se_monad\"\nwhere\n\"ensure_safe_mapping (Inl (InvalidPTE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inl (SmallPagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda>slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | SmallPagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst)\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inl (LargePagePTE _ _ _, pt_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pte \\<leftarrow> liftE $ get_master_pte slot;\n        (case pte of\n              InvalidPTE \\<Rightarrow> returnOk ()\n            | LargePagePTE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pt_slots\"\n|\n\"ensure_safe_mapping (Inr (InvalidPDE, _)) = returnOk ()\"\n|\n\"ensure_safe_mapping (Inr (PageTablePDE _, _)) = fail\"\n|\n\"ensure_safe_mapping (Inr (SectionPDE _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SectionPDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"\n|\n\"ensure_safe_mapping (Inr (SuperSectionPDE _ _ _, pd_slots)) =\n    mapME_x (\\<lambda> slot. (doE\n        pde \\<leftarrow> liftE $ get_master_pde slot;\n        (case pde of\n              InvalidPDE \\<Rightarrow> returnOk ()\n            | SuperSectionPDE _ _ _ \\<Rightarrow> returnOk ()\n            | _ \\<Rightarrow> throwError DeleteFirst\n            )\n    odE)) pd_slots\"\n\ntext \\<open>Look up a thread's IPC buffer and check that the thread has the right\nauthority to read or (in the receiver case) write to it.\\<close>\ndefinition\nlookup_ipc_buffer :: \"bool \\<Rightarrow> word32 \\<Rightarrow> (word32 option,'z::state_ext) s_monad\" where\n\"lookup_ipc_buffer is_receiver thread \\<equiv> do\n    buffer_ptr \\<leftarrow> thread_get tcb_ipc_buffer thread;\n    buffer_frame_slot \\<leftarrow> return (thread, tcb_cnode_index 4);\n    buffer_cap \\<leftarrow> get_cap buffer_frame_slot;\n    (case buffer_cap of\n      ArchObjectCap (PageCap _ p R vms _) \\<Rightarrow>\n        if vm_read_write \\<subseteq> R \\<or> vm_read_only \\<subseteq> R \\<and> \\<not>is_receiver\n        then return $ Some $ p + (buffer_ptr && mask (pageBitsForSize vms))\n        else return None\n    | _ \\<Rightarrow> return None)\nod\"\n\ntext \\<open>Locate the page directory associated with a given virtual ASID.\\<close>\ndefinition\nfind_pd_for_asid :: \"asid \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"find_pd_for_asid asid \\<equiv> doE\n    assertE (asid > 0);\n    asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n    pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of asid));\n    pool \\<leftarrow> (case pool_ptr of\n               Some ptr \\<Rightarrow> liftE $ get_asid_pool ptr\n             | None \\<Rightarrow> throwError InvalidRoot);\n    pd \\<leftarrow> returnOk (pool (ucast asid));\n    (case pd of\n          Some ptr \\<Rightarrow> returnOk ptr\n        | None \\<Rightarrow> throwError InvalidRoot)\nodE\"\n\ntext \\<open>Locate the page directory and check that this process succeeds and\nreturns a pointer to a real page directory.\\<close>\ndefinition\nfind_pd_for_asid_assert :: \"asid \\<Rightarrow> (word32,'z::state_ext) s_monad\" where\n\"find_pd_for_asid_assert asid \\<equiv> do\n   pd \\<leftarrow> find_pd_for_asid asid <catch> K fail;\n   get_pde pd;\n   return pd\n od\"\n\ntext \\<open>Format a VM fault message to be passed to a thread's supervisor after\nit encounters a page fault.\\<close>\nfun\nhandle_vm_fault :: \"word32 \\<Rightarrow> vmfault_type \\<Rightarrow> (unit,'z::state_ext) f_monad\"\nwhere\n\"handle_vm_fault thread ARMDataAbort = doE\n    addr \\<leftarrow> liftE $ do_machine_op getHDFAR;\n    uaddr \\<leftarrow> liftE $ do_machine_op (addressTranslateS1 addr);\n    fault \\<leftarrow> liftE $ do_machine_op getHSR;\n    let faddr = (uaddr && complement (mask pageBits)) || (addr && mask pageBits)\n    in\n    throwError $ ArchFault $ VMFault faddr [0, fault && 0x3ffffff]\nodE\"\n|\n\"handle_vm_fault thread ARMPrefetchAbort = doE\n    pc \\<leftarrow> liftE $ as_user thread $ getRestartPC;\n    upc \\<leftarrow> liftE $ do_machine_op (addressTranslateS1 pc);\n    fault \\<leftarrow> liftE $ do_machine_op getHSR;\n    let faddr = (upc && complement (mask pageBits)) || (pc && mask pageBits)\n    in\n    throwError $ ArchFault $ VMFault faddr [1, fault && 0x3ffffff]\nodE\"\n\ntext \\<open>Load the optional hardware ASID currently associated with this virtual\nASID.\\<close>\ndefinition\nload_hw_asid :: \"asid \\<Rightarrow> (hardware_asid option,'z::state_ext) s_monad\" where\n\"load_hw_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    return $ option_map fst $ asid_map asid\nod\"\n\ntext \\<open>Associate a hardware ASID with a virtual ASID.\\<close>\ndefinition\nstore_hw_asid :: \"asid \\<Rightarrow> hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"store_hw_asid asid hw_asid \\<equiv> do\n    pd \\<leftarrow> find_pd_for_asid_assert asid;\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid \\<mapsto> (hw_asid, pd)));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>);\n    hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid \\<mapsto> asid));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>Clear all TLB mappings associated with this virtual ASID.\\<close>\ndefinition\ninvalidate_tlb_by_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_tlb_by_asid asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"\n\ntext \\<open>Flush all cache and TLB entries associated with this virtual ASID.\\<close>\ndefinition\nflush_space :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_space asid \\<equiv> do\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    do_machine_op cleanCaches_PoU;\n    (case maybe_hw_asid of\n          None \\<Rightarrow> return ()\n        | Some hw_asid \\<Rightarrow> do_machine_op $ invalidateLocalTLB_ASID hw_asid)\nod\"\n\ntext \\<open>Remove any mapping from this virtual ASID to a hardware ASID.\\<close>\ndefinition\ninvalidate_asid :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid asid \\<equiv> do\n    asid_map \\<leftarrow> gets (arm_asid_map \\<circ> arch_state);\n    asid_map' \\<leftarrow> return (asid_map (asid:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_map := asid_map' \\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>Remove any mapping from this hardware ASID to a virtual ASID.\\<close>\ndefinition\ninvalidate_hw_asid_entry :: \"hardware_asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_hw_asid_entry hw_asid \\<equiv> do\n  hw_asid_map \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n  hw_asid_map' \\<leftarrow> return (hw_asid_map (hw_asid:= None));\n  modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_hwasid_table := hw_asid_map' \\<rparr>\\<rparr>)\nod\"\n\ntext \\<open>Remove virtual to physical mappings in either direction involving this\nvirtual ASID.\\<close>\ndefinition\ninvalidate_asid_entry :: \"asid \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"invalidate_asid_entry asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  when (maybe_hw_asid \\<noteq> None) $ invalidate_hw_asid_entry (the maybe_hw_asid);\n  invalidate_asid asid\nod\"\n\ntext \\<open>Locate a hardware ASID that is not in use, if necessary by reclaiming\none from another virtual ASID in a round-robin manner.\\<close>\ndefinition\nfind_free_hw_asid :: \"(hardware_asid,'z::state_ext) s_monad\" where\n\"find_free_hw_asid \\<equiv> do\n    hw_asid_table \\<leftarrow> gets (arm_hwasid_table \\<circ> arch_state);\n    next_asid \\<leftarrow> gets (arm_next_asid \\<circ> arch_state);\n    maybe_asid \\<leftarrow> return (find (\\<lambda>a. hw_asid_table a = None)\n                    (take (length [minBound :: hardware_asid .e. maxBound])\n                        ([next_asid .e. maxBound] @ [minBound .e. next_asid])));\n    (case maybe_asid of\n       Some hw_asid \\<Rightarrow> return hw_asid\n     | None \\<Rightarrow>  do\n            invalidate_asid $ the $ hw_asid_table next_asid;\n            do_machine_op $ invalidateLocalTLB_ASID next_asid;\n            invalidate_hw_asid_entry next_asid;\n            new_next_asid \\<leftarrow> return (next_asid + 1);\n            modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_next_asid := new_next_asid \\<rparr>\\<rparr>);\n            return next_asid\n       od)\nod\"\n\ntext \\<open>Get the hardware ASID associated with a virtual ASID, assigning one if\nnone is already assigned.\\<close>\ndefinition\nget_hw_asid :: \"asid \\<Rightarrow> (hardware_asid,'z::state_ext) s_monad\" where\n\"get_hw_asid asid \\<equiv> do\n  maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n  (case maybe_hw_asid of\n    Some hw_asid \\<Rightarrow> return hw_asid\n  | None \\<Rightarrow>  do\n      new_hw_asid \\<leftarrow> find_free_hw_asid;\n      store_hw_asid asid new_hw_asid;\n      return new_hw_asid\n  od)\nod\"\n\n\nabbreviation\n  \"arm_context_switch_hwasid pd hwasid \\<equiv> writeContextIDAndPD hwasid (addrFromPPtr pd)\"\n\ndefinition\n  arm_context_switch :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (unit, 'z::state_ext) s_monad\"\nwhere\n  \"arm_context_switch pd asid \\<equiv> do\n    hwasid \\<leftarrow> get_hw_asid asid;\n    do_machine_op $ arm_context_switch_hwasid pd hwasid\n   od\"\n\ntext \\<open>Manipulation of VCPU-related state and registers\\<close>\n\ndefinition\n  vcpu_update :: \"obj_ref \\<Rightarrow> (vcpu \\<Rightarrow> vcpu) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_update vr f \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    set_vcpu vr (f vcpu)\n  od\"\n\ndefinition\n  vgic_update :: \"obj_ref \\<Rightarrow> (gic_vcpu_interface \\<Rightarrow> gic_vcpu_interface) \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vgic_update vr f \\<equiv> vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_vgic := f (vcpu_vgic vcpu) \\<rparr> )\"\n\ndefinition\n  vgic_update_lr :: \"obj_ref \\<Rightarrow> nat \\<Rightarrow> virq \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vgic_update_lr vr irq_idx virq \\<equiv>\n    vgic_update vr (\\<lambda>vgic. vgic \\<lparr> vgic_lr := (vgic_lr vgic)(irq_idx := virq) \\<rparr>)\"\n\ndefinition\n  vcpu_save_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_save_reg vr reg \\<equiv> do\n    rval \\<leftarrow> do_machine_op (readVCPUHardwareReg reg);\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := rval) \\<rparr> )\n  od\"\n\ndefinition\n  vcpu_save_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_save_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_save_reg vr reg) [from .e. to]\"\n\ndefinition\n  vcpu_restore_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_restore_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    do_machine_op (writeVCPUHardwareReg reg (vcpu_regs vcpu reg))\n  od\"\n\ndefinition\n  vcpu_restore_reg_range :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> vcpureg \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_restore_reg_range vr from to \\<equiv> mapM_x (\\<lambda>reg. vcpu_restore_reg vr reg) [from .e. to]\"\n\ndefinition\n  vcpu_read_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> (machine_word, 'z::state_ext) s_monad\"\nwhere\n  \"vcpu_read_reg vr reg \\<equiv> do\n    vcpu \\<leftarrow> get_vcpu vr;\n    return (vcpu_regs vcpu reg)\n  od\"\n\ndefinition\n  vcpu_write_reg :: \"obj_ref \\<Rightarrow> vcpureg \\<Rightarrow> machine_word \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_write_reg vr reg val \\<equiv>\n    vcpu_update vr (\\<lambda>vcpu. vcpu \\<lparr> vcpu_regs := (vcpu_regs vcpu)(reg := val) \\<rparr> )\"\n\ndefinition save_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"save_virt_timer vcpu_ptr \\<equiv> do\n     vcpu_save_reg vcpu_ptr VCPURegCNTV_CTL;\n     do_machine_op $ writeVCPUHardwareReg VCPURegCNTV_CTL 0;\n     cval \\<leftarrow> do_machine_op get_cntv_cval_64;\n     cntvoff \\<leftarrow> do_machine_op get_cntv_off_64;\n     vcpu_write_reg vcpu_ptr VCPURegCNTV_CVALhigh (ucast (cval >> 32));\n     vcpu_write_reg vcpu_ptr VCPURegCNTV_CVALlow (ucast cval);\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFFhigh (ucast (cntvoff >> 32));\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFFlow (ucast cntvoff);\n     cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu_update vcpu_ptr (\\<lambda>vcpu. vcpu\\<lparr>vcpu_vtimer := VirtTimer cntpct \\<rparr>)\n   od\"\n\ndefinition irq_vppi_event_index :: \"irq \\<rightharpoonup> vppievent_irq\" where\n  \"irq_vppi_event_index irq \\<equiv>\n     if irq = irqVTimerEvent\n     then Some VPPIEventIRQ_VTimer\n     else None\"\n\ndefinition restore_virt_timer :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"restore_virt_timer vcpu_ptr \\<equiv> do\n     cval_high \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTV_CVALhigh;\n     cval_low \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTV_CVALlow;\n     (cval :: 64 word) \\<leftarrow> return $ ((ucast cval_high) << 32) || ucast cval_low;\n     do_machine_op $ set_cntv_cval_64 cval;\n     current_cntpct \\<leftarrow> do_machine_op read_cntpct;\n     vcpu \\<leftarrow> get_vcpu vcpu_ptr;\n     last_pcount \\<leftarrow> return $ vtimerLastPCount $ vcpu_vtimer vcpu;\n     delta \\<leftarrow> return $ current_cntpct - last_pcount;\n     offs_high \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTVOFFhigh;\n     offs_low \\<leftarrow> vcpu_read_reg vcpu_ptr VCPURegCNTVOFFlow;\n     (offset :: 64 word) \\<leftarrow> return $ (((ucast offs_high) << 32) || ucast offs_low) + delta;\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFFhigh (ucast (offset >> 32));\n     vcpu_write_reg vcpu_ptr VCPURegCNTVOFFlow (ucast offset);\n     do_machine_op $ set_cntv_off_64 offset;\n     masked \\<leftarrow> return $ (vcpu_vppi_masked vcpu (the $ irq_vppi_event_index irqVTimerEvent));\n     \\<comment> \\<open>we do not know here that irqVTimerEvent is IRQReserved, therefore not IRQInactive,\n        so the only way to prove we don't unmask an inactive interrupt is to check\\<close>\n     safe_to_unmask \\<leftarrow> is_irq_active irqVTimerEvent;\n     when safe_to_unmask $ do_machine_op $ maskInterrupt masked irqVTimerEvent;\n     vcpu_restore_reg vcpu_ptr VCPURegCNTV_CTL\n   od\"\n\ntext \\<open>Turn VPCU mode off on the hardware level.\\<close>\ndefinition\n  vcpu_disable :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_disable vo \\<equiv> do\n    do_machine_op dsb;\n    (case vo of\n      Some vr \\<Rightarrow> do\n        hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n        vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n        vcpu_save_reg vr VCPURegSCTLR;\n        do_machine_op isb\n      od\n    | _ \\<Rightarrow> return ());\n    do_machine_op $ do\n        set_gic_vcpu_ctrl_hcr 0; \\<comment> \\<open>turn VGIC off\\<close>\n        isb;\n        setSCTLR sctlrDefault; \\<comment> \\<open>turn SI MMU off\\<close>\n        setHCR hcrNative;\n        isb\n      od;\n    case vo of\n      Some vr \\<Rightarrow> do\n          save_virt_timer vr;\n          do_machine_op $ maskInterrupt True irqVTimerEvent\n        od\n      | _ \\<Rightarrow> return ()\n    od\"\n\ntext \\<open>Turn VCPU mode on, on the hardware level.\\<close>\ndefinition\n  vcpu_enable :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_enable vr \\<equiv> do\n     vcpu_restore_reg vr VCPURegSCTLR;\n     vcpu \\<leftarrow> get_vcpu vr;\n     do_machine_op $ do\n        setHCR hcrVCPU;\n        isb;\n        set_gic_vcpu_ctrl_hcr (vgic_hcr $ vcpu_vgic vcpu)\n     od;\n     restore_virt_timer vr\n   od\"\n\ntext \\<open>\n  Prepare the current VCPU for removal.\n\\<close>\ndefinition\n  vcpu_invalidate_active :: \"(unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_invalidate_active \\<equiv> do\n    cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n    case cur_v of\n      Some (vr, True) \\<Rightarrow> vcpu_disable None\n    | _ \\<Rightarrow> return ();\n    modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := None \\<rparr>\\<rparr>)\n  od\"\n\ntext \\<open>VCPU objects can be associated with and dissociated from TCBs.\\<close>\n(* ARMHYP: maybe these vcpu related definitions can go into a separate file? *)\n\ntext \\<open>Removing the connection between a TCB and VCPU:\\<close>\ndefinition dissociate_vcpu_tcb :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere \"dissociate_vcpu_tcb vr t \\<equiv> do\n  t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n  v \\<leftarrow> get_vcpu vr;\n  assert (t_vcpu = Some vr \\<and> vcpu_tcb v = Some t); \\<comment> \\<open>make sure they were associated\\<close>\n  cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n  when (\\<exists>a. cur_v = Some (vr,a)) vcpu_invalidate_active;\n  arch_thread_set (\\<lambda>x. x \\<lparr> tcb_vcpu := None \\<rparr>) t;\n  set_vcpu vr (v\\<lparr> vcpu_tcb := None \\<rparr>);\n  as_user t $ do\n    cpsr \\<leftarrow> getRegister CPSR;\n    setRegister CPSR $ sanitise_register False CPSR cpsr\n  od\nod\"\n\ntext \\<open>Register + context save for VCPUs\\<close>\n\ndefinition\n  vcpu_save :: \"(obj_ref \\<times> bool) option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_save vb \\<equiv>\n     case vb\n     of Some (vr, active) \\<Rightarrow> do\n          do_machine_op dsb;\n\n          when active $ do\n            vcpu_save_reg vr VCPURegSCTLR;\n            hcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_hcr;\n            vgic_update vr (\\<lambda>vgic. vgic\\<lparr> vgic_hcr := hcr \\<rparr>);\n            save_virt_timer vr\n          od;\n\n          vmcr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_vmcr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_vmcr := vmcr\\<rparr>);\n\n          apr \\<leftarrow> do_machine_op get_gic_vcpu_ctrl_apr;\n          vgic_update vr (\\<lambda>vgic. vgic \\<lparr>vgic_apr := apr\\<rparr>);\n\n          num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n          gicIndices \\<leftarrow> return [0..<num_list_regs];\n\n          mapM (\\<lambda>vreg. do\n                    val \\<leftarrow> do_machine_op $ get_gic_vcpu_ctrl_lr (of_nat vreg);\n                    vgic_update_lr vr vreg val\n                  od)\n            gicIndices;\n\n          vcpu_save_reg_range vr VCPURegACTLR VCPURegSPSRfiq;\n          do_machine_op isb\n       od\n     | _ \\<Rightarrow> fail\"\n\ntext \\<open>Register + context restore for VCPUs\\<close>\ndefinition\n  vcpu_restore :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_restore vr \\<equiv> do\n     do_machine_op $ set_gic_vcpu_ctrl_hcr 0;  \\<comment> \\<open>turn off VGIC\\<close>\n     do_machine_op $ isb;\n     vcpu \\<leftarrow> get_vcpu vr;  \\<comment> \\<open>restore GIC VCPU control state\\<close>\n     vgic \\<leftarrow> return (vcpu_vgic vcpu);\n     num_list_regs \\<leftarrow> gets (arm_gicvcpu_numlistregs \\<circ> arch_state);\n     gicIndices \\<leftarrow> return [0..<num_list_regs];\n     do_machine_op $ do\n         set_gic_vcpu_ctrl_vmcr (vgic_vmcr vgic);\n         set_gic_vcpu_ctrl_apr (vgic_apr vgic);\n         mapM (\\<lambda>p. set_gic_vcpu_ctrl_lr (of_nat (fst p)) (snd p))\n              (map (\\<lambda>i. (i, (vgic_lr vgic) i)) gicIndices)\n     od;\n    \\<comment> \\<open>restore banked VCPU registers except SCTLR (that's in VCPUEnable)\\<close>\n     vcpu_restore_reg_range vr VCPURegACTLR VCPURegSPSRfiq;\n     vcpu_enable vr\n  od\"\n\n\ntext \\<open>\n  Make a new VCPU the active/current VCPU. If passed None, will mark the current VCPU as\n  not active, and disable VCPU mode, but leave the rest intact caching for the case where\n  we switch back to the same VCPU soon.\n\\<close>\ndefinition vcpu_switch :: \"obj_ref option \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_switch v \\<equiv> case v of\n   None \\<Rightarrow> do\n     cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (case cur_v of\n        None \\<Rightarrow> return () \\<comment> \\<open>both null, current cannot be active\\<close>\n      | Some (vr, active) \\<Rightarrow> do \\<comment> \\<open>switch to thread without vcpu\\<close>\n          when active $ do  \\<comment> \\<open> save state if not saved already\\<close>\n            vcpu_disable (Some vr);\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (vr, False) \\<rparr>\\<rparr>)\n          od;\n          return ()\n        od)\n     od\n | Some new \\<Rightarrow> do\n     cur_v \\<leftarrow> gets (arm_current_vcpu \\<circ> arch_state);\n     (case cur_v of\n        None \\<Rightarrow> do \\<comment> \\<open>switch to the new vcpu with no current one\\<close>\n          vcpu_restore new;\n          modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n        od\n      | Some (vr, active) \\<Rightarrow> \\<comment> \\<open>switch from an existing vcpu\\<close>\n          (if vr \\<noteq> new\n          then do \\<comment> \\<open>different vcpu\\<close>\n            vcpu_save cur_v;\n            vcpu_restore new;\n            modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n          od\n          else \\<comment> \\<open>same vcpu\\<close>\n            when (\\<not> active) $ do\n              do_machine_op isb;\n              vcpu_enable new;\n              modify (\\<lambda>s. s\\<lparr> arch_state := (arch_state s)\\<lparr> arm_current_vcpu := Some (new, True) \\<rparr>\\<rparr>)\n            od))\n   od\"\n\ntext \\<open>Associating a TCB and VCPU, removing any potentially existing associations:\\<close>\ndefinition associate_vcpu_tcb :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"associate_vcpu_tcb vr t \\<equiv> do\n    t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n    case t_vcpu of Some p \\<Rightarrow> dissociate_vcpu_tcb p t\n                 | _ \\<Rightarrow> return ();\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of Some p \\<Rightarrow> dissociate_vcpu_tcb vr p\n                     | _ \\<Rightarrow> return ();\n    arch_thread_set (\\<lambda>x. x \\<lparr> tcb_vcpu := Some vr \\<rparr>) t;\n    set_vcpu vr (v\\<lparr> vcpu_tcb := Some t \\<rparr>);\n    ct \\<leftarrow> gets cur_thread;\n    when (t = ct) $ vcpu_switch (Some vr)\n  od\"\n\ntext \\<open>\n  Prepare a given VCPU for removal: dissociate it, and clean up current VCPU state\n  if necessary.\n\\<close>\ndefinition vcpu_finalise :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"vcpu_finalise vr \\<equiv> do\n    v \\<leftarrow> get_vcpu vr;\n    case vcpu_tcb v of\n      Some t \\<Rightarrow> dissociate_vcpu_tcb vr t\n    | None \\<Rightarrow> return ()\n   od\"\n\n(* end of vcpu related definitions *)\n\ntext \\<open>Switch into the address space of a given thread or the global address\nspace if none is correctly configured.\\<close>\ndefinition\n  set_vm_root :: \"word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"set_vm_root tcb \\<equiv> do\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    (case thread_root of\n       ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow> doE\n           pd' \\<leftarrow> find_pd_for_asid asid;\n           whenE (pd \\<noteq> pd') $ throwError InvalidRoot;\n           liftE $ arm_context_switch pd asid\n       odE\n     | _ \\<Rightarrow> throwError InvalidRoot) <catch>\n    (\\<lambda>_. do\n       global_us_pd \\<leftarrow> gets (arm_us_global_pd o arch_state);\n       do_machine_op $ set_current_pd $ addrFromKPPtr global_us_pd\n    od)\nod\"\n\ntext \\<open>Before deleting an ASID pool object we must deactivate all page\ndirectories that are installed in it.\\<close>\ndefinition\ndelete_asid_pool :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid_pool base ptr \\<equiv> do\n  assert (base && mask asid_low_bits = 0);\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  when (asid_table (asid_high_bits_of base) = Some ptr) $ do\n    pool \\<leftarrow> get_asid_pool ptr;\n    mapM (\\<lambda>offset. (when (pool (ucast offset) \\<noteq> None) $ do\n                          flush_space $ base + offset;\n                          invalidate_asid_entry $ base + offset\n                    od)) [0  .e.  (1 << asid_low_bits) - 1];\n    asid_table' \\<leftarrow> return (asid_table (asid_high_bits_of base:= None));\n    modify (\\<lambda>s. s \\<lparr> arch_state := (arch_state s) \\<lparr> arm_asid_table := asid_table' \\<rparr>\\<rparr>);\n    tcb \\<leftarrow> gets cur_thread;\n    set_vm_root tcb\n  od\nod\"\n\ntext \\<open>When deleting a page directory from an ASID pool we must deactivate\nit.\\<close>\ndefinition\ndelete_asid :: \"asid \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"delete_asid asid pd \\<equiv> do\n  asid_table \\<leftarrow> gets (arm_asid_table \\<circ> arch_state);\n  (case asid_table (asid_high_bits_of asid) of\n    None \\<Rightarrow> return ()\n  | Some pool_ptr \\<Rightarrow>  do\n     pool \\<leftarrow> get_asid_pool pool_ptr;\n     when (pool (ucast asid) = Some pd) $ do\n                flush_space asid;\n                invalidate_asid_entry asid;\n                pool' \\<leftarrow> return (pool (ucast asid := None));\n                set_asid_pool pool_ptr pool';\n                tcb \\<leftarrow> gets cur_thread;\n                set_vm_root tcb\n            od\n    od)\nod\"\n\n\ntext \\<open>Switch to a particular address space in order to perform a flush\noperation.\\<close>\ndefinition\nset_vm_root_for_flush :: \"word32 \\<Rightarrow> asid \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"set_vm_root_for_flush pd asid \\<equiv> do\n    tcb \\<leftarrow> gets cur_thread;\n    thread_root_slot \\<leftarrow> return (tcb, tcb_cnode_index 1);\n    thread_root \\<leftarrow> get_cap thread_root_slot;\n    not_is_pd \\<leftarrow> (case thread_root of\n                    ArchObjectCap (PageDirectoryCap cur_pd (Some _)) \\<Rightarrow> return (cur_pd \\<noteq> pd)\n                  | _ \\<Rightarrow> return True);\n    (if not_is_pd then do\n        arm_context_switch pd asid;\n        return True\n    od\n    else return False)\nod\"\n\ndefinition\ndo_flush :: \"flush_type \\<Rightarrow> vspace_ref \\<Rightarrow> vspace_ref \\<Rightarrow> paddr \\<Rightarrow> unit machine_monad\" where\n\"do_flush flush_type vstart vend pstart \\<equiv>\n    let vstart' = ptrFromPAddr pstart;\n        vend'  = vstart' + (vend - vstart)\n    in\n    (case flush_type of\n       Clean \\<Rightarrow> cleanCacheRange_RAM vstart' vend' pstart\n     | Invalidate \\<Rightarrow> invalidateCacheRange_RAM vstart' vend' pstart\n     | CleanInvalidate \\<Rightarrow> cleanInvalidateCacheRange_RAM vstart' vend' pstart\n     | Unify \\<Rightarrow> do\n         cleanCacheRange_PoU vstart' vend' pstart;\n         dsb;\n         invalidateCacheRange_I vstart' vend' pstart;\n         branchFlushRange vstart' vend' pstart;\n         isb\n     od)\"\n\ntext \\<open>Flush mappings associated with a page table.\\<close>\ndefinition\nflush_table :: \"word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_table pd asid vptr pt \\<equiv> do\n    assert (vptr && mask (pageBitsForSize ARMSection) = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_ASID hw_asid;\n      when root_switched $ do\n        tcb \\<leftarrow> gets cur_thread;\n        set_vm_root tcb\n      od\n    od\nod\"\n\ntext \\<open>Flush mappings associated with a given page.\\<close>\ndefinition\nflush_page :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"flush_page page_size pd asid vptr\\<equiv> do\n    assert (vptr && mask pageBits = 0);\n    root_switched \\<leftarrow> set_vm_root_for_flush pd asid;\n    maybe_hw_asid \\<leftarrow> load_hw_asid asid;\n    when (maybe_hw_asid \\<noteq> None) $ do\n      hw_asid \\<leftarrow> return (the maybe_hw_asid);\n      do_machine_op $ invalidateLocalTLB_VAASID (vptr || ucast hw_asid);\n      when root_switched $ do\n          tcb \\<leftarrow> gets cur_thread;\n          set_vm_root tcb\n      od\n   od\nod\"\n\ntext \\<open>Return the optional page directory a page table is mapped in.\\<close>\ndefinition\npage_table_mapped :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (obj_ref option,'z::state_ext) s_monad\" where\n\"page_table_mapped asid vaddr pt \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    pd_slot \\<leftarrow> returnOk $ lookup_pd_slot pd vaddr;\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    case pde of\n      PageTablePDE addr \\<Rightarrow> returnOk $\n             if addrFromPPtr pt = addr then Some pd else None\n    | _ \\<Rightarrow> returnOk None\nodE <catch> (K $ return None)\"\n\ntext \\<open>Unmap a page table from its page directory.\\<close>\ndefinition\nunmap_page_table :: \"asid \\<Rightarrow> vspace_ref \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page_table asid vaddr pt \\<equiv> do\n    pdOpt \\<leftarrow> page_table_mapped asid vaddr pt;\n    case pdOpt of\n      None \\<Rightarrow> return ()\n    | Some pd \\<Rightarrow> do\n        pd_slot \\<leftarrow> return $ lookup_pd_slot pd vaddr;\n        store_pde pd_slot InvalidPDE;\n        do_machine_op $ cleanByVA_PoU pd_slot (addrFromPPtr pd_slot);\n        flush_table pd asid vaddr pt\n    od\nod\"\n\ntext \\<open>Check that a given frame is mapped by a given mapping entry.\\<close>\ndefinition\ncheck_mapping_pptr :: \"obj_ref \\<Rightarrow> vmpage_size \\<Rightarrow> (obj_ref + obj_ref) \\<Rightarrow> (bool,'z::state_ext) s_monad\" where\n\"check_mapping_pptr pptr pgsz tablePtr \\<equiv> case tablePtr of\n   Inl ptePtr \\<Rightarrow> do\n     pte \\<leftarrow> get_pte ptePtr;\n     return $ case pte of\n       SmallPagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSmallPage\n     | LargePagePTE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMLargePage\n     | _ \\<Rightarrow> False\n   od\n | Inr pdePtr \\<Rightarrow> do\n     pde \\<leftarrow> get_pde pdePtr;\n     return $ case pde of\n       SectionPDE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSection\n     | SuperSectionPDE x _ _ \\<Rightarrow> x = addrFromPPtr pptr \\<and> pgsz = ARMSuperSection\n     | _ \\<Rightarrow> False\n   od\"\n\n\ndefinition\n  \"last_byte_pte x \\<equiv> x + ((1 << pte_bits) - 1)\"\n\ndefinition\n  \"last_byte_pde x \\<equiv> x + ((1 << pde_bits) - 1)\"\n\ntext \\<open>Unmap a mapped page if the given mapping details are still current.\\<close>\ndefinition\nunmap_page :: \"vmpage_size \\<Rightarrow> asid \\<Rightarrow> vspace_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"unmap_page pgsz asid vptr pptr \\<equiv> doE\n    pd \\<leftarrow> find_pd_for_asid asid;\n    (case pgsz of\n          ARMSmallPage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                store_pte p InvalidPTE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMLargePage \\<Rightarrow> doE\n            p \\<leftarrow> lookup_pt_slot pd vptr;\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inl p);\n            liftE $ do\n                assert $ p && mask 7 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) largePagePTE_offsets);\n                mapM (swp store_pte InvalidPTE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pte (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE\n        | ARMSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                store_pde p InvalidPDE;\n                do_machine_op $ cleanByVA_PoU p (addrFromPPtr p)\n            od\n          odE\n        | ARMSuperSection \\<Rightarrow> doE\n            p \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n            throw_on_false undefined $\n                check_mapping_pptr pptr pgsz (Inr p);\n            liftE $ do\n                assert $ p && mask 7 = 0;\n                slots \\<leftarrow> return (map (\\<lambda>x. x + p) superSectionPDE_offsets);\n                mapM (swp store_pde InvalidPDE) slots;\n                do_machine_op $ cleanCacheRange_PoU (hd slots) (last_byte_pde (last slots))\n                                                    (addrFromPPtr (hd slots))\n            od\n          odE);\n    liftE $ flush_page pgsz pd asid vptr\nodE <catch> (K $ return ())\"\n\n\ntext \\<open>PageDirectory and PageTable capabilities cannot be copied until they\nhave a virtual ASID and location assigned. This is because page directories\ncannot have multiple current virtual ASIDs and page tables cannot be shared\nbetween address spaces or virtual locations.\\<close>\ndefinition\n  arch_derive_cap :: \"arch_cap \\<Rightarrow> (cap,'z::state_ext) se_monad\"\nwhere\n  \"arch_derive_cap c \\<equiv> case c of\n     PageTableCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageTableCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageDirectoryCap _ (Some x) \\<Rightarrow> returnOk (ArchObjectCap c)\n   | PageDirectoryCap _ None \\<Rightarrow> throwError IllegalOperation\n   | PageCap dev r R pgs x \\<Rightarrow> returnOk (ArchObjectCap (PageCap dev r R pgs None))\n   | ASIDControlCap \\<Rightarrow> returnOk (ArchObjectCap c)\n   | ASIDPoolCap _ _ \\<Rightarrow> returnOk (ArchObjectCap c)\n   | VCPUCap _ \\<Rightarrow> returnOk (ArchObjectCap c)\"\n\ntext \\<open>No user-modifiable data is stored in ARM-specific capabilities.\\<close>\ndefinition\n  arch_update_cap_data :: \"bool \\<Rightarrow> data \\<Rightarrow> arch_cap \\<Rightarrow> cap\"\nwhere\n  \"arch_update_cap_data preserve data c \\<equiv> ArchObjectCap c\"\n\n\ntext \\<open>Actions that must be taken on finalisation of AR\\_MHYP-specific\ncapabilities.\\<close>\ndefinition\n  arch_finalise_cap :: \"arch_cap \\<Rightarrow> bool \\<Rightarrow> (cap \\<times> cap,'z::state_ext) s_monad\"\nwhere\n  \"arch_finalise_cap c x \\<equiv> case (c, x) of\n    (ASIDPoolCap ptr b, True) \\<Rightarrow>  do\n    delete_asid_pool b ptr;\n    return (NullCap, NullCap)\n    od\n  | (PageDirectoryCap ptr (Some a), True) \\<Rightarrow> do\n    delete_asid a ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageTableCap ptr (Some (a, v)), True) \\<Rightarrow> do\n    unmap_page_table a v ptr;\n    return (NullCap, NullCap)\n  od\n  | (PageCap _ ptr _ s (Some (a, v)), _) \\<Rightarrow> do\n     unmap_page s a v ptr;\n     return (NullCap, NullCap)\n  od\n  | (VCPUCap vcpu_ref, True) \\<Rightarrow> do\n     vcpu_finalise vcpu_ref;\n     return (NullCap, NullCap)\n  od\n  | _ \\<Rightarrow> return (NullCap, NullCap)\"\n\ndefinition\n  prepare_thread_delete :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"prepare_thread_delete p \\<equiv> do\n   t_vcpu \\<leftarrow> arch_thread_get tcb_vcpu p;\n   case t_vcpu of\n   Some v \\<Rightarrow> dissociate_vcpu_tcb v p\n | None \\<Rightarrow> return ()\n od\"\n\n\ntext \\<open>A thread's virtual address space capability must be to a page directory\nto be valid on the ARM architecture.\\<close>\ndefinition\n  is_valid_vtable_root :: \"cap \\<Rightarrow> bool\" where\n  \"is_valid_vtable_root c \\<equiv> \\<exists>r a. c = ArchObjectCap (PageDirectoryCap r (Some a))\"\n\ndefinition\ncheck_valid_ipc_buffer :: \"vspace_ref \\<Rightarrow> cap \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n\"check_valid_ipc_buffer vptr c \\<equiv> case c of\n  (ArchObjectCap (PageCap False _ _ _ _)) \\<Rightarrow> doE\n    whenE (\\<not> is_aligned vptr msg_align_bits) $ throwError AlignmentError;\n    returnOk ()\n  odE\n| _ \\<Rightarrow> throwError IllegalOperation\"\n\ntext \\<open>Decode a user argument word describing the kind of VM attributes a\nmapping is to have.\\<close>\ndefinition\nattribs_from_word :: \"word32 \\<Rightarrow> vm_attributes\" where\n\"attribs_from_word w \\<equiv>\n  let V = (if w !!0 then {PageCacheable} else {})\n  in if w!!2 then insert XNever V else V\"\n\ntext \\<open>Update the mapping data saved in a page or page table capability.\\<close>\ndefinition\n  update_map_data :: \"arch_cap \\<Rightarrow> (word32 \\<times> word32) option \\<Rightarrow> arch_cap\" where\n  \"update_map_data cap m \\<equiv> case cap of PageCap dev p R sz _ \\<Rightarrow> PageCap dev p R sz m\n                                     | PageTableCap p _ \\<Rightarrow> PageTableCap p m\"\n\ntext \\<open>Get information about the frame of a given virtual address\\<close>\ndefinition\n  resolve_vaddr :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> ((vmpage_size \\<times> obj_ref) option, 'z::state_ext) s_monad\"\nwhere\n  \"resolve_vaddr pd vaddr \\<equiv> do\n     pd_slot \\<leftarrow> return $ lookup_pd_slot pd vaddr;\n     pde \\<leftarrow> get_master_pde pd_slot;\n     case pde of\n         SectionPDE f _ _ \\<Rightarrow> return $ Some (ARMSection, f)\n       | SuperSectionPDE f _ _ \\<Rightarrow> return $ Some (ARMSuperSection, f)\n       | PageTablePDE t \\<Rightarrow> (do\n           pt \\<leftarrow> return $ ptrFromPAddr t;\n           pte_slot \\<leftarrow> return $ lookup_pt_slot_no_fail pt vaddr;\n           pte \\<leftarrow> get_master_pte pte_slot;\n           case pte of\n               LargePagePTE f _ _ \\<Rightarrow> return $ Some (ARMLargePage, f)\n             | SmallPagePTE f _ _ \\<Rightarrow> return $ Some (ARMSmallPage, f)\n             | _ \\<Rightarrow> return None\n         od)\n       | _ \\<Rightarrow> return None\n   od\"\n\ntext \\<open>\n  A pointer is inside a user frame if its top bits point to a @{text DataPage}.\n\\<close>\ndefinition\n  in_user_frame :: \"word32 \\<Rightarrow> 'z::state_ext state \\<Rightarrow> bool\" where\n  \"in_user_frame p s \\<equiv>\n   \\<exists>sz. kheap s (p && ~~ mask (pageBitsForSize sz)) =\n        Some (ArchObj (DataPage False sz))\"\n\ntext \\<open>Make numeric value of @{const msg_align_bits} visible.\\<close>\nlemmas msg_align_bits = msg_align_bits'[unfolded word_size_bits_def, simplified]\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchVSpaceAcc_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nAccessor functions for architecture specific parts of the specification.\n*)\n\nchapter \"Accessing the ARM VSpace\"\n\ntheory ArchVSpaceAcc_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  This part of the specification is fairly concrete as the machine architecture\n  is visible to the user in seL4 and therefore needs to be described.\n  The abstraction compared to the implementation is in the data types for\n  kernel objects. The interface which is rich in machine details remains the same.\n\\<close>"}
{"title": "./spec/abstract/ARM_HYP/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The high bits of a virtual ASID.\\<close>\ndefinition\n  asid_high_bits_of :: \"asid \\<Rightarrow> 7 word\" where\n  \"asid_high_bits_of asid \\<equiv> ucast (asid >> asid_low_bits)\""}
{"title": "./spec/abstract/ARM_HYP/ArchVSpaceAcc_A.thy", "section": "Kernel Heap Accessors", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>Manipulate ASID pools, page directories and page tables in the kernel\nheap.\\<close>\n(* declared in Arch as workaround for VER-1099 *)\nlocale_abbrev aobjs_of :: \"'z::state_ext state \\<Rightarrow> obj_ref \\<rightharpoonup> arch_kernel_obj\"\n  where\n  \"aobjs_of \\<equiv> \\<lambda>s. kheap s |> aobj_of\"\n\ndefinition\n  get_asid_pool :: \"obj_ref \\<Rightarrow> (10 word \\<rightharpoonup> obj_ref,'z::state_ext) s_monad\" where\n  \"get_asid_pool ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (ASIDPool pool) \\<Rightarrow> return pool\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_asid_pool :: \"obj_ref \\<Rightarrow> (10 word \\<rightharpoonup> obj_ref) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n \"set_asid_pool ptr pool \\<equiv> set_object ptr (ArchObj (arch_kernel_obj.ASIDPool pool))\"\n\ndefinition\n  get_vcpu :: \"obj_ref \\<Rightarrow> (vcpu,'z::state_ext) s_monad\" where\n  \"get_vcpu ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (VCPU v) \\<Rightarrow> return v\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_vcpu :: \"obj_ref \\<Rightarrow> vcpu \\<Rightarrow> (unit,'z::state_ext) s_monad\"\nwhere\n  \"set_vcpu ptr vcpu \\<equiv> set_object ptr (ArchObj (VCPU vcpu))\"\n\ndefinition\n  get_pd :: \"obj_ref \\<Rightarrow> (11 word \\<Rightarrow> pde,'z::state_ext) s_monad\" where\n  \"get_pd ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageDirectory pd) \\<Rightarrow> return pd\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pd :: \"obj_ref \\<Rightarrow> (11 word \\<Rightarrow> pde) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pd ptr pd \\<equiv> set_object ptr (ArchObj (PageDirectory pd))\"\n\ndefinition\n  set_current_pd :: \"paddr \\<Rightarrow> unit machine_monad\"\nwhere\n  \"set_current_pd pd \\<equiv> setCurrentPDPL2 pd\"\n\ntext \\<open>The following function takes a pointer to a PDE in kernel memory\n  and returns the actual PDE.\\<close>\ndefinition\n  get_pde :: \"obj_ref \\<Rightarrow> (pde,'z::state_ext) s_monad\" where\n  \"get_pde ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pd_bits);\n     offset \\<leftarrow> return ((ptr && mask pd_bits) >> pde_bits);\n     pd \\<leftarrow> get_pd base;\n     return $ pd (ucast offset)\n   od\"\n\ndefinition\n  store_pde :: \"obj_ref \\<Rightarrow> pde \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pde p pde \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pd_bits);\n    offset \\<leftarrow> return ((p && mask pd_bits) >> pde_bits);\n    pd \\<leftarrow> get_pd base;\n    pd' \\<leftarrow> return $ pd (ucast offset := pde);\n    set_pd base pd'\n  od\"\n\n\ndefinition\n  get_pt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pte,'z::state_ext) s_monad\" where\n  \"get_pt ptr \\<equiv> do\n     kobj \\<leftarrow> get_object ptr;\n     (case kobj of ArchObj (PageTable pt) \\<Rightarrow> return pt\n                 | _ \\<Rightarrow> fail)\n   od\"\n\ndefinition\n  set_pt :: \"obj_ref \\<Rightarrow> (9 word \\<Rightarrow> pte) \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"set_pt ptr pt \\<equiv> set_object ptr (ArchObj (PageTable pt))\"\n\ntext \\<open>The following function takes a pointer to a PTE in kernel memory\n  and returns the actual PTE.\\<close>\ndefinition\n  get_pte :: \"obj_ref \\<Rightarrow> (pte,'z::state_ext) s_monad\" where\n  \"get_pte ptr \\<equiv> do\n     base \\<leftarrow> return (ptr && ~~mask pt_bits);\n     offset \\<leftarrow> return ((ptr && mask pt_bits) >> pte_bits);\n     pt \\<leftarrow> get_pt base;\n     return $ pt (ucast offset)\n   od\"\n\ndefinition\n  store_pte :: \"obj_ref \\<Rightarrow> pte \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n  \"store_pte p pte \\<equiv> do\n    base \\<leftarrow> return (p && ~~mask pt_bits);\n    offset \\<leftarrow> return ((p && mask pt_bits) >> pte_bits);\n    pt \\<leftarrow> get_pt base;\n    pt' \\<leftarrow> return $ pt (ucast offset := pte);\n    set_pt base pt'\n  od\""}
{"title": "./spec/abstract/ARM_HYP/ArchVSpaceAcc_A.thy", "section": "Basic Operations", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The kernel window is mapped into every virtual address space from the\n@{term kernel_base} pointer upwards. This function copies the mappings which\ncreate the kernel window into a new page directory object.\\<close>\ndefinition\ncopy_global_mappings :: \"obj_ref \\<Rightarrow> (unit,'z::state_ext) s_monad\" where\n\"copy_global_mappings new_pd \\<equiv> return ()\"\n(*do\n    global_pt \\<leftarrow> gets (arm_global_pt \\<circ> arch_state);\n    pd_size \\<leftarrow> return (1 << pd_bits);\n    offset \\<leftarrow> return (pd_size - (1 << pde_bits));\n    store_pde (new_pd + offset) (PageTablePDE (addrFromPPtr global_pt))\nod*)\n\n\ntext \\<open>Walk the page directories and tables in software.\\<close>\n\ntext \\<open>The following function takes a page-directory reference as well as\n  a virtual address and then computes a pointer to the PDE in kernel memory\\<close>\ndefinition\nlookup_pd_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> word32\" where\n\"lookup_pd_slot pd vptr \\<equiv>\n    let pd_index = vptr >> (pageBits + pt_bits - pte_bits) \\<comment> \\<open>ARMHYP\\<close>\n    in pd + (pd_index << pde_bits)\"\n\ntext \\<open>The following function takes a page-directory reference as well as\n  a virtual address and then computes a pointer to the PTE in kernel memory.\n  Note that the function fails if the virtual address is mapped on a section or\n  super section.\\<close>\ndefinition\nlookup_pt_slot :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> (word32,'z::state_ext) lf_monad\" where\n\"lookup_pt_slot pd vptr \\<equiv> doE\n    pd_slot \\<leftarrow> returnOk (lookup_pd_slot pd vptr);\n    pde \\<leftarrow> liftE $ get_pde pd_slot;\n    (case pde of\n          PageTablePDE ptab \\<Rightarrow>   (doE\n            pt \\<leftarrow> returnOk (ptrFromPAddr ptab);\n            pt_index \\<leftarrow> returnOk ((vptr >> pageBits) && mask (pt_bits - pte_bits));\n            pt_slot \\<leftarrow> returnOk (pt + (pt_index << pte_bits));\n            returnOk pt_slot\n          odE)\n        | _ \\<Rightarrow> throwError $ MissingCapability 21)\nodE\"\n\n\ntext \\<open>A non-failing version of @{const lookup_pt_slot} when the pd is already known\\<close>\ndefinition\n  lookup_pt_slot_no_fail :: \"word32 \\<Rightarrow> vspace_ref \\<Rightarrow> word32\"\nwhere\n  \"lookup_pt_slot_no_fail pt vptr \\<equiv>\n     let pt_index = ((vptr >> pageBits) && mask (pt_bits - pte_bits))\n     in pt + (pt_index << pte_bits)\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchDecode_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nDecoding system calls\n*)\n\nchapter \"Decoding Architecture-specific System Calls\"\n\ntheory ArchDecode_A\nimports\n  Interrupt_A\nbegin\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/ARM_HYP/ArchDecode_A.thy", "section": "Architecture calls", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition ensures that the given pointer is aligned\nto the given page size.\\<close>\n\ndefinition\n  check_vp_alignment :: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> (unit,'z::state_ext) se_monad\" where\n  \"check_vp_alignment sz vptr \\<equiv>\n     unlessE (is_aligned vptr (pageBitsForSize sz)) $\n       throwError AlignmentError\"\n\ntext \\<open>This definition converts a user-supplied argument into an\ninvocation label, used to determine the method to invoke.\n\\<close>\n\ndefinition\n  label_to_flush_type :: \"invocation_label \\<Rightarrow> flush_type\"\nwhere\n  \"label_to_flush_type label \\<equiv> case label of\n       ArchInvocationLabel ARMPDClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPageClean_Data \\<Rightarrow> Clean\n     | ArchInvocationLabel ARMPDInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPageInvalidate_Data \\<Rightarrow> Invalidate\n     | ArchInvocationLabel ARMPDCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPageCleanInvalidate_Data \\<Rightarrow> CleanInvalidate\n     | ArchInvocationLabel ARMPDUnify_Instruction \\<Rightarrow> Unify\n     | ArchInvocationLabel ARMPageUnify_Instruction \\<Rightarrow> Unify\""}
{"title": "./spec/abstract/ARM_HYP/ArchDecode_A.thy", "section": "Architecture calls", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This definition decodes architecture-specific invocations.\n\\<close>\n\ndefinition\n  page_base :: \"vspace_ref \\<Rightarrow> vmpage_size \\<Rightarrow> vspace_ref\"\nwhere\n  \"page_base vaddr vmsize \\<equiv> vaddr && ~~ mask (pageBitsForSize vmsize)\"\n\n\n(* decode mmu invocations *)\n\ndefinition\n  isIOSpaceFrame :: \"arch_cap \\<Rightarrow> bool\"\n  where \"isIOSpaceFrame c \\<equiv> False\"\n\ndefinition\n  decode_mmu_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"decode_mmu_invocation label args x_slot cte cap extra_caps \\<equiv>\ncase cap of\n\n  PageDirectoryCap _ _ \\<Rightarrow>\n    if isPDFlushLabel (invocation_type label) then\n    if length args > 1\n    then let start = args ! 0;\n             end = args ! 1\n    in doE\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            whenE (start \\<ge> kernel_base \\<or> end > kernel_base) $ throwError IllegalOperation;\n            (pd,asid) \\<leftarrow> (case cap of\n                    PageDirectoryCap pd (Some asid) \\<Rightarrow> returnOk (pd,asid)\n                  | _ \\<Rightarrow> throwError $ InvalidCapability 0);\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 0;\n            frame_info \\<leftarrow> liftE $ resolve_vaddr pd start;\n            case frame_info of\n                None \\<Rightarrow> returnOk $ InvokePageDirectory PageDirectoryNothing\n              | Some (frame_size, frame_base) \\<Rightarrow>\n                    let base_start = page_base start frame_size;\n                        base_end = page_base (end - 1) frame_size;\n                        offset = start && mask (pageBitsForSize frame_size);\n                        pstart = frame_base + offset\n                    in doE\n                        whenE (base_start \\<noteq> base_end) $ throwError $\n                            RangeError start (base_start + mask (pageBitsForSize frame_size));\n                        returnOk $ InvokePageDirectory $\n                            PageDirectoryFlush (label_to_flush_type (invocation_type label))\n                            start (end - 1) pstart pd asid\n                    odE\n    odE\n    else throwError TruncatedMessage\n    else throwError IllegalOperation\n\n| PageTableCap p mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageTableMap then\n    if length args > 1 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             pd_cap = fst (extra_caps ! 0)\n    in doE\n            whenE (mapped_address \\<noteq> None) $ throwError $ InvalidCapability 0;\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            whenE (vaddr \\<ge> kernel_base) $ throwError $ InvalidArgument 0;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            pd_index \\<leftarrow> returnOk (shiftr vaddr (pageBits + pt_bits - pte_bits));\n            vaddr' \\<leftarrow> returnOk (vaddr && ~~ mask (pageBits + pt_bits - pte_bits));\n            pd_slot \\<leftarrow> returnOk (pd + (pd_index << pde_bits));\n            oldpde \\<leftarrow> liftE $ get_master_pde pd_slot;\n            unlessE (oldpde = InvalidPDE) $ throwError DeleteFirst;\n            pde \\<leftarrow> returnOk (PageTablePDE (addrFromPPtr p));\n            returnOk $ InvokePageTable $\n                PageTableMap\n                (ArchObjectCap $ PageTableCap p (Some (asid, vaddr')))\n                cte pde pd_slot\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageTableUnmap\n    then doE\n            final \\<leftarrow> liftE $ is_final_cap (ArchObjectCap cap);\n            unlessE final $ throwError RevokeFirst;\n            returnOk $ InvokePageTable $ PageTableUnmap (ArchObjectCap cap) cte\n    odE\n    else throwError IllegalOperation\n\n| PageCap dev p R pgsz mapped_address \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMPageMap then\n    if length args > 2 \\<and> length extra_caps > 0\n    then let vaddr = args ! 0;\n             rights_mask = args ! 1;\n             attr = args ! 2;\n             pd_cap = fst (extra_caps ! 0)\n        in doE\n            (pd,asid) \\<leftarrow> (case pd_cap of\n                            ArchObjectCap (PageDirectoryCap pd (Some asid)) \\<Rightarrow>\n                              returnOk (pd,asid)\n                         | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            case mapped_address of\n              Some (asid', vaddr') \\<Rightarrow> doE\n                whenE (asid' \\<noteq> asid) (throwError $ InvalidCapability 1);\n                whenE (vaddr' \\<noteq> vaddr) (throwError $ InvalidArgument 0)\n              odE\n            | None \\<Rightarrow> doE\n                vtop \\<leftarrow> returnOk (vaddr + (1 << (pageBitsForSize pgsz)) - 1);\n                whenE (vtop \\<ge> kernel_base) $ throwError $ InvalidArgument 0\n              odE;\n            pd' \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (pd' \\<noteq> pd) $ throwError $ InvalidCapability 1;\n            vm_rights \\<leftarrow> returnOk (mask_vm_rights R (data_to_rights rights_mask));\n            check_vp_alignment pgsz vaddr;\n            entries \\<leftarrow> create_mapping_entries (addrFromPPtr p)\n                                              vaddr pgsz vm_rights\n                                              (attribs_from_word attr) pd;\n            ensure_safe_mapping entries;\n            returnOk $ InvokePage $ PageMap asid\n                (ArchObjectCap $ PageCap dev p R pgsz (Some (asid, vaddr)))\n                cte entries\n        odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageUnmap\n    then  returnOk $ InvokePage $ PageUnmap cap cte\n    else if isPageFlushLabel (invocation_type label) then\n        if length args > 1\n        then let start = args ! 0;\n                 end = args ! 1;\n                 pstart = start + addrFromPPtr p\n        in doE\n            (asid, _) \\<leftarrow> (case mapped_address of\n                Some a \\<Rightarrow> returnOk a\n              | _ \\<Rightarrow> throwError IllegalOperation);\n            pd \\<leftarrow> lookup_error_on_failure False $ find_pd_for_asid asid;\n            whenE (end \\<le> start) $ throwError $ InvalidArgument 1;\n            page_size \\<leftarrow> returnOk $ 1 << pageBitsForSize pgsz;\n            whenE (start \\<ge> page_size \\<or> end > page_size) $ throwError $ InvalidArgument 0;\n            whenE (pstart < physBase \\<or> ((end - start) + pstart) > paddrTop) $ throwError IllegalOperation;\n            returnOk $ InvokePage $ PageFlush\n                (label_to_flush_type (invocation_type label)) (start + p) \\<comment> \\<open>check\\<close>\n                (end + p - 1) pstart pd asid\n    odE\n    else throwError TruncatedMessage\n    else if invocation_type label = ArchInvocationLabel ARMPageGetAddress\n    then returnOk $ InvokePage $ PageGetAddr p\n  else  throwError IllegalOperation\n\n| ASIDControlCap \\<Rightarrow>\n    if invocation_type label = ArchInvocationLabel ARMASIDControlMakePool then\n    if length args > 1 \\<and> length extra_caps > 1\n    then let index = args ! 0;\n             depth = args ! 1;\n             (untyped, parent_slot) = extra_caps ! 0;\n             root = fst (extra_caps ! 1)\n         in doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            free_set \\<leftarrow> returnOk (- dom asid_table \\<inter> {x. x \\<le> (1 << asid_high_bits) - 1});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            free \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_select asid_table) free_set;\n            base \\<leftarrow> returnOk (ucast free << asid_low_bits);\n            (p,n) \\<leftarrow> (case untyped of UntypedCap False p n f \\<Rightarrow> returnOk (p,n)\n                                    | _ \\<Rightarrow> throwError $ InvalidCapability 1);\n            frame \\<leftarrow> (if n = pageBits\n                      then doE\n                        ensure_no_children parent_slot;\n                        returnOk p\n                      odE\n                      else  throwError $ InvalidCapability 1);\n            dest_slot \\<leftarrow> lookup_target_slot root (to_bl index) (unat depth);\n            ensure_empty dest_slot;\n            returnOk $ InvokeASIDControl $ MakePool frame dest_slot parent_slot base\n        odE\n    else  throwError TruncatedMessage\n    else  throwError IllegalOperation\n\n| ASIDPoolCap p base \\<Rightarrow>\n  if invocation_type label = ArchInvocationLabel ARMASIDPoolAssign then\n  if length extra_caps > 0\n  then\n    let (pd_cap, pd_cap_slot) = extra_caps ! 0\n     in case pd_cap of\n          ArchObjectCap (PageDirectoryCap _ None) \\<Rightarrow> doE\n            asid_table \\<leftarrow> liftE $ gets (arm_asid_table \\<circ> arch_state);\n            pool_ptr \\<leftarrow> returnOk (asid_table (asid_high_bits_of base));\n            whenE (pool_ptr = None) $ throwError $ FailedLookup False InvalidRoot;\n            whenE (p \\<noteq> the pool_ptr) $ throwError $ InvalidCapability 0;\n            pool \\<leftarrow> liftE $ get_asid_pool p;\n            free_set \\<leftarrow> returnOk (- dom pool \\<inter> {x. ucast x + base \\<noteq> 0});\n            whenE (free_set = {}) $ throwError DeleteFirst;\n            offset \\<leftarrow> liftE $ select_ext (\\<lambda>_. free_asid_pool_select pool base) free_set;\n            returnOk $ InvokeASIDPool $ Assign (ucast offset + base) p pd_cap_slot\n          odE\n        | _ \\<Rightarrow>  throwError $ InvalidCapability 1\n  else  throwError TruncatedMessage\n  else  throwError IllegalOperation\n| VCPUCap p \\<Rightarrow> fail \\<comment> \\<open>not an MMU invocation\\<close>\"\n\n(* arch decode invocations *)\n\ndefinition\n  arch_decode_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cap_ref \\<Rightarrow> cslot_ptr \\<Rightarrow> arch_cap \\<Rightarrow> (cap \\<times> cslot_ptr) list \\<Rightarrow>\n   (arch_invocation,'z::state_ext) se_monad\"\nwhere\n  \"arch_decode_invocation label args x_slot cte cap extra_caps \\<equiv> case cap of\n VCPUCap _ \\<Rightarrow> decode_vcpu_invocation label args cap extra_caps\n\\<comment> \\<open>arm-hyp: add cases for iommu\\<close>\n| _ \\<Rightarrow> decode_mmu_invocation label args x_slot cte cap extra_caps\"\n\ndefinition\n  arch_data_to_obj_type :: \"nat \\<Rightarrow> aobject_type option\" where\n \"arch_data_to_obj_type n \\<equiv>\n  if n = 0 then Some PageDirectoryObj\n  else if n = 1 then Some SmallPageObj\n  else if n = 2 then Some LargePageObj\n  else if n = 3 then Some SectionObj\n  else if n = 4 then Some SuperSectionObj\n  else if n = 5 then Some PageTableObj\n  else if n = 6 then Some VCPUObj\n  else None\"\n\ndefinition arch_decode_irq_control_invocation ::\n  \"data \\<Rightarrow> data list \\<Rightarrow> cslot_ptr \\<Rightarrow> cap list \\<Rightarrow> (arch_irq_control_invocation,'z::state_ext) se_monad\"\n  where\n  \"arch_decode_irq_control_invocation label args src_slot cps \\<equiv>\n    (if invocation_type label = ArchInvocationLabel ARMIRQIssueIRQHandler\n      then if length args \\<ge> 4 \\<and> length cps \\<ge> 1\n        then let irq_word = args ! 0;\n                 trigger = args ! 1;\n                 index = args ! 2;\n                 depth = args ! 3;\n                 cnode = cps ! 0;\n                 irq = ucast irq_word\n        in doE\n          arch_check_irq irq_word;\n          irq_active \\<leftarrow> liftE $ is_irq_active irq;\n          whenE irq_active $ throwError RevokeFirst;\n\n          dest_slot \\<leftarrow> lookup_target_slot cnode (data_to_cptr index) (unat depth);\n          ensure_empty dest_slot;\n\n          returnOk $ ArchIRQControlIssue irq dest_slot src_slot (trigger \\<noteq> 0)\n        odE\n      else throwError TruncatedMessage\n    else throwError IllegalOperation)\"\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchInvocation_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch specific object invocations\n*)\n\nchapter \"ARM Object Invocations\"\n\ntheory ArchInvocation_A\nimports Structures_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>These datatypes encode the arguments to the various possible\nARM-specific system calls. Selectors are defined for various fields\nfor convenience elsewhere.\\<close>\n\ndatatype flush_type = Clean | Invalidate | CleanInvalidate | Unify\n\ndatatype page_directory_invocation =\n    PageDirectoryFlush (pd_flush_type: flush_type) (pd_flush_start: vspace_ref)\n                       (pd_flush_end: vspace_ref) (pd_flush_pstart: word32)\n                       (pd_flush_pd: obj_ref) (pd_flush_asid: asid)\n  | PageDirectoryNothing\n\ndatatype page_table_invocation =\n    PageTableMap cap cslot_ptr pde obj_ref\n  | PageTableUnmap cap cslot_ptr\n\ndatatype asid_control_invocation =\n    MakePool obj_ref cslot_ptr cslot_ptr asid\n\ndatatype asid_pool_invocation =\n    Assign asid obj_ref cslot_ptr\n\ndatatype page_invocation\n     = PageMap\n         (page_map_asid: asid)\n         (page_map_cap: cap)\n         (page_map_ct_slot: cslot_ptr)\n         (page_map_entries: \"pte \\<times> (obj_ref list) + pde \\<times> (obj_ref list)\")\n     | PageUnmap\n         (page_unmap_cap: arch_cap)\n         (page_unmap_cap_slot: cslot_ptr)\n     | PageFlush\n         (page_flush_type: flush_type)\n         (page_flush_start: vspace_ref)\n         (page_flush_end: vspace_ref)\n         (page_flush_pstart: word32)\n         (page_flush_pd: obj_ref)\n         (page_flush_asid: asid)\n     | PageGetAddr\n         (page_get_paddr: obj_ref)\n\ndatatype vcpu_invocation =\n       VCPUSetTCB obj_ref (*vcpu*) obj_ref (*tcb*)\n     | VCPUInjectIRQ obj_ref nat virq\n     | VCPUReadRegister obj_ref vcpureg\n     | VCPUWriteRegister obj_ref vcpureg machine_word\n     | VCPUAckVPPI obj_ref (* vcpu *) vppievent_irq\n\ndatatype arch_invocation\n     = InvokePageTable page_table_invocation\n     | InvokePageDirectory page_directory_invocation\n     | InvokePage page_invocation\n     | InvokeASIDControl asid_control_invocation\n     | InvokeASIDPool asid_pool_invocation\n     | InvokeVCPU vcpu_invocation\n\n(* The ARM platform currently does not define any additional register sets for\nthe \"CopyRegisters\" operation. This may be changed in future to support a floating point unit. *)\n\ndatatype arch_copy_register_sets = ARMNoExtraRegisters\n\ndefinition \"ArchDefaultExtraRegisters \\<equiv> ARMNoExtraRegisters\"\n\ndatatype arch_irq_control_invocation =\n    ArchIRQControlIssue irq cslot_ptr cslot_ptr bool\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nARM specific data types\n*)\n\nchapter \"ARM-Specific Data Types\"\n\ntheory Arch_Structs_A\nimports\n  \"ExecSpec.Arch_Structs_B\"\n  ExceptionTypes_A\n  VMRights_A\n  ExecSpec.Arch_Kernel_Config_Lemmas\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\nThis theory provides architecture-specific definitions and datatypes\nincluding architecture-specific capabilities and objects.\n\\<close>"}
{"title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "section": "Architecture-specific capabilities", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>An ASID is simply a word.\\<close>\ntype_synonym asid = \"word32\"\n\ndatatype vm_attribute = PageCacheable | XNever\ntype_synonym vm_attributes = \"vm_attribute set\""}
{"title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "section": "Architecture-specific objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The ARM kernel supports capabilities for ASID pools and an ASID controller capability,\nalong with capabilities for page directories, page tables, and page mappings.\\<close>\n\ndatatype arch_cap =\n   ASIDPoolCap obj_ref asid\n | ASIDControlCap\n | PageCap bool obj_ref cap_rights vmpage_size \"(asid * vspace_ref) option\"\n | PageTableCap obj_ref \"(asid * vspace_ref) option\"\n | PageDirectoryCap obj_ref \"asid option\"\n | VCPUCap obj_ref\n\nlemmas arch_cap_cases =\n  arch_cap.induct[where arch_cap=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P, simplified, rule_format]\n\nlemmas arch_cap_cases_asm =\narch_cap.induct[where arch_cap=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n  simplified, rule_format, rotated -1]\n\ndefinition\n  is_page_cap :: \"arch_cap \\<Rightarrow> bool\" where\n  \"is_page_cap c \\<equiv> \\<exists>x0 x1 x2 x3 x4. c = PageCap x0 x1 x2 x3 x4\""}
{"title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "section": "Architecture-specific objects", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>This section gives the types and auxiliary definitions for the\narchitecture-specific objects: a page directory entry (@{text \"pde\"})\ncontains either an invalid entry, a page table reference, a section\nreference, or a super-section reference; a page table entry contains\neither an invalid entry, a large page, or a small page mapping;\nfinally, an architecture-specific object is either an ASID pool, a\npage table, a page directory, or a data page used to model user\nmemory.\n\\<close>\n\ntext \\<open>\nHypervisor extensions use long page table descriptors (64-bit) for the stage 2\ntranslation (host-to-hypervisor). This is a three-level table system, but the\nhardware can be configured to omit the first level entirely if all second\nlevels are stored contiguously. We use this configuration to preserve the usual\npage table/directory nomenclature.\nseL4 does not use hardware domains or parity on ARM hypervisor systems.\n\\<close>\ndatatype pde =\n   InvalidPDE\n | PageTablePDE obj_ref\n | SectionPDE obj_ref vm_attributes cap_rights\n | SuperSectionPDE obj_ref vm_attributes cap_rights\n\ndatatype pte =\n   InvalidPTE\n | LargePagePTE obj_ref vm_attributes cap_rights\n | SmallPagePTE obj_ref vm_attributes cap_rights\n\ntype_synonym hyper_reg_context = machine_word\n\n\ntext \\<open>With hypervisor extensions enabled, page table and page directory entries occupy\n8 bytes. Page directories occupy four frames, and page tables occupy a frame.\\<close>\n\ndefinition\n  pde_bits :: \"nat\" where\n  \"pde_bits \\<equiv> 3\"\n\ndefinition\n  pte_bits :: \"nat\" where\n  \"pte_bits \\<equiv> 3\"\n\ndefinition\n  pd_bits :: \"nat\" where\n  \"pd_bits \\<equiv> 11 + pde_bits\"\n\ndefinition\n  pt_bits :: \"nat\" where\n  \"pt_bits \\<equiv> 9 + pte_bits\"\n\ndefinition\n  vcpu_bits :: \"nat\" where\n  \"vcpu_bits \\<equiv> pageBits\"\n\n\ntext \\<open>vcpu\\<close>\n\ntype_synonym virq = machine_word\n\nend\n\nqualify ARM_HYP_A (in Arch)\n\nrecord  gic_vcpu_interface =\n  vgic_hcr  :: machine_word\n  vgic_vmcr :: machine_word\n  vgic_apr  :: machine_word\n  vgic_lr   :: \"nat \\<Rightarrow> ARM_HYP_A.virq\"\n\nrecord vcpu =\n  vcpu_tcb   :: \"obj_ref option\"\n  vcpu_vgic  :: gic_vcpu_interface\n  vcpu_regs :: \"vcpureg \\<Rightarrow> machine_word\"\n  vcpu_vppi_masked :: \"vppievent_irq \\<Rightarrow> bool\"\n  vcpu_vtimer :: virt_timer\n\nend_qualify\n\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition \"vcpu_sctlr vcpu \\<equiv> vcpu_regs vcpu VCPURegSCTLR\"\n\ndefinition\n  default_gic_vcpu_interface :: gic_vcpu_interface\nwhere\n  \"default_gic_vcpu_interface \\<equiv> \\<lparr>\n      vgic_hcr  = vgicHCREN,\n      vgic_vmcr = 0,\n      vgic_apr  = 0,\n      vgic_lr   = \\<lambda>_. 0 \\<rparr>\"\n\ndefinition\n  default_vcpu :: vcpu where\n  \"default_vcpu \\<equiv> \\<lparr>\n      vcpu_tcb    = None,\n      vcpu_vgic   = default_gic_vcpu_interface,\n      vcpu_regs   = (\\<lambda>_. 0) (VCPURegSCTLR := sctlrDefault\n                             , VCPURegACTLR := actlrDefault),\n      vcpu_vppi_masked = (\\<lambda>_. False),\n      vcpu_vtimer = VirtTimer 0\n      \\<rparr>\"\n\n\ntext \\<open>\n  ASID pools translate 10 bits, VCPUs store a potential association to a TCB as well as\n  an extended register context. Page tables have 512 entries (cf B3.6.5, pg 1348). For data pages,\n  we record their size.\n\\<close>\n\ndatatype arch_kernel_obj =\n   ASIDPool \"10 word \\<rightharpoonup> obj_ref\"\n | PageTable \"9 word \\<Rightarrow> pte\"  (* ARMHYP *)\n | PageDirectory \"11 word \\<Rightarrow> pde\"  (* ARMHYP *)\n | DataPage bool vmpage_size\n | VCPU vcpu\n\nlemmas arch_kernel_obj_cases =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x'\" for x P,\n                         simplified, rule_format]\n\nlemmas arch_kernel_obj_cases_asm =\n  arch_kernel_obj.induct[where arch_kernel_obj=x and P=\"\\<lambda>x'. x = x' \\<longrightarrow> P x' \\<longrightarrow> R\" for P R x,\n                         simplified, rule_format, rotated -1]\n\ndefinition cte_level_bits :: nat where\n  \"cte_level_bits \\<equiv> 4\"\n\nprimrec\n  arch_obj_size :: \"arch_cap \\<Rightarrow> nat\"\nwhere\n  \"arch_obj_size (ASIDPoolCap p as) = pageBits\"\n| \"arch_obj_size ASIDControlCap = 0\"\n| \"arch_obj_size (PageCap dev x rs sz as4) = pageBitsForSize sz\"\n| \"arch_obj_size (PageDirectoryCap x as2) = pd_bits\"\n| \"arch_obj_size (PageTableCap x as3) = pt_bits\"\n| \"arch_obj_size (VCPUCap _) = vcpu_bits\"\n\nprimrec\n  arch_cap_is_device :: \"arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_cap_is_device (PageCap dev x rs sz as4) = dev\"\n| \"arch_cap_is_device ASIDControlCap = False\"\n| \"arch_cap_is_device (ASIDPoolCap p as) = False\"\n| \"arch_cap_is_device (PageTableCap x as3) = False\"\n| \"arch_cap_is_device (PageDirectoryCap x as2) = False\"\n| \"arch_cap_is_device (VCPUCap _) = False\"\n\ndefinition tcb_bits :: nat where\n  \"tcb_bits \\<equiv> 9\"\n\ndefinition endpoint_bits :: nat where\n  \"endpoint_bits \\<equiv> 4\"\n\ndefinition ntfn_bits :: nat where\n  \"ntfn_bits \\<equiv> 4\"\n\ndefinition untyped_min_bits :: nat where\n  \"untyped_min_bits \\<equiv> 4\"\n\ndefinition untyped_max_bits :: nat where\n  \"untyped_max_bits \\<equiv> 29\"\n\nprimrec\n  arch_kobj_size :: \"arch_kernel_obj \\<Rightarrow> nat\"\nwhere\n  \"arch_kobj_size (ASIDPool p) = pageBits\"\n| \"arch_kobj_size (PageTable pte) = pt_bits\"\n| \"arch_kobj_size (PageDirectory pde) = pd_bits\"\n| \"arch_kobj_size (DataPage dev sz) = pageBitsForSize sz\"\n| \"arch_kobj_size (VCPU _) = vcpu_bits\"\n\nprimrec\n  aobj_ref :: \"arch_cap \\<rightharpoonup> obj_ref\"\nwhere\n  \"aobj_ref (ASIDPoolCap p as) = Some p\"\n| \"aobj_ref ASIDControlCap = None\"\n| \"aobj_ref (PageCap dev x rs sz as4) = Some x\"\n| \"aobj_ref (PageDirectoryCap x as2) = Some x\"\n| \"aobj_ref (PageTableCap x as3) = Some x\"\n| \"aobj_ref (VCPUCap x) = Some x\"\n\nprimrec (nonexhaustive)\n  acap_rights :: \"arch_cap \\<Rightarrow> cap_rights\"\nwhere\n \"acap_rights (PageCap dev x rs sz as) = rs\"\n\ndefinition\n  acap_rights_update :: \"cap_rights \\<Rightarrow> arch_cap \\<Rightarrow> arch_cap\" where\n \"acap_rights_update rs ac \\<equiv> case ac of\n    PageCap dev x rs' sz as \\<Rightarrow> PageCap dev x (validate_vm_rights rs) sz as\n  | _                   \\<Rightarrow> ac\""}
{"title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "section": "Architecture-specific object types and default objects", "subsection": "", "subsubsection": "", "code": "\ndatatype\n  aobject_type =\n    SmallPageObj\n  | LargePageObj\n  | SectionObj\n  | SuperSectionObj\n  | PageTableObj\n  | PageDirectoryObj\n  | ASIDPoolObj\n  | VCPUObj\n\ndefinition\n  arch_is_frame_type :: \"aobject_type \\<Rightarrow> bool\"\n  where\n    \"arch_is_frame_type aobj \\<equiv> case aobj of\n         SmallPageObj \\<Rightarrow> True\n       | LargePageObj \\<Rightarrow> True\n       | SectionObj \\<Rightarrow> True\n       | SuperSectionObj \\<Rightarrow> True\n       | _ \\<Rightarrow> False\"\n\ndefinition  arch_default_cap :: \"aobject_type \\<Rightarrow> obj_ref \\<Rightarrow> nat \\<Rightarrow> bool \\<Rightarrow> arch_cap\" where\n \"arch_default_cap tp r n dev \\<equiv> case tp of\n  SmallPageObj \\<Rightarrow> PageCap dev r vm_read_write ARMSmallPage None\n  | LargePageObj \\<Rightarrow> PageCap dev r vm_read_write ARMLargePage None\n  | SectionObj \\<Rightarrow> PageCap dev r vm_read_write ARMSection None\n  | SuperSectionObj \\<Rightarrow> PageCap dev r vm_read_write ARMSuperSection None\n  | PageTableObj \\<Rightarrow> PageTableCap r None\n  | PageDirectoryObj \\<Rightarrow> PageDirectoryCap r None\n  | VCPUObj \\<Rightarrow> VCPUCap r\n  | ASIDPoolObj \\<Rightarrow> ASIDPoolCap r 0\" (* unused *)\n\ndefinition\n  default_arch_object :: \"aobject_type \\<Rightarrow> bool \\<Rightarrow> nat \\<Rightarrow> arch_kernel_obj\" where\n \"default_arch_object tp dev n \\<equiv> case tp of\n    SmallPageObj \\<Rightarrow> DataPage dev ARMSmallPage\n  | LargePageObj \\<Rightarrow> DataPage dev ARMLargePage\n  | SectionObj \\<Rightarrow> DataPage dev ARMSection\n  | SuperSectionObj \\<Rightarrow> DataPage dev ARMSuperSection\n  | PageTableObj \\<Rightarrow> PageTable (\\<lambda>x. InvalidPTE)\n  | PageDirectoryObj \\<Rightarrow> PageDirectory (\\<lambda>x. InvalidPDE)\n  | VCPUObj \\<Rightarrow> VCPU default_vcpu\n  | ASIDPoolObj \\<Rightarrow> ASIDPool (\\<lambda>_. None)\"\n\ntype_synonym hw_asid = word8\n\ntype_synonym arm_vspace_region_uses = \"vspace_ref \\<Rightarrow> arm_vspace_region_use\""}
{"title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "section": "Architecture-specific state", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>The architecture-specific state for the ARM model\nconsists of the first level of the ASID table (@{text \"arm_asid_table\"}), a\nmap from hardware ASIDs to seL4 ASIDs (@{text \"arm_hwasid_table\"}),\nthe next hardware ASID to preempt (@{text \"arm_next_asid\"}), the\ninverse map from seL4 ASIDs to hardware ASIDs (first component of\n@{text \"arm_asid_map\"}), and the address of the page directory and\npage tables mapping the shared address space, along with a description\nof this space (@{text \"arm_global_pd\"}, @{text \"arm_global_pts\"}, and\n@{text \"arm_kernel_vspace\"} respectively).\n\nHardware ASIDs are only ever associated with seL4 ASIDs that have a\ncurrently active page directory. The second component of\n@{text \"arm_asid_map\"} values is the address of that page directory.\n\\<close>\n\nend\n\nqualify ARM_HYP_A (in Arch)\n\ntext \\<open>arch\\_state\\<close>\n\nrecord arch_state =\n  arm_asid_table    :: \"7 word \\<rightharpoonup> obj_ref\"\n  arm_hwasid_table  :: \"ARM_HYP_A.hw_asid \\<rightharpoonup> ARM_HYP_A.asid\"\n  arm_next_asid     :: ARM_HYP_A.hw_asid\n  arm_asid_map      :: \"ARM_HYP_A.asid \\<rightharpoonup> (ARM_HYP_A.hw_asid \\<times> obj_ref)\"\n  arm_current_vcpu    :: \"(obj_ref \\<times> bool) option\"\n  arm_gicvcpu_numlistregs :: nat\n  arm_kernel_vspace :: ARM_HYP_A.arm_vspace_region_uses\n  arm_us_global_pd  :: obj_ref\n\nend_qualify\n\ncontext Arch begin arch_global_naming (A)"}
{"title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "section": "Type declarations for invariant definitions", "subsection": "", "subsubsection": "", "code": "\ndatatype aa_type =\n    AASIDPool\n  | APageTable\n  | APageDirectory\n  | AVCPU\n  | AUserData vmpage_size\n  | ADeviceData vmpage_size\n\n\ndefinition aa_type :: \"arch_kernel_obj \\<Rightarrow> aa_type\"\nwhere\n \"aa_type ao \\<equiv> (case ao of\n           PageTable pt             \\<Rightarrow> APageTable\n         | PageDirectory pd         \\<Rightarrow> APageDirectory\n         | DataPage dev sz          \\<Rightarrow> if dev then ADeviceData sz else AUserData sz\n         | ASIDPool f               \\<Rightarrow> AASIDPool\n         | VCPU v                   \\<Rightarrow> AVCPU)\"\n\ntext \\<open>For implementation reasons the badge word has differing amounts of bits\\<close>\ndefinition\n  badge_bits :: nat where\n  badge_bits_def [simp]: \"badge_bits \\<equiv> 28\"\nend"}
{"title": "./spec/abstract/ARM_HYP/Arch_Structs_A.thy", "section": "Arch-specific tcb", "subsection": "", "subsubsection": "", "code": "\nqualify ARM_HYP_A (in Arch)\n\n(* arch specific part of tcb: this must have a field for user context *)\nrecord arch_tcb =\n tcb_context       :: user_context\n tcb_vcpu          :: \"obj_ref option\"\n\nend_qualify\n\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  default_arch_tcb :: arch_tcb where\n  \"default_arch_tcb \\<equiv> \\<lparr>\n      tcb_context    = new_context,\n      tcb_vcpu       = None \\<rparr>\"\n\ntext \\<open>\n  Accessors for @{text \"tcb_context\"} inside @{text \"arch_tcb\"}. These are later used to\n  implement @{text as_user}, i.e.\\ need to be compatible with @{text user_monad}.\\<close>\ndefinition\n  arch_tcb_context_set :: \"user_context \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_context_set uc a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := uc \\<rparr>\"\n\ndefinition\n  arch_tcb_context_get :: \"arch_tcb \\<Rightarrow> user_context\"\nwhere\n  \"arch_tcb_context_get a_tcb \\<equiv> tcb_context a_tcb\"\n\n(* FIXME: the following means that we break the set/getRegister abstraction\n          and should move some of this into the machine interface (same as X64) *)\ntext \\<open>\n  Accessors for the user register part of the @{text \"arch_tcb\"}.\n  (Because @{typ \"register \\<Rightarrow> machine_word\"} might not be equal to @{typ user_context}).\\<close>\ndefinition\n  arch_tcb_set_registers :: \"(register \\<Rightarrow> machine_word) \\<Rightarrow> arch_tcb \\<Rightarrow> arch_tcb\"\nwhere\n  \"arch_tcb_set_registers regs a_tcb \\<equiv> a_tcb \\<lparr> tcb_context := UserContext regs \\<rparr>\"\n\ndefinition\n  arch_tcb_get_registers :: \"arch_tcb \\<Rightarrow> register \\<Rightarrow> machine_word\"\nwhere\n  \"arch_tcb_get_registers a_tcb \\<equiv> user_regs (tcb_context a_tcb)\"\n\nend\n\n\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchFault_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nFunctions for fault handling.\n*)\n\nchapter \\<open>arch fault related functions\\<close>\n\ntheory ArchFault_A\nimports Structures_A Tcb_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\nfun make_arch_fault_msg :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> (data \\<times> data list,'z::state_ext) s_monad\"\nwhere\n  \"make_arch_fault_msg (VMFault vptr archData) thread = do\n     pc \\<leftarrow> as_user thread getRestartPC;\n     return (5, pc # vptr # archData) od\"\n| \"make_arch_fault_msg (VCPUFault hsr) thread = return (7, [hsr])\"\n| \"make_arch_fault_msg (VPPIEvent irq) thread = return (8, [ucast irq])\"\n| \"make_arch_fault_msg (VGICMaintenance archData) thread = do\n      msg \\<leftarrow> return $ (case archData of None \\<Rightarrow> [-1] | Some idx \\<Rightarrow> [idx]);\n      return (6, msg)\n   od\"\n\ndefinition\n  handle_arch_fault_reply :: \"arch_fault \\<Rightarrow> obj_ref \\<Rightarrow> data \\<Rightarrow> data list \\<Rightarrow> (bool,'z::state_ext) s_monad\"\nwhere\n  \"handle_arch_fault_reply af thread x y = return True\"\n\n\nend\n\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchTcb_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"Architecture-specific TCB functions\"\n\ntheory ArchTcb_A\nimports KHeap_A\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ndefinition\n  sanitise_register :: \"bool \\<Rightarrow> register \\<Rightarrow> machine_word \\<Rightarrow> machine_word\"\nwhere\n  \"sanitise_register t r v \\<equiv> case r of\n      CPSR \\<Rightarrow>\n       if t \\<and>\n          v && 0x1f \\<in> {0x10, 0x11, 0x12, 0x13, 0x17, 0x1b, 0x1f}\n            \\<comment> \\<open>@{text \\<open>PMODE_(USER/FIQ/IRQ/SUPERVISOR/ABORT/UNDEFINED/SYSTEM)\\<close>}\\<close>\n       then v\n       else (v && 0xf8000000) || 0x150\n    | _    \\<Rightarrow> v\"\n\ndefinition\n  arch_get_sanitise_register_info :: \"obj_ref \\<Rightarrow> (bool, 'a::state_ext) s_monad\"\nwhere\n  \"arch_get_sanitise_register_info t \\<equiv> do\n          vcpu \\<leftarrow> arch_thread_get tcb_vcpu t;\n          return (vcpu \\<noteq> None)\n   od\"\n\ndefinition\n  arch_post_modify_registers :: \"obj_ref \\<Rightarrow> obj_ref \\<Rightarrow> (unit, 'a::state_ext) s_monad\"\nwhere\n  \"arch_post_modify_registers cur t \\<equiv> return ()\"\n\nend\nend"}
{"title": "./spec/abstract/ARM_HYP/ArchCSpace_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nArch-specific functions for the abstract model of CSpace.\n*)\n\nchapter \"ArchCSpace\"\n\ntheory ArchCSpace_A\nimports\n  ArchVSpace_A\nbegin\ncontext Arch begin arch_global_naming (A)\n\ndefinition cnode_guard_size_bits :: \"nat\"\nwhere\n  cnode_guard_size_bits_def [simp]: \"cnode_guard_size_bits \\<equiv> 5\"\n\ndefinition cnode_padding_bits :: \"nat\"\nwhere\n  cnode_padding_bits_def [simp]: \"cnode_padding_bits \\<equiv> 3\"\n\ntext \\<open>On a user request to modify a cnode capability, extract new guard bits and guard.\\<close>\ndefinition\n  update_cnode_cap_data :: \"data \\<Rightarrow> nat \\<times> data\" where\n \"update_cnode_cap_data w \\<equiv>\n    let\n      guard_bits = 18;\n      guard_size' = unat ((w >> cnode_padding_bits) && mask cnode_guard_size_bits);\n      guard'' = (w >> (cnode_padding_bits + cnode_guard_size_bits)) && mask guard_bits\n    in (guard_size', guard'')\"\n\n\ntext \\<open>For some purposes capabilities to physical objects are treated\ndifferently to others.\\<close>\ndefinition\n  arch_is_physical :: \"arch_cap \\<Rightarrow> bool\" where\n  \"arch_is_physical cap \\<equiv> case cap of ASIDControlCap \\<Rightarrow> False | _ \\<Rightarrow> True\"\n\ntext \\<open>Check whether the second capability is to the same object or an object\ncontained in the region of the first one.\\<close>\nfun\n  arch_same_region_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\"\nwhere\n  \"arch_same_region_as (PageCap dev r R s x) (PageCap dev' r' R' s' x') =\n   (let\n     topA = r + (1 << pageBitsForSize s) - 1;\n     topB = r' + (1 << pageBitsForSize s') - 1\n   in r \\<le> r' \\<and> topA \\<ge> topB \\<and> r' \\<le> topB)\"\n| \"arch_same_region_as (PageTableCap r x) (PageTableCap r' x') = (r' = r)\"\n| \"arch_same_region_as (PageDirectoryCap r x) (PageDirectoryCap r' x') = (r' = r)\"\n| \"arch_same_region_as ASIDControlCap ASIDControlCap = True\"\n| \"arch_same_region_as (ASIDPoolCap r a) (ASIDPoolCap r' a') = (r' = r)\"\n| \"arch_same_region_as (VCPUCap r) (VCPUCap r') = (r' = r)\"\n| \"arch_same_region_as _ _ = False\"\n\n\ntext \\<open>Check whether two arch capabilities are to the same object.\\<close>\ndefinition\n  same_aobject_as :: \"arch_cap \\<Rightarrow> arch_cap \\<Rightarrow> bool\" where\n \"same_aobject_as cp cp' \\<equiv>\n   (case (cp, cp') of\n      (PageCap dev ref _ pgsz _,PageCap dev' ref' _ pgsz' _)\n          \\<Rightarrow> (dev, ref, pgsz) = (dev', ref', pgsz')\n              \\<and> ref \\<le> ref + 2 ^ pageBitsForSize pgsz - 1\n    | _ \\<Rightarrow> arch_same_region_as cp cp')\"\n\n(* Proofs don't want to see this definition *)\ndeclare same_aobject_as_def[simp]\n\ndefinition\n  arch_is_cap_revocable :: \"cap \\<Rightarrow> cap \\<Rightarrow> bool\"\nwhere\n  \"arch_is_cap_revocable c c' \\<equiv> False\"\n\nend\nend"}
{"title": "./spec/abstract/ARM_HYP/Machine_A.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(*\nTypes and operations to access the underlying machine, instantiated\nfor ARM.\n*)\n\nchapter \"ARM Machine Instantiation\"\n\ntheory Machine_A\nimports\n  \"ExecSpec.MachineOps\"\nbegin\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>\n  The specification is written with abstract type names for object\n  references, user pointers, word-based data, cap references, and so\n  on. This theory provides an instantiation of these names to concrete\n  types for the ARM architecture. Other architectures may have slightly\n  different instantiations.\n\\<close>\ntype_synonym obj_ref            = machine_word\ntype_synonym vspace_ref         = machine_word\n\ntype_synonym data               = machine_word\ntype_synonym cap_ref            = \"bool list\"\ntype_synonym length_type        = machine_word\n\ntype_synonym asid_low_len       = 10\ntype_synonym asid_low_index     = \"asid_low_len word\"\n\ntype_synonym asid_high_len      = 7\ntype_synonym asid_high_index    = \"asid_high_len word\"\n\n(* It might be nice if asid was \"17 word\", but Refine is easier if it is a machine_word.  *)\n(* Making asid a machine_word means that we need invariants that the extra bits are zero. *)\ntype_synonym asid_len           = 17\ntype_synonym asid_rep_len       = machine_word_len\ntype_synonym asid               = \"asid_rep_len word\"\n\ntext \\<open>With the definitions above, most conversions between abstract\ntype names boil down to just the identity function, some convert from\n@{text word} to @{typ nat} and others between different word sizes\nusing @{const ucast}.\\<close>\ndefinition\n  oref_to_data   :: \"obj_ref \\<Rightarrow> data\" where\n  \"oref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_oref   :: \"data \\<Rightarrow> obj_ref\" where\n  \"data_to_oref \\<equiv> id\"\n\ndefinition\n  vref_to_data   :: \"vspace_ref \\<Rightarrow> data\" where\n  \"vref_to_data \\<equiv> id\"\n\ndefinition\n  data_to_vref   :: \"data \\<Rightarrow> vspace_ref\" where\n  \"data_to_vref \\<equiv> id\"\n\ndefinition\n  nat_to_len     :: \"nat \\<Rightarrow> length_type\" where\n  \"nat_to_len \\<equiv> of_nat\"\n\ndefinition\n  data_to_nat    :: \"data \\<Rightarrow> nat\" where\n  \"data_to_nat \\<equiv> unat\"\n\ndefinition\n  data_to_16     :: \"data \\<Rightarrow> 16 word\" where\n  \"data_to_16 \\<equiv> ucast\"\n\ndefinition\n  data_to_cptr :: \"data \\<Rightarrow> cap_ref\" where\n  \"data_to_cptr \\<equiv> to_bl\"\n\ndefinition\n  combine_ntfn_badges :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_badges \\<equiv> semiring_bit_operations_class.or\"\n\ndefinition\n  combine_ntfn_msgs :: \"data \\<Rightarrow> data \\<Rightarrow> data\" where\n  \"combine_ntfn_msgs \\<equiv> semiring_bit_operations_class.or\"\n\n\ntext \\<open>These definitions will be unfolded automatically in proofs.\\<close>\nlemmas data_convs [simp] =\n  oref_to_data_def data_to_oref_def vref_to_data_def data_to_vref_def\n  nat_to_len_def data_to_nat_def data_to_16_def data_to_cptr_def\n\n\ntext \\<open>The following definitions provide architecture-dependent sizes\n  such as the standard page size and capability size of the underlying\n  machine.\n\\<close>\ndefinition\n  slot_bits :: nat where\n  \"slot_bits \\<equiv> 4\"\n\ndefinition\n  msg_label_bits :: nat where\n  [simp]: \"msg_label_bits \\<equiv> 20\"\n\ndefinition\n  new_context :: \"user_context\" where\n  \"new_context \\<equiv> UserContext ((\\<lambda>r. 0) (CPSR := 0x150))\"\n\ntext \\<open>The lowest virtual address in the kernel window. The kernel reserves the\nvirtual addresses from here up in every virtual address space.\\<close>\ndefinition\n  kernel_base :: \"vspace_ref\" where\n  \"kernel_base \\<equiv> 0xe0000000\"\n\ndefinition\n  idle_thread_ptr :: vspace_ref where\n  \"idle_thread_ptr = kernel_base + 0x1000\"\n\nend\n\narch_requalify_consts (A) kernel_base idle_thread_ptr\n\ncontext Arch begin arch_global_naming (A)\n\ntext \\<open>Miscellaneous definitions of constants used in modelling machine\noperations.\\<close>\n\ndefinition\n  nat_to_cref :: \"nat \\<Rightarrow> nat \\<Rightarrow> cap_ref\" where\n  \"nat_to_cref len n \\<equiv> drop (word_bits - len)\n                           (to_bl (of_nat n :: machine_word))\"\n\ndefinition\n \"msg_info_register \\<equiv> msgInfoRegister\"\ndefinition\n \"msg_registers \\<equiv> msgRegisters\"\ndefinition\n \"cap_register \\<equiv> capRegister\"\ndefinition\n \"badge_register \\<equiv> badgeRegister\"\ndefinition\n \"frame_registers \\<equiv> frameRegisters\"\ndefinition\n \"gp_registers \\<equiv> gpRegisters\"\ndefinition\n \"exception_message \\<equiv> exceptionMessage\"\ndefinition\n \"syscall_message \\<equiv> syscallMessage\"\n\n\ndatatype arch_fault =\n    VMFault vspace_ref \"machine_word list\"\n  | VGICMaintenance \"data option\" (* idx *)\n  | VCPUFault data (* hsr *)\n  | VPPIEvent irq (* vppi IRQ *)\n\n\nend\n\nend"}
{"title": "./spec/cspec/TypHeapLimits.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: BSD-2-Clause\n *)\n\ntheory TypHeapLimits\n  imports CParser.TypHeapLib\nbegin\n\ndefinition\n  states_all_but_typs_eq :: \"char list set \\<Rightarrow> heap_raw_state \\<Rightarrow> heap_raw_state \\<Rightarrow> bool\"\nwhere\n \"states_all_but_typs_eq names hrs hrs'\n    = (hrs_htd hrs = hrs_htd hrs'\n        \\<and> (\\<forall>x. hrs_mem hrs x = hrs_mem hrs' x\n             \\<or> (\\<exists>p td. x \\<in> {p ..+ size_td td} \\<and> td_names td \\<subseteq> names\n                    \\<and> typ_name td \\<noteq> pad_typ_name\n                    \\<and> valid_footprint (hrs_htd hrs) p td)))\"\n\nlemma heap_list_eq_from_region_eq:\n  \"\\<forall>x \\<in> {p ..+ n}. hp x = hp' x\n    \\<Longrightarrow> heap_list hp n p = heap_list hp' n p\"\n  apply (induct n arbitrary: p)\n   apply simp\n  apply (simp add: intvl_def)\n  apply (frule_tac x=p in spec, drule mp, rule_tac x=0 in exI,\n         simp+)\n  apply (erule meta_allE, erule meta_mp)\n  apply clarsimp\n  apply (drule spec, erule mp)\n  apply (rule_tac x=\"Suc k\" in exI)\n  apply simp\n  done\n\nlemma states_all_but_typs_eq_clift:\n  \"\\<lbrakk> states_all_but_typs_eq names hrs hrs';\n      \\<forall>x \\<in> td_names (typ_info_t TYPE('a)). x \\<notin> names;\n      typ_name (typ_info_t TYPE('a)) \\<noteq> pad_typ_name \\<rbrakk>\n     \\<Longrightarrow> (clift hrs :: (_ \\<rightharpoonup> ('a :: c_type))) = clift hrs'\"\n  apply (rule ext, simp add: lift_t_def)\n  apply (cases hrs, cases hrs', clarsimp)\n  apply (simp add: lift_typ_heap_def restrict_map_def)\n  apply (simp add: s_valid_def proj_d_lift_state\n                   states_all_but_typs_eq_def hrs_htd_def\n                   hrs_mem_def)\n  apply clarsimp\n  apply (simp add: heap_list_s_heap_list h_t_valid_def)\n  apply (subst heap_list_eq_from_region_eq, simp_all)\n  apply clarsimp\n  apply (drule spec, erule disjE, assumption)\n  apply clarsimp\n  apply (drule(1) valid_footprint_neq_disjoint)\n    apply (clarsimp simp: typ_uinfo_t_def typ_tag_lt_def\n                          typ_tag_le_def)\n    apply (force dest: td_set_td_names\n                intro: td_set_td_names[OF td_set_self])\n   apply (clarsimp simp: field_of_def typ_uinfo_t_def)\n   apply (force dest: td_set_td_names\n               intro: td_set_td_names[OF td_set_self])\n  apply (simp add: size_of_def)\n  apply blast\n  done\n\nlemma states_all_but_typs_eq_refl:\n  \"states_all_but_typs_eq names hrs hrs\"\n  by (simp add: states_all_but_typs_eq_def)\n\nlemma states_all_but_typs_eq_trans:\n  \"states_all_but_typs_eq names hrs hrs'\n     \\<Longrightarrow> states_all_but_typs_eq names hrs' hrs''\n     \\<Longrightarrow> states_all_but_typs_eq names hrs hrs''\"\n  apply (clarsimp simp add: states_all_but_typs_eq_def\n                  del: disjCI)\n  apply (drule_tac x=x in spec)+\n  apply clarsimp\n  done\n\nlemma states_all_but_typs_eq_update:\n  \"\\<lbrakk> hrs_htd hrs \\<Turnstile>\\<^sub>t (ptr :: ('a :: c_type) ptr);\n      td_names (typ_info_t TYPE('a)) \\<subseteq> names;\n      typ_name (typ_info_t TYPE('a)) \\<noteq> pad_typ_name;\n      wf_fd (typ_info_t TYPE('a)) \\<rbrakk>\n        \\<Longrightarrow>\n   states_all_but_typs_eq names hrs\n    (hrs_mem_update (heap_update ptr v) hrs)\"\n  apply (clarsimp simp: states_all_but_typs_eq_def hrs_mem_update\n                   del: disjCI)\n  apply (subst disj_commute, rule disjCI)\n  apply (rule_tac x=\"ptr_val ptr\" in exI)\n  apply (rule_tac x=\"typ_uinfo_t TYPE('a)\" in exI)\n  apply (simp add: typ_uinfo_t_def h_t_valid_def heap_update_def)\n  apply (rule ccontr)\n  apply (subst(asm) heap_update_nmem_same)\n   apply (simp add: to_bytes_def length_fa_ti)\n   apply (subst length_fa_ti, simp_all add: size_of_def)\n  done\n\nend"}
{"title": "./spec/cspec/KernelState_C.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\n(* The base theory for generated bitfield proofs about the kernel *)\n\ntheory KernelState_C\nimports\n  \"Word_Lib.WordSetup\"\n  \"CLib.BitFieldProofsLib\"\n  \"Substitute\"\nbegin\n\ntype_synonym c_ptr_name = int\ntype_synonym 't c_com = \"('t, c_ptr_name, strictc_errortype) com\"\ntype_synonym 't c_body = \"('t, c_ptr_name, strictc_errortype) body\"\ntype_synonym 't c_xstate = \"('t, strictc_errortype) xstate\"\n\ntype_synonym cstate = \"globals myvars\"\ntype_synonym rf_com = \"cstate c_com\"\n\nabbreviation\n  \"cslift (s :: cstate) \\<equiv> clift (t_hrs_' (globals s))\"\n\nlemma cslift_def: \"is_an_abbreviation\" by (simp add: is_an_abbreviation_def)\n\n(* Add an abbreviation for the common case of hrs_htd (t_hrs_' (globals s)) \\<Turnstile>\\<^sub>t p *)\nabbreviation\n  \"c_h_t_valid\" :: \"cstate \\<Rightarrow> 'a::c_type ptr \\<Rightarrow> bool\"  (\"_ \\<Turnstile>\\<^sub>c _\" [99,99] 100)\nwhere\n  \"s \\<Turnstile>\\<^sub>c p == hrs_htd (t_hrs_' (globals s)),c_guard \\<Turnstile>\\<^sub>t p\"\n\n(* The HoarePartialDef theorems are used extensively\n   (as opposed to their HoareTotalDef counterparts, which aren't used much).\n   We can give most their long names, but conseqPre is used over 400 times,\n   so for these cases we override the namespaces *)\nlemmas conseqPre = HoarePartialDef.conseqPre\nlemmas conseqPost = HoarePartialDef.conseqPost\n\n(* Likewise, we'd prefer to get HOL.conj_cong over StateFun.conj_cong *)\nlemmas conj_cong = HOL.conj_cong\n\n(* Removes two rules that are too eager for the bitfield proofs. *)\ndeclare bit_shiftr_eq[simp del]\ndeclare shiftl_of_Suc[simp del]\n\nend"}
{"title": "./spec/cspec/KernelInc_C.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory KernelInc_C\nimports\n  \"Substitute\"\n  \"structures_defs\"\n  \"structures_proofs\"\n  \"shared_types_defs\"\n  \"shared_types_proofs\"\nbegin\n\nend"}
{"title": "./spec/cspec/Substitute.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Substitute\n\nimports\n  \"CKernel.Kernel_C\"\n  \"AsmRefine.GlobalsSwap\"\nbegin\n\nML \\<open>\n\nstructure SubstituteSpecs = struct\n\nval list_abs = uncurry (fold_rev (fn (x, T) => fn t => Abs (x, T, t)));\n\nfun get_rhs thm =\n    snd (Logic.dest_equals (Thm.concl_of thm))\n    handle TYPE _ =>\n      snd (HOLogic.dest_eq (Thm.concl_of thm));\n\nfun get_lhs thm =\n    fst (Logic.dest_equals (Thm.concl_of thm))\n    handle TYPE _ =>\n      fst (HOLogic.dest_eq (Thm.concl_of thm));\n\nfun term_convert prefix convs (tm as Const (name, _)) =\n    if not (String.isPrefix prefix name) then tm\n    else the (Termtab.lookup convs tm)\n  | term_convert _ _ tm = tm;\n\nfun suspicious_term ctxt s t = if Term.add_var_names t [] = [] then ()\n  else (tracing (\"suspicious \" ^ s);\n    Syntax.pretty_term ctxt t |> Pretty.string_of |> tracing;\n    ())\n\nval debug_trace = ref (Bound 0);\n\nfun convert prefix src_ctxt proc (tm as Const (name, _)) (convs, ctxt) =\n  ((term_convert prefix convs tm; (convs, ctxt))\n  handle Option =>\n let\n    val cname = unprefix prefix name;\n    val def_thm = Proof_Context.get_thm src_ctxt (cname ^ \"_def\")\n    val rhs = get_rhs def_thm;\n    val _ = suspicious_term ctxt \"init rhs\" rhs;\n    val consts = Term.add_consts rhs [];\n    val (convs, ctxt) = fold (convert prefix src_ctxt proc o Const)\n        consts (convs, ctxt);\n    val rhs' = map_aterms (term_convert prefix convs) rhs;\n    val rhs'' = proc ctxt cname rhs';\n    val _ = suspicious_term ctxt \"adjusted rhs\" rhs'';\n\n  in if rhs'' aconv rhs\n    then (Termtab.insert (K true) (tm, tm) convs,\n        ctxt\n        |> Local_Theory.begin_nested |> snd\n        |> Local_Theory.abbrev Syntax.mode_default ((Binding.name cname, NoSyn), get_lhs def_thm)\n        |> snd |> Local_Theory.note ((Binding.name (cname ^ \"_def\"), []), [def_thm])\n        |> snd |> Local_Theory.end_nested\n    )\n\n  else let\n      val _ = tracing (\"Defining \" ^ cname);\n\n      val pre_def_ctxt = ctxt\n      val b = Binding.name cname\n      val ctxt = Local_Theory.begin_nested ctxt |> snd\n      val ((tm', _), ctxt) = Local_Theory.define\n          ((b, NoSyn), ((Thm.def_binding b, []), rhs'')) ctxt\n      val tm'' = Morphism.term (Proof_Context.export_morphism ctxt pre_def_ctxt) tm'\n      val ctxt = Local_Theory.end_nested ctxt\n\n      val lhs_argTs = get_lhs def_thm |> strip_comb |> snd |> map fastype_of;\n      val abs_tm = list_abs (map (pair \"_\") lhs_argTs, tm'')\n\n    in (Termtab.insert (K true) (tm, abs_tm) convs, ctxt) end\n  end)\n  | convert _ _ _ (tm) _ = raise TERM (\"convert: not Const\", [tm])\n\n\nfun prove_impl_tac ctxt ss =\n    SUBGOAL (fn (t, n) => let\n        val lhs = t |> HOLogic.dest_Trueprop |> HOLogic.dest_eq |> fst;\n        val cnames = Term.add_const_names lhs []\n          |> filter (String.isSuffix \"_'proc\");\n        val unfolds = map (Proof_Context.get_thm ctxt o suffix \"_def\"\n          o Long_Name.base_name) cnames;\n      in simp_tac (put_simpset ss ctxt addsimps unfolds) n\n      end);\n\nfun convert_impls ctxt = let\n\n    val thm = Proof_Context.get_thm ctxt \"\\<Gamma>_def\"\n\n    val proc_defs = (Term.add_const_names (Thm.concl_of thm) [])\n      |> filter (String.isSuffix Hoare.proc_deco)\n      |> map (suffix \"_def\" #> Proof_Context.get_thm ctxt)\n\n    val tree_lemmata = StaticFun.prove_partial_map_thms thm\n        (ctxt addsimps proc_defs)\n\n    fun impl_name_from_proc (Const (s, _)) = s\n            |> Long_Name.base_name\n            |> unsuffix Hoare.proc_deco\n            |> suffix HoarePackage.implementationN\n      | impl_name_from_proc t = raise TERM (\"impl_name_from_proc\", [t])\n\n    val saves = tree_lemmata |> map (apfst (fst #> impl_name_from_proc))\n\n  in Local_Theory.notes (map (fn (n, t) => ((Binding.name n, []), [([t], [])])) saves)\n    ctxt |> snd end\n\nfun take_all_actions prefix src_ctxt proc tm csenv\n      styargs ctxt = let\n    val (_, ctxt) = convert prefix src_ctxt proc tm (Termtab.empty, ctxt);\n  in ctxt\n    |> convert_impls\n    |> Modifies_Proofs.prove_all_modifies_goals_local csenv (fn _ => true) styargs\n  end\n\nend\n\n\\<close>\n\nML \\<open>\nfun com_rewrite f t = case fastype_of t of\n    (comT as Type (@{type_name com}, [s, _, ft]))\n      => let\n    val gd = Const (@{const_name Guard},\n                ft --> (HOLogic.mk_setT s) --> comT --> comT)\n    fun add_guard ((f, gd_s), c) = gd $ f $ gd_s $ c;\n\n    val seq = Const (@{const_name Seq}, comT --> comT --> comT);\n    val skip = Const (@{const_name Skip}, comT);\n    fun add_guards_to_seq gs (Const (@{const_name Seq}, _) $ a $ b)\n        = seq $ add_guards_to_seq gs a $ b\n      | add_guards_to_seq gs c\n        = seq $ foldr add_guard skip gs $ c;\n\n    fun add_guards c [] = c\n      | add_guards ((w as Const (@{const_name While}, _)) $ S $ c) gs\n        = seq $ (w $ S $ add_guards_to_seq gs c) $ foldr add_guard skip gs\n      | add_guards (call as (Const (@{const_name call}, _) $ _ $ _ $ _ $ _)) gs\n        = foldr add_guard (seq $ call $ foldr add_guard skip gs) gs\n      | add_guards c gs = foldr add_guard c gs;\n\n    fun inner t = case t of\n      (Const (@{const_name \"switch\"}, T) $ v $ set_com_list) => let\n        val (ss, cs) = map_split HOLogic.dest_prod\n          (HOLogic.dest_list set_com_list);\n        val cs' = map inner cs;\n        val (v', gs) = f v;\n        val (ss', gss) = map_split f ss;\n        val listT = HOLogic.mk_prodT\n          (HOLogic.mk_setT (range_type (domain_type T)), comT);\n      in foldr add_guard (head_of t $ v' $ HOLogic.mk_list listT\n            (map HOLogic.mk_prod (ss' ~~ cs')))\n          (gs @ flat gss)\n      end\n      | _ => let\n        val (h, xs) = strip_comb t;\n        (* assumption: we can only get into the com type with one of the\n           constructors or pseudo-constructors, which don't need rewriting,\n           so we can ignore h *)\n        val xTs = xs ~~ (fastype_of h |> strip_type |> fst);\n        fun upd_arg (x, T) = if T = comT then (inner x, []) else f x;\n        val (ys, gss) = map_split upd_arg xTs;\n      in add_guards (list_comb (h, ys)) (flat gss) end\n  in inner (Envir.beta_eta_contract t) end\n  | _ => t;\n\n\\<close>\n\nsetup \\<open>DefineGlobalsList.define_globals_list_i\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\" @{typ globals}\\<close>\n\n\nlocale substitute_pre\n  = fixes symbol_table :: \"string \\<Rightarrow> addr\"\n      and domain :: \"addr set\"\n\nbegin\n\nabbreviation\n \"globals_list \\<equiv> kernel_all_global_addresses.global_data_list\"\n\nend\n\nlocale kernel_all_substitute = substitute_pre\nbegin\n\nML \\<open>\nfun mk_rew (t as Abs (s, T, _)) = mk_rew (betapply (t, Var ((s, 0), T)))\n  | mk_rew t = HOLogic.dest_eq t\n\nval mk_varifyT = Term.map_types Logic.varifyT_global\n\nlocal\nval c_guard_rew =\n  @{term \"\\<lambda>p b. Guard C_Guard {s. c_guard (p s)} b\n     = Guard C_Guard {s. h_t_valid (hrs_htd (t_hrs_' (globals s))) c_guard (p s)} b\"}\n  |> mk_varifyT |> mk_rew\n\nval c_guard_rew_weak =\n  @{term \"\\<lambda>p b. Guard C_Guard {s. c_guard (p s)} b\n         = Guard C_Guard {s. ptr_safe (p s) (hrs_htd (t_hrs_' (globals s)))\n            \\<and> c_guard (p s)} b\"}\n      |> mk_varifyT |> mk_rew\n\nin\nfun strengthen_c_guards ss thy s =\n  if (exists (curry (=) s) ss)\n  then Pattern.rewrite_term thy [c_guard_rew_weak] []\n  else Pattern.rewrite_term thy [c_guard_rew] []\nend;\n\\<close>\n\nlemmas global_data_defs\n    = kernel_all_global_addresses.global_data_defs\n\nlemmas globals_list_def\n    = kernel_all_global_addresses.global_data_list_def\n\nML \\<open>\n\n(* the unvarify sets ?symbol_table back to symbol_table. be careful *)\nval global_datas = @{thms global_data_defs}\n  |> map (Thm.concl_of #> Logic.unvarify_global\n        #> Logic.dest_equals #> snd #> Envir.beta_eta_contract)\n\nval const_globals = map_filter\n    (fn (Const (@{const_name const_global_data}, _) $ nm $ t)\n        => SOME (HOLogic.dest_string nm, t)\n        | _ => NONE) global_datas\n\nlocal\n\nval hrs_htd_update_guard_rew1 =\n    @{term \"\\<lambda>u. Basic (\\<lambda>s. globals_update (t_hrs_'_update (hrs_htd_update (u s))) s)\n         = Guard C_Guard {s. globals_list_distinct (fst ` dom_s (u s (hrs_htd (t_hrs_' (globals s)))))\n                         symbol_table globals_list}\n           (Basic (\\<lambda>s. globals_update (t_hrs_'_update (id hrs_htd_update (u s))) s))\"}\n        |> mk_rew\n\nval hrs_htd_update_guard_rew2 =\n  @{term \"t_hrs_'_update (id hrs_htd_update f) = t_hrs_'_update (hrs_htd_update f)\"}\n  |> Logic.varify_global |> HOLogic.dest_eq;\n\nval consts = map snd const_globals\n\nval index_eq_set_helper\n  = Syntax.parse_term @{context} (String.concat\n    [\"\\<lambda>str t n c. {s :: globals myvars. c \\<longrightarrow>\",\n        \"h_val (hrs_mem (t_hrs_' (globals s)))\",\n        \" (CTypesDefs.ptr_add (Ptr (symbol_table str)) (of_nat (n s)))\",\n        \" = t s}\"])\n\nval eq_set_helper\n  = Syntax.parse_term @{context} (String.concat\n    [\"\\<lambda>str t c. {s :: globals myvars. c \\<longrightarrow>\",\n        \"h_val (hrs_mem (t_hrs_' (globals s)))\",\n        \" (Ptr (symbol_table str)) = t}\"])\n\nval s = @{term \"s :: globals myvars\"}\n\nval grab_name_str = head_of #> dest_Const #> fst #> Long_Name.base_name\n    #> HOLogic.mk_string\n\nin\n\nfun const_global_asserts ctxt cond\n  (t as (Const (@{const_name index}, _) $ arr $ n)) = if member (=) consts arr\n    then [(index_eq_set_helper $ grab_name_str arr\n        $ lambda s t $ lambda s n $ cond) |> Syntax.check_term ctxt]\n    else []\n  | const_global_asserts ctxt cond (Const c) = if member (=) consts (Const c)\n    then [(eq_set_helper $ grab_name_str (Const c) $ Const c $ cond)\n        |> Syntax.check_term ctxt]\n    else []\n  | const_global_asserts ctxt cond (f $ x) = if member (=) consts (f $ x)\n    then [(eq_set_helper $ grab_name_str (f $ x) $ (f $ x) $ cond)\n        |> Syntax.check_term ctxt]\n    else const_global_asserts ctxt cond f @ const_global_asserts ctxt cond x\n  | const_global_asserts ctxt cond (a as Abs (_, @{typ \"globals myvars\"}, _))\n    = const_global_asserts ctxt cond (betapply (a, s))\n  | const_global_asserts ctxt cond (Abs (_, _, t))\n    = const_global_asserts ctxt cond t\n  | const_global_asserts _ _ _ = []\n\nfun guard_rewritable_globals const_cond ctxt =\n  Pattern.rewrite_term @{theory} [hrs_htd_update_guard_rew2] []\n  o Pattern.rewrite_term @{theory} [hrs_htd_update_guard_rew1] []\n  o com_rewrite (fn t =>\n     (t, map (pair @{term C_Guard})\n        (case const_cond of SOME cond => const_global_asserts ctxt cond t\n                | NONE => [])))\n\nval guard_htd_updates_with_domain = com_rewrite\n  (fn t => if fastype_of t = @{typ \"globals myvars \\<Rightarrow> globals myvars\"}\n        andalso Term.exists_Const (fn (s, _) => s = @{const_name \"hrs_htd_update\"}) t\n        then (t, [(@{term MemorySafety}, betapply (@{term \"\\<lambda>f :: globals myvars \\<Rightarrow> globals myvars.\n                {s. htd_safe domain (hrs_htd (t_hrs_' (globals s)))\n              \\<and> htd_safe domain (hrs_htd (t_hrs_' (globals (f s))))}\"}, t))])\n        else (t, []))\n\nval guard_halt = com_rewrite\n  (fn t => if t = @{term \"halt_'proc\"}\n    then (t, [(@{term DontReach}, @{term \"{} :: globals myvars set\"})])\n    else (t, []))\n\nfun acc_ptr_adds (Const (@{const_name h_val}, _) $ m $ (Const (@{const_name ptr_add}, _) $ p $ n))\n    = [(p, n, true)] @ maps acc_ptr_adds [m, p, n]\n  | acc_ptr_adds (Const (@{const_name heap_update}, _) $ (Const (@{const_name ptr_add}, _) $ p $ n))\n    = [(p, n, true)] @ maps acc_ptr_adds [p, n]\n  | acc_ptr_adds (Const (@{const_name ptr_add}, _) $ p $ n)\n    = [(p, n, false)] @ maps acc_ptr_adds [p, n]\n  | acc_ptr_adds (f $ x) = maps acc_ptr_adds [f, x]\n  | acc_ptr_adds (abs as Abs (_, T, t)) = if T = @{typ \"globals myvars\"}\n    then acc_ptr_adds (betapply (abs, @{term \"s :: globals myvars\"}))\n    else acc_ptr_adds t\n  | acc_ptr_adds _ = []\n\nfun mk_bool true = @{term True} | mk_bool false = @{term False}\n\nval guard_acc_ptr_adds = com_rewrite\n  (fn t => (t, acc_ptr_adds t |> map (fn (p, n, strong) => let\n    val assn = Const (@{const_name ptr_add_assertion'},\n            fastype_of p --> @{typ \"int \\<Rightarrow> bool \\<Rightarrow> heap_typ_desc \\<Rightarrow> bool\"})\n        $ p $ n $ mk_bool strong\n        $ @{term \"hrs_htd (t_hrs_' (globals (s :: globals myvars)))\"}\n    val gd = HOLogic.mk_Collect (\"s\", @{typ \"globals myvars\"}, assn)\n  in (@{term MemorySafety}, gd) end)))\n\nend\n\n\\<close>\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\nML \\<open>\n  Feedback.verbosity_level := ~1;\n\\<close>\n\nlocal_setup \\<open>\nSubstituteSpecs.take_all_actions\n  \"Kernel_C.kernel_all_global_addresses.\"\n  (Locale.init \"Kernel_C.kernel_all_global_addresses\" @{theory})\n  (fn ctxt => fn s => guard_rewritable_globals NONE ctxt\n    o (strengthen_c_guards [\"memset_body\", \"memcpy_body\", \"memzero_body\"]\n          (Proof_Context.theory_of ctxt) s)\n    o guard_halt\n    o guard_htd_updates_with_domain\n    o guard_acc_ptr_adds)\n  @{term kernel_all_global_addresses.\\<Gamma>}\n  (CalculateState.get_csenv @{theory} \"../c/build/$L4V_ARCH/kernel_all.c_pp\" |> the)\n  [@{typ \"globals myvars\"}, @{typ int}, @{typ strictc_errortype}]\n\\<close>\n\nend\n\nend"}
{"title": "./spec/cspec/ARM/Kernel_C.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . (*FIXME: arch-split*)\n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> word32\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> word32 \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend\n\n(* workaround for the fact that the C parser wants to know the vmpage sizes*)\n\n(* create appropriately qualified aliases *)\ncontext begin interpretation Arch . global_naming vmpage_size\n\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 8\"\n\ndefinition\n  ctcb_offset :: \"32 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]\n\ntext \\<open>Hide unqualified names conflicting with Kernel_Config names. Force use of Kernel_C prefix\n  for these:\\<close>\nhide_const (open)\n  numDomains\n\ntext \\<open>Add a more usable name for the collection of ThreadState definitions\\<close>\nlemmas ThreadState_defs = StrictC'_thread_state_defs\n\n(* hide vmpage sizes again *)\nhide_const\n vmpage_size.ARMSmallPage\n vmpage_size.ARMLargePage\n vmpage_size.ARMSection\n vmpage_size.ARMSuperSection\n\n(* re-allow fully qualified accesses (for consistency). Slightly clunky *)\ncontext Arch begin\n\nglobal_naming \"ARM.vmpage_size\"\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nglobal_naming ARM\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\nend\n\n\nend"}
{"title": "./spec/cspec/X64/Kernel_C.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . (*FIXME: arch-split*)\n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> machine_word\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> machine_word \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend\n\n(* x86-64 asm statements are not yet supported by the c-parser *)\nsetup \\<open>Context.theory_map (ASM_Ignore_Hooks.add_hook (fn _ => true))\\<close>\n\n(* workaround for the fact that the C parser wants to know the vmpage sizes*)\n(* create appropriately qualified aliases *)\ncontext begin interpretation Arch . global_naming vmpage_size\nrequalify_consts X64SmallPage X64LargePage X64HugePage\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 10\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]\n\ntext \\<open>Hide unqualified names conflicting with Kernel_Config names. Force use of Kernel_C prefix\n  for these:\\<close>\nhide_const (open)\n  numDomains\n\ntext \\<open>Add a more usable name for the collection of ThreadState definitions\\<close>\nlemmas ThreadState_defs = StrictC'_thread_state_defs\n\n(* hide vmpage sizes again *)\nhide_const\n  vmpage_size.X64SmallPage\n  vmpage_size.X64LargePage\n  vmpage_size.X64HugePage\n\n(* re-allow fully qualified accesses (for consistency). Slightly clunky *)\ncontext Arch begin\nglobal_naming \"X64.vmpage_size\" requalify_consts X64SmallPage X64LargePage X64HugePage\nglobal_naming \"X64\" requalify_consts X64SmallPage X64LargePage X64HugePage\nend\n\nend"}
{"title": "./spec/cspec/RISCV64/Kernel_C.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . (*FIXME: arch-split*)\n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> machine_word\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> machine_word \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend\n\n(* workaround for the fact that the C parser wants to know the vmpage sizes*)\n(* create appropriately qualified aliases *)\ncontext begin interpretation Arch . global_naming vmpage_size\nrequalify_consts RISCVSmallPage RISCVLargePage RISCVHugePage\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 9\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]\n\ntext \\<open>Hide unqualified names conflicting with Kernel_Config names. Force use of Kernel_C prefix\n  for these:\\<close>\nhide_const (open)\n  numDomains\n\ntext \\<open>Add a more usable name for the collection of ThreadState definitions\\<close>\nlemmas ThreadState_defs = StrictC'_thread_state_defs\n\n(* hide vmpage sizes again *)\nhide_const\n  vmpage_size.RISCVSmallPage\n  vmpage_size.RISCVLargePage\n  vmpage_size.RISCVHugePage\n\n(* re-allow fully qualified accesses (for consistency). Slightly clunky *)\ncontext Arch begin\nglobal_naming \"RISCV.vmpage_size\" requalify_consts RISCVSmallPage RISCVLargePage RISCVHugePage\nglobal_naming \"RISCV\" requalify_consts RISCVSmallPage RISCVLargePage RISCVHugePage\nend\n\nend"}
{"title": "./spec/cspec/AARCH64/Kernel_C.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n  pt_array_len\n  vs_array_len\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . (*FIXME: arch-split*)\n\n(* Sanity checks for array sizes. ptTranslationBits not yet available at definition site. *)\nlemma ptTranslationBits_vs_index_bits:\n  \"ptTranslationBits VSRootPT_T = vs_index_bits\"\n  by (simp add: ptTranslationBits_def vs_index_bits_def)\n\n(* FIXME AARCH64: this is guaranteed to always succeed even though config_ARM_PA_SIZE_BITS_40\n   is unfolded. It'd be nicer if we could also get something symbolic out of value_type, though *)\nlemma ptTranslationBits_vs_array_len':\n  \"2 ^ ptTranslationBits VSRootPT_T = vs_array_len\"\n  by (simp add: vs_array_len_val ptTranslationBits_vs_index_bits vs_index_bits_def\n                Kernel_Config.config_ARM_PA_SIZE_BITS_40_def)\n\nlemmas ptTranslationBits_vs_array_len = ptTranslationBits_vs_array_len'[unfolded vs_array_len_val]\n\ntype_synonym cghost_state =\n  \"(machine_word \\<rightharpoonup> vmpage_size) \\<times>   \\<comment> \\<open>Frame sizes\\<close>\n   (machine_word \\<rightharpoonup> nat) \\<times>           \\<comment> \\<open>CNode sizes\\<close>\n   (machine_word \\<rightharpoonup> pt_type) \\<times>       \\<comment> \\<open>PT types\\<close>\n   ghost_assertions\"                 \\<comment> \\<open>ASMRefine assertions\\<close>\n\ndefinition gs_clear_region :: \"addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n     (\\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n      \\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x,\n      \\<lambda>x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd (snd gs)) x,\n      snd (snd (snd gs)))\"\n\ndefinition gs_new_frames:: \"vmpage_size \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n     if bits < pageBitsForSize sz then gs\n     else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                    x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n               else fst gs x, snd gs)\"\n\ndefinition gs_new_cnodes:: \"nat \\<Rightarrow> addr \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n     if bits < sz + 4 then gs\n     else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                       then Some sz\n                       else fst (snd gs) x, snd (snd gs))\"\n\ndefinition gs_new_pt_t:: \"pt_type \\<Rightarrow> addr \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_new_pt_t pt_t ptr \\<equiv>\n     \\<lambda>gs. (fst gs, fst (snd gs), (fst (snd (snd gs))) (ptr \\<mapsto> pt_t), snd (snd (snd gs)))\"\n\nabbreviation gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> machine_word\" where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd \\<circ> snd \\<circ> snd)\"\n\nabbreviation gs_set_assn :: \"int \\<Rightarrow> machine_word \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd \\<circ> apsnd \\<circ> apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend\n\n(* Workaround for the fact that the retype annotations need the vmpage sizes*)\n(* create appropriately qualified aliases *)\ncontext begin interpretation Arch . global_naming vmpage_size\nrequalify_consts ARMSmallPage ARMLargePage ARMHugePage\nend\n\n(* Also need pt_type constructors for retype annotations. We leave them available globally for C. *)\ncontext begin interpretation Arch .\nrequalify_consts NormalPT_T VSRootPT_T\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 10\"\n\ndefinition\n  ctcb_offset :: \"64 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]\n\ntext \\<open>Hide unqualified names conflicting with Kernel_Config names. Force use of Kernel_C prefix\n  for these:\\<close>\nhide_const (open)\n  numDomains\n\ntext \\<open>Add a more usable name for the collection of ThreadState definitions\\<close>\nlemmas ThreadState_defs = StrictC'_thread_state_defs\n\n(* hide vmpage sizes again *)\nhide_const\n  vmpage_size.ARMSmallPage\n  vmpage_size.ARMLargePage\n  vmpage_size.ARMHugePage\n\n(* re-allow fully qualified accesses (for consistency). Slightly clunky *)\ncontext Arch begin\nglobal_naming \"AARCH64.vmpage_size\" requalify_consts ARMSmallPage ARMLargePage ARMHugePage\nglobal_naming \"AARCH64\" requalify_consts ARMSmallPage ARMLargePage ARMHugePage\nend\n\nend"}
{"title": "./spec/cspec/ARM_HYP/Kernel_C.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2014, General Dynamics C4 Systems\n *\n * SPDX-License-Identifier: GPL-2.0-only\n *)\n\ntheory Kernel_C\nimports\n  \"ExecSpec.MachineTypes\"\n  \"CLib.CTranslationNICTA\"\n  \"AsmRefine.CommonOps\"\nbegin\n\nexternal_file\n  \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n\ncontext begin interpretation Arch .\n\nrequalify_types\n  machine_state\n\nend\n\ndeclare [[populate_globals=true]]\n\ncontext begin interpretation Arch . (*FIXME: arch-split*)\n\ntype_synonym cghost_state = \"(machine_word \\<rightharpoonup> vmpage_size) * (machine_word \\<rightharpoonup> nat)\n    * ghost_assertions\"\n\ndefinition\n  gs_clear_region :: \"word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\" where\n  \"gs_clear_region ptr bits gs \\<equiv>\n   (%x. if x \\<in> {ptr..+2 ^ bits} then None else fst gs x,\n    %x. if x \\<in> {ptr..+2 ^ bits} then None else fst (snd gs) x, snd (snd gs))\"\n\ndefinition\n  gs_new_frames:: \"vmpage_size \\<Rightarrow> word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_frames sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < pageBitsForSize sz then gs\n   else (\\<lambda>x. if \\<exists>n\\<le>mask (bits - pageBitsForSize sz).\n                  x = ptr + n * 2 ^ pageBitsForSize sz then Some sz\n             else fst gs x, snd gs)\"\n\ndefinition\n  gs_new_cnodes:: \"nat \\<Rightarrow> word32 \\<Rightarrow> nat \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_new_cnodes sz ptr bits \\<equiv> \\<lambda>gs.\n   if bits < sz + 4 then gs\n   else (fst gs, \\<lambda>x. if \\<exists>n\\<le>mask (bits - sz - 4). x = ptr + n * 2 ^ (sz + 4)\n                     then Some sz\n                     else fst (snd gs) x, snd (snd gs))\"\n\nabbreviation\n  gs_get_assn :: \"int \\<Rightarrow> cghost_state \\<Rightarrow> word32\"\n  where\n  \"gs_get_assn k \\<equiv> ghost_assertion_data_get k (snd o snd)\"\n\nabbreviation\n  gs_set_assn :: \"int \\<Rightarrow> word32 \\<Rightarrow> cghost_state \\<Rightarrow> cghost_state\"\n  where\n  \"gs_set_assn k v \\<equiv> ghost_assertion_data_set k v (apsnd o apsnd)\"\n\ndeclare [[record_codegen = false]]\ndeclare [[allow_underscore_idents = true]]\n\nend\n\n(* workaround for the fact that the C parser wants to know the vmpage sizes*)\n\n(* create appropriately qualified aliases *)\ncontext begin interpretation Arch . global_naming vmpage_size\n\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nend\n\ndefinition\n  ctcb_size_bits :: nat\nwhere\n  \"ctcb_size_bits \\<equiv> 8\"\n\ndefinition\n  ctcb_offset :: \"32 word\"\nwhere\n  \"ctcb_offset \\<equiv> 2 ^ ctcb_size_bits\"\n\nlemmas ctcb_offset_defs = ctcb_offset_def ctcb_size_bits_def\n\ncond_sorry_modifies_proofs SORRY_MODIFIES_PROOFS\n\ninstall_C_file \"../c/build/$L4V_ARCH/kernel_all.c_pp\"\n  [machinety=machine_state, ghostty=cghost_state]\n\ntext \\<open>Hide unqualified names conflicting with Kernel_Config names. Force use of Kernel_C prefix\n  for these:\\<close>\nhide_const (open)\n  numDomains\n\ntext \\<open>Add a more usable name for the collection of ThreadState definitions\\<close>\nlemmas ThreadState_defs = StrictC'_thread_state_defs\n\n(* hide vmpage sizes again *)\nhide_const\n vmpage_size.ARMSmallPage\n vmpage_size.ARMLargePage\n vmpage_size.ARMSection\n vmpage_size.ARMSuperSection\n\n(* re-allow fully qualified accesses (for consistency). Slightly clunky *)\ncontext Arch begin\n\nglobal_naming \"ARM.vmpage_size\"\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\n\nglobal_naming ARM\nrequalify_consts ARMSmallPage ARMLargePage ARMSection ARMSuperSection\nend\n\n\nend"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "", "subsection": "", "subsubsection": "", "code": "\n(*\n * Copyright 2023, Proofcraft Pty Ltd\n * Copyright 2020, Data61, CSIRO (ABN 41 687 119 230)\n *\n * SPDX-License-Identifier: BSD-2-Clause\n *)\n\n(*\n   Nondeterministic state and error monads with failure in Isabelle.\n*)\n\nchapter \"Nondeterministic State Monad with Failure\"\n\ntheory Nondet_Monad\n  imports\n    Fun_Pred_Syntax\n    Monad_Lib\nbegin\n\ntext \\<open>\n  \\label{c:monads}\n\n  State monads are used extensively in the seL4 specification. They are defined below.\\<close>"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Adding Exceptions", "subsection": "", "subsubsection": "", "code": "\ntext \\<open>\n  The basic type of the nondeterministic state monad with failure is\n  very similar to the normal state monad. Instead of a pair consisting\n  of result and new state, we return a set of these pairs coupled with\n  a failure flag. Each element in the set is a potential result of the\n  computation. The flag is @{const True} if there is an execution path\n  in the computation that may have failed. Conversely, if the flag is\n  @{const False}, none of the computations resulting in the returned\n  set can have failed.\\<close>\ntype_synonym ('s, 'a) nondet_monad = \"'s \\<Rightarrow> ('a \\<times> 's) set \\<times> bool\"\n\n\ntext \\<open>\n  Print the type @{typ \"('s,'a) nondet_monad\"} instead of its unwieldy expansion.\n  Needs an AST translation in code, because it needs to check that the state variable\n  @{typ 's} occurs twice. This comparison is not guaranteed to always work as expected\n  (AST instances might have different decoration), but it does seem to work here.\\<close>\nprint_ast_translation \\<open>\n  let\n    fun monad_tr _ [t1, Ast.Appl [Ast.Constant @{type_syntax prod},\n                          Ast.Appl [Ast.Constant @{type_syntax set},\n                            Ast.Appl [Ast.Constant @{type_syntax prod}, t2, t3]],\n                          Ast.Constant @{type_syntax bool}]] =\n      if t3 = t1\n      then Ast.Appl [Ast.Constant @{type_syntax \"nondet_monad\"}, t1, t2]\n      else raise Match\n  in [(@{type_syntax \"fun\"}, monad_tr)] end\n\\<close>\n\n\ntext \\<open>\n  The definition of fundamental monad functions @{text return} and\n  @{text bind}. The monad function @{text \"return x\"} does not change\n  the  state, does not fail, and returns @{text \"x\"}.\\<close>\ndefinition return :: \"'a \\<Rightarrow> ('s,'a) nondet_monad\" where\n  \"return a \\<equiv> \\<lambda>s. ({(a,s)},False)\"\n\ntext \\<open>\n  The monad function @{text \"bind f g\"}, also written @{text \"f >>= g\"},\n  is the execution of @{term f} followed by the execution of @{text g}.\n  The function @{text g} takes the result value \\emph{and} the result\n  state of @{text f} as parameter. The definition says that the result of\n  the combined operation is the union of the set of sets that is created\n  by @{text g} applied to the result sets of @{text f}. The combined\n  operation may have failed, if @{text f} may have failed or @{text g} may\n  have failed on any of the results of @{text f}.\\<close>\ndefinition bind ::\n  \"('s, 'a) nondet_monad \\<Rightarrow> ('a \\<Rightarrow> ('s, 'b) nondet_monad) \\<Rightarrow> ('s, 'b) nondet_monad\" (infixl \">>=\" 60)\n  where\n  \"bind f g \\<equiv> \\<lambda>s. (\\<Union>(fst ` case_prod g ` fst (f s)),\n                   True \\<in> snd ` case_prod g ` fst (f s) \\<or> snd (f s))\"\n\ntext \\<open>Sometimes it is convenient to write @{text bind} in reverse order.\\<close>\nabbreviation (input) bind_rev ::\n  \"('c \\<Rightarrow> ('a, 'b) nondet_monad) \\<Rightarrow> ('a, 'c) nondet_monad \\<Rightarrow> ('a, 'b) nondet_monad\" (infixl \"=<<\" 60)\n  where\n  \"g =<< f \\<equiv> f >>= g\"\n\ntext \\<open>\n  The basic accessor functions of the state monad. @{text get} returns\n  the current state as result, does not fail, and does not change the state.\n  @{text \"put s\"} returns nothing (@{typ unit}), changes the current state\n  to @{text s} and does not fail.\\<close>\ndefinition get :: \"('s,'s) nondet_monad\" where\n  \"get \\<equiv> \\<lambda>s. ({(s,s)}, False)\"\n\ndefinition put :: \"'s \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"put s \\<equiv> \\<lambda>_. ({((),s)}, False)\""}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Adding Exceptions", "subsection": "Failure", "subsubsection": "", "code": "\ntext \\<open>\n  Basic nondeterministic functions. @{text \"select A\"} chooses an element\n  of the set @{text A}, does not change the state, and does not fail\n  (even if the set is empty). @{text \"f \\<sqinter> g\"} executes @{text f} or\n  executes @{text g}. It retuns the union of results of @{text f} and\n  @{text g}, and may have failed if either may have failed.\\<close>\ndefinition select :: \"'a set \\<Rightarrow> ('s,'a) nondet_monad\" where\n  \"select A \\<equiv> \\<lambda>s. (A \\<times> {s}, False)\"\n\ndefinition alternative ::\n  \"('s, 'a) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad\" (infixl \"\\<sqinter>\" 20)\n  where\n  \"f \\<sqinter> g \\<equiv> \\<lambda>s. (fst (f s) \\<union> fst (g s), snd (f s) \\<or> snd (g s))\"\n\ntext \\<open>\n  A variant of @{text select} that takes a pair. The first component is a set\n  as in normal @{text select}, the second component indicates whether the\n  execution failed. This is useful to lift monads between different state\n  spaces.\\<close>\ndefinition select_f :: \"'a set \\<times> bool  \\<Rightarrow> ('s,'a) nondet_monad\" where\n  \"select_f S \\<equiv> \\<lambda>s. (fst S \\<times> {s}, snd S)\"\n\ntext \\<open>\n  @{text state_select} takes a relationship between states, and outputs\n  nondeterministically a state related to the input state. Fails if no such\n  state exists.\\<close>\ndefinition state_select :: \"('s \\<times> 's) set \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"state_select r \\<equiv> \\<lambda>s. ((\\<lambda>x. ((), x)) ` {s'. (s, s') \\<in> r}, \\<not> (\\<exists>s'. (s, s') \\<in> r))\""}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Adding Exceptions", "subsection": "Failure", "subsubsection": "", "code": "\ntext \\<open>\n  The monad function that always fails. Returns an empty set of results and sets the failure flag.\\<close>\ndefinition fail :: \"('s, 'a) nondet_monad\" where\n  \"fail \\<equiv> \\<lambda>s. ({}, True)\"\n\ntext \\<open>Assertions: fail if the property @{text P} is not true\\<close>\ndefinition assert :: \"bool \\<Rightarrow> ('a, unit) nondet_monad\" where\n  \"assert P \\<equiv> if P then return () else fail\"\n\ntext \\<open>Fail if the value is @{const None}, return result @{text v} for @{term \"Some v\"}\\<close>\ndefinition assert_opt :: \"'a option \\<Rightarrow> ('b, 'a) nondet_monad\" where\n  \"assert_opt v \\<equiv> case v of None \\<Rightarrow> fail | Some v \\<Rightarrow> return v\"\n\ntext \\<open>An assertion that also can introspect the current state.\\<close>\ndefinition state_assert :: \"('s \\<Rightarrow> bool) \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"state_assert P \\<equiv> get >>= (\\<lambda>s. assert (P s))\""}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Adding Exceptions", "subsection": "Generic functions on top of the state monad", "subsubsection": "", "code": "\ntext \\<open>Apply a function to the current state and return the result without changing the state.\\<close>\ndefinition gets :: \"('s \\<Rightarrow> 'a) \\<Rightarrow> ('s, 'a) nondet_monad\" where\n  \"gets f \\<equiv> get >>= (\\<lambda>s. return (f s))\"\n\ntext \\<open>Modify the current state using the function passed in.\\<close>\ndefinition modify :: \"('s \\<Rightarrow> 's) \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"modify f \\<equiv> get >>= (\\<lambda>s. put (f s))\"\n\nlemma simpler_gets_def:\n  \"gets f = (\\<lambda>s. ({(f s, s)}, False))\"\n  by (simp add: gets_def return_def bind_def get_def)\n\nlemma simpler_modify_def:\n  \"modify f = (\\<lambda>s. ({((), f s)}, False))\"\n  by (simp add: modify_def bind_def get_def put_def)\n\ntext \\<open>Execute the given monad when the condition is true, return @{text \"()\"} otherwise.\\<close>\ndefinition \"when\" :: \"bool \\<Rightarrow> ('s, unit) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"when P m \\<equiv> if P then m else return ()\"\n\ntext \\<open>Execute the given monad unless the condition is true, return @{text \"()\"} otherwise.\\<close>\ndefinition unless :: \"bool \\<Rightarrow> ('s, unit) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"unless P m \\<equiv> when (\\<not>P) m\"\n\ntext \\<open>\n  Perform a test on the current state, performing the left monad if\n  the result is true or the right monad if the result is false. \\<close>\ndefinition condition ::\n  \"('s \\<Rightarrow> bool) \\<Rightarrow> ('s, 'r) nondet_monad \\<Rightarrow> ('s, 'r) nondet_monad \\<Rightarrow> ('s, 'r) nondet_monad\"\n  where\n  \"condition P L R \\<equiv> \\<lambda>s. if (P s) then (L s) else (R s)\"\n\nnotation (output)\n  condition  (\"(condition (_)//  (_)//  (_))\" [1000,1000,1000] 1000)\n\ntext \\<open>\n  Apply an option valued function to the current state, fail if it returns @{const None},\n  return @{text v} if it returns @{term \"Some v\"}.\\<close>\ndefinition gets_the :: \"('s \\<Rightarrow> 'a option) \\<Rightarrow> ('s, 'a) nondet_monad\" where\n  \"gets_the f \\<equiv> gets f >>= assert_opt\"\n\ntext \\<open>\n  Get a map (such as a heap) from the current state and apply an argument to the map.\n  Fail if the map returns @{const None}, otherwise return the value.\\<close>\ndefinition gets_map :: \"('s \\<Rightarrow> 'a \\<Rightarrow> 'b option) \\<Rightarrow> 'a \\<Rightarrow> ('s, 'b) nondet_monad\" where\n  \"gets_map f p \\<equiv> gets f >>= (\\<lambda>m. assert_opt (m p))\""}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Adding Exceptions", "subsection": "The Monad Laws", "subsubsection": "", "code": "\ntext \\<open>An alternative definition of @{term bind}, sometimes more convenient.\\<close>\nlemma bind_def':\n  \"(f >>= g) \\<equiv>\n       \\<lambda>s. ({(r'', s''). \\<exists>(r', s') \\<in> fst (f s). (r'', s'') \\<in> fst (g r' s') },\n                     snd (f s) \\<or> (\\<exists>(r', s') \\<in> fst (f s). snd (g r' s')))\"\n  by (rule eq_reflection)\n     (auto simp add: bind_def split_def Let_def)\n\ntext \\<open>Each monad satisfies at least the following three laws.\\<close>\n\ntext \\<open>@{term return} is absorbed at the left of a @{term bind}, applying the return value directly:\\<close>\nlemma return_bind[simp]:\n  \"(return x >>= f) = f x\"\n  by (simp add: return_def bind_def)\n\ntext \\<open>@{term return} is absorbed on the right of a @{term bind}\\<close>\nlemma bind_return[simp]:\n  \"(m >>= return) = m\"\n  by (simp add: bind_def return_def split_def)\n\ntext \\<open>@{term bind} is associative\\<close>\nlemma bind_assoc:\n  fixes m :: \"('a,'b) nondet_monad\"\n  fixes f :: \"'b \\<Rightarrow> ('a,'c) nondet_monad\"\n  fixes g :: \"'c \\<Rightarrow> ('a,'d) nondet_monad\"\n  shows \"(m >>= f) >>= g  =  m >>= (\\<lambda>x. f x >>= g)\"\n  unfolding bind_def Let_def split_def\n  by (auto intro: rev_image_eqI)"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Adding Exceptions", "subsection": "The Monad Laws", "subsubsection": "", "code": "\ntext \\<open>\n  The type @{typ \"('s,'a) nondet_monad\"} gives us nondeterminism and\n  failure. We now extend this monad with exceptional return values\n  that abort normal execution, but can be handled explicitly.\n  We use the sum type to indicate exceptions.\n\n  In @{typ \"('s, 'e + 'a) nondet_monad\"}, @{typ \"'s\"} is the state,\n  @{typ 'e} is an exception, and @{typ 'a} is a normal return value.\n\n  This new type itself forms a monad again. Since type classes in\n  Isabelle are not powerful enough to express the class of monads,\n  we provide new names for the @{term return} and @{term bind} functions\n  in this monad. We call them @{text returnOk} (for normal return values)\n  and @{text bindE} (for composition). We also define @{text throwError}\n  to return an exceptional value.\\<close>\ndefinition returnOk :: \"'a \\<Rightarrow> ('s, 'e + 'a) nondet_monad\" where\n  \"returnOk \\<equiv> return o Inr\"\n\ndefinition throwError :: \"'e \\<Rightarrow> ('s, 'e + 'a) nondet_monad\" where\n  \"throwError \\<equiv> return o Inl\"\n\ntext \\<open>\n  Lifting a function over the exception type: if the input is an\n  exception, return that exception; otherwise continue execution.\\<close>\ndefinition lift :: \"('a \\<Rightarrow> ('s, 'e + 'b) nondet_monad) \\<Rightarrow> 'e +'a \\<Rightarrow> ('s, 'e + 'b) nondet_monad\" where\n  \"lift f v \\<equiv> case v of Inl e \\<Rightarrow> throwError e | Inr v' \\<Rightarrow> f v'\"\n\ntext \\<open>\n  The definition of @{term bind} in the exception monad (new\n  name @{text bindE}): the same as normal @{term bind}, but\n  the right-hand side is skipped if the left-hand side\n  produced an exception.\\<close>\ndefinition bindE ::\n  \"('s, 'e + 'a) nondet_monad \\<Rightarrow> ('a \\<Rightarrow> ('s, 'e + 'b) nondet_monad) \\<Rightarrow> ('s, 'e + 'b) nondet_monad\"\n  (infixl \">>=E\" 60) where\n  \"f >>=E g \\<equiv> f >>= lift g\"\n\ntext \\<open>\n  Lifting a normal nondeterministic monad into the\n  exception monad is achieved by always returning its\n  result as normal result and never throwing an exception.\\<close>\ndefinition liftE :: \"('s,'a) nondet_monad \\<Rightarrow> ('s, 'e+'a) nondet_monad\" where\n  \"liftE f \\<equiv> f >>= (\\<lambda>r. return (Inr r))\"\n\ntext \\<open>\n  Since the underlying type and @{text return} function changed,\n  we need new definitions for when and unless:\\<close>\ndefinition whenE :: \"bool \\<Rightarrow> ('s, 'e + unit) nondet_monad \\<Rightarrow> ('s, 'e + unit) nondet_monad\" where\n  \"whenE P f \\<equiv> if P then f else returnOk ()\"\n\ndefinition unlessE :: \"bool \\<Rightarrow> ('s, 'e + unit) nondet_monad \\<Rightarrow> ('s, 'e + unit) nondet_monad\" where\n  \"unlessE P f \\<equiv> if P then returnOk () else f\"\n\ntext \\<open>\n  Throwing an exception when the parameter is @{term None}, otherwise\n  returning @{term \"v\"} for @{term \"Some v\"}.\\<close>\ndefinition throw_opt :: \"'e \\<Rightarrow> 'a option \\<Rightarrow> ('s, 'e + 'a) nondet_monad\" where\n  \"throw_opt ex x \\<equiv> case x of None \\<Rightarrow> throwError ex | Some v \\<Rightarrow> returnOk v\"\n\ntext \\<open>\n  Failure in the exception monad is redefined in the same way\n  as @{const whenE} and @{const unlessE}, with @{term returnOk}\n  instead of @{term return}.\\<close>\ndefinition assertE :: \"bool \\<Rightarrow> ('a, 'e + unit) nondet_monad\" where\n  \"assertE P \\<equiv> if P then returnOk () else fail\""}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Adding Exceptions", "subsection": "The Monad Laws", "subsubsection": "", "code": "\ntext \\<open>More direct definition of @{const liftE}:\\<close>\nlemma liftE_def2:\n  \"liftE f = (\\<lambda>s. ((\\<lambda>(v,s'). (Inr v, s')) ` fst (f s), snd (f s)))\"\n  by (auto simp: liftE_def return_def split_def bind_def)\n\ntext \\<open>Left @{const returnOk} absorbtion over @{term bindE}:\\<close>\nlemma returnOk_bindE[simp]: \"(returnOk x >>=E f) = f x\"\n  unfolding bindE_def returnOk_def\n  by (clarsimp simp: lift_def)\n\nlemma lift_return[simp]:\n  \"lift (return \\<circ> Inr) = return\"\n  by (auto simp: lift_def throwError_def split: sum.splits)\n\ntext \\<open>Right @{const returnOk} absorbtion over @{term bindE}:\\<close>\nlemma bindE_returnOk[simp]:\n  \"(m >>=E returnOk) = m\"\n  by (simp add: bindE_def returnOk_def)\n\ntext \\<open>Associativity of @{const bindE}:\\<close>\nlemma bindE_assoc:\n  \"(m >>=E f) >>=E g = m >>=E (\\<lambda>x. f x >>=E g)\"\n  unfolding bindE_def\n  by (fastforce simp: bind_assoc lift_def throwError_def\n                split: sum.splits\n                intro: arg_cong[where f=\"\\<lambda>x. m >>= x\"])\n\ntext \\<open>@{const returnOk} could also be defined via @{const liftE}:\\<close>\nlemma returnOk_liftE:\n  \"returnOk x = liftE (return x)\"\n  by (simp add: liftE_def returnOk_def)\n\ntext \\<open>Execution after throwing an exception is skipped:\\<close>\nlemma throwError_bindE[simp]:\n  \"(throwError E >>=E f) = throwError E\"\n  by (simp add: bindE_def bind_def throwError_def lift_def return_def)"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Syntax", "subsection": "The Monad Laws", "subsubsection": "", "code": "\ntext \\<open>This section defines traditional Haskell-like do-syntax\n  for the state monad in Isabelle.\\<close>"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Syntax", "subsection": "Syntax for the Exception Monad", "subsubsection": "", "code": "\ntext \\<open>\n  We use @{text K_bind} to syntactically indicate the case where the return argument\n  of the left side of a @{term bind} is ignored\\<close>\ndefinition K_bind :: \"'a \\<Rightarrow> 'b \\<Rightarrow> 'a\" where\n  K_bind_def[iff]: \"K_bind \\<equiv> \\<lambda>x y. x\"\n\nnonterminal\n  dobinds and dobind and nobind\n\nsyntax\n  \"_dobind\"    :: \"[pttrn, 'a] => dobind\"             (\"(_ <-/ _)\" 10)\n  \"\"           :: \"dobind => dobinds\"                 (\"_\")\n  \"_nobind\"    :: \"'a => dobind\"                      (\"_\")\n  \"_dobinds\"   :: \"[dobind, dobinds] => dobinds\"      (\"(_);//(_)\")\n\n  \"_do\"        :: \"[dobinds, 'a] => 'a\"               (\"(do ((_);//(_))//od)\" 100)\nsyntax (xsymbols)\n  \"_dobind\"    :: \"[pttrn, 'a] => dobind\"             (\"(_ \\<leftarrow>/ _)\" 10)\n\ntranslations\n  \"_do (_dobinds b bs) e\"  == \"_do b (_do bs e)\"\n  \"_do (_nobind b) e\"      == \"b >>= (CONST K_bind e)\"\n  \"do x <- a; e od\"        == \"a >>= (\\<lambda>x. e)\"\n\ntext \\<open>Syntax examples:\\<close>\nlemma \"do x \\<leftarrow> return 1;\n          return (2::nat);\n          return x\n       od =\n       return 1 >>=\n       (\\<lambda>x. return (2::nat) >>=\n            K_bind (return x))\"\n  by (rule refl)\n\nlemma \"do x \\<leftarrow> return 1;\n          return 2;\n          return x\n       od = return 1\"\n  by simp"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Syntax", "subsection": "Syntax for the Exception Monad", "subsubsection": "", "code": "\ntext \\<open>\n  Since the exception monad is a different type, we need to distinguish it in the syntax\n  if we want to avoid ambiguous terms. We use @{text doE}/@{text odE} for this, but can\n  re-use most of the productions from @{text do}/@{text od} above. \\<close>\nsyntax\n  \"_doE\" :: \"[dobinds, 'a] => 'a\"  (\"(doE ((_);//(_))//odE)\" 100)\n\ntranslations\n  \"_doE (_dobinds b bs) e\"  == \"_doE b (_doE bs e)\"\n  \"_doE (_nobind b) e\"      == \"b >>=E (CONST K_bind e)\"\n  \"doE x <- a; e odE\"       == \"a >>=E (\\<lambda>x. e)\"\n\ntext \\<open>Syntax examples:\\<close>\nlemma \"doE x \\<leftarrow> returnOk 1;\n           returnOk (2::nat);\n           returnOk x\n       odE =\n       returnOk 1 >>=E\n       (\\<lambda>x. returnOk (2::nat) >>=E\n            K_bind (returnOk x))\"\n  by (rule refl)\n\nlemma \"doE x \\<leftarrow> returnOk 1;\n           returnOk 2;\n           returnOk x\n       odE = returnOk 1\"\n  by simp"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Library of additional Monadic Functions and Combinators", "subsection": "Syntax for the Exception Monad", "subsubsection": "", "code": "\ntext \\<open>Lifting a normal function into the monad type:\\<close>\ndefinition liftM :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> ('s,'a) nondet_monad \\<Rightarrow> ('s, 'b) nondet_monad\" where\n  \"liftM f m \\<equiv> do x \\<leftarrow> m; return (f x) od\"\n\ntext \\<open>The same for the exception monad:\\<close>\ndefinition liftME :: \"('a \\<Rightarrow> 'b) \\<Rightarrow> ('s,'e+'a) nondet_monad \\<Rightarrow> ('s,'e+'b) nondet_monad\" where\n  \"liftME f m \\<equiv> doE x \\<leftarrow> m; returnOk (f x) odE\"\n\ntext \\<open>Execute @{term f} for @{term \"Some x\"}, otherwise do nothing.\\<close>\ndefinition maybeM :: \"('a \\<Rightarrow> ('s, unit) nondet_monad) \\<Rightarrow> 'a option \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"maybeM f y \\<equiv> case y of Some x \\<Rightarrow> f x | None \\<Rightarrow> return ()\"\n\ntext \\<open>Run a sequence of monads from left to right, ignoring return values.\\<close>\ndefinition sequence_x :: \"('s, 'a) nondet_monad list \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"sequence_x xs \\<equiv> foldr (\\<lambda>x y. x >>= (\\<lambda>_. y)) xs (return ())\"\n\ntext \\<open>\n  Map a monadic function over a list by applying it to each element\n  of the list from left to right, ignoring return values.\\<close>\ndefinition mapM_x :: \"('a \\<Rightarrow> ('s,'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s, unit) nondet_monad\" where\n  \"mapM_x f xs \\<equiv> sequence_x (map f xs)\"\n\ntext \\<open>\n  Map a monadic function with two parameters over two lists,\n  going through both lists simultaneously, left to right, ignoring\n  return values.\\<close>\ndefinition zipWithM_x ::\n  \"('a \\<Rightarrow> 'b \\<Rightarrow> ('s,'c) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> 'b list \\<Rightarrow> ('s, unit) nondet_monad\"\n  where\n  \"zipWithM_x f xs ys \\<equiv> sequence_x (zipWith f xs ys)\"\n\ntext \\<open>\n  The same three functions as above, but returning a list of\n  return values instead of @{text unit}\\<close>\ndefinition sequence :: \"('s, 'a) nondet_monad list \\<Rightarrow> ('s, 'a list) nondet_monad\" where\n  \"sequence xs \\<equiv> let mcons = (\\<lambda>p q. p >>= (\\<lambda>x. q >>= (\\<lambda>y. return (x#y))))\n                 in foldr mcons xs (return [])\"\n\ndefinition mapM :: \"('a \\<Rightarrow> ('s,'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s, 'b list) nondet_monad\" where\n  \"mapM f xs \\<equiv> sequence (map f xs)\"\n\ndefinition zipWithM ::\n  \"('a \\<Rightarrow> 'b \\<Rightarrow> ('s,'c) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> 'b list \\<Rightarrow> ('s, 'c list) nondet_monad\"\n  where\n  \"zipWithM f xs ys \\<equiv> sequence (zipWith f xs ys)\"\n\ndefinition foldM ::\n  \"('b \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad) \\<Rightarrow> 'b list \\<Rightarrow> 'a \\<Rightarrow> ('s, 'a) nondet_monad\"\n  where\n  \"foldM m xs a \\<equiv> foldr (\\<lambda>p q. q >>= m p) xs (return a) \"\n\ndefinition foldME ::\n  \"('b \\<Rightarrow> 'a \\<Rightarrow> ('s,('e + 'b)) nondet_monad) \\<Rightarrow> 'b \\<Rightarrow> 'a list \\<Rightarrow> ('s, ('e + 'b)) nondet_monad\"\n  where\n  \"foldME m a xs \\<equiv> foldr (\\<lambda>p q. q >>=E swp m p) xs (returnOk a)\"\n\ntext \\<open>\n  The sequence and map functions above for the exception monad, with and without\n  lists of return value\\<close>\ndefinition sequenceE_x :: \"('s, 'e+'a) nondet_monad list \\<Rightarrow> ('s, 'e+unit) nondet_monad\" where\n  \"sequenceE_x xs \\<equiv> foldr (\\<lambda>x y. doE _ <- x; y odE) xs (returnOk ())\"\n\ndefinition mapME_x :: \"('a \\<Rightarrow> ('s,'e+'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s,'e+unit) nondet_monad\" where\n  \"mapME_x f xs \\<equiv> sequenceE_x (map f xs)\"\n\ndefinition sequenceE :: \"('s, 'e+'a) nondet_monad list \\<Rightarrow> ('s, 'e+'a list) nondet_monad\" where\n  \"sequenceE xs \\<equiv> let mcons = (\\<lambda>p q. p >>=E (\\<lambda>x. q >>=E (\\<lambda>y. returnOk (x#y))))\n                   in foldr mcons xs (returnOk [])\"\n\ndefinition mapME ::\n  \"('a \\<Rightarrow> ('s,'e+'b) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s,'e+'b list) nondet_monad\"\n  where\n  \"mapME f xs \\<equiv> sequenceE (map f xs)\"\n\ntext \\<open>Filtering a list using a monadic function as predicate:\\<close>\nprimrec filterM :: \"('a \\<Rightarrow> ('s, bool) nondet_monad) \\<Rightarrow> 'a list \\<Rightarrow> ('s, 'a list) nondet_monad\" where\n  \"filterM P []       = return []\"\n| \"filterM P (x # xs) = do\n     b  <- P x;\n     ys <- filterM P xs;\n     return (if b then (x # ys) else ys)\n   od\"\n\ntext \\<open>An alternative definition of @{term state_select}\\<close>\nlemma state_select_def2:\n  \"state_select r \\<equiv> (do\n    s \\<leftarrow> get;\n    S \\<leftarrow> return {s'. (s, s') \\<in> r};\n    assert (S \\<noteq> {});\n    s' \\<leftarrow> select S;\n    put s'\n  od)\"\n  apply (clarsimp simp add: state_select_def get_def return_def assert_def fail_def select_def\n                            put_def bind_def fun_eq_iff\n                    intro!: eq_reflection)\n  apply fastforce\n  done"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Catching and Handling Exceptions", "subsection": "Syntax for the Exception Monad", "subsubsection": "", "code": "\ntext \\<open>\n  Turning an exception monad into a normal state monad\n  by catching and handling any potential exceptions:\\<close>\ndefinition catch ::\n  \"('s, 'e + 'a) nondet_monad \\<Rightarrow> ('e \\<Rightarrow> ('s, 'a) nondet_monad) \\<Rightarrow> ('s, 'a) nondet_monad\"\n  (infix \"<catch>\" 10) where\n  \"f <catch> handler \\<equiv>\n     do x \\<leftarrow> f;\n        case x of\n          Inr b \\<Rightarrow> return b\n        | Inl e \\<Rightarrow> handler e\n     od\"\n\ntext \\<open>\n  Handling exceptions, but staying in the exception monad.\n  The handler may throw a type of exceptions different from\n  the left side.\\<close>\ndefinition handleE' ::\n  \"('s, 'e1 + 'a) nondet_monad \\<Rightarrow> ('e1 \\<Rightarrow> ('s, 'e2 + 'a) nondet_monad) \\<Rightarrow> ('s, 'e2 + 'a) nondet_monad\"\n  (infix \"<handle2>\" 10) where\n  \"f <handle2> handler \\<equiv>\n   do\n      v \\<leftarrow> f;\n      case v of\n        Inl e \\<Rightarrow> handler e\n      | Inr v' \\<Rightarrow> return (Inr v')\n   od\"\n\ntext \\<open>\n  A type restriction of the above that is used more commonly in\n  practice: the exception handle (potentially) throws exception\n  of the same type as the left-hand side.\\<close>\ndefinition handleE ::\n  \"('s, 'x + 'a) nondet_monad \\<Rightarrow> ('x \\<Rightarrow> ('s, 'x + 'a) nondet_monad) \\<Rightarrow> ('s, 'x + 'a) nondet_monad\"\n  (infix \"<handle>\" 10) where\n  \"handleE \\<equiv> handleE'\"\n\ntext \\<open>\n  Handling exceptions, and additionally providing a continuation\n  if the left-hand side throws no exception:\\<close>\ndefinition handle_elseE ::\n  \"('s, 'e + 'a) nondet_monad \\<Rightarrow> ('e \\<Rightarrow> ('s, 'ee + 'b) nondet_monad) \\<Rightarrow>\n   ('a \\<Rightarrow> ('s, 'ee + 'b) nondet_monad) \\<Rightarrow> ('s, 'ee + 'b) nondet_monad\" (\"_ <handle> _ <else> _\" 10)\n  where\n  \"f <handle> handler <else> continue \\<equiv>\n   do v \\<leftarrow> f;\n      case v of Inl e  \\<Rightarrow> handler e\n              | Inr v' \\<Rightarrow> continue v'\n   od\""}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Catching and Handling Exceptions", "subsection": "Syntax for the Exception Monad", "subsubsection": "", "code": "\ntext \\<open>\n  Loops are handled using the following inductive predicate;\n  non-termination is represented using the failure flag of the\n  monad.\\<close>\n\ninductive_set whileLoop_results ::\n  \"('r \\<Rightarrow> 's \\<Rightarrow> bool) \\<Rightarrow> ('r \\<Rightarrow> ('s, 'r) nondet_monad) \\<Rightarrow> ((('r \\<times> 's) option) \\<times> (('r \\<times> 's) option)) set\"\n  for C B where\n    \"\\<lbrakk> \\<not> C r s \\<rbrakk> \\<Longrightarrow> (Some (r, s), Some (r, s)) \\<in> whileLoop_results C B\"\n  | \"\\<lbrakk> C r s; snd (B r s) \\<rbrakk> \\<Longrightarrow> (Some (r, s), None) \\<in> whileLoop_results C B\"\n  | \"\\<lbrakk> C r s; (r', s') \\<in> fst (B r s); (Some (r', s'), z) \\<in> whileLoop_results C B  \\<rbrakk>\n       \\<Longrightarrow> (Some (r, s), z) \\<in> whileLoop_results C B\"\n\ninductive_cases whileLoop_results_cases_valid: \"(Some x, Some y) \\<in> whileLoop_results C B\"\ninductive_cases whileLoop_results_cases_fail: \"(Some x, None) \\<in> whileLoop_results C B\"\ninductive_simps whileLoop_results_simps: \"(Some x, y) \\<in> whileLoop_results C B\"\ninductive_simps whileLoop_results_simps_valid: \"(Some x, Some y) \\<in> whileLoop_results C B\"\ninductive_simps whileLoop_results_simps_start_fail[simp]: \"(None, x) \\<in> whileLoop_results C B\"\n\ninductive whileLoop_terminates ::\n  \"('r \\<Rightarrow> 's \\<Rightarrow> bool) \\<Rightarrow> ('r \\<Rightarrow> ('s, 'r) nondet_monad) \\<Rightarrow> 'r \\<Rightarrow> 's \\<Rightarrow> bool\"\n  for C B where\n    \"\\<not> C r s \\<Longrightarrow> whileLoop_terminates C B r s\"\n  | \"\\<lbrakk> C r s; \\<forall>(r', s') \\<in> fst (B r s). whileLoop_terminates C B r' s' \\<rbrakk>\n        \\<Longrightarrow> whileLoop_terminates C B r s\"\n\ninductive_cases whileLoop_terminates_cases: \"whileLoop_terminates C B r s\"\ninductive_simps whileLoop_terminates_simps: \"whileLoop_terminates C B r s\"\n\ndefinition whileLoop ::\n  \"('a \\<Rightarrow> 'b \\<Rightarrow> bool) \\<Rightarrow> ('a \\<Rightarrow> ('b, 'a) nondet_monad) \\<Rightarrow> 'a \\<Rightarrow> ('b, 'a) nondet_monad\"\n  where\n  \"whileLoop C B \\<equiv> \\<lambda>r s.\n     ({(r',s'). (Some (r, s), Some (r', s')) \\<in> whileLoop_results C B},\n      (Some (r, s), None) \\<in> whileLoop_results C B \\<or> \\<not>whileLoop_terminates C B r s)\"\n\nnotation (output)\n  whileLoop  (\"(whileLoop (_)//  (_))\" [1000, 1000] 1000)\n\ndefinition whileLoopE ::\n  \"('r \\<Rightarrow> 's \\<Rightarrow> bool) \\<Rightarrow> ('r \\<Rightarrow> ('s, 'e + 'r) nondet_monad) \\<Rightarrow> 'r \\<Rightarrow> 's \\<Rightarrow> (('e + 'r) \\<times> 's) set \\<times> bool\"\n  where\n  \"whileLoopE C body \\<equiv>\n     \\<lambda>r. whileLoop (\\<lambda>r s. (case r of Inr v \\<Rightarrow> C v s | _ \\<Rightarrow> False)) (lift body) (Inr r)\"\n\nnotation (output)\n  whileLoopE  (\"(whileLoopE (_)//  (_))\" [1000, 1000] 1000)"}
{"title": "./spec/abstract/Nondeterministic State Monad with Failure.thy", "section": "Combinators that have conditions with side effects", "subsection": "Syntax for the Exception Monad", "subsubsection": "", "code": "\ndefinition notM :: \"('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad\" where\n  \"notM m = do c \\<leftarrow> m; return (\\<not> c) od\"\n\ndefinition whileM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad\"\n  where\n  \"whileM C B \\<equiv> do\n    c \\<leftarrow> C;\n    whileLoop (\\<lambda>c s. c) (\\<lambda>_. do B; C od) c;\n    return ()\n  od\"\n\ndefinition ifM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad \\<Rightarrow> ('s, 'a) nondet_monad\"\n  where\n  \"ifM test t f = do\n    c \\<leftarrow> test;\n    if c then t else f\n   od\"\n\ndefinition ifME ::\n  \"('a, 'b + bool) nondet_monad \\<Rightarrow> ('a, 'b + 'c) nondet_monad \\<Rightarrow> ('a, 'b + 'c) nondet_monad\n   \\<Rightarrow> ('a, 'b + 'c) nondet_monad\"\n  where\n  \"ifME test t f = doE\n    c \\<leftarrow> test;\n    if c then t else f\n   odE\"\n\ndefinition whenM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad \\<Rightarrow> ('s, unit) nondet_monad\"\n  where\n  \"whenM t m = ifM t m (return ())\"\n\ndefinition orM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad\"\n  where\n  \"orM a b = ifM a (return True) b\"\n\ndefinition andM ::\n  \"('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad \\<Rightarrow> ('s, bool) nondet_monad\"\n  where\n  \"andM a b = ifM a b (return False)\"\n\nend"}
